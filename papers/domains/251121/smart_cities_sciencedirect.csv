id,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1016/j.rcim.2021.102283,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-04-01,sciencedirect,Real-time data-driven dynamic scheduling for flexible job shop with insufficient transportation resources using hybrid deep Q network,https://api.elsevier.com/content/abstract/scopus_id/85118113364,"With the extensive application of automated guided vehicles in manufacturing system, production scheduling considering limited transportation resources becomes a difficult problem. At the same time, the real manufacturing system is prone to various disturbance events, which increase the complexity and uncertainty of shop floor. To this end, this paper addresses the dynamic flexible job shop scheduling problem with insufficient transportation resources (DFJSP-ITR) to minimize the makespan and total energy consumption. As a sequential decision-making problem, DFJSP-ITR can be modeled as a Markov decision process where the agent should determine the scheduling object and allocation of resources at each decision point. So this paper adopts deep reinforcement learning to solve DFJSP-ITR. In this paper, the multiobjective optimization model of DFJSP-ITR is established. Then, in order to make agent learn to choose the appropriate rule based on the production state at each decision point, a hybrid deep Q network (HDQN) is developed for this problem, which combines deep Q network with three extensions. Moreover, the shop floor state model is established at first, and then the decision point, generic state features, genetic-programming-based action space and reward function are designed. Based on these contents, the training method using HDQN and the strategy for facing new job insertions and machine breakdowns are proposed. Finally, comprehensive experiments are conducted, and the results show that HDQN has superiority and generality compared with current optimization-based approaches, and can effectively deal with disturbance events and unseen situations through learning.",smart cities
10.1016/j.ress.2021.108119,Journal,Reliability Engineering and System Safety,scopus,2022-02-01,sciencedirect,Prognostics and Health Management (PHM): Where are we and where do we (need to) go in theory and practice,https://api.elsevier.com/content/abstract/scopus_id/85117331443,"We are performing the digital transition of industry, living the 4th industrial revolution, building a new World in which the digital, physical and human dimensions are interrelated in complex socio-cyber-physical systems. For the sustainability of these transformations, knowledge, information and data must be integrated within model-based and data-driven approaches of Prognostics and Health Management (PHM) for the assessment and prediction of structures, systems and components (SSCs) evolutions and process behaviors, so as to allow anticipating failures and avoiding accidents, thus, aiming at improved safe and reliable design, operation and maintenance.
                  There is already a plethora of methods available for many potential applications and more are being developed: yet, there are still a number of critical problems which impede full deployment of PHM and its benefits in practice. In this respect, this paper does not aim at providing a survey of existing works for an introduction to PHM nor at providing new tools or methods for its further development; rather, it aims at pointing out main challenges and directions of advancements, for full deployment of condition-based and predictive maintenance in practice.",smart cities
10.1016/j.snb.2021.130958,Journal,Sensors and Actuators B: Chemical,scopus,2022-01-15,sciencedirect,From air quality sensors to sensor networks: Things we need to learn,https://api.elsevier.com/content/abstract/scopus_id/85118500250,"As a potential complement to traditional regulatory instruments, low-cost air quality sensors (LCAQS) can be deployed in dense monitoring networks to provide timely and comprehensive snapshots of pollutant concentrations and their spatial and temporal variability at various scales with relatively less cost and labor. However, a lack of practical guidance and a limited understanding of sensor data quality hinder the widespread application of this emerging technology. We leveraged air quality data collected from state and local monitoring agencies in metropolitan areas of the United States to evaluate how low-cost sensors could be deployed across the U.S. We found that ozone, as a secondary pollutant, is more homogeneous than other pollutants at various scales. PM2.5, CO, and NO2 displayed homogeneities that varied by city, making it challenging to design a uniform network that was suitable across geographies. Our low-cost sensor data in New York City indicated that PM2.5 sensors track well with light-scattering reference methods, particularly at low concentrations. The same phenomenon was also found after thoroughly evaluating sensor evaluation reports from the Air Quality Sensor Performance Evaluation Center (AQ-SPEC). Furthermore, LCAQS data collected during wildfire episodes in Portland, OR show that a real-time (i.e. in situ) machine learning calibration process is a promising approach to address the data quality challenges persisting in LCAQS applications. Our research highlights the urgency and importance of practical guidance for deploying LCAQS.",smart cities
10.1016/j.jenvman.2021.113950,Journal,Journal of Environmental Management,scopus,2022-01-15,sciencedirect,Water need and water use efficiency of two plant species in soil-containing and soilless substrates under green roof conditions,https://api.elsevier.com/content/abstract/scopus_id/85118363434,"Despite the significance of urban landscapes, there are limiting factors like spaces and water resources to expand them across the world. These limitations necessitate the development of water-conserving strategies in vertical infrastructures such as green roofs. One water-conserving strategy is precise irrigation regimes based on the plant species’ water needs. We investigated the water need of Carpobrotus edulis and Aptenia cordifolia under treatments with different soil-containing and soil-less water-absorbing substrate amenders and humic acid applications. The experiment was factorial based on a randomized complete block design with three replications and was conducted from May to September 2020. The first factor was the substrates with different green roof substrate compositions including soil-containing and soilless substrates with varying bentonite percentages. The second factor was humic acid levels (zero, 100, and 200 mg/l), which were applied as fertigation every 15 days during the experiment. Water needs were determined using the lysimetric method. The results showed that despite the soil-containing substrate with bentonite, the soilless substrate alone could not lead to optimal plant growth. The highest water use efficiency and the least evapotranspiration were obtained from the substrate containing 20%Soil +20% leca +20% perlite +20% mineral pumice +20% leaf litter plus 12% w bentonite, combined with A. cordifolia. This plant species showed a better performance compared with C. edulis. During the spring and summer months, the soil-containing substrate with bentonite and A. cordifolia can create a sustainable green roof system by creating better coverage, more water conservation, and a more aesthetic appearance. Based on the results, the application of the highest concentration level of humic acid (200 mg/l) increased the water use efficiency by about 40% after the establishment of the plants. Also, using this level of humic acid reduced the evapotranspiration rate in A. cordifolia up to 10 ml/day and in C. edulis up to 15 ml/day.",smart cities
10.1016/j.dsp.2021.103290,Journal,Digital Signal Processing: A Review Journal,scopus,2022-01-01,sciencedirect,Deep residual learning-based cognitive model for detection and classification of transmitted signal patterns in 5G smart city networks,https://api.elsevier.com/content/abstract/scopus_id/85118634214,"Primary user (PU) signal detection or classification is a critical component of cognitive radio (CR) related wireless communication applications. In CR, the PU detection methods are mostly based on statistical models, and their detection performance heavily relies on the accuracy of assumed models. In this paper, we design a novel detector, dubbed as PU-Net, that dynamically learns the PU activity patterns in a cognitive 5G smart city, where a network of unmanned aerial vehicles (UAVs) is deployed as flying base stations to serve the Internet-of-Things (IoT) users. Unlike the traditional schemes, the PU-Net is free from signal-noise model assumptions and is leveraged through deep residual learning integrated with atrous spatial pyramid pooling (ASPP) to sense the PU's transmitted signal patterns in the network. The PU-Net detects and classifies the active and idle PU states by exploiting the multilevel spatial-temporal features in the signal and noise frames. The proposed model is trained using locally synthesized Rayleigh channel-impaired data with large variability of modulated signals and different noise floor regimes. Additionally, the PU-Net model is blind-tested and evaluated on real-world over-the-air signals and with variable-length frames and varying channel effects at secondary users (SUs). With extensive experiments, it is shown that PU-Net outperforms other benchmark detectors, obtaining an accuracy of 0.9974, with 0.9978 recall and 0.9970 precision in detecting and classifying the PU transmitted signal patterns. Correspondingly, the proposed PU-Net can be adopted for IoT/UAV-assisted communication systems in optimizing spectrum efficiency and resolving the coexistence issues in 5G and beyond networks.",smart cities
10.1016/j.compind.2021.103556,Journal,Computers in Industry,scopus,2022-01-01,sciencedirect,C-Ports: A proposal for a comprehensive standardization and implementation plan of digital services offered by the “Port of the Future”,https://api.elsevier.com/content/abstract/scopus_id/85118477493,"In this paper we address the topic of a possible path to standardize the ICT services expected to be delivered by the so-called “Port of the Future”. How the most relevant technologies and Information Systems are used by the Port Communities for their businesses is discussed together with a detailed analysis of the on-going actions carried on by Standard Setting Organizations. Considering the examples given by the C-ITS Platform and the C-Roads programme at EU level, a proposal of contents to be considered in a comprehensive standardization action is given. The innovation services are therefore grouped into four bundles: (i) Vessel & Marine Navigation, (ii) e-Freight & (Intermodal) Logistics, (iii) Passenger Transport, (iv) Environmental sustainability. The standardized version of these applications will be finally labeled as C-Port services. Alongside the standardization plan, a proposal for ranking the ports on the basis of a specially-defined C-Port vector is discussed with the purpose of addressing the well-known lack of consensus around the mathematical definition of the Smart Port Index. Considering the good practice and the background offered by the Port of Livorno in terms of innovation actions, the prospected final user applications are then labeled as Day 1, Day 1.5, and Day 2 services in consideration of the technical and commercial gaps to be filled. As a case study about the evolution in the C-Port vector experienced by the Port of Livorno in the last years will also be discussed.",smart cities
10.1016/j.apenergy.2021.117853,Journal,Applied Energy,scopus,2022-01-01,sciencedirect,Transferable representation modelling for real-time energy management of the plug-in hybrid vehicle based on k-fold fuzzy learning and Gaussian process regression,https://api.elsevier.com/content/abstract/scopus_id/85114985028,"Electric vehicles, including plug-in hybrids, are important for achieving net-zero emission and will dominate road transportation in the future. Energy management, which optimizes the onboard energy usage, is a critical functionality of electric vehicles. It is usually developed following the model-based routine, which is conventionally costly and time-consuming and is hard to meet the increasing market competition in the digital era. To reduce the development workload for the energy management controller, this paper studies an innovative transfer learning routine. A new transferable representation control model is proposed by incorporating two promising artificial intelligence technologies, adaptive neural fuzzy inference system and Gaussian process regression, where the former applies k-fold cross valudation to build a neural fuzzy system for real-time implementation of offline optimization result, and the later connects the neural fuzzy system with a ‘deeper’ architecture to transfer the offline optimization knowledge learnt at source domain to new target domains. By introducing a concept of control utility that evaluates vehicle energy efficiency with a penalty on usage of battery energy, experimental evaluations based on the hardware-in-the-loop testing platform are conducted. Competitive real-time control ultility values (as much as 90% of offline benchmarking results) can be achieved by the proposed control method. They are over 27% higher than that achieved by the neural-network-based model.",smart cities
10.1016/j.future.2021.07.012,Journal,Future Generation Computer Systems,scopus,2022-01-01,sciencedirect,STGNN-TTE: Travel time estimation via spatial–temporal graph neural network,https://api.elsevier.com/content/abstract/scopus_id/85112278666,"Estimating the travel time of urban trajectories is a basic but challenging task in many intelligent transportation systems, which is the foundation of route planning and traffic control. The difficulty of travel time estimation is the impact of entangled spatial and temporal dynamics on real-time traffic conditions. However, most existing works does not fully exploit structured spatial information and temporal dynamics, resulting in low accuracy travel time estimation. To address the problem,we propose a novel spatial–temporal graph neural network framework, namely STGNN-TTE, for travel time estimation. Specifically, we adopt a spatial–temporal module to capture the real-time traffic conditions and a transformer layer to estimate the links’ travel time and the total routes’ travel time synchronously. In the spatial–temporal module, we present a multi-scale deep spatial–temporal graph convolutional network to capture the structured spatial–temporal dynamics. Also, in order to enhance the individual representation of each link, we adopt another transformer layer to extract the individualized long-term temporal dynamics. Finally, these two parts are integrated by a gating fusion module as the real-time traffic condition representation. We evaluate our model by sufficient experiments on three real-world trajectory datasets, and the experimental results demonstrate that our model is significantly superior to several existing methods.",smart cities
10.1016/j.foodchem.2021.130573,Journal,Food Chemistry,scopus,2022-01-01,sciencedirect,Development of a label free electrochemical sensor based on a sensitive monoclonal antibody for the detection of tiamulin,https://api.elsevier.com/content/abstract/scopus_id/85111054948,"Based on a murine monoclonal antibody (mAb) against tiamulin (TML), an electrochemical immunosensor was proposed using silver-graphene oxide (Ag-GO) nanocomposites and gold nanocomposites (AuNPs) to detect tiamulin (TML). Due to the synergetic properties of Ag-GO nanocomposites and AuNPs, the conductivity of the immunosensor was significantly enhanced. On account of the specific mAb and conductive nanocomposites, the proposed electrochemical immunosensor exhibited a low LOD of 0.003 ng mL−1 for the detection of TML in a wide linear range of 0.01 to 1000 ng mL−1. In addition, the immunosensor did not involve additional redox species. Furthermore, the efficient and simple electrochemical immunosensor was employed to detect TML in real samples with high accuracy, suggesting a potential detection platform for other veterinary antibiotics in animal derived foods.",smart cities
10.1016/j.eswa.2021.115718,Journal,Expert Systems with Applications,scopus,2021-12-30,sciencedirect,Two-stage convolutional neural network for road crack detection and segmentation,https://api.elsevier.com/content/abstract/scopus_id/85112844870,"Automatic detection of road cracks is an important task to support road inspection for transport infrastructure. Various methods have been proposed for road crack detection and segmentation, however, there is no established method for handling real road images that are noisy and of low quality. In this paper, a new method utilising a two-stage convolutional neural network (CNN) is proposed for road crack detection and segmentation in images at the pixel level. Our novel contribution is a framework where the first stage serves to remove noise or artifacts and isolate the potential cracks to a small area, and the second stage is able to learn the context of cracks in the detected area. This is hence more effective than learning over the entire original noisy image. Extensive experiments on real datasets including public sources and our collected dataset have been conducted. The experimental results show that the two-stage CNN model outperformed existing approaches, especially for noisy, low-resolution images, and imbalanced datasets. Our approach achieves an F1-measure of over 0.91 on three datasets.",smart cities
10.1016/j.tra.2021.10.009,Journal,Transportation Research Part A: Policy and Practice,scopus,2021-12-01,sciencedirect,Modelling the energy consumption of electric vehicles under uncertain and small data conditions,https://api.elsevier.com/content/abstract/scopus_id/85118560545,"This study models the energy consumption of electric vehicles (EVs) under uncertain and small data conditions by combining the machine learning method and the idea of controlled experiments. We propose a Machine Learning-Control Variable model, termed the MLCV model, to estimate the trip energy consumption of EVs. Different data augmentation methods, ensemble methods, sampling factors are adopted as the parameters of the proposed method. Through parameter search, the accuracy of the base learner can be further improved. Our method utilizes real driving behaviours that are generated by real drivers and collected in a complex urban environment, making the approach generalizable. The experimental results demonstrate that the proposed MLCV model is superior to existing machine learning models in terms of estimation accuracy.",smart cities
10.1016/j.scs.2021.103116,Journal,Sustainable Cities and Society,scopus,2021-12-01,sciencedirect,Cyber-Resilient Smart Cities: Detection of Malicious Attacks in Smart Grids,https://api.elsevier.com/content/abstract/scopus_id/85117711985,"A massive challenge for future cities is being environmentally sustainable by incorporating renewable energy resources (RES). At the same time, future smart cities need to support resilient environments against cyber-threats on their supported information and communication technologies (ICT). Therefore, the cybersecurity of future smart cities and their smart grids is of paramount importance, especially on how to detect cyber-attacks with growing uncertainties, such as frequent topological changes and RES of intermittent nature. Such raised uncertainties can cause a significant change in the underlying distribution of measurements and system states. In such an environment, historical measured data will not accurately exhibit the current network’s operating point. Hence, future power grids’ dynamic behaviors within smart cities are much more complicated than the conventional ones, leading to incorrect classification of the new instances by the current attack detectors. In this paper, to address this problem, a long short-term memory (LSTM) recurrent neural network (RNN) is carefully designed by embedding the dynamically time-evolving power system’s characteristics to accurately model the dynamic behaviors of modern power grids that are influenced by RES or system reconfiguration to distinguish natural smart grid changes and real-time attacks. The proposed framework’s performance is evaluated using the IEEE 14-bus system using real-world load data with multiple attack cases such as attacks to the network after a line outage and combination of RES. Results confirm that the developed LSTM-based attack detection model has a generalization ability to catch modern power grids’ dynamic behaviors, excelling current traditional approaches in the designed case studies and achieves accuracy higher than 90% in all experiments.",smart cities
10.1016/j.compeleceng.2021.107440,Journal,Computers and Electrical Engineering,scopus,2021-12-01,sciencedirect,Security and privacy-aware Artificial Intrusion Detection System using Federated Machine Learning,https://api.elsevier.com/content/abstract/scopus_id/85116891961,"Beyond 5G networks integrating 5G technology offer efficient services globally with sustainable higher capacity and much lower latency across various applications. Moving into the beyond 5G networks, edge intelligence solutions with data-driven machine learning algorithms and cybersecurity paradigms have become crucial among various real-time applications, including smart transportation, smart health, etc. Since the data gets transferred continuously from the edge devices to the dedicated computing in any edge computing environment, it experiences a higher risk of vulnerability and complexity measures. In this view, this paper firstly defines a federated machine learning mechanism for privacy-enhanced edge intelligence model Beyond 5G networks with Paillier Homomorphic Encryption and differential privacy. Secondly, an Artificial Immune Intrusion Detection System has been designed to monitor and classify the nodes resulting in an anomaly in the edge network so that the network can experience smooth and secure data transmission as per the requirement. The experiments and comparison results show that the proposed system is more optimal and secure than the existing edge security models.",smart cities
10.1016/j.comcom.2021.09.005,Journal,Computer Communications,scopus,2021-12-01,sciencedirect,Improving performance and data transmission security in VANETs,https://api.elsevier.com/content/abstract/scopus_id/85115794144,"This article proposes a new approach to achieve fast and reliable transfer of data and uses machine learning techniques for data processing to improve the performance and data transmission security of the vehicular network. The proposed approach is the combination of 5G cellular network and alternative data transmission channels. The data collection experiment took place within different areas of the city of Berlin over a 3-month time period and involved the use of 5G technologies. The study carried out the analysis and classification of big data with the help of position-based routing protocols and the Support Vector Machine algorithms. The said techniques were employed to detect non-line-of-sight (NLoS) conditions in real time, which ensure the secure transmission of data without the loss or degradation of network performance. The novelty of the work is that it tackles various traffic scenarios (the extent of road congestion can affect the quality of big data transmission) and offers a way to improve big data transfer using the Support Vector Machine technology. The study results show that the proposed approach is effective enough with big data and can be employed to improve the performance of urban VANET networks and data transmission security. The study results can be useful in developing high-performance 5G-VANET applications to improve traffic safety in urban vehicular environments.",smart cities
10.1016/j.asoc.2021.107859,Journal,Applied Soft Computing,scopus,2021-12-01,sciencedirect,Securing Smart Cities using LSTM algorithm and lightweight containers against botnet attacks,https://api.elsevier.com/content/abstract/scopus_id/85114806873,"Smart Cities contains millions of IoT sensors supporting critical applications such as Smart Transport, Buildings, Intelligent Vehicles, and Logistics. A central administrator appointed by the government manages and maintains the security of each node. Smart City relies upon millions of sensors that are heterogeneous and do not support standard security architecture. Different manufacturers have weak protection protocols for their products and do not update their firmware upon newly identified operating systems’ vulnerabilities. Adversaries using brute force methods exploit the lack of inbuilt security systems on IoT devices to grow their bot network. Smart cities require a standard framework combining soft computing and Deep Learning (DL) for device fleet management and complete control of sensor operating systems for absolute security. This paper presents a real-world application for IoT fleet management security using a lightweight container-based botnet detection (C-BotDet) framework. Using a three-phase approach, the framework using Artificial Intelligence detects compromised IoT devices sending malicious traffic on the network. Balena Cloud revokes API keys and prevents a compromised device from infecting other devices to form a more giant botnet. VPN (Virtual Private Network) prevents inter-device communication and routes all malicious traffic through an external server. The framework quickly updates the standard Linux-based operating system IoT device fleet without relying on different manufacturers to update their system security individually. The simulation and analysis of the C-BotDet framework are presented in a practical working environment to demonstrate its implementation feasibility.",smart cities
10.1016/j.jenvman.2021.113594,Journal,Journal of Environmental Management,scopus,2021-12-01,sciencedirect,A hybrid computational intelligence approach for bioremediation of amoxicillin based on fungus activities from soil resources and aflatoxin B1 controls,https://api.elsevier.com/content/abstract/scopus_id/85113717787,"Nowadays, releasing the Emerging Pollutants (EPs) in the nature is one of the main reasons for many health and environmental disasters. Amoxicillin as an antibiotic is one of the EPs and categorized as the Endocrine Disrupting Compounds (EDCs) in hazardous materials. Accumulation of amoxicillin in the soil bulk increases the cancer risk, drug resistances and other epidemiological diseases. Hence, the soil bioremediation of antibiotics can be a solution for this problem which is more environmental-friendly system. This study technically creates a bio-engine setup in soil bulk for remediation of amoxicillin based on Aspergillus Flavus (AF) activities and Removal Percentage (RP) of amoxicillin with Aflatoxin B1 Generation (AG) controls. The main novelty is to propose a hybrid computational intelligence approach to do optimization for mechanical and biological aspects and to predict the behavior of bio-engine's effective mechanical and biological features in an intelligent way. The optimization model is formulated by the Central Composite Design (CCD) which is set by the Response Surface Methodology (RSM). The prediction model is formulated by the Random Forest (RF), Adaptive Neuro Fuzzy Inference System (ANFIS) and Random Tree (RT) algorithms. According to the experimental practices from real soil samples in different times and places, concentration of amoxicillin and Aflatoxin B1 are set equal to 25 mg/L (ppm) and 15 μg/L (ppb). Likewise, the outcomes of experiments in CCD-RSM computations are evaluated by curve fitting comparisons between linear, 2FI, quadratic and cubic polynomial equations with considering to regression coefficient and predicted regression coefficient values, ANOVA and optimization by sequential differentiation. Based on the results of CCD-RSM, the RP performance in the optimum conditions is measured around 86% and in 25 days after runtime, the RP and AG are balanced in the safe mode. The proposed hybrid model achieves the 0.99 accuracy. The applicability of the research is done using real field evaluations from drug industrial park in Mashhad city in Iran. Finally, a broad analysis is done and managerial insights are concluded. The main findings of the present research are: (I) with application of bioremediation from fungus activities, amoxicillin amounts can be control in soil resources with minimum AG, (II) ANFIS model has the best accuracy for smart monitoring of amoxicillin bioremediation in soil environments and (III) based on the statistical assessments Aeration Intensity and AF/Biological Waste ratio are most effective on the amoxicillin removal percentage.",smart cities
10.1016/j.scs.2021.103265,Journal,Sustainable Cities and Society,scopus,2021-12-01,sciencedirect,Distributed Artificial Intelligence Empowered Sustainable Cognitive Radio Sensor Networks: A Smart City on-demand Perspective,https://api.elsevier.com/content/abstract/scopus_id/85113411074,"Smart cities are claimed to be smart if the new technologies are capable of providing desired sustainable outcome. The sustainable properties of smart city applications require less energy consumption and efficient resource allocation. The Internet-of-Things (IoT), 5G, and fog networks have emerged as the most crucial researched areas due to their numerous applications for smart cities to provide the desired sustainable outcome. The sustainable properties of Wireless Sensor Networks (WSNs) play a vital role in the deployment of these technologies into the physical world and efficient utilization of the available spectrum is a major problem faced here. As a potential solution of this, Cognitive Radio (CR) merged with WSN as Cognitive Radio Sensor Networks (CRSNs) make the smart perspective with high resource management through cooperative communication. The proposed work establishes a dynamic correlation between Secondary Users/nodes (SUs) in a single cluster according to their statistical behavior at the time of performing smart cooperative communication in CRSNs to improve sustainability of smart world IoT applications. Distributed Artificial Intelligence (DAI) is used to calculate the real-time resource allocation to these clusters using their respective Coordinator Agent (CoA) based on the dynamic behaviors. To improve sustainability in the smart city applications, the time delay in the prediction of vacant channels is reduced which results in making these applications become more energy efficient. The effectiveness of the proposed work is illustrated with mathematical analysis and simulation results confirm its better sustainable performance compared to the existing techniques.",smart cities
10.1016/j.eswa.2021.115498,Journal,Expert Systems with Applications,scopus,2021-12-01,sciencedirect,Real-time human pose estimation on a smart walker using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85109217957,"Rehabilitation is important to improve quality of life for mobility-impaired patients. Smart walkers are a commonly used solution that should embed automatic and objective tools for data-driven human-in-the-loop control and monitoring. However, present solutions focus on extracting few specific metrics from dedicated sensors with no unified full-body approach. We investigate a general, real-time, full-body pose estimation framework based on two RGB+D camera streams with non-overlapping views mounted on a smart walker equipment used in rehabilitation. Human keypoint estimation is performed using a two-stage neural network framework. The 2D-Stage implements a detection module that locates body keypoints in the 2D image frames. The 3D-Stage implements a regression module that lifts and relates the detected keypoints in both cameras to the 3D space relative to the walker. Model predictions are low-pass filtered to improve temporal consistency. A custom acquisition method was used to obtain a dataset, with 14 healthy subjects, used for training and evaluating the proposed framework offline, which was then deployed on the real walker equipment. An overall keypoint detection error of 3.73 pixels for the 2D-Stage and 44.05 mm for the 3D-Stage were reported, with an inference time of 26.6 ms when deployed on the constrained hardware of the walker. We present a novel approach to patient monitoring and data-driven human-in-the-loop control in the context of smart walkers. It is able to extract a complete and compact body representation in real-time and from inexpensive sensors, serving as a common base for downstream metrics extraction solutions, and Human-Robot interaction applications. Despite promising results, more data should be collected on users with impairments, to assess its performance as a rehabilitation tool in real-world scenarios.",smart cities
10.1016/j.eswa.2021.115380,Journal,Expert Systems with Applications,scopus,2021-11-30,sciencedirect,Intelligent control of an UAV with a cable-suspended load using a neural network estimator,https://api.elsevier.com/content/abstract/scopus_id/85111010813,"Unmanned aerial vehicles (UAVs) have been proved very useful in civil and military sectors: defense, security, shipping, construction, agriculture, entertainment, etc. Some of these applications, especially those related to transport and logistic operations, require the use of suspended loads that may make the vehicle unstable. In order to deal with this non-linear complex system with a changing mass, further research on modelling and control must be developed. In this work, a new intelligent control strategy is proposed and applied to a quadrotor with a cable-suspended load. The UAV carrying a suspended load has two different dynamic behaviors, depending on the state of the cable. Thus, we proposed to model the complete system using the hybrid automata formalism. Using this novel UAV model approach, a hybrid control is designed based on feedback linearization controllers combined with an artificial neural network, which acts as an online estimator of the unknown mass. The suspended load is dealt with as an external disturbance. Simulation results show how the on-line learning control scheme increases the robustness of the control and it is able to stabilize the quadrotor without any information about neither the position of the load nor the tension of the cable. Additionally, the computational complexity of the proposal is studied to show the feasibility of the implementation of this intelligent control strategy on real hardware.",smart cities
10.1016/j.neucom.2021.08.073,Journal,Neurocomputing,scopus,2021-11-13,sciencedirect,Balanced distortion and perception in single-image super-resolution based on optimal transport in wavelet domain,https://api.elsevier.com/content/abstract/scopus_id/85114383530,"Single image super-resolution (SISR) is a classic ill-posed problem in computer vision. In recent years, deep-learning-based (DL-based) models have achieved promising results with the SISR problem. However, most existing methods suffer from an intrinsic trade-off between distortion and perceptual quality. To satisfy the requirements in different real-world situations, the balance of distortion and visual quality for image super-resolution is a critical issue. In DL-based models, the uses of hybrid loss (i.e., the combination of the distortion loss and the perceptual loss) and network interpolation are two common approaches to balancing the distortion and perceptual quality of super-resolved images. However, these two kinds of methods lack flexibility and hold strict constraints on network architectures. In this paper, we propose an image-fusion interpolation method for image super-resolution, which can balance the distortion and visual quality of super-resolved images, based on the optimal transport theory in the wavelet domain. The advantage of our proposed method is that it can be applied to any pretrained DL-based model, without any requirement from the network architecture and parameters. In addition, our proposed method is parameter-free and can run fast without using a GPU. Compared with existing state-of-the-art SISR methods, experiment results show that our proposed method can achieve a better balance between the distortion and visual quality in super-resolved images.",smart cities
10.1016/j.ins.2021.08.086,Journal,Information Sciences,scopus,2021-11-01,sciencedirect,Multi-view group representation learning for location-aware group recommendation,https://api.elsevier.com/content/abstract/scopus_id/85118764349,"With the development of location-based services (LBS), many location-based social sites like Foursquare and Plancast have emerged. People can organize and participate in group activities on those sites. Therefore, recommending venues for group activities is of practical value. However, the group decision making process is complicated, requiring trade-offs among group members. And the data sparsity and cold-start problems make it difficult to make effective group recommendation. In this manuscript, we propose a Multi-view Group Representation Learning (MGPL) framework for location-aware group recommendation. The proposed multi-view group representation learning framework can leverage multiple types of information for deep representation learning of group preferences and incorporate the spatial attributes of locations to further capture the group mobility preferences. Experiments on two real datasets Foursqaure and Plancast show that our method significantly outperforms the-state-of-art approaches.",smart cities
10.1016/j.trc.2021.103416,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-11-01,sciencedirect,DRL-TP3: A learning and control framework for signalized intersections with mixed connected automated traffic,https://api.elsevier.com/content/abstract/scopus_id/85116670530,"The emerging connected and automated vehicle (CAV) technologies offer new opportunities for urban signalized intersection management. Through wireless communication and advanced sensing capabilities, CAVs can detect the surrounding traffic environment and share real-time vehicular information with each other and the infrastructure, and individual trajectories of CAVs can be precisely controlled. This paper proposes a real-time learning and control framework for signalized intersection management, which includes both signal optimization and CAV trajectory control. The proposed framework integrates perception, prediction, planning, and optimization components and aims at improving efficiency mixed connected automated traffic in terms of traffic throughput and delay. This framework applies the Long Short Term Memory (LSTM) networks to implicitly learn traffic patterns and driver behavior and then estimate and predict the microscopic traffic conditions that are only partially observable. Then it utilizes deep reinforcement learning (DRL) to solve signal optimization problems by learning from the dynamic interactions between vehicles and the traffic environment. Under the proposed framework, the vehicular trajectories of CAVs can be controlled to maximize the utilization of the green time and reduce the start-up lost time by using a highly efficient trajectory planning algorithm. The CAV platooning operation, in coordination with traffic signals, is also implemented such that CAVs can pass the intersection efficiently. Simulations are performed at a signalized intersection a signalized intersection with multi-lane approaches, high traffic demand, and standard ring-barrier control, and results show that the proposed DRL-TP3 framework can significantly improve the throughput and reduce the average delay across different CAV market penetration rates (MPRs). We also investigate the impacts of different sensor capabilities of unobservable vehicle estimation and implementation of a lane change prohibition zone under the DRL-TP3 framework.",smart cities
10.1016/j.aap.2021.106409,Journal,Accident Analysis and Prevention,scopus,2021-11-01,sciencedirect,A deep learning approach for real-time crash prediction using vehicle-by-vehicle data,https://api.elsevier.com/content/abstract/scopus_id/85116019471,"In road safety, real-time crash prediction may play a crucial role in preventing such traffic events. However, much of the research in this line generally uses data aggregated every five or ten minutes. This article proposes a new image-inspired data architecture capable of capturing the microscopic scene of vehicular behavior. In order to achieve this, an accident-prediction model is built for a section of the Autopista Central urban highway in Santiago, Chile, based on the concatenation of multiple-input Convolutional Neural Networks, using both the aggregated standard traffic data and the proposed architecture. Different oversampling methodologies are analyzed to balance the training data, finding that the Deep Convolutional Generative Adversarial Networks technique with random undersampling presents better results when generating synthetic instances that permit maximizing the predictive performance. Computational experiments suggest that this model outperforms other traditional prediction methodologies in terms of AUC and sensitivity values over a range of false positives with greater applicability in real life.",smart cities
10.1016/j.trc.2021.103389,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-11-01,sciencedirect,Multi-models machine learning methods for traffic flow estimation from Floating Car Data,https://api.elsevier.com/content/abstract/scopus_id/85115775540,"Traffic flow measurement is very important for traffic management systems. However, the existing traditional measurement approaches are highly time-consuming and expensive to continuously gather the required data and to maintain the corresponding equipment, such as loop detectors and video cameras. On the other hand, many services on the web propose to estimate automobile travel time taking into account traffic conditions thanks to crowd sourced data (Floating Car Data). This work proposes to reconstruct, from estimated travel time, traffic flows using machine learning method. In particular, we evaluate the capacity of Gaussian Process Regressor (GPR) to address this issue. After obtaining estimated travel time on a given route, a clustering process shows that travel duration profiles in each day can be associated to different “types of day”. Then, different regressors are trained in order to estimate traffic flows from travel duration. In the “multi-model” variant, we trained a Regressor for each type of day. Conversely, in the “single model” variant, only one Regressor is trained (the type of day is not taken into account). This is an innovative work to estimate and reconstruct the traffic flow in transportation networks with machine learning method from aggregated Floating Car Data (FCD). A series of experiments are conducted to compare the estimated traffic flows, obtained by the proposed single model and multi-model, and the real ones from actual sensors. The obtained results show that both single model and multi-models can capture the tendency of real traffic flows. Furthermore, the performance can be improved by regulating parameters in GPR machine learning model, such as half width of sample window and sample size (a whole week or only weekdays), and multi-models can highly increase the performance compared with the single model. Therefore, the proposed GPR machine learning and FCD based new method can replace those traditional loop detectors for the measurement of traffic flow.",smart cities
10.1016/j.trc.2021.103372,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-11-01,sciencedirect,A customized deep learning approach to integrate network-scale online traffic data imputation and prediction,https://api.elsevier.com/content/abstract/scopus_id/85114686460,"Online data imputation and traffic prediction based on real-time data streams are essential for the intelligent transportation systems, particularly online navigation applications based on the real-time traffic information. However, the inevitable data missing problem caused by various disturbances undermines the information contained in such real-time data, thereby threatening the reliability of data acquisition as well as the prediction results. Such scenarios raise a strong need for integrating the tasks of network-scale online data imputation and traffic prediction, because the existing two-step approaches that separate the above procedures cannot be implemented in an online manner. In this paper, we propose a customized spatiotemporal deep learning architecture, named the graph convolutional bidirectional recurrent neural network (GCBRNN), to combine network-scale online data imputation and traffic prediction into an integrated task. The imputation mechanism and bidirectional framework are developed to cooperatively estimate missing entries and infer future values. We further design a network-scale graph convolutional gated recurrent unit (NGC-GRU) within the GCBRNN, which applies the graph convolution operation and 
                        
                           1
                           ×
                           1
                        
                      convolution module to capture the spatiotemporal dependencies in the traffic data. Experiments are carried out on two real-world traffic networks, including traffic speed and flow datasets. The comparison results demonstrate that our approach significantly outperforms several classical benchmark models with respect to both the imputation and prediction tasks on two datasets under various missing data rates.",smart cities
10.1016/j.scs.2021.103209,Journal,Sustainable Cities and Society,scopus,2021-11-01,sciencedirect,Evaluation of policy options supporting electric vehicles in city logistics: a case study,https://api.elsevier.com/content/abstract/scopus_id/85112641022,"Due to the restriction of movement of heavy-duty vehicles (e.g.trucks), most cities have started to implement urban consolidation centers to reduce the negative impact of carbon emission. Accordingly, this study focuses on the city logistics problem with respect to policy decisions regarding the use of light commercial vehicles through urban consolidation schemes in a way to minimise carbon emissions and, thus, total transportation costs. In particular, this study has developed a mathematical model to minimise total transportation costs including routing costs, vehicle fixed costs, emission costs, and zone entry fees. The proposed model is solved using a modified ant colony optimisation (MACO) technique. The optimal results are obtained within CPU time, and results are validated using the ACO algorithm and the Cplex solver. Meanwhile, different supporting policies are introduced, and computational experiments are executed on a real-life case study. Results show that the purchase subsidy and zone entry fee are significant considerations when promoting electric vehicles (EVs) in city logistics.",smart cities
10.1016/j.apenergy.2021.117504,Journal,Applied Energy,scopus,2021-11-01,sciencedirect,Deep reinforcement learning control of electric vehicle charging in the presence of photovoltaic generation,https://api.elsevier.com/content/abstract/scopus_id/85111920114,"In recent years, the importance of electric mobility has increased in response to climate change. The fast-growing deployment of electric vehicles (EVs) worldwide is expected to decrease transportation-related 
                        
                           C
                           
                              
                                 O
                              
                              
                                 2
                              
                           
                        
                      emissions, facilitate the integration of renewables, and support the grid through demand–response services. Simultaneously, inadequate EV charging patterns can lead to undesirable effects in grid operation, such as high peak-loads or low self-consumption of solar electricity, thus calling for novel methods of control. This work focuses on applying deep reinforcement learning (RL) to the EV charging control problem with the objectives to increase photovoltaic self-consumption and EV state of charge at departure. Particularly, we propose mathematical formulations of environments with discrete, continuous, and parametrized action spaces and respective deep RL algorithms to resolve them. The benchmarking of the deep RL control against naive, rule-based, deterministic optimization, and model-predictive control demonstrates that the suggested methodology can produce consistent and employable EV charging strategies, while its performance holds a great promise for real-time implementations.",smart cities
10.1016/j.ssci.2021.105407,Journal,Safety Science,scopus,2021-11-01,sciencedirect,Highway 4.0: Digitalization of highways for vulnerable road safety development with intelligent IoT sensors and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85111074950,"According to United Nations (UN) 2030 agenda, the transportation system needs to be enhanced for the establishment of access to safe, affordable, accessible, and sustainable transport systems along with enhanced road safety. The highway road transport system is one of the transport systems that enables to transits goods and humans from one location to another location. The agenda of UN 2030 for the transport system will be accomplished with the assistance of digital technologies like the internet of things (IoT) and artificial intelligence (AI). The implementation of these digital technologies on highways empowers to provide reliable, smarter, intelligent, and renewable energy sources experience to the users travelling along the highways. This study discusses the significance of the digitalization of highways that supporting and realizing a sustainable environment on the highways. To discuss the significance of digitalization, the study has categorized digitalization into five subcomponents namely smart highway lighting system, smart traffic and emergency management system, renewable energy sources on highways, smart display and AI in highways. An architecture-for smart highway lighting, smart traffic, and emergency management are proposed and discussed in the study. The significance of implementing smart display boards and renewable sources with real-time applications is also addressed in this study. Moreover, the integration of AI in highways is addressed with the perspective of enhancing road safety. The integration of deep learning (DL) in the edge-based vision node for predicting the patterns of traffic flow, highway road safety, and maintenance of quality roads have been addressed in the discussion section. Embedding the deep learning techniques in the vison node at the traffic junction and the highway lighting controller is able to deliver an intelligent system that provides sustained experience and management of the highways. Smart reflectors, adoption of renewable energy, developing vehicle-to-vehicle communication in vehicles, and smart lamppost are the few recommendations for the implementation of digitalizing highways.",smart cities
10.1016/j.comnet.2021.108379,Journal,Computer Networks,scopus,2021-10-24,sciencedirect,Q-FANET: Improved Q-learning based routing protocol for FANETs,https://api.elsevier.com/content/abstract/scopus_id/85112294163,"Flying Ad-Hoc Networks (FANETs) introduce ad-hoc networking into the context of flying nodes, allowing real-time communication between these nodes and ground control stations. Due to the nature of this kind of node, the structure of a FANET is dynamic, changing very often. Since it has applications in military scenarios and other mission-critical systems, an agile and reliable network is essential with robust and efficient routing protocols. Nonetheless, maintaining an acceptable network delay generated by the selection of routes remains a considerable challenge, owing to the nodes’ high mobility. This article addresses this problem by proposing a routing scheme based on an improved Q-Learning algorithm to reduce network delay in scenarios with high-mobility, called Q-FANET. This proposal has its performance evaluated and compared with other state-of-the-art methods using the WSNET simulator. The experiments provide evidence that the Q-FANET presents lower delay, a minor increase in packet delivery ratio, and significant lower jitter compared with other reinforcement learning-based routing protocols.",smart cities
10.1016/j.jenvman.2021.113191,Journal,Journal of Environmental Management,scopus,2021-10-15,sciencedirect,Exploring the potential of utilizing unsupervised machine learning for urban drainage sensor placement under future rainfall uncertainty,https://api.elsevier.com/content/abstract/scopus_id/85109431597,"Recently, advanced informatics and sensing techniques show promise of enabling a new generation of smart stormwater systems, where real-time sensors are deployed to detect flooding hotspots. Existing stormwater design criteria assume that historical rainfall frequency and intensity are reliable predictors to place real-time sensing devices. However, nonstationarity in rainfall due to climate change violates this assumption by disturbing hydrologic regimes and relocating flooding spots. This paper proposes a novel methodology of combining unsupervised machine learning (Agglomerative Clustering) and analysis of variance (ANOVA) to optimize the sensor placement under uncertain rainfalls. An urban drainage network located in Salt Lake City, Utah, USA, is chosen as the case study to demonstrate the application of the proposed method. Results show that: i) the proposed Agglomerative Clustering and ANOVA integrated approach can efficiently and accurately pinpoint sensor locations for drainage flooding detection; ii) rainfall uncertainty has limited impacts on the number of sensors, but it induces significant effects on sensor locations from the historical period (2000–2009) to the future period (2040–2049). By exploring the effects of climate nonstationarity on sensor placement, this work aims to help engineers and decision-makers better respond to the changing climates and rainfall extremes in urban drainage catchments.",smart cities
10.1016/j.eswa.2021.115080,Journal,Expert Systems with Applications,scopus,2021-10-15,sciencedirect,Spectral decision in cognitive radio networks based on deep learning,https://api.elsevier.com/content/abstract/scopus_id/85105355301,"Cognitive radio networks (CRN) have gained great relevance in the efficient use of the radio spectrum, and one of the key aspects of this technology is the spectral decision. The performance of secondary user communication depends largely on the intelligent choice of an appropriate spectral opportunity. The purpose of this research is to propose and assess the performance of a spectral decision model for CRN based on the Deep Learning technique. To achieve this, a classifier was adapted through the feature extraction technique that identifies three levels of traffic (high, medium and low) in a spectral occupation experimental power matrix that models the primary user. The extraction of features is done by Deep Learning and the process of classifying the successful set of features is done by a Support Vector Machine (SVM). These were used along with five evaluation metrics—total handoffs, failed handoffs, bandwidth, delay and throughput—to measure the performance of the proposed spectral decision model based on the Deep Learning technique, and to compare the results with the Multi-Criteria Optimization and Compromise Solution (VIKOR), Technique for Order Preference by Similarity to Ideal Solution (TOPSIS), and Simple Additive Weighting (SAW). This work presents five contributions: incorporation of the real behavior of licensed users, implementation of performance metrics for spectral mobility, proposal of an RGB conversion algorithm based on the threshold level, feedback in the classifier and a methodology based on priorities and scores to establish the channels with the highest availability. The results of this evaluation show that the proposed model has a better performance in the five metrics compared to the other techniques.",smart cities
10.1016/j.neucom.2021.06.028,Journal,Neurocomputing,scopus,2021-10-07,sciencedirect,A joint temporal-spatial ensemble model for short-term traffic prediction,https://api.elsevier.com/content/abstract/scopus_id/85108592550,"In this paper, we address the problem of short-term traffic flow prediction since accurate prediction of short-term traffic flow facilitates timely traffic management and rapid response. We advocate deep machine learning approach and propose a novel ensemble model, named ALLSCP, that considers both temporal and spatial characteristics of traffic conditions. Specifically, we consider (1) short-, medium- and long-term temporal traffic evolution, (2) global and local spatial traffic patterns and (3) the correlation of temporal-spatial features in our predictions. We use real-world traffic data from two locations (i.e., Los Angeles and London) with frequent fluctuations (due to proneness to traffic accidents and/or congestion) to train and test our model. For each location, we consider road segments with and without junctions (i.e., linear vs intersection). We compare our model against well-known existing machine/deep learning prediction models. Our results indicate that our ALLSCP model consistently achieves the most accurate predictions (
                        
                           ≈
                           96
                           %
                        
                      accuracy both on linear and intersection roadways) when compared against existing models in the literature. In addition, we conducted ablation experiments to further gain insights into the contributions of individual constituent models of our ensemble ALLSCP model. Our results indicate that ALLSCP achieves the best results and is also robust against emergent traffic situations.",smart cities
10.1016/j.aei.2021.101393,Journal,Advanced Engineering Informatics,scopus,2021-10-01,sciencedirect,A real-time vehicle detection and a novel vehicle tracking systems for estimating and monitoring traffic flow on highways,https://api.elsevier.com/content/abstract/scopus_id/85113660129,"Real-time highway traffic monitoring systems play a vital role in road traffic management, planning, and preventing frequent traffic jams, traffic rule violations, and fatal road accidents. These systems rely entirely on online traffic flow info estimated from time-dependent vehicle trajectories. Vehicle trajectories are extracted from vehicle detection and tracking data obtained by processing road-side camera images. General-purpose object detectors including Yolo, SSD, EfficientNet have been utilized extensively for real-time object detection task, but, in principle, Yolo is preferred because it provides a high frame per second (FPS) performance and robust object localization functionality. However, this algorithm’s average vehicle classification accuracy is below 57%, which is insufficient for traffic flow monitoring. This study proposes improving the vehicle classification accuracy of Yolo, and developing a novel bounding box (Bbox)-based vehicle tracking algorithm. For this purpose, a new vehicle dataset is prepared by annotating 7216 images with 123831 object patterns collected from highway videos. Nine machine learning-based classifiers and a CNN-based classifier were selected. Next, the classifiers were trained via the dataset. One out of ten classifiers with the highest accuracy was selected to combine to Yolo. This way, the classification accuracy of the Yolo-based vehicle detector was increased from 57% to 95.45%. Vehicle detector 1 (Yolo) and vehicle detector 2 (Yolo + best classifier), and the Kalman filter-based tracking as vehicle tracker 1 and the Bbox-based tracking as vehicle tracker 2 were applied to the categorical/total vehicle counting tasks on 4 highway videos. The vehicle counting results show that the vehicle counting accuracy of the developed approach (vehicle detector 2 + vehicle tracker 2) was improved by 13.25% and this method performed better than the other 3 vehicle counting systems implemented in this study.",smart cities
10.1016/j.ins.2021.08.042,Journal,Information Sciences,scopus,2021-10-01,sciencedirect,Exploiting dynamic spatio-temporal correlations for citywide traffic flow prediction using attention based neural networks,https://api.elsevier.com/content/abstract/scopus_id/85113394687,"For intelligent transportation systems (ITS), predicting urban traffic crowd flows is of great importance. However, it is challenging to represent various complex spatial relationships across distinct regions, as well as dynamic temporal relations among various time periods. To overcome this challenge, we propose DHSTNet, a novel deep Spatio-temporal neural network for predicting traffic crowd flows. Our proposed approach consists of four components: (i) the closeness component considers spontaneous changes of the traffic crowd flows; (ii) the period influence component frequently characterizes variations of daily flows; (iii) the weekly influence component characterizes the weekly arrangements of crowd flows; and (iv) the external branch component identifies various external influences. Our model applies diverse weights to individual branches. Then, it fuses the outcomes of the four features. Extensive experiments on two real-world datasets demonstrate the advantage of the proposed model over the compared baseline methods. Moreover, to verify the generalization of the proposed model, we apply the proposed attention-based mechanism with a previously proposed model, resulting in a hybrid approach known as Att-DHSTNet, to forecast short-term crowd flows. Experimental results also confirm improved performance.",smart cities
10.1016/j.envsci.2021.06.011,Journal,Environmental Science and Policy,scopus,2021-10-01,sciencedirect,A Big Data and Artificial Intelligence Framework for Smart and Personalized Air Pollution Monitoring and Health Management in Hong Kong,https://api.elsevier.com/content/abstract/scopus_id/85111282536,"All people in the world are entitled to enjoy a clean environment and a good quality of life. With big data and artificial intelligence technologies, it is possible to estimate personalized air pollution exposure and synchronize it with activity, health, quality of life and behavioural data, and provide real-time, personalized and interactive alert and advice to improve the health and well-being of individual citizens. In this paper, we propose an overarching framework outlining five major challenges to personalized air pollution monitoring and health management, and respective methodologies in an integrated interdisciplinary manner. First, urban air quality data is sparse, rendering it difficult to provide timely personalized alert and advice. Second, collected data, especially those involving human inputs such as health perception, are often missing and erroneous. Third, the data collected are heterogeneous, and highly complex, not easily comprehensible to facilitate individual and collective decision-making. Fourth, the causal relationships between personal air pollutants exposure (specifically, PM2.5 and PM1.0 and NO2) and personal health conditions, and health-related quality of life perception, of young asthmatics and young healthy citizens in Hong Kong (HK), are yet to be established. Fifth, whether personalized and smart information and advice provided can induce behavioural change and improve health and quality of life are yet to be determined. To overcome these challenges, our first novelty is to develop an AI and big data framework to estimate and forecast air quality in high temporal-spatial resolution and real-time. Our second novelty includes the deployment of mobile pollution sensor platforms to substantially improve the accuracy of estimated and forecasted air quality data, and the collection of activity, health condition and perception data. Our third novelty is the development of visualization tools and comprehensible indexes, by correlating personal exposure with four types of personal data, to provide timely, personalized pollution, health and travel alerts and advice. Our fourth novelty is determining causal relationship, if any, between personal pollutants, PM1.0 and PM2.5, NO2 exposure and personal health condition, and personal health perception, based on a clinical experiment of 150 young asthmatics and 150 young healthy citizens in HK. Our fifth novelty is an intervention study to determine if smart information, presented via our proposed visualized platform, will induce personal behavioural change. Our novel big data AI-driven approach, when integrated with other analytical approaches, provides an integrated interdisciplinary framework for personalized air pollution monitoring and health management, easily transferrable to and applicable in other domains and countries.",smart cities
10.1016/j.chaos.2021.111246,Journal,"Chaos, Solitons and Fractals",scopus,2021-10-01,sciencedirect,To restrict or not to restrict? Use of artificial neural network to evaluate the effectiveness of mitigation policies: A case study of Turkey,https://api.elsevier.com/content/abstract/scopus_id/85111261415,"Outbreaks, epidemics or pandemics have increased over the last years, increasing the morbidity and mortality over large geographical areas, as well as causing financial crises and irreversible social changes. Coping with emerging infectious diseases such as Covid-19, different mitigation policies are developed by countries. However, the benefit of each mitigation policy is still not well-explored due to the considerable difference between implementations of policies in each country. The question is which policies play a significant role in controlling Covid-19 transmission. Developing two models used in Artificial Neural Network, this study investigates the impact of mitigation policies or strategies (a combination of policies) by considering different vaccination and mutation scenarios. The former model requires the prediction of reproduction number based on the number of cases reported in previous days; whereas, the latter model is constructed based on the number of people impacted by a mitigation policy or strategy. Although the first model yields more accurate results, it requires the use of historical data; hence, the passage of time during a critical period of fighting against Covid-19. The benefit of the second model is that it can be implemented more quickly by determining a coefficient for each policy or strategy based on the restricted population and/or limited mobility. Testing different scenarios through a real-world example from Turkey, we find mitigation policies or strategies play a significant role in controlling Covid-19; as well as vaccination and mutation scenarios. Our results suggest continuous and predetermined mitigation policies or strategies should be implemented to control the spread of infectious diseases in addition to a successful vaccination program.",smart cities
10.1016/j.xphs.2021.05.016,Journal,Journal of Pharmaceutical Sciences,scopus,2021-10-01,sciencedirect,"Microstructure, Quality, and Release Performance Characterization of Long-Acting Polymer Implant Formulations with X-Ray Microscopy and Quantitative AI Analytics",https://api.elsevier.com/content/abstract/scopus_id/85111064589,"Long-acting implants are typically formulated using carrier(s) with specific physical and chemical properties, along with the active pharmaceutical ingredient (API), to achieve the desired daily exposure for the target duration of action. In characterizing such formulations, real-time in-vitro and in-vivo experiments that are typically used to characterize implants are lengthy, costly, and labor intensive as these implants are designed to be long acting. A novel characterization technique, combining high resolution three-dimensional X-Ray microscopy imaging, image-based quantification, and transport simulation, has been employed to provide a mechanistic understanding of formulation and process impact on the microstructures and performance of a polymer-based implant. Artificial intelligence-based image segmentation and image data analytics were used to convert morphological features visualized at high resolution into numerical microstructure models. These digital models were then used to calculate key physical parameters governing drug transport in a polymer matrix, including API uniformity, API domain size, and permeability. This powerful new tool has the potential to advance the mechanistic understanding of the interplay between drug-microstructure and performance and accelerate the therapeutic development long-acting implants.",smart cities
10.1016/j.scs.2021.103111,Journal,Sustainable Cities and Society,scopus,2021-10-01,sciencedirect,Multi-stage deep learning approaches to predict boarding behaviour of bus passengers,https://api.elsevier.com/content/abstract/scopus_id/85108877077,"Smart card data has emerged in recent years and provide a comprehensive, and cheap source of information for planning and managing public transport systems. This paper presents a multi-stage machine learning framework to predict passengers’ boarding stops using smart card data. The framework addresses the challenges arising from the imbalanced nature of the data (e.g. many non-travelling data) and the ‘many-class’ issues (e.g. many possible boarding stops) by decomposing the prediction of hourly ridership into three stages: whether to travel or not in that one-hour time slot, which bus line to use, and at which stop to board. A simple neural network architecture, fully connected networks (FCN), and two deep learning architectures, recurrent neural networks (RNN) and long short-term memory networks (LSTM) are implemented. The proposed approach is applied to a real-life bus network. We show that the data imbalance has a profound impact on the accuracy of prediction at individual level. At aggregated level, FCN is able to accurately predict the rideship at individual stops, it is poor at capturing the temporal distribution of ridership. RNN and LSTM are able to measure the temporal distribution but lack the ability to capture the spatial distribution through bus lines.",smart cities
10.1016/j.asoc.2021.107601,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,Hierarchical deep reinforcement learning to drag heavy objects by adult-sized humanoid robot,https://api.elsevier.com/content/abstract/scopus_id/85107951694,"Most research on robot manipulation focuses on objects that are light enough for the robot to pick them up. However, in our daily life, some objects are too big or too heavy to be picked up or carried, so that dragging them is necessary. Although bipedal humanoid robots have nowadays good mobility on level ground, dragging unfamiliar objects including large and heavy objects on various surfaces is an interesting research area with many applications, which will provide insights into human manipulation and will encourage the development of novel algorithms for robot motion planning and control. This is a challenging problem, not only because of the unknown and potentially variable friction of the foot, but also because the feet of the robot may slip during unbalanced poses. In this paper, we propose a novel hierarchical deep learning algorithm that learns how to drag heavy objects with an adult-sized humanoid robot for the first time. First, we present a Three-layered Convolution Volumetric Network (TCVN) for 3D object classification with point clouds volumetric occupancy grid integration. Second, we propose a lightweight real-time instance segmentation method named Tiny-YOLACT for the detection and classification of the floor surface. Third, we propose a deep Q-learning algorithm to learn the policy control of the Center of Mass of the robot (DQL-COM). The DQL-COM algorithm learning is bootstrapped using the ROS Gazebo simulator. After initial training, we complete training on the THORMANG-Wolf, a 1.4 m tall adult-sized humanoid robot with 27 degrees of freedom and weighing 48 kg, on three distinct types of surfaces. We evaluate the performance of our approach by dragging eight different types of objects (e.g., a small suitcase, a large suitcase, a chair). The extensive experiments (480 times on the real robot) included dragging a heavy object with a mass of 84.6 kg (two times greater than the robot’s weight) and showed remarkable success rates of 92.92% when combined with the force–torque sensors, and 83.75% without force–torque sensors.",smart cities
10.1016/j.knosys.2021.107261,Journal,Knowledge-Based Systems,scopus,2021-09-27,sciencedirect,Federated conditional generative adversarial nets imputation method for air quality missing data,https://api.elsevier.com/content/abstract/scopus_id/85111226892,"The air quality is a topic of extreme concern that attracts a lot of attention in the world. Many intelligent air quality monitoring networks have been deployed in various places, especially in big cities. These monitoring networks collect air quality data with some missing data for some reasons which pose an obstacle for air quality publishing and studies. Generative adversarial nets (GAN) methods have achieved state-of-the-art performance in missing data imputation. GAN-based imputation method needs enough training data while one monitoring network has just a few and poor quality monitoring data and these data sets do not meet the independent identical distribution (IID) condition. Therefore, one monitoring network side needs to utilize more monitoring data from other sides as far as possible. However, in the real world, these air quality monitoring networks are owned by different organizations — companies, the government even some secret units. Many of them cannot share detailed monitoring data due to security, privacy, and industrial competition. In this paper, it is the first time to propose a conditional GAN imputation method under a federated learning framework to solve the data sets that come from diverse data-owners without sharing. Furthermore, we improve the vanilla conditional GAN performance with Wasserstein distance and “Hint mask” trick. The experimental results show that our GAN-based imputation methods can achieve the best performance. And our federated GAN imputation method outperforms the GAN imputation method trained locally for each participant which means our imputation model can work. Our proposed federated GAN method can benefit model quality by increasing access to air quality data through private multi-institutional collaborations. We further investigate the effects of data geographical distribution across collaborating participants on model quality and, interestingly, we find that the GAN training process with a federated learning framework performs more stable.",smart cities
10.1016/j.knosys.2021.107214,Journal,Knowledge-Based Systems,scopus,2021-09-27,sciencedirect,Self-supervised human mobility learning for next location prediction and trajectory classification,https://api.elsevier.com/content/abstract/scopus_id/85108861041,"Massive digital mobility data are accumulated nowadays due to the proliferation of location-based service (LBS), which provides the opportunity of learning knowledge from human traces that can benefit a range of business and management applications, such as location recommendation, anomaly trajectory detection, crime discrimination, and epidemic tracing. However, human mobility data is usually sporadically updated since people may not frequently access mobile apps or publish the geo-tagged contents. Consequently, distilling meaningful supervised signals from sparse and noisy human mobility is the main challenge of existing models. This work presents a Self-supervised Mobility Learning (SML) framework to encode human mobility semantics and facilitate the downstream location-based tasks. SML is designed for modeling sparse and noisy human mobility trajectories, focusing on leveraging rich spatio-temporal contexts and augmented traces to improve the trajectory representations. It provides a principled way to characterize the inherent movement correlations while tackling the implicit feedback and weak supervision problems in existing model-based approaches. Besides, contrastive instance discrimination is first introduced for spatio-temporal data training by explicitly distinguishing the real user check-ins from the negative samples that tend to be wrongly predicted. Extensive experiments on two practical applications, i.e., location prediction and trajectory classification, demonstrate that our method can significantly improve the location-based services over the state-of-the-art baselines.",smart cities
10.1016/j.oceaneng.2021.109535,Journal,Ocean Engineering,scopus,2021-09-15,sciencedirect,Data mining approach for automatic ship-route design for coastal seas using AIS trajectory clustering analysis,https://api.elsevier.com/content/abstract/scopus_id/85110502854,"In this paper, we propose an automatic route design method based on simple recurrent unit (SRU) and automatic identification system (AIS) data. Laplacian eigen maps and Gaussian kernel functions are used to compress the AIS data and extract the turning points of all ships. Fuzzy adaptive density-based spatial clustering of applications with noise (FA-DBSCAN) technique is used to cluster the turning points obtained at the preprocessing stage to obtain the turning region. Optimal turn region matching is used to connect the turning regions of similar routes, and the SRU neural network algorithm is used to learn the relationship between different types, sizes, and drafts of ships in each turning region; extract the feature-turning points; and obtain the recommended coastal routes, speed, and course of each type of ship. In the experimental stage, a large variety of AIS data from two sea areas are used to compare and analyze the designed route and real-ship data through LSTM and SRU experiments. The results show that the SRU algorithm improves the training speed and accuracy in comparison to LSTM, while the generated automatic route meets the requirements of navigation practice.",smart cities
10.1016/j.eswa.2021.114998,Journal,Expert Systems with Applications,scopus,2021-09-15,sciencedirect,Integrated decision support system for rich vehicle routing problems,https://api.elsevier.com/content/abstract/scopus_id/85105694613,"Recent economic and environmental constraints push supply chain management systems to adopt closed-loop supply chain operating modes that have to address very complex problems including the end-user quality of services, environmental considerations, and daily transportation time variations. Relevant and challenging research areas require a proper coordination between the data provider software (Transport Management Software) and the operational research tool in charge of trip definition.
                  This paper proposes a decision support system applied to the Vehicle Routing Problem able to tackle very large instances with real-life constraints. Our contribution is to propose an architecture that handle both static resolution prior to the completion of routes and update them in a dynamical context during their completions. This is implemented through a REST based API using numerous state-of-the-art operational research methods. Moreover, this system in used in practice by the Mapotempo company.",smart cities
10.1016/j.neucom.2021.03.068,Journal,Neurocomputing,scopus,2021-09-10,sciencedirect,A transfer approach with attention reptile method and long-term generation mechanism for few-shot traffic prediction,https://api.elsevier.com/content/abstract/scopus_id/85105872583,"Spatial–temporal prediction is a fundamental problem for intelligent transportation system (ITS), which is important for traffic management such as vehicle controls and travel plans. Deep learning has achieved success in spatial–temporal prediction with adequate data. However, many cities still suffer from data scarcity due to lack of essential infrastructure and services for data collection. Therefore, spatial–temporal prediction of cities with scarce data can be regarded as a few-shot learning problem. In this paper, we propose a novel transfer learning method to tackle spatial–temporal prediction tasks with only a small collection of data. Our proposed model aims to transfer the knowledge from multiple source cities to the target city by considering the different spatial–temporal distribution similarities between cities. Specifically, our model is designed as a spatial–temporal network based on a first-order meta-learning algorithm Reptile with an attention mechanism. Different from meta-learning algorithms that aim to learn a well-generalized initialization which can be adapted to any new task, our model achieves better performance on the specific target city by considering the different distribution similarities between multiple source cities and the target city. In addition, as it is difficult to learn the long-term spatial–temporal dependency with limited data in the target city, we propose a generation mechanism to learn and transfer long-term temporal features from source cities which have abundant long-period data to the target city. In the experiments, we compare our model with other state-of-the-art methods in real-world traffic prediction task. The experiments demonstrate the effectiveness of the proposed model.",smart cities
10.1016/j.apgeog.2021.102532,Journal,Applied Geography,scopus,2021-09-01,sciencedirect,Detecting home countries of social media users with machine-learned ranking approach: A case study in Hong Kong,https://api.elsevier.com/content/abstract/scopus_id/85112020941,"Inferring individual's home country from geotagged footprints is widely applied in human mobility research. Previous studies mainly used simple empirical methods that are based on intuitive hypothetical assumptions. Because the exact relationships between users' home countries and geotagged footprints haven't be quantitatively revealed, empirical methods based on human intuitions and past experiences are used for rough approximation. In this study, we propose a machine-learning approach for the task of home country detection, by formulating the task as a query-ranking problem and using a machine-learned ranking model for problem solving. The used model is a Multiple Additive Regression Trees framework that aims to rank regions in specific orders and the region ranked first is designated as the home country. Our approach is data-driven and can adaptively learn the unknown function from input (geotagged footprints) to output (user's home country), thus alleviating the bias introduced by previous empirical methods. We conduct experiments with real-world datasets, and results demonstrate that our approach achieves better performance than previous empirical methods. The model's parameter sensitivity is also investigated, and results show that user's origin may be a factor affecting the approach's performance and that our approach achieves robust good performance with various parameter settings.",smart cities
10.1016/j.watres.2021.117482,Journal,Water Research,scopus,2021-09-01,sciencedirect,Deep-learning based monitoring of FOG layer dynamics in wastewater pumping stations,https://api.elsevier.com/content/abstract/scopus_id/85111929509,"Accumulation of fat, oil and grease (FOG) in the sumps of wastewater pumping stations is a common failure cause for these facilities. Floating solids are often not transported by the pump suction inlets and the individual solids can accumulate to stiff and thick FOG layers. The lack of data about the dynamics in FOG layer formation still hampers the design of effective measures towards its mitigation. In this article, we present a low-cost camera-based automated system for the observation of FOG layer dynamics in wastewater pumping stations at high-frequency (minutes) over extended time windows (months). Optical imagery is processed through a deep-learning computer vision routine that allows describing FOG layer dynamics (e.g. accumulation rate and changes in shape) and various hydraulic processes in the pump sump (e.g. the water level, surface flow velocity fields, vorticity, or circulation). Furthermore, the system can perform in-camera image processing, thus allowing the transfer of compressed-processed datasets when deployed in remote locations (Edge AI computing), which could be of great utility for the hydro-ecological monitoring community. In this study, the technology applied is illustrated with a dataset (six months, two-minute frequency) collected at a wastewater pumping station at the municipality of Rotterdam, The Netherlands. This monitoring system represents a source of information for the management of (waste)water pumping stations (e.g. detection of free-surface vortices and scheduling of sump cleaning operations) and facilitates the collection of standardized high-frequency FOG layer dynamics data for a detailed description of FOG build-up and transport processes.",smart cities
10.1016/j.trc.2021.103289,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-09-01,sciencedirect,Real-world ride-hailing vehicle repositioning using deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85111873690,"We present a new practical framework based on deep reinforcement learning and decision-time planning for real-world vehicle repositioning on ride-hailing (a type of mobility-on-demand, MoD) platforms. Our approach learns the spatiotemporal state-value function using a batch training algorithm with deep value networks. The optimal repositioning action is generated on-demand through value-based policy search, which combines planning and bootstrapping with the value networks. For the large-fleet problems, we develop several algorithmic features that we incorporate into our framework and that we demonstrate to induce coordination among the algorithmically-guided vehicles. We benchmark our algorithm with baselines in a ride-hailing simulation environment to demonstrate its superiority in improving income efficiency measured by income-per-hour. We have also designed and run a real-world experiment program with regular drivers on a major ride-hailing platform. We have observed significantly positive results on key metrics comparing our method with experienced drivers who performed idle-time repositioning based on their own expertise.",smart cities
10.1016/j.jstrokecerebrovasdis.2021.105962,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-09-01,sciencedirect,StrokeWatch: An Instrument for Objective Standardized Real-Time Measurement of Door-to-Needle Times in Acute Ischemic Stroke Treatment,https://api.elsevier.com/content/abstract/scopus_id/85109982805,"Objectives
                  Monitoring critical time intervals in acute ischemic stroke treatment delivers metrics for quality of performance – the door-to-needle time being well-established. To resolve the conflict of self-reporting bias a “StrokeWatch” was designed – an instrument for objective standardized real-time measurement of procedural times.
               
                  Materials and methods
                  An observational, monocentric analysis of patients receiving intravenous thrombolysis for acute ischemic stroke between January 2018 and September 2019 was performed based on an ongoing investigator-initiated, prospective, and blinded endpoint registry. Patient data and treatment intervals before and after introduction of ""StrokeWatch"" were compared.
               
                  Results
                  “StrokeWatch” was designed as a mobile board equipped with three digital stopwatches tracking door-to-needle, door-to-groin, and door-to-recanalization intervals as well as a form for standardized documentation. 118 patients before introduction of “StrokeWatch” (subgroup A) and 53 patients after introduction of “StrokeWatch” (subgroup B) were compared. There were no significant differences in baseline characteristics, procedural times, or clinical outcome. A non-significant increase in patients with door-to-needle intervals of 60 min or faster (93.2 vs 98.1%, p = 0.243) and good functional outcome (mRS d90 ≤ 2, 47.5 vs 58.5%, p = 0.218) as well as a significant increase in reports of delayed arrival of intra-hospital patient transport service (0.8 vs 13.2%, p = 0.001) were observed in subgroup B.
               
                  Conclusions
                  The implementation of StrokeWatch for objective standardized real-time measurement of door-to-needle times is feasible in a real-life setting without negative impact on procedural times or outcome. It helped to reassure a high-quality treatment standard and reveal factors associated with procedural delays.",smart cities
10.1016/j.oceaneng.2021.109435,Journal,Ocean Engineering,scopus,2021-09-01,sciencedirect,An enhanced CNN-enabled learning method for promoting ship detection in maritime surveillance system,https://api.elsevier.com/content/abstract/scopus_id/85109195594,"The accurate and real-time detection of moving ships has become an essential component in maritime video surveillance, leading to enhanced traffic safety and security. With the rapid development of artificial intelligence, it becomes feasible to develop intelligent techniques to promote ship detection results in maritime applications. In this work, we propose to develop an enhanced convolutional neural network (CNN) to improve ship detection under different weather conditions. To be specific, the learning and representation capacities of our network are promoted by redesigning the sizes of anchor boxes, predicting the localization uncertainties of bounding boxes, introducing the soft non-maximum suppression, and reconstructing a mixed loss function. In addition, a flexible data augmentation strategy with generating synthetically-degraded images is presented to enlarge the volume and diversity of original dataset to train learning-based ship detection methods. This strategy is capable of making our CNN-based detection results more reliable and robust under adverse weather conditions, e.g., rain, haze, and low illumination. Experimental results under different monitoring conditions demonstrate that our method significantly outperforms other competing methods (e.g., SSD, Faster R-CNN, YOLOv2 and YOLOv3) in terms of detection accuracy, robustness and efficiency. The ship detection results under poor imaging conditions have also been implemented to demonstrate the superior performance of our learning method.",smart cities
10.1016/j.trc.2021.103272,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-09-01,sciencedirect,Spatial-temporal pricing for ride-sourcing platform with reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85108979514,"Ever since the emergence of ride-sourcing services, the spatial–temporal pricing problem has been a hot research topic in both the transportation and management fields. The difficulty lies in simultaneously obtaining the optimal multivariable solution for spatial pricing and sequential solution for dynamic pricing, considering the heterogeneity, dynamics, and imbalance of on-demand ride supply/demand. Due to this problem's complexity, most studies have simplified the modeling setting and omitted the complicated matching and waiting process between drivers and passengers. To go beyond the existing models, this paper proposes a reinforcement learning enhanced agent-based modeling and simulation (RL-ABMS) system to reveal the complex mechanism in the ride-sourcing system and tackle the problem of spatial–temporal pricing for a ride-sourcing platform. The reinforcement learning approach proximal policy optimization (PPO) is implemented in the RL-ABMS system, where two feed-forward neural networks are built as critic and actor. The critic judges the goodness of the current state, and the actor generates the optimal pricing strategy.Compared with the fixed pricing strategy, the experimental results on a real-world urban network show that dynamic pricing raises the platform's profit to 1.25 times, and spatial–temporal pricing even raises it to 1.85 times. Besides, the number of idle drivers/vehicles has significantly dropped under the spatial–temporal pricing strategy, which indicates that our proposed strategy has a remarkable effect on coordinating supply and demand in the ride-sourcing market.",smart cities
10.1016/j.scs.2021.103050,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Optimization of AI-driven communication systems for green hospitals in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85107113682,"The green hospital is an important part for constructing Sustainable Cities. In this paper, system optimization algorithms based on artificial intelligence technologies are proposed by studying the communication system of the green hospital in the smart sustainable city, and the overall architecture design and detailed functional module design were carried out. The functions in the system can be divided into basic information management function, patient monitoring function, and remote self-test, etc. The medical equipment management system is characterized by the combination of Internet of Things technology, so that equipment managers can control the operating status of the equipment at any time, and can remotely upgrade and control the equipment through the system, and medical staff can view the measurement data of the equipment at the system interface and grasp the real-time information of treating patients to improve work efficiency. The accuracy of the improved particle swarm optimization (PSO) algorithm was compared with that of a single BP neural network algorithm. According to the requirement analysis of the health monitoring software and the overall design scheme of the system, each functional module of the health monitoring software is designed and the specific implementation of each functional module is carried out.",smart cities
10.1016/j.scs.2021.103009,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Applying machine learning in intelligent sewage treatment: A case study of chemical plant in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85106305327,"Nowadays, sewage treatment in sustainable cities attracts more researchers both from academic and industrial communities. Especially, since industrial sewage is normally highly toxic, which could cause serious pollution in a city and lead to health problems of residents, it is critical to monitor and predictably maintain sewage treatment facilities in cities. This paper presents an intelligent sewage treatment system based on machine learning and Internet of Things sensors to assist to manage the sewage treatment in a fine chemical plant. The implemented system has operated for twenty months, acquired multi-dimension data such as temperatures in different treatment processes, operation parameters of devices, and real-time Chemical Oxygen Demand (COD). Since the change trend of outflow COD is highly related to operation status, this paper innovatively uses different types of temperature and water inflow data as model inputs and applies three algorithms to make prediction, which are Support Vector Regression (SVR), Long Short-Term Memory (LSTM) neural network, and Gated Recurrent Unit (GRU) neural network. The experimental results show that GRU model performs better (MAPE = 10.18%, RMSE = 35.67, MAE = 31.16) than LSTM and SVR. This study can be extended to various sewage treatment scenarios in sustainable cities.",smart cities
10.1016/j.eswa.2021.114951,Journal,Expert Systems with Applications,scopus,2021-09-01,sciencedirect,Providing music service in Ambient Intelligence: experiments with gym users,https://api.elsevier.com/content/abstract/scopus_id/85104365062,"Ambient Intelligence (AmI) is an interdisciplinary research area of ICT which has evolved since the 90s, taking great advantage from the advent of the Internet of Things (IoT). AmI creates, by using Artificial Intelligence (AI), an intelligent ecosystem in which computers, sensors, lighting, music, personal devices, and distributed services, work together to improve the user experience through the support of natural and intuitive user interfaces. Nowadays, AmI is used in various contexts, e.g., for building smart homes and smart cities, providing healthcare, and creating an adequate atmosphere in retail and public environments.
                  In this paper, we propose a novel AmI system for gym environments, named Gym Intelligence, able to provide adequate music atmosphere, according to the users’ physical effort during the training. The music is taken from Spotify and is classified according to some music features, as provided by Spotify itself. The system is based on a multi-agent computational intelligence model built on two main components: 
                        
                           (
                           i
                           )
                        
                      machine learning methods that forecast appropriate values for the Spotify music features, and 
                        
                           (
                           ii
                           )
                        
                      a multi-objective dynamic genetic algorithm that selects a specific Spotify music track, according to such values. Gym Intelligence is built by sensing the ambient with a minimal, low-cost, and non-intrusive set of sensors, and it has been designed considering the outcome of a preliminary analysis in real gyms, involving real users. We have considered well-known regression methods and we have validated them using a collected data 
                        
                           (
                           i
                           )
                        
                      about the users’ physical effort, through the sensors, and 
                        
                           (
                           ii
                           )
                        
                      about the users’ music preferences, through an Android app that the users have used during the training. Among the regression methods considered, the one that provided the best results is the Random Forest, which predicted Spotify music features with a mean absolute error of 0.02 and a root mean squared error of 0.05. We have implemented Gym Intelligence and deployed it in five real gyms. We have evaluated it conducting several experiments. The experiments show how, with the help of Gym Intelligence, the users’ satisfaction about the provided background music, rose from 3.05 to 4.91 (on a scale from 1 to 5, where 5 is the maximum score).",smart cities
10.1016/j.bspc.2021.102792,Journal,Biomedical Signal Processing and Control,scopus,2021-08-01,sciencedirect,Recognizing drowsiness in young men during real driving based on electroencephalography using an end-to-end deep learning approach,https://api.elsevier.com/content/abstract/scopus_id/85109099510,"It is widely agreed that driving while drowsy is a severe threat to road safety. Therefore, in this work, we present a novel approach that does not require manual selection of feature sets and then delivers them to the classifier, using deep learning theory and convolutional neural network (ConvNets) to automatically detect driver drowsiness based on multi-channel EEG signals during real driving. The proposed 12-layer deep ConvNets model automatically learns and extracts the most prominent features from the raw EEG data through 5 convolutional layers, 3 max pooling layers and 1 mean pooling layer and optimizes the classification results through 3 fully connected layers at the same time, which is an end-to-end manner. To overcome the lack of a large amount of EEG data, a data augmentation strategy is proposed. The proposed deep ConvNets model is trained on 4 s segments of EEG data from different participants and tested using a 10-fold cross validation. It gave an accuracy, precision, sensitivity, specificity, and mean f-measure of 97.02 % ± 0.0177, 96.74 % ± 0.0347, 97.76 % ± 0.0168, 96.22 % ± 0.0426, and 97.19 % ± 0.0157, respectively on the testing data set and outperforms the state-of-the-art systems, which proved the good generalization performance of the deep model. Considering that the proposed model can learn features from the data without using specialized feature extraction and classification methods, ConvNets may be considered as an alternative for similar detections based on EEG signals such as operators fatigue in navigation, construction industry, etc.",smart cities
10.1016/j.eti.2021.101718,Journal,Environmental Technology and Innovation,scopus,2021-08-01,sciencedirect,Environmental monitoring and landscape design of green city based on remote sensing image and improved neural network,https://api.elsevier.com/content/abstract/scopus_id/85109066212,"In some developed countries in Europe, cities are developing very rapidly, but the rapid development of these countries also has to go through the following stages, which are the three essential development processes of urbanization, counter-urbanization and re-urbanization. My country’s development situation is relatively uneven. In the more developed areas of my country, the speed of urbanization is relatively rapid, such as cities near the Yangtze River Delta and the Pearl River Delta. But with the development of urbanization, these areas are also facing a very troublesome problem, that is, the balance between the development of the city and the environmental ecosystem. In order to monitor this situation, we will use remote sensing technology to conduct a comprehensive survey of the urban environmental ecosystem and analyze the impact and effect of the rapid development of the city on the changes in the ecosystem. This article will focus on the area around the Yangtze River Delta, and investigate the spatial patterns of urban environmental ecosystems by comparing this area with cities in developed regions such as Western Europe and North America. Under the conditions of different regions and different degrees of urbanization, the comprehensive situation of environmental elements in the city is investigated, and the environmental impact effects and the causes, effects and effects of environmental changes are more accurately studied. Combine the BP network model related to the nervous system in the experiment, and continuously optimize the model during the experiment. The experimental data selects environmental difference reports displayed in different years and different seasons to predict the air pollution value of a certain city. The reason why we use this method is that this model can improve the accuracy of statistical data and greatly simplify the unnecessary and complicated steps in the research process, and it can also reduce the error problems generated in the operation of the BP system, such as when we When entering a piece of data, the data obtained is often very different from the target data. Therefore, we will use the ant colony algorithm to solve the above problems, and add stereo and 3D technologies, which can monitor experiments in real time, greatly improve the speed of the experiment, and the 3D stereo technology can make the results more perceptual to meet the needs of the experiment.",smart cities
10.1016/j.scs.2021.102945,Journal,Sustainable Cities and Society,scopus,2021-08-01,sciencedirect,Effective task scheduling algorithm with deep learning for Internet of Health Things (IoHT) in sustainable smart cities,https://api.elsevier.com/content/abstract/scopus_id/85105291613,"In the recent years, important key factor for urban planning is to analyze the sustainability and its functionality towards smart cities. Presently, many researchers employ the conservative machine learning based analysis but those are not appropriate for IoT based health data analysis because of their physical feature extraction and low accuracy. In this paper, we propose remote health monitoring and data analysis by integrating IoT and deep learning concepts. We proposed novel IoT based FoG assisted cloud network architecture that accumulates real-time health care data from patients via several medical IoT sensor networks, these data are analyzed using a deep learning algorithm deployed at Fog based Healthcare Platform. Furthermore, the proposed methodology is applied to the sustainable smart cities to evaluate the process for real-time. The proposed framework not only analyses the healthcare data but also provides immediate relief measures to the patient facing critical conditions and needs immediate consultancy of doctor. Performance is measure in terms of accuracy, precision and sensitivity of the proposed DHNN with task scheduling algorithm and it is obtained 97.6%, 97.9%, and 94.9%. While accuracy, precision and sensitivity for deep CNN is 96.5%, 97.5% and 94% and for Deep auto-encoder is 92%, 91%, and 82.5%.",smart cities
10.1016/j.future.2021.03.003,Journal,Future Generation Computer Systems,scopus,2021-08-01,sciencedirect,Deep spatial–temporal sequence modeling for multi-step passenger demand prediction,https://api.elsevier.com/content/abstract/scopus_id/85102645477,"Supply–demand imbalance poses significant challenges to transportation systems such as taxis and shared vehicles (cars and bikes) and leads to excessive delays, income loss, and energy consumption. Accurate prediction of passenger demands is an essential step towards rescheduling resources to resolve the above challenges. However, existing work cannot fully capture and leverage the complex nonlinear spatial–temporal relationships within multi-modal data. They either include excessive data from weakly-correlated regions or oversight the correlations among those similar yet geographically distant regions. Moreover, these methods mainly focus on predicting the passenger demand for one future time step, whereas predictions over longer time scales are more valuable for developing efficient vehicle deployment strategies. We propose an end-to-end deep learning based framework to solve the above challenges. Our model comprises three parts: (1) a cascade graph convolutional recurrent neural network to extract spatial–temporal correlations within citywide historical vehicle demand data; (2) two multi-layer LSTM networks to represent the external meteorological data and time meta separately; (3) an encoder–decoder module to fuse the above two parts and decode the representation to achieve prediction over a longer time period into the future. We evaluate our framework on three real-world datasets and show that our model can better capture the spatial–temporal relationships and outperform the most discriminative state-of-the-art methods.",smart cities
10.1016/j.neucom.2020.08.091,Journal,Neurocomputing,scopus,2021-07-15,sciencedirect,Enhancing random forest classification with NLP in DAMEH: A system for DAta Management in eHealth Domain,https://api.elsevier.com/content/abstract/scopus_id/85101877123,"The use of pervasive IoT devices in Smart Cities, have increased the Volume of data produced in many and many field. Interesting and very useful applications grow up in number in E-health domain, where smart devices are used in order to manage huge amount of data, in highly distributed environments, in order to provide smart services able to collect data to fill medical records of patients. The problem here is to gather data, to produce records and to analyze medical records depending on their contents. Since data gathering involve very different devices (not only wearable medical sensors, but also environmental smart devices, like weather, pollution and other sensors) it is very difficult to classify data depending their contents, in order to enable better management of patients. Data from smart devices couple with medical records written in natural language: we describe here an architecture that is able to determine best features for classification, depending on existent medical records. The architecture is based on pre-filtering phase based on Natural Language Processing, that is able to enhance Machine learning classification based on Random Forests. We carried on experiments on about 5000 medical records from real (anonymized) case studies from various health-care organizations in Italy. We show accuracy of the presented approach in terms of Accuracy-Rejection curves.",smart cities
10.1016/j.comnet.2021.108078,Journal,Computer Networks,scopus,2021-07-05,sciencedirect,Transfer reinforcement learning-based road object detection in next generation IoT domain,https://api.elsevier.com/content/abstract/scopus_id/85104603461,"The landscape of fifth generation (5G) and beyond 5G (B5G)-enabled Internet of Things(IoT) is expected to seamlessly and ubiquitously connect everything, which includes 5G, cloud computing, artificial intelligence and other cutting-edge technologies to realize truly intelligent applications in smart cities. In this paper, we present an important key technology for smart city, which is a road target recognition algorithm for smart city applications and designs a set of corresponding programs to assist automatic drivers, pedestrians and visually impaired people in road safety, or to manage city infrastructure. The system can connect robots in cars, wearable devices and body area network in pedestrians or blind people. A target recognition algorithm based on scene fusion is designed to recognize the specific target in the road environment, and transfer reinforcement learning method is used to improve the accuracy and real-time performance of target recognition. The system provides them with travel assistance, identify dangerous or useful objects for them through high-performance target recognition services. It can collect the road visual scene data by road cameras and transmit it to edge devices for training model. The model is collaborated trained in the edge devices and aggregated by the cloud. Based on the transfer reinforcement learning method, the vision-based road target recognition has been implemented, and the accurate and reliable target recognition can be realized. Many details of experiments verify the effectiveness of our technology.",smart cities
10.1016/j.ebiom.2021.103465,Journal,EBioMedicine,scopus,2021-07-01,sciencedirect,A mass spectrometry-based targeted assay for detection of SARS-CoV-2 antigen from clinical specimens,https://api.elsevier.com/content/abstract/scopus_id/85109005451,"Background
                  The COVID-19 pandemic caused by severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) has overwhelmed health systems worldwide and highlighted limitations of diagnostic testing. Several types of diagnostic tests including RT-PCR-based assays and antigen detection by lateral flow assays, each with their own strengths and weaknesses, have been developed and deployed in a short time.
               
                  Methods
                  Here, we describe an immunoaffinity purification approach followed a by high resolution mass spectrometry-based targeted qualitative assay capable of detecting SARS-CoV-2 viral antigen from nasopharyngeal swab samples. Based on our discovery experiments using purified virus, recombinant viral protein and nasopharyngeal swab samples from COVID-19 positive patients, nucleocapsid protein was selected as a target antigen. We then developed an automated antibody capture-based workflow coupled to targeted high-field asymmetric waveform ion mobility spectrometry (FAIMS) - parallel reaction monitoring (PRM) assay on an Orbitrap Exploris 480 mass spectrometer. An ensemble machine learning-based model for determining COVID-19 positive samples was developed using fragment ion intensities from the PRM data.
               
                  Findings
                  The optimized targeted assay, which was used to analyze 88 positive and 88 negative nasopharyngeal swab samples for validation, resulted in 98% (95% CI = 0.922–0.997) (86/88) sensitivity and 100% (95% CI = 0.958–1.000) (88/88) specificity using RT-PCR-based molecular testing as the reference method.
               
                  Interpretation
                  Our results demonstrate that direct detection of infectious agents from clinical samples by tandem mass spectrometry-based assays have potential to be deployed as diagnostic assays in clinical laboratories, which has hitherto been limited to analysis of pure microbial cultures.
               
                  Funding
                  This study was supported by DBT/Wellcome Trust India Alliance Margdarshi Fellowship grant IA/M/15/1/502023 awarded to AP and the generosity of Eric and Wendy Schmidt.",smart cities
10.1016/j.compeleceng.2021.107226,Journal,Computers and Electrical Engineering,scopus,2021-07-01,sciencedirect,IoT-based crowd monitoring system: Using SSD with transfer learning,https://api.elsevier.com/content/abstract/scopus_id/85106607784,"The constantly developing urbanization and the emergence of smart cities require better security surveillance and crowd monitoring systems. The growing availability of the Internet of Things (IoT) devices in public and private organizations also provide intelligent and secure surveillance solutions for real-time monitoring in public spaces. This article introduces an IoT-based crowd surveillance system that uses a deep learning model to detect and count people using an overhead view perspective. The Single Shot Multibox Detector (SSD) model with Mobilenetv2 as the basic network is used for the detection of people. The detection model’s accuracy is enhanced with a transfer learning approach. Two virtual lines are defined to count how many people are leaving and entering the scene. In order to assess performance, experiments are performed using different video clips. Results indicate that transfer learning increases the overall detection performance of the system with an accuracy of 95%.",smart cities
10.1016/j.patrec.2021.03.033,Journal,Pattern Recognition Letters,scopus,2021-07-01,sciencedirect,Perceptual quality-preserving black-box attack against deep learning image classifiers,https://api.elsevier.com/content/abstract/scopus_id/85105264673,"Deep neural networks provide unprecedented performance in all image classification problems, including biometric recognition systems, key elements in all smart city environments. Recent studies, however, have shown their vulnerability to adversarial attacks, spawning intense research in this field. To improve system security, new countermeasures and stronger attacks are proposed by the day. On the attacker’s side, there is growing interest for the realistic black-box scenario, in which the user has no access to the network parameters. The problem is to design efficient attacks which mislead the neural network without compromising image quality. In this work, we propose to perform the black-box attack along a high-saliency and low-distortion path, so as to improve both attack efficiency and image perceptual quality. Experiments on real-world systems prove the effectiveness of the proposed approach both on benchmark tasks and actual biometric applications.",smart cities
10.1016/j.compenvurbsys.2021.101628,Journal,"Computers, Environment and Urban Systems",scopus,2021-07-01,sciencedirect,Flood depth mapping in street photos with image processing and deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85103680478,"Many parts of the world experience severe episodes of flooding every year. In addition to the high cost of mitigation and damage to property, floods make roads impassable and hamper community evacuation, movement of goods and services, and rescue missions. Knowing the depth of floodwater is critical to the success of response and recovery operations that follow. However, flood mapping especially in urban areas using traditional methods such as remote sensing and digital elevation models (DEMs) yields large errors due to reshaped surface topography and microtopographic variations combined with vegetation bias. This paper presents a deep neural network approach to detect submerged stop signs in photos taken from flooded roads and intersections, coupled with Canny edge detection and probabilistic Hough transform to calculate pole length and estimate floodwater depth. Additionally, a tilt correction technique is implemented to address the problem of sideways tilt in visual analysis of submerged stop signs. An in-house dataset, named BluPix 2020.1 consisting of paired web-mined photos of submerged stop signs across 10 FEMA regions (for U.S. locations) and Canada is used to evaluate the models. Overall, pole length is estimated with an RMSE of 17.43 and 8.61 in. in pre- and post-flood photos, respectively, leading to a mean absolute error of 12.63 in. in floodwater depth estimation. Findings of this research are sought to equip jurisdictions, local governments, and citizens in flood-prone regions with a simple, reliable, and scalable solution that can provide (near-) real time estimation of floodwater depth in their surroundings.",smart cities
10.1016/j.asoc.2021.107269,Journal,Applied Soft Computing,scopus,2021-07-01,sciencedirect,Machine learning based simulation optimisation for urban routing problems,https://api.elsevier.com/content/abstract/scopus_id/85102411679,"Many real world routing problems, including those in tourism and surveillance, can be formulated as team orienteering problems. The goal in such problems is to maximise the rewards collected by a fleet of vehicles whose routes must be completed within a time limit. This work considers a team orienteering problem set within a traffic simulation. In the stochastic environment of a road network, travel times depend on network structure, the demands of road users, driver behaviour and the congestion that arises from these. As a result travel times are difficult to predict. In this work a learnheuristic solution approach is proposed. Learnheuristics integrate machine learning and optimisation for solving combinatorial problems with inherent parameter learning problems—in this case travel times. The machine learning component is used to predict travel times based on data obtained from a limited budget of traffic simulation runs, a budget that is used within the run-time learnheuristic algorithm. In each iteration of the learnheuristic, the optimisation component utilises the travel time predictions of the machine learning algorithm to rapidly generate candidate solutions. The strongest candidate is tested in the traffic simulator, and the results of which are used to train the machine learning component. In a range of test instances, the effectiveness of different combinations of machine learning and optimisation components are tested. Experiments reveal that different combinations of machine learning and optimisation components produce solutions with different characteristics in terms of total reward and reliability. Local search followed by biased randomisation combined with a neural network was found to be effective in multiple instances. The question of how best to use the run-time of a learnheuristic is also addressed.",smart cities
10.1016/j.neucom.2020.01.124,Journal,Neurocomputing,scopus,2021-06-07,sciencedirect,"Predicting energy cost of public buildings by artificial neural networks, CART, and random forest",https://api.elsevier.com/content/abstract/scopus_id/85101355528,"The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities.",smart cities
10.1016/j.treng.2021.100068,Journal,Transportation Engineering,scopus,2021-06-01,sciencedirect,Real-time traffic quantization using a mini edge artificial intelligence platform,https://api.elsevier.com/content/abstract/scopus_id/85111397458,"Traffic analysis is dependent on reliable and accurate datasets that quantify the vehicle composition, speed and traffic density over a long period of time. The utilisation of big data is required if equitable and efficient transportation networks are to be realised for smart, interconnected cities of the future. The rapid and widespread adoption of digital twins, IoT (Internet of Things), artificial intelligence and mini edge computing technologies serve as the catalyst to rapidly develop and deploy smart systems for real-time data acquisition of traffic in and around urban and metropolitan areas. This paper presents a proof of concept of a mini edge computing platform for real-time edge processing, which serves as a digital twin of a multi-lane freeway located in Pretoria, South Africa. Video data acquired from an Unmanned Aerial Vehicle (UAV) is processed using a neural network architecture designed for real-time object detection tracking of vehicles. The implementation successfully counted vehicles (cars and trucks) together with an estimation of the speed of each detected vehicle. These results compare favourably to the ground truth data with vehicle counting accuracies of 5% realised. Detection of sparse motorcycles and pedestrians were less than optimal. This proof of concept can be easily scaled and deployed over a wide geographic area. Integration of these cyber-physical assets can be incorporated into existing video monitoring systems or fused with optical sensors as a single data acquisition system.",smart cities
10.1016/j.jum.2021.03.004,Journal,Journal of Urban Management,scopus,2021-06-01,sciencedirect,Predicting community attitudes towards alternative virus-management plans,https://api.elsevier.com/content/abstract/scopus_id/85106610574,"In mid 2020 people vigorously debated which Corona virus-management strategy should be implemented – ‘total Lockdown’, ‘Partial Lockdown’ or ‘do Nothing’. For success, the chosen strategy would need considerable public support. So here we demonstrate how support, or otherwise, could have been predicted using our freely available Planticipate app. It self improves by sending its users' judgements to the cloud, where learning routines formulate regression- and neural network-based relationships between thirteen, key, plan-evaluation criteria and overall plan desirability. Hence whenever any set of plans are scored on the criteria, these relationships generate forecasts of plan desirability according to a number of demographic groups of past users. Our app predicted that many community groups will regard the ‘do-Nothing’ option as statistically significantly inferior to the other two plans, and it also made several less-than-statistically-significant forecasts which were extremely thought provoking. Using innovative face charts to better interpret complicated, thirteen-dimensional data, Planticipate also suggested probable reasons for such forecasts. These included an apparent fixation upon only permissiveness and productivity by people living in North America and relative pragmatism amongst females. Such revelations immediately suggested possible modifications for making different plans more acceptable to certain community groups. Given that in reality several of these modifications were only implemented later on during the pandemic, an early application of our app would almost certainly have prompted faster, more creative and more empathetic urban management.",smart cities
10.1016/j.dib.2021.107127,Journal,Data in Brief,scopus,2021-06-01,sciencedirect,H2020 project CAPTOR dataset: Raw data collected by low-cost MOX ozone sensors in a real air pollution monitoring network,https://api.elsevier.com/content/abstract/scopus_id/85106384559,"The H2020 CAPTOR project deployed three testbeds in Spain, Italy and Austria with low-cost sensors for the measurement of tropospheric ozone (O3). The aim of the H2020 CAPTOR project was to raise public awareness in a project focused on citizen science. Each testbed was supported by an NGO in charge of deciding how to raise citizen awareness according to the needs of each country. The data presented in this document correspond to the raw data captured by the sensor nodes in the Spanish testbed using SGX Sensortech MICS 2614 metal-oxide sensors. The Spanish testbed consisted of the deployment of twenty-five nodes. Each sensor node included four SGX Sensortech MICS 2614 ozone sensors, one temperature sensor and one relative humidity sensor. Each node underwent a calibration process by co-locating the node at an EU reference air quality monitoring station, followed by a deployment in a sub-urban or rural area in Catalonia, Spain. All nodes spent two to three weeks co-located at a reference station in Barcelona, Spain (urban area), followed by two to three weeks co-located at three sub-urban reference stations near the final deployment site. The nodes were then deployed in volunteers' homes for about two months and, finally, the nodes were co-located again at the sub-urban reference stations for two weeks for final calibration and assessment of potential drifts. All data presented in this paper are raw data taken by the sensors that can be used for scientific purposes such as calibration studies using machine learning algorithms, or once the concentration values of the nodes are obtained, they can be used to create tropospheric ozone pollution maps with heterogeneous data sources (reference stations and low-cost sensors).",smart cities
10.1016/j.jisa.2021.102823,Journal,Journal of Information Security and Applications,scopus,2021-06-01,sciencedirect,ME-Box: A reliable method to detect malicious encrypted traffic,https://api.elsevier.com/content/abstract/scopus_id/85105699348,"Currently, encryption (such as the Transport Layer Security protocol) is used by increasingly more network applications to protect their security and privacy, while it also benefits network attackers who can encrypt their traffic to evade detection. The detection of malicious encrypted traffic is becoming a critical task for cyber security. To accomplish this task, researchers have proposed several enlightening methods, including decryption followed by deep packet inspection (DPI), direct DPI on ciphertext and identification by machine learning algorithms. However, due to privacy violations or performance limitations, the state-of-the-art is far from satisfactory.
                  In this paper, we propose a novel framework and system called ME-Box (Machine learning and Evidence verification) for reliable detection of malicious encrypted traffic. ME-Box has middleboxes deployed in the network and agents installed on the sending hosts. Middleboxes first evaluate the trust degrees of encrypted flows by machine learning methods. If some flows are classified as suspicious, then middleboxes provide evidence of the evaluation results and request the corresponding session-keys from the agents. The agents verify the evidence, and if it is convincing, respond with the correct session-keys. With the session-keys, middleboxes finally decrypt the suspected encrypted flows and perform conventional DPI using intrusion signatures. We implement a prototype system of ME-Box and test it with real malware traffic. The experimental results show that ME-Box requires no modification of current cryptographic protocols and keeps end-users’ privacy well, and its performance is practically deployable.",smart cities
10.1016/j.trc.2021.103156,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-06-01,sciencedirect,Efficient dispatching for on-demand ride services: Systematic optimization via Monte-Carlo tree search,https://api.elsevier.com/content/abstract/scopus_id/85105698494,"Efficient dispatching for on-demand ride services is essential to the ride-sourcing platform, passengers, and drivers in a competitive ride-sourcing market. The existing first-come-first-serve (FCFS) dispatching method is a myopic mechanism that sought to minimize individual-level waiting time. To improve the passenger-vehicle matching efficiency and reduce the cancelation rate, a searching tree structure is developed to deal with the vehicle dispatching problem considering vehicles still in service. This paper formulates a distinctive systematic dispatching model from the passengers' perspective and presents new dispatching rules to match passengers and vehicles. Based on an improved tree policy and efficient branch reduction policy, we customize and enhance the reinforcement learning approach, Monte-Carlo Tree Search (MCTS), to solve the multi-period sequential dispatching problem and enable efficient dispatches. The computational Complexity of MCTS is analytically derived. As benchmarks, the Hungarian algorithm, CPLEX, greedy algorithm, and two global optimization algorithms are employed. We compare these algorithms by using both simulation and real-world city-scale on-demand ride-sourcing data. Both numerical and city-scale experiment results show that the improved MCTS dispatching approach increases the percentages of satisfied passengers and dispatched drivers, and reduces the number of unmatched passengers and cumulative waiting time compared to the benchmark algorithms. The results shed light on modeling urban dispatching problems with available vehicles in both forward-looking and backward-looking time periods. This paper demonstrates that improved MCTS performs well in solving a multi-period sequential optimization problem in real-world city-scale applications.",smart cities
10.1016/j.scs.2021.102801,Journal,Sustainable Cities and Society,scopus,2021-06-01,sciencedirect,"Smart and sustainable logistics of Port cities: A framework for comprehending enabling factors, domains and goals",https://api.elsevier.com/content/abstract/scopus_id/85104756448,"Digital technologies integrated into port logistics are becoming increasingly decisive among port cities around the world. This growing importance is due to the need for policymakers, urban managers, port authorities, local administrators, shipping companies, couriers, and so on to develop increasingly digitalized and sustainable logistic processes. Therefore, in a global context characterized by intense datafication and globalization of trade, the data-based approach has become a necessary modus operandi to promote smart and sustainable logistics development. This forward-looking model of port logistics uses technologies such as IoT, sensors, cloud computing platforms, Big Data analytics, Artificial Intelligence (AI), GPS tracking systems, radars, drones, real-time monitoring stations, smart grids, and so on in order to collect, process, monitor and analyse data and information concerning the economic, environmental, social and technological sphere of port cities. In this sense, mobile and fixed platforms help logistics operators to optimize the management of flows (e.g., water, waste, emissions, raw materials, people, monetary investments, etc.) in an efficient and digitized manner. The study proposes a systematic literature review of the most recurring themes concerning smart and sustainable logistics initiatives within port cities in order to develop a multidimensional framework capable of holistically integrating the prevailing enabling factors (Ecosystem, Internal Organization, Data and Security, Policy and Regulation, Finance and Funding, and Digital and Technology), domains (Mobility, Environment, Economy, Telecommunications, Safety and Security, Government, and Community) and goals (Sustainable Development and Digitalization) that characterize smart and sustainable logistical development. To this end, the best practices of several pioneering port cities such as Rotterdam, Hamburg, Singapore, Los Angeles, Amsterdam, etc. implemented in partnerships with technology companies such as Cisco, IBM, Huawei and SAP were also analysed. Therefore, the results of this research show that smart and sustainable logistics initiatives in port cities: (a) have the potential to enhance the efficiency of the economic, environmental, social and technological flows; (b) increase the involvement and awareness of stakeholders such as couriers, shippers, shipping companies, citizens, port authorities, municipalities, security officers, gate and terminal personnel, and so on; and (c) provide a detailed overview of the enabling factors, domains and goals that must be activated by port cities to foster a smart and sustainable logistic transition.",smart cities
10.1016/j.scs.2021.102822,Journal,Sustainable Cities and Society,scopus,2021-06-01,sciencedirect,A real-time tracking controller for piezoelectric actuators based on reinforcement learning and inverse compensation,https://api.elsevier.com/content/abstract/scopus_id/85102276498,"Nanotechnology is a promising technology and has been widely applied for sustainable smart cities. As the fundamental devices for nanotechnology, piezoelectric actuators (PEAs) have gained wide attention in precision manufacturing because of the advantages of rapid response, large mechanical force and high resolution. However, the inherent nonlinearities of PEAs hinder wide applications for nano-positioning and high-precision manipulation. To eliminate these nonlinearities, various control methods have been proposed, while the optimal control of PEAs is considered rarely. Inspired by the reinforcement learning, adaptive dynamic programming (ADP) is proposed to solve the optimal tracking control problem of PEAs. In this paper, a controller based on reinforcement learning and inverse compensation is designed for the tracking control of PEAs. The experiments on the PEA platform are designed to verify the effectiveness of the proposed method. Comparisons with some representative controllers have demonstrated that the proposed controller has a better control performance.",smart cities
10.1016/j.watres.2021.117012,Journal,Water Research,scopus,2021-05-15,sciencedirect,Gas-diffusion-electrode based direct electro-stripping system for gaseous ammonia recovery from livestock wastewater,https://api.elsevier.com/content/abstract/scopus_id/85102581788,"Livestock wastewater (LW) typically contains a substantial amount of NH4
                     + that can potentially be recovered and used in fertilizers or chemicals. In an attempt to recover NH4
                     + from LW, a novel electrochemical approach using a gas diffusion electrode (GDE) was developed and its efficacy was demonstrated in this study. The GDE-based electrochemical device, when operated at an air-flow rate of 20 mL/min, was free of back-diffusion flux, which is a fatal drawback of any membrane-based NH4
                     + separation approach. Continuous operation resulted in a nitrogen flux of 890 g N/m2d with synthetic LW and 770 g N/m2d with real LW at a current density of 10 mA/cm2. The electrochemical energy input was 7.42 kWh/kg N with synthetic LW and 9.44 kWh/kg N with real LW. Compared with the traditional stripping method, the GDE-based electrochemical system has a certain potential to be competitive, in terms of energy consumption. For instance, a rough-cost estimate based only on operating costs regarding chemical usage, air blowing, and water pumping revealed that the system consumed 13.44 kWh/kg N, whereas the conventional stripper required 27.6 kWh/kg N. This analysis showed that an electrochemical approach such as our GDE-based method can recover NH3, (particularly in gaseous form) from LW. In addition, with the future development of a smart operation method, as proposed and demonstrated in this study, the cost-effective implementation of a GDE-based method is feasible.",smart cities
10.1016/j.bdr.2021.100217,Journal,Big Data Research,scopus,2021-05-15,sciencedirect,CSIP: Enhanced Link Prediction with Context of Social Influence Propagation,https://api.elsevier.com/content/abstract/scopus_id/85102463635,"Data mining in social networks brings an indispensable role for the construction of smart cities from the perspective of social development. Link prediction is an important task of data mining, especially in the knowledge graph, which is also called knowledge graph completion. Link prediction aims to find missing links or predict potential links according to the current social network. The most existing link prediction methods focus on static information in social networks, such as topology and node attributes, which are partly provided by users. When users are unwilling to provide or intentionally hide these static features, traditional link prediction methods cannot achieve ideal performance. The dynamic information of social influence propagation in social networks can avoid the user's subjective impact and better reflect the relationship between users. In addition, users show different degrees of interest and authority on various topics in the real world, leading to different influence propagation patterns. Therefore, we use context of social influence to optimize the topic-aware influence propagation model to improve the performance of link prediction. In this paper, we propose a new multi-output graph neural network framework to capture influence propagation in social networks and model the influence of users in different roles. In this way, the underlying information of influence between users can be used to construct new features to improve the performance of link prediction. Our experiments conduct the method on multiple benchmark datasets. The experimental results show that the modeling of context is effective, and our model outperforms the compared state-of-the-art link prediction methods.",smart cities
10.1016/j.trc.2021.102967,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-05-01,sciencedirect,Automated eco-driving in urban scenarios using deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85103105894,"Urban settings are challenging environments to implement eco-driving strategies for automated vehicles. It is often assumed that sufficient information on the preceding vehicle pulk is available to accurately predict the traffic situation. Because vehicle-to-vehicle communication was introduced only recently, this assumption will not be valid until a sufficiently high penetration of the vehicle fleet has been reached. Thus, in the present study, we employed Reinforcement Learning (RL) to develop eco-driving strategies for cases where little data on the traffic situation are available.
                  An A-segment electric vehicle was simulated using detailed efficiency models to accurately determine its energy-saving potential. A probabilistic traffic environment featuring signalized urban roads and multiple preceding vehicles was integrated into the simulation model. Only information on the traffic light timing and minimal sensor data were provided to the control algorithm. A twin-delayed deep deterministic policy gradient (TD3) agent was implemented and trained to control the vehicle efficiently and safely in this environment.
                  Energy savings of up to 19% compared with a simulated human driver and up to 11% compared with a fine-tuned Green Light Optimal Speed Advice (GLOSA) algorithm were determined in a probabilistic traffic scenario reflecting real-world conditions. Overall, the RL agents showed a better travel time and energy consumption trade-off than the GLOSA reference.",smart cities
10.1016/j.isprsjprs.2021.02.015,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2021-05-01,sciencedirect,Artificial and beneficial – Exploiting artificial images for aerial vehicle detection,https://api.elsevier.com/content/abstract/scopus_id/85102891261,"Object detection in aerial images is an important task in environmental, economic, and infrastructure-related tasks. One of the most prominent applications is the detection of vehicles, for which deep learning approaches are increasingly used. A major challenge in such approaches is the limited amount of data that arises, for example, when more specialized and rarer vehicles such as agricultural machinery or construction vehicles are to be detected. This lack of data contrasts with the enormous data hunger of deep learning methods in general and object recognition in particular. In this article, we address this issue in the context of the detection of road vehicles in aerial images. To overcome the lack of annotated data, we propose a generative approach that generates top-down images by overlaying artificial vehicles created from 2D CAD drawings on artificial or real backgrounds. Our experiments with a modified RetinaNet object detection network show that adding these images to small real-world datasets significantly improves detection performance. In cases of very limited or even no real-world images, we observe an improvement in average precision of up to 0.70 points. We address the remaining performance gap to real-world datasets by analyzing the effect of the image composition of background and objects and give insights into the importance of background.",smart cities
10.1016/j.atmosres.2021.105490,Journal,Atmospheric Research,scopus,2021-05-01,sciencedirect,Changes of ammonia concentrations in wintertime on the North China Plain from 2018 to 2020,https://api.elsevier.com/content/abstract/scopus_id/85100690328,"The reduced economic and social activities during the Chinese Spring Festival provide a unique experiment to evaluate reductions in anthropogenic NH3 emissions in China. However, quantifying this unique scenario is challenging as meteorology may mask the real changes in observed NH3 concentrations. Here, we applied a machine learning technique to decouple the effects of meteorology and confirmed that the real (deweathered) NH3 concentration dropped to a minimum during the Spring Festival in 2019 and 2020 at both urban (Beijing) and rural (Xianghe) sites on the North China Plain. Compared with the scenario without the Spring Festival effect, we predicted that NH3 concentrations in 2020 were 39.8% and 24.6% higher than the observed values at the urban and rural sites, respectively. The significant difference between the two sites indicates a larger reduction in anthropogenic NH3 emissions in urban areas than in rural areas due to the Spring Festival and lockdown measures of COVID-19. Future control strategies should consider the emissions of NH3 from the transportation, industrial and residential sectors, considering that agricultural emissions are minor in cold seasons.",smart cities
10.1016/j.biopha.2021.111331,Journal,Biomedicine and Pharmacotherapy,scopus,2021-05-01,sciencedirect,Qingjie Fuzheng Granule suppresses lymphangiogenesis in colorectal cancer via the VEGF-C/VEGFR-3 dependent PI3K/AKT pathway,https://api.elsevier.com/content/abstract/scopus_id/85100646902,"Scope
                  To investigate the effect of Qingjie Fuzheng Granule (QFG) on lymphangiogenesis and lymphatic metastasis in colorectal cancer.
               
                  Methods
                  The effects of QFG on the expression and secretion of vascular endothelial growth factor-C (VEGF-C) in HCT-116 cells were investigated both in vitro and in vivo. HCT-116 cells were treated with different concentrations (0.2, 0.5, and 1.0 mg/mL) of QFG. The VEGF-C expression level was determined using RT-qPCR and western blotting, and the VEGF-C concentration in supernatant was measured by ELISA. Tumor xenograft models of HCT-116 cells were generated using BALB/c nude mice, and the mice were randomly divided into a control group (gavaged with normal saline) and QFG group (gavaged with 2 g/kg QFG). The effect of QFG on tumor growth was evaluated by comparing the volume and weight of tumors between two groups. Immunohistochemistry (IHC) and RT-qPCR were performed to detect the expression levels of VEGF-C, vascular endothelial growth factor receptor 3 (VEGFR-3), and LYVE-1 (lymphatic vessel endothelial hyaluronan receptor 1). ELISA was performed to measure the concentration of serum VEGF-C. TMT proteomics technology and Reactome pathway analysis were used to explore the mechanism of QFG inhibiting lymphangiogenesis in tumor. The VEGF-C (5 ng/mL)-stimulated human lymphatic endothelial cell (HLEC) model was conducted to evaluate the effect of QFG on lymphangiogenesis in vitro. The model cells were treated with different concentrations (0.2, 0.5, and 1.0 mg/mL) of QFG. Cell viability was then determined using an MTT assay. The cell migration, invasion, and tube-formation ability were analyzed using transwell migration, matrigel invasion and tube formation assays, respectively. The underlying mechanism was uncovered, the levels of VEGFR-3, matrix metalloproteinase 2 (MMP-2), matrix metalloproteinase 9 (MMP-9), p-PI3K/PI3K, p-AKT/AKT and p-mTOR/ mTOR were detected using western blotting.
               
                  Results
                  QFG significantly reduced VEGF-C expression and secretion in HCT-116 cells. QFG evidently suppressed in vivo tumor growth and the expression of VEGF-C, VEGFR-3, and LYVE-1. The serum VEGF-C level was also reduced by QFG. Moreover, TMT proteomics technology and Reactome pathway analysis identified 95 differentially expressed protein and multiple enriched pathway about matrix metalloproteinase and extracellular matrix, which is direct associate with lymphangiogenesis. In vitro experiment, QFG inhibited the viability, migration, invasion and tube formation of HLECs. Additionally, QFG reduced the VEGFR-3, MMP-2, MMP-9 expression levels, and the p-PI3K/PI3K, p-AKT/AKT, p-mTOR/ mTOR ratios.
               
                  Conclusion
                  QFG can exert its effect on both tumor cells and HLECs, exhibiting ani- lymphangiogenesis in colorectal cancer via the VEGF-C/VEGFR-3 dependent PI3K/AKT pathway pathway.",smart cities
10.1016/j.sysarc.2021.102016,Journal,Journal of Systems Architecture,scopus,2021-05-01,sciencedirect,SimEdgeIntel: A open-source simulation platform for resource management in edge intelligence,https://api.elsevier.com/content/abstract/scopus_id/85099788069,"To meet the challenges posed by the explosive growth of mobile traffic, data caching at the network edge has been considered a key technology in future mobile networks, while the potential of device-to-device (D2D) communications in areas such as traffic offloading is also of great interest. Existing work does not have a network switching mechanism, which would ensure load balancing and improve quality of service are also ignored. Existing simulators perform poorly in terms of algorithmic compatibility, and require a high level of coding ability which are difficult to get started. In this paper, an edge simulator called SimEdgeIntel is presented for resource management that opens up detailed configuration options, enabling researchers quickly deploy mobile with edge intelligence. It supports researchers to customize the development of mobility models, caching algorithms and switching strategies. The interface-oriented system architecture helps researchers achieve cross-platform and cross-language algorithm import with machine learning techniques. In the experimental section, we perform a comprehensive evaluation of SimEdgeIntel based on real-world tracing, proving its scalability and effectiveness in terms of cache hit rate, delivery latency, and backhaul traffic, and evaluating its performance in terms of CPU and memory, respectively.",smart cities
10.1016/j.is.2019.101444,Journal,Information Systems,scopus,2021-05-01,sciencedirect,Speed prediction in large and dynamic traffic sensor networks,https://api.elsevier.com/content/abstract/scopus_id/85073835684,"Smart cities are nowadays equipped with pervasive networks of sensors that monitor traffic in real-time and record huge volumes of traffic data. These datasets constitute a rich source of information that can be used to extract knowledge useful for municipalities and citizens. In this paper we are interested in exploiting such data to estimate future speed in traffic sensor networks, as accurate predictions have the potential to enhance decision making capabilities of traffic management systems. Building effective speed prediction models in large cities poses important challenges that stem from the complexity of traffic patterns, the number of traffic sensors typically deployed, and the evolving nature of sensor networks. Indeed, sensors are frequently added to monitor new road segments or replaced/removed due to different reasons (e.g., maintenance). Exploiting a large number of sensors for effective speed prediction thus requires smart solutions to collect vast volumes of data and train effective prediction models. Furthermore, the dynamic nature of real-world sensor networks calls for solutions that are resilient not only to changes in traffic behavior, but also to changes in the network structure, where the cold start problem represents an important challenge. We study three different approaches in the context of large and dynamic sensor networks: local, global, and cluster-based. The local approach builds a specific prediction model for each sensor of the network. Conversely, the global approach builds a single prediction model for the whole sensor network. Finally, the cluster-based approach groups sensors into homogeneous clusters and generates a model for each cluster. We provide a large dataset, generated from 
                        ∼
                     1.3 billion records collected by up to 272 sensors deployed in Fortaleza, Brazil, and use it to experimentally assess the effectiveness and resilience of prediction models built according to the three aforementioned approaches. The results show that the global and cluster-based approaches provide very accurate prediction models that prove to be robust to changes in traffic behavior and in the structure of sensor networks.",smart cities
10.1016/j.trc.2020.102895,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-04-01,sciencedirect,An enhanced artificial bee colony algorithm for the green bike repositioning problem with broken bikes,https://api.elsevier.com/content/abstract/scopus_id/85102032396,"The Bike Repositioning Problem (BRP) has raised many researchers’ attention in recent years to improve the service quality of Bike Sharing Systems (BSSs). It is mainly about designing the routes and loading instructions for the vehicles to transfer bikes among stations in order to achieve a desirable state. This study tackles a static green BRP that aims to minimize the CO2 emissions of the repositioning vehicle besides achieving the target inventory level at stations as much as possible within the time budget. Two types of bikes are considered, including usable and broken bikes. The Enhanced Artificial Bee Colony (EABC) algorithm is adopted to generate the vehicle route. Two methods, namely heuristic and exact methods, are proposed and incorporated into the EABC algorithm to compute the loading/unloading quantities at each stop. Computational experiments were conducted on the real-world instances having 10–300 stations. The results indicate that the proposed solution methodology that relies on the heuristic loading method can provide optimal solutions for small instances. For large-scale instances, it can produce better feasible solutions than two benchmark methodologies in the literature.",smart cities
10.1016/j.trc.2021.103059,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-04-01,sciencedirect,Network-wide traffic signal control optimization using a multi-agent deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85101941829,"Inefficient traffic control may cause numerous problems such as traffic congestion and energy waste. This paper proposes a novel multi-agent reinforcement learning method, named KS-DDPG (Knowledge Sharing Deep Deterministic Policy Gradient) to achieve optimal control by enhancing the cooperation between traffic signals. By introducing the knowledge-sharing enabled communication protocol, each agent can access to the collective representation of the traffic environment collected by all agents. The proposed method is evaluated through two experiments respectively using synthetic and real-world datasets. The comparison with state-of-the-art reinforcement learning-based and conventional transportation methods demonstrate the proposed KS-DDPG has significant efficiency in controlling large-scale transportation networks and coping with fluctuations in traffic flow. In addition, the introduced communication mechanism has also been proven to speed up the convergence of the model without significantly increasing the computational burden.",smart cities
10.1016/j.trb.2021.02.007,Journal,Transportation Research Part B: Methodological,scopus,2021-04-01,sciencedirect,Macroscopic traffic flow modeling with physics regularized Gaussian process: A new insight into machine learning applications in transportation,https://api.elsevier.com/content/abstract/scopus_id/85101806933,"Despite the wide implementation of machine learning (ML) technique in traffic flow modeling recently, those data-driven approaches often fall short of accuracy in the cases with a small or noisy training dataset. To address this issue, this study presents a new modeling framework, named physics regularized machine learning (PRML), to encode classical traffic flow models (referred as physics models) into the ML architecture and to regularize the ML training process. More specifically, leveraging the Gaussian process (GP) as the base model, a stochastic physics regularized Gaussian process (PRGP) model is developed and a Bayesian inference algorithm is used to estimate the mean and kernel of the PRGP. A physics regularizer, based on macroscopic traffic flow models, is also developed to augment the estimation via a shadow GP and an enhanced latent force model is used to encode physical knowledge into the stochastic process. Based on the posterior regularization inference framework, an efficient stochastic optimization algorithm is then developed to maximize the evidence lowerbound of the system likelihood. For model evaluations, this paper conducts empirical studies on a real-world dataset which is collected from a stretch of I-15 freeway, Utah. Results show the new PRGP model can outperform the previous compatible methods, such as calibrated traffic flow models and pure machine learning methods, in estimation precision and is more robust to the noisy training dataset.",smart cities
10.1016/j.isprsjprs.2021.01.027,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2021-04-01,sciencedirect,VPC-Net: Completion of 3D vehicles from MLS point clouds,https://api.elsevier.com/content/abstract/scopus_id/85101520322,"As a dynamic and essential component in the road environment of urban scenarios, vehicles are the most popular investigation targets. To monitor their behavior and extract their geometric characteristics, an accurate and instant measurement of vehicles plays a vital role in traffic and transportation fields. Point clouds acquired from the mobile laser scanning (MLS) system deliver 3D information of road scenes with unprecedented detail. They have proven to be an adequate data source in the fields of intelligent transportation and autonomous driving, especially for extracting vehicles. However, acquired 3D point clouds of vehicles from MLS systems are inevitably incomplete due to object occlusion or self-occlusion. To tackle this problem, we proposed a neural network to synthesize complete, dense, and uniform point clouds for vehicles from MLS data, named Vehicle Points Completion-Net (VPC-Net). In this network, we introduce a new encoder module to extract global features from the input instance, consisting of a spatial transformer network and point feature enhancement layer. Moreover, a new refiner module is also presented to preserve the vehicle details from inputs and refine the complete outputs with fine-grained information. Given sparse and partial point clouds as inputs, the network can generate complete and realistic vehicle structures and keep the fine-grained details from the partial inputs. We evaluated the proposed VPC-Net in different experiments using synthetic and real-scan datasets and applied the results to 3D vehicle monitoring tasks. Quantitative and qualitative experiments demonstrate the promising performance of the proposed VPC-Net and show state-of-the-art results.",smart cities
10.1016/j.trc.2021.103049,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-04-01,sciencedirect,Prediction of runway configurations and airport acceptance rates for multi-airport system using gridded weather forecast,https://api.elsevier.com/content/abstract/scopus_id/85101363258,"Accurate prediction of real-time airport capacity, a.k.a. airport acceptance rates (AARs), is key to enabling efficient air traffic flow management. AARs are dependent on selected runway configurations and both are affected by weather conditions. Although there have been studies tackling on the prediction of AARs or runway configurations or both, the prediction accuracy is relatively low and only single airport is considered. This study presents a data-driven deep-learning framework for predicting both runway configurations and AARs to support efficient air traffic management for complex multi-airport systems. The two major contributions from this work are 1) the proposed model uses assembled gridded weather forecast for the terminal airspace instead of an isolated station-based terminal weather forecast, and 2) the model captures the operational interdependency aspects inherent in the parameter learning process so that proposed modeling framework can predict both runway configuration and AARs simultaneously with higher accuracy. The proposed method is demonstrated with a numerical experiment taking three major airports in New York Metroplex as the case study. The prediction accuracy of the proposed method is compared with methods in current literature and the analysis results show that the proposed method outperforms all existing methods.",smart cities
10.1016/j.scs.2020.102700,Journal,Sustainable Cities and Society,scopus,2021-04-01,sciencedirect,Cascade saccade machine learning network with hierarchical classes for traffic sign detection,https://api.elsevier.com/content/abstract/scopus_id/85099520140,"Traffic signs detection is one of the significant tasks for autonomous driving. It conveys notable traffic information timely to road users and maintains traffic safety in smart grid of cities. However, the size of most traffic signs is less than 0.5% of the image of traffic scene, and the uneven distribution of training samples limits the accuracy of the model. Moreover, the appearance of traffic signs within the same category of meaning always varies in shapes, colors, from one country to another. Few works have provided robust solutions to these problems simultaneously. In this paper, motivated from the property of saccade in human vision, we developed a novel architecture cascade saccade network with class hierarchy structure for traffic sign detection and domain shift problem. Experiments on Chinese traffic sign benchmarks (TT100K) demonstrated that the proposed detector achieves comparable performance with the state-of-the-art methods with an average performance improvement of 6% in precision and 14% in recall for small size, and detection time with a GPU is 0.08 s per 2048 × 2048 sized image, which can satisfy the real time requirements of driving safety applications. Moreover, proposed model can be easily extended to solve the cross-domain detection of traffic signs.",smart cities
10.1016/j.asoc.2020.107069,Journal,Applied Soft Computing,scopus,2021-04-01,sciencedirect,Deep learning feature exploration for Android malware detection,https://api.elsevier.com/content/abstract/scopus_id/85098947132,"Android mobile devices and applications are widely deployed and used in industry and smart city. Malware detection is one of the most powerful and effective approaches to guarantee security of Android systems, especially for industrial platform and smart city. Recently, researches using machine learning-based techniques for Android malware detection increased rapidly. Nevertheless, most of the appeared approaches have to perform feature analysis and selection, so-called feature engineering, which is time-consuming and relies on artificial experience. To solve the inefficiency problem of feature engineering, we propose TC-Droid, an automatic framework for Android malware detection based on text classification method. The core idea of TC-Droid is derived from the field of text classification. TC-Droid feeds on the text sequence of APPs analysis reports generated by AndroPyTool, applies a convolutional neural network (CNN) to explore significant information (or knowledge) under original report text, instead of manual feature engineering. In an evaluation with different number of real-world samples, TC-Droid outperforms state-of-the-art model (Drebin) and several classic models (NB, LR, KNN, RF) as well. With multiple experimental settings and corresponding comparisons, TC-Droid achieves effective and flexible performance in Android malware detection task.",smart cities
10.1016/j.seppur.2020.118238,Journal,Separation and Purification Technology,scopus,2021-04-01,sciencedirect,Continuous microfluidic solvent extraction of cobalt from mimicked and real asteroid leaching solutions,https://api.elsevier.com/content/abstract/scopus_id/85098699532,"This research proposes a pathway for the last step of the asteroid mining process: the purification of the adjacent metals, cobalt and nickel, in the frame of in-situ resource utilization (ISRU) in space. Major technological and economic challenges will need to be overcome, and one main issue to be tackled is the reduction of water usage in this process. Therefore, the leached metal solutions are expected to contain ultra-high metal concentrations, up to 10 mol/l. These solutions will have challenging thermodynamic properties (increased density, viscosity and interfacial tension). As a result, an analysis of dimensionless numbers for fluidics and mass transport was made, showing that some of these are favourable under the constraints of accessible microfluidic operations. Experiments were performed with advanced microfluidic reactors (a coiled-flow inverter (CFI) and an industrial re-entrance flow reactor from Corning®) at high metal concentrations and high nickel to cobalt ratios (3:0.3 mol/l Ni:Co). Using Cyanex 272 as a selective extractant for cobalt, extraction efficiencies of 60% with high separation factors (>1000) were reached in just one extraction stage. The CFI showed high extraction efficiency for low fluid velocities and a residence time of 60 s. For the Corning® reactor, high fluid velocities or the use of many modules (>3) are needed to obtain an emulsion, resulting in high extraction efficiencies at a very short residence time of 13 s. The comparison between the CFI and the Corning® reactor shows that they share the best operation point (at 120 ml/h), but the Corning® reactor performs better at higher flow rates and thus can leverage higher productivity. However, the CFI is easier to operate and has a much lower pressure drop, resulting in low energy input. Finally, an iron meteorite sample was leached and efficiently extracted in both microfluidic reactors.",smart cities
10.1016/j.cpc.2020.107779,Journal,Computer Physics Communications,scopus,2021-04-01,sciencedirect,Mammography and breast tomosynthesis simulator for virtual clinical trials,https://api.elsevier.com/content/abstract/scopus_id/85098176202,"Computer modeling and simulations are increasingly being used to predict the clinical performance of x-ray imaging devices in silico, and to generate synthetic patient images for training and testing of machine learning algorithms. We present a detailed description of the computational models implemented in the open source GPU-accelerated Monte Carlo x-ray imaging simulation code MC-GPU. This code, originally developed to simulate radiography and computed tomography, has been extended to replicate a commercial full-field digital mammography and digital breast tomosynthesis (DBT) device. The code was recently used to image 3000 virtual breast models with the aim of reproducing in silico a clinical trial used in support of the regulatory approval of DBT as a replacement of mammography for breast cancer screening. The updated code implements a more realistic x-ray source model (extended 3D focal spot, tomosynthesis acquisition trajectory, tube motion blurring) and an improved detector model (direct-conversion Selenium detector with depth-of-interaction effects, fluorescence tracking, electronic noise and anti-scatter grid). The software uses a high resolution voxelized geometry model to represent the breast anatomy. To reduce the GPU memory requirements, the code stores the voxels in memory within a binary tree structure. The binary tree is an efficient compression mechanism because many voxels with the same composition are combined in common tree branches while preserving random access to the phantom composition at any location. A delta scattering ray-tracing algorithm which does not require computing ray-voxel interfaces is used to minimize memory access. Multiple software verification and validation steps intended to establish the credibility of the implemented computational models are reported. The software verification was done using a digital quality control phantom and an ideal pinhole camera. The validation was performed reproducing standard bench testing experiments used in clinical practice and comparing with experimental measurements. A sensitivity study intended to assess the robustness of the simulated results to variations in some of the input parameters was performed using an in silico clinical trial pipeline with simulated lesions and mathematical observers. We show that MC-GPU is able to simulate x-ray projections that incorporate many of the sources of variability found in clinical images, and that the simulated results are robust to some uncertainty in the input parameters. Limitations of the implemented computational models are discussed.
               
                  Program summary
                  
                     Program title: MCGPU_VICTRE
                  
                     CPC Library link to program files: 
                     https://doi.org/10.17632/k5x2bsf27m.1
                  
                  
                     Licensing provisions: CC0 1.0
                  
                     Programming language: C (with NVIDIA CUDA extensions)
                  
                     Nature of problem: The health risks associated with ionizing radiation impose a limit to the amount of clinical testing that can be done with x-ray imaging devices. In addition, radiation dose cannot be directly measured inside the body. For these reasons, a computational replica of an x-ray imaging device that simulates radiographic images of synthetic anatomical phantoms is of great value for device evaluation. The simulated radiographs and dosimetric estimates can be used for system design and optimization, task-based evaluation of image quality, machine learning software training, and in silico imaging trials.
                  
                     Solution method: Computational models of a mammography x-ray source and detector have been implemented. X-ray transport through matter is simulated using Monte Carlo methods customized for parallel execution in multiple Graphics Processing Units. The input patient anatomy is represented by voxels, which are efficiently stored in the video memory using a new binary tree structure compression mechanism.",smart cities
10.1016/j.envpol.2020.115900,Journal,Environmental Pollution,scopus,2021-04-01,sciencedirect,Understanding the true effects of the COVID-19 lockdown on air pollution by means of machine learning,https://api.elsevier.com/content/abstract/scopus_id/85097107266,"During March 2020, most European countries implemented lockdowns to restrict the transmission of SARS-CoV-2, the virus which causes COVID-19 through their populations. These restrictions had positive impacts for air quality due to a dramatic reduction of economic activity and atmospheric emissions. In this work, a machine learning approach was designed and implemented to analyze local air quality improvements during the COVID-19 lockdown in Graz, Austria. The machine learning approach was used as a robust alternative to simple, historical measurement comparisons for various individual pollutants. Concentrations of NO2 (nitrogen dioxide), PM10 (particulate matter), O3 (ozone) and Ox (total oxidant) were selected from five measurement sites in Graz and were set as target variables for random forest regression models to predict their expected values during the city’s lockdown period. The true vs. expected difference is presented here as an indicator of true pollution during the lockdown. The machine learning models showed a high level of generalization for predicting the concentrations. Therefore, the approach was suitable for analyzing reductions in pollution concentrations. The analysis indicated that the city’s average concentration reductions for the lockdown period were: -36.9 to −41.6%, and −6.6 to −14.2% for NO2 and PM10, respectively. However, an increase of 11.6–33.8% for O3 was estimated. The reduction in pollutant concentration, especially NO2 can be explained by significant drops in traffic-flows during the lockdown period (−51.6 to −43.9%). The results presented give a real-world example of what pollutant concentration reductions can be achieved by reducing traffic-flows and other economic activities.",smart cities
10.1016/j.jep.2020.113654,Journal,Journal of Ethnopharmacology,scopus,2021-03-25,sciencedirect,Antidiabetic effect of a flavonoid-rich extract from Sophora alopecuroides L. in HFD- and STZ- induced diabetic mice through PKC/GLUT4 pathway and regulating PPARα and PPARγ expression,https://api.elsevier.com/content/abstract/scopus_id/85097798210,"Headings ethnopharmacological relevance
                  
                     Sophora alopecuroides L. is a traditional ethnopharmacological plant, which is widely used in traditional Chinese medicine and Mongolian and Uighur medicine to ameliorate “thirst disease”.
               
                  Aim of the study
                  This study aimed to investigate the antidiabetic activities and mechanisms of a flavonoid-rich extract from Sophora alopecuroides L. (SA-FRE) both in vivo and vitro.
               
                  Materials and methods
                  The main six chemical constituents of SA-FRE were elucidated based on an off-line semi-preparative liquid chromatography nuclear magnetic resonance (LC-NMR) protocol. Myc-GLUT4-mOrange-L6 cell models and mouse model with diabetes induced by high-fat diet combined with STZ injection were respectively adopted to investigate the antidiabetic effects of SA-FRE both in vitro and vivo.
                  
               
                  Results
                  
                     In vivo, 4-week treatment of SA-FRE ameliorated hyperglycemia, dyslipidemia, and insulin resistance in diabetic mice. Mechanically, SA-FRE regulated PPARα and PPARγ expression in white adipose tissue (WAT) and liver, thereby ameliorating dyslipidemia. Moreover, SA-FRE increased the phosphorylation of PKC and further stimulated the GLUT4 expression in WAT and skeletal muscle, thus increasing the glucose utilization in vivo. In vitro, 50 μg/mL SA-FRE increased GLUT4 translocation to about 1.91-fold and glucose uptake to 1.82-fold in L6-myotubes. SA-FRE treatment increased the GLUT4 expression at both gene and protein levels. Furthermore, only Gö6983, a PKC inhibitor, reversed the SA-FRE-induced GLUT4 translocation and expression at the gene and protein levels.
               
                  Conclusions
                  Generally, SA-FRE ameliorated hyperglycemia, dyslipidemia, and insulin resistance partly through activating PKC/GLUT4 pathway and regulating PPARα and PPARγ expression.",smart cities
10.1016/j.adhoc.2020.102383,Journal,Ad Hoc Networks,scopus,2021-03-15,sciencedirect,Recommending irregular regions using graph attentive networks,https://api.elsevier.com/content/abstract/scopus_id/85099212473,"Due to the prevalence of human activity in urban spaces, recommending ROIs (region-of-interests) to users, especially irregular ROIs, becomes an important task in location-based social networks. A fundamental problem is how to aggregate users’ preferences over POIs (point-of-interests) to infer the users’ region-level mobility patterns. The majority of existing studies ignore the users’ implicit interactions with individual POIs when addressing this issue. For example, a user check-in a region cannot provide any specific information about how the user likes this region (we call this phenomenon “ROI-level” implicitness) and which POI in this region the user is interested in (i.e., “POI-level” implicitness). Furthermore, existing studies adopt predefined strategies for region-level preference aggregation, that is, initializing the importance of different POIs with identical weights, which is insufficient to model the reality of social networks.
                  We emphasize two facts in this paper: 
                        (1)
                      there simultaneously exists ROI-level and POI-level implicitness that blurs the users’ underlying preferences; and 
                        (2)
                      individual POIs should have non-uniform weights and more importantly, the weights should vary across different users. To address these issues, we contribute a novel solution, namely GANR
                        
                           
                           
                              2
                           
                        
                      (Graph Attentive Neural Network for Region Recommendation). Specifically, to learn the user preferences over irregular ROIs, we provide a principled neural network equipped with two attention modules: the POI-level attention module, to select the informative POIs of one ROI, and the ROI-level attention module, to learn the ROI preferences. Moreover, we learn the interactions between users and ROIs under the NGCF (Neural Graph Collaborative Filtering) framework. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework.",smart cities
10.1016/j.comnet.2021.107820,Journal,Computer Networks,scopus,2021-03-14,sciencedirect,Quick &amp; plenty: Achieving low delay &amp; high rate in 802.11ac edge networks,https://api.elsevier.com/content/abstract/scopus_id/85099254906,"We consider transport layer approaches for achieving high rate, low delay communication over edge paths where the bottleneck is an 802.11ac WLAN. We first show that by regulating send rate so as to maintain a target aggregation level it is possible to realise high rate, low delay communication over 802.11ac WLANs. We then address two important practical issues arising in production networks, namely that (i) many client devices are non-rooted mobile handsets/tablets and (ii) the bottleneck may lie in the backhaul rather than the WLAN, or indeed vary between the two over time. We show that both these issues can be resolved by use of simple and robust machine learning techniques. We present a prototype transport layer implementation of our low delay rate allocation approach and use this to evaluate performance under real radio conditions.",smart cities
10.1016/j.neucom.2020.11.038,Journal,Neurocomputing,scopus,2021-03-07,sciencedirect,Multi-stage attention spatial-temporal graph networks for traffic prediction,https://api.elsevier.com/content/abstract/scopus_id/85098736017,"Accurate traffic prediction plays an important role in Intelligent Transportation System. This problem is very challenging due to the heterogeneity and dynamic spatio-temporal dependence of large-scale traffic data. Existing models often suffer two limitations: (1) They usually only consider one type of data in the input, or simply treat other collected time series data as features, ignoring the non-linear interactions among different series. In fact, heterogeneous data at a specific location has direct impacts on the predicted series. (2) The method based on graph convolutional network uses a fixed Laplacian matrix to model spatial correlation, without considering its dynamics. The aggregations also occur only in the neighborhood, making it difficult to capture long-range dependencies. In this paper, we propose a Multi-Stage Attention Spatial-Temporal Graph Networks (MASTGN). First, an internal attention mechanism is designed to capture the interactions among multiple time series collected by the same sensor. Second, to model the complex spatial correlations, we apply a dynamic neighborhood-based attention mechanism. Unlike the general attention-based methods that ignore the structure information of the road network, we use the adjacency relations as a prior to divide the nodes of a road network into different neighborhood sets. In this way, attention can capture spatial correlations both within the same order neighborhood, and among different neighborhoods dynamically. Furthermore, a temporal attention mechanism is used to extract the dynamic temporal dependencies. Experiments are conducted on two real traffic datasets, and the results verify the effectiveness of the proposed model.",smart cities
10.1016/j.neucom.2020.03.121,Journal,Neurocomputing,scopus,2021-03-07,sciencedirect,Detecting urban hot regions by using massive geo-tagged image data,https://api.elsevier.com/content/abstract/scopus_id/85089358407,"Detecting hot regions plays an important role in urban traffic planning and analytics, which is also useful in self-driving car routing and navigation. In this light, we propose and study a novel urban hot-region detection method by using massive geo-tagged image data. Given a set Q of regions (each region q is made up by a set of geo-tagged images), and a matching threshold 
                        
                           θ
                        
                     , if a region q is matched with m other regions, its hot degree is defined by m. The hot-region detection (HRD) search finds the regions with the highest hot degrees. We believe that this type of search may benefit many applications in self-driving cars, including route planning and navigation, and traffic management and analytics in general. The HRD search is challenging due to two reasons. First, how to evaluate the similarity when matching different regions. Second, how to compute the HRD search efficiently, since its time complexity is 
                        
                           O
                           (
                           |
                           Q
                           
                              
                                 |
                              
                              
                                 2
                              
                           
                           )
                        
                     . To overcome the challenges, we define a novel spatial-density correlation measure to evaluate the similarity between two regions, and develop a parallel search framework to process the HRD efficiently. In addition, a series of optimization techniques, e.g., pruning techniques, are defined to further enhance the query efficiency. Finally, we conduct extensive experiments on real data sets to study the performance of the developed methods.",smart cities
10.1016/j.iot.2020.100347,Journal,Internet of Things (Netherlands),scopus,2021-03-01,sciencedirect,RL-PMAgg: Robust aggregation for PM2.5 using deep RL-based trust management system,https://api.elsevier.com/content/abstract/scopus_id/85114812625,"Air pollution has become a major environmental issue in large cities. Air pollutants, especially fine particulate matter (PM2.5) has raised various concerns on human health. As a result, several low-cost PM2.5 monitoring systems have been deployed worldwide. However, an accurate air pollution monitoring system profoundly relies on data quality. In this paper, we propose RL-PMAgg for robustly computing PM2.5 pollution rates in existence of faulty sensors. Our method consists of three modules. The outlier detector gives quality assessments to the measurements. We use an RL-based trust management system to create a profile for each sensor and track its behavior in the long run. Then, an aggregated PM2.5 rate is computed by using a set of honest sensors along with their trust levels and measurements. We evaluate RL-PMAgg on both simulated and real-world datasets. We compare the proposed method with relevant works. Experimental results show that RL-PMAgg resists the majority of attacks as compared with other works.",smart cities
10.1016/j.tra.2021.01.020,Journal,Transportation Research Part A: Policy and Practice,scopus,2021-03-01,sciencedirect,"Spatio-temporal analysis of on-demand transit: A case study of Belleville, Canada",https://api.elsevier.com/content/abstract/scopus_id/85100659326,"The rapid increase in the cyber-physical nature of transportation, availability of GPS data, mobile applications, and effective communication technologies have led to the emergence of On-Demand Transit (ODT) systems. In September 2018, the City of Belleville in Canada started an on-demand public transit pilot project, where the late-night fixed-route (RT 11) was substituted with the ODT providing a real-time ride-hailing service. We present an in-depth analysis of the spatio-temporal demand and supply, level of service, and origin and destination patterns of Belleville ODT users, based on the data collected from September 2018 till May 2019. The independent and combined effects of the demographic characteristics (population density, working-age, and median income) on the ODT trip production and attraction levels were studied using GIS and the K-means machine learning clustering algorithm. The results indicate that ODT trips demand is highest for 11:00 pm–11:45 pm during the weekdays and 8:00 pm–8:30 pm during the weekends. We expect this to be the result of users returning home from work or shopping. Results showed that 39% of the trips were found to have a waiting time of smaller than 15 min, while 28% of trips had a waiting time of 15–30 min. The dissemination areas with higher population density, lower median income, or higher working-age percentages tend to have higher ODT trip attraction levels, except for the dissemination areas that have highly attractive places like commercial areas. For the sustainable deployment of ODT services, we recommend (a) proactively relocating the empty ODT vehicles near the neighbourhoods with high level of activity, (b) dynamically updating the fleet size and location based on the anticipated changes in the spatio-temporal demand, and (c) using medium occupancy vehicles, like vans or minibuses to ensure high level of service.",smart cities
10.1016/j.compeleceng.2021.107004,Journal,Computers and Electrical Engineering,scopus,2021-03-01,sciencedirect,Vehicle logo detection based on deep convolutional networks,https://api.elsevier.com/content/abstract/scopus_id/85100057639,"For intelligent transportation systems, vehicle logo is an important part in the research of vehicle information recognition. Deep convolutional neural networks (CNNs) have been more reasonable and stronger than artificial selection in feature extraction and expression for targets. In our previous work, we found that the network of feature extraction and the training policy of detection have great effects on the accuracy of vehicle logo. For improving small-scale object detecting precision, we change the training policy. According to our previous work, we propose a lightweight network structure with separable convolution to improve the real-time character for vehicle logo while implement the method in embedded devices. The experiment proves that our model can effectively improve the detection accuracy of vehicle logo. Our training policy is valid method for small-scale objects. The lightweight network can solve the equilibrium problem of detecting precision and speed.",smart cities
10.1016/j.trc.2020.102962,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-03-01,sciencedirect,Decoding pedestrian and automated vehicle interactions using immersive virtual reality and interpretable deep learning,https://api.elsevier.com/content/abstract/scopus_id/85098936346,"To ensure pedestrian-friendly streets in the era of automated vehicles, reassessment of current policies, practices, design, rules and regulations of urban areas is of importance. This study investigates pedestrian crossing behaviour which, as an important element of urban dynamics, is expected to be affected by the presence of automated vehicles. For this purpose, an interpretable machine learning framework is proposed to explore factors affecting pedestrians’ wait time before crossing mid-block crosswalks in the presence of automated vehicles. To collect rich behavioural data, we developed a dynamic and immersive virtual reality experiment, with 180 participants from a heterogeneous population in 4 different locations in the Greater Toronto Area (GTA). Pedestrian wait time behaviour is then analysed using a data-driven Cox Proportional Hazards (CPH) model, in which the linear combination of the covariates is replaced by a flexible non-linear deep neural network. The proposed model achieved a 5% improvement in goodness of fit, but more importantly, enabled us to incorporate a richer set of covariates. A game theoretic based interpretability method is used to understand the contribution of different covariates to the time pedestrians wait before crossing. Results show that the presence of automated vehicles on roads, wider lane widths, high density on roads, limited sight distance, and lack of walking habits are the main contributing factors to longer wait times. Our study suggested that, to move towards pedestrian-friendly urban areas, educational programs for children, enhanced safety measures for seniors, promotion of active modes of transportation, and revised traffic rules and regulations should be considered.",smart cities
10.1016/j.trc.2020.102912,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-03-01,sciencedirect,Urban flow prediction with spatial–temporal neural ODEs,https://api.elsevier.com/content/abstract/scopus_id/85097721555,"With the recent advances in deep learning, data-driven methods have shown compelling performance in various application domains enabling the Smart Cities paradigm. Leveraging spatial–temporal data from multiple sources for (citywide) traffic forecasting is a key to strengthen the smart city management in areas such as urban traffic control, abnormal event detection, etc. Existing approaches of traffic flow prediction mainly rely on the development of various deep neural networks –e.g., Convolutional Neural Networks such as ResNet are used for modeling spatial dependencies among different regions, whereas recurrent neural networks are increasingly implemented for temporal dynamics modeling. Despite their advantages, the existing approaches suffer from limitations of intensive computations, lack of capabilities to properly deal with missing values, and simplistic integration of heterogeneous data. In this paper, we propose a novel urban flow prediction framework by generalizing the hidden states of the model with continuous-time dynamics of the latent states using neural ordinary differential equations (ODE). Specifically, we introduce a discretize-then-optimize approach to improve and balance the prediction accuracy and computational efficiency. It not only guarantees the prediction error but also provides high flexibility for decision-makers. Furthermore, we investigate the factors, both intrinsic and extrinsic, that affect the city traffic volume and use separate neural networks to extract and disentangle the influencing factors, which avoids the brute-force data fusion in previous works. Extensive experiments conducted on the real-world large-scale datasets demonstrate that our method outperforms the state-of-the-art baselines, while requiring significantly less memory cost and fewer model parameters.",smart cities
10.1016/j.energy.2020.119437,Journal,Energy,scopus,2021-03-01,sciencedirect,"The effects of dynamic traffic conditions, route characteristics and environmental conditions on trip-based electricity consumption prediction of electric bus",https://api.elsevier.com/content/abstract/scopus_id/85097465270,"As prediction of trip-based electricity consumption has become an prerequisite for the deployment of large-scale EB fleets, this study has established random forest-based models to systematically investigate the impacts of environmental conditions, route characteristics, and dynamic traffic conditions. The models have been performed on real-world data collected from 1024 EBs over five consecutive months in Shenzhen, China. The results show that considering all the influencing variables can significantly enhance the prediction performance, but comparatively speaking, the route characteristics contribute the most among the three categories and involving more variables demonstrates greater advantages within the trip length under 20 km. It is also found that the trip length, the number of bus stops and the number of the traffic lights passed rank the top three most influencing factors, while the wet-dry condition is the least one. In addition, the variations under five operation scenarios show similar trend. The trip length and average travel speed are inversely proportional to the specific electricity consumption, while the number of bus stops visited, traffic lights passed, and ambient temperature exhibit a gentle proportional relationship. Moreover, it is suggested to plan the new bus line over 10 km in terms of reducing electricity consumption per kilometre.",smart cities
10.1016/j.asej.2020.07.001,Journal,Ain Shams Engineering Journal,scopus,2021-03-01,sciencedirect,Evolutionary multi-objective network optimization algorithm in trajectory planning,https://api.elsevier.com/content/abstract/scopus_id/85088971459,"Flight network optimization, one of the airspace planning challenges, effectively manages airspace resources toward increasing airspace capacity and reducing air traffic congestion. In this paper, the structure of the air transport network is analyzed with a multi-objective genetic algorithm to reduce the number of airways and to aggregate the passengers and also to reduce route changes and the travel time fortravelers. The proposed topology model of this study is based on the combination of two topologies – point-to-point and hub-and-spoke – with multiple goals for decreasing in airways and travel length per passenger and also to reach the minimum number of air stops per passenger. Four state-of-the-art Multi-objective Genetic Algorithms (MOGAs) are considered for comparison studies and are tested and assessed in data of the Iran airline industry in 2018, as an experiment to real-world applications. Using the combination of point-to-point and hub-and-spoke topologies can improve the performance of the MOGA to solve a network-wide flight trajectory planning. Based on Iran airline traffic patterns in 2018, the proposed model successfully decreased 50.8% of air routes (184 air routes) compared to the current situations while the average travel length and the average changes in routes were increased up to 13.8% (about 100 km) and up to 18%, respectively. The proposed model also suggests that the current air routes of Iran can be decreased to 24.7% (89 airways) if the travel length and the number of changes increase up to 4.5% (32 km) and 5%, respectively. The simulation results show the potential benefits of the proposed model and the advantages of it. Optimizing the structure of the flight network can significantly reduce operational cost while ensuring the operation safety. According to the results, the multi-objective optimization model is successfully able to precisely design the efficiently optimized airline topologies.",smart cities
10.1016/j.patter.2020.100195,Journal,Patterns,scopus,2021-02-12,sciencedirect,Topic classification of electric vehicle consumer experiences with transformer-based deep learning,https://api.elsevier.com/content/abstract/scopus_id/85100638713,"The transportation sector is a major contributor to greenhouse gas (GHG) emissions and is a driver of adverse health effects globally. Increasingly, government policies have promoted the adoption of electric vehicles (EVs) as a solution to mitigate GHG emissions. However, government analysts have failed to fully utilize consumer data in decisions related to charging infrastructure. This is because a large share of EV data is unstructured text, which presents challenges for data discovery. In this article, we deploy advances in transformer-based deep learning to discover topics of attention in a nationally representative sample of user reviews. We report classification accuracies greater than 91% (F1 scores of 0.83), outperforming previously leading algorithms in this domain. We describe applications of these deep learning models for public policy analysis and large-scale implementation. This capability can boost intelligence for the EV charging market, which is expected to grow to US$27.6 billion by 2027.",smart cities
10.1016/j.measurement.2020.108779,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-02-01,sciencedirect,A SVM-based framework for fault detection in high-speed trains,https://api.elsevier.com/content/abstract/scopus_id/85098707682,"High-Speed Trains (HSTs) demand high reliability, maintainability and availability of their installed equipment. The braking system, in particular, is a safety-critical system in HSTs. Accurately and efficiently detecting any ongoing faults in such a system is very important to ensure safety, facilitate maintenance and reduce downtime of HSTs. Data-driven approaches have become very popular for fault detection with the implemented built-in monitoring systems and the artificial intelligence. Due to the high reliability of the HSTs, most of the monitoring data are on the normal conditions and only a small part concerns the faulty conditions. Such imbalanced data may reduce the fault detection rate of a data-driven model. Along with the between-class imbalance problem, the fusion of various continuous and discrete signals is also an obstacle in building an efficient fault detection model. In this paper, the weighted-feature strategy and the cost-sensitive learning are integrated effectively in a multi-kernel support vector machine model, to solve the problems brought by between-class imbalance and heterogeneous signals. The experiments on real datasets concerning faults in braking systems of a HST and fourteen public imbalanced datasets are carried out to verify the effectiveness and generalizability of the proposed method. With respect to both F-measure and G-mean, the proposed method outperforms the benchmark methods in the experiments, showing the potential of the combination of weighted feature strategy, multiple kernel learning and support vector machine in fault detection.",smart cities
10.1016/j.imavis.2020.104095,Journal,Image and Vision Computing,scopus,2021-02-01,sciencedirect,"A Survey on Object Detection for the Internet of Multimedia Things (IoMT) using Deep Learning and Event-based Middleware: Approaches, Challenges, and Future Directions",https://api.elsevier.com/content/abstract/scopus_id/85098694350,"An enormous amount of sensing devices (scalar or multimedia) collect and generate information (in the form of events) over the Internet of Things (IoT). Present research on IoT mainly focus on the processing of scalar sensor data events and barely considers the challenges posed by multimedia based events. In this paper, we systematically review the existing solutions available for the Internet of Multimedia Things (IoMT) by analyzing sensing, networking, service, and application-level services provided by IoT. We present state-of-the-art event-based middleware methods and their suitability for multimedia event processing methods. We observe that existing IoT event-based middleware solutions focus on structured (scalar) events and possess only domain-specific characteristics for unstructured (multimedia) events. A case study for object detection is also presented to demonstrate the requirements associated with the processing of multimedia events within smart cities, even with common image recognition based applications. In order to validate the existing issues in the detection of objects, we also presented an evaluation of object detection models using existing datasets. At the end of each section, we shed light on trends, gaps, and possible solutions based on our analysis, experiments, and review of the existing research. Finally, we summarize the challenges and future research directions for the generalized multimedia event processing (by taking detection of each and every object as an example) based on applications using IoMT. Our experiments demonstrate that existing models are very slow to respond to any unseen class, and existing rich datasets do not have a sufficient number of classes to meet the requirements of real-time applications of smart cities. We show that although there is a significantly large technical literature on IoT, and research on IoMT is also quite actively growing, there have not been much research efforts directed towards the processing of multimedia events. As an example, although deep learning techniques have been shown to achieve impressive performance in applications like image recognition, the methods are deficient in detecting new (previously unseen) objects for multimedia based applications in smart cities. In light of these facts, it becomes imperative to conduct research on bringing together the abilities of event-based middleware for IoMT, and low response-time based online training and adaptation techniques.",smart cities
10.1016/j.cageo.2020.104642,Journal,Computers and Geosciences,scopus,2021-02-01,sciencedirect,Real-time water level monitoring using live cameras and computer vision techniques,https://api.elsevier.com/content/abstract/scopus_id/85098225043,"Characterizing urban hydrographs during rain storms, hurricanes, and river floods is important to decrease loss of lives and assist emergency responders with mapping disruptions to operation of major cities. High water marks, stream gages, and rapidly deployed instrumentation are the current state-of-practice for hydrological data during a flood event. The objective of this study was to develop technology that can provide accurate and timely flood hydrographs while harnessing the Big Data generated from videos and images. In particular, levels are predicted from images by using reference objects as a scale. The novelty of this work involved leveraging object-based image analysis (OBIA), which used image segmentation training algorithms to differentiate areas of images or videos. In particular, the deep learning-based semantic segmentation technique was trained using images from an MIT database along with images compiled from traffic cameras and the experiments and a case study. The fully convolutional network was used for image segmentation and subsequent object labeling. This algorithm was applied to a laboratory and two field experiments before demonstration at Buffalo Bayou in Houston, TX during Hurricane Harvey. The laboratory and field experiments indicated that the image segmentation technique was reproducible and accurate from a controlled environment to rain storms and localized flooding in small streams on the LSU campus. Moreover, the segmentation algorithm successfully estimated flood levels in Buffalo Bayou in downtown Houston, Texas during Hurricane Harvey. This signifies that if time-lapse imagery is available, this algorithm- and program-estimated water elevations can provide insight to the hydrograph and spatial inundation during flooding from rainstorms or hurricanes.",smart cities
10.1016/j.gaitpost.2020.11.014,Journal,Gait and Posture,scopus,2021-02-01,sciencedirect,EEG differentiates left and right imagined Lower Limb movement,https://api.elsevier.com/content/abstract/scopus_id/85097772977,"Background
                  Identifying which EEG signals distinguish left from right leg movements in imagined lower limb movement is crucial to building an effective and efficient brain-computer interface (BCI). Past findings on this issue have been mixed, partly due to the difficulty in collecting and isolating the relevant information. The purpose of this study was to contribute to this new and important literature.
               
                  Research Question
                  Can left versus right imagined stepping be differentiated using the alpha, beta, and gamma frequencies of EEG data at four electrodes (C1, C2, PO3, and PO4)?
               
                  Methods
                  An experiment was conducted with a sample of 16 healthy male participants. They imagined left and right lower limb movements across 60 trials at two time periods separated by one week. Participants were fitted with a 64-electrode headcap, lay supine on a specially designed device and then completed the imagined task while observing a customized computer-generated image of a human walking to signify the left and right steps, respectively.
               
                  Results
                  Findings showed that eight of the twelve frequency bands from 4 EEG electrodes were significant in differentiating imagined left from right lower limb movement. Using these data points, a neural network analysis resulted in an overall participant average test classification accuracy of left versus right movements at 63 %.
               
                  Significance
                  Our study provides support for using the alpha, beta and gamma frequency bands at the sensorimotor areas (C1 and C2 electrodes) and incorporating information from the parietal/occipital lobes (PO3 and PO4 electrodes) for focused, real-time EEG signal processing to assist in creating a BCI for those with lower limb compromised mobility.",smart cities
10.1016/j.micpro.2020.103621,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Optimal logistics transportation and route planning based on fpga processor real-time system and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85097714099,"The shared bus's development requirements, relief of traffic congestion in urban areas, and improved utilization of the road resources providing the transport mode of the excellent user experience neotype are very urgent. To predict precise travel needs, the key for planning a dynamic routing lie a lie of the shared bus implementation. However, the shared bus data's sparse and high volatility will require a lot of resistance to predict travel accurately. Based on the user experience, very different from the traditional public transportation that is far more challenging to the relatively high number of optimization goals is because passengers of the shared bus route planning and shared bus route planning. This article, based on the shared bus data from different audiences sources, travel demand prediction and dynamic route planning in ""the last mile"", and a two-step process that consists of the shared bus dynamic routing (sub-bus), proposed and your scene. First of all, such traffic, time, week, location, and five of the prediction function such as a bus, to analyze residents' travel behavior to prepare the travel demand based on them precisely the machine learning model used to predict. Secondly, dynamically and predict the results of multiple operations bus optimal routing, designed to generate a fixed based on the shared bus destinations' operating characteristics, a dynamic programming algorithm wants below. Several experiments, based on the shared subway shuttle bus of evidence that people of the data and the reality has been purchased, the sub-bus is better than the method of dynamic route planning, etc. for the scene of such a ""last mile"".",smart cities
10.1016/j.ocecoaman.2020.105478,Journal,Ocean and Coastal Management,scopus,2021-02-01,sciencedirect,Autonomous litter surveying and human activity monitoring for governance intelligence in coastal eco-cyber-physical systems,https://api.elsevier.com/content/abstract/scopus_id/85097580928,"The human impact on the coastal ecosystems is a global environmental concern. Due to the growing urbanization, industrialization, and transportation, this impact on the living and non-living components of the coastal area is expected to further increase in the coming years. Artificial intelligence based automation of the coastal monitoring, including data collection, analysis and decision making, provides real-time insights and opportunities for large-scale coastal management and governance. In this paper, a framework for autonomous litter surveying and human activity monitoring for governance intelligence in coastal eco-cyber-physical systems (ecoCystem) is presented. A large dataset of more than 20,000 images focused on smart coastal management is collected to model the real world scenarios. A combination of various artificial intelligence based methods are used for automatic detection and classification of various litter in the coastal environment. Furthermore, the proposed framework is capable of autonomous monitoring of humans activities and detection of illegal entry of vehicles and boats to the beach area. The accuracy of the proposed autonomous system is 87% for correct classification of fully visible litter and 95% for fully visible vehicles. The experimental results show that the application of computer vision and machine learning for autonomous litter classification shows promising results for increasing the speed and scale of litter surveying in the coastal area. Further training of the artificial intelligence models is necessary for increasing the accuracy of the proposed framework and real-world deployment in the coastal environment. The proposed human activity monitoring system can be used for autonomous coastal law enforcement and real-time and active protection of the coastal zones.",smart cities
10.1016/j.tranpol.2020.11.008,Journal,Transport Policy,scopus,2021-02-01,sciencedirect,Predicting weather-induced delays of high-speed rail and aviation in China,https://api.elsevier.com/content/abstract/scopus_id/85096997005,"High-speed rail (HSR) has become a competitive mode with aviation for medium-distance intercity travel, given the massive deployment of the HSR infrastructure network in China. While the travel experience with both HSR and air has become more convenient, the systems’ operational reliability in terms of punctuality remains a key concern, especially during disruptive events, such as under severe weather conditions. Although previous studies have attempted to investigate the impact of severe weather events on the operational performance of transportation systems, there is still a lack of ability to forecast to what extent the performance of different transportation systems may vary under various conditions. This study develops an integrated modeling framework that allows us to predict the performance of weather-induced delays of different transportation systems, including HSR and aviation. By applying machine-learning methods to real-world transportation performance data, the study examines the robustness of the method, variations of data characteristics and the different applications of the predictive modeling system. Overall, the concept and modeling framework provide important implications for the improvement of transportation system resilience to various severe weather-related disruptions through the understanding of the impact and its predictability of the system performance.",smart cities
10.1016/j.micpro.2020.103301,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,IoT enabled cancer prediction system to enhance the authentication and security using cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85094168107,"In recent days, Internet of Things, Cloud Computing, Deep learning, Machine learning and Artificial Intelligence are considered to be an emerging technologies to solve variety of real world problems. These techniques are importantly applied in various fields such as healthcare systems, transportation systems, agriculture and smart cities to produce fruitful results for number of issues in today's environment. This research work focuses on one such application in the field of IoT together with cloud computing. More number of sensors that are deployed in human body is used to collect patient related data such as deviation in body temperature and others which leads to variation in blood cells that turned to be cancerous cells. Main intention of this work is design a cancer prediction system using Internet of Things upon extracting the details of blood results to test whether it is normal or abnormal. In addition to this, encryption is done on the blood results of cancer affected patient and store it in cloud for quick reference through Internet for the doctor or healthcare nurse to handle the patient data secretly. This research work concentrates on enhancing the health care computations and processing. It provides a framework to enhance the performance of the existing health care industry across the globe. As the entire medical data has to be saved in cloud, the traditional medical treatment limitations can be overcome. Encryption and decryption is done using AES algorithm in order to provide authentication and security in handling cancer patients. The main focus is to handle healthcare data effectively for the patient when they are away from the home town since the needed cancer treatment details are stored in cloud. The task completion time is greatly reduce from 400 to 160  by using VMs. CloudSim gives an adaptable simulation structure that empowers displaying and reproduced results.",smart cities
10.1016/j.asoc.2020.106753,Journal,Applied Soft Computing,scopus,2021-02-01,sciencedirect,A comparative study of swarm intelligence and evolutionary algorithms on urban land readjustment problem,https://api.elsevier.com/content/abstract/scopus_id/85092012210,"Land Readjustment and redistribution (LR) is a land management tool that helps regular urban development with the contribution of landowners. The main purpose of LR is to transform irregularly developed land parcels into suitable forms. Since it is necessary to handle many criteria simultaneously to solve LR problems, classical mathematical methods can be insufficient due to time limitation. Since LR problems are similar to traveling salesman problems and typical scheduling problems in terms of structure, they are kinds of NP-hard problems in combinatorial optimization. Therefore, metaheuristic algorithms are used in order to solve NP-hard problems instead of classical methods. At first, in this study, an effective problem-specific objective function is proposed to address the main criteria of the problem. In addition, a map-based crossover operator and three different mutation operators are proposed for the LR, and then a hybrid approach is implemented by utilizing those operators together. Furthermore, since the optimal value of the problem handled in real world cannot be exactly estimated, a synthetic dataset is proposed as a benchmarking set in LR which makes the success of algorithms can be objectively evaluated. This dataset consists of 5 different problems according to number of parcel which are 20, 40, 60, 80 and 100. Each problem set consists of 4 sub-problems in terms of number of landowners per-parcel which are 1, 2, 3 and 4. Therefore, the dataset consists of 20 kinds of problems. In this study, artificial bee colony, particle swarm optimization, differential evolution, genetic and tree seed algorithm are used. In the experimental studies, five algorithms are set to run under equal conditions using the proposed synthetic dataset. When the acquired experimental results are examined, genetic algorithm seems to be the most effective algorithm in terms of both speed and performance. Although artificial bee colony has better results from genetic algorithm in a few problems, artificial bee colony is the second most successful algorithm after genetic algorithm in terms of performance. However, in terms of time, artificial bee colony is an algorithm nearly as successful as genetic algorithm. On the other hand, the results of differential evolution, particle swarm optimization and tree seed algorithms are similar to each other in terms of solution quality. In conclusion, the statistical tests clearly show that genetic algorithm is the most effective technique in solving LR problems in terms of speed, performance and robustness.",smart cities
10.1016/j.jid.2020.06.027,Journal,Journal of Investigative Dermatology,scopus,2021-02-01,sciencedirect,Label-Free Quantification of Pharmacokinetics in Skin with Stimulated Raman Scattering Microscopy and Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85090852929,"The treatment of inflammatory skin conditions relies on a deep understanding of how drugs and tissue behave and interact. Although numerous methods have been developed that aim to follow and quantify topical drug pharmacokinetics, these tools can come with limitations, assumptions, and trade-offs that do not allow for real-time tracking of drug flow and flux on the cellular level in situ. We have developed a quantitative imaging toolkit that makes use of stimulated Raman scattering microscopy and deep learning–based computational image analysis to quantify the uptake of specific drug molecules in skin without the need for labels. Analysis powered by trained convolutional neural networks precisely identified features such as cells, cell junctions, and cell types within skin to enable multifactorial analysis of skin pharmacokinetics. We imaged and quantified the flow and flux of small molecule drugs through the layers and structures of ex vivo nude mouse ear skin and extracted pharmacokinetic parameters through convolutional neural network–based image processing, including relative area under the curve accumulation, time of maximum drug concentration, and in situ partition ratios. This approach, which facilitates the direct observation and quantification of pharmacokinetics, can be used to glean mechanistic insight into underlying phenomena in skin pharmacokinetics.",smart cities
10.1016/j.neucom.2021.10.085,Journal,Neurocomputing,scopus,2021-01-01,sciencedirect,Streamlining advanced taxi assignment strategies based on legal analysis,https://api.elsevier.com/content/abstract/scopus_id/85119035737,"In recent years many novel applications have appeared that promote the provision of services and activities in a collaborative manner. The key idea behind such systems is to take advantage of idle or underused capacities of existing resources, in order to provide improved services that assist people in their daily tasks, with additional functionality, enhanced efficiency, and/or reduced cost. Particularly in the domain of urban transportation, many researchers have put forward novel ideas, which are then implemented and evaluated through prototypes that usually draw upon AI methods and tools. However, such proposals also bring up multiple non-technical issues that need to be identified and addressed adequately if such systems are ever meant to be applied to the real world. While, in practice, legal and ethical aspects related to such AI-based systems are seldomly considered in the beginning of the research and development process, we argue that they not only restrict design decisions, but can also help guiding them.
                  In this manuscript, we set out from a prototype of a taxi coordination service that mediates between individual (and autonomous) taxis and potential customers. After representing key aspects of its operation in a semi-structured manner, we analyse its viability from the viewpoint of current legal restrictions and constraints, so as to identify additional non-functional requirements as well as options to address them. Then, we go one step ahead, and actually modify the existing prototype to incorporate the previously identified recommendations. Performing experiments with this improved system helps us identify the most adequate option among several legally admissible alternatives.",smart cities
10.1016/j.aap.2021.106473,Journal,Accident Analysis and Prevention,scopus,2021-01-01,sciencedirect,Mining patterns of autonomous vehicle crashes involving vulnerable road users to understand the associated factors,https://api.elsevier.com/content/abstract/scopus_id/85118989110,"Autonomous or automated vehicles (AVs) have the potential to improve traffic safety by eliminating majority of human errors. As the interest in AV deployment increases, there is an increasing need to assess and understand the expected implications of AVs on traffic safety. Until recently, most of the literature has been based on either survey questionnaires, simulation analysis, virtual reality, or simulation to assess the safety benefits of AVs. Although few studies have used AV crash data, vulnerable road users (VRUs) have not been a topic of interest. Therefore, this study uses crash narratives from four-year (2017–2020) of AV crash data collected from California to explore the direct and indirect involvement of VRUs. The study applied text network and compared the text classification performance of four classifiers - Support Vector Machine (SVM), Naïve Bayes (NB), Random Forest (RF), and Neural Network (NN) and associated performance metrics to attain the objective. It was found that out of 252 crashes, VRUs were, directly and indirectly, involved in 23 and 12 crashes, respectively. Among VRUs, bicyclists and scooterists are more likely to be involved in the AV crashes directly, and bicyclists are likely to be at fault, while pedestrians appear more in the indirectly involvements. Further, crashes that involve VRUs indirectly are likely to occur when the AVs are in autonomous mode and are slightly involved minor damages on the rear bumper than the ones that directly involve VRUs. Additionally, feature importance from the best performing classifiers (RF and NN) revealed that crosswalks, intersections, traffic signals, movements of AVs (turning, slowing down, stopping) are the key predictors of the VRUs-AV related crashes. These findings can be helpful to AV operators and city planners.",smart cities
10.1016/j.matpr.2021.01.072,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Flash flood risk management modeling in indian cities using IoT based reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85116453644,"Each year, flash floods in India have affected life, infrastructure and the economy of the country and there is a need for a systemic model of real-time flash flood management. So, to mitigate these losses, we proposed a flash flood management model focused on reinforcement learning. Based on their severity, the flash flood data is collected and rewards are distributed and this data is compared to the data collected from smart IoT devices deployed in the region impacted by the flood. We allocate the state-based reward values once the comparison is completed. The evacuation of flash flood water through the contour of the flash flood is carried out. This bypass has gates at different points that mean that, depending on the incentives, the gates are opened to remove flash flood water. The proposed solution was evaluated to be a faster, more effective and more accurate real-time flash flood management method.",smart cities
10.1016/j.ifacol.2021.06.039,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-01-01,sciencedirect,Secure Multi-party Co-planning of Barge Departures,https://api.elsevier.com/content/abstract/scopus_id/85112704997,"Container transport requires real-time control and a high degree of cooperation to alleviate disturbances and perform smoothly without unnecessary environmental impact and monetary losses. The involved operators are, however, often reluctant to cooperate as they fear loosing valuable information and autonomy, eventually leading their clients to choose another (cooperating) operator. In this paper we propose a real-time co-planning method, called Secure Departure Learning that in real-time lets several truck operators indicate to a barge operator what departure schedules they prefer without revealing any sensitive information. The method uses Paillier encryption and a learning method inspired by Bayesian Optimization in a model predictive control framework. At frequent time intervals a number of potential barge schedules are communicated to the co-planning truck operators. They evaluate their operation cost for each schedule and communicate it to the barge operator encrypted using several public keys. The barge operator computes the encrypted total cost for each schedules, which hereafter is decrypted by several truck operators. The first action of the schedule that results in the lowest total cost is implemented in a model predictive control fashion. Simulated experiments on a realistic, Dutch transport network illustrate that Secure Departure Learning is a good alternative for replacing the current method in practice, where barge departures are scheduled ahead of time and only mode-decisions can be updated in real time. Secure Departure Learning offers a new perspective on cooperation at the operational level in freight transport where co-planning and information protection can go hand in hand.",smart cities
10.1016/j.jksuci.2021.07.020,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2021-01-01,sciencedirect,Intelligent transportation systems: A survey on modern hardware devices for the era of machine learning,https://api.elsevier.com/content/abstract/scopus_id/85112559600,"The increasing complexity of Intelligent Transportation Systems (ITS), that comprise a wide variety of applications and services, has imposed a necessity for high-performance Modern Hardware Devices (MHDs). The performance challenge has become more noticeable with the integration of Machine Learning (ML) techniques deployed in large-scale settings. ML has effectively supported the field of ITS by providing efficient and optimized solutions to problems that were otherwise tackled using traditional statistical and analytical approaches. Addressing the hardware deployment needs of ITS in the era of ML is a challenging problem that involves temporal, spatial, environmental, and economical factors. This survey reviews the recent literature of ML-driven ITS, in which MHDs were utilized, with a focus on performance indicators. A taxonomy is then synthesized, giving a complete representation of what the current capabilities of the surveyed ITS rely on in terms of ML techniques and technological infrastructure. To alleviate the difficulties faced in the non-trivial task of selecting suitable ML techniques and MHDs for an ITS with a specific complexity level, a performance evaluation framework is proposed. The presented survey sets the basis for developing suitable hardware, facilitating the integration of ML within ITS, and bridging the gap between research and real-world deployments.",smart cities
10.1016/j.ijtst.2021.06.003,Journal,International Journal of Transportation Science and Technology,scopus,2021-01-01,sciencedirect,Weather and surface condition detection based on road-side webcams: Application of pre-trained Convolutional Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85109031507,"Adverse weather has long been recognized as one of the major causes of motor vehicle crashes due to its negative impact on visibility and road surface. Providing drivers with real-time weather information is therefore extremely important to ensure safe driving in adverse weather. However, identification of road weather and surface conditions is a challenging task because it requires the deployment of expensive weather stations and often needs manual identification and/or verification. Most of the Department of Transportations (DOTs) in the U.S. have installed roadside webcams mostly for operational awareness. This study leveraged these easily accessible data sources to develop affordable automatic road weather and surface condition detection systems. The developed detection models are focused on three weather conditions; clear, light snow, and heavy snow; as well as three surface conditions: dry, snowy, wet/slushy. Several pre-trained Convolutional Neural Network (CNN) models, including AlexNet, GoogLeNet, and ResNet18, were applied with proper modification via transfer learning to achieve the classification tasks. The best performance was achieved using ResNet18 architecture with an unprecedented overall detection accuracy of 97% for weather detection and 99% for surface condition detection. The proposed study has the potential to provide more accurate and consistent weather information in real-time that can be made readily available to be used by road users and other transportation agencies. The proposed models could also be used to generate temporal and spatial variations of adverse weather for proper optimization of maintenance vehicles’ route and time.",smart cities
10.1016/j.jfoodeng.2021.110732,Journal,Journal of Food Engineering,scopus,2021-01-01,sciencedirect,A simplified modelling approach for predicting shrinkage and sensitive material properties during low temperature air drying of porous food materials,https://api.elsevier.com/content/abstract/scopus_id/85108981426,"Many food materials are dried to enhance shelf-life. Drying is an energy-intensive process, and accurate drying models could be used in real time process control of drying equipment to drive cost optimizations. However, most physics-based models suffer from two shortcomings: they require thermo-physical properties of the food materials to be known a priori, and they usually neglect material shrinkage due to moisture loss. In this work, we first develop a simplified physics-based transport model to predict temperatures and moisture content and corresponding spatial and temporal shrinkage during low temperature air drying process, where volumetric shrinkage is dominated by moisture loss. This model agrees well with experiments conducted by us (reported in this paper) as well as with those conducted by others (taken from the literature) on food samples. Further, using the validated modelling framework, we have developed an experimentally validated deep learning-based artificial neural network (ANN) model for properties' estimation. This ANN model is designed to estimate solid density, initial porosity, and initial water saturation of a given food material, using temperature and moisture data from a set of simple experiments with error less than 1%. Using these predicted parameters as input, the physics-based model can predict temperature and moisture for real-time drying to within 5% accuracy. The method proposed in this work could play an important role in industrial drying process optimisation and will find wide applications in the food processing industry.",smart cities
10.1016/j.adhoc.2021.102545,Journal,Ad Hoc Networks,scopus,2021-01-01,sciencedirect,Deep convolutional recurrent model for region recommendation with spatial and temporal contexts,https://api.elsevier.com/content/abstract/scopus_id/85107995105,"Spatiotemporal-aware region recommendation satisfies a user by providing an region of POIs (point-of-interests) that he/she may prefer. This recommendation is typically performed by analyzing the region mobility patterns of the user with some spatial and temporal contexts. This kind of recommendation can help, for example, a businessman to enjoy his urban life, or a tourist to travel in an unfamiliar area. In this study, we propose a deep-learning framework to model region-level mobility patterns of users, where personal and global user preferences across regions as well as spatiotemporal dependencies are comprehensively incorporated. To be specific, we model user preferences through a pyramidal Convolutional Long Short-Term Memory (ConvLSTM) component, and induce the dynamic region attributes through a recurrent component. By fusing two components to recommend next time region, our framework can tackle three complex challenges: (1) Modeling users’ distinctive spatio-temporal preferences over regions; (2) tracing diverse region mobility patterns of users over time; and (3) capturing the intrinsic correlations between regions. Extensive experiments on real-world datasets validate the effectiveness of the novel approach.",smart cities
10.1016/j.matpr.2021.02.348,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Predictive analytics of bridge safety for intelligent transportation system using ensemble model,https://api.elsevier.com/content/abstract/scopus_id/85107404137,"Bridges are the main links for many transportation systems. Many of the bridges built are subjected to deterioration but are still in use. Factors like heavy weights imposed by vehicles, pressure of water and depreciation effect the lifetime of the bridges. This may lead to various disasters endangering the lives of people. Hence continuous monitoring of bridges using real time bridge data is required to predict bridge safety and alert user passing by the bridge. Existing bridge safety monitoring systems are either Sensor based or uses specialized equipment to monitor safety using frequencies of vibration. Such systems are expensive and have low performance. Traditional prediction algorithms from data mining and regression modeling can help in correlation between input parameters and bridge condition using historical data. They have difficulty either in scaling of data or may not adapt to dynamic changes in input data. Mobile app based system that uses ensemble of both Artificial Neural Network (ANN) and Gaussian Process Regression (GPR) is proposed in this paper to predict bridge safety. This paper signifies on the structural health monitoring of the bridge and the potential advantage of integrating Artificial Intelligence based predictive analytics into IoT sensors to assess the bridge safety. Three different experiments based on ANN, GPR and ensemble of ANN,GPR are made. In the first step, ANN is trained and validated on two datasets with different scenario (Indian and U.S.A). Error reported from this best trained network is used by GPR for statistical analysis of the error distributions. This combined system based mobile app is evaluated using NRMSE, COD and cross entropy loss measures. Test results proved that, the third hyper-parameter values of ensemble model yielded a good result with less error rate than ANN and GPR predictive models.",smart cities
10.1016/j.procs.2021.03.066,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Safemobility: An IoT-Based system for safer mobility using machine learning in the age of COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85106733824,"In the face of the COVID-19 pandemic and the absence of a vaccine or an effective treatment against the virus, the available studies show that today, the most effective measure for prevention continues to be social distancing. In this sense, in this article, we focus implementing an IoT-based System for safer mobility in the age of COVID-19 using machine learning called SafeMobility. This system has been designed to monitor in real-time the social distancing between people and control the capacity in common interior spaces via a multilayer architecture that integrates IoT, fog, and cloud solutions. To control the capacity safely, we have detected the location of people using machine learning models. We have trained and evaluated these models from a data set containing the RSSI signals of the different surrounding WiFi networks obtained via a portable IoT device. Besides, this portable device integrated with a high precision laser sensor has also been used to detect the distance between people, thus avoiding potential infections. Also, we have exploited the advantages of fog computing to perform data processing and analysis in a fog node using the machine learning model that presented the highest accuracy in the evaluation. In case of non-compliance with the allowed social distance or the established peak capacity, alert messages are sent via a lightweight and optimal protocol in using IoT applications. A web application hosted on a cloud server receives the information from the fog node in real-time and dynamically displays the congestion sites in the environment. Our experiments demonstrate the effectiveness of the system to determine the position of the people with an accuracy of 91%.",smart cities
10.1016/j.isatra.2021.04.003,Journal,ISA Transactions,scopus,2021-01-01,sciencedirect,Automatic ship classification for a riverside monitoring system using a cascade of artificial intelligence techniques including penalties and rewards,https://api.elsevier.com/content/abstract/scopus_id/85104572124,"Riverside monitoring systems are used for controlling the passage of ships, counting them to prevent overcrowding in a port, or raising an alarm if the ship is unknown or not safe. This type of control and analysis is commonly carried out by many people who supervise CCTV in real time. In this paper, we present an alternative approach to automatic image analysis using a variety of artificial intelligence techniques. Based on collaborative learning, these are punished if they make an incorrect classification. The main advantage is the possibility of continually increasing the amount of knowledge during system operation. However, overtraining is possible, so each time, the best classifier is chosen. Another advantage for practical use is the small database, which allows for the quick and practical implementation of such a system. To verify its effectiveness, this ship classification system was tested on data obtained in a Polish city, Szczecin, as part of a bigger project for classifying inland ships and publicly available databases (for more general ship problems).",smart cities
10.1016/j.rsase.2020.100461,Journal,Remote Sensing Applications: Society and Environment,scopus,2021-01-01,sciencedirect,Integrating machine learning with Markov chain and cellular automata models for modelling urban land use change,https://api.elsevier.com/content/abstract/scopus_id/85098984348,"Modelling urban land use change is of profound concern to environmental scientists who have found cellular automata models very attractive for simulating urban dynamics. The quest for suitable predictive models to improve realistic simulation of urban land use change has resulted in the use of several notable cellular automata calibrations. Cellular automata model has become very attractive and one of the strongest models for urban growth simulation due to its simplicity and possibility of evolution. However, the inability of cellular automata to include driving forces of urban growth in the simulation process has warranted further cellular automata calibrations to minimize this weakness. To address this problem, and contrary to previous cellular automata calibrations, this research presents a novel integration of support vector machine, Markov chain and cellular automata for urban change modelling. Support vector machine is introduced as a machine learning technique to mine the impact of the explanatory variables that drive urban change. Markov chain is employed to mine the urban transition probabilities between the various urban epochs while cellular automata are used to implement the incremental discrete time steps based on neighbourhood interaction from an initial time to a future time. This modelling is implemented using Landsat data acquired in 1984, 2000 and 2015 over Lagos in Nigeria, Africa’s most populous city. Urban transitions (1984–2000 and 2000–2015) are used to simulate future urban state in 2030 and validation metrics include McNemar's test. The introduction of stochasticity into the model helps create the typical randomness inherent in the real world for deriving future urban forms through discrete cellular automata iterations. The high accuracy obtained in this experiment implies a substantial fit between the predicted and reference data. This outcome proves the robustness of this method for modelling urban change.",smart cities
10.1016/j.trc.2020.102917,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-01-01,sciencedirect,Classifying travelers' driving style using basic safety messages generated by connected vehicles: Application of unsupervised machine learning,https://api.elsevier.com/content/abstract/scopus_id/85097718764,"Driving style can substantially impact mobility, safety, energy consumption, and vehicle emissions. While a range of methods has been used in the past for driving style classification, the emergence of connected vehicles equipped with communication devices provides a new opportunity to classify driving style using high-resolution (10 Hz) microscopic real-world data. In this study, location-based big data and machine learning are used to classify driving styles ranging from aggressive to calm. This classification can be used to customize driver assistance systems, assess mobility, crash risk, fuel consumption, and emissions. This study’s main objective is to develop a framework that harnesses Basic Safety Messages (BSMs) generated by connected vehicles to quantify instantaneous driving behavior and classify driving styles in different spatial contexts using unsupervised machine learning methods. To this end, a subset of the Safety Pilot Model Deployment (SPMD) with more than 27 million BSM observations generated by more than 1300 individuals making trips on diverse roadways and through several neighborhoods in Ann Arbor, Michigan, were processed and analyzed. To quantify driving style, the concept of temporal driving volatility, as a surrogate safety measure of unsafe driving behavior, was utilized and applied to vehicle kinematics, i.e., observed speeds and longitudinal/lateral accelerations. Specifically, six volatility measures are extracted and used for classifying drivers. K-means and K-medoids methods are applied for grouping drivers in aggressive, normal, and calm clusters. Clustering results indicate that not only does driving style vary among drivers, but the thresholds for aggressive and calm driving vary across different roadway types due to variations in environment and road conditions. The proportion of aggressive driving styles was also higher on commercial streets than on highways and residential streets. Notably, we propose a Driving Score to measure driving performance consistently across drivers.",smart cities
10.1016/j.trc.2020.102858,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-01-01,sciencedirect,Predicting origin-destination ride-sourcing demand with a spatio-temporal encoder-decoder residual multi-graph convolutional network,https://api.elsevier.com/content/abstract/scopus_id/85097352081,"With the rapid development of mobile-internet technologies, on-demand ride-sourcing services have become increasingly popular and largely reshaped the way people travel. Demand prediction is one of the most fundamental components in supply-demand management systems of ride-sourcing platforms. With an accurate short-term prediction for origin-destination (OD) demand, the platforms make precise and timely decisions on real-time matching, idle vehicle reallocations, and ride-sharing vehicle routing, etc. Compared to the zone-based demand prediction that has been examined in many previous studies, OD-based demand prediction is more challenging. This is mainly due to the complicated spatial and temporal dependencies among the demand of different OD pairs. To overcome this challenge, we propose the Spatio-Temporal Encoder-Decoder Residual Multi-Graph Convolutional network (ST-ED-RMGC), a novel deep learning model for predicting ride-sourcing demand of various OD pairs. Firstly, the model constructs OD graphs, which utilize adjacent matrices to characterize the non-Euclidean pair-wise geographical and semantic correlations among different OD pairs. Secondly, based on the constructed graphs, a residual multi-graph convolutional (RMGC) network is designed to encode the contextual-aware spatial dependencies, and a long-short term memory (LSTM) network is used to encode the temporal dependencies, into a dense vector space. Finally, we reuse the RMGC networks to decode the compressed vector back to OD graphs and predict the future OD demand. Through extensive experiments on the for-hire-vehicles datasets in Manhattan, New York City, we show that our proposed deep learning framework outperforms the state-of-arts by a significant margin.",smart cities
10.1016/j.trc.2020.102851,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-01-01,sciencedirect,DNEAT: A novel dynamic node-edge attention network for origin-destination demand prediction,https://api.elsevier.com/content/abstract/scopus_id/85097168126,"The ride-hailing service platforms have grown tremendously around the world and attracted a wide range of research interests. A key to ride-hailing service platforms is how to realize accurate and reliable demand prediction. However, most of the existing studies focus on the region-level demand prediction while only a few attempts to address the problem of origin–destination (OD) demand prediction. In this paper, from the graph aspects, we construct the dynamic OD graphs to describe the ride-hailing demand data. We propose a novel neural architecture named the Dynamic Node-Edge Attention Network (DNEAT) to address the unique challenges of OD demand prediction from the demand generation and attraction perspectives. Different from previous studies, in DNEAT, we develop a new neural layer, named k-hop temporal node-edge attention layer (
                        k
                     -TNEAT), to capture the temporal evolution of node topologies in dynamic OD graphs instead of the pre-defined relationships among regions. We evaluate our model on two real-world ride-hailing demand datasets (from Chengdu, China, and New York City). The experiment results show that the proposed model outperforms six baseline models and is more robust to demand data with high sparsity.",smart cities
10.1016/j.scs.2020.102582,Journal,Sustainable Cities and Society,scopus,2021-01-01,sciencedirect,Towards the sustainable development of smart cities through mass video surveillance: A response to the COVID-19 pandemic,https://api.elsevier.com/content/abstract/scopus_id/85096158767,"Sustainable smart city initiatives around the world have recently had great impact on the lives of citizens and brought significant changes to society. More precisely, data-driven smart applications that efficiently manage sparse resources are offering a futuristic vision of smart, efficient, and secure city operations. However, the ongoing COVID-19 pandemic has revealed the limitations of existing smart city deployment; hence; the development of systems and architectures capable of providing fast and effective mechanisms to limit further spread of the virus has become paramount. An active surveillance system capable of monitoring and enforcing social distancing between people can effectively slow the spread of this deadly virus. In this paper, we propose a data-driven deep learning-based framework for the sustainable development of a smart city, offering a timely response to combat the COVID-19 pandemic through mass video surveillance. To implementing social distancing monitoring, we used three deep learning-based real-time object detection models for the detection of people in videos captured with a monocular camera. We validated the performance of our system using a real-world video surveillance dataset for effective deployment.",smart cities
10.1016/j.cmpb.2020.105786,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-01-01,sciencedirect,Machine-Learning based model order reduction of a biomechanical model of the human tongue,https://api.elsevier.com/content/abstract/scopus_id/85092376686,"Background and Objectives: This paper presents the results of a Machine-Learning based Model Order Reduction (MOR) method applied to a complex 3D Finite Element (FE) biomechanical model of the human tongue, in order to create a Digital Twin Model (DTM) that enables real-time simulations. The DTM is designed for future inclusion in a computer assisted protocol for tongue surgery planning.
                  
                     Methods: The proposed method uses an “a posteriori” MOR that allows, from a limited number of simulations with the FE model, to predict in real time mechanical responses of the human tongue to muscle activations.
                  
                     Results: The MOR method is evaluated for simulations associated with separate single tongue muscle activations. It is shown to be able to account with a sub-millimetric spatial accuracy for the non-linear dynamical behavior of the tongue model observed in these simulations.
                  
                     Conclusion: Further evaluations of the MOR method will include tongue movements induced by multiple muscle activations. At this stage our MOR method offers promising perspectives for the use of the tongue model in a clinical context to predict the impact of tongue surgery on tongue mobility. As a long term application, this DTM of the tongue could be used to predict the functional consequences of the surgery in terms of speech production and swallowing.",smart cities
10.1016/j.envres.2020.110141,Journal,Environmental Research,scopus,2021-01-01,sciencedirect,Assessing personal exposure using Agent Based Modelling informed by sensors technology,https://api.elsevier.com/content/abstract/scopus_id/85092078286,"Technology innovations create possibilities to capture exposure-related data at a great depth and breadth. Considering, though, the substantial hurdles involved in collecting individual data for whole populations, this study introduces a first approach of simulating human movement and interaction behaviour, using Agent Based Modelling (ABM).
                  A city scale ABM was developed for urban Thessaloniki, Greece that feeds into population-based exposure assessment without imposing prior bias, basing its estimations onto emerging properties of the behaviour of the computerised autonomous decision makers (agents) that compose the city-system. Population statistics, road and buildings networks data were transformed into human, road and building agents, respectively. Survey outputs with time-use patterns were associated with human agent rules, aiming to model representative to real-world behaviours. Moreover, time-geography of exposure data, derived from a local sensors campaign, was used to inform and enhance the model. As a prevalence of an agent-specific decision-making, virtual individuals of different sociodemographic backgrounds express different spatiotemporal behaviours and their trajectories are coupled with spatially resolved pollution levels.
                  Personal exposure was evaluated by assigning PM concentrations to human agents based on coordinates, type of location and intensity of encountered activities. Study results indicated that PM2.5 inhalation adjusted exposure between housemates can differ by 56.5% whereas exposure between two neighbours can vary by as much as 87%, due to the prevalence of different behaviours.
                  This study provides details of a new methodology that permits the cost-effective construction of refined time-activity diaries and daily exposure profiles, taking into account different microenvironments and sociodemographic characteristics. The proposed method leads to a refined exposure assessment model, addressing effectively vulnerable subgroups of population. It can be used for evaluating the probable impacts of different public health policies prior to implementation reducing, therefore, the time and expense required to identify efficient measures.",smart cities
10.1016/j.apenergy.2020.116001,Journal,Applied Energy,scopus,2020-12-15,sciencedirect,Velocity prediction and profile optimization based real-time energy management strategy for Plug-in hybrid electric buses,https://api.elsevier.com/content/abstract/scopus_id/85093645311,"The Plug-in hybrid vehicle (PHEV) has been progressively penetrated in the urban public transport system and seen a foreseeable fast growth in the future. Within this horizon, energy management is an enabling technique for the cost-efficient operation of the PHEV. In this paper, a model predictive control (MPC)-based real-time energy management strategy (EMS) combining a cloud-enabled velocity profile optimizer (VPO) and vehicle-side velocity predictor is proposed for the Plug-in hybrid bus (PHEB) under the intelligent transportation systems (ITS). Particularly, the velocity profile and the state of charge (SOC) sequences are optimized by incorporating the genetic algorithm (GA) with the dynamic programming (DP), giving rise to a novel GA-DP-based VPO. In the case that the vehicle can be hardly decoupled from the traffic flow, a multi-feature predictor based on Long Short Term Memory (LSTM) Network is triggered to replace the cloud-enabled VPO to predict the short-term velocity. Results show that the prediction accuracy can be improved by 5.4% by employing the multi-feature training. The equivalent fuel consumption with the mode-switching EMS in the optimized UDDS cycle can be reduced by 14.9% compared with the state of the art. The proposed strategy is validated with a real-time performance by performing the hardware in the loop (HIL) experiment.",smart cities
10.1016/j.comnet.2020.107573,Journal,Computer Networks,scopus,2020-12-09,sciencedirect,AI-enabled mobile multimedia service instance placement scheme in mobile edge computing,https://api.elsevier.com/content/abstract/scopus_id/85091771160,"Leveraging cloud infrastructure to the mobile edge computing helps the mobile users to get real time multimedia services in Fifth Generation (5G) network system. To ensure higher Quality-of-Experience (QoE), faster migration of mobile multimedia service instances is required to cope up with user mobility. By deploying the mobile multimedia service instances proactively in multiple edge nodes (ENs) helps the users to get higher QoE. However, excessive deployment of service replicas might increase the cost of the overall network. To establish trade-off between these two conflicting objectives, we have formulated the problem as a Multi-objective Integer Linear Programming (MILP) by integrating the users’ path prediction model. This problem is proven to be an NP-hard one for large networks, thus we develop an artificial intelligence (AI) based meta-heuristic Binary Particle Swarm Optimization (BPSO) algorithm to achieve near-optimal solution within polynomial time. The performance analysis results show the significant performance improvement in terms of QoE and user satisfaction as compared to other state-of-the-art works.",smart cities
10.1016/j.iot.2020.100301,Journal,Internet of Things (Netherlands),scopus,2020-12-01,sciencedirect,Predicting parking occupancy via machine learning in the web of things,https://api.elsevier.com/content/abstract/scopus_id/85098729769,"The Web of Things (WoT) enables information gathered by sensors deployed in urban environments to be easily shared utilizing open Web standards and semantic technologies, creating easier integration with other Web-based information, towards advanced knowledge. Besides WoT, an essential aspect of understanding dynamic urban systems is artificial intelligence (AI). Via AI, data produced by WoT-enabled sensory observations can be analyzed and transformed into meaningful information, which describes and predicts current and future situations in time and space. This paper examines the impact of WoT and AI in smart cities, considering a real-world problem, the one of predicting parking availability. Traffic cameras are used as WoT sensors, together with weather forecasting Web services. Machine learning (ML) is employed for AI analysis, using predictive models based on neural networks and random forests. The performance of the ML models for the prediction of parking occupancy is better than the state of the art work in the problem under study, scoring an MSE of 7.18 at a time horizon of 60 minutes.",smart cities
10.1016/j.trc.2020.102877,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-12-01,sciencedirect,Congestion recognition for hybrid urban road systems via digraph convolutional network,https://api.elsevier.com/content/abstract/scopus_id/85096833013,"Congestion recognition is the prerequisite for traffic control and management, vehicle routing, and many other applications in intelligent transportation systems. Different types of roads with traffic facilities provide multi-source heterogeneous field traffic data, which contain the fundamental information and distinct features for congestion recognition. To exploit these traffic big data, in this paper, we propose a machine learning-based framework to tackle the congestion recognition problem. It can be divided in two parts, a digraph-based representation for hybrid urban traffic network and a Dirgraph Convolutional Neural Network (DGCN)-based learning model. At first, the representation incorporates the fundamental traffic variables with the correlation of different traffic flows, and partially decouples the global network topology from local traffic information. And then, to proceed with digraph-based samples, a new type of graph feature extraction method is introduced and the graph Fourier transform is defined accordingly. This distinguishes the proposed model from the conventional graph convolutional networks. Comprehensive experiments are conducted based on real traffic data. The results demonstrate the advantages of the proposed framework over the existing congestion recognition methods.",smart cities
10.1016/j.eng.2020.07.020,Journal,Engineering,scopus,2020-12-01,sciencedirect,Tall Buildings with Dynamic Facade Under Winds,https://api.elsevier.com/content/abstract/scopus_id/85092929162,"Burgeoning growth of tall buildings in urban areas around the world is placing new demands on their performance under winds. This involves selection of the building form that minimizes wind loads and structural topologies that efficiently transfer loads. Current practice is to search for optimal shapes, but this limits buildings with static or fixed form. Aerodynamic shape tailoring that consists of modifying the external form of the building has shown great promise in reducing wind loads and associated structural motions as reflected in the design of Taipei 101 and Burj Khalifa. In these buildings, corner modifications of the cross-section and tapering along the height are introduced. An appealing alternative is to design a building that can adapt its form to the changing complex wind environment in urban areas with clusters of tall buildings, i.e., by implementing a dynamic facade. To leap beyond the static shape optimization, autonomous dynamic morphing of the building shape is advanced in this study, which is implemented through a cyber–physical system that fuses together sensing, computing, actuating, and engineering informatics. This approach will permit a building to intelligently morph its profile to minimize the source of dynamic wind load excitation, and holds the promise of revolutionizing tall buildings from conventional static to dynamic facades by taking advantage of the burgeoning advances in computational design.",smart cities
10.1016/j.robot.2020.103652,Journal,Robotics and Autonomous Systems,scopus,2020-12-01,sciencedirect,Self-awareness in intelligent vehicles: Feature based dynamic Bayesian models for abnormality detection,https://api.elsevier.com/content/abstract/scopus_id/85092022930,"The evolution of Intelligent Transportation Systems in recent times necessitates the development of self-awareness in agents. Before the intensive use of Machine Learning, the detection of abnormalities was manually programmed by checking every variable and creating huge nested conditions that are very difficult to track. This paper aims to introduce a novel method to develop self-awareness in autonomous vehicles that mainly focuses on detecting abnormal situations around the considered agents. Multi-sensory time-series data from the vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN) models used for future state prediction and the detection of dynamic abnormalities. Moreover, an initial level collective awareness model that can perform joint anomaly detection in co-operative tasks is proposed.
                  The GNG algorithm learns the DBN models’ discrete node variables; probabilistic transition links connect the node variables. A Markov Jump Particle Filter (MJPF) is applied to predict future states and detect when the vehicle is potentially misbehaving using learned DBNs as filter parameters.
                  In this paper, datasets from real experiments of autonomous vehicles performing various tasks used to learn and test a set of switching DBN models.",smart cities
10.1016/j.arr.2020.101174,Journal,Ageing Research Reviews,scopus,2020-12-01,sciencedirect,"A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",https://api.elsevier.com/content/abstract/scopus_id/85091870837,"One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",smart cities
10.1016/j.autcon.2020.103354,Journal,Automation in Construction,scopus,2020-12-01,sciencedirect,Real-time online detection of trucks loading via genetic neural network,https://api.elsevier.com/content/abstract/scopus_id/85091689126,"This article focuses on real-time online detection of trucks loading via genetic neural network. Firstly, according to the state structure of the truck and the deployment of the sensor in the monitoring system, a mathematical model that magnetic sensors detecting the weight of the truck is established, it provides a theoretical basis for the calculation of the compensator deviation. Secondly, a feedback compensator for disturbance signals is designed by genetic neural network in the load monitoring system. Thirdly, the stability of the control system is analyzed by the Lyapunov stability theory. Fourthly, a real-time monitoring system is proposed for the loading of trucks. Finally, a complete experiment is processed to in-depth discussion and analysis. Field experiments showed that this scheme solves the problem of real-time load detection of trucks, it proposes a monitoring system for transportation in the construction industry.",smart cities
10.1016/j.jclepro.2020.122722,Journal,Journal of Cleaner Production,scopus,2020-12-01,sciencedirect,A PM<inf>2.5</inf> concentration prediction model based on multi-task deep learning for intensive air quality monitoring stations,https://api.elsevier.com/content/abstract/scopus_id/85088383286,"With the deployment and real-time monitoring of a large number of micro air quality monitoring stations, new application scenarios have been provided for the research of air quality prediction methods based on artificial intelligence. Integrating deep learning with multi-task learning, this paper proposes a hybrid model for air quality prediction to leverage data from intensive air quality monitoring stations. The proposed model consists of a shared layer, a task-specific layer, and a multi-loss joint optimization module. It is tested on three monitoring stations located in three different districts of Lanzhou City, China, for PM2.5 concentration prediction. The results show that: (1) When the number of convolutional layers of convolutional neural network in the shared layer and the number of gated recurrent unit layers in the task-specific layer exist in two layers, model performs the best, and its predictability of the optimization algorithm with early-stopping will be significantly improved. (2) Using the proposed model to predict PM2.5 concentration on horizon 
                        
                           t
                           +
                           1
                        
                     , the mean absolute error and root mean square error are 4.54 and 7.96, respectively, indicating better performance in intensive air quality prediction than previous models based on simple hybridization. (3) The predictive performance on different stations is different, and the proposed model performs better than other models when there are large fluctuations and sudden changes in the data. Overall, the proposed model has good temporal stability and generalization ability and provides a new method for air quality prediction in intensive air quality monitoring scenarios.",smart cities
10.1016/j.jns.2020.117081,Journal,Journal of the Neurological Sciences,scopus,2020-11-15,sciencedirect,New technologies and Amyotrophic Lateral Sclerosis – Which step forward rushed by the COVID-19 pandemic?,https://api.elsevier.com/content/abstract/scopus_id/85090005531,"Amyotrophic Lateral Sclerosis (ALS) is a fast-progressive neurodegenerative disease leading to progressive physical immobility with usually normal or mild cognitive and/or behavioural involvement. Many patients are relatively young, instructed, sensitive to new technologies, and professionally active when developing the first symptoms. Older patients usually require more time, encouragement, reinforcement and a closer support but, nevertheless, selecting user-friendly devices, provided earlier in the course of the disease, and engaging motivated carers may overcome many technological barriers. ALS may be considered a model for neurodegenerative diseases to further develop and test new technologies. From multidisciplinary teleconsults to telemonitoring of the respiratory function, telemedicine has the potentiality to embrace other fields, including nutrition, physical mobility, and the interaction with the environment. Brain-computer interfaces and eye tracking expanded the field of augmentative and alternative communication in ALS but their potentialities go beyond communication, to cognition and robotics. Virtual reality and different forms of artificial intelligence present further interesting possibilities that deserve to be investigated. COVID-19 pandemic is an unprecedented opportunity to speed up the development and implementation of new technologies in clinical practice, improving the daily living of both ALS patients and carers.
                  The present work reviews the current technologies for ALS patients already in place or being under evaluation with published publications, prompted by the COVID-19 pandemic.",smart cities
10.1016/j.neucom.2020.07.009,Journal,Neurocomputing,scopus,2020-11-06,sciencedirect,Short-term traffic flow prediction: From the perspective of traffic flow decomposition,https://api.elsevier.com/content/abstract/scopus_id/85088821587,"Some researchers treat traffic flow as an entirety while predicting short-term traffic flow. Through analyzing real-world traffic flow, we have found that urban traffic shows a stable changing process along with random disturbs. An alternative way is to decompose traffic flow into two components: periodicity and volatility. We propose a hybrid method named Time-Series Analysis and Supervised-Learning (TSA-SL) for short-term traffic flow prediction from the perspective of traffic flow decomposition. In the method, period traffic flow is modeled with a typical TSA method called Fourier Transform (FT), where periodic behaviors are described as the combination of sines and cosines. The volatility of the current location is determined by its surroundings, so spatial–temporal correlations are extracted as input features of SL. Then, three hybrid prediction models, including FT-SVR, FT-GBRT and FT-LSTM, are built with proposed TSA-SL. In the experiment, an Electronic Registration Identification (ERI) dataset including massive real-world individual trajectories is employed. Comparing with classical baseline models, our proposed TSA-SL method has certain superiority. Furthermore, we decompose traffic flow into different components in terms of traveling purposes and vehicle types. The experimental results show that our method performs better in predicting partial traffic flow than predicting all traffic flow.",smart cities
10.1016/j.jweia.2020.104320,Journal,Journal of Wind Engineering and Industrial Aerodynamics,scopus,2020-11-01,sciencedirect,"Emerging frontiers in wind engineering: Computing, stochastics, machine learning and beyond",https://api.elsevier.com/content/abstract/scopus_id/85092221687,"Over the last several decades, wind engineering a multi-disciplinary subject involving engineering meteorology, fluid dynamics, structural dynamics, structural engineering, probabilistic methods, and design has addressed the challenges posed by winds of synoptic and non-synoptic origins. Combined computational approaches and laboratory to full-scale experiments have enhanced our ability to design and construct wind-resistant structures that range from low-rise to supertall buildings, footbridges to super long-span bridges and, wind turbines on the ground and floating foundations and floating offshore drilling and production systems. During this period, we have seen extraordinary advances in experimental facilities, instrumentation and data acquisition and management. At the laboratory scale, new wind tunnels have emerged with added features like extra-wide cross-sections, from passive to active driving systems, from boundary layer to flow simulators with vortical flows mimicking non-synoptic winds features. While at full-scale, we have been able to use deployable sensing networks in the path of landfalling hurricanes/typhoons to monitoring in real-time the performance of tall buildings and long-span bridges during extreme wind events. Advanced technologies like aerial surveying using drones and satellite imagery have been employed to enhance the post-storm surveillance capabilities. These advances have enabled us to build a cadre of civil infrastructure that meets some of the challenges posed by the extreme winds. Yet there remain several frontiers that still need to be addressed for example the three “Nons,” the triple emerging fronts, i.e., non-stationarity, non-Gaussianity, non-linearity prevalent in the changing dynamic of winds prevailing in gust fronts, vortical and convective systems, rolls, meso-scale features and intermittent turbulence. In the face of these challenges, increasing heights, spans, and depths of structures exposed to these winds pose additional challenges as their performance becomes more sensitive to their dynamics, thus necessitating new tools and perspectives that go beyond customary analysis and modeling norms. Fortunately, amidst these challenges, there are new opportunities to complement our existing capabilities as the burgeoning growth in computational resources and parallel computational advances coupled with data analytics and AI-based schemes, e.g., machine learning hold the promise of expanding our modeling and simulation capacity far beyond our current conventional schemes offer. All these advances can be couched in a Generalized Wind Loading Chain to capture the three “Nons” by building upon the wind loading chain proposed by Davenport based on linear and stationary conditions. An example of the Gust Front Factor in this framework is an effective means for designing under non-synoptic winds. This paper expands on these new computational opportunities and ways to take advantage of their added capabilities to address emerging challenges in building a resilient and sustainable civil infrastructure and beyond to stability and safety of high-speed trains.",smart cities
10.1016/j.trc.2020.102787,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-11-01,sciencedirect,Prediction of rare feature combinations in population synthesis: Application of deep generative modelling,https://api.elsevier.com/content/abstract/scopus_id/85091974069,"Population synthesis is concerned with the generation of agents for agent-based modelling in many fields, such as economics, transportation, ecology and epidemiology. When the number of attributes describing the agents and/or their level of detail becomes large, survey data cannot densely support the joint distribution of the attributes in the population due to the curse of dimensionality. It leads to a situation where many attribute combinations are missing from the sample data while such combinations exist in the real population. In this case, it becomes essential to consider methods that are able to impute such missing information effectively. In this paper, we propose to use deep generative latent models. These models are able to learn a compressed representation of the data space, which when projected back to the original space, leads to an effective way of imputing information in the observed data space. Specifically, we employ the Wasserstein Generative Adversarial Network (WGAN) and the Variational Autoencoder (VAE) for a large-scale population synthesis application. The models are applied to a Danish travel survey with a feature-space of more than 60 variables and trained and tested using cross-validation. A new metric that applies to the evaluation of generative models in an unsupervised setting is proposed. It is based on the ability to generate diverse yet valid synthetic attribute combinations by comparing if the models can recover missing combinations (sampling zeros) while keeping truly impossible combinations (structural zeros) models at a minimum. For a low-dimensional experiment, the VAE, the marginal sampler and the fully random sampler generate 5%, 21% and 26% more structural zeros per sampling zero when compared to the WGAN. For a high dimensional case, these figures increase to 44%, 2217% and 170440% respectively. This research directly supports the development of agent-based systems and in particular cases where detailed socio-economic or geographical representations are required.",smart cities
10.1016/j.conengprac.2020.104630,Journal,Control Engineering Practice,scopus,2020-11-01,sciencedirect,Vision-based robust control framework based on deep reinforcement learning applied to autonomous ground vehicles,https://api.elsevier.com/content/abstract/scopus_id/85090751679,"Given the recent advances in computer vision, image processing and control systems, self-driving vehicles has been one of the most promising and challenging research topics nowadays. The design of vision-based robust controllers to keep an autonomous car in the center of the lane, despite uncertainties and disturbances, is still an ongoing challenge. This paper presents a hybrid control architecture that combines Deep Reinforcement Learning (DRL) and Robust Linear Quadratic Regulator (RLQR) for vision-based lateral control of an autonomous vehicle. Evolutionary estimation is used to model the vehicle uncertainties. For performance comparison, a DRL method and three other hybrid controllers are also evaluated. The inputs for each controller are real-time semantically segmented RGB camera images which serve as the basis to calculate continuous steering actions to keep the vehicle on the center of the lane with a constant velocity. Simulation results show that the proposed hybrid RLQR with evolutionary estimation of uncertainties architecture outperforms the other algorithms implemented. It presents lower tracking errors, smoother steering inputs, total collision avoidance and better generalization in new urban environments. Furthermore, it significantly decreases the required training time.",smart cities
10.1016/j.ijdrr.2020.101705,Journal,International Journal of Disaster Risk Reduction,scopus,2020-11-01,sciencedirect,Earthquake risk assessment using an integrated Fuzzy Analytic Hierarchy Process with Artificial Neural Networks based on GIS: A case study of Sanandaj in Iran,https://api.elsevier.com/content/abstract/scopus_id/85088025165,"Earthquakes are natural phenomena, which induce natural hazard that seriously threatens urban areas, despite significant advances in retrofitting urban buildings and enhancing the knowledge and ability of experts in natural disaster control. Iran is one of the most seismically active countries in the world. The purpose of this study was to evaluate and analyze the extent of earthquake vulnerability in relation to demographic, environmental, and physical criteria. An earthquake risk assessment (ERA) map was created by using a Fuzzy-Analytic Hierarchy Process coupled with an Artificial Neural Networks (FAHP-ANN) model generating five vulnerability classes. Combining the application of a FAHP-ANN with a geographic information system (GIS) enabled to assign weights to the layers of the earthquake vulnerability criteria. The model was applied to Sanandaj City in Iran, located in the seismically active Sanandaj-Sirjan zone which is frequently affected by devastating earthquakes. The Multilayer Perceptron (MLP) model was implemented in the IDRISI software and 250 points were validated for grades 0 and 1. The validation process revealed that the proposed model can produce an earthquake probability map with an accuracy of 95%. A comparison of the results attained by using a FAHP, AHP and MLP model shows that the hybrid FAHP-ANN model proved flexible and reliable when generating the ERA map. The FAHP-ANN model accurately identified the highest earthquake vulnerability in densely populated areas with dilapidated building infrastructure. The findings of this study are useful for decision makers with a scientific basis to develop earthquake risk management strategies.",smart cities
10.1016/j.measurement.2020.107847,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Under the background of healthy China: Regulating the analysis of hybrid machine learning in sports activities to control chronic diseases,https://api.elsevier.com/content/abstract/scopus_id/85086573801,"One of the most important concerns in human life is concentrating on health. Major threats to human life are chronic diseases such as cancer and diabetes. China government mainly focusing on understanding the progression and spreading of chronic diseases over the population for allocating medical resources and designing a strategy in healthcare. Various conventional methods have been used for fetching chronic disease indicators in large scale based on the population health. But they are costly, not time effective and less accuracy in prediction. But this paper used Hybrid Predicting Model designed by incorporating the main features of the Gaussian Mixture Method and Collaborating Topic Modelling to increase the prediction accuracy. The proposed HPM method experimented on human mobility pattern dataset collected from the various metropolitan area of China. From the dataset, HPM predicts the rate of chronic disease presence and relative activity. GMM obtain the health condition whereas CTM obtains the data sparsity. The proposed hybrid prediction method is implemented in MATLAB software and experimented. Form the obtained results and comparing with the other existing methods, it is identified that the HPM outperforms in terms of prediction accuracy. HPM is evaluated using real-time check-in and chronic disease dataset in China cities. The proposed HPM method obtained 0.09% of the value which is high than the other baseline methods. From the obtained MSE and value, it is well clear the proposed HPM outperforms than the baseline methods.",smart cities
10.1016/j.knosys.2020.106294,Journal,Knowledge-Based Systems,scopus,2020-10-28,sciencedirect,Predicting taxi demands via an attention-based convolutional recurrent neural network,https://api.elsevier.com/content/abstract/scopus_id/85088892538,"As a flexible public transportation in urban areas, taxis play an important role in providing comfortable and convenient services for passengers. Due to the existence of the imbalance between supply of drivers and demand of passengers, an accurate fine-grained taxi demand prediction in real time can help guide drivers to plan their routes and reduce the waiting time of passengers. Recently, several methods based on deep neural networks have been provided to predict taxi demands. However, these works are limited in properly incorporating multi-view features of taxi demands together, with considering the influences of context information. In this paper, we propose a convolutional recurrent network model for fine-grained taxi demand prediction. Local convolutional layers and gated recurrent units are employed in our model to extract multi-view spatial–temporal features of taxi demands. Moreover, a novel context-aware attention module is designed to incorporate the predictions of each region with considering its contextual information, which is our first attempt. We also conduct comprehensive experiments based on multiple real-world datasets in New York City and Chengdu. The experimental results show that our model outperforms state-of-the-art methods, and validate the usefulness of each module in our model.",smart cities
10.1016/j.neucom.2020.05.038,Journal,Neurocomputing,scopus,2020-10-28,sciencedirect,Dynamic spatial-temporal feature optimization with ERI big data for Short-term traffic flow prediction,https://api.elsevier.com/content/abstract/scopus_id/85087868524,"Accurate short-term traffic flow prediction is an important basis of intelligent transportation systems (ITS) such as transportation operations and urban planning applications. However, due to the lack of complete directly measured data on urban traffic flow, existing studies cannot adequately mine the dynamic spatial-temporal correlations characterizing traffic flows in urban road networks. Electronic registration identification (ERI), which is an emerging technology for uniquely identifying a vehicle, can help collect the travel records of all vehicles. This inspires us to employ ERI big data for traffic flow prediction. In this paper, we propose a dynamic spatial-temporal feature optimization method with ERI big data for short-term traffic flow prediction based on a gradient–boosted regression tree, called DSTO-GBRT. Firstly, the framework of DSTO-GBRT is built. Secondly, we analyze the dynamic spatial-temporal correlations among the current prediction point and upstream correlative points using the Pearson correlation coefficient (PCC). Thirdly, to eliminate the linear correlations among features, we exploit principal component analysis (PCA) to optimize the original training data and obtain optimized training data. In the experiment, real-world ERI big data from Chongqing are employed for the proposed DSTO-GBRT method. Compared with ST-GBRT, ARIMA, DSTO-BPNN and DSTO-SVM, the results demonstrate that DSTO-GBRT can provide timely and adaptive prediction even in rush hour, when traffic conditions change rapidly. Furthermore, compared with DSO-GBRT and DTO-GBRT, the results show that the proposed DSTO-GBRT method is more accurate.",smart cities
10.1016/j.jclepro.2020.121941,Journal,Journal of Cleaner Production,scopus,2020-10-20,sciencedirect,Artificial intelligence-enabled context-aware air quality prediction for smart cities,https://api.elsevier.com/content/abstract/scopus_id/85088373071,"Metropolitan areas around the world are experiencing a surge in air pollution levels due to different anthropogenic causes, making accurate air quality prediction a critical task for public health. Although many prediction systems have been researched and modelled, many of them have neglected the different effects that air pollution has on each individual citizen. Hence, we present a novel context prediction model that includes context-aware computing concepts to merge an accurate air pollution prediction algorithm (using Long Short-Term Memory Deep Neural Network) with information from both surrounding pollution sources (e.g., bushfire incidents, traffic volumes) and user’s health profile. This model is then integrated into a tool called My Air Quality Index (MyAQI), which is further implemented and evaluated in a real-life use case set up in Melbourne Urban Area (Victoria, Australia). Results obtained with MyAQI show both that (i) high precision levels are reached (90–96%) when forecasting air quality situations in four air quality monitoring stations, and (ii) the proposed model is highly adaptable to users’ individual health condition effects under the same airborne pollutant levels.",smart cities
10.1016/j.knosys.2020.106302,Journal,Knowledge-Based Systems,scopus,2020-10-12,sciencedirect,Spatio-temporal feature fusion for dynamic taxi route recommendation via deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85088663557,"Dynamic taxi route recommendation aims at recommending cruising routes to vacant taxis such that they can quickly find and pick up new passengers. Given citizens’ giant but unbalancing riding demand and the very limited taxis in a city, dynamic taxi route recommendation is essential for its ability to alleviate the waiting time of passengers and increase the earning of taxi drivers. Thus, in this paper we study the dynamic taxi route recommendation problem as a sequential decision-making problem and we design an effective two-step method to tackle it. First, we propose to consider and extract multiple real-time spatio-temporal features, which are related with the easiness degree of vacant taxis picking up new passengers. Second, we design an adaptive deep reinforcement learning method, which learns a carefully designed deep policy network to better fuse the extracted spatio-temporal features such that effective route recommendation can be done. Extensive experiments using real-world data from San Francisco and New York are conducted. Comparing with the state-of-the-arts, our method can increase at least 15.8% of average earning for taxi drivers and reduce at least 29.6% of average waiting time for passengers.",smart cities
10.1016/j.knosys.2020.106256,Journal,Knowledge-Based Systems,scopus,2020-10-12,sciencedirect,Community detection based on the Matthew effect,https://api.elsevier.com/content/abstract/scopus_id/85088031223,"Community structure exists in most real-world networks, such as social networks, smart grids, and transportation networks. Established approaches for community detection usually depend on some user-defined criteria (e.g., minimum cut, normalized cut, modularity, etc.). These criteria-based methods usually involve some optimization procedures and need to specify some parameters, which are thus time consuming and sensitive to parameters. In this paper, inspired by the Mathew effect of human society, we view a network as a social system and design a new algorithm called CDME (community detection based on the Matthew effect). Relying on the new concept, CDME has many desirable properties. It allows uncovering high-quality communities driven by dynamic CDME is also parameter free. More importantly, since CDME works in a local way and only needs to calculate the attractiveness of neighboring nodes, which lend itself to handling large-scale networks. Experiments on both synthetic and real-world data sets have demonstrated that CDME has many benefits and outperforms many state-of-the-art algorithms.",smart cities
10.1016/j.jvcir.2020.102912,Journal,Journal of Visual Communication and Image Representation,scopus,2020-10-01,sciencedirect,A survey on analysis and implementation of state-of-the-art haze removal techniques,https://api.elsevier.com/content/abstract/scopus_id/85091202375,"Haze is a poor-quality state described by the opalescent appearance of the atmosphere which reduces the visibility. It is caused by high concentrations of atmospheric air pollutants, such as dust, smoke and other particles that scatter and absorb sunlight. The poor visibility can result in the failure of multiple computer vision applications such as smart transport systems, image processing, object detection, surveillance etc. One of the major issues in the field of image processing is the restoration of images that are corrupted due to different degradations. Typically, the images or videos captured in the outside environment have low contrast, colour fade and restricted visibility due to suspended particles of the atmosphere that directly influence the image quality. This can cause difficulty in identifying the objects in the captured hazy images or frames. To address this problem, several image dehazing techniques have been developed in the literature, each of which has its own advantages and limitations, but effective image restoration remains a challenging task. In recent times, various learning (Machine learning & Deep learning) based methods greatly condensed the drawbacks of manual design of haze related features and reduces the difficulty in efficient restoration of images with less computational time and cost. The current state-of-the-art methods for haze free images, mainly from the last decade, are thoroughly examined in this survey. Moreover, this paper systematically summarizes the hardware implementations of various haze removal methods in real time. It is with the hope that this current survey acts as a reference for researchers in this scientific area and to provide a direction for future improvements based on current achievements.",smart cities
10.1016/j.tre.2020.102070,Journal,Transportation Research Part E: Logistics and Transportation Review,scopus,2020-10-01,sciencedirect,Integrating Dijkstra's algorithm into deep inverse reinforcement learning for food delivery route planning,https://api.elsevier.com/content/abstract/scopus_id/85091002808,"In China, rapid development of online food delivery brings massive orders, which relies heavily on deliverymen riding e-bikes. In practice, actual delivery routes of most orders are not the same as the system recommended routes, and the road network information for some areas is outdated or incomplete. In this research, we develop a deep inverse reinforcement learning (IRL) algorithm to capture deliverymen’s preferences from historical GPS trajectories and recommend their preferred routes. Considering the characteristics of food delivery routes, we employ Dijkstra’s algorithm instead of value iteration, to determine the current policy and compute the gradient of IRL. Moreover, we plan routes at the presence and absence of road network information, providing accurate navigation when road network information is unknown. Numerical experiments on real delivery trajectories provided by Meituan-Dianping Group show that our approach improves 
                        
                           F
                           1
                           -
                           
                              
                                 score
                              
                              
                                 distance
                              
                           
                        
                      by 
                        
                           8.0
                           %
                        
                      and 
                        
                           6.1
                           %
                        
                      at the presence and absence of road network information, respectively.",smart cities
10.1016/j.trb.2020.08.005,Journal,Transportation Research Part B: Methodological,scopus,2020-10-01,sciencedirect,An actor-critic deep reinforcement learning approach for metro train scheduling with rolling stock circulation under stochastic demand,https://api.elsevier.com/content/abstract/scopus_id/85090424869,"This paper presents a novel actor-critic deep reinforcement learning approach for metro train scheduling with circulation of limited rolling stock. The scheduling problem is modeled as a Markov decision process driven by stochastic passenger demand. As in most dynamic optimization problems, the complexity of the scheduling process grows exponentially with the amount of states, decisions, and uncertainties involved. This study aims to address this ‘curses of dimensionality’ issue by adopting an actor-critic deep reinforcement learning solution framework. The framework simplifies the evaluation and searching process for potential optimal solutions by parameterizing the original state and decision spaces with the use of artificial neural networks. A deep deterministic policy gradient algorithm is developed for training the artificial neural networks via simulated system transitions before the actor-critic agent can be applied for online schedule control. The proposed approach is tested with a real-world scenario configured with data collected from the Victoria Line of London Underground, UK. Experiment results illustrate the advantages of the proposed method over a range of established meta-heuristics in terms of computing time, system efficiency, and robustness under different stochastic environments. This study innovates urban transit operations with state-of-the-art computer science and dynamic optimization techniques.",smart cities
10.1016/j.trc.2020.102747,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-10-01,sciencedirect,Estimating multi-class dynamic origin-destination demand through a forward-backward algorithm on computational graphs,https://api.elsevier.com/content/abstract/scopus_id/85089847740,"Transportation networks are unprecedentedly complex with heterogeneous vehicular flow. Conventionally, vehicles are classified by size, the number of axles or engine types, e.g., standard passenger cars versus trucks. However, vehicle flow heterogeneity stems from many other aspects in general, e.g., ride-sourcing vehicles versus personal vehicles, human driven vehicles versus connected and automated vehicles. Provided with some observations of vehicular flow for each class in a large-scale transportation network, how to estimate the multi-class spatio-temporal vehicular flow, in terms of time-varying Origin-Destination (OD) demand and path/link flow, remains a big challenge. This paper presents a solution framework for multi-class dynamic OD demand estimation (MCDODE) in large-scale networks that work for any vehicular data in general. The proposed framework cast the standard OD estimation methods into a computational graph with tensor representations of spatio-temporal flow and all intermediate features involved in the MCDODE formulation. A forward-backward algorithm is proposed to efficiently solve the MCDODE formulation on computational graphs. In addition, we propose a novel concept of tree-based cumulative curves to compute the exact multi-class Dynamic Assignment Ratio (DAR) matrix. A Growing Tree algorithm is developed to construct tree-based cumulative curves. The proposed framework is examined on a small network, a mid-size network as well as a real-world large-scale network. The experiment results indicate that the proposed framework is compelling, satisfactory and computationally plausible.",smart cities
10.1016/j.trc.2020.102749,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-10-01,sciencedirect,Analyzing network-wide patterns of rail transit delays using Bayesian network learning,https://api.elsevier.com/content/abstract/scopus_id/85089554926,"Rail transit delays are generally discussed in terms of on-time performance or problems at individual stops. Such stop-scale approaches ignore the fact that delays are also caused and perpetuated by network-wide factors (e.g., bottlenecks caused by shared tracks by multiple transit lines). The objective of this paper is to develop a network model and metrics that can quantify the delay dependencies between transit network stops, and identify local sources of network-wide issues. For this purpose, Bayesian network learning (at the intersection of machine learning and network science) was utilized. Based on the calculated Bayesian networks (BNs), network metrics (inducer and susceptible) were formulated to quantify the network-wide impacts of the delays experienced at the stops. To implement the proposed framework, the delays at Long Island Rail Road (LIRR) were gathered through a crowdsourced real-time transit information app called onTime. The developed BN model was tested through cross-validation, yielded promising accuracy results, successfully identified the problematic stops based on LIRR reports, and provided further insights on network impacts. The BN model and the developed metrics were further tested using a natural experiment, i.e., a before and after study focusing on a recently completed track expansion project at LIRR. The findings imply that BN learning can successfully identify the network dependencies and indicate the rail links/corridors that are the best candidate for subsequent improvement investments. Overall, the developed metrics can quantify the delay dependencies between stops and they can be used by policy makers and practitioners for investment and improvement decisions.",smart cities
10.1016/j.trc.2020.102715,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-10-01,sciencedirect,Deep reinforcement learning algorithm for dynamic pricing of express lanes with multiple access locations,https://api.elsevier.com/content/abstract/scopus_id/85089151204,"This article develops a deep reinforcement learning (Deep-RL) framework for dynamic pricing on managed lanes with multiple access locations and heterogeneity in travelers’ value of time, origin, and destination. This framework relaxes assumptions in the literature by considering multiple origins and destinations, multiple access locations to the managed lane, en route diversion of travelers, partial observability of the sensor readings, and stochastic demand and observations. The problem is formulated as a partially observable Markov decision process (POMDP) and policy gradient methods are used to determine tolls as a function of real-time observations. Tolls are modeled as continuous and stochastic variables and are determined using a feedforward neural network. The method is compared against a feedback control method used for dynamic pricing. We show that Deep-RL is effective in learning toll policies for maximizing revenue, minimizing total system travel time, and other joint weighted objectives, when tested on real-world transportation networks. The Deep-RL toll policies outperform the feedback control heuristic for the revenue maximization objective by generating revenues up to 8.5% higher than the heuristic and for the objective minimizing total system travel time (TSTT) by generating TSTT up to 8.4% lower than the heuristic. We also propose reward shaping methods for the POMDP to overcome the undesired behavior of toll policies, like the jam-and-harvest behavior of revenue-maximizing policies. Additionally, we test transferability of the algorithm trained on one set of inputs for new input distributions and offer recommendations on real-time implementations of Deep-RL algorithms. The source code for our experiments is available online at https://github.com/venktesh22/ExpressLanes_Deep-RL.",smart cities
10.1016/j.jddst.2020.101919,Journal,Journal of Drug Delivery Science and Technology,scopus,2020-10-01,sciencedirect,"Nose to brain delivery of eletriptan hydrobromide nanoparticles: Preparation, in vitro/in vivo evaluation and effect on trigeminal activation",https://api.elsevier.com/content/abstract/scopus_id/85088221302,"Migraine is a chronic disorder of the brain and acts through peripheral trigeminal activation. Thus, both central and peripheral stimulations can play a part in sensitization and activation of trigeminal neurons. Intranasal drug delivery offers a possible solution due to direct link to trigeminal nerves. A wide variety of therapeutic compounds can be administered intranasally for their topical, systemic and central nervous system (CNS) action. In this study, eletriptan hydrobromide (EH) loaded PLGA nanoparticles were prepared and their antimigraine activity was evaluated after intranasal administration. It was shown that PLGA nanoparticles had an average particle size of 201.5 ± 13.6 nm and zeta potential value of – 17.3 ± 2.11 mV. After cellular uptake and P-glycoprotein efflux studies, EH nanoparticles were shown to overcome P- glycoprotein mediated drug efflux. The pharmacokinetic parameters revealed a marked improvement in the CNS permeation behavior of intranasal EH loaded nanoparticle administration as compared to intravenous administration of drug (p < 0.05). There was two times higher AUCbrain representing a higher total amount of drug reaching to the brain (AUC0-∞ = 100.34 ± 29.13 ng/ml.h for intranasal nanoparticle administration and AUC0-∞ = 60.01 ± 11.30 ng/ml.h for intravenous solution). We showed that expressions of c-fos and substance P are dependent on the drug that reached to the brain and intranasal drug administration prolonged the expression of substance P and c-fos mRNA levels. Based on the results, intranasal PLGA nanoparticle administration of EH may be evaluated as a better treatment option for migraine therapy.",smart cities
10.1016/j.scitotenv.2020.139625,Journal,Science of the Total Environment,scopus,2020-10-01,sciencedirect,Modelling of instantaneous emissions from diesel vehicles with a special focus on NO<inf>x</inf>: Insights from machine learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85086741927,"Accurate instantaneous vehicle emissions models are vital for evaluating the impacts of road transport on air pollution at high temporal and spatial resolution. In this study, we apply machine learning techniques to a dataset of 70 diesel vehicles tested in real-world driving conditions to: (i) cluster vehicles with similar emissions performance, and (ii) model instantaneous emissions. The application of dynamic time warping and clustering analysis by NOx emissions resulted in 17 clusters capturing 88% of trips in the dataset. We show that clustering effectively groups vehicles with similar emissions profiles, however no significant correlation between emissions and vehicle characteristics (i.e. engine size, vehicle weight) were found. For each cluster, we evaluate three instantaneous emissions models: a look-up table (LT) approach, a non-linear regression (NLR) model and a neural network multi-layer perceptron (MLP) model. The NLR model provides accurate instantaneous NOx predictions, on par with the MLP: relative errors in prediction of emission factors are below 20% for both models, average fractional biases are −0.01 (s.d. 0.02) and −0.0003 (s.d. 0.04), and average normalised mean squared errors are 0.25 (s.d. 0.14) and 0.29 (s.d. 0.16), for the NLR and MLP models respectively. However, neural networks are better able to deal with vehicles not belonging to a specific cluster. The new models that we present rely on simple inputs of vehicle speed and acceleration, which could be extracted from existing sources including traffic cameras and vehicle tracking devices, and can therefore be deployed immediately to enable fast and accurate prediction of vehicle NOx emissions. The speed and the ease of use of these new models make them an ideal operational tool for policy makers aiming to build emission inventories or evaluate emissions mitigation strategies.",smart cities
10.1016/j.inffus.2020.04.004,Journal,Information Fusion,scopus,2020-10-01,sciencedirect,Classical and deep learning methods for recognizing human activities and modes of transportation with smartphone sensors,https://api.elsevier.com/content/abstract/scopus_id/85083902633,"The Sussex-Huawei Locomotion-Transportation Recognition Challenge presented a unique opportunity to the activity-recognition community to test their approaches on a large, real-life benchmark dataset with activities different from those typically recognized. The goal of the challenge was to recognize, as accurately as possible, eight locomotion activities (Still, Walk, Run, Bike, Car, Bus, Train, Subway) using smartphone sensor data. This paper describes the method we developed to win this challenge, and provides an analysis of the effectiveness of its components. We used complex feature extraction and selection methods to train classical machine learning models. In addition, we trained deep learning models using a novel end-to-end architecture for deep multimodal spectro-temporal fusion. All the models were fused into an ensemble with the final predictions smoothed by a hidden Markov model to account for temporal dependencies of the activities. The presented method achieved an F1 score of 94.9% on the challenge test data. We tested different sampling frequencies, window sizes, feature types, classification models and the importance of stand-alone sensors and their fusion for the task. Finally, we present an energy-efficient smartphone implementation of the method.",smart cities
10.1016/j.neucom.2020.01.117,Journal,Neurocomputing,scopus,2020-09-17,sciencedirect,Unsupervised urban scene segmentation via domain adaptation,https://api.elsevier.com/content/abstract/scopus_id/85085004469,"Image semantic segmentation is a basic and challenging computer vision task, where each pixel in an image is classified into a semantic class. In recent years, deep neural networks have settled many computer vision problems such as semantic segmentation, image classification, object detection. A lot of approaches based on deep neural networks have achieved outstanding performance on different benchmarks. However, most of them are restricted by the scale of elaborate labeled data to train a deep neural network, especially on image semantic segmentation. Collecting pixel-level annotated images is an extremely time-consuming process. Thus, utilization of synthetic data is becoming prevalent. Nevertheless, simply applying the models trained on synthetic data leads to a dramatic performance drop on real images due to the domain shift. In this paper, we propose an adversarial learning method for domain adaptation from the perspectives of both image-level and feature-level. The former adapts images from two domains to appear as if drawn from one domain and the latter attempts to learn similarities between the source and target domains in feature-level common space. To further enhance the adapted model, we introduce a self-training strategy using pseudo-labels. Extensive experiments and ablation studies are conducted under various settings and experiment results indicate our unsupervised method outperforms other state-of-the-art methods.",smart cities
10.1016/j.jenvman.2020.110852,Journal,Journal of Environmental Management,scopus,2020-09-15,sciencedirect,"Municipal wastewater sludge as a renewable, cost-effective feedstock for transportation biofuels using hydrothermal liquefaction",https://api.elsevier.com/content/abstract/scopus_id/85085765258,"U.S. municipal wastewater contains approximately 160 trillion Btu/y of influent chemical energy, but very little is recovered and utilized nationwide. Hydrothermal liquefaction (HTL) is a thermochemical process that converts biomass into a biocrude intermediate that can be upgraded to a variety of liquid fuels. HTL provides an opportunity to enhance energy recovery at wastewater treatment plants by transforming underutilized municipal wastewater solids into a renewable, cost-effective feedstock for transportation biofuels. In this study, we estimate total national economic sludge feedstock supply by performing discounted cash flow analyses at >15,000 U.S. wastewater treatment facilities to assess the net present value of 30-year HTL investments, with comparison to wider adoption of anaerobic digestion (AD). This analysis is the first to model HTL technology deployment across the real-world fleet of wastewater treatment plants. Analyses indicate treatment facilities ≥17 ML/d (4.6 million gal/d) could supply 9.77 Tg/y of dry solids feedstock to economically produce 3.67 GL/y of biocrude intermediate, thereby increasing energy, environmental, and financial sustainability of sludge treatment while reducing disposal costs and operational and environmental risk.",smart cities
10.1016/j.neucom.2020.05.013,Journal,Neurocomputing,scopus,2020-09-03,sciencedirect,Multi-source urban data fusion for property value assessment: A case study in Philadelphia,https://api.elsevier.com/content/abstract/scopus_id/85084813673,"The property value assessment in the real estate market still remains as a challenges due to incomplete and insufficient information, as well as the lack of efficient algorithms. House attributes, such as size and number of bedrooms, are currently being employed to perform the estimation by professional appraisers and researchers. Numerous algorithms have been proposed; however, a better assessment performance is still expected by the market. Nowadays, there are more available relevant data from various sources in urban areas, which have a potential impact on the house value. In this paper, we propose to fuse urban data, i.e., metadata and imagery data, with house attributes to unveil the market value of the property in Philadelphia. Specifically, two deep neural networks, i.e., metadata fusion network and image appraiser, are proposed to extract the representations, i.e., expected levels, from metadata and street-view images, respectively. A boosted regression tree (BRT) is adapted to estimate the market values of houses with the fused metadata and expected levels. The experimental results with the data collected from the city of Philadelphia demonstrate the effectiveness of the proposed model. The research presented in this paper also provides the real estate industry a new reference to the property value assessment with the data fusion methodology.",smart cities
10.1016/j.iot.2020.100205,Journal,Internet of Things (Netherlands),scopus,2020-09-01,sciencedirect,Multi-UAV Allocation Framework for Predictive Crime Deterrence and Data Acquisition,https://api.elsevier.com/content/abstract/scopus_id/85105803842,"The recent decline in the number of police and security force personnel has raised a serious security issue that could lead to reduced public safety and delayed response to crimes in urban areas. This may be alleviated in part by utilizing micro or small unmanned aerial vehicles (UAVs) and their high-mobility on-board sensors in conjunction with machine-learning techniques such as neural networks to offer better performance in predicting times and places that are high-risk and deterring crimes. The key to the success of such operation lies in the suitable placement of UAVs. This paper proposes a multi-UAV allocation framework for predictive crime deterrence and data acquisition that consists of the overarching methodology, a problem formulation, and an allocation method that work with a prediction model using a machine learning approach. In contrast to previous studies, our framework provides the most effective arrangement of UAVs for maximizing the chance to apprehend offenders whilst also acquiring data that will help improve the performance of subsequent crime prediction. This paper presents the system architecture assumed in this study, followed by a detailed description of the methodology, the formulation of the problem, and the UAV allocation method of the proposed framework. Our framework is tested using a real-world crime dataset to evaluate its performance with respect to the expected number of crimes deterred by the UAV patrol. Furthermore, to address the engineering practice of the proposed framework, we discuss the feasibility of the simulated deployment scenario in terms of energy consumption and the relationship between data analysis and crime prediction.",smart cities
10.1016/j.jocs.2020.101205,Journal,Journal of Computational Science,scopus,2020-09-01,sciencedirect,Real-time mobile sensor management framework for city-scale environmental monitoring,https://api.elsevier.com/content/abstract/scopus_id/85090220558,"Environmental disasters such as flash floods are becoming more and more prevalent and carry an increasing burden to human civilization. They are usually unpredictable, fast in development and extend across large geographical areas. The consequences of such disasters can be reduced through better monitoring, for example using mobile sensing platforms that can give timely and accurate information to first responders and the public. Given the extended scale of the areas to monitor, and the time-varying nature of the phenomenon, we need fast algorithms to quickly determine the best sequence of locations to be monitored. This problem is very challenging: the present informative mobile sensor routing algorithms are either short-sighted or computationally demanding when applied to large scale systems. In this paper, a real-time sensor task scheduling algorithm that suits the features and needs of city-scale environmental monitoring tasks is proposed. The algorithm is run in forward search and makes use of the predictions of an associated distributed parameter system, modeling flash flood propagation. It partly inherits the causal relation expressed by a search tree, which describes all possible sequential decisions. The computationally heavy data assimilation steps in the forward search tree are replaced by functions dependent on the covariance matrix between observation sets. Taking flood tracking in an urban area as a concrete example, numerical experiments in this paper indicate that this scheduling algorithm can achieve better results than myopic planning algorithms and other heuristics based sensor placement algorithms. Furthermore, this paper relies on a deep learning-based data-driven model to track the system states, and experiments suggest that popular estimation techniques have very good performance when applied to precise data-driven models. The data and code can be freely downloaded from https://drive.google.com/drive/folders/1gRz4T2KGFXtlnSugarfUL8r355cXb7Ko?usp=sharing.",smart cities
10.1016/j.jairtraman.2020.101840,Journal,Journal of Air Transport Management,scopus,2020-09-01,sciencedirect,Automated data-driven prediction on aircraft Estimated Time of Arrival,https://api.elsevier.com/content/abstract/scopus_id/85088012391,"4D trajectory prediction is the core element of the future air transportation system. It aims to improve the operational ability and the predictability of air traffic. In this paper, a novel automated data-driven framework to deal with the prediction of Estimated Time of Arrival (ETA) on the runway at the entry point of Terminal Manoeuvring Area (TMA) is introduced. The proposed framework mainly consists of data preprocessing and machine learning models. Firstly, the dataset is divided, analyzed, cleaned, and estimated. Then, the flights are clustered into partitions according to different runway-in-use (QFU). Several candidate machine learning models are trained and selected on the corresponding dataset of each QFU. Feature engineering is conducted to transform raw data into features. After that, the experiments are performed on real ADS-B data in Beijing TMA with nested cross validation. By comparing the prediction performance on the preprocessed and un-preprocessed datasets, the results demonstrate that the proposed data preprocessing is able to improve the data quality. It is also robust to outliers, missing data, and noise. Finally, an ensemble learning strategy named stacking is introduced. Compared to other individual models, the stacked model has a more complex structure and performs best in ETA prediction. This fact reveals that the framework proposed in this study could make accurate and reliable ETA predictions.",smart cities
10.1016/j.compag.2020.105632,Journal,Computers and Electronics in Agriculture,scopus,2020-09-01,sciencedirect,Comfort and health evaluation of live mutton sheep during the transportation based on wearable multi-sensor system,https://api.elsevier.com/content/abstract/scopus_id/85087855037,"The uncertainty of transport environment threatens the comfort and health of live mutton sheep and even affects the quality of meat after slaughter. Using modern information technology to solve the deficiencies of live animal centralized transport is of great significance for the stable development of animal husbandry. In this paper, the wearable multi-sensor system was specially designed, and the system test experiment and transport monitoring experiment were carried out. According to the continuous and real-time data of environmental and physiological parameters obtained from the transport monitoring experiment, the optimization extraction, data collection analysis, correlation analysis and simulation analysis of the internal environment in the carriage were carried out, and the prediction model between environmental and physiological parameters based on generalized regression neural network (GRNN) and the prediction model of comfort and health evaluation based on back propagation neural network (BPNN) were established. The results show that: (1) The wearable multi-sensor system had high accuracy and stability of data collection, and the power consumption and communication performance can meet the monitoring requirements. (2) The observation values of internal environmental parameters increased gradually with the accumulation of transport time, and finally reached the state of dynamic balance. The heart rate fluctuated greatly and was higher than the normal range. The blood oxygen saturation showed a gradual decrease trend, but the overall was in the normal range. The body temperature gradually increased, and was affected by discomfort. (3) The correlation analysis showed that there was a significant correlation between environmental and physiological parameters. (4) The area with larger value of environmental parameters was close to the middle and front of the carriage, which was mainly caused by the high density and poor air circulation. (5) The prediction model between environmental and physiological parameters based on GRNN and the prediction model of comfort and health evaluation based on BPNN had high prediction accuracy, and the combination of the two models can map the impact of environmental factors on the change of vital signs to the relationship between comfort and health. Therefore, in the case of unknown vital signs information, only obtaining environmental information can also predict the health levels, which can provide decision-making basis for relevant practitioners.",smart cities
10.1016/j.compenvurbsys.2020.101521,Journal,"Computers, Environment and Urban Systems",scopus,2020-09-01,sciencedirect,Using graph structural information about flows to enhance short-term demand prediction in bike-sharing systems,https://api.elsevier.com/content/abstract/scopus_id/85087769371,"Short-term demand prediction is important for managing transportation infrastructure, particularly in times of disruption, or around new developments. Many bike-sharing schemes face the challenges of managing service provision and bike fleet rebalancing due to the “tidal flows” of travel and use. For them, it is crucial to have precise predictions of travel demand at a fine spatiotemporal granularities. Despite recent advances in machine learning approaches (e.g. deep neural networks) and in short-term traffic demand predictions, relatively few studies have examined this issue using a feature engineering approach to inform model selection. This research extracts novel time-lagged variables describing graph structures and flow interactions from real-world bike usage datasets, including graph node Out-strength, In-strength, Out-degree, In-degree and PageRank. These are used as inputs to different machine learning algorithms to predict short-term bike demand. The results of the experiments indicate the graph-based attributes to be more important in demand prediction than more commonly used meteorological information. The results from the different machine learning approaches (XGBoost, MLP, LSTM) improve when time-lagged graph information is included. Deep neural networks were found to be better able to handle the sequences of the time-lagged graph variables than other approaches, resulting in more accurate forecasting. Thus incorporating graph-based features can improve understanding and modelling of demand patterns in urban areas, supporting bike-sharing schemes and promoting sustainable transport. The proposed approach can be extended into many existing models using spatial data and can be readily transferred to other applications for predicting dynamics in mass transit systems. A number of limitations and areas of further work are discussed.",smart cities
10.1016/j.trc.2020.102674,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-09-01,sciencedirect,Stacked bidirectional and unidirectional LSTM recurrent neural network for forecasting network-wide traffic state with missing values,https://api.elsevier.com/content/abstract/scopus_id/85087588891,"Short-term traffic forecasting based on deep learning methods, especially recurrent neural networks (RNN), has received much attention in recent years. However, the potential of RNN-based models in traffic forecasting has not yet been fully exploited in terms of the predictive power of spatial–temporal data and the capability of handling missing data. In this paper, we focus on RNN-based models and attempt to reformulate the way to incorporate RNN and its variants into traffic prediction models. A stacked bidirectional and unidirectional LSTM network architecture (SBU-LSTM) is proposed to assist the design of neural network structures for traffic state forecasting. As a key component of the architecture, the bidirectional LSTM (BDLSM) is exploited to capture the forward and backward temporal dependencies in spatiotemporal data. To deal with missing values in spatial–temporal data, we also propose a data imputation mechanism in the LSTM structure (LSTM-I) by designing an imputation unit to infer missing values and assist traffic prediction. The bidirectional version of LSTM-I is incorporated in the SBU-LSTM architecture. Two real-world network-wide traffic state datasets are used to conduct experiments and published to facilitate further traffic prediction research. The prediction performance of multiple types of multi-layer LSTM or BDLSTM models is evaluated. Experimental results indicate that the proposed SBU-LSTM architecture, especially the two-layer BDLSTM network, can achieve superior performance for the network-wide traffic prediction in both accuracy and robustness. Further, comprehensive comparison results show that the proposed data imputation mechanism in the RNN-based models can achieve outstanding prediction performance when the model’s input data contains different patterns of missing values.",smart cities
10.1016/j.aap.2020.105658,Journal,Accident Analysis and Prevention,scopus,2020-09-01,sciencedirect,<sup>⋆</sup>This paper has been handled by associate editor Tony Sze.The application of novel connected vehicles emulated data on real-time crash potential prediction for arterials,https://api.elsevier.com/content/abstract/scopus_id/85087200575,"Real-time crash potential prediction could provide valuable information for Active Traffic Management Systems. Fixed infrastructure-based vehicle detection devices were widely used in the previous studies to obtain different types of data for crash potential prediction. However, it was difficult to obtain data in large range through these devices due to the costs of installation and maintenance. This paper introduced a novel connected vehicle (CV) emulated data for real-time crash potential prediction. Different from the fixed devices’ data, CV emulated data have high flexibility and can be obtained continuously with relatively low cost. Crash and CV emulated data were collected from two urban arterials in Orlando, USA. Crash data were archived by the Signal for Analytics system (S4A), while the CV emulated data were obtained through the data collection API with a high frequency. Different data cleaning and preparation techniques were implemented, while various speed-related variables were generated from the CV emulated data. A Long Short-term Memory (LSTM) neural network was trained to predict the crash potential in the next 5−10 min. The results from the model illustrated the feasibility of using a novel CV emulated data to predict real-time crash potential. The average and 50th percentile speed were the two most important variables for the crash potential prediction. In addition, the proposed LSTM outperformed Bayesian logistics regression and XGBoost in terms of sensitivity, Area under Curve (AUC), and false alarm rate. With the rapid development of the connected vehicle systems, the results from this paper can be extended to other types of vehicles and data, which can significantly enhance traffic safety.",smart cities
10.1016/j.aap.2020.105628,Journal,Accident Analysis and Prevention,scopus,2020-09-01,sciencedirect,Automated traffic incident detection with a smaller dataset based on generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85086517198,"An imbalanced and small training sample can cause an incident detection model to have a low detection rate and a high false alarm rate. To solve the scarcity of incident samples, a novel incident detection framework is proposed based on generative adversarial networks (GANs). First, spatial and temporal rules are presented to extract variables from traffic data, which is followed by the random forest algorithm to rank the importance of variables. Then, some new incident samples are generated using GANs. Finally, the support vector machine algorithm is applied as the incident detection model. Real traffic data, which were collected from a 69.5-mile section of the I-80 highway, are used to validate the proposed approach. A total of 140 detectors are installed on the section enabling traffic flow to be measured every 30s. During 14 days, 139 incident samples and 946 nonincident samples were extracted from the raw data. Five categories of experiments are designed to evaluate whether the proposed framework can solve the small sample size problem, imbalanced sample problem, and timeliness problem in the current incident detection system. The experimental results show that our proposed framework can considerably improve the detection rate and reduce the false alarm rate of traffic incident detection. The balance of the dataset can improve the detection rate from 87.48% to 90.68% and reduce the false alarm rate from 12.76% to 7.11%. This paper lends support to further studies on combining GANs with the machine learning model to address the imbalance and small sample size problems related to intelligent transportation systems.",smart cities
10.1016/j.adhoc.2020.102224,Journal,Ad Hoc Networks,scopus,2020-09-01,sciencedirect,A performance modeling and analysis of a novel vehicular traffic flow prediction system using a hybrid machine learning-based model,https://api.elsevier.com/content/abstract/scopus_id/85085930980,"Traffic prediction on the road, as a vital part of the Intelligent Transportation System (ITS) has attracted much attention recently. It is always one of the hot topics about how to implement an efficient, robust, and accurate vehicular traffic prediction system. With the help of Machine Learning-based (ML) methods, especially Deep Learning-based (DL) methods, the accuracy of the prediction model is increased. However, we also noticed that there are still many open challenges under ML-based vehicular traffic prediction model real-world implementation. Firstly, the time consumption for training DL model is relatively large when compared to parametric models, such as ARIMA, SARIMA. Second, it is still a hot topic for road traffic prediction that how to capture the spacial relationship between road detectors, which is affected by the geographic correlation, as well as the time change. The last but not the least, it is important for us to implement the prediction system into the real world; meanwhile, we should find a way to make use of the advanced technology applied in ITS to improve the prediction system itself. In this paper, we focus on improving the features of the prediction model, which can be helpful for implementing the model in the real world. We present a new hybrid deep learning model by using Graph Convolutional Network (GCN) and the deep aggregation structure (i.e., the sequence to sequence structure) of Gated Recurrent Unit (GRU). Meanwhile, in order to solve the real-world prediction problem, i.e., the online prediction task, we present a new online prediction strategy by using refinement learning. In order to further improve the model’s accuracy and efficiency when applied to ITS, we make use of an efficient parallel training strategy while taking advantage of the vehicular cloud structure.",smart cities
10.1016/j.scs.2020.102252,Journal,Sustainable Cities and Society,scopus,2020-09-01,sciencedirect,A deep learning-based IoT-oriented infrastructure for secure smart City,https://api.elsevier.com/content/abstract/scopus_id/85085594643,"In recent years, the Internet of Things (IoT) infrastructures are developing in various industrial applications in sustainable smart cities and societies such as smart manufacturing, smart industries. The Cyber-Physical System (CPS) is also part of IoT-oriented infrastructure. CPS has gained considerable success in industrial applications and critical infrastructure with a distributed environment. This system aims to integrate the physical world to computational facilities as cyberspace. However, there are many challenges, such as security and privacy, centralization, communication latency, scalability in such an environment. To mitigate these challenges, we propose a Deep Learning-based IoT-oriented infrastructure for a secure smart city where Blockchain provides a distributed environment at the communication phase of CPS, and Software-Defined Networking (SDN) establishes the protocols for data forwarding in the network. A deep learning-based cloud is utilized at the application layer of the proposed infrastructure to resolve communication latency and centralization, scalability. It enables cost-effective, high-performance computing resources for smart city applications such as the smart industry, smart transportation. Finally, we evaluated the performance of our proposed infrastructure. We compared it with existing methods using quantitative analysis and security and privacy analysis with different measures such as scalability and latency. The evaluation of our implementation results shows that performance is improved.",smart cities
10.1016/j.jnca.2020.102692,Journal,Journal of Network and Computer Applications,scopus,2020-08-15,sciencedirect,MARIO: A spatio-temporal data mining framework on Google Cloud to explore mobility dynamics from taxi trajectories,https://api.elsevier.com/content/abstract/scopus_id/85084749934,"With the major advances in location acquisition techniques, deployment of GPS enabled devices and increasing number of mobile users, substantial amount of location traces are generated from different geographical regions. It provides unprecedented opportunities to analyze and derive valuable insights of urban dynamics, specifically, time-dependent mobility patterns and region-specific travel demands. This work proposes an end-to-end mobility association rule mining framework called MARIO, conducive to extract urban mobility dynamics through analysing large taxi trip traces of a city. The MARIO framework consists of (i) generating mobility-dynamics network by spatio-temporal analysis of taxi-trips, (ii) finding travel demand variations in different functional regions of the urban area, (iii) extracting mobility association rules and (iv) predicting travel demands and traffic dynamics using extracted associative rules. The proposed MARIO framework is implemented in Google Cloud Platform and an extensive set of experiments using real GPS trace dataset of NYC Green and Yellow Taxi trace, Roma Taxi Dataset and San Francisco Taxi Dataset have been carried out to demonstrate the effectiveness of the framework. The performance of the proposed approach is significantly better than the baseline methods in predicting travel demands (with the reduction of average MAPE value and execution time by 50%).",smart cities
10.1016/j.jclepro.2020.121426,Journal,Journal of Cleaner Production,scopus,2020-08-10,sciencedirect,A sentiment reporting framework for major city events: Case study on the China-United States trade war,https://api.elsevier.com/content/abstract/scopus_id/85084032594,"Smart cities are conceptualized as a vehicle for sustainable urban development and a means to deliver high quality of life for residents. One of the core functions of a smart city consists in the continuous monitoring of events, assets and people and the use of this information and intelligence for the streamlining of the city’s operations. Public opinion represents one type of intelligence of particular importance and value. By monitoring public opinion, governments seek to understand prevalent views about the current events and policies, as well as identify extreme views and trends that may represent problematic situations or precursors to violent actions. Ultimately, maintaining a constant awareness of public opinion means that authorities can better assess and predict public reactions in relation to ongoing events, and thus take appropriate actions to maintain public safety. Due to the popular use of social media to express sentiments and emotions about current events, social media content analysis has been contemplated as a promising solution to capture public opinion. However, existing approaches take a coarse-grained retrospective approach to social media content analysis. Furthermore, those approaches suffer from the lack of scalability and efficiency, as they necessitate the collection and analysis of large volumes of social media content (often millions of posts), to come up with relevant conclusions. In this work, we address those limitations by proposing a novel framework for the real-time monitoring of public opinion. To ensure efficiency and scalability, our framework focuses on the analysis of high impact social media content generated by opinion leaders and their followers as means to offer in-depth insights and sentiment intelligence reports about events, as they are occurring in real time. The proposed framework was implemented and tested on data harvested from 52 economic opinion leaders, with a focus on the China-US trade war as case study. The results show that the convolutional neural network (CNN) classifier used for sentiment analysis yielded a classification accuracy of 86% when differentiating between four sentiment categories: Support, strong support, dissent, and strong dissent. The Support Vector Machine (SVM) classifier employed to perform in-depth emotional analysis attained an accuracy of 82% when differentiating between five emotions: Angry, depressed, excited, happy, and worried. Unlike existing retrospective social media analysis approaches that require the analysis of millions of posts, our approach focuses on the analysis of high-impact social media content in real-time, thus constituting an efficient, sustainable, and timely solution to public opinion monitoring.",smart cities
10.1016/j.neucom.2020.03.031,Journal,Neurocomputing,scopus,2020-08-04,sciencedirect,LSTM variants meet graph neural networks for road speed prediction,https://api.elsevier.com/content/abstract/scopus_id/85081970960,"Traffic flow prediction is a fundamental issue in smart cities and plays an important role in urban traffic planning and management. An accurate predictive model can help individuals make reliable travel plans and choose optimal routes while efficiently helping administrators maintain traffic order. Road speed prediction, which is a sub-task of traffic flow forecasting, is challenging due to the complicated spatial dependencies characterizing road networks and dynamic temporal traffic patterns. Given the power of recurrent neural networks (RNNs) in learning temporal relations and graph neural networks (GNNs) in integrating graph-structured and node-attributed features, in this paper, we design a novel graph LSTM (GLSTM) framework to capture spatial-temporal representations in road speed forecasting. More specifically, we first present a temporal directed attributed graph to model complex traffic flow. Then, to take advantage of the structure properties and graph features, we employ a message-passing mechanism for feature aggregation and updating. Finally, we further implement several variants of LSTMs with a GN block under the encoder-decoder framework to model spatial-temporal dependencies. The experiments show that our proposed model is able to fully utilize both the road latent graph structure and traffic speed to forecast the road state during future periods. The results on two real-world datasets show that our GLSTM can outperform state-of-the-art baseline methods by up to 32.8% in terms of MAE, 43.2% in terms of MAPE and 23.1% in terms of RMSE.",smart cities
10.1016/j.jvcir.2020.102845,Journal,Journal of Visual Communication and Image Representation,scopus,2020-08-01,sciencedirect,Volume preserving image segmentation with entropy regularized optimal transport and its applications in deep learning,https://api.elsevier.com/content/abstract/scopus_id/85088041387,"Image segmentation with a volume constraint is an important prior for many real applications. In this work, we present a novel volume preserving image segmentation algorithm, which is based on the entropy and Total Variation (TV) regularized optimal transport theory. The volume and classification constraints can be regarded as two measures preserving constraints in the optimal transport. By studying the dual problem, we develop a simple but efficient dual algorithm for our model. Moreover, to be different from many variational based image segmentation algorithms, the proposed algorithm can be directly unrolled to a new Volume Preserving and TV regularized softmax (VPTV-softmax) layer for semantic segmentation in the popular Deep Convolution Neural Network (DCNN). The experiment results show that our proposed model is very competitive and can improve the performance of many semantic segmentation networks such as the popular U-net and DeepLabv3+.",smart cities
10.1016/j.trc.2020.102678,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-08-01,sciencedirect,Efficient proactive vehicle relocation for on-demand mobility service with recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/85087527697,"One major challenge for on-demand mobility service (OMS) providers is to seamlessly match empty vehicles with trip requests so that the total vacant mileage is minimized. In this study, we develop an innovative data-driven approach for devising efficient vehicle relocation policy for OMS that (1) proactively relocates vehicles before the demand is observed and (2) reduces the inequality among drivers’ income so that the proactive relocation policy is fair and is likely to be followed by drivers. Our approach represents the fusion of optimization and machine learning methods, which comprises three steps: First, we formulate the optimal proactive relocation as an optimal/stable matching problems and solve for global optimal solutions based on historical data. Second, the optimal solutions are then grouped and fed to train the deep learning models which consist of fully connected layers and long short-term memory networks. Low rank approximation is introduced to reduce the model complexity and improve the training performances. Finally, we use the trained model to predict the relocation policy which can be implemented in real time. We conduct comprehensive numerical experiments and sensitivity analyses to demonstrate the performances of the proposed method using New York City taxi data. The results suggest that our method will reduce empty mileage per trip by 54–70% under the optimal matching strategy, and a 25–32% reduction can also be achieved by following the stable matching strategy. We also validate that the predicted relocation policies are robust in the presence of uncertain passenger demand level and passenger trip-requesting behavior.",smart cities
10.1016/j.compbiomed.2020.103820,Journal,Computers in Biology and Medicine,scopus,2020-08-01,sciencedirect,"Drug delivery: Experiments, mathematical modelling and machine learning",https://api.elsevier.com/content/abstract/scopus_id/85087275421,"We address the problem of determining from laboratory experiments the data necessary for a proper modeling of drug delivery and efficacy in anticancer therapy. There is an inherent difficulty in extracting the necessary parameters, because the experiments often yield an insufficient quantity of information. To overcome this difficulty, we propose to combine real experiments, numerical simulation, and Machine Learning (ML) based on Artificial Neural Networks (ANN), aiming at a reliable identification of the physical model factors, e.g. the killing action of the drug. To this purpose, we exploit the employed mathematical-numerical model for tumor growth and drug delivery, together with the ANN - ML procedure, to integrate the results of the experimental tests and feed back the model itself, thus obtaining a reliable predictive tool. The procedure represents a hybrid data-driven, physics-informed approach to machine learning. The physical and mathematical model employed for the numerical simulations is without extracellular matrix (ECM) and healthy cells because of the experimental conditions we reproduce.",smart cities
10.1016/j.tox.2020.152527,Journal,Toxicology,scopus,2020-08-01,sciencedirect,Role of interleukin 1 beta in the regulation of rat intestinal multidrug resistance-associated protein 2 under conditions of experimental endotoxemia,https://api.elsevier.com/content/abstract/scopus_id/85086591907,"Multidrug resistance-associated protein 2 (Mrp2), expressed at the brush border membrane (BBM) of the enterocyte, is an ABC transporter with relevant intestinal barrier function. Its toxicological relevance lies in preventing absorption and tissue accumulation of dietary contaminants, drugs, and potentially harmful endogenous metabolites. Expression and activity of intestinal Mrp2 is downregulated in LPS-induced endotoxemia. In addition, confocal microscopy studies demonstrated internalization of the transporter to endocytic vesicles. Since IL-1β plays an important role as early mediator of LPS-inflammatory responses, we evaluated whether IL-1β mediates LPS-induced impairment of Mrp2 function. Two protocols were used: I) In vivo administration of LPS (5 mg/kg b.wt., i.p., single dose) to rats in simultaneous with administration of anti-IL-1β (25 μg/kg b.wt., i.p., 4 doses), followed by studies of Mrp2 expression, localization and activity, 24 h after LPS administration; II) In vitro incubation of isolated intestinal sacs with IL-1β (10 ng/mL) for 30 min, followed by analysis of Mrp2 activity and localization. We found that in vivo immunoneutralization of IL-1β partially prevented the decrease of Mrp2 protein expression and activity as well as its internalization to intracellular domains induced by LPS. Involvement of IL-1β in the alteration of Mrp2 localization and activity was more directly demonstrated in isolated intestinal sacs, as incubation with IL-1β resulted in detection of Mrp2 in intracellular regions of the enterocyte in simultaneous with alteration of transport activity. In conclusion, IL-1β induces early internalization of intestinal Mrp2, which could partially explain loss of expression at the BBM under conditions of experimental endotoxemia. Concomitant impairment of Mrp2-dependent barrier function may have pathophysiological relevance since IL-1β mediates the effect of many local and systemic inflammatory processes.",smart cities
10.1016/j.scitotenv.2020.138533,Journal,Science of the Total Environment,scopus,2020-07-15,sciencedirect,Combined use of principal component analysis and artificial neural network approach to improve estimates of PM<inf>2.5</inf> personal exposure: A case study on older adults,https://api.elsevier.com/content/abstract/scopus_id/85083345897,"Accurate exposure estimate of the air pollutant PM2.5 is required to evaluate its health impacts in epidemiological studies, due to its adverse effects on human's respiratory and cardiovascular systems. However, traditional personal sampling is time and cost consuming. Thus, modeling techniques are needed to accurately predict the personal exposure level to PM2.5. In this study, a total of 117 older adults over 60 were recruited in Tianjin, a heavily polluted city in northern China, for indoor, outdoor and personal PM2.5 sampling. Eighteen variables which may increase the exposure level of older adults were recorded for artificial neural network (ANN) simulation. Four modeling techniques, including time-integrated activity modeling, Monte Carlo simulation, ANN modeling, and combined use of principal component analysis (PCA) and ANN model, were used to evaluate their ability for predicting real exposure values of PM2.5. The results of traditional time-weighted activity modeling showed the lowest correlation with measured values with R2 of 0.57 and 0.42 in winter and summer, respectively. For Monte Carlo simulation, high correlation was obtained (R2 of 0.93 and 0.92 in winter and summer, respectively) between percentiles of the predicted and the real exposure values. Compared with the simple ANN models, the combined use of PCA and ANN produced the most accurate results with R2 of 0.99 and RMSE lower than 15. Since the information of the input variables for the PCA-ANN model can be obtained from the questionnaire and fixed air quality monitoring sites, this technique shows a great potential in predicting personal exposure level to the air pollutant because no additional concentration measurement is needed.",smart cities
10.1016/j.trc.2020.102661,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-07-01,sciencedirect,Dynamic holding control to avoid bus bunching: A multi-agent deep reinforcement learning framework,https://api.elsevier.com/content/abstract/scopus_id/85085259879,"Bus bunching has been a long-standing problem that undermines the efficiency and reliability of public transport services. The most popular countermeasure in practice is to introduce static and dynamic holding control. However, most previous holding control strategies mainly consider local information with a pre-specified headway/schedule, while the global coordination of the whole bus fleet and its long-term effect are often overlooked. To efficiently incorporate global coordination and long-term operation in bus holding, in this paper we propose a multi-agent deep reinforcement learning (MDRL) framework to develop dynamic and flexible holding control strategies for a bus route. Specifically, we model each bus as an agent that interacts with not only its leader/follower but also all other vehicles in the fleet. To better explore potential strategies, we develop an effective headway-based reward function in the proposed framework. In the learning framework, we model fleet coordination by using a basic actor-critic scheme along with a joint action tracker to better characterize the complex interactions among agents in policy learning, and we apply proximal policy optimization to improve learning performance. We conduct extensive numerical experiments to evaluate the proposed MDRL framework against multiple baseline models that only rely on local information. Our results demonstrate the superiority of the proposed framework and show the promise of applying MDRL in the coordinative control of public transport vehicle fleets in real-world operations.",smart cities
10.1016/j.jvcir.2020.102798,Journal,Journal of Visual Communication and Image Representation,scopus,2020-07-01,sciencedirect,An effective hybrid pruning architecture of dynamic convolution for surveillance videos,https://api.elsevier.com/content/abstract/scopus_id/85084956273,"The large-scale surveillance videos analysis becomes important as the development of the intelligent city; however, the heavy computational resources necessary for the state-of-the-art deep learning model makes real-time processing hard to be implemented. As the characteristic of high scene similarity generally existing in surveillance videos, we propose an effective compression architecture called dynamic convolution, which can reuse the previous feature maps to reduce the calculation amount; and combine with filter pruning to further speed up the performance. In this paper, we tested the presented method on 45 surveillance videos with various scenes. The experimental results show that the hybrid pruning architecture can reduce up to 80.4% of FLOPs while preserving the precision within 1.34% mAP; furthermore, the method can improve the processing speed up to 2.8 times compared to the traditional Single Shot MultiBox Detection.",smart cities
10.1016/j.trc.2020.102628,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-07-01,sciencedirect,Neuro-dynamic programming for optimal control of macroscopic fundamental diagram systems,https://api.elsevier.com/content/abstract/scopus_id/85084421696,"The macroscopic fundamental diagram (MFD) can effectively reduce the spatial dimension involved in dynamic optimization of traffic performance for large-scale networks. Solving the Hamilton-Jacobi-Bellman (HJB) equation takes center stage in yielding solutions to the optimal control problem. At the core of solving the HJB equation is the value function that represents choosing a sequence of actions to optimize the system performance. However, this problem generally becomes intractable for possible discontinuities in the solution and the curse of dimensionality for systems with all but modest dimension. To address these challenges, a neural network is used to approximate the value function to obtain the optimal controls through policy iteration. Furthermore, a saturated operator is embedded in the neural network approximator to handle the difficulty caused by the control and state constraints. This policy iteration can be implemented as an iterative data-driven technique that integrates with the model-based optimal design based on real-time observations. Numerical experiments are conducted to show that the neuro-dynamic programming approach can achieve optimization goals while stabilizing the system by regulating the traffic state to the desired uncongested equilibrium.",smart cities
10.1016/j.apenergy.2020.115031,Journal,Applied Energy,scopus,2020-07-01,sciencedirect,Tackling SOC long-term dynamic for energy management of hybrid electric buses via adaptive policy optimization,https://api.elsevier.com/content/abstract/scopus_id/85084056362,"Plug-in hybrid electric buses (PHEBs) have the potential to satisfy both the fuel efficiency and the driving-mileage under complex urban traffic conditions. However, the optimal charge and discharge management is still a pivotal challenge of energy management for the inherent uncertainty in driving conditions. The common reference state-of-charge (SOC) profile based methods are limited by the adaptiveness which restricts the economic performance of on-line energy management systems. Promisingly, reinforcement learning based energy management strategies exhibited the significant self-learning ability. However, for PHEBs, the sparse rewards by the long-term SOC shortage make the strategies easily trick into the local optimal solution. The work presented in this paper concentrates on combining battery power reduction in the form of conditional entropy into reinforcement learning based energy management strategy. The proposed method named adaptive policy optimization (APO) introduces a novel advantage function to evaluate energy-saving performance considering long-term SOC dynamic, and a Bayesian neural network based SOC shortage probability estimator is utilized to optimize the energy management strategy parameterized by a deep neural network. Several experiments in a standard driving cycle demonstrate the optimality, self-learning ability and convergence of the APO. Moreover, the adaptability and robust performance get validated over the real bus trajectories data. With the comprehensive experiments in this paper, the proposed model exhibits enhanced fuel economy and more suitable SOC planning in comparison with the existing energy management strategies. The results indicate that APO respectively outperforms the compared online strategies by 
                        
                           9.8
                           %
                        
                      and 
                        
                           2.6
                           %
                        
                      and reaches 98
                        
                           %
                        
                      energy-saving rate of the offline global optimum.",smart cities
10.1016/j.eswa.2020.113251,Journal,Expert Systems with Applications,scopus,2020-07-01,sciencedirect,Integrating complex event processing and machine learning: An intelligent architecture for detecting IoT security attacks,https://api.elsevier.com/content/abstract/scopus_id/85079340111,"The Internet of Things (IoT) is growing globally at a fast pace: people now find themselves surrounded by a variety of IoT devices such as smartphones and wearables in their everyday lives. Additionally, smart environments, such as smart healthcare systems, smart industries and smart cities, benefit from sensors and actuators interconnected through the IoT. However, the increase in IoT devices has brought with it the challenge of promptly detecting and combating the cybersecurity attacks and threats that target them, including malware, privacy breaches and denial of service attacks, among others. To tackle this challenge, this paper proposes an intelligent architecture that integrates Complex Event Processing (CEP) technology and the Machine Learning (ML) paradigm in order to detect different types of IoT security attacks in real time. In particular, such an architecture is capable of easily managing event patterns whose conditions depend on values obtained by ML algorithms. Additionally, a model-driven graphical tool for security attack pattern definition and automatic code generation is provided, hiding all the complexity derived from implementation details from domain experts. The proposed architecture has been applied in the case of a healthcare IoT network to validate its ability to detect attacks made by malicious devices. The results obtained demonstrate that this architecture satisfactorily fulfils its objectives.",smart cities
10.1016/j.neucom.2019.01.115,Journal,Neurocomputing,scopus,2020-06-21,sciencedirect,GAN-Based virtual-to-real image translation for urban scene semantic segmentation,https://api.elsevier.com/content/abstract/scopus_id/85068137487,"Semantic image segmentation requires large amounts of pixel-wise labeled training data. Creating such data generally requires labor-intensive human manual annotation. Thus, extracting training data from video games is a practical idea, and pixel-wise annotation can be automated from video games with near perfect accuracy. However, experiments show that models trained using raw video-game data cannot be directly applied to real-world scenes because of the domain shift problem. In this paper, we propose a domain-adaptive network based on CycleGAN that translates scenes from a virtual domain to a real domain in both the pixel and feature spaces. Our contributions are threefold: 1) we propose a dynamic perceptual network to improve the quality of the generated images in the feature spaces, making the translated images are more conducive to semantic segmentation; 2) we introduce a novel weighted self-regularization loss to prevent semantic changes in translated images; and 3) we design a discrimination mechanism to coordinate multiple subnetworks and improve the overall training efficiency. We devise a series of metrics to evaluate the quality of translated images during our experiments on the public GTA-V (a video game dataset, i.e., the virtual domain) and Cityscapes (a real-world dataset, i.e., the real domain) and achieved notably improved results, demonstrating the efficacy of the proposed model.",smart cities
10.1016/j.psj.2019.10.015,Journal,Poultry Science,scopus,2020-06-01,sciencedirect,Cleaning and disinfection of crates and trucks used for duck transport: field observations during the H5N8 avian influenza outbreaks in France in 2017,https://api.elsevier.com/content/abstract/scopus_id/85084461250,"Transport of infected birds is thought to play a key role in the spread of avian influenza (AI) on poultry farms during epizootic outbreaks. Ensuring efficient cleaning and disinfection (C&D) of equipment used for transport is needed to prevent the spread of AI. This study aimed to evaluate the efficacy against the AI virus of C&D protocols applied on trucks and crates used for the transport of ducks during the H5N8 AI outbreaks in France in 2017. In 3 abattoirs, 16 transport vehicles and their crates were sampled by swabbing to detect the influenza type A genome by real-time reverse-transcription polymerase chain reaction. Vehicles were tested before and after decontamination, which was carried out in accordance with the abattoirs' protocols. A total of 86 samples out of 299 collected before C&D were positive for AI (29%); 7 trucks out of 16 transported crates detected positive for AI. After C&D, the AI genome was detected in 56 samples out of 308 (18%). Ten trucks were loaded with a shipment of AI-positive crates. Eight vehicles were detected positive in the cabin, on the truck bed, and/or on the wheels. Despite reinforcement of C&D, the efficacy of decontamination was variable among slaughterhouses. The efficacy seemed to depend on the initial contamination load, C&D protocols, and how the protocol is implemented. Breaks in biosecurity measures led to frequent contamination of trucks after C&D. Observational studies during animal health crises are of interest to analyze practices in emergency conditions and to put forward measures aimed at increased preparedness.",smart cities
10.1016/j.advwatres.2020.103600,Journal,Advances in Water Resources,scopus,2020-06-01,sciencedirect,Deep reinforcement learning for the real time control of stormwater systems,https://api.elsevier.com/content/abstract/scopus_id/85084420277,"A new generation of smart stormwater systems promises to reduce the need for new construction by enhancing the performance of the existing infrastructure through real-time control. Smart stormwater systems dynamically adapt their response to individual storms by controlling distributed assets, such as valves, gates, and pumps. This paper introduces a real-time control approach based on Reinforcement Learning (RL), which has emerged as a state-of-the-art methodology for autonomous control in the artificial intelligence community. Using a Deep Neural Network, a RL-based controller learns a control strategy by interacting with the system it controls - effectively trying various control strategies until converging on those that achieve a desired objective. This paper formulates and implements a RL algorithm for the real-time control of urban stormwater systems. This algorithm trains a RL agent to control valves in a distributed stormwater system across thousands of simulated storm scenarios, seeking to achieve water level and flow set-points in the system. The algorithm is first evaluated for the control of an individual stormwater basin, after which it is adapted to the control of multiple basins in a larger watershed (4 km
                     2). The results indicate that RL can very effectively control individual sites. Performance is highly sensitive to the reward formulation of the RL agent. Generally, more explicit guidance led to better control performance, and more rapid and stable convergence of the learning process. While the control of multiple distributed sites also shows promise in reducing flooding and peak flows, the complexity of controlling larger systems comes with a number of caveats. The RL controller’s performance is very sensitive to the formulation of the Deep Neural Network and requires a significant amount of computational resource to achieve a reasonable performance enhancement. Overall, the controlled system significantly outperforms the uncontrolled system, especially across storms of high intensity and duration. A frank discussion is provided, which should allow the benefits and drawbacks of RL to be considered when implementing it for the real-time control of stormwater systems. An open source implementation of the full simulation environment and control algorithms is also provided.",smart cities
10.1016/j.compbiomed.2020.103792,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,Automated detection of COVID-19 cases using deep neural networks with X-ray images,https://api.elsevier.com/content/abstract/scopus_id/85083900518,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (https://github.com/muhammedtalo/COVID-19)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.",smart cities
10.1016/j.atmosenv.2020.117451,Journal,Atmospheric Environment,scopus,2020-06-01,sciencedirect,Estimating ground-level PM<inf>2.5</inf> using micro-satellite images by a convolutional neural network and random forest approach,https://api.elsevier.com/content/abstract/scopus_id/85083652155,"PM2.5 poses a serious threat to public health, however its spatial concentrations are not well characterized due to the sparseness of regulatory air quality monitoring (AQM) stations. This motivates novel low-cost methods to estimate ground-level PM2.5 at a fine spatial resolution so that PM2.5 exposure in epidemiological research can be better quantified. Satellite-retrieved aerosol products are widely used to estimate the spatial distribution of ground-level PM2.5. However, these aerosol products can be subject to large uncertainties due to many approximations and assumptions made in multiple stages of their retrieval algorithms. Therefore, estimating ground-level PM2.5 directly from satellites (e.g. satellite images) by skipping the intermediate step of aerosol retrieval can potentially yield lower errors because it avoids retrieval error propagating into PM2.5 estimation and is desirable compared to current ground-level PM2.5 retrieval methods. Additionally, the spatial resolutions of estimated PM2.5 are usually constrained by those of the aerosol products and are currently largely at a comparatively coarse 1 km or greater resolution. Such coarse spatial resolutions are unable to support scientific studies that thrive on highly spatially-resolved PM2.5. These limitations have motivated us to devise a computer vision algorithm for estimating ground-level PM2.5 at a high spatiotemporal resolution by directly processing the global-coverage, daily, near real-time updated, 3 m/pixel resolution, three-band micro-satellite imagery of spatial coverages significantly smaller than 1 
                        ×
                      1 km (e.g., 200 
                        ×
                      200 m) available from Planet Labs. In this study, we employ a deep convolutional neural network (CNN) to process the imagery by extracting image features that characterize the day-to-day dynamic changes in the built environment and more importantly the image colors related to aerosol loading, and a random forest (RF) regressor to estimate PM2.5 based on the extracted image features along with meteorological conditions. We conducted the experiment on 35 AQM stations in Beijing over a period of ~3 years from 2017 to 2019. We trained our CNN-RF model on 10,400 available daily images of the AQM stations labeled with the corresponding ground-truth PM2.5 and evaluated the model performance on 2622 holdout images. Our model estimates ground-level PM2.5 accurately at a 200 m spatial resolution with a mean absolute error (MAE) as low as 10.1 μg m−3 (equivalent to 23.7% error) and Pearson and Spearman r scores up to 0.91 and 0.90, respectively. Our trained CNN from Beijing is then applied to Shanghai, a similar urban area. By quickly retraining only RF but not CNN on the new Shanghai imagery dataset, our model estimates Shanghai 10 AQM stations' PM2.5 accurately with a MAE and both Pearson and Spearman r scores of 7.7 μg m−3 (18.6% error) and 0.85, respectively. The finest 200 m spatial resolution of ground-level PM2.5 estimates from our model in this study is higher than the vast majority of existing state-of-the-art satellite-based PM2.5 retrieval methods. And our 200 m model's estimation performance is also at the high end of these state-of-the-art methods. Our results highlight the potential of augmenting existing spatial predictors of PM2.5 with high-resolution satellite imagery to enhance the spatial resolution of PM2.5 estimates for a wide range of applications, including pollutant emission hotspot determination, PM2.5 exposure assessment, and fusion of satellite remote sensing and low-cost air quality sensor network information.",smart cities
10.1016/j.trc.2020.102620,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-06-01,sciencedirect,Learning traffic as a graph: A gated graph wavelet recurrent neural network for network-scale traffic prediction,https://api.elsevier.com/content/abstract/scopus_id/85082964822,"Network-wide traffic forecasting is a critical component of modern intelligent transportation systems for urban traffic management and control. With the rise of artificial intelligence, many recent studies attempted to use deep neural networks to extract comprehensive features from traffic networks to enhance prediction performance, given the volume and variety of traffic data has been greatly increased. Considering that traffic status on a road segment is highly influenced by the upstream/downstream segments and nearby bottlenecks in the traffic network, extracting well-localized features from these neighboring segments is essential for a traffic prediction model. Although the convolution neural network or graph convolution neural network has been adopted to learn localized features from the complex geometric or topological structure of traffic networks, the lack of flexibility in the local-feature extraction process is still a big issue. Classical wavelet transform can detect sudden changes and peaks in temporal signals. Analogously, when extending to the graph/spectral domain, graph wavelet can concentrate more on key vertices in the graph and discriminatively extract localized features. In this study, to capture the complex spatial-temporal dependencies in network-wide traffic data, we learn the traffic network as a graph and propose a graph wavelet gated recurrent (GWGR) neural network. The graph wavelet is incorporated as a key component for extracting spatial features in the proposed model. A gated recurrent structure is employed to learn temporal dependencies in the sequence data. Comparing to baseline models, the proposed model can achieve state-of-the-art prediction performance and training efficiency on two real-world datasets. In addition, experiments show that the sparsity of graph wavelet weight matrices greatly increases the interpretability of GWGR.",smart cities
10.1016/j.aap.2020.105520,Journal,Accident Analysis and Prevention,scopus,2020-06-01,sciencedirect,A long short-term memory-based framework for crash detection on freeways with traffic data of different temporal resolutions,https://api.elsevier.com/content/abstract/scopus_id/85082833015,"Traffic crash detection is a major component of intelligent transportation systems. It can explore inner relationships between traffic conditions and crash risk, prevent potential crashes, and improve road safety. However, there exist some limitations in current studies on crash detection: (1) The commonly used machine learning methods cannot simulate the evolving transitions of traffic conditions before crash occurrences; (2) Current models collected traffic data of only one temporal resolution, which cannot fully represent traffic trends in different time intervals. Therefore, this study proposes a Long short-term memory (LSTM) based framework considering traffic data of different temporal resolutions (LSTMDTR) for crash detection. LSTM is an effective deep learning method to capture the long-term dependency and dynamic transitions of pre-crash conditions. Three LSTM networks considering traffic data of different temporal resolutions are constructed, which can comprehensively indicate traffic variations in different time intervals. A fully-connected layer is used to combine the outputs of three LSTM networks, and a dropout layer is used to reduce overfitting and improve prediction performance. The LSTMDTR model is implemented on datasets of I880-N and I805-N in California, America. The results indicate that the LSTMDTR model can obtain satisfactory performance on crash detection, with the highest crash accuracy of 70.43 %. LSTMDTR models constructed on one freeway can be transferred to other similar freeways, with 65.12 % of crash accuracy on transferability. Compared with machine learning methods and LSTM models with one or two temporal resolutions, the LSTMDTR model has been validated to perform better on crash detection and transferability. A proper number of neurons in the LSTMDTR model should be determined in real applications considering acceptable detection performance and computation time. The dropout technique can reduce overfitting and improve the generalization ability of the LSTMDTR model, increasing crash accuracy from 64.49 % to 70.43 %.",smart cities
10.1016/j.jnca.2020.102596,Journal,Journal of Network and Computer Applications,scopus,2020-06-01,sciencedirect,On the classification of fog computing applications: A machine learning perspective,https://api.elsevier.com/content/abstract/scopus_id/85082445495,"Currently, Internet applications running on mobile devices generate a massive amount of data that can be transmitted to a Cloud for processing. However, one fundamental limitation of a Cloud is the connectivity with end devices. Fog computing overcomes this limitation and supports the requirements of time-sensitive applications by distributing computation, communication, and storage services along the Cloud to Things (C2T) continuum, empowering potential new applications, such as smart cities, augmented reality (AR), and virtual reality (VR). However, the adoption of Fog-based computational resources and their integration with the Cloud introduces new challenges in resource management, which requires the implementation of new strategies to guarantee compliance with the quality of service (QoS) requirements of applications.
                  In this context, one major question is how to map the QoS requirements of applications on Fog and Cloud resources. One possible approach is to discriminate the applications arriving at the Fog into Classes of Service (CoS). This paper thus introduces a set of CoS for Fog applications which includes, the QoS requirements that best characterize these Fog applications. Moreover, this paper proposes the implementation of a typical machine learning classification methodology to discriminate Fog computing applications as a function of their QoS requirements. Furthermore, the application of this methodology is illustrated in the assessment of classifiers in terms of efficiency, accuracy, and robustness to noise. The adoption of a methodology for machine learning-based classification constitutes a first step towards the definition of QoS provisioning mechanisms in Fog computing. Moreover, classifying Fog computing applications can facilitate the decision-making process for Fog scheduler.",smart cities
10.1016/j.scitotenv.2020.137459,Journal,Science of the Total Environment,scopus,2020-06-01,sciencedirect,NO<inf>x</inf> removal efficiency of urban photocatalytic pavements at pilot scale,https://api.elsevier.com/content/abstract/scopus_id/85081197829,"Photocatalytic technology implemented in construction materials is a promising solution to contribute to alleviate air quality issues found in big cities. Photocatalysis has been proved able to mineralise most harmful contaminants. However, important problems associated with monitoring the efficiency of these solutions under real conditions still remain, including the lack of affordable analytical tools to measure NOx concentrations with enough accuracy. In this work, two pilot scale demonstration platforms were built at two different locations to assess the photocatalytic NOX removal efficiency of ten selected materials exposed outdoors for AQmesh low-cost sensor PODs were used to measure ground-level to measure NO and NO2 concentrations during nearly one year. The pollutant removal efficiency of the materials was then calculated based on a comparison with simultaneously concentration measurements carried-out on reference, non-active materials. It was found that the NO2 removal efficiency presented large variations across the seasons, with maxima during the warmer months, while NO efficiencies were comparatively steadier. Statistical analysis delivered evidence that the efficiencies significantly depend on different meteorological variables (irradiance and relative humidity) besides NO, NO2 ambient concentrations. Lower efficiencies were observed for higher concentration levels and vice versa. The influence of water vapour could be related to two different effects: a short-term contribution by the instantaneous air humidity and a long-term component associated with the hygroscopic state of the material. The contribution of wind to the pollutant removal efficiencies was principally related to the humidity of air masses moving above the location and to the advection of pollutants from specific emission sources.",smart cities
10.1016/j.asoc.2020.106123,Journal,Applied Soft Computing Journal,scopus,2020-06-01,sciencedirect,Dynamic ensemble mechanisms to improve particulate matter forecasting,https://api.elsevier.com/content/abstract/scopus_id/85080929358,"Respirable solid particles and liquid droplets suspended in the air, known as particulate matter (PM), may have a significant impact on human health, urban infrastructure, and natural and agricultural systems. The adverse effects of PM have raised public concern, especially in heavily polluted areas in the world, making it imperative the development of strategies to keep the concentration levels of these pollutants below harmful thresholds. Traditional machine learning approaches have been used to forecast PM concentrations. However, complex chemical processes may be involved in the composition of PM in the atmosphere and influenced by many meteorological parameters. Thus, underlying data distributions of PM data, uninterruptedly collected, may evolve over time. This phenomenon, known as concept drift, implies an important challenge for traditional machine learning techniques since they do not have mechanisms to handle changes on data distribution at the running time, thus limiting their forecasting capabilities. The overall goal of this work is to evaluate whether the incorporation of mechanisms to deal with concept drift, together with online sequential learning approaches, can improve the accuracy of PM forecasting. To do so, new mechanisms that enable online dynamic ensembles to handle and retain knowledge from different concepts for more time were proposed and adapted to EOS and DOER algorithms, resulting in three approaches: EOS-rank, EOS-D and DOER-rank. These ensemble strategies, which were based on Online Sequential Extreme Learning Machines (OS-ELM), were compared with five algorithms from the literature. To evaluate their performance, real-world and artificial datasets, with known dynamic behaviors, and PM concentration datasets from different cities of the State of São Paulo, Brazil, were used in the experiments. The obtained results showed that the proposed approaches can handle dynamic environments with different rates of drift and that EOS-rank was capable of outperforming most approaches from the literature in scenarios with higher rates of drift. The results also indicate that PM data distributions slowly evolve over time and, consequently, the proposed mechanisms that keep information of past concepts and slowly adapt the ensemble tend to present better results when applied to forecast PM concentration.",smart cities
10.1016/j.ins.2020.01.043,Journal,Information Sciences,scopus,2020-06-01,sciencedirect,Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting,https://api.elsevier.com/content/abstract/scopus_id/85080078627,"Accurate and real-time traffic passenger flows forecasting at transportation hubs, such as subway/bus stations, is a practical application and of great significance for urban traffic planning, control, guidance, etc. Recently deep learning based methods are promised to learn the spatial-temporal features from high non-linearity and complexity of traffic flows. However, it is still very challenging to handle so much complex factors including the urban transportation network topological structures and the laws of traffic flows with spatial and temporal dependencies. Considering both the static hybrid urban transportation network structures and dynamic spatial-temporal relationships among stations from historical traffic passenger flows, a more effective and fine-grained spatial-temporal features learning framework is necessary. In this paper, we propose a novel spatial-temporal incidence dynamic graph neural networks framework for urban traffic passenger flows prediction. We first model dynamic traffic station relationships over time as spatial-temporal incidence dynamic graph structures based on historically traffic passenger flows. Then we design a novel dynamic graph recurrent convolutional neural network, namely Dynamic-GRCNN, to learn the spatial-temporal features representation for urban transportation network topological structures and transportation hubs. To fully utilize the historical passenger flows, we sample the short-term, medium-term and long-term historical traffic data in training, which can capture the periodicity and trend of the traffic passenger flows at different stations. We conduct extensive experiments on different types of traffic passenger flows datasets including subway, taxi and bus flows in Beijing. The results show that the proposed Dynamic-GRCNN effectively captures comprehensive spatial-temporal correlations significantly and outperforms both traditional and deep learning based urban traffic passenger flows prediction methods.",smart cities
10.1016/j.neucom.2019.07.103,Journal,Neurocomputing,scopus,2020-05-21,sciencedirect,Visual Recognition of traffic police gestures with convolutional pose machine and handcrafted features,https://api.elsevier.com/content/abstract/scopus_id/85074513481,"Autonomous vehicles have become a hot spot of the automotive industry, many cities have claimed that autonomous vehicles should be capable of recognizing gestures used by traffic police. Traditional traffic police gesture recognition methods rely on depth-sensor or wearable-devices, which limits their availability in the domain of the intelligent vehicle. Vision-based methods have fewer requirements for distance, but the modeling process is challenging due to the complexity of the visual scenes. Inspired by the recent success in vision-based pose estimation networks such as Convolutional Pose Machine (CPM), in this paper, we propose a novel vision-based human-machine interface to recognize eight kinds of Chinese traffic police gestures and apply it in the real-time recognition tasks. This method integrates a modified CPM network and two kinds of handcrafted features: Relative Bone Length and Angle with Gravity as spatial domain features, and adopt a Long short-term memory (LSTM) network to extract temporal domain features. To train and validate our method, we create a gestures dataset with two hours of traffic police gesture videos, which has 3354 gesture instances. The experiment results show that the proposed method is capable of recognizing traffic police gestures, and is fast enough for online gesture prediction.",smart cities
10.1016/j.scs.2020.102091,Journal,Sustainable Cities and Society,scopus,2020-05-01,sciencedirect,A novel hybrid modelling structure fabricated by using Takagi-Sugeno fuzzy to forecast HVAC systems energy demand in real-time for Basra city,https://api.elsevier.com/content/abstract/scopus_id/85079685656,"the HVAC systems consume more than half of the total buildings energy demand, forecasting the cooling/heating load of the building is important to predict buildings energy demand. The energy assessment tools such as a model for forecasting building energy consumption is based on outdoor thermal conditions, the outdoor conditions are highly nonlinear in real life cannot be represented by linear differential equations and have an uncertain disturbance nature. This paper contrives a novel nonlinear model structure to cope with such difficulty, which is composed of two hybrid nonlinear forms, Takagi-Sugeno fuzzy system (TS-FS) and Neural Networks’ Weights. Such a structure has many advantages, including suitability for multi-layer implementations like an integrated eight-dimension net of parameters and weights which represents model input-output relations of a nonlinear system. The Gauss-Newton algorithm is used to tune model weights and parameters for the fitting of nonlinear regression of clusters model to data. The main feature of the proposed model is to express the dynamic conditions of the outdoor thermal environment of each fuzzy implication by a cluster functions model and thus promote the prediction performance. The overall proposed model is tested on the training and validation of multizone then compared with the RLF model. The corresponding results show that a better hybrid modelling and uncertainty mitigation which is achieved without significant loss of prediction accuracy.",smart cities
10.1016/j.simpat.2019.102013,Journal,Simulation Modelling Practice and Theory,scopus,2020-05-01,sciencedirect,Using cloud and fog computing for large scale IoT-based urban sound classification,https://api.elsevier.com/content/abstract/scopus_id/85073835710,"The Internet of Things (IoT) has become the forefront of bridging different technologies together. It brings rise to online computational services that make mundane tasks convenient. However, the volume of devices connecting to the network started to increase. In turn, services that thrived on centralized storage are being strained and overloaded. As applications and software advances, processing and computational power become a concern to technology companies. With data risks and large numbers of connected devices, cloud computing has become outdated. Devices are forced to commit unnecessary expenses to stay relevant in the market due to the increase in software complexity. This need for change resulted in the introduction of edge computing. Edge computing distributes the computational strain between the server and the devices. This contribution allows the cloud to accommodate more users and devices are no longer in need to make significant changes to their design every so often. Many real-time applications have evolved to require high amounts of processing power to execute. For example, sound classification comes with massive computational needs due to its affiliation with neural networks and deep learning. This paper aims to create a feasible and deployable real-time sound classification system. There were three configurations tested in this paper. The results of our experiments show that cloud computing and edge computing alone cannot cater to a technological market that is exponentially growing in size and complexity. However, the same results show promise in finding optimal configurations in terms of a combination of end device power consumption, application runtime and server latency to systems instead of focusing on a single model. Overall, it is better to take into consideration the strengths and weaknesses of each computing architecture. In finding a reasonable configuration balance, lower power consumption in end devices and lesser computational strain on cloud servers is a must.",smart cities
10.1016/j.apenergy.2020.114680,Journal,Applied Energy,scopus,2020-04-15,sciencedirect,Household standards and socio-economic aspects as a factor determining energy consumption in the city,https://api.elsevier.com/content/abstract/scopus_id/85079833073,"Political or economic attempts to mitigate climate change by increasing fossil fuel prices lead to and an increase in energy poverty, i.e., social effects. The ideal solution would be to combine modernisation activities in terms of energy use in cities with sustainable strategies and redevelopment policies. The article's purpose is to estimate the potential for reducing energy consumption depending on socioeconomic factors (household standard and its location in the city) based on built-in scenarios and searching for the optimal way of conducting development policy at the local level. This assumption enables the implementation of the European Union climate policy. To this aim, modelling based on real and estimated data on the diversity of energy consumption in the structure of a medium-sized city in Europe (Zielona Góra) carried out. While creating scenarios, there used a modelling method based on radial artificial neural networks, which map the input set into the output set by matching many individual approximating functions to setpoints. This approach works well for data whose geolocation is in the city quarters. As a result of the simulations, the minimum and maximum achievable energy saving potential for low-intensity buildings in the quarters was estimated, taking into account the possibilities of investing in renewable energy by individual households. The observations included in the article may be relevant to other regions that are interested in reducing the energy consumption of buildings and pollution emissions from the cities. This is particularly important for the regions of Europe that benefit from the financial support of the European Union (including local development programmes based on financing European priority axes for economic development).",smart cities
10.1016/j.foodcont.2019.107016,Journal,Food Control,scopus,2020-04-01,sciencedirect,Improving efficiency of RFID-based traceability system for perishable food by utilizing IoT sensors and machine learning model,https://api.elsevier.com/content/abstract/scopus_id/85075906850,"Radio Frequency Identification (RFID) technology has significantly improved in the past few years and is presently sought for implementation in the identification and traceability of perishable food in the food sector to safeguard food safety and quality. It is currently considered a worthy successor to the barcode system and has significant advantages for monitoring products in the perishable food supply chain (PFSC). The present study proposes a traceability system that utilizes RFID and Internet of Things (IoT) sensors. RFID technology can be used to track and trace perishable food while IoT sensors can be used to measure temperature and humidity during storage and transportation. Furthermore, it is important that RFID gates can identify the direction of tags and whether products are being received or shipped through the gate. In this study, machine-learning models are utilized to detect the direction of passive RFID tags. The input features are derived from receive signal strength (RSS) and the timestamp of tags. The proposed system has been tested in the perishable food supply chain and has revealed significant benefits to managers and customers by providing real-time product information and complete temperature and humidity history. In addition, by integrating a machine-learning model into the RFID gate, tagged products that move in or out through a gate can be correctly identified and thus improve the efficiency of the traceability system.",smart cities
10.1016/j.techfore.2018.03.024,Journal,Technological Forecasting and Social Change,scopus,2020-04-01,sciencedirect,Big data analytics: Computational intelligence techniques and application areas,https://api.elsevier.com/content/abstract/scopus_id/85044950715,"Big Data has significant impact in developing functional smart cities and supporting modern societies. In this paper, we investigate the importance of Big Data in modern life and economy, and discuss challenges arising from Big Data utilization. Different computational intelligence techniques have been considered as tools for Big Data analytics. We also explore the powerful combination of Big Data and Computational Intelligence (CI) and identify a number of areas, where novel applications in real world smart city problems can be developed by utilizing these powerful tools and techniques. We present a case study for intelligent transportation in the context of a smart city, and a novel data modelling methodology based on a biologically inspired universal generative modelling approach called Hierarchical Spatial-Temporal State Machine (HSTSM). We further discuss various implications of policy, protection, valuation and commercialization related to Big Data, its applications and deployment.",smart cities
10.1016/j.jbiomech.2019.109513,Journal,Journal of Biomechanics,scopus,2020-03-26,sciencedirect,Real-time feedback to reduce low-back load in lifting and lowering,https://api.elsevier.com/content/abstract/scopus_id/85075972424,"Low-back pain (LBP) is a common health problem. Literature indicates an exposure-response relation between work-related lifting and LBP. Therefore, this study investigated effects of three kinds of real-time feedback on low-back load, quantified as lumbar moments, during lifting. We recruited 97 healthy male and female participants without a recent history of LBP and without prior biomechanical knowledge on lifting. Participants were assigned to groups based on the time of enrollment, filling the four groups in the following order: moment feedback, trunk inclination angle feedback, lumbar flexion feedback, and a control group not receiving feedback. Feedback was given by a sound when a threshold level of the input variable was exceeded. Participants were unaware of the input variable for the feedback, but were instructed to try to avoid the audio feedback by changing their lifting strategy. The groups with feedback were able to reduce the audio feedback and thus changed the input variable towards a more desired level. Lumbar moments significantly decreased over trials in the inclination and moment feedback groups, remained similar in the lumbar flexion group and increased in the control group. Between group comparisons revealed that low-back load was significantly lower in the moment and inclination groups compared to the control group. Additionally, moments were lower in the inclination group than in the lumbar flexion group. Real-time feedback on moments or trunk inclination is a promising tool to reduce low-back load during lifting and lowering.",smart cities
10.1016/j.jmmm.2019.166206,Journal,Journal of Magnetism and Magnetic Materials,scopus,2020-03-15,sciencedirect,Simultaneous Magnetic Particle Imaging and Navigation of large superparamagnetic nanoparticles in bifurcation flow experiments,https://api.elsevier.com/content/abstract/scopus_id/85075955999,"Magnetic Particle Imaging (MPI) has been successfully used to visualize the distribution of superparamagnetic nanoparticles within 3D volumes with high sensitivity in real time. Since the magnetic field topology of MPI scanners is well suited for applying magnetic forces on particles and micron-sized ferromagnetic devices, MPI has been recently used to navigate micron-sized particles and micron-sized swimmers. In this work, we analyze the magnetophoretic mobility and the imaging performance of two different particle types for Magnetic Particle Imaging/Navigation (MPIN). MPIN constantly switches between imaging and magnetic modes, enabling quasi-simultaneous navigation and imaging of particles. We determine the limiting flow velocity to be 8.18 mL s−1 using a flow bifurcation experiment, that allows all particles to flow only through one branch of the bifurcation. Furthermore, we have succeeded in navigating the particles through the branch of a bifurcation phantom narrowed by either 60% or 100% stenosis, while imaging their accumulation on the stenosis. The particles in combination with therapeutic substances have a high potential for targeted drug delivery and could help to reduce the dose and improve the efficacy of the drug, e.g. for specific tumor therapy and ischemic stroke therapy.",smart cities
10.1016/j.eswa.2019.112975,Journal,Expert Systems with Applications,scopus,2020-03-15,sciencedirect,Wildfire detection using transfer learning on augmented datasets,https://api.elsevier.com/content/abstract/scopus_id/85073573447,"Wildfire detection is a time-critical application as the difficulty to pinpoint ignition locations in a short time-frame often leads to the escalation of the severity of fire events. This problem has motivated considerable interest from expert systems research to develop accurate early-warning applications and the breakthroughs in deep learning in complex visual understanding tasks open novel research opportunities. However, despite the improvements in performance demonstrated in the current literature, a comprehensive study of the challenges and limitations of this approach is still a gap in the state-of-the-art. To address this issue, the contributions of this work are threefold. First, we overview recent works to identify common difficulties and shortcomings of these approaches, and assess issues related to the quality of the databases. Second, to overcome data limitations, this work proposes a transfer learning approach coupled with data augmentation techniques tested under a tenfold cross-validation scheme. The proposed framework enables leveraging an open-source dataset featuring images from more than 35 real fire events, which unlike video-based works offers higher variability between samples, allowing evaluating the approach in an extensive set of real scenarios. Third, this article presents an in-depth study of the limitations, providing a comprehensive analysis of the patterns causing misclassifications. The key insights gained in this analysis provide relevant takeaways to guide future research towards the implementation of expert systems in decision support systems in firefighting and civil protection operations.",smart cities
10.1016/j.taml.2020.01.023,Journal,Theoretical and Applied Mechanics Letters,scopus,2020-03-01,sciencedirect,Deep density estimation via invertible block-triangular mapping,https://api.elsevier.com/content/abstract/scopus_id/85091900518,"In this work, we develop an invertible transport map, called KRnet, for density estimation by coupling the Knothe–Rosenblatt (KR) rearrangement and the flow-based generative model, which generalizes the real-valued non-volume preserving (real NVP) model (arX-iv:1605.08803v3). The triangular structure of the KR rearrangement breaks the symmetry of the real NVP in terms of the exchange of information between dimensions, which not only accelerates the training process but also improves the accuracy significantly. We have also introduced several new layers into the generative model to improve both robustness and effectiveness, including a reformulated affine coupling layer, a rotation layer and a component-wise nonlinear invertible layer. The KRnet can be used for both density estimation and sample generation especially when the dimensionality is relatively high. Numerical experiments have been presented to demonstrate the performance of KRnet.",smart cities
10.1016/j.comcom.2020.02.009,Journal,Computer Communications,scopus,2020-03-01,sciencedirect,UAV monitoring and forecasting model in intelligent traffic oriented applications,https://api.elsevier.com/content/abstract/scopus_id/85079351564,"Intelligent transportation system is a traffic management system developed with the progress of society and traffic. Its idea is to integrate the real-time operation of people, vehicles, roads and traffic involved in the traffic. The purpose of this paper is to build a safe, reliable and efficient vehicle monitoring and forecasting model for IOT. Based on the Beidou satellite positioning technology and Lora communication technology, aiming at the problem that the deep learning detection method cannot meet the real-time requirements in processing the monitoring video, this paper proposes a method of using multiple single target trackers instead of some yolov3 detection tasks, and puts forward the design idea and specific implementation scheme of the vehicle monitoring and prediction model. The vehicle monitoring and prediction model is used to detect four kinds of targets, namely, small cars, buses, trucks and pedestrians. The multi-target trajectory tracking is used to carry out the traffic statistics of multi vehicle types, the detection of two kinds of abnormal behaviors of traffic targets is low speed and parking, and the capture of pedestrians. The experimental results show that the vehicle monitoring and prediction model has the highest accuracy of location and type recognition for four types of traffic objects, namely, small cars, trucks, buses and pedestrians, reaching 80%.",smart cities
10.1016/j.ins.2019.10.071,Journal,Information Sciences,scopus,2020-03-01,sciencedirect,A spatiotemporal attention mechanism-based model for multi-step citywide passenger demand prediction,https://api.elsevier.com/content/abstract/scopus_id/85075531584,"In taxi dispatch systems, predicting citywide passenger pickup/dropoff demand is indispensable for developing effective taxi distribution and scheduling strategies to resolve the demand-service mismatch. Compared with predicting next-step only, predicting multiple steps is preferable since it can provide a long term view, thus preventing short-sighted strategies. However, multi-step citywide passenger demand prediction (MsCPDP) is challenging due to the complicated spatiotemporal correlations in the distribution of passenger demand and the lack of ground truth from pre-steps for the prediction of subsequent steps. In this paper, a deep-learning-based prediction model with spatiotemporal attention mechanism is proposed for MsCPDP. The model, called ST-Attn, follows the general encoder-decoder framework for modelling sequential data but adopts a multiple-output strategy without recurrent neural network units. The spatiotemporal attention mechanism learns to determine the focus on those parts of the city at certain periods that are more relevant to the passenger demand in the predicted region and time period. In addition, a pre-predicted result calculated by spatiotemporal kernel density estimation is fed to ST-Attn, which provides a reference for further accurate prediction. Experiments on three real-world datasets are carried out to verify ST-Attn’s performance, and the results show that ST-Attn outperforms the baselines in terms of MsCPDP.",smart cities
10.1016/j.comcom.2020.01.050,Journal,Computer Communications,scopus,2020-02-15,sciencedirect,Deep learning-based intelligent face recognition in IoT-cloud environment,https://api.elsevier.com/content/abstract/scopus_id/85078483384,"In recent years, the Internet-of-Things (IoT) technology is being used in many application areas such as healthcare, video surveillance, transportation etc. The massive adoption and growth of IoT in these areas are generating a massive amount of data. For example, IoT devices such as cameras are generating a huge amount of images when used in hospital surveillance scenarios. Here, face recognition is an important element that can be used for securing hospital facilities, emotion detection and sentiment analysis of patients, detecting patient fraud, and hospital traffic pattern analysis. Automatic and intelligent face recognition systems have high accuracy in a controlled environment; however, they have low accuracy in an uncontrolled environment. Also, the systems need to operate in real-time in many applications such as smart healthcare. This paper suggests a tree-based deep model for automatic face recognition in a cloud environment. The proposed deep model is computationally less expensive without compromising the accuracy. In the model, an input volume is split into several volumes, where a tree is constructed for each volume. A tree is defined by its branching factor and height. Each branch is represented by a residual function, which is constituted by a convolutional layer, a batch normalization, and a non-linear function. The proposed model is evaluated in various publicly available databases. A comparison of performance is also done with state-of-the-art deep models for face recognition. The results of the experiments demonstrate that the proposed model achieved accuracies of 98.65%, 99.19%, 95.84% on FEI, ORL, and LFW databases, respectively.",smart cities
10.1016/j.aap.2019.105371,Journal,Accident Analysis and Prevention,scopus,2020-02-01,sciencedirect,Real-time crash risk prediction on arterials based on LSTM-CNN,https://api.elsevier.com/content/abstract/scopus_id/85075499681,"Real-time crash risk prediction is expected to play a crucial role in preventing traffic accidents. However, most existing studies only focus on freeways rather than urban arterials. This paper proposes a real-time crash risk prediction model on arterials using a long short-term memory convolutional neural network (LSTM-CNN). This model can explicitly learn from the various features, such as traffic flow characteristics, signal timing, and weather conditions. Specifically, LSTM captures the long-term dependency while CNN extracts the time-invariant features. The synthetic minority over-sampling technique (SMOTE) is used for resampling the training dataset. Five common models are developed to compare the results with the proposed model, such as the XGBoost, Bayesian Logistics Regression, LSTM, etc. Experiments suggest that the proposed model outperforms others in terms of Area Under the Curve (AUC) value, sensitivity, and false alarm rate. The findings of this paper indicate the promising performance of using LSTM-CNN to predict real-time crash risk on arterials.",smart cities
10.1016/j.rvsc.2019.10.018,Journal,Research in Veterinary Science,scopus,2020-02-01,sciencedirect,Characterization of a chymotrypsin-like enzyme from Trichinella spiralis and its facilitation of larva penetration into the host's enteral epithelial cells,https://api.elsevier.com/content/abstract/scopus_id/85074405144,"The aim of this work was to identify the molecular characteristics of a chymotrypsin-like enzyme from Trichinella spiralis (Tschy) and its facilitation of larval penetration into enteral epithelial cells (EECs). The complete Tschy cDNA sequence was cloned and expressed in Escherichia coli BL21. RT-PCR, IIFA and western blotting showed that Tschy was expressed at the T. spiralis muscle larvae (ML), intestinal infective L1 larvae (IL1), adult worms (AW) and embryo stages and was primarily located in the stichosome of this parasite. The results of ELISA, IIFA and Far-western assays showed that there was a specific binding between rTschy and EECs, and the binding was dependent on the dose of both rTschy and EEC proteins. Confocal microscopy demonstrated that the binding was located in the EEC cytoplasm. rTschy facilitated T. spiralis larval penetration of EECs, and anti-rTschy antibodies impeded the larval intrusion of EECs. These results demonstrate that Tschy facilitated the larval intrusion of the host's enteral epithelium and could be a candidate molecular target for vaccine against the enteral invasive phase of T. spiralis.",smart cities
10.1016/j.bspc.2019.101701,Journal,Biomedical Signal Processing and Control,scopus,2020-02-01,sciencedirect,Unsupervised automatic online spike sorting using reward-based online clustering,https://api.elsevier.com/content/abstract/scopus_id/85073983688,"Brain-machine interfaces (BMIs) can enable paralyzed people to regain mobility. In these interfaces, some different type of signals can be obtained from the brain, one of which is the action potential waveform (spike). In the case of using spikes, sorting the recorded signals and isolating the effects of the individual neurons can lead to a greater efficiency. Also, because of the nature of BMIs, real-time spike sorting is necessary. In many spike sorting approaches, the main outline consists of the following steps: spike detection, feature extraction, and clustering. In this study, a novel method for clustering is presented. This method is referred to as Reward-Based Online Clustering (RBOC) which is formed based on the reinforcement learning algorithm. The significant property of this proposed technique is its capability for real-time implementation that is required by BMIs. This method can automatically detect the clusters while there is no knowledge about the number of clusters. The performance of the proposed method is demonstrated through both simulation and experimental study. Evaluation with artificially simulated (ground truth) data shows that, on average, the accuracy of categorizing the spikes from the same origins is above 94 percent. Moreover, implementation of the method on the experimental data obtained from the rat brain represents convincing sorting results. It is noteworthy to say that, in most cases, this new method outperforms the results of similar previous works.",smart cities
10.1016/j.jclepro.2019.118788,Journal,Journal of Cleaner Production,scopus,2020-01-20,sciencedirect,Rapid evaluation of micro-scale photovoltaic solar energy systems using empirical methods combined with deep learning neural networks to support systems’ manufacturers,https://api.elsevier.com/content/abstract/scopus_id/85073926377,"Solar energy is becoming one of the most attractive renewable sources. In many cases, due to a wide range of financial or installation limitations, off-grid small scale micro power panels are favoured as modular systems to power lighting in gardens or to be integrated together to power small devices such as mobile phone chargers and distributed smart city facilities and services. Manufacturers and systems’ integrators have a wide range of options of micro-scale photo voltaic panels to choose from. This makes the selection of the right panel a challenging task and risky investment. To address this and to help manufacturers, this paper suggests and evaluates a novel approach based on integrating empirical lab-testing with short-term real data and neural networks to assess the performance of micro-scale photovoltaic panels and their suitability for a specific application in specific environment. The paper outlines the combination of lab testing power output under seasonal and hourly conditions during the year combined with environmental and operating conditions such as temperature, dust accumulation and tilt angle performance. Based on the lab results, a short in-situ experimental work is implemented and the performance over the year in the selected location in Kuwait is evaluated using deep learning neural networks. The findings of this approach are compared with simulation and long-term real data. The results show a maximum error of 23% of the neural network output when compared with the actual data, and a correlation values with previous work within 87.3% and 91.9% which indicate that the proposed approach could provide an experimental rapid and accurate assessment of the expected power output. Hence, supporting the rapid decision-making process for manufacturers and reducing investment risks.",smart cities
10.1016/j.comnet.2019.106980,Journal,Computer Networks,scopus,2020-01-15,sciencedirect,Machine learning-driven service function chain placement and scaling in MEC-enabled 5G networks,https://api.elsevier.com/content/abstract/scopus_id/85074699825,"5G mobile network technology promises to deliver unprecedented ultra-low latency and high data rates, paving the way for many novel applications and services. Network Function Virtualization (NFV) and Multi-access Edge Computing (MEC) are two of the technologies that are expected to play a pivotal role in 5G to achieve ambitious Quality of Service requirements of such applications. While NFV provides flexibility by enabling network functions to be dynamically deployed and inter-connected to realize Service Function Chains (SFC), MEC brings the computing capability to the edges of the mobile network thus reducing latency and alleviating the transport network load. However, adequate mechanisms are needed to meet the dynamically changing network service demands, to optimally utilize the network resources while, at the same time, making sure that the end-to-end latency requirement of services is always satisfied.
                  In this work, we first propose machine learning models, in particular neural-networks, that can perform auto-scaling by predicting the required number of virtual network function instances based on the traffic demand, using the traffic traces collected over a real-operator commercial network. We then employ Integer Linear Programming (ILP) techniques to formulate and solve a joint user association and SFC placement problem, where each SFC represents a service requested by a user with end-to-end latency and data rate requirements. Finally, we propose a heuristic to address the scalability concern of the ILP model.",smart cities
10.1016/j.ifacol.2021.04.197,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Cognitive Artificial Population System: Framework and Application,https://api.elsevier.com/content/abstract/scopus_id/85107879835,"Agent-based social simulation has been comprehensively applied in the research of social and ecological systems. At its core is an artificial population, which endogenously drives the system evolution for particular applications, such as urban transportation, reginal economics, analysis of infectious disease transmission, and military simulation. In contrast with the previous population simulations where simple mathematical models are used to ‘reproduce’ actual demographic features, this paper proposes a self-evolutionary digital population system, named as Cognitive Artificial Population System (CAPS). At a more fine-grained level, CAPS focuses on the agent cognitive, reasoning and learning process in their surrounding environment, thus can exploit most advantages from cognitive computing and Artificial Intelligence. As a case study, Chinese population evolution is implemented using the proposed framework. Computational experiments indicate that CAPS is able to achieve good predicted population structures for real social systems.",smart cities
10.1016/j.ifacol.2020.12.1161,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Real-time classification of road type and condition in passenger vehicles,https://api.elsevier.com/content/abstract/scopus_id/85105047362,"Modern vehicles are equipped with numerous sensors and hence offer an increasing degree of environmental perception. In this work, a method is presented that is able to classify different road types and their conditions based on standard vehicle sensors. Therefore, training and validation data on two routes in urban traffic and on federal highways was gathered using a Volkswagen Golf GTE Plug-In Hybrid. The method uses features based on both frequency and time domain extended with a physical vehicle sub-model. For the classification a decision tree model is trained offline and implemented for online use on target hardware commonly used in modern vehicles. A Bayesian and Markov based filter is used to smooth the output and increase the accuracy of the classification.
                  Since the method is based on sensors that are available in modern vehicles, there is no need for additional hardware, reducing the effort required for implementation. Results show promising classification performance, especially for classifying cobblestone. The three classes of good, medium and bad asphalt labeled relatively precise despite very similar characteristics. Possible applications of the approach could be to adapt vehicles suspension and driving dynamics, to parameterize driver assistance systems, or to update road maps according to their current condition.",smart cities
10.1016/j.glt.2020.09.004,Journal,Global Transitions,scopus,2020-01-01,sciencedirect,Development of an IoT based real-time traffic monitoring system for city governance,https://api.elsevier.com/content/abstract/scopus_id/85102077498,"A significant amount of research work carried out on traffic management systems, but intelligent traffic monitoring is still an active research topic due to the emerging technologies such as the Internet of Things (IoT) and Artificial Intelligence (AI). The integration of these technologies will facilitate the techniques for better decision making and achieve urban growth. However, the existing traffic prediction methods mostly dedicated to highway and urban traffic management, and limited studies focused on collector roads and closed campuses. Besides, reaching out to the public, and establishing active connections to assist them in decision-making is challenging when the users are not equipped with any smart devices. This research proposes an IoT based system model to collect, process, and store real-time traffic data for such a scenario. The objective is to provide real-time traffic updates on traffic congestion and unusual traffic incidents through roadside message units and thereby improve mobility. These early-warning messages will help citizens to save their time, especially during peak hours. Also, the system broadcasts the traffic updates from the administrative authorities. A prototype is implemented to evaluate the feasibility of the model, and the results of the experiments show good accuracy in vehicle detection and a low relative error in road occupancy estimation. The study is part of the Omani-funded research project, investigating Real-Time Feedback for Adaptive Traffic Signals.",smart cities
10.1016/j.procs.2020.10.020,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Road traffic forecasting using a real data set in Morocco,https://api.elsevier.com/content/abstract/scopus_id/85099880129,"Traffic forecasting is a research topic debated by several researchers affiliated to a range of disciplines. It is becoming increasingly important given the growth of motorized vehicles on the one hand, and the scarcity of lands for new transportation infrastructure on the other. In this context, the ability to provide highly accurate traffic forecasts is of fundamental importance to manage traffic, especially in the context of smart cities. This work is in line with this perspective and aims to solve this problem. The proposed methodology plans to forecast day-by-day traffic stream using three different models: the Multilayer Perceptron of Artificial Neural Networks (ANN), the Seasonal Autoregressive Integrated Moving Average (SARIMA) and the Support Machine Regression (SMOreg). Using those three models, the forecast is realized based on a history of real traffic data recorded on a road section over 42 months. Besides, a recognized traffic manager in Morocco provides this dataset; the performance is then tested based on predefined criteria. From the experiment results, it is clear that the proposed ANN model achieves highest prediction accuracy with the lowest absolute relative error of 0.57%.",smart cities
10.1016/j.micpro.2020.103491,Journal,Microprocessors and Microsystems,scopus,2020-01-01,sciencedirect,Distance music education course based on FPGA and wireless sensor,https://api.elsevier.com/content/abstract/scopus_id/85096611950,"Online music courses complement face-to-face learning and higher education in the face of the rapidly evolving technology and the Internet. The Master of College and Distance Education is available worldwide and offers online opportunities to pursue professional development at many universities, which is now online. Personal online courses are another option for music education in real time communication. In the previous method based on Deep learning and data mining for Distance Music Education Course. The existing method gives the technical challenge, over filtering, deployment challenges. The proposed method is based on FPGA (Field Programmable Gate Arrays) and Machine learning for Distance Music Education Course. The wireless sensor shows that there are different ways for adults to participate in online music training. Hence, the nature of online communication and interaction with teachers and students is different. There are requests. For practice-based or performance-based courses, practical issues such as low-quality audio and time delays may arise. Online learning offers flexibility and internationalization and has a strong ability to connect with many people. In this case, wireless sensors communicate our teachers look at it from a practical perspective, such as ease of transportation and payment. Further educational efforts also need to promote music and online distance education.",smart cities
10.1016/j.procs.2020.09.009,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Passenger BIBO detection with IoT support and machine learning techniques for intelligent transport systems,https://api.elsevier.com/content/abstract/scopus_id/85093365315,"The present article discusses the issue of automation of the CICO (Check-In/Check-Out) process for public transport fare collection systems, using modern tools forming part of the Internet of Things, such as Beacon and Smartphone. It describes the concept of an integrated passenger identification model applying machine learning technology in order to reduce or eliminate the risks associated with the incorrect classification of a smartphone user as a vehicle passenger. This will allow for the construction of an intelligent fare collection system, operating in the BIBO (Be-In/Be-Out) model, implementing the ""hands-free"" and ""pay-as-you-go"" approach. The article describes the architecture of the research environment, and the implementation of the elaborated model in the Bad.App4 proprietary solution. We also presented the complete process of concept verification under real-life conditions. Research results were described and supplemented with commentary.",smart cities
10.1016/j.matpr.2019.11.222,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Design of a robotic walking stick with mobility assistance control technology (MAVI) for visually impaired people,https://api.elsevier.com/content/abstract/scopus_id/85088581669,"The investigation of the present research is a new mechatronic system for a robotic unicycle staff that thanks to a meticulous analysis of the new technologies applied to assistance of technological mobility of people with visual disability as an orthopedic walking stick or a walker. We proceed to contribute with the design of a stick-type mechatronic system coupled to a differential traction platform that facilitates the mobilization of people with motor deficiency by giving them an assistance system to support in the march. It was verified that the design supports the maximum weight established in the parameters of 14[kg] It was shown that the walking stick can be used with people up to a weight of 93[kg]. The performance of the load cells with an experimental work cycle by incorporating an application in Android so the user has a feeling of immersion and to provide the possibility of interacting with the device, being able to establish between the user and the robotic staff a bidirectional transfer in real time of information. The findings of the research, multi-axis load cells will be implemented in the future with a control was applying neural networks to minimize the displacement error.",smart cities
10.1016/j.procs.2020.03.027,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Strategic zoning approach for urban areas: Towards a shared transportation system,https://api.elsevier.com/content/abstract/scopus_id/85085571988,"Investigating downstream freight demand is a prerequisite to accomplishing the overall strategic implementation of transportation systems. Machine learning has recently become widely applied in order to support decision-making in several logistic operational levels: travel/arrival time prediction, occupancy forecasting of logistic spaces, route optimization and so on. Nevertheless, strategic decision-making often overlooks flow tendencies forecasting. Targeting this perspective, the present paper aims at proposing an urban zoning approach based on time series forecasting of supply chain demand through clustering customers. To conduct our approach, we have selected a set of machine learning algorithms that are believed to be robust according to the literature and the achieved accuracy benchmarks. Considering real-life data-based computational results, a number of analytical insights are illustrated.",smart cities
10.1016/j.procs.2020.03.036,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Air Quality Forecasting using LSTM RNN and Wireless Sensor Networks,https://api.elsevier.com/content/abstract/scopus_id/85085553433,"In the past few decades, many urban areas around the world have suffered from severe air pollution and the health hazards that come with it, making gathering real-time air quality and air quality forecasting very important to take preventive and corrective measures. This paper proposes a scalable architecture to monitor and gather real-time air pollutant concentration data from various places and to use this data to forecast future air pollutant concentrations. Two sources are used to collect air quality data. The first being a wireless sensor network that gathers and sends pollutant concentrations to a server, with its sensor nodes deployed in various locations in Bengaluru city in South India. The second source is the real-time air quality data gathered and made available by the Government of India as a part of its Open Data initiative. Both sources provide average concentrations of various air pollutants on an hourly basis. Due to its proven track record of success with time-series data, a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) model was chosen to perform the task of air quality forecasting. This paper critically analyses the performance of the model in two regions that exhibit a significant difference in temporal variations in air quality. As these variations increase, the model suffers performance degradation necessitating adaptive modelling.",smart cities
10.1016/j.trpro.2020.03.110,Conference Proceeding,Transportation Research Procedia,scopus,2020-01-01,sciencedirect,Towards ensemble learning of traffic flows' spatiotemporal structure,https://api.elsevier.com/content/abstract/scopus_id/85084669748,"Short-term urban traffic forecasting is an important problem of transportation engineering. Many modern forecasting models utilise information about a spatiotemporal structure of traffic flows – relationships between flow characteristics at distant road links that appear with time delays. Accurate identification of this structure is critically important for models’ forecasting accuracy and interpretability. This paper proposes application of an ensemble learning technique for learning the spatiotemporal structure. The proposed ensemble combines three spatiotemporal feature filtering methods that are widely used in traffic modelling – travel time-based, which utilises information about road connectivity and travel times between road segments, cross-correlation-based, which uses the correlation structure of dependencies, and a graphical model-based, which discovers conditional relationships between traffic flows. The resulting ensemble is used for specification of features in the spatially regularised vector autoregressive model and applied to a real-world data set (Minneapolis, USA). Extensive experiments demonstrate promising results of the proposed ensemble learning in terms of model forecasting accuracy, robustness of estimated structures and parsimony of resulting model specifications.",smart cities
10.1016/j.trpro.2020.03.108,Conference Proceeding,Transportation Research Procedia,scopus,2020-01-01,sciencedirect,Estimating time of arrival of trains at level crossings for the provision of multimodal cooperative services,https://api.elsevier.com/content/abstract/scopus_id/85084662425,"While cooperative services have been almost fully deployed in the road sector and are already being implemented in various cities in Europe as a pre-requisite for the introduction of autonomous vehicles, few attempts have been made in the same direction for the rail sector. This study proposes a system that aims to improve safety and minimize risk in the meeting point between road and rail, known as level crossings, by monitoring the location of floating road vehicles via a mobile device application. A neural network predictive model for estimating time of arrival of trains is also utilized. The safety system has been implemented and tested under real life conditions in the city of Thessaloniki, Greece.",smart cities
10.1016/j.trpro.2020.03.079,Conference Proceeding,Transportation Research Procedia,scopus,2020-01-01,sciencedirect,A Comparison of Deep Learning Methods for Urban Traffic Forecasting using Floating Car Data,https://api.elsevier.com/content/abstract/scopus_id/85084648332,"Cities today must address the challenge of sustainable mobility, and traffic state forecasting plays a key role in mitigating traffic congestion in urban areas. For example, predicting path travel time is a crucial issue in navigation and route planning applications. Furthermore, the pervasive penetration of information and communication technologies makes floating car data an important source of real-time data for intelligent transportation system applications. This paper deals with the problem of forecasting urban traffic when floating car data is available. A comparison of four deep learning methods is presented to demonstrate the capabilities of the neural network approaches (recurrent and/or convolutional) in solving the traffic forecasting problem in an urban context. Different tests are proposed in order to not only evaluate the developed deep learning models, but also to analyze how the penetration rates of floating cars affect forecasting accuracy. The presented experiments were designed according to a microscopic traffic simulation approach in order to emulate floating car data fleets, which provide vehicle position and speed, and to validate the obtained results. Finally, some conclusions and further research are presented.",smart cities
10.1016/j.procs.2020.03.362,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Reliability Analysis of Wireless Link for IOT Applications under Shadow-Fading Conditions,https://api.elsevier.com/content/abstract/scopus_id/85084426440,"Sensor nodes in IoT applications exhibit limited computing power, communication range and energy resource. These are some of the major constraints in the deployment of these systems. This leads to a multivariable optimization problem. Further, the variations in geographic conditions such as ground, terrain, atmosphere and mobility between various nodes introduces severe randomness in received signal strength at particular nodes. To mitigate this random nature of wireless link, probabilistic channel models are explored and analyzed. For more realistic estimation, multiple factors such as fading, shadowing, interference and noise must be considered simultaneously. In this paper, the reliability of wireless link in such environment is analyzed by capturing effect of these parameters through compound probability distributions. Expressions for Link and node outage have been obtained and measured through network simulation for reliability analysis. The comparative study with the other available fading models shows that the proposed model is more suitable in approximating real phenomenon of wireless link design.",smart cities
10.1016/j.trpro.2020.03.041,Conference Proceeding,Transportation Research Procedia,scopus,2020-01-01,sciencedirect,Mathematical Remodeling Concept in Simulation of Complicated Variable Structure Transportation Systems,https://api.elsevier.com/content/abstract/scopus_id/85083457310,"Mathematical Remodeling is aimed at transforming mathematical or simulation models of one or different classes (or subsystems forming a studied system) into a model of one predefined unified class. Depending on the goals and specific applications, different interpretations of remodeling are possible. Theoretical model constructed based on its physical meaning, can be quite complicated and is not suitable for further analysis. In this case, an array of input and output training data (which could not be obtained in real conditions) can be generated using the software implementation of the model. Using these obtained values and according to Remodeling concept it is necessary to determine a new model of a given structure with the required accuracy, which can approximate the original model in the best way. The paper presents examples of applying Mathematical Remodeling concept to constructing a dynamic system with a variable structure. Such systems are used to simulate an inertial torque transformer, which is a part of a stepless car transmission. Another example of this approach is the method of estimating freeway section capacity. Feedforward neural networks are used as remodeling classes in both cases. The introduced applications of Mathematical Remodeling approach are in the basis of constructing intelligent transportation systems.",smart cities
10.1016/j.trpro.2020.02.093,Conference Proceeding,Transportation Research Procedia,scopus,2020-01-01,sciencedirect,Risk identification of implementation of ITS to real traffic,https://api.elsevier.com/content/abstract/scopus_id/85083429743,"Intelligent Transportation System is one of the concepts of modern sustainable transport in Smart Cities, which increases flow and safety of road traffic with use of information and communication technologies. The use of smart technologies such as Internet of Things, BigData, Artificial Intelligence and so on, requires strengthening or even creating a new communication infrastructure in the field of traffic. This paper discusses the risks of ITS implementation by analyzing the current state, identifying the key risk factors and showing possibilities in reduction of these risk using system methodology. It can be assumed that this transformation will be time-consuming, not only in policy and construction areas, but also in putting these systems into operation. In this meantime, when smart and non-smart systems will come in contact, there should be expected risk situations, that could cause difficulties for large-scale ITS to emerge, for example for large cities. An important part is also early awareness of the population which is affected by the situation of putting the system into operation, especially trainings for professional drivers. A participant in traffic, who are not affected by smart technologies as so-called “internet generation“ should be taken into account, as possible source of risk situations. Determining the potential risks on all the above-mentioned case is a current problem because of the rapid development and onset of ITS.",smart cities
10.1016/j.eplepsyres.2019.106244,Journal,Epilepsy Research,scopus,2020-01-01,sciencedirect,Modulation of epileptogenesis: A paradigm for the integration of enzyme-based microelectrode arrays and optogenetics,https://api.elsevier.com/content/abstract/scopus_id/85075920814,"Background
                  Genesis of acquired epilepsy includes transformations spanning genetic-to- network-level modifications, disrupting the regional excitatory/inhibitory balance. Methodology concurrently tracking changes at multiple levels is lacking. Here, viral vectors are used to differentially express two opsin proteins in neuronal populations within dentate gyrus (DG) of hippocampus. When activated, these opsins induced excitatory or inhibitory neural output that differentially affected neural networks and epileptogenesis. In vivo measures included behavioral observation coupled to real-time measures of regional glutamate flux using ceramic-based amperometric microelectrode arrays (MEAs).
               
                  Results
                  Using MEA technology, phasic increases of extracellular glutamate were recorded immediately upon application of blue light/488 nm to DG of rats previously transfected with an AAV 2/5 vector containing an (excitatory) channelrhodopsin-2 transcript. Rats receiving twice-daily 30-sec light stimulation to DG ipsilateral to viral transfection progressed through Racine seizure stages. AAV 2/5 (inhibitory) halorhodopsin-transfected rats receiving concomitant amygdalar kindling and DG light stimuli were kindled significantly more slowly than non-stimulated controls. In in vitro slice preparations, both excitatory and inhibitory responses were independently evoked in dentate granule cells during appropriate light stimulation. Latency to response and sensitivity of responses suggest a degree of neuron subtype-selective functional expression of the transcripts.
               
                  Conclusions
                  This study demonstrates the potential for coupling MEA technology and optogenetics for real-time neurotransmitter release measures and modification of seizure susceptibility in animal models of epileptogenesis. This microelectrode/optogenetic technology could prove useful for characterization of network and system level dysfunction in diseases involving imbalanced excitatory/inhibitory control of neuron populations and guide development of future treatment strategies.",smart cities
10.1016/j.aap.2019.105319,Journal,Accident Analysis and Prevention,scopus,2020-01-01,sciencedirect,Detecting motorcycle helmet use with deep learning,https://api.elsevier.com/content/abstract/scopus_id/85074491322,"The continuous motorization of traffic has led to a sustained increase in the global number of road related fatalities and injuries. To counter this, governments are focusing on enforcing safe and law-abiding behavior in traffic. However, especially in developing countries where the motorcycle is the main form of transportation, there is a lack of comprehensive data on the safety-critical behavioral metric of motorcycle helmet use. This lack of data prohibits targeted enforcement and education campaigns which are crucial for injury prevention. Hence, we have developed an algorithm for the automated registration of motorcycle helmet usage from video data, using a deep learning approach. Based on 91,000 annotated frames of video data, collected at multiple observation sites in 7 cities across the country of Myanmar, we trained our algorithm to detect active motorcycles, the number and position of riders on the motorcycle, as well as their helmet use. An analysis of the algorithm's accuracy on an annotated test data set, and a comparison to available human-registered helmet use data reveals a high accuracy of our approach. Our algorithm registers motorcycle helmet use rates with an accuracy of −4.4% and +2.1% in comparison to a human observer, with minimal training for individual observation sites. Without observation site specific training, the accuracy of helmet use detection decreases slightly, depending on a number of factors. Our approach can be implemented in existing roadside traffic surveillance infrastructure and can facilitate targeted data-driven injury prevention campaigns with real-time speed. Implications of the proposed method, as well as measures that can further improve detection accuracy are discussed.",smart cities
10.1016/bs.adcom.2019.09.005,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Impact of cloud security in digital twin,https://api.elsevier.com/content/abstract/scopus_id/85073737509,"Digital Twin is a way to virtually represent or model a physical object using the real time data. This innovation sets up a way to deal with industries and organizations to supervise their products, consequently bridging the gap between design and implementations. As the name suggests, “Digital Twin” infers that a reproduction of the product is made in order to have a nearby relationship with the live item. The procedure of computerized twin begins by gathering real time data, processed data, and operational data and performs distinctive investigation which helps in anticipating the future. This additionally enhances the customer experiences by giving a digital feel of their product. The objective behind all these is the job of gathering information and putting them in a place, i.e., the cloud which could store exorbitant data. The user experience gets enhanced by the intervention of digital twin technology which could help in the successful working of the products geographically distributed. The impact of Internet of Things and Cloud Computing lifts up the digital twin.
                  The information gathered from the sources can be arranged in terms of utilization and prospect to change on a timely basis. These data, as they are stored require proper coordination and a legitimate use.
                  Digital Twin innovation assumes incredible opportunities in the field of manufacturing, healthcare, smart cities, automobile and so on. The effect of having a digital twin for the product makes it simple for activities and recognize the blemishes, if any happened. This approach can help reduce the workload and furthermore can get trained on the virtual machine without the need of a specific training.
                  With the most prevailing technologies of today, like Artificial Intelligence, Machine Learning and Internet of Things more prominent approach to train and monitor products, taking care of its own execution, collaborating to different frameworks, performing self-repairs are made possible. Hence the future is getting unfolded with the emerging DIGITAL TWIN era. The massive data utilized in the field of digital twin is prone to severe security breaches. Thus digital twin technology should be handled with extreme care so as to protect the data. Hence, this chapter identifies the ways and means of collecting, organizing and storing the data in a secured cloud environment. The data is filtered according to the use and priority and pushed into the cloud. It is determined to implement an exclusive algorithm for a secured cloud which would greatly benefit the users and the providers to handle and process it effectively.",smart cities
10.1016/j.bspc.2019.101638,Journal,Biomedical Signal Processing and Control,scopus,2020-01-01,sciencedirect,EEG mobility artifact removal for ambulatory epileptic seizure prediction applications,https://api.elsevier.com/content/abstract/scopus_id/85070796123,"Mobile monitoring of electroencephalogram (EEG) signals is prone to different sources of artifacts. Most importantly, motion-related artifacts present a major challenge hindering the clean acquisition of EEG data as they spread all over the scalp and across all frequency bands. This leads to additional complexity in the development of neurologically-oriented mobile health solutions. Among the top five most common neurological disorders, epilepsy has increasingly relied on EEG for diagnosis. Separate methods have been used to classify EEG segments in the context of epilepsy while reducing the existing mobility artifacts. This work specifically devises an approach to remove motion-related artifacts in the context of epilepsy. The proposed approach first includes the recording of EEG signals using a wearable EEG headset. The recorded signals are then colored by some motion artifacts generated in a lab-controlled experiment. This stage is followed by temporal and spectral characterization of the signals and artifact removal using independent component analysis (ICA). The proposed approach is tested using real clinical EEG data and results showed an average increase in accuracy of ∼9% in seizure detection and ∼24% in prediction.",smart cities
10.1016/j.eswa.2019.112867,Journal,Expert Systems with Applications,scopus,2020-01-01,sciencedirect,A new efficient hybrid algorithm for large scale multiple traveling salesman problems,https://api.elsevier.com/content/abstract/scopus_id/85070555970,"Multiple traveling salesmen problem (MTSP) is not only a generalization of the traveling salesman problem (TSP), but also more suitable for modeling practical problems in the real life than TSP. For solving the MTSP with multiple depots, the requirement of minimum and maximum number of cities that each salesman should visit, a hybrid algorithm called ant colony-partheno genetic algorithms (AC-PGA) is provided by combining partheno genetic algorithms (PGA) and ant colony algorithms (ACO). The main idea in this paper is to divide the variables into two parts. In detail, it exploits PGA to comprehensively search the best value of the first part variables and then utilizes ACO to accurately determine the second part variables value. For comparative analysis, PGA, improved PGA (IPGA), two-part wolf pack search (TWPS), artificial bee colony (ABC) and invasive weed optimization (IWO) algorithms are adopted to solve MTSP and validated with publicly available TSPLIB benchmarks. The results of comparative experiments show that AC-PGA is sufficiently effective in solving large scale MTSP and has better performance than the existing algorithms.",smart cities
10.1016/j.compeleceng.2019.106497,Journal,Computers and Electrical Engineering,scopus,2019-12-01,sciencedirect,Proactive machine learning-based solution for advanced manageability of multi-persona mobile computing,https://api.elsevier.com/content/abstract/scopus_id/85074295071,"Latest mobile virtualization techniques have opened the door for multi-persona mobility to overcome security and privacy concerns of bring-your-own devices practice. Multi-persona allows a physical device to co-host multiple virtual phones with impenetrable walls among them. However, physical resources should be always enough to support virtual instances and applications needs without performance degradation or system crash. Though computation offloading can augment devices resources, yet some applications are not offloadable. Additionally, idle applications and virtual environments impose high overhead on the device. Through machine learning, this work predicts future context and resource needs of currently running virtual environments and potential future active ones. It provides advanced manageability strategies, formulated in an optimization model, which appropriately turn off applications and switch off virtual environments to release device resources when needed. A dynamic programming algorithm is advocated to find the adequate strategies. Extensive experiments conducted demonstrate the efficiency of our proposition.",smart cities
10.1016/j.eap.2019.08.002,Journal,Economic Analysis and Policy,scopus,2019-12-01,sciencedirect,Road traffic forecasting — A hybrid approach combining Artificial Neural Network with Singular Spectrum Analysis,https://api.elsevier.com/content/abstract/scopus_id/85071460321,"The paper presents a comparison of a hybrid methodology which combines Singular Spectrum Analysis (SSA) with Artificial Neural Networks (ANN) against conventional ANN, applied on time series analysis and forecasting of road traffic volume. The main research objective was to develop a short-term forecast of daily traffic volume at toll stations across the Greek National Highway Network. The proposed methodology was implemented and evaluated upon a custom developed integrated forecasting software, based on the Mathworks MatLab platform. Experimental outcomes on daily data, from specific toll stations, demonstrate a superior prediction accuracy of hybrid SSA–ANN forecasting methodology against conventional ANN, when compared to performances of statistical criteria such as Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Coefficient of Determination (R2). A comparison of results revealed that the SSA–ANN hybrid model could improve the forecasting accuracy of the conventional ANN model in the case of daily traffic volume forecasting. An Intelligent Transport System with embedded hybrid SSA–ANN forecasting algorithm could manage and analyze big data traffic volume time series in real time, providing an advanced decision support system for transportation system management and maintenance, while it would enable proactive decisions to mitigate the economic and environmental impacts of traffic congestion.",smart cities
10.1016/j.future.2019.07.056,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,Online travel mode detection method using automated machine learning and feature engineering,https://api.elsevier.com/content/abstract/scopus_id/85070075208,"Online travel mode detection provides context information useful for location-based services, in order to deliver a customized user experience. In the last years, many smartphone-based travel mode detection techniques have been proposed, but few explored the usage of dimensionality reduction in conjunction with hyperparameter optimization to improve accuracy with a reduced cost. In this paper, we propose a method to improve the accuracy and computational cost trade-off of travel mode detection, in which use state-of-the-art Feature Engineering and Automated Machine Learning techniques. In addition, we apply the proposed method in a real mobility dataset using different features and parameters. Our experiments showed that the combination of these techniques can greatly improve online detection performance.",smart cities
10.1016/j.eswa.2019.04.023,Journal,Expert Systems with Applications,scopus,2019-12-01,sciencedirect,Experimental analysis of heuristic solutions for the moving target traveling salesman problem applied to a moving targets monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85068183652,"The Traveling Salesman Problem (TSP) is an important problem in computer science which consists in finding a path linking a set of cities so that each of then can be visited once, before the traveler comes back to the starting point. This is highly relevant because several real world problems can be mapped to it. A special case of TSP is the one in which the cities (the points to be visited) are not static as the cities, but mobile, changing their positions as the time passes. This variation is known as Moving Target TSP (MT-TSP). Emerging systems for crowd monitoring and control based on unmanned aerial vehicles (UAVs) can be mapped to this variation of the TSP problem, as a number of persons (targets) in the crowd can be assigned to be monitored by a given number of UAVs, which by their turn divide the targets among them. These target persons have to be visited from time to time, in a similar way to the cities in the traditional TSP. Aiming at finding a suitable solution for this type of crowd monitoring application, and considering the fact that exact solutions are too complex to perform in a reasonable time, this work explores and compares different heuristic methods for the intended solution. The performed experiments showed that the Genetic Algorithms present the best performance in finding acceptable solutions for the problem in restricted time and processing power situations, performing better compared to Ant Colony Optimization and Simulated Annealing Algorithms.",smart cities
10.1016/j.future.2019.06.030,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,A short-term energy prediction system based on edge computing for smart city,https://api.elsevier.com/content/abstract/scopus_id/85068147974,"The development of Internet of Things technologies has provided potential for real-time monitoring and control of environment in smart cities. In the field of energy management, energy prediction can be carried out by sensing and analyzing dynamic environmental information of the energy consumption side, and provide decision support for energy production to avoid excess or insufficient energy supply and achieve agile production. However, due to the complexity and diversity of the IoT data, it is difficult to build an efficient energy prediction system that reflects the dynamics of the IoT environment. To address this problem, a short-term energy prediction system based on edge computing architecture is proposed, in which data acquisition, data processing and regression prediction are distributed in sensing nodes, routing nodes and central server respectively. Semantics and stream processing techniques are utilized to support efficient IoT data acquisition and processing. In addition, an online deep neural network model adapted to the characteristics of IoT data is implemented for energy prediction. A real-world case study of energy prediction in a regional energy system is given to verify the feasibility and efficiency of our system. The results show that the system can provide support for real-time energy prediction with high precision in a promising way.",smart cities
10.1016/j.jclepro.2019.117870,Journal,Journal of Cleaner Production,scopus,2019-11-20,sciencedirect,"Digestate evaporation treatment in biogas plants: A techno-economic assessment by Monte Carlo, neural networks and decision trees",https://api.elsevier.com/content/abstract/scopus_id/85070258305,"Biogas production is one of the most promising pathways toward fully utilizing green energy within a circular economy. The anaerobic digestion process is the industry standard technology for biogas production due to its lowered energy consumption and its reliance on microbiology. Even in such an environmental-friendly process, liquid digestate is still produced from the remains of digested bio-feedstock and will require treatment. With unsuitable treatment procedure for liquid digestate, the mass of bio-feedstock can potentially escape the circular supply chain within the economy. This paper recommends the implementation of evaporator systems to provide a sustainable liquid digestate treating mechanism within the economy. Studied evaporator systems are represented by vacuum evaporation in combination with ammonia scrubber, stripping and reverse osmosis. Nevertheless, complex multi-dimensional decisions should be made by stakeholders before implementing such systems. Our work utilizes a novel techno-economics model to study the techno-economics robustness in implementing recent state-of-art vacuum evaporation systems with exploitation of waste heat from combined heat and power (CHP) units in biogas plants (BGP). To take into the account the stochasticity of the real world and robustness of the analysis, we used the Monte-Carlo simulation technique to generate more than 20,000 of different possibilities for the implementation of the evaporation system. Favourable decision pathways are then selected using a novel methodology which utilizes the artificial neural network and a hyper-optimized decision tree classifier. Two pathways that give the highest probability of providing a fast payback period are identified. Descriptive statistics are also used to analyse the distributions of decision parameters that lead to success in implementing the evaporator system. The results highlighted that integration of evaporation system are favourable when transport costs and incentives for CHP units are large and while feed-in tariffs for electricity production and specific investment costs are low. The result of this work is expected to pave the way for BGP stakeholders and decision makers in implementing liquid digestate treating technologies within the currently existing infrastructure.",smart cities
10.1016/j.trc.2019.09.008,Journal,Transportation Research Part C: Emerging Technologies,scopus,2019-11-01,sciencedirect,An effective spatial-temporal attention based neural network for traffic flow prediction,https://api.elsevier.com/content/abstract/scopus_id/85072262628,"Due to its importance in Intelligent Transport Systems (ITS), traffic flow prediction has been the focus of many studies in the last few decades. Existing traffic flow prediction models mainly extract static spatial-temporal correlations, although these correlations are known to be dynamic in traffic networks. Attention-based models have emerged in recent years, mostly in the field of natural language processing, and have resulted in major progresses in terms of both accuracy and interpretability. This inspires us to introduce the application of attentions for traffic flow prediction. In this study, a deep learning based traffic flow predictor with spatial and temporal attentions (STANN) is proposed. The spatial and temporal attentions are used to exploit the spatial dependencies between road segments and temporal dependencies between time steps respectively. Experiment results with a real-world traffic dataset demonstrate the superior performance of the proposed model. The results also show that the utilization of multiple data resolutions could help improve prediction accuracy. Furthermore, the proposed model is demonstrated to have potential for improving the understanding of spatial-temporal correlations in a traffic network.",smart cities
10.1016/j.eswa.2019.05.001,Journal,Expert Systems with Applications,scopus,2019-10-15,sciencedirect,Canadian Traveler Problem with Neutralizations,https://api.elsevier.com/content/abstract/scopus_id/85065488474,"The Canadian Traveler Problem (CTP) and the Obstacle Neutralization Problem (ONP) are two well-studied graph-theoretic path planning problems in the literature and both problems have been shown to be computationally intractable. In CTP, certain edges in a graph are blocked by a known probability and their status is revealed only when the traversing agent is at either end of these edges using the agent’s limited disambiguation capability. The goal is to minimize the expected length of the traversal between a starting and a termination vertex by devising a policy that dictates in real-time which edge to disambiguate. In ONP, an agent needs to safely and swiftly navigate from a given source location to a destination through an arrangement of obstacles in the plane. The agent has a limited neutralization capability and uses it to safely pass through an obstacle at a cost of increased traversal length. The agent’s goal is to find the sequence of obstacles to be neutralized en route which minimizes the overall traversal length subject to the agent’s limited neutralization capability. Both of these problems have important and practical applications within the context of expert and intelligent systems. These include: autonomous robot navigation, adaptive transportation systems, naval and land minefield countermeasures, and navigation inside disaster areas for emergency relief operations. In this study, we consider a new path planning problem in the simultaneous presence of disambiguation and neutralization capabilities. This appears to be the first of its kind in the literature despite the close and inherent relationship between CTP and ONP. We call this problem the Canadian Traveler Problem with Neutralizations (CTPN). We present a Markov decision process formulation of CTPN and propose an optimal algorithm. This is based on an extension of the well-known AO* search algorithm. We provide computational experiments on Delaunay graphs to assess the relative performance of this algorithm in comparison to the well-known value iteration and AO* algorithms. We then investigate the relative utility and importance of the disambiguation and neutralization capabilities in order to assist decision-makers with financial constraints as well as navigation performance decisions.",smart cities
10.1016/j.chieco.2019.101344,Journal,China Economic Review,scopus,2019-10-01,sciencedirect,Does renaming promote economic development? New evidence from a city-renaming reform experiment in China,https://api.elsevier.com/content/abstract/scopus_id/85071947169,"To explore the impact of city-renaming reform on economic growth, we compare the empirical performance of the synthetic control method, panel data approach and machine learning method (LASSO and elastic net) by the case of Xiangyang, which was officially renamed in 2010. We find that for the data on real GDP growth, the panel data approach reveals the best performance under the criteria of evaluating the quality of a model. The estimation results show that Xiangyang's real GDP growth rate rose by about 1.43% annually after the renaming reform. However, further discussions show that the annual growth rate of the tertiary industry decreased by 1.59%, which contradicts the mechanism of the brand effect of the reform. The statistical inference demonstrates that even if a city did not implement the city-renaming reform in 2010, the probability of obtaining an effect as large as Xiangyang's would be 25.9%. Therefore, the effect of the city-renaming reform is insignificant and other policy interventions—rather than the city-renaming reform—promote economic growth in Xiangyang. In summary, policymakers cannot win a “Promotion Tournament” by renaming cities.",smart cities
10.1016/j.bios.2019.111549,Journal,Biosensors and Bioelectronics,scopus,2019-10-01,sciencedirect,Efficient electron-mediated electrochemical biosensor of gold wire for the rapid detection of C-reactive protein: A predictive strategy for heart failure,https://api.elsevier.com/content/abstract/scopus_id/85071785022,"C-reactive protein (CRP) is considered a promising biomarker for the rapid and high-throughput real-time monitoring of cardiovascular disease and inflammation in unprocessed clinical samples. Implementation of this monitoring would enable various transformative biomedical applications. We have fabricated a highly specific sensor chip to detect CRP with a detection limit of 2.25 fg/mL. The protein was immobilized on top of a gold (Au) wire/polycarbonate (PC) substrate using 1-ethyl-3-(3-dimethylamino-propyl) carbodiimide hydrochloride/N-hydroxy succinimide-activated 3-mercaptoproponic acid (MPA) as a self-assembled monolayer agent and bovine serum albumin (BSA) as a blocking agent. In contrast to the bare PC substrate, the CRP/BSA/anti-CRP/MPA/Au substrate exhibited a considerably high electrochemical signal toward CRP. The influence of the experimental parameters on CRP detection was assessed via various analysis methods, and these parameters were then optimized. The linear dynamic range of the CRP was 5–220 fg/mL for voltammetric and impedance analysis. Morever, the strategy exhibited high selectivity against various potential interfering species and was capable of directly probing trace amounts of the target CRP in human serum with excellent selectivity. The analytical assay based on the CRP/BSA/anti-CRP/MPA/Au substrate could be exploited as a potentially useful tool for detecting CRP in clinical samples.",smart cities
10.1016/j.trc.2019.08.013,Journal,Transportation Research Part C: Emerging Technologies,scopus,2019-10-01,sciencedirect,Missing data detection and imputation for urban ANPR system using an iterative tensor decomposition approach,https://api.elsevier.com/content/abstract/scopus_id/85071232914,"The automatic number plate recognition (ANPR) system has been widely implemented as an important part of intelligent transportation system (ITS). However, similar to other traffic monitoring devices, missing data is a common and critical problem in the ANPR system. To solve the missing data problem, numerous tensor-based methods have been proposed in previous studies. Most of them, however, assume that where and when missing data occur in the dataset are known. This would be impractical, because missing data may occur randomly. In this study, we propose a novel tensor-based algorithm, specifically, an iterative tensor decomposition (ITD) approach, that utilizes multidimensional inherent correlation of traffic data to detect and impute missing data in the ANPR system. The proposed algorithm is tested with a real-world ANPR system dataset. The experimental results show that missing data from the ANPR system can be classified into three cases, i.e., no missing, random elements missing, and extreme missing. The proposed ITD can accurately detect and correct missing data under different missing cases. Furthermore, ITD is also compared with other state-of-the-art methods and the results show that ITD outperforms the existing methods.",smart cities
10.1016/j.scs.2019.101615,Journal,Sustainable Cities and Society,scopus,2019-10-01,sciencedirect,"Thai sentiment analysis with deep learning techniques: A comparative study based on word embedding, POS-tag, and sentic features",https://api.elsevier.com/content/abstract/scopus_id/85067187685,"A smart city connects physical, information technology, social, and business infrastructures together to leverage their collective intelligence. Feedback drives improvements in service, city development, and quality of life in the city. Therefore, sentiment analysis in real-time of opinions expressed in text form by residents in the city is absolutely necessary. Nowadays, machine learning is widely applied to sentiment analysis of decisions in business, especially deep learning. In this experiment, we evaluated and compared the performances of several conventional deep learning models: Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Bidirectional LSTM (Bi-LSTM), in sentiment analysis of Thai children tales. In several previous studies, many features have been used in all of the models mentioned, features such as word embedding that helps a model to understand the semantics of each word, POS-tag that helps a model to understand the grammatical function of words, and sentic that helps a model to understand the emotion of words. Some combinations of these features have also been used. The results of this experiment show that the CNN model that used all three features gave the best result of 0.817 F1-score at p < 0.01, which was significantly better than all other models.",smart cities
10.1016/j.jpdc.2017.11.009,Journal,Journal of Parallel and Distributed Computing,scopus,2019-10-01,sciencedirect,Person re-identification with multiple similarity probabilities using deep metric learning for efficient smart security applications,https://api.elsevier.com/content/abstract/scopus_id/85044716579,"Surveillance video analysis plays a vital role in the daily operations of smart cities, which increasingly relies on person re-identification technology to sustain smart security applications. However, research challenges of re-identification remain especially in terms of recognizing the different appearances of the same person in a harsh real-world environment: (1) the adaptability of the selected features to the dynamic environment cannot be guaranteed, and (2) existing methods rooted from metric learning aim to find a single metric function, and they lack the ability to measure the different appearances of the same person. To address these problems, this study proposes a multiple deep metric learning method empowered by the functionality of person similarity probability measurement. The proposed method exploits multiple stacked auto-encoder networks and classification networks to quantify pedestrians’ similarity relations. The stacked auto-encoder networks directly recognize persons from surveillance images at the pixel level. The classification networks are equipped with the Softmax regression models and produce multiple similarity probabilities to characterize different appearances belonging to the same person. An Adaboost-like model is designed to fuse the probabilities corresponding to multiple metrics, which ensures a high accuracy of recognition. Experimental results on two public datasets (VIPeR and CUHK-01) indicate that the proposed method outperforms existing algorithms by 2%–10% at rank 1. Based on the similarity probabilities learned by the proposed model, the algorithm for matching the person pair can achieve a time complexity as low as 
                        O
                        
                           (
                           n
                           )
                        
                     , which can be deployed at a large scale on the distributed intelligent surveillance network, with each node maintaining limited computing capabilities.",smart cities
10.1016/j.neucom.2019.01.031,Journal,Neurocomputing,scopus,2019-09-17,sciencedirect,"A novel deep learning driven, low-cost mobility prediction approach for 5G cellular networks: The case of the Control/Data Separation Architecture (CDSA)",https://api.elsevier.com/content/abstract/scopus_id/85066248608,"One of the fundamental goals of mobile networks is to enable uninterrupted access to wireless services without compromising the expected quality of service (QoS). This paper reports a number of significant contributions. First, a novel analytical model is proposed for holistic handover (HO) cost evaluation, that integrates signaling overhead, latency, call dropping, and radio resource wastage. The developed mathematical model is applicable to several cellular architectures, but the focus here is on the Control/Data Separation Architecture (CDSA). Second, data-driven HO prediction is proposed and evaluated as part of the holistic cost, for the first time, through novel application of a recurrent deep learning architecture, specifically, a stacked long-short-term memory (LSTM) model. Finally, simulation results and preliminary analysis reveal different cases where non-predictive and predictive deep neural networks can be effectively utilized, based on HO management requirements. Both analytical and machine learning models are evaluated with a benchmark, real-world dataset measuring human behaviors and interactions. Numerical and comparative simulation results demonstrate the potential of our proposed deep learning-driven HO management framework, as a future benchmark for the mobile networking and machine learning communities.",smart cities
10.1016/j.jnca.2019.06.003,Journal,Journal of Network and Computer Applications,scopus,2019-09-15,sciencedirect,MAPLE: A Machine Learning Approach for Efficient Placement and Adjustment of Virtual Network Functions,https://api.elsevier.com/content/abstract/scopus_id/85067443855,"As one of the many advantages of cloud computing, Network Function Virtualization (NFV) has revolutionized the network and telecommunication industry through enabling the migration of network functions from expensive dedicated hardware to software-defined components that run in the form of Virtual Network Functions (VNFs). However, with NFV comes numerous challenges related mainly to the complexity of deploying and adjusting VNFs in the physical networks, owing to the huge number of nodes and links in today's datacenters, and the inter-dependency among VNFs forming a certain network service. Several contributions have been made in an attempt to answer these challenges, where most of the existing solutions focus on the static placement of VNFs and overlook the dynamic aspect of the problem, which arises mainly due to the ever-changing resource availability in the cloud datacenters and the continuous mobility of the users. Few attempts have been lately made to incorporate the dynamic aspect to the VNF deployment solutions. The main problem of these approaches lies in their reactive readjustment scheme which determines the placement/migration strategy upon the receipt of a new request or the happening of a certain event, thus resulting in high setup latencies. In this paper, we take advantage of machine learning to reduce the complexity of the placement and readjustment processes through designing a cluster-based proactive solution. The solution consists of (1) an Integer Linear Programming (ILP) model that considers a tradeoff between the minimization of the latency, Service-Level Objective (SLO) violation cost, hardware utilization, and VNF readjustment cost, (2) an optimized k-medoids clustering approach which proactively partitions the substrate network into a set of disjoint on-demand clusters and (3) data-driven cluster-based placement and readjustment algorithms that capitalize on machine learning to intelligently eliminate some cost functions from the optimization problem to boost its feasibility in large-scale networks. Simulation results show that the proposed solution considerably reduces the readjustment time and decrease the hardware utilization compared to the K-means, original k-medoids and migration without clustering approaches.",smart cities
10.1016/j.ifacol.2019.11.465,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,"Integration of automatic generated simulation models, machine control projects and management tools to support whole life cycle of industrial digital twins",https://api.elsevier.com/content/abstract/scopus_id/85078871061,"The paper presents a framework of automatic generation of industrial digital twins. These digital twins will be suitable to support preliminary design phases of systems development, but also to support next phases of detailed designs implementation and systems running phases. These digital twin allow, from the preliminary designing phase, to generate a complete simulation of the target industrial system. But, at the same time, and without the need to develop and add any subsequent code, they should be a valuable support for the phases and tasks of exploitation: maintenance, machine or system learning, etc. The problem is that the requirements for first development phases are much more generic than those for later phases. For this reason, instead of incorporating specificities in the simulation system, the framework takes advantage of the applications which are being developed for the implementation of the real system. In these applications (the control program and the decisions and the high level management system), the specificities have had to be taken into account. The system has been specialized in industrial transportation and warehouse systems which, although have a finite number or building objects, they have an infinite set of final configurations, very different one from each other. The paper presents an evaluation of current simulation platforms suitable to be used as part of the framework, and the digital twin industrial system generation framework itself. An example of application is as well presented.",smart cities
10.1016/j.isprsjprs.2019.07.009,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2019-09-01,sciencedirect,Development and evaluation of a deep learning model for real-time ground vehicle semantic segmentation from UAV-based thermal infrared imagery,https://api.elsevier.com/content/abstract/scopus_id/85069676654,"Real-time unmanned aerial vehicles (UAVs)-based thermal infrared images processing, due to high spatial resolution and knowledge of the various infrared radiant energy level distribution of solid bodies, has important applications such as monitoring and control of the various phenomena in different natural situations. One of these applications is monitoring the ground vehicles in cities by using detection or semantic segmentation of them in the thermal images. In this research, our purpose is to improve the performance of deep learning combined model by using Gaussian-Bernoulli Restricted Boltzmann Machine (GB-RBM) specifications for the segmentation of the ground vehicles from UAV-based thermal infrared imagery. The proposed model is studied in three steps. First, designing the proposed model by using an encoder-decoder structure and addition of extracted features from convolutional layers and restricted Boltzmann machine in the network. Second, the implementation of the research goals on four sets of UAV-based thermal infrared imagery named NPU_CS_UAV_IR_DATA that was collected from some streets of China by using FLIR TAU2 thermal infrared sensor in 2017. Finally, analyzing the performance of the proposed model by using five state-of-the-art models in semantic segmentation. The results evaluated the performance of the proposed model as a robust model with the average precision and average processing time of approximately 0.97, and 19.73 s for all datasets, respectively.",smart cities
10.1016/j.freeradbiomed.2019.07.002,Journal,Free Radical Biology and Medicine,scopus,2019-09-01,sciencedirect,Hydroxytyrosol prevents PM<inf>2.5</inf>-induced adiposity and insulin resistance by restraining oxidative stress related NF-κB pathway and modulation of gut microbiota in a murine model,https://api.elsevier.com/content/abstract/scopus_id/85068933540,"Exposure to fine particular matter (≤2.5 μM, PM2.5) contributes to increased risk of obesity and type 2 diabetes. Hydroxytyrosol (HT), a simple polyphenol found in virgin olive oil, is considered to be beneficial for cardiovascular and metabolic disorders. The current study determined whether HT could improve PM2.5-induced adiposity and insulin resistance (IR), and explored the underlying mechanisms. Fifteen adult female C57BL/6j mice on a chow diet were randomly divided into three groups receiving (1) sterile PBS, (2) PM2.5 suspended in sterile PBS (1 mg/mL) and (3) PM2.5+HT (50 mg/kg/day). PM2.5/PBS exposure was administered by oropharynx instillation every other day and HT supplementation was achieved by gavage every day. Four-week PM2.5 exposure did not affect body weight, but significantly increased visceral fat mass. The abdominal adiposity coincided with adipocyte hypertrophy and proliferation in visceral white adipose tissue (WAT), as well as decreased metabolic activity in brown adipose tissue and subcutaneous WAT. PM2.5 enhanced the oxidative stress by diminishing antioxidant enzyme activities in liver and serum, whereas contents of 4-hydroxynonenal (4-HNE), malondialdehyde (MDA) levels in liver and serum were elevated. These changes were accompanied by macrophage infiltration and activation of NF-κB pathway in the liver. Moreover, PM2.5 exposure led to glucose intolerance and insulin insensitivity, impaired hepatic glycogenesis, and decreased insulin-stimulated Akt phosphorylation in peripheral tissues. Importantly, HT treatment prevented PM2.5-induced visceral adipogenesis, oxidative stress, hepatic inflammation and NF-κB activation, systemic and peripheral IR. In vitro, after HepG2 cells were incubated with PM2.5 (0, 5, 25, 50, 100 and 200 μg/mL), reduced glutathione depletion and 4-HNE, 8-hydroxy-2'-deoxyguanosine, MDA increment in a dose-dependent manner were observed; likewise, insulin-stimulated glucose uptake decreased in a dose-dependent manner. Further, with antioxidant NAC and NF-κB inhibitor PDTC, we confirmed that HT attenuated PM2.5-induced IR through restraining NF-κB activation evoked by oxidative stress. In addition, HT could expand gut microbiota richness, reduce pathogenic bacteria and accommodate the microbial architecture in PM2.5-exposed mice, which were correlated with parameters of adiposity, oxidative stress and glycometabolism. HT could effectively correct imbalanced oxidative stress triggered by PM2.5, in turn ameliorated NF-κB pathway and insulin signaling. Gut microbiota may mediate the actions of HT.",smart cities
10.1016/j.envres.2019.108535,Journal,Environmental Research,scopus,2019-09-01,sciencedirect,Urban greenery and mental wellbeing in adults: Cross-sectional mediation analyses on multiple pathways across different greenery measures,https://api.elsevier.com/content/abstract/scopus_id/85067848081,"Background
                  Multiple mechanisms have been proposed to explain how greenery in the vicinity of people's homes enhances their mental health and wellbeing. Mediation studies, however, focus on a limited number of mechanisms and rely on remotely sensed greenery measures, which do not accurately capture how neighborhood greenery is perceived on the ground.
               
                  Objective
                  To examine: 1) how streetscape and remote sensing-based greenery affect people's mental wellbeing; 2) whether and, if so, to what extent the associations are mediated by physical activity, stress, air quality and noise, and social cohesion; and 3) whether differences in the mediation across the streetscape greenery and NDVI exposure metrics occurred.
               
                  Methods
                  We used a population sample of 1029 adult residents of the metropolis of Guangzhou, China, from 2016. Mental wellbeing was quantified by the World Health Organization Well-Being Index (WHO-5). Two objective greenery measures were extracted at the neighborhood level: 1) streetscape greenery from street view data via a convolutional neural network, and 2) the normalized difference vegetation index (NDVI) from Landsat 8 remote sensing images. Single and multiple mediation analyses with multilevel regressions were conducted.
               
                  Results
                  Streetscape and NDVI greenery were weakly and positively, but not significantly, correlated. Our regression results revealed that streetscape greenery and NDVI were, individually and jointly, positively associated with mental wellbeing. Significant partial mediators for the streetscape greenery were physical activity, stress, air quality and noise, and social cohesion; together, they explained 62% of the association. For NDVI, only physical activity and social cohesion were significant partial mediators, accounting for 22% of the association.
               
                  Conclusions
                  Mental health and wellbeing and both streetscape and satellite-derived greenery seem to be both directly correlated and indirectly mediated. Our findings signify that both greenery measures capture different aspects of natural environments and may contribute to people's wellbeing by means of different mechanisms.",smart cities
10.1016/j.phymed.2019.152967,Journal,Phytomedicine,scopus,2019-09-01,sciencedirect,Mechanism-based pharmacokinetics-pharmacodynamics studies of harmine and harmaline on neurotransmitters regulatory effects in healthy rats: Challenge on monoamine oxidase and acetylcholinesterase inhibition,https://api.elsevier.com/content/abstract/scopus_id/85066284236,"Background
                  β-Carboline alkaloid harmine (HAR) and harmaline (HAL) are monoamine oxidase (MAO) and acetylcholinesterase (AChE) inhibitors. However, whether HAR and HAL inhibit MAO or AChE selectively and competitively is unclear.
               
                  Purpose
                  The purpose of this study was to investigate the potential competition inhibition of HAR and HAL on MAO and AChE in brain endothelial cells (RBE4) and in healthy rats to provide a basis for the application of the inhibitors in the treatment of patients with depression and with Parkinson's disease or Alzheimer's disease.
               
                  Study design/methods
                  The transport properties of HAR and HAL by using blood-brain barrier models constructed with RBE4 were systematically investigated. Then, the modulation effects of HAR and HAL on CNS neurotransmitters (NTs) in healthy rat brains were determined by a microdialysis method coupled with LC-MS/MS. The competition inhibition of HAR and HAL on MAO and AChE was evaluated through real time-PCR, Western blot analysis, and molecular docking experiments.
               
                  Results
                  Results showed that HAL and HAR can be detected in the blood and striatum 300 min after intravenous injection (1 mg/kg). Choline (Ch), gamma-aminobutyric acid (GABA), glutamate (Glu), and phenylalanine (Phe) levels in the striatum decreased in a time-dependent manner after the HAL treatment, with average velocities of 1.41, 0.73, 3.86, and 1.10 (ng/ml)/min, respectively. The Ch and GABA levels in the striatum decreased after the HAR treatment, with average velocities of 1.16 and 0.22 ng/ml/min, respectively. The results of the cocktail experiment using the human liver enzyme indicated that the IC50 value of HAL on MAO-A was 0.10 ± 0.08 µm and that of HAR was 0.38 ± 0.21 µm. Their IC50 values on AChE were not obtained. These findings indicated that HAL and HAR selectively acted on MAO in vitro. However, RT-PCR and Western blot analysis results showed that the AChE mRNA and protein expression decreased in a time-dependent manner in RBE4 cells after the HAR and HAL treatments.
               
                  Conclusion
                  NT analysis results showed that HAL and HAR selectively affect AChE in vivo. HAL and HAR may be highly and suitably developed for the treatment of Alzheimer's disease.",smart cities
10.1016/j.neucom.2018.05.139,Journal,Neurocomputing,scopus,2019-08-18,sciencedirect,Intelligent decision support to determine the best sensory guardrail locations,https://api.elsevier.com/content/abstract/scopus_id/85065041356,"Introducing intelligent safety devices in the roads would lead to enhance both the time of reaction and the traffic safety. Nevertheless, these intelligent devices are expensive, so choosing their location should be done carefully. This research is focused a decision support system to decide the placement of a specific safety device designed in a research project. This approach includes a feature selection stage, a model learning stage and the deployment stage. Decision models learn from real datasets with information related with accidents, classifying the samples as Fatal, Severe or Slight injury. Also, a case based risk index is proposed, so samples within the same label can be sorted. Therefore, in the deployment stage, each possible location is ranked and the user gets a feedback of the suitability of each of them to be considered for placing the intelligent safety device. The experimentation shows the proposal is valid provided the dataset for training includes enough granularity. However, it is shown that specific risk index should be designed for each road type and fork.",smart cities
10.1016/j.trd.2019.06.009,Journal,Transportation Research Part D: Transport and Environment,scopus,2019-08-01,sciencedirect,Development of an integrated modelling-measurement system for near-real-time estimates of harbour activity impact to atmospheric pollution in coastal cities,https://api.elsevier.com/content/abstract/scopus_id/85067675487,"Several studies focused on harbour impact on air quality of port-cities showing that maritime emissions could be comparable to traffic emissions of a medium-size town having relevant impact on air quality nearby the harbours. In order to plan efficient mitigation strategies, environmental and port authorities have an increasing need of reliable tools for investigating the impact of ships traffic and harbour logistics on atmospheric pollutants. In this work a system based on the integration of measurements collected using a network of low-cost on-line sensors with local scale dispersion modelling was developed. It was implemented, as a pilot action, in the information and management software of the Bari harbour (SE Italy). It can operate in near-real-time, in forecast mode, and on archived data for long-term assessments. It was tested studying the impact of the Bari harbour for the year 2018. The lowest impact was observed for CO, being the pollutant with the lowest share of the contribution of ships (between 8% and 68%) compared with the total harbour contribution. The impacts on PM2.5 and PM10 are larger arriving up to 11.8% of concentrations in the harbour area with an influence of shipping between 44% and 97%. The impact on SO2 is almost solely due to ships and it arrives up to 80% in the harbour area. The impact on NOX ranges from a few percent in the urban area up to 40% in the harbour area and it is the pollutant of major concern regarding compliance with air quality standards.",smart cities
10.1016/j.trc.2019.05.042,Journal,Transportation Research Part C: Emerging Technologies,scopus,2019-08-01,sciencedirect,A machine learning based personalized system for driving state recognition,https://api.elsevier.com/content/abstract/scopus_id/85066926167,"Reliable driving state recognition (e.g. normal, drowsy, and aggressive) plays a significant role in improving road safety, driving experience and fuel efficiency. It lays the foundation for a number of advanced functions such as driver safety monitoring systems and adaptive driving assistance systems. In these applications, state recognition accuracy is of paramount importance to guarantee user acceptance. This paper is mainly focused on developing a personalized driving state recognition system by learning from non-intrusive, easily accessible vehicle related measurements and its validation using real-world driving data. Compared to conventional approaches, this paper first highlights the necessities of adopting a personalized system by analysing feature distribution of individual driver’s data and all drivers’ data via advanced data visualization and statistical analysis. If significant differences are identified, a dedicated personalized model is learnt to predict the driver’s driving state. Spearman distance is also drawn to evaluate the differences between individual driver’s data and all drivers’ data in a quantitative manner. In addition, five categories of classifiers are tested and compared to identify a suitable one for classification, where random forest with Bayesian parameter optimization outperforms others and therefore is adopted in this paper. A recently collected dataset from real-world driving experiments is adopted to evaluate the proposed system. Comparative experimental results indicate that the personalized learning system with road information significantly outperforms conventional approaches without considering personalized characteristics or road information, where the overall accuracy increases from 81.3% to 91.6%. It is believed that the newly developed personalized learning system can find a wide range of applications where diverse behaviours exist.",smart cities
10.1016/j.trc.2019.02.010,Journal,Transportation Research Part C: Emerging Technologies,scopus,2019-08-01,sciencedirect,The effect of social influence and social interactions on the adoption of a new technology: The use of bike sharing in a student population,https://api.elsevier.com/content/abstract/scopus_id/85061773352,"The present study investigates how social influence and social interactions can affect the adoption of new technologies, using stated preference (SP) survey data combined with an “accelerated reality” experience of social interaction among the respondents. Specifically, the intention to use a pro-environmental transport mode (the bike sharing) during a public transport strike within a cohort of students has been analysed. Previous studies have modelled social influence effects using SP data by providing a hypothetical scenario with simulated interactions or information about social conformity processes (i.e. social adoption) during the survey. In our paper, in addition to the impact of assumed social norms, the effect of live/real social interactions is included in the survey. SP survey is developed to investigate the effect of Level-of-Service attributes on the hypothetical choices in the scenario of a public transport strike. Besides the pre-defined attributes characterising the alternatives in the SP design, the survey includes techniques to acquire information on conformity and social interactions. Specifically, the interviewees undertake a before and after stated preference experiment (SP1 and SP2), with a period of group discussion in between the two parts. This SP experiment involves different cognitive and interpersonal mechanisms, such as the functional information exchange on benefits and drawbacks of cycling and bike sharing. The aim is to establish whether hypothetical scenarios of social conformity are different from real/live social interactions and whether these social influence processes actually affect the individuals' mode choice. A joint SP1/SP2 mixed logit (ML) model has been estimated to explore the choice behaviour of individuals and allows us to incorporate the inertia/propensity to change behaviour between SP1 and SP2. Moreover, considering the “Reflexive Layers of Influence” (RLI) framework, the processes generated by social interactions (diffusion, translation and reflexivity) are measured and incorporated in the model. We finally show the effect of these social influence variables on the goodness-of-fit of the models and choice simulation for prediction. We also draw conclusions about the value of such enhanced choice models in understanding and predicting the impacts of social interactions on choice behaviour in the context of new transport technologies.",smart cities
10.1016/j.artint.2018.12.008,Journal,Artificial Intelligence,scopus,2019-08-01,sciencedirect,Ridesharing car detection by transfer learning,https://api.elsevier.com/content/abstract/scopus_id/85061523747,"Ridesharing platforms like Uber and Didi are getting more and more popular around the world. However, unauthorized ridesharing activities taking advantages of the sharing economy can greatly impair the healthy development of this emerging industry. As the first step to regulate on-demand ride services and eliminate black market, we design a method to detect ridesharing cars from a pool of cars based on their trajectories. Since licensed ridesharing car traces are not openly available and may be completely missing in some cities due to legal issues, we turn to transferring knowledge from public transport open data, i.e., taxis and buses, to ridesharing detection among ordinary vehicles. We propose a novel two-stage transfer learning framework, called CoTrans. In Stage 1, we take taxi and bus data as input to learn a random forest (RF) classifier using trajectory features shared by taxis/buses and ridesharing/other cars. Then, we use the RF to label all the candidate cars. In Stage 2, leveraging the subset of high confident labels from the previous stage as input, we further learn a convolutional neural network (CNN) classifier for ridesharing detection, and iteratively refine the RF and CNN, as well as the feature set, via a co-training process. Finally, we use the resulting ensemble of the RF and CNN to identify the ridesharing cars in the candidate pool. Experiments on real car, taxi and bus traces show that CoTrans, with no need of a pre-labeled ridesharing dataset, can outperform state-of-the-art transfer learning methods with an accuracy comparable to human labeling.",smart cities
10.1016/j.scitotenv.2019.04.031,Journal,Science of the Total Environment,scopus,2019-07-10,sciencedirect,An extensively shared antibiotic resistome among four seasons suggests management prioritization in a subtropical riverine ecosystem,https://api.elsevier.com/content/abstract/scopus_id/85064196919,"Although seasonality is a key driver of environmental fluctuation in aquatic ecosystems, there exists limited knowledge on the factors controlling the distribution of antibiotic resistance genes (ARGs) across seasons at a watershed scale. Here we used high-throughput quantitative PCR to quantify 285 ARGs conferring resistance to most major classes of antibiotics, reveal their spatial and seasonal distribution patterns, and depict the underlying mechanisms in a subtropical riverine ecosystem under low and high human pressures, in Xiamen city, southeast China. Our results showed that spatial differences in ARG richness and abundance overwhelmed their seasonal variations, with only ARGs that confer resistance to sulfonamide and vancomycin being significantly different across seasons. Only a few abundant ARGs (19 ARGs) could contribute to >70% of the total ARGs abundance and were found in all seasons. The significantly higher number of ARGs in the summer rainy period than other seasons coincided with high number of significant edges in ARG co-occurrence networks. Summer rainfall had strong dilution effect on ARGs in upstream waters and enrichment effect in downstream waters. The variance partitioning analysis indicated that the environment explained larger variance of ARG profiles than mobile genetic elements (MGEs), spatial predictors and the rainfall. Nevertheless, strong and significant correlations between transposase gene absolute abundance and aminoglycoside, chloramphenicol, MLS, multidrug and tetracycline classes of resistance genes inferred the role of MGEs on ARG distribution. Overall, our results imply that the modelling and management of ARGs in highly dynamic ecosystems could be better implemented by considering priority genes that dominate at spatial and seasonal gradients.",smart cities
10.1016/j.ufug.2019.126365,Journal,Urban Forestry and Urban Greening,scopus,2019-07-01,sciencedirect,Exploring the effect of urban features and immediate environment on body responses,https://api.elsevier.com/content/abstract/scopus_id/85067818650,"This study investigates the relationship between urban features (sky exposure, green spaces, visual complexity, and built-up area), immediate environmental factors (air temperature, relative humidity, Heat Stress Index, Wet Bulb Globe Temperature, wind speed, and noise), personal characteristics (perceived restorativeness) and body reactions (body skin temperature and skin conductance responses). The proposed framework is based on multi-sensor data fusion from wearable physiological sensors, wireless environmental sensors, smartphones, images, geographic information systems datasets, and questionnaires. An experimental setup in a real-world setting is conducted and machine learning algorithms for regression problems and feature selection for variable importance are implemented. The results suggest a significant association between immediate environmental factors and body reactions; however, urban features are found to be weak explanatory variables. A deeper analysis of the identified stress hotspots revealed that locations with more dense green spaces, greater sky exposure, and smaller built-up area tended to report lower levels of stress reaction.",smart cities
10.1016/j.ast.2019.04.048,Journal,Aerospace Science and Technology,scopus,2019-07-01,sciencedirect,Real time estimation of impaired aircraft flight envelope using feedforward neural networks,https://api.elsevier.com/content/abstract/scopus_id/85065791672,"Extensive research in recent years has focused on developing flight envelope estimation methods to improve current loss of control prevention and recovery systems. Such methods are practically efficient only if they are able to evaluate in real time the new flight envelope of damaged aircraft based on the altered dynamics. Due to nonlinear dynamics of aircraft, common approaches to estimate the entire flight envelope of high-fidelity models are numerically intensive and their real time implementation is computationally impossible. So current methods are based on reduced complexity models or flight envelopes are determined locally. This paper presents a novel method to estimate the global flight envelope of impaired aircraft in real-time for any unknown failure degree. In the proposed method, first, numerous flight envelopes are evaluated using a high fidelity model at various failure degrees and different flight conditions and prepared as training data. Then multiple feedforward neural networks are trained offline by a Bayesian regularization backpropagation algorithm. Finally, the trained networks are used to estimate flight envelopes in real time. The method is applied to rudder and aileron failure cases of the NASA Generic Transport Model. Results show that the estimated flight envelopes are good approximations of the high fidelity global flight envelopes.",smart cities
10.1016/j.scs.2019.101499,Journal,Sustainable Cities and Society,scopus,2019-07-01,sciencedirect,Artificial Neural Network based Smart and Energy Efficient Street Lighting System: A Case Study for Residential area in Hosur,https://api.elsevier.com/content/abstract/scopus_id/85065181990,"Smart city is the term described to integrate all facilities to the people in a frequently accessible manner. Street lighting system is one of the part of the facility provided in smart cities. The unwanted utilisation of the street lighting affects the economic status of the country indirectly. Power consumption through street lighting is major problem, hence action plan is taken to promote the reduction policies of the power consumption. Reducing the unnecessary power consumption is not a simple task, but with soft computing approaches power consumption can be reduced. The objective of this article is to present an ANN based energy efficient smart street lighting systems. The proposed design were implemented and executed in a residential area, Hosur and the results are carried out at different scenarios and various seasons. The decision making module exploits the analysis factors obtained via lighting sensor, motion sensor, PIR sensor, etc. artificial neural network and fuzzy logic controller makes an efficient decision making process for demand based utilisation and to avoid the unnecessary utilisation of street lights. The five levels of scenarios are tested and implemented in a real time. Through this work, the smart and energy efficiency street lighting system reduced the unwanted utilisation by 34% and reduced the power consumption rate of 13.5%.",smart cities
10.1016/j.scs.2019.101523,Journal,Sustainable Cities and Society,scopus,2019-07-01,sciencedirect,Cost efficient resource allocation for real-time tasks in embedded systems,https://api.elsevier.com/content/abstract/scopus_id/85065049277,"Various application classes are being deployed to the cloud these days making use of a pay-as-you-go policy. However, existing cloud technologies are still at an early stage of maturity for applications with real-time constraints. With the emergence of Internet of Things (IoT) deployments and embedded systems in smart infrastructure, requirements for off-loading computation to cloud are increasing. In real-time systems, the resource allocation problem is NP-hard, especially when these systems are deployed in cloud computing environments where task execution involves deadline constraints. As a solution, hybrid approaches provide the opportunities to investigate efficient resource allocation for task scheduling problems. We propose a hybridized form of cuckoo search and genetic algorithms known as HGCS (hybrid genetic and cuckoo search) by embedding genetic operators that optimize makespan and cost of real-time tasks scheduled on cloud virtual machines. The inclusion of genetic operators in the cuckoo search algorithm leads to a rigorous search of the solution space, finding the best feasible schedule that can execute tasks in the lowest time, which in turn reduces the total resources usage cost. The performance of the proposed algorithm is tested by using real-time tasks that need data files for successful completion. The HGCS algorithm is evaluated by comparing the results with genetic and cuckoo search algorithms individually. The experimental results favor HGCS over the other two counterparts in providing a schedule respecting the time constraints of the system with reduced makespan and execution cost.",smart cities
10.1016/j.neunet.2019.03.004,Journal,Neural Networks,scopus,2019-07-01,sciencedirect,Multilayer one-class extreme learning machine,https://api.elsevier.com/content/abstract/scopus_id/85063345577,"One-class classification has been found attractive in many applications for its effectiveness in anomaly or outlier detection. Representative one-class classification algorithms include the one-class support vector machine (SVM), Naive Parzen density estimation, autoencoder (AE), etc. Recently, the one-class extreme learning machine (OC-ELM) has been developed for learning acceleration and performance enhancement. But existing one-class algorithms are generally less effective in complex and multi-class classifications. To alleviate the deficiency, a multilayer neural network based one-class classification with ELM (in short, as ML-OCELM) is developed in this paper. The stacked AEs are employed in ML-OCELM to exploit an effective feature representation for complex data. The effective kernel based learning framework is also investigated in the stacked AEs of ML-OCELM, leading to a multilayer kernel based OC-ELM (in short, as MK-OCELM). The MK-OCELM has advantages of less human-intervention parameters and good generalization performance. Experiments on 13 benchmark UCI classification datasets and a real application on urban acoustic classification (UAC) are carried out to show the superiority of the proposed ML-OCELM/MK-OCELM over the OC-ELM and several state-of-the-art algorithms.",smart cities
10.1016/j.schres.2019.03.027,Journal,Schizophrenia Research,scopus,2019-06-01,sciencedirect,Evidence of brain network aberration in healthy subjects with urban upbringing – A multimodal DTI and VBM study,https://api.elsevier.com/content/abstract/scopus_id/85064162040,"City living represents not only the allegory of modern life, but also – due to attractive living conditions, employment and infrastructure – a crucial reality for a growing portion of the global society. Regarding the remarkable increase of the schizophrenia incidence in individuals exposed to an urban environment during upbringing the understanding of responsible pathogenetic mechanisms is important. Schizophrenia has been conceptualized as a disorder of brain dysconnectivity. We investigated the association between urban upbringing and gray matter as well as white matter in a large sample of healthy subjects (n = 290). Voxelwise analyses revealed a strong inverse correlation of early life urbanicity and gray matter volume of the bilateral dorsolateral prefrontal cortices (DLPFC) and the right inferior parietal lobe (IPL) as well as the white matter characteristics in the left superior longitudinal fasciculus (SLF). A positive correlation was found for the gray matter volume of the left precuneus. These results may point to an altered brain development associated with urban upbringing, which not only affects single brain regions but a fronto-parietal network. Considering a DLPFC susceptibility to stress, our findings support the hypothesis of the pathogenetic role of social stress in an urban environment.",smart cities
10.1016/j.jclepro.2019.02.179,Journal,Journal of Cleaner Production,scopus,2019-06-01,sciencedirect,"Evaluating air quality by combining stationary, smart mobile pollution monitoring and data-driven modelling",https://api.elsevier.com/content/abstract/scopus_id/85062521801,"Air pollution impact assessment is a major objective for various community councils in large cities, which have lately redirected their attention towards using more low-cost sensing units supported by citizen involvement. However, there is a lack of research studies investigating real-time mobile air-quality measurement through smart sensing units and even more of any data-driven modelling techniques that could be deployed to predict air quality accurately from the generated data-sets. This paper addresses these challenges by: a) proposing a comparative and detailed investigation of various air quality monitoring devices (both fixed and mobile), tested through field measurements and citizen sensing in an eco-neighbourhood from Lorraine, France, and by b) proposing a machine learning approach to evaluate the accuracy and potential of such mobile generated data for air quality prediction. The air quality evaluation consists of three experimenting protocols: a) first, we installed fixed passive tubes for monitoring the nitrogen dioxide concentrations placed in strategic locations highly affected by traffic circulation in an eco-neighbourhood, b) second, we monitored the nitrogen dioxide registered by citizens using smart and mobile pollution units carried at breathing level; results revealed that mobile-captured concentrations were 3–5 times higher than the ones registered by passive-static monitoring tubes and c) third, we compared different mobile pollution stations working simultaneously, which revealed noticeable differences in terms of result variability and sensitivity. Finally, we applied a machine learning modelling by using decision trees and neural networks on the mobile-generated data and show that humidity and noise are the most important factors influencing the prediction of nitrogen dioxide concentrations of mobile stations.",smart cities
10.1016/j.scitotenv.2019.02.339,Journal,Science of the Total Environment,scopus,2019-06-01,sciencedirect,Assessment of online bacterial particle counts for monitoring the performance of reverse osmosis membrane process in potable reuse,https://api.elsevier.com/content/abstract/scopus_id/85062375435,"Safety of potable reuse can be enhanced by improved water quality monitoring techniques for assessing water treatment processes. This study evaluated the efficacy of online bacterial counting for continuous monitoring of reverse osmosis (RO) membranes to remove bacteria using real-time bacteriological commercial counters and an on-site pilot-scale RO system. Prior to on-site assessments, the online bacterial counting was verified by comparing the measurement of fluorescent particles in water with flow cytometry. During a seven day pilot test of RO treatment at a water reclamation plant, online bacterial counts in RO permeate were monitored below 15 counts/mL; whereas the bacterial counts in RO feed water were approximately 2500 to 10,000 counts/mL. Removal rates of bacterial counts ranged from 2.6 to 3.1-log (average = 2.9-log) by continuously monitoring bacterial removal. This is greater than a 2-log reduction frequently determined using other water quality surrogates (i.e., electrical conductivity). Overall, the continuous monitoring of bacteria in RO feed and permeate can be implemented without the addition of chemicals to provide near real-time bacterial counts to measure their reduction after RO treatment. This can be developed for continuous performance monitoring of the RO process, providing greater assurance of microbial water quality after RO treatment.",smart cities
10.1016/j.knosys.2019.01.015,Journal,Knowledge-Based Systems,scopus,2019-05-15,sciencedirect,Day-ahead traffic flow forecasting based on a deep belief network optimized by the multi-objective particle swarm algorithm,https://api.elsevier.com/content/abstract/scopus_id/85062469265,"Traffic flow forecasting is a necessary part in the intelligent transportation systems in supporting dynamic and proactive traffic control and making traffic management plan. However, most of the previous studies attempting to build traffic flow forecasting models focus on short-term forecasting as the next step. In this paper, a deep feature leaning approach is proposed to predict short-term traffic flow in the following multiple steps using supervised learning techniques. To achieve traffic flow forecasting for the next day, an advanced multi-objective particle swarm optimization algorithm is applied to optimize some parameters in deep belief networks. The modified model can boost the accuracy of the forecasting results and enhance its multiple step prediction ability. Using real-time and historical temporal–spatial traffic data, day-ahead prediction experiment is implemented. The results of the hybrid model are compared with several commonly used benchmark models and some improved deep neural network based on evaluation criteria. Also, the proposed optimization algorithm is compared with the traditional particle swarm optimization algorithm. Furthermore, the significance in the number of hidden layers is analyzed. When the layers are increasing more than 4, the performance of the proposed model stops improving significantly. The results indicate the proposed model can extract complex features of traffic flow and therefore the forecasting accuracy and stability can be effectively improved.",smart cities
10.1016/j.scitotenv.2019.01.345,Journal,Science of the Total Environment,scopus,2019-05-15,sciencedirect,Different modelling approaches for predicting titanium dioxide nanoparticles mobility in intact soil media,https://api.elsevier.com/content/abstract/scopus_id/85061912312,"Understanding the transport behaviour of new and emerging materials such as engineered nanoparticles (ENPs) is vital for the accurate assessment of their functionality and fate in environmental systems. Predicting ENP mobility in soil systems based on common attributes of either soil or ENPs is of significant interest as an alternative to conducting laborious and time consuming column experiments. Thus this study investigates the importance of different soil properties and experimental conditions on titanium dioxide nanoparticles (nTiO2) mobility in real soil media and also evaluates four different modelling approaches including Multiple Linear Regression (MLR), Classification and Regression Tree (CART), Random Forest (RF) and Artificial Neural Network (ANN) for predicting nTiO2 mobility in soil media. The performance of both ANN and RF models were good for predicting nTiO2 transport in soil media, with ANN predictions being slightly superior to RF with less generalization errors. However, RF had the advantage of requiring less input predictors. In comparison the MLR model exhibited poor performance in both calibration and validation datasets, and while the validity of CART was almost acceptable in the calibration dataset, its efficiency was poor for the validation dataset. In addition to soil solution chemistry and hydraulic properties, other important factors having a major contribution to nTiO2 transport through soil included soil fracture associated properties and the existence of preferential flows.",smart cities
10.1016/j.exppara.2019.03.017,Journal,Experimental Parasitology,scopus,2019-05-01,sciencedirect,Minimal modulation of macrocyclic lactone susceptibility in Caenorhabditis elegans following inhibition of cytochrome P450 monooxygenase activity,https://api.elsevier.com/content/abstract/scopus_id/85064170705,"Anthelmintic and in particular macrocyclic lactone (ML) resistance is a widespread problem in trichostrongyloid parasitic nematodes, yet mechanisms of ML resistance are still poorly understood. In the absence of target-site changes in resistant parasite field populations, increased drug extrusion and xenobiotic metabolism have been implicated in modification of susceptibility to MLs. In addition to P-glycoproteins, cytochrome P450 monooxygenases (CYPs) were considered to be involved in ML resistance. CYPs are highly divergent in nematodes with about 80 genes in the model organism Caenorhabditis elegans. Using larval development assays in the C. elegans model, piperonyl butoxide (PBO) and a temperature-sensitive variant of the emb-8 cytochrome reductase were used for chemical and genetic ablation of CYP activity. Additionally, a loss-of-function variant of cyp-14A5 was characterized to determine whether increased expression of this CYP in an ivermectin (IVM)-tolerant C. elegans line might be related to the phenotype. In a preliminary experiment with PBO, susceptibility to 5 nM IVM was synergistically increased by PBO. However, effects of genetic ablation of CYP activity on the EC50 values were small (1.5-fold decrease) for IVM and not significant for moxidectin (MOX). However, due to the steep concentration-response-curves, there were again strong differences between the wild-type and the CYP deficient genotype at individual IVM but not MOX concentrations. Although these results suggest small but significant effects on the susceptibility level of C. elegans to IVM, the cyp14A5 gene proposed by a previous study as candidate was ruled out since it was neither IVM/MOX inducible nor did a strain with a loss-of-function allele show increased susceptibility to either drug. In conclusion, the effect of the CYP system on IVM susceptibility in C. elegans is at best low while effects on MOX susceptibility were not detected. The previously suggested candidate cyp14A5 could be excluded to be involved in ML metabolism.",smart cities
10.1016/j.trb.2018.06.012,Journal,Transportation Research Part B: Methodological,scopus,2019-05-01,sciencedirect,"Short-term travel behavior prediction with GPS, land use, and point of interest data",https://api.elsevier.com/content/abstract/scopus_id/85049525291,"In everyday travel, U.S. commuters will each spend 38 h a year stuck in traffic and waste over $800 in fuel (TTI, 2015). Yet, despite this statistic, the regular commute of drivers is often predictable, leading many federal projects to aim at alleviating congestion through traveler information and intelligent transportation systems (e.g., INFLO, Queue WARN, CACC, EnableATIS, ATIS2.0). Short-term destination prediction is a developing field of research that can improve these approaches through real-traveler information, such as route, traffic incidence, and congestion levels. The short-term destination prediction problem consists of capturing vehicle Global Positioning System (GPS) traces and learning from historic locations and trajectories to predict a vehicle's destination. Drivers have predictable trip destinations that can be estimated through probabilistic modeling of past trips. To study these concepts, a database of GPS driving traces (260 participants for 70 days) was collected. To model the user's trip purpose in the prediction algorithm, a new data source was explored: point of interest (POI)/land use data. An open source land use/POI dataset is merged with the GPS dataset. The resulting database includes over 20,000 trips with travel characteristics and land use/POI data. From land use/POI data and travel patterns, trip purpose was calculated with machine learning methods. To take advantage of this data source, a new prediction model structure was developed that uses trip purpose when it is available and that falls back on traditional spatial temporal Markov models when it is not. For the first time, there is an understanding of “why” a trip is taken (not just “where” and “when”), allowing the use of “why” in the prediction model. This paper explores the baseline model followed by the inclusion of trip purpose. First, a baseline tiered time origin model was developed using the Markov Chain approach. This modelling structure allows for a short training period of current modeling techniques. The other major advantage to this structure is it allows for easy implementation of the trip purpose module. Then, a machine learning technique derived the trip purpose on 5-, 15- and 30-trip learning sets, followed by results organized by purpose, time, and origin. The machine learning technique does not require future land use data and is feasible for applicable use. This model is the first to use trip purpose to make a short-term destination prediction in pseudo real-time. Results show improved accuracy and speed over the current start-of-trip destination prediction models.",smart cities
10.1016/j.neucom.2019.02.012,Journal,Neurocomputing,scopus,2019-04-21,sciencedirect,RNN-based default logic for route planning in urban environments,https://api.elsevier.com/content/abstract/scopus_id/85061662530,"Urban route planning is important for smart cities and intelligent transportation systems. Most of the exiting methods of urban route planning are either graph based search algorithms or optimization methods, however they show many weaknesses in real-world applications due to their high computational complexities and needs for global information of urban environments. To solve this problem, we propose a novel Recurrent Neural Network (RNN) based default logic for route planning. The proposed method is composed of three parts. The first part is the default theory of route planning, forcing no loops in the generated routes. The second part is the RNN based default reasoning to recommend default rules. The RNN outputs the probability distribution of the defaults used next, so the proposed method is a probabilistic method. The third part is the update algorithm of map models to improve the accuracy of default reasoning in dynamic environments. Training the proposed RNN is simple because no statistic computation is required for training. The time complexity of the proposed method during testing is just O(ρ
                     2), where ρ is the length of the optimal route for two given nodes. To evaluate the proposed method, we build a new map model named BJ simulating the complex urban environments of the Beijing city, China. Extensive experiments on the BJ map model in both static and dynamic environments show the effectiveness and accuracy of the proposed method.",smart cities
10.1016/j.energy.2019.02.032,Journal,Energy,scopus,2019-04-01,sciencedirect,Implementation of machine learning based real time range estimation method without destination knowledge for BEVs,https://api.elsevier.com/content/abstract/scopus_id/85062153000,"In this work, an advanced range estimation method based on experimental test data including environmental factors and dynamic vehicle parameters with driver and road type predictions is proposed for electric vehicles.
                  The focus point of the given study is to predict remaining range in general, at first start-up, without knowing future driving profile, in terms of giving an idea of how much distance can be travelled with the remaining amount of energy. Road type and driver profile are estimated by utilizing decision tree method and periodogram of jerk trace, respectively. Based on the preliminary results, utilized decision tree algorithm classifies the road type with an accuracy over 98%.
                  Vehicle range is estimated online by using machine learning algorithm based on experimental train data sets where chassis dynamometer tests were conducted by performing specific driving cycle in various conditions. For a real life verification, the vehicle is driven for a 50.4 km distance in a road having mostly urban driving characteristics. The results of real life measurements show that the proposed method predicts range with a low margin of error and estimates final remaining capacity 11.3% better than rated one.",smart cities
10.1016/j.ins.2018.11.028,Journal,Information Sciences,scopus,2019-04-01,sciencedirect,Machine learning based privacy-preserving fair data trading in big data market,https://api.elsevier.com/content/abstract/scopus_id/85056879362,"In the era of big data, the produced and collected data explode due to the emerging technologies and applications that pervade everywhere in our daily lives, including internet of things applications such as smart home, smart city, smart grid, e-commerce applications and social network. Big data market can carry out efficient data trading, which provides a way to share data and further enhances the utility of data. However, to realize effective data trading in big data market, several challenges need to be resolved. The first one is to verify the data availability for a data consumer. The second is privacy of a data provider who is unwilling to reveal his real identity to the data consumer. The third is the payment fairness between a data provider and a data consumer with atomic exchange. In this paper, we address these challenges by proposing a new blockchain-based fair data trading protocol in big data market. The proposed protocol integrates ring signature, double-authentication-preventing signature and similarity learning to guarantee the availability of trading data, privacy of data providers and fairness between data providers and data consumers. We show the proposed protocol achieves the desirable security properties that a secure data trading protocol should have. The implementation results with Solidity smart contract demonstrate the validity of the proposed blockchain-based fair data trading protocol.",smart cities
10.1016/j.bios.2018.12.047,Journal,Biosensors and Bioelectronics,scopus,2019-03-15,sciencedirect,Fabrication of an ultrasensitive and selective electrochemical aptasensor to detect carcinoembryonic antigen by using a new nanocomposite,https://api.elsevier.com/content/abstract/scopus_id/85060201085,"A lable-free electrochemical aptasensor was successfully developed for the sensitive detection of carcinoembryonic antigen as a tumor biomarker. To do this, a ternary nanocomposite of hemin, graphene oxide and multi-walled carbon nanotubes was used. The aptamer can be attached to the surface of a hemin, graphene oxide and multi-walled carbon nanotubes glassy carbon electrode through –NHCO- covalent bonds to form a sensing surface. Through fourier transform infrared spectroscopy and scanning electron microscopy, it was indicated that hemin can be successfully incorporated into hemin, graphene oxide and multi-walled carbon nanotubes. Hemin, which protects graphene nanosheets, also serves as an in-situ probe owing to its well-defined redox properties. Multi-walled carbon nanotubes in the modifier enhance conductivity and facilitate the electron transfer between hemin and the glassy carbon electrode. In this study, carcinoembryonic antigen got specifically bound to the aptamer, and the current changes were used for selective and specific detection of that antigen. The devised aptasensor proved to have excellent performance with a wide linear range of 1.0 × 10–15 – 1.0 × 10−8 gmL−1 and a detection limit of 0.82 fg mL−1. The inter-day and intra-day values of RSD% were obtained in the range of 0.10–2.91 and 2.21–4.56 respectively. According to the experiments conducted on real samples, it may be claimed that the proposed label-free electrochemical aptasensor is capable enough of determining carcinoembryonic antigen in clinical diagnostics.",smart cities
10.1016/j.scitotenv.2018.11.345,Journal,Science of the Total Environment,scopus,2019-03-15,sciencedirect,Wastewater-based monitoring of illicit drug consumption in Istanbul: Preliminary results from two districts,https://api.elsevier.com/content/abstract/scopus_id/85057321417,"Wastewater-based epidemiology is a well-established and complementary approach for monitoring illicit drug use in the general population. In this study, amphetamine (AMP), methamphetamine (METH), 3,4-methylenedioxymethamphetamine (MDMA), cocaine (COC) (from benzoylecgonine), and cannabis (from THC-COOH) consumption levels were investigated for the first time in Turkey (Istanbul). A solid-phase extraction method was applied to influent wastewater samples collected from two districts, Beyoglu and Catalca. Liquid chromatography-tandem mass spectrometry (LC-MS/MS) analysis was conducted with electrospray ionization in positive mode. Calibration curves were acquired in linear form with >0.999 correlation coefficients. Limit of detection levels were measured as 0.91–151 ng/L, and limit of quantitation levels were in the range of 3 to 500 ng/L. Solid-phase extraction recovery and repeatability experiments were achieved by spiking the mix solution to different concentrations (50, 250, 750 ng/L) in 50 mL tap water and wastewater (500, 1000 ng/L) samples in six replicates. The method was optimized, and recoveries were found to be over 80% for all six substances with up to 11.9% relative standard deviation. According to the real sample results, cannabis was found to be the most abused illicit substance among the analytes. The mean consumptions of the two districts, including seven consecutive days for AMP, METH, MDMA, COC, and cannabis, were found to be 27.2, 322, 331, 385, and 1224 mg/day/1000 inhabitants, respectively. In this presented study, all targeted compounds were analyzed simultaneously with the same analytical conditions. To the best of our knowledge, this report is the first to present illicit drug consumption data from Istanbul.",smart cities
10.1016/j.matdes.2018.107577,Journal,Materials and Design,scopus,2019-03-05,sciencedirect,Ensemble Kalman filter-based data assimilation for three-dimensional multi-phase-field model: Estimation of anisotropic grain boundary properties,https://api.elsevier.com/content/abstract/scopus_id/85059744257,"Data assimilation (DA) has been used as a machine learning approach to estimate a system's state and the unknown parameters in its numerical model by integrating observed data into model predictions. In this paper, we propose using the DA methodology based on the ensemble Kalman filter (EnKF) to improve the accuracy of microstructure prediction using three-dimensional multi-phase-field (3D-MPF) model and estimate the model parameters simultaneously. To demonstrate the applicability of the DA methodology, we performed numerical experiments in which a priori assumed true parameters related to the grain boundary (GB) energy cusp and GB mobility peak of Σ7 coincidence site lattice GB were estimated from synthetic data of time-evolving polycrystalline microstructure. Four model parameters related to the Σ7 GB properties were successfully estimated by assimilating the synthetic microstructure data to the 3D-MPF model predictions using the EnKF-based DA method. Furthermore, we accurately reproduced the preliminarily assumed true shapes of GB energy cusp and GB mobility peak by using the estimated parameters. The results suggest that implementation of the EnKF-based DA method in the MPF model has great potential for identifying unknown material properties and estimating unmeasurable microstructure evolutions in polycrystalline materials based on real time-series 3D microstructure observation data.",smart cities
10.1016/j.healthplace.2019.01.014,Journal,Health and Place,scopus,2019-03-01,sciencedirect,Public spaces and happiness: Evidence from a large-scale field experiment,https://api.elsevier.com/content/abstract/scopus_id/85060243870,"This study examines the relationships between public spaces, immediate environment and momentary subjective wellbeing (M-SWB). The empirical findings are based on a unique dataset collected from tens of thousands of students in Singapore. The students wore a sensor for one week, and happy moments were captured as well as geospatial an environmental data throughout the country. This is a large-scale in-the-wild user study. The findings provide weak empirical evidence that visiting parks and community centers increase the probability of experiencing M-SWB compared with commercial areas. In line with previous studies, proximity to natural influencers such as green-, blue spaces or reservoirs was found to be not statistically significant. On the other hand, immediate noise levels and air temperature were strongly associated with M-SWB. The unique contribution of the paper is the estimation of place-, environment-, and personal-effects on momentary happiness using nearly-real time data.",smart cities
10.1016/j.resourpol.2018.12.013,Journal,Resources Policy,scopus,2019-03-01,sciencedirect,State of the art about metaheuristics and artificial neural networks applied to open pit mining,https://api.elsevier.com/content/abstract/scopus_id/85059167765,"In search of the best way to extract and take advantage of minerals, highlighting that these are part of the most important raw materials for the economic development of today's society, the following bibliographical review is presented, which covers the main metaheuristic techniques highlighted in the optimization of mining processes and artificial neural networks (ANN), fundamental for predicting them; With this, the applications and results of these methods can be observed in mining unit operations such as: blasting, transport and mineral processing, which until now have models or techniques for their prediction that are not applicable in all mining complexes, as well as metaheuristics for three fundamental variables of open-pit planning, which are: geological uncertainty, cutting law and extraction programming. In addition to this, the proposals that have been developed in the global optimization of mining complexes are shown. There is also a brief description of how these techniques were applied to optimize the operations and previous variables of the mining planning, as well as their implementation in several mines around the world. The information shown shows available alternatives for the implementation of new actions in favor of reaching the objectives for real and hypothetical sites, yielding satisfactory results. Finally, the conclusions of this work are presented.",smart cities
10.1016/j.is.2018.10.005,Journal,Information Systems,scopus,2019-03-01,sciencedirect,Creative design of emergency management scenarios driven by semantics: An application to smart cities,https://api.elsevier.com/content/abstract/scopus_id/85057111728,"We present a framework to support creative design of emergency management scenarios. By creative design of scenarios we mean the process of imagining situations and describing them through models and stories. The framework supports the tasks of gathering and organizing knowledge about emergency management situations by automatically generating conceptual models, related to fragments of emergency scenarios. It leverages semantics-based techniques to enable a computational creativity approach. A software application was defined to support the activities of modeling scenarios by permitting to generate, organize, and query sets of these conceptual models, which we name mini-stories, and that can be adopted to inspire the activity of creative design. Selected mini-stories are blueprints for more detailed user scenario descriptions and models that can be used, for instance, for analysis or simulation. As a case study, we consider emergency management in smart cities. This is a challenging domain because smart cities are characterized by interconnected physical and virtual services forming complex ecosystems, which provide sophisticated services to the population and to institutions, manage public resources in a optimal way, and involve citizens in decisional processes. As a consequence, smart city ecosystems can be threatened by several hazards spanning from natural disasters, as tsunami and earthquakes, to anthropic events, as terrorist attacks. Ability of service providers and institutional operators to face and manage emergency situations is therefore a relevant issue. Simulation and analysis of both crisis events and executions of management plans are a promising approach to deal with these articulated problems. However, manual definition of models to base the analysis is a demanding activity due to the huge number of different situations to consider. It requires knowledge related to the crisis and emergency domains, to the context (e.g., a specific city and its current regulations) and ability in modeling tasks. All these aspects demand for tools to support modeling activities, and our proposal aims at fulfilling this need. In particular, the discussed framework uses in a integrated way three types of knowledge: structural knowledge, to support the construction of models based on design patterns; domain knowledge, here related to smart cities and emergency management and represented by means of ontologies; and contextual knowledge, related to specific aspects (e.g., localization) of the considered scenario and represented as rules. We validated the presented approach by means of experiments performed by real city planners.",smart cities
10.1016/j.future.2017.08.009,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,AGRA: AI-augmented geographic routing approach for IoT-based incident-supporting applications,https://api.elsevier.com/content/abstract/scopus_id/85028541738,"Applications that cater to the needs of disaster incident response generate large amount of data and demand large computational resource access. Such datasets are usually collected in real-time at the incident scenes using different Internet of Things (IoT) devices. Hierarchical clouds, i.e., core and edge clouds, can help these applications’ real-time data orchestration challenges as well as with their IoT operations scalability, reliability and stability by overcoming infrastructure limitations at the ad-hoc wireless network edge. Routing is a crucial infrastructure management orchestration mechanism for such systems. Current geographic routing or greedy forwarding approaches designed for early wireless ad-hoc networks lack efficient solutions for disaster incident-supporting applications, given the high-speed and low-latency data delivery that edge cloud gateways impose. In this paper, we present a novel Artificial Intelligent (AI)-augmented geographic routing approach, that relies on an area knowledge obtained from the satellite imagery (available at the edge cloud) by applying deep learning. In particular, we propose a stateless greedy forwarding that uses such an environment learning to proactively avoid the local minimum problem by diverting traffic with an algorithm that emulates electrostatic repulsive forces. In our theoretical analysis, we show that our Greedy Forwarding achieves in the worst case a 
                        3
                        .
                        291
                      path stretch approximation bound with respect to the shortest path, without assuming presence of symmetrical links or unit disk graphs. We evaluate our approach with both numerical and event-driven simulations, and we establish the practicality of our approach in a real incident-supporting hierarchical cloud deployment to demonstrate improvement of application level throughput due to a reduced path stretch under severe node failures and high mobility challenges of disaster response scenarios.",smart cities
10.1016/j.esd.2018.12.002,Journal,Energy for Sustainable Development,scopus,2019-02-01,sciencedirect,Identifying urban geometric types as energy performance patterns,https://api.elsevier.com/content/abstract/scopus_id/85058706592,"This paper aims to find the impact of geometric parameters on the energy performance of buildings, to using them to identify types regarding major geometric characteristics of a target area. Conventional approaches to control energy efficiency of buildings mainly focus on materials and capacity of insulation, but rarely consider urban and building geometries. By examining energy impacts on urban blocks by urban geometric forms, this paper seeks to identify urban geometric types and energy patterns on urban blocks. To achieve the aims of this study, this paper follows two steps: First, significant indicators for analyzing energy performance are identified in urban geometries; second, the types that capture urban geometry of a real city are categorized. As a result, as a reference for urban planning and design, the paper identifies 13 types that represent the characteristics of urban geometries regarding energy performance. The geometric indicators are carefully measured and their significance to energy performance of buildings is examined through regression analysis. According to these indicators, the 13 types are categorized using a hierarchical clustering algorithm, a machine learning method. Additionally, the 13 types are discussed for implementation as references in urban planning and design, particularly in block planning for a city.",smart cities
10.1016/j.comnet.2018.11.013,Journal,Computer Networks,scopus,2019-01-15,sciencedirect,Towards automatic fingerprinting of IoT devices in the cyberspace,https://api.elsevier.com/content/abstract/scopus_id/85056904979,"Nowadays, the cyberspace consists of an increasing number of IoT devices, such as net-printers, webcams, and routers. Illuminating the nature of online devices would provide insights into detecting potentially vulnerable devices on the Internet. However, there is a lack of device discovery in large-scale due to the massive number of device models (i.e., types, vendors, and products). In this paper, we propose an efficient approach to generate fingerprints of IoT devices. We observe that device manufacturers have different network system implementations on their products. We explore features spaces of IoT devices in three network layers, including the network-layer, transport-layer, and application-layer. Utilizing the feature of network protocols, we generate IoT device fingerprints based on neural network algorithms. Furthermore, we implement the prototype system and conduct real experiments to validate the performance of device fingerprints. Results show that our classification can generate device class labels with a 94% precision and 95% recall. We use those device fingerprints to discover 15.3 million network-connected devices and analyze their distribution characteristics in cyberspace.",smart cities
10.1016/j.procs.2019.09.442,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Unmanned aerial vehicle in the machine learning environment,https://api.elsevier.com/content/abstract/scopus_id/85079097933,"Unmanned Aerial Vehicles and machine learning have started gaining attentions of academic and industrial research. The Unmanned Aerial Vehicles have extended the freedom to operate and monitor the activities from remote locations. This study retrieved and synthesized research on the use of Unmanned Aerial Vehicles along with machine learning and its algorithms in different areas and regions. The objective was to synthesize the scope and importance of machine learning models in enhancing Unmanned Aerial Vehicles capabilities, solutions to problems, and numerous application areas.
                  The machine learning implementation has reduced numbers of challenges to Unmanned Aerial Vehicles besides enhancing the capabilities and opening the door to the different sectors. The Unmanned Aerial Vehicles and machine learning association has resulted in fast and reliable outputs. The combination of Unmanned Aerial Vehicles and machine learning has helped in real time monitoring, data collection and processing, and prediction in the computer/wireless networks, smart cities, military, agriculture, and mining.",smart cities
10.1016/j.procs.2019.09.181,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,A quantum genetic algorithm for pickup and delivery problems with coalition formation,https://api.elsevier.com/content/abstract/scopus_id/85076257816,"With the “last mile” of the delivery process being the most expensive phase, autonomous package delivery systems are gaining traction as they aim for faster and cheaper delivery of goods to city, urban and rural destinations. This interest is further fueled by the emergence of e-commerce, where many applications can benefit from autonomous package delivery solutions. However, the environment stochasticity, variability and task complexity for autonomous operation make it difficult to deploy such systems in real-world applications without the incorporation of advanced machine learning and optimization algorithms. Moving away from designing a “one size fits all” agent to solve the outdoor package delivery problem and considering ad-hoc teams of agents trained within a data-driven framework could provide the answer. In this work, we propose a delivery scheduling algorithm for heterogeneous multi-agent systems using the pickup and delivery problem (PDP) formulation. Specifically, a 3-index mixed integer program-based PDP that allows coalition formation (PDP-CF) among agents is derived to allow multi-agent PDP schedules. We propose a quantum genetic algorithm to solve for the schedule since it is can better handle the large computational complexity of PDP-CF. Multiple PDP scenario simulations show the merits of the proposed approach.",smart cities
10.1016/j.procs.2019.08.214,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Flood Forecasting with Machine Learning Technique on Hydrological Modeling,https://api.elsevier.com/content/abstract/scopus_id/85074543718,"Urban flooding is a major problem in Thailand. An essential countermeasure towards better flooding management is to forecast flood water levels in the real-time manner. Most existing early warning systems (EWS) in Thailand contain a lot of miscalculations when they face with real situations. Towards prediction improvement, this paper presents hydrological modeling augmented with alternative five machine learning techniques; linear regression, neural network regression, Bayesian linear regression and boosted decision tree regression. As the testbed system, the so-called MIKE-11 hydrologic forecasting model, developed by Danish Hydraulic Institute (DHI), Denmark, is used. To test error reduction in runoff forecasting, the water-level records during 2012-2016 data are used for training and the derived model is tested on the record of 2017, in the experiments.",smart cities
10.1016/j.procs.2019.09.007,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Increase the interest in learning by implementing augmented reality: Case studies studying rail transportation.,https://api.elsevier.com/content/abstract/scopus_id/85073117730,"Learn a subject, for some people, might be an uninteresting and boring activity, especially when the subject to learn are difficult subjects to understand. Many methods used to change learning activities become more enjoyable and interested. This study proposed a new method in learning activities, by applied augmented reality technology in the learning process. The case study used in this paper are implementation the augmented reality in studied subjects related to train technology. In this study, author implement augmented reality on learning material, combines real and virtual things in one media, in this case a mobile device. The impact of implementation of augmented studied, at the end of experiment, author can conclude when implement augmented reality technology in learning material helps the learning process and increasing the impressive and fun factor in learning process and make the learning process more interested. Implementation of Augmented Reality in learning material gives more information about the object being studied, information about on shapes, textures, and provide more visualization for the object.",smart cities
10.1016/j.procs.2019.04.090,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Deep neural network method of recognizing the critical situations for transport systems by video images,https://api.elsevier.com/content/abstract/scopus_id/85071926362,"The deep neural network method of recognizing critical situations for transport systems according to video frames from the intelligent vehicles cameras is offered, that is effective in terms of accuracy and high-speed performance. Unlike the known solutions for the objects and normal or critical situations detection and recognition, it uses the classification with the subsequent reinforcement on the basis of several video stream frames and with the automatic annotation algorithm. The adapted architectures of neural networks are offered: the dual network to identify drivers and passengers according to the face image, the network with independent recurrent layers to classify situations according to the video fragment. The scheme of the intellectual distributed city system of transport safety using the cameras and on-board computers united in a single network is offered. Software modules in Python are developed and natural experiments are made. The possibility of the offered algorithms and programs in UGV or in the driver assistant systems implementation is shown with the illustrating examples in real-time.",smart cities
10.1016/j.trc.2018.12.007,Journal,Transportation Research Part C: Emerging Technologies,scopus,2019-01-01,sciencedirect,Cordon control with spatially-varying metering rates: A Reinforcement Learning approach,https://api.elsevier.com/content/abstract/scopus_id/85058715529,"The work explores how Reinforcement Learning can be used to re-time traffic signals around cordoned neighborhoods. An RL-based controller is developed by representing traffic states as graph-structured data and customizing corresponding neural network architectures to handle those data. The customizations enable the controller to: (i) model neighborhood-wide traffic based on directed-graph representations; (ii) use the representations to identify patterns in real-time traffic measurements; and (iii) capture those patterns to a spatial representation needed for selecting optimal cordon-metering rates. Input to the selection process also includes a total inflow to be admitted through a cordon. The rate is optimized in a separate process that is not part of the present work. Our RL-controller distributes that separately-optimized rate across the signalized street links that feed traffic through the cordon. The resulting metering rates vary from one feeder link to the next. The selection process can reoccur at short time intervals in response to changing traffic patterns. Once trained on a few cordons, the RL-controller can be deployed on cordons elsewhere in a city without additional training.
                  This portability feature is confirmed via simulations of traffic on an idealized street network. The tests also indicate that the controller can reduce the network’s vehicle hours traveled well beyond what can be achieved via spatially-uniform cordon metering. The extra reductions in VHT are found to grow larger when traffic exhibits greater in-homogeneities over the network.",smart cities
10.1016/j.biopha.2018.10.106,Journal,Biomedicine and Pharmacotherapy,scopus,2019-01-01,sciencedirect,SGLT-2 inhibitors reduce glucose absorption from peritoneal dialysis solution by suppressing the activity of SGLT-2,https://api.elsevier.com/content/abstract/scopus_id/85056279239,"Background
                  Sodium glucose cotransporter-2 (SGLT-2) inhibitors have been widely used in the clinic to reduce blood glucose levels by enhancing glucose excretion. However, whether such agents might also reduce glucose absorption via the peritoneal function of human peritoneal mesothelial cells (HPMCs) that also express SGLT-2 is not clear.
               
                  Methods
                  An acute peritoneal dialysis (PD) model in nonuremic rats was established. Ratios of peritoneal glucose uptake at D4/D0 of Sprague-Dawley rats treated with the SGLT-2 inhibitor, empagliflozin were tested to evaluate the effect of this inhibitor on peritoneal glucose absorption. An in vitro model of HPMCs obtained from peritoneal dialysate effluent in patients undergoing PD was used. HPMCs were exposed to high glucose (60 mM) in the presence and absence of empagliflozin. Glucose uptake and glucose consumption, which were used to estimate the activity of SGLT-2 in HPMCs, were measured by flow cytometry and hexokinase respectively. The expression of SGLT-2 in both peritoneum and HPMCs was also observed by real-time polymerase chain reaction (PCR), western blot, and immunofluorescence staining.
               
                  Results
                  Both ratios of peritoneal glucose uptake at D4/D0 and ultrafiltration of rats treated with 3 mg kg−1 of empagliflozin for 3 days increased significantly compared to those of the control group (0.32 ± 0.40 vs. 0.11 ± 0.11 mM, P = 0.001；17.00 ± 3.58 vs. -13.67 ± 17.25 ml, P = 0.002). Compared to the control group, the expression of mRNA and protein in SGLT-2 increased significantly in the rats treated with 3 mg kg−1 of empagliflozin for 3 days. Both glucose consumption and uptake of HPMCs incubated with 1 μM of empagliflozin for 24 h decreased significantly compared to control values (8.69 ± 1.77 vs. 11.48 ± 1.00 mM, P = 0.004; 31.97 ± 4.81 vs. 43.98 ± 1.38, P =  0.002).
               
                  Conclusion
                  An SGLT-2 inhibitor was able to exert a glucose-lowering effect in peritoneum exposed to PD solution by inhibiting the activity of SGLT-2.",smart cities
10.1016/j.ijbiomac.2018.10.047,Journal,International Journal of Biological Macromolecules,scopus,2019-01-01,sciencedirect,Functional characterization of two ABC transporters in Sinonovacula constricta gills and their barrier action in response to pathogen infection,https://api.elsevier.com/content/abstract/scopus_id/85054840014,"P-glycoprotein (P-gp or ABCB1) and multidrug resistance associated proteins (MRPs or ABCC) belonging to the family of ATP-binding cassette (ABC) transporters protect aquatic organisms from various toxicants and pathogen exposure. The function of ABC transporters of Sinonovacula constricta in response to pathogens was explored by cloning the complete cDNA of ABCB1 and ABCC5 of S. constricta through the rapid amplification of cDNA ends. Tissue-specific expression showed that ABCB1 and ABCC5 have the highest expression in hemocytes and gills among eight examined tissues, respectively. The transport activities of ABCB1 and ABCC5 in the gills were severely inhibited after their corresponding inhibitor treatments. The expression levels and transport activities of ABCB1 and ABCB5 were also investigated by using S. constricta samples infected by Vibrio parahaemolyticus at a final concentration of 107 CFU/mL. Results showed that the mRNA expression levels of ABCB1 and ABCC5 were significantly down-regulated when exposed to V. parahaemolyticus at 6 h and 12 h (P < 0.05) and then recovered to normal level at 24 h and 48 h. Consistently, the activities of the two ABC transporters display the same trends as the mRNA expression levels. The results, combined with that of previous investigations, indicated that these activities may be an innate immune response in S. constricta. Immunohistochemical results justified the tissue localization of P-gp in the interface between external environment and tissues. Taken together, our findings demonstrated that ABC transporters form an active, physiological barrier at the tissue–environment interface in S. constricta gills in response to pathogen infection, and they might play a vital role in adaptation and response to environmental stress and the immune defense.",smart cities
10.1016/j.knosys.2018.08.015,Journal,Knowledge-Based Systems,scopus,2019-01-01,sciencedirect,Intelligent operation of heavy haul train with data imbalance: A machine learning method,https://api.elsevier.com/content/abstract/scopus_id/85052841819,"Compared with high speed trains and metro subways, heavy haul train operations are more challenging for their complex dynamic characteristics and complicated running environments. When running on a continuous and steep descent, the air brake operation strategy has become the most important issue for the safety and efficiency of heavy haul train transportation. Due to the difficulty in modeling the train’s dynamics and pneumatic brake system precisely, this paper addresses the intelligent driving problem for heavy haul train based on the fusion of expert knowledge and machine learning methodologies. By considering the characteristics of manual driving on steep descent, the pneumatic brake operation problem is formulated as a multi-class classification model. To overcome the negative influences of data imbalances, EasyEnsemble for the multi-class with a KNN based Denoising (EMKD) algorithm is introduced to determine the feasible Air Pressure Reduction (APR) and the exact time for exerting and releasing the air brake. This approach utilizes the EasyEnsemble.M algorithm to moderate the class imbalanced datasets and takes advantage of the AdaBoost.M1 algorithm to ensemble weak classifiers. Specifically, the K-nearest neighbor based Denoising (KD) algorithm is elaborated to remove the possible noise data from the minority dataset. Additionally, expert knowledge is obtained by abstracting the experience of sophisticated drivers and technical specifications, which are employed as operating constraints to regulate the output of the EMKD algorithm. The operational safety in terms of the in-train forces and punctuality of the proposed algorithm are validated by a number of experiments under the real running circumstances of Shuohuang heavy haul railway.",smart cities
10.1016/j.cyto.2018.06.002,Journal,Cytokine,scopus,2019-01-01,sciencedirect,Porcine reproductive and respiratory syndrome virus induces concurrent elevation of High Mobility Group Box-1 protein and pro-inflammatory cytokines in experimentally infected piglets,https://api.elsevier.com/content/abstract/scopus_id/85048284087,"Porcine Reproductive and Respiratory Syndrome (PRRS), caused by PRRS virus (PRRSV), is one of the most important devastating diseases of pigs, characterized by reproductive failure in sows, and respiratory disease with heavy mortality in piglets. PRRS virus has been reported to elevate the levels of proinflammatory cytokines in the serum of infected pigs. High Mobility Group Box-1 (HMGB-1) protein is a cellular biomolecule belonging to the Danger Associated Molecular Patterns (DAMP) family, which stimulates immune cells to release pro-inflammatory cytokines upon release out of cells. The role of HMGB-1 in the pathogenesis of PRRSV remains largely unknown. In the present study, HMGB-1 levels in serum samples collected from six-week-old piglets infected intra-nasally with 2 × 105.75 TCID50/mL of Indian PRRSV (Ind-297221/2013) was estimated by ELISA up to 21 days post infection (dpi). Pro-inflammatory cytokine mRNA (IL-1β, IL-6 and TNF- α) expression in PBL was estimated by SYBR green based real time PCR. Mean HMGB-1 concentration in serum was found to be significantly elevated in PRRSV infected piglets on 6 dpi as compared to uninfected control piglets. At mRNA level, significant increase in expression of HMGB-1 was observed from 4 to 5 dpi and from 11 to 13 dpi. IL-1β and IL-6 mRNA were significantly upregulated between 4 and 6 dpi. Significant increase in TNF-α gene expression was seen only on 7 and 9 dpi. Higher levels of pro-inflammatory cytokines and HMGB-1 could be correlated with fever which was observed within 7 dpi in all the infected piglets and additionally around 13 dpi in the animal that died on 17 dpi. Thus, elevated HMGB-1 level in PRRSV infected piglets could be correlated with concurrent increase in pro-inflammatory cytokine (IL-6) mRNA. In-vitro studies were conducted in PRRSV infected Porcine Pulmonary Alveolar Macrophages (PAM) to ascertain HMGB-1 role in PRRS pathogenesis. The results of both in-vivo and in-vitro studies showed that HMGB-1 plays an important role in mediating the pro-inflammatory cytokine responses in PRRS pathogenesis.",smart cities
10.1016/j.oceaneng.2018.10.009,Journal,Ocean Engineering,scopus,2018-12-15,sciencedirect,Novel DVS guidance and path-following control for underactuated ships in presence of multiple static and moving obstacles,https://api.elsevier.com/content/abstract/scopus_id/85054883863,"This note focuses on the waypoints-based path-following problem of underactuated ships, where the reference path is surrounded by multiple static and moving obstacles. By virtue of the improved dynamical virtual ship (DVS) principle, a novel guidance law with multi-obstacles avoidance is proposed to generate the real-time attitude reference. In this approach, the manoeuvering tasks are specified as three priority levels: the static obstacle avoidance, the moving obstacle avoidance and the path-following mission. And the detailed design abides the International Regulations for Preventing Collisions at Sea (COLREGs) to ensure the sailing safety, especially for moving obstacles or other vessels. Furthermore, a robust neural algorithm is developed by using the neural networks (NNs) approximation and the robust neural damping technique. The system gain uncertainty of actuators is tackled and less information about the hydrodynamic structure, the actuator model and the external disturbances are required. Considerable efforts are made to obtain the semi-global practical finite-time bounded (SGPFB) stability. The proposed scheme is with advantages of concise structure and improved autonomy. Finally, two experiments are employed to verify the effectiveness of the proposed strategy.",smart cities
10.1016/j.eswa.2018.06.037,Journal,Expert Systems with Applications,scopus,2018-12-15,sciencedirect,Two-echelon logistics delivery and pickup network optimization based on integrated cooperation and transportation fleet sharing,https://api.elsevier.com/content/abstract/scopus_id/85049438774,"The optimization of the two-echelon logistics delivery and pickup network (2E-LDPN) is a strategical and tactical task which can efficiently be achieved by establishing cooperative alliances. Under the coordination of logistics services providers or logistics facilities of the existing network, high operating costs caused by cross and long distance transportation can be reduced via the inclusive reorganization of the entire network. In order to minimize the total cost, this study simultaneously considers semitrailer truck and vehicle sharing, and establishes a linear mathematical model capable of interpreting real world practices under single or multiple alliances scenarios. An Improved Particle Swarm Optimization (IPSO) algorithm and the Ant Colony Optimization (ACO) algorithm are reasonably combined into a hybrid meta-heuristics to solve the cooperative 2E-LDPN optimization problem. This algorithm combines the merits of IPSO and ACO with local and global search capabilities, and redistributes customer zones on the basis of region partitioning solutions in order to rationalize transportation activities. Finally, an Improved Shapley value model is applied to guarantee profits allocation's fairness and is proved reliable in term of alliance stability. Empirical results out of a case study in Chongqing city show that the IPSO–ACO hybrid algorithm is superior to three well-known algorithms on the cost solution and the number of iterations. Using the Improved Shapley value model and strictly monotonic path (SMP) selection principles, optimal adhesion sequences for two alliances and a grand alliance are yielded. The implemented transition from two sub-alliances based network to the grand alliance is in line with real-world's practices and provides decision makers with a useful tool for the design of cooperative alliances. In addition, the proposed cooperation strategy and profit allocation method enable companies to increase cost savings and the logistics network's efficiency. Besides, semitrailer truck and vehicle sharing as feature of collaboration conditional clauses reduces the size of transportation fleets, and promotes greener logistics operations.",smart cities
10.1016/B978-0-12-814601-9.00020-1,Book,Multimodal Behavior Analysis in the Wild: Advances and Challenges.,scopus,2018-11-16,sciencedirect,Wearable systems for improving tourist experience,https://api.elsevier.com/content/abstract/scopus_id/85072183737,"In this chapter we present original approaches for the development of a smart audio-guide that adapts to the actions and interests of visitors of cultural heritage sites and exhibitions either in indoor or outdoor scenarios. The guide is capable of perceiving the context. It understands what the user is looking at, if he is moving or is inattentive (e.g. talking with someone), in order to provide relevant information at the appropriate timing. Automatic recognition of artworks is performed with different approaches depending on the scenario, i.e. indoor and outdoor. These approaches are, respectively, based on Convolutional Neural Network (CNN) and SIFT descriptors, performing, when appropriate, object localization and classification. The computer-vision system works in real time on the mobile device, exploiting also a fusion of audio and motion sensors. Configurable interfaces to ease interaction and fruition of multimedia insights are provided for both scenarios. The audio-guide has been deployed on a NVIDIA Jetson TX1 and a NVIDIA Shield Tablet K1, tested in a real world environment (Bargello Museum of Florence and the historical city center of Florence), and evaluated with regard to system usability.",smart cities
10.1016/j.neucom.2018.06.049,Journal,Neurocomputing,scopus,2018-11-07,sciencedirect,A Deep Spatial-Temporal Ensemble Model for Air Quality Prediction,https://api.elsevier.com/content/abstract/scopus_id/85049832090,"Air quality has drawn much attention in the recent years because it seriously affects people’s health. Nowadays, monitoring stations in a city can provide real-time air quality, but people also strongly desire air quality prediction, which is a challenging problem as it depends on several complicated factors, such as weather patterns and spatial-temporal dependencies of air quality. In this paper, we design a data-driven approach that utilizes historical air quality and meteorological data to predict air quality in the future. We propose a deep spatial-temporal ensemble(STE) model which is comprised of three components. The first component is an ensemble method with a weather-pattern-based partitioning strategy. It trains multiple individual models and combines them dynamically. The second one is to discover spatial correlation by analyzing Granger causalities among stations and generating spatial data as relative stations and relative areas. The last one is a temporal predictor based on deep LSTM to learn both long-term and short-term dependencies of air quality. We evaluate our model with data from 35 monitoring stations in Beijing, China. The experiments show that each component of our model makes contribution to the improvement in prediction accuracy and the model is superior to baselines.",smart cities
10.1016/j.compag.2018.09.037,Journal,Computers and Electronics in Agriculture,scopus,2018-11-01,sciencedirect,A decision support tool to enhance agricultural growth in the Mékrou river basin (West Africa),https://api.elsevier.com/content/abstract/scopus_id/85054181612,"We describe in this paper the implementation of E-Water, an open software Decision Support System (DSS), designed to help local managers assess the Water Energy Food Environment (WEFE) nexus. E-Water aims at providing optimal management solutions to enhance food crop production at river basin level. The DSS was applied in the transboundary Mékrou river basin, shared among Benin, Burkina Faso and Niger. The primary sector for local economy in the region is agriculture, contributing significantly to income generation and job creation. Fostering the productivity of regional agricultural requires the intensification of farming practices, promoting additional inputs (mainly nutrient fertilizers and water irrigation) but, also, a more efficient allocation of cropland.
                  In order to cope with the heterogeneity of data, and the analyses and issues required by the WEFE nexus approach, our DSS integrates the following modules: (1) the EPIC biophysical agricultural model; (2) a simplified regression metamodel, linking crop production with external inputs; (3) a linear programming and a multiobjective genetic algorithm optimization routines for finding efficient agricultural strategies; and (4) a user-friendly interface for input/output analysis and visualization.
                  To test the main features of the DSS, we apply it to various real and hypothetical scenarios in the Mékrou river basin. The results obtained show how food unavailability due to insufficient local production could be reduced by, approximately, one third by enhancing the application and optimal distribution of fertilizers and irrigation. That would also affect the total income of the farming sector, eventually doubling it in the best case scenario. Furthermore, the combination of optimal agricultural strategies and modified optimal cropland allocation across the basin would bring additional moderate increases in food self-sufficiency, and more substantial gains in the total agricultural income.
                  The proposed software framework proves to be effective, enabling decision makers to identify efficient and site-specific agronomic management strategies for nutrients and water. Such practices would augment crop productivity, which, in turn, would allow to cope with increasing future food demands, and find a balanced use of natural resources, also taking other economic sectors—like livestock, urban or energy—into account.",smart cities
10.1016/j.jnca.2018.06.010,Journal,Journal of Network and Computer Applications,scopus,2018-10-15,sciencedirect,A framework for healthcare support in the rural and low income areas of the developing world,https://api.elsevier.com/content/abstract/scopus_id/85049924793,"Cyber-Healthcare is an emerging field of the healthcare domain that builds upon cyber physical health systems (CPHSs) to provide pervasive access to medical services any time and from anywhere in the world where medical expertise is available. It is expected to change the way healthcare is delivered in the developing world and enable both its rural and urban settings to leapfrog from poorly equipped to medically prepared environments capable of tackling some of its most challenging health issues. However, owing to their infancy stage in the developing world, CPHSs require substantial research and practical work to move from their theoretical boundaries into the development, deployment and exploitation phase. This paper proposes a Cyber-Healthcare framework and its implementation as a fog-based CPHS infrastructure using low-cost lightweight devices to achieve patients' condition recognition as a first step towards the implementation of digital healthcare support systems in the developing world. We propose a multi-layer architecture for the framework and consider a patients' condition recognition system that uses machine learning techniques as a key component of the framework. We present experimental results that reveal i) the relative efficiency of different machine learning algorithms used for patient condition recognition and ii) the storage and processing overheads incurred by two popular lightweight embedded devices when used as fog computing devices in the CPHS.",smart cities
10.1016/j.cmpb.2018.08.013,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-10-01,sciencedirect,A facial expression controlled wheelchair for people with disabilities,https://api.elsevier.com/content/abstract/scopus_id/85052210734,"Background and Objectives
                  In order to improve assistive technologies for people with reduced mobility, this paper develops a new intelligent real-time emotion detection system to control equipment, such as electric wheelchairs (EWC) or robotic assistance vehicles. Every year, degenerative diseases and traumas prohibit thousands of people to easily control the joystick of their wheelchairs with their hands. Most current technologies are considered invasive and uncomfortable such as those requiring the user to wear some body sensor to control the wheelchair.
               
                  Methods
                  In this work, the proposed Human Machine Interface (HMI) provides an efficient hands-free option that does not require sensors or objects attached to the user's body. It allows the user to drive the wheelchair using its facial expressions which can be flexibly updated. This intelligent solution is based on a combination of neural networks (NN) and specific image preprocessing steps. First, the Viola-Jones combination is used to detect the face of the disability from a video. Subsequently, a neural network is used to classify the emotions displayed on the face. This solution called ""The Mathematics Behind Emotion"" is capable of classifying many facial expressions in real time, such as smiles and raised eyebrows, which are translated into signals for wheelchair control. On the hardware side, this solution only requires a smartphone and a Raspberry Pi card that can be easily mounted on the wheelchair.
               
                  Results
                  Many experiments have been conducted to evaluate the efficiency of the control acquisition process and the user experience in driving a wheelchair through facial expressions. The classification accuracy can expect 98.6% and it can offer an average recall rate of 97.1%. Thus, all these experiments have proven that the proposed system is able of accurately recognizing user commands in real time. Indeed, the obtained results indicate that the suggested system is more comfortable and better adapted to severely disabled people in their daily lives, than conventional methods. Among the advantages of this system, we cite its real time ability to identify facial emotions from different angles.
               
                  Conclusions
                  The proposed system takes into account the patient's pathology. It is intuitive, modern, doesn't require physical effort and can be integrated into a smartphone or tablet. The results obtained highlight the efficiency and reliability of this system, which ensures safe navigation for the disabled patient.",smart cities
10.1016/j.trc.2018.07.008,Journal,Transportation Research Part C: Emerging Technologies,scopus,2018-10-01,sciencedirect,A knowledge-transfer-based learning framework for airspace operation complexity evaluation,https://api.elsevier.com/content/abstract/scopus_id/85050134533,"A sector is a component airspace whose operation is allocated to an air traffic controller. The operation complexity of a sector plays a critical role in the current Air Traffic Management system, e.g. it determines the workload volume of air traffic controllers and serves as a reliable index for airspace configuration and traffic flow management. Therefore, accurately evaluating the sector operation complexity is a problem of paramount importance in both practice and research. Due to numerous interacting factors, traditional methods based on only one single complexity indicator fail to accurately reflect the true complexity, especially when these factors are nonlinearly correlated. In light of these, the attempt to use machine learning models to mine the complex factor-complexity relationship has prevailed recently. The performance of these models however relies heavily on sufficient samples. The high cost of collecting ample data often results in a small training set, adversely impacting on the performance that these machine learning models can achieve. To overcome this problem, this paper for the first time proposes a new sector operation complexity evaluation framework based on knowledge transfer specifically for small-training-sample environment. The proposed framework is able to effectively mine knowledge hidden within the samples of the target sector, i.e. the sector undergoes evaluation, as well as other sectors, i.e. non-target sectors. Moreover, the framework can properly handle the integration between the knowledge derived from different sectors. Extensive experiments on real data of 6 sectors in China illustrate that our proposed framework can achieve promising performance on complexity evaluation when only a small training set of the target sector is available.",smart cities
10.1016/j.future.2018.05.013,Journal,Future Generation Computer Systems,scopus,2018-10-01,sciencedirect,A resilient and distributed near real-time traffic forecasting application for Fog computing environments,https://api.elsevier.com/content/abstract/scopus_id/85047314955,"In this paper we propose an architecture for a city-wide traffic modeling and prediction service based on the Fog Computing paradigm. The work assumes an scenario in which a number of distributed antennas receive data generated by vehicles across the city. In the Fog nodes data is collected, processed in local and intermediate nodes, and finally forwarded to a central Cloud location for further analysis. We propose a combination of a data distribution algorithm, resilient to back-haul connectivity issues, and a traffic modeling approach based on deep learning techniques to provide distributed traffic forecasting capabilities. In our experiments, we leverage real traffic logs from one week of Floating Car Data (FCD) generated in the city of Barcelona by a road-assistance service fleet comprising thousands of vehicles. FCD was processed across several simulated conditions, ranging from scenarios in which no connectivity failures occurred in the Fog nodes, to situations with long and frequent connectivity outage periods. For each scenario, the resilience and accuracy of both the data distribution algorithm, and the learning methods were analyzed. Results show that the data distribution process running in the Fog nodes is resilient to back-haul connectivity issues and is able to deliver data to the Cloud location even in presence of severe connectivity problems. Additionally, the proposed traffic modeling and forecasting method exhibits better behavior when run distributed in the Fog instead of centralized in the Cloud, especially when connectivity issues occur that force data to be delivered out of order to the Cloud.",smart cities
10.1016/j.scs.2018.06.004,Journal,Sustainable Cities and Society,scopus,2018-08-01,sciencedirect,Provably secure pseudo-identity based device authentication for smart cities environment,https://api.elsevier.com/content/abstract/scopus_id/85049310156,"IoT based smart city idea is evolving with an intention of improving the quality of citizens’ life by practicing information and communication technologies. Smart city concept is believed to be possible by integrating the evolving technologies such as internet of things (IoT), automation and machine learning in which IoT holds the key role. Authentication has already been identified as a foremost security concern around the IoT, as millions of small devices go online and begin to share their data. Authentication in IoT environment mainly considers the three types of communications: IoT device – IoT device, IoT device – IoT gateway, and IoT gateway – mobile client. In this paper, we design a protocol to address the authentication process between IoT gateway and mobile client. The proposed protocol's security is analyzed formally and informally to demonstrate robustness. Performance analysis of the proposed protocol has also paid adequate attention to show the probability of implementation in real time applications.",smart cities
10.1016/j.jhydrol.2018.05.003,Journal,Journal of Hydrology,scopus,2018-08-01,sciencedirect,Addressing the incorrect usage of wavelet-based hydrological and water resources forecasting models for real-world applications with best practices and a new forecasting framework,https://api.elsevier.com/content/abstract/scopus_id/85048519861,"Many recent studies propose wavelet-based hydrological and water resources forecasting models that have been incorrectly developed and that cannot properly be used for real-world forecasting problems. The incorrect development of these wavelet-based forecasting models occurs during wavelet decomposition (the process of extracting high- and low-frequency information into different sub-time series known as wavelet and scaling coefficients, respectively) and as a result introduces error into the forecast model inputs. The source of this error is due to the boundary condition that is associated with wavelet decomposition (and the wavelet and scaling coefficients) and is linked to three main issues: 1) using ‘future data’ (i.e., data from the future that is not available); 2) inappropriately selecting decomposition levels and wavelet filters; and 3) not carefully partitioning calibration and validation data. By not addressing these boundary conditions during wavelet decomposition, incorrectly developed wavelet-based forecasting models often result in much better performance than what is realistically achievable. We demonstrate that the discrete wavelet transform (DWT) multiresolution analysis (DWT-MRA) and maximal overlap discrete wavelet transform (MODWT) multiresolution analysis (MODWT-MRA), two commonly adopted wavelet decomposition methods used in the development of hydrological and water resources wavelet-based forecasting models, suffer from these boundary conditions and cannot be used properly for real-world forecasting. However, by following a proposed set of best (correct) practices, we show that the MODWT and à trous algorithm (AT) can be used to correctly forecast target (e.g., hydrological and water resources) processes in real-world scenarios. In this vein, we contribute a set of best practices, which focusses on deriving “boundary-corrected” wavelet and scaling coefficients from time series data, overcoming the boundary condition issues and providing hydrological and water resources modellers with a justified and coherent strategy for developing wavelet-based forecasting models that may be used for real-world forecasting problems. We coalesce these best practices into a new forecasting framework named Wavelet Data-Driven Forecasting Framework (WDDFF) that uses a combination of input variable selection and data-driven models to convert “boundary-corrected” wavelet and scaling coefficients into forecasts of a target process. Through a real-world urban water demand forecasting experiment in Montreal, Canada, we demonstrate the superiority of WDDFF against benchmark forecasting models such as (non-wavelet-based) random walk, multiple linear regression, extreme learning machine, and second-order Volterra series models. For the same case study, we also show how the WDDFF provides realistic and accurate forecasts while a recently proposed wavelet-based forecasting model that adopts the (invalid) MODWT-MRA for wavelet decomposition provides incorrect and unrealistic forecasts. We conclude that WDDFF is a useful tool for forecasting real-world hydrological and water resources processes that overcomes the limitations of many earlier wavelet-based forecasting methods and should be explored further for forecasting different processes such as streamflow, rainfall, evaporation, etc.",smart cities
10.1016/j.vaccine.2018.05.020,Journal,Vaccine,scopus,2018-06-22,sciencedirect,"Effect of maternal immunization against pertussis in Medellin and the metropolitan area, Colombia, 2016–2017",https://api.elsevier.com/content/abstract/scopus_id/85047081810,"Background
                  In 2013, pertussis immunization (Tdap) for pregnant women was implemented in Colombia to protect newborns in response to increased pertussis incidence.
               
                  Objective
                  To assess the effect of Tdap maternal immunization on the concentration of mother/umbilical cord antibodies and the occurrence of pertussis in infants during their first six months of life.
               
                  Methods
                  A cohort study in eight randomly selected hospitals in Medellin and metropolitan area of Antioquia, Colombia was conducted in 2015–2016. IgG PT antibody levels in paired maternal and umbilical cord sera were measured from 805 mothers immunized recruited during labor and 200 mothers recruited during the prenatal care before immunization and followed until delivery. Antibodies were analyzed by commercial ELISA kits. 896 infants were followed to detect acute respiratory infections and paroxysms of coughing, inspiratory whoop, apnea, cyanosis or post-tussive vomiting. For laboratory confirmation, B. pertussis- specific real time PCR was performed.
               
                  Results
                  We observed a high prevalence of titers >100 IU/mL (mother: 18.40% [95% CI 16–21%]; umbilical cord: 23.1% [95% CI 19.2–27.4%]), positive correlation of umbilical cord and maternal antibodies, higher antibody concentration in vaccinated than in non-vaccinated mothers and significant difference in antibody levels before and after vaccination (Wilcoxon test p = 0.000). The trans placental transport ratio was higher if the mother was vaccinated between 26 and 30 weeks of pregnancy and maximum eight weeks before delivery. Two cases of pertussis were confirmed in infants (incidence of 1.99 per 1000).
               
                  Conclusion
                  The expected effect of Tdap maternal vaccination against pertussis was observed.",smart cities
10.1016/j.enbuild.2018.03.065,Journal,Energy and Buildings,scopus,2018-06-15,sciencedirect,Holistic modelling techniques for the operational optimisation of multi-vector energy systems,https://api.elsevier.com/content/abstract/scopus_id/85045633868,"Modern district energy systems are highly complex with several controllable and uncontrollable variables. To effectively manage a multi-vector district requires a holistic perspective in terms of both modelling and optimisation. Current district optimisation strategies found in the literature often consider very simple models for energy generation and conversion technologies. To improve upon the state of the art, more realistic and accurate models must be produced whilst remaining computationally and mathematically simple enough to calculate within short periods. Therefore, this paper provides a comprehensive review of modelling techniques for common district energy conversion technologies including Power-to-Gas. In addition, dynamic building modelling techniques are reviewed, as buildings must be considered active and flexible participants in a district energy system. In both cases, a specific focus is placed on artificial intelligence-based models suitable for implementation in the real-time operational optimisation of multi-vector systems. Future research directions identified from this review include the need to integrate simplified models of energy conversion units, energy distribution networks, dynamic building models and energy storage into a holistic district optimisation framework. Finally, a future district energy management solution is proposed. It leverages semantic modelling to allow interoperability of heterogeneous data sources to provide added value inferencing from contextually enriched information.",smart cities
10.1016/j.engappai.2018.03.016,Journal,Engineering Applications of Artificial Intelligence,scopus,2018-06-01,sciencedirect,PRoA: An intelligent multi-criteria Personalized Route Assistant,https://api.elsevier.com/content/abstract/scopus_id/85045475454,"Personalization of pedestrian routes becomes a necessity due to the wide variety of user profiles that may differ on preferences or requirements to choose a route. Several software applications offer routes usually based on single criterion like distance or time; however, these criteria do not often fit the pedestrian needs.
                  Here, we will first focus on the Personalized Routes Problem and then we will approach the specific case of designing accessible and green pedestrian routes.
                  The proposal is implemented as a freely available Android application (named as PRoA, by intelligent multi-criteria Personalized Route Assistant), which automatically obtains geographical data and information for the decision criteria from open datasets.
                  The proposal is evaluated using real cases at the city of Granada, Spain.",smart cities
10.1016/j.asoc.2018.02.026,Journal,Applied Soft Computing Journal,scopus,2018-06-01,sciencedirect,Meta-Lamarckian learning in multi-objective optimization for mobile social network search,https://api.elsevier.com/content/abstract/scopus_id/85043530128,"Mobile Social Networks (MSNs) have recently brought a revolution in socially-oriented applications and services for mobile phones. In this paper, we consider the search problem in a MSN that aims at simultaneously maximizing the user's search outcome (recall) and mobile phone performance (battery usage). Because of the conflicting nature of these two objectives, the problem is dealt within the context of Multi-Objective Optimization (MOO). Our proposed approach hybridizes a Multi-objective Evolutionary Algorithm based on Decomposition (MOEA/D) with a Meta-Lamarckian (ML) learning strategy that learns from the problem's properties and objective functions. The ML strategy is devised for adaptively select the best performing local search heuristic for each case, from a pool of general-purpose heuristics, so as to locally optimize the solutions during the evolution. We evaluated our propositions on a realistic multi-objective MSN search problem using trace-driven experiments with real mobility and social patterns. Extensive experimental studies reveal that the proposed method successfully learns the behaviour of individual local search heuristics during the evolution, adaptively follows the pattern of the best performing heuristics at different areas of the objective space and offers better performance in terms of both convergence and diversity than its competitors.
                  The proposed Meta-Lamarckian based MOEA does not utilize any problem-specific heuristics, as most cases in the literature do, facilitating its applicability to other combinatorial MOO problems. To test its generalizability the proposed method is also evaluated on various test instances of the well-studied multi-objective Permutation Flow Shop Scheduling Problem.",smart cities
10.1016/j.future.2017.08.060,Journal,Future Generation Computer Systems,scopus,2018-06-01,sciencedirect,A hybrid quantum-induced swarm intelligence clustering for the urban trip recommendation in smart city,https://api.elsevier.com/content/abstract/scopus_id/85029816491,"The development of internet technologies has brought digital services to the hands of common man. In the selection process of relevant digital services to the active target user, recommender systems have proved its efficiency as a successful decision support tool. Among many successful techniques incorporated to generate recommendations, collaborative filtering has been widely used to make similarity-based predictions for the recommendation of the relevant list of items to the users. As an advancement, utilizing clustering mechanisms with collaborative filtering for grouping similar users as clusters can enhance the efficiency of the recommendation generated. Though many clustering mechanisms have been employed to group similar users in the existing works, incorporation of bio-inspired clustering has yet to be explored for the generation of optimal recommendations. In this paper, a novel user clustering approach based on Quantum-behaved Particle Swarm Optimization (QPSO) has been proposed for the collaborative filtering based recommender system. The proposed recommendation approach has been evaluated on real-world large-scale datasets of Yelp and TripAdvisor for hit-rate, precision, recall, f-measure, and accuracy. The obtained results illustrate the advantageous performance of proposed approach over its peer works of recent times. We have also developed a new mobile recommendation framework XplorerVU for the urban trip recommendation in smart cities, to evaluate the proposed recommendation approach and the real-time implementation details of the mobile application in the smart-cities are also presented. The evaluation results prove the usefulness of the generated recommendations and depict the users’ satisfaction on the proposed recommendation approach.",smart cities
10.1016/j.pestbp.2017.10.006,Journal,Pesticide Biochemistry and Physiology,scopus,2018-05-01,sciencedirect,Effects and inhibition mechanism of phenazine-1-carboxamide on the mycelial morphology and ultrastructure of Rhizoctonia solani,https://api.elsevier.com/content/abstract/scopus_id/85032899734,"The purpose of this research was to explore the effect of phenazine-1-carboxamide (PCN) on Rhizoctonia solani and to elucidate its mechanisms of action. The toxicity of PCN to R. solani was measured using a growth rate method. The results indicated that PCN inhibited R. solani with a 50% effective concentration (EC50) of 9.0934μg/mL. The mycelia of R. solani were then exposed to 18.18μg/mL (2EC50) of PCN. Optical microscopy, scanning electron microscopy (SEM), and transmission electron microscopy (TEM) were used to observe the effects of PCN on mycelial morphology and ultrastructure. Following the PCN treatment, the optical microscopy observations revealed that the mycelia appeared twisted; the branching mycelia grew, but the main mycelia did not grow following branching; and the mycelial roots possessed more vacuoles. SEM observations revealed that the mycelia were locally swollen and exhibited a sharp decrease in prominence. TEM observations showed that the cell wall became thin and deformed; the mitochondria disappeared; the septum twisted; and most of the organelles were difficult to discern. Conversely, all of the organelles could be clearly observed in the control. We then used real-time quantitative PCR and an enzyme activity testing kit to further explore the effects of PCN on the cell wall and mitochondria. Physiological and biochemical results demonstrated that both the cell wall and mitochondria constitute are PCN targets. PCN inhibited the activities of chitin synthetase and complex I of the mitochondria electron transport chain. Molecular experiments demonstrated that PCN controlled the growth of R. solani mycelia by inhibiting the expression level of chitin synthetase genes. Future research on PCN should investigate its influence on metabolic pathways, thereby aiding in the potential development of novel pesticides.",smart cities
10.1016/j.trc.2018.01.008,Journal,Transportation Research Part C: Emerging Technologies,scopus,2018-03-01,sciencedirect,Reinforcement learning approach for coordinated passenger inflow control of urban rail transit in peak hours,https://api.elsevier.com/content/abstract/scopus_id/85044656834,"In peak hours, when the limited transportation capacity of urban rail transit is not adequate enough to meet the travel demands, the density of the passengers waiting at the platform can exceed the critical density of the platform. Coordinated passenger inflow control strategy is required to adjust/meter the inflow volume and relieve some of the demand pressure at crowded metro stations so as to ensure both operational efficiency and safety at such stations for all passengers. However, such strategy is usually developed by the operation staff at each station based on their practical working experience. As such, the best strategy/decision cannot always be made and sometimes can even be highly undesirable due to their inability to account for the dynamic performance of all metro stations in the entire rail transit network. In this paper, a new reinforcement learning-based method is developed to optimize the inflow volume during a certain period of time at each station with the aim of minimizing the safety risks imposed on passengers at the metro stations. Basic principles and fundamental components of the reinforcement learning, as well as the reinforcement learning-based problem-specific algorithm are presented. The simulation experiment carried out on a real-world metro line in Shanghai is constructed to test the performance of the approach. Simulation results show that the reinforcement learning-based inflow volume control strategy is highly effective in minimizing the safety risks by reducing the frequency of passengers being stranded. Additionally, the strategy also helps to relieve the passenger congestion at certain stations.",smart cities
10.1016/j.ijleo.2017.11.171,Journal,Optik,scopus,2018-03-01,sciencedirect,Catenary image segmentation using the simplified PCNN with adaptive parameters,https://api.elsevier.com/content/abstract/scopus_id/85035806726,"The catenary fault detection method based on image processing technique plays an important role in the railway transportation safety system, and image segmentation is the hot and critical stage of this detection method. Conventional pulse coupled neural network (PCNN) model has too many parameters which should be set with values in advance for image segmentation. However, the setting of parameters is critical but complex task, and the segmentation effect and efficiency significantly rely on the network parameters setting. To overcome the above mentioned disadvantages, the simplified PCNN (SPCNN) model based on the conventional PCNN is introduced. First, simplify the input domain, the external input signal is directly used as the input neuron. Then the linking input and the dynamic threshold of the neuron are simplified. Furthermore, the linking coefficients of the modulation field are adaptively determined by normalized mean square error, and the iteration number is adaptively determined in accordance with the minimum cross entropy. In this simplified model, some parameters are reduced but the important mechanisms of PCNN are still remained. Finally, several sets of real-time collected catenary images are segmented by the SPCNN model with adaptive parameters. Experiments results show that the proposed method not only significantly improves image segmentation performance than the conventional image segmentation methods but also shows the continuity and integrity of the segmented images, especially for the pull rods, posts, insulators and other parts of catenary. Furthermore, it is superior to the conventional image segmentation in terms of parameters setting, visual appearance and objective evaluation criteria of 
                        
                           V
                           O
                           I
                        
                     and 
                        
                           P
                           R
                           I
                        
                     values.",smart cities
10.1016/j.jfranklin.2017.02.011,Journal,Journal of the Franklin Institute,scopus,2018-03-01,sciencedirect,An intelligent propagation distance estimation algorithm based on fundamental frequency energy distribution for periodic vibration localization,https://api.elsevier.com/content/abstract/scopus_id/85014472964,"Earth surface vibrations generated by passing vehicles, excavation equipment, footsteps, etc., attract increasing attentions in the research community due to their wide applications. In this paper, we investigate the periodic vibration source localization problem, which has recently shown significance in excavation device detection and localization for urban underground pipeline network protection. An intelligent propagation distance estimation algorithm based on a novel fundamental frequency energy distribution (FBED) feature is developed for periodic vibration signal localization. Contributions of the paper lie in three aspects: 1) a novel frequency band energy distribution (FBED) feature is developed to characterize the property of vibrations at different propagation distances; 2) an intelligent propagation distance estimation model built on the FBED feature with machine learning algorithms is proposed, where for comparisons, the support vector machine (SVM) for regression and regularized extreme learning machine (RELM) are used; 3) a localization algorithm based on the distance-of-arrival (DisOA) estimation using three piezoelectric transducer sensors is given for source position estimation. To testify the effectiveness of the proposed algorithms, case studies on real collected periodic vibration signals generated by two electric hammers with different fundamental frequencies are presented in the paper. The transmission medium is the cement road and experiments on vibration signals recorded at different propagation distances are conducted.",smart cities
10.1016/j.jnca.2017.12.010,Journal,Journal of Network and Computer Applications,scopus,2018-02-15,sciencedirect,Device-free human localization and tracking with UHF passive RFID tags: A data-driven approach,https://api.elsevier.com/content/abstract/scopus_id/85040013056,"Localizing and tracking human movement in a device-free and passive manner is promising in two aspects: i) it neither requires users to wear any sensors or devices, ii) nor it needs them to consciously cooperate during the localization. Such indoor localization technique underpins many real-world applications such as shopping navigation, intruder detection, surveillance care of seniors etc. However, current passive localization techniques either need expensive/sophisticated hardware such as ultra-wideband radar or infrared sensors, or have an issue of invasion of privacy such as camera-based techniques, or need regular maintenance such as the replacement of batteries. In this paper, we build a novel data-driven localization and tracking system upon a set of commercial ultra-high frequency passive radio-frequency identification tags in an indoor environment. Specifically, we formulate human localization problem as finding a location with the maximum posterior probability given the observed received signal strength indicator from passive radio-frequency identification tags. In this regard, we design a series of localization schemes to capture the posterior probability by taking the advance of supervised-learning models including Gaussian Mixture Model, 
                        k
                      Nearest Neighbor and Kernel-based Learning. For tracking a moving target, we mathematically model the task as searching a location sequence with the most likelihood, in which we first augment the probabilistic estimation learned in localization to construct the Emission Matrix and propose two human mobility models to approximate the Transmission Matrix in the Hidden Markov Model. The proposed tracking model is able to transfer the pattern learned in localization into tracking but also reduce the location-state candidates at each transmission iteration, which increases both the computation efficiency and tracking accuracy. The extensive experiments in two real-world scenarios reveal that our approach can achieve up to 94% localization accuracy and an average 0.64 m tracking error, outperforming other state-of-the-art radio-frequency identification based indoor localization systems.",smart cities
10.1016/j.jhydrol.2017.12.048,Journal,Journal of Hydrology,scopus,2018-02-01,sciencedirect,"Comparison of thermal, salt and dye tracing to estimate shallow flow velocities: Novel triple-tracer approach",https://api.elsevier.com/content/abstract/scopus_id/85039759553,"The accurate measurement of shallow flow velocities is crucial to understand and model the dynamics of sediment and pollutant transport by overland flow. In this study, a novel triple-tracer approach was used to re-evaluate and compare the traditional and well established dye and salt tracer techniques with the more recent thermal tracer technique in estimating shallow flow velocities. For this purpose a triple tracer (i.e. dyed-salted-heated water) was used. Optical and infrared video cameras and an electrical conductivity sensor were used to detect the tracers in the flow. Leading edge and centroid velocities of the tracers were measured and the correction factors used to determine the actual mean flow velocities from tracer measured velocities were compared and investigated. Experiments were carried out for different flow discharges (32–1813 ml s−1) on smooth acrylic, sand, stones and synthetic grass bed surfaces with 0.8, 4.4 and 13.2% slopes. The results showed that thermal tracers can be used to estimate shallow flow velocities, since the three techniques yielded very similar results without significant differences between them. The main advantages of the thermal tracer were that the movement of the tracer along the measuring section was more easily visible than it was in the real image videos and that it was possible to measure space-averaged flow velocities instead of only one velocity value, with the salt tracer. The correction factors used to determine the actual mean velocity of overland flow varied directly with Reynolds and Froude numbers, flow velocity and slope and inversely with flow depth and bed roughness. In shallow flows, velocity estimation using tracers entails considerable uncertainty and caution must be taken with these measurements, especially in field studies where these variables vary appreciably in space and time.",smart cities
10.1016/j.neucom.2017.11.008,Journal,Neurocomputing,scopus,2018-01-31,sciencedirect,A dynamic colour perception system for autonomous robot navigation on unmarked roads,https://api.elsevier.com/content/abstract/scopus_id/85033771926,"Navigation on unmarked and possible poorly delineated roads where the boundaries between the road and the non-road surfaces are not clearly indicated is a particularly challenging task for autonomous vehicles. The results of this study show that fairly robust navigation strategies can be generated by a robot equipped with a dynamic active-vision based control system represented by an artificial neural network synthesized using evolutionary computation techniques. In the experiments described in this paper, a simulated Pioneer robot is required to visually navigate multiple poorly delineated roads that differ in terms of variations in luminance and/or chrominance between the road and the adjacent non-road areas. Low resolution camera images are processed by a mechanism that continuously adjusts the contribution of each component of a three dimensional colour model (e.g., R, G and B) to the generation of the robot perceptual experience. We show that the best controller can successfully drive a simulated Pioneer robot in environments with colour characteristics never encountered during the design phase, and operate with colour models never used during training. We show that the dynamic differential weighting of the colour components is underpinned by a complex pattern of neural activity that allows the robot to successfully adapt its perceptual system to the colour characteristics of different visual scenes. We also show that the controller can be easily ported onto real hardware, by showing the results of a series of tests with a physical Pioneer robot required to navigate various poorly delineated pedestrian roads.",smart cities
10.1016/j.neucom.2017.01.110,Journal,Neurocomputing,scopus,2018-01-03,sciencedirect,Making physical proofs of concept of reinforcement learning control in single robot hose transport task complete,https://api.elsevier.com/content/abstract/scopus_id/85023642304,"This paper deals with the realization of physical proof of concept experiments in the paradigm of Linked Multi-Component Robotic Systems (LMCRS). The main objective is to demonstrate that the controllers learned through Reinforcement Learning (RL) algorithms with different state space formalizations and different spatial discretizations in a simulator are reliable in a real world configuration of the task of transporting a hose by a single robot. This one is a prototypical example of LMCRS task (extendable to much more complex tasks). We describe how the complete system has been designed and implemented. Two different previously learned RL controllers have been tested solving two different LMCRS control problems, using different state space modeling and discretization step in each case. The physical realizations validate previously published simulation based results, giving a strong argument in favor of the suitability of RL techniques to deal with LMCRS systems.",smart cities
10.1016/j.trpro.2018.09.053,Conference Proceeding,Transportation Research Procedia,scopus,2018-01-01,sciencedirect,Automatic Transport Network Matching Using Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85063278570,"Public transport users are increasingly expecting better service and up to date information, in pursuit of a seamless journey experience. In order to meet these expectations, many transport operators are already offering free mobile apps to help customers better plan their journeys and access real-time travel information. Leveraging the spatio-temporal data that such apps can produce at scale (i.e. timestamped GPS traces), opens an opportunity to bridge the gap between passenger expectations and capabilities of the operators by providing a real-time 360-degree view of the transport network based on the ‘Apps as infrastructure’ paradigm. The first step towards fulfilling this vision is to understand which routes and services the passengers are travelling on at any given time. Mapping a GPS trace onto a particular transport network is known as ‘network matching’. In this paper, the problem is formulated as a supervised sequence classification task, where sequences are made of geographic coordinates, time, and line and direction of travel as the label. We present and compare two data-driven approaches to this problem: (i) a heuristic algorithm, which looks for nearby stops and makes an estimation based on their timetables — used as a baseline — and (ii) a deep learning approach using a recurrent neural network (RNN). Since RNNs require considerable amounts of data to train a good model, and collecting and labelling this data from real users is a challenging task, one of our contributions is a synthetic journey data generator. The datasets that we generated have been made as realistic as possible by querying real timetables and adding position and temporal noise to simulate variable GPS accuracy and vehicle delays, sampled from empirical distributions estimated using thousands of real location reports. To validate our approach we have used a separate dataset made of hundreds of real user journeys provided by a UK-based bus operator. Our experimental results are very promising and our next step is to deploy the solution in a production environment. From the operator’s point of view, this will enable multiple smart applications like account-based ticketing, identification of disruptions, real-time passenger counting, and network analysis.",smart cities
10.1016/j.procs.2018.10.294,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,DSRC based sensor-pooling protocol for connected vehicles in future smart cities,https://api.elsevier.com/content/abstract/scopus_id/85061968937,"Smart cities are racing to create a more connected Intelligent Transportation Systems (ITS) that rely on collecting data from every possible sensor such as a smart utility meter or a smart parking meter. The use of more sensors resulted in generating a lot of information that maps the smart city environment conditions to more real time data points that needed to be shared and analyzed among smart city nodes. One possibility, to carry and share the collected data, is in autonomous vehicles systems, which use the Dedicated Short Range Communications (DSRC) technology. For example, in a Car-to-Parking-Meter or a Vehicle-to-Vehicle (V2V) communications, short-range embedded sensors such as Bluetooth, Cameras, Lidar send the collected data to the vehicle’s Electronic Control Unit (ECU) or to a road side gateway for making collaborative decisions and react to the environment’s surrounding conditions.
                  The goal of this research is to develop and test a DSRC based sensor-pooling protocol for vehicles to cooperatively communicate inclement weather or environment conditions. Five simulation experiments are setup using PreScan and Simulink to validate and study the scalability of the proposed solution. PreScan is an automotive simulation platform that is used for developing and testing Advanced Driver Assistance System (ADAS). The research findings proved that the DSRC can be used to effectively stream the short range sensors’ collected data over a long distance communications link.",smart cities
10.1016/j.egypro.2018.09.205,Conference Proceeding,Energy Procedia,scopus,2018-01-01,sciencedirect,A real-time MPC-based energy management of hybrid energy storage system in urban rail vehicles,https://api.elsevier.com/content/abstract/scopus_id/85058243576,"The most challenges for the hybrid energy storage system made up of the battery and super capacitor (SC) are the reasonable energy management strategy (EMS) and real-time implementation. Therefore, a variable-step multistep prediction MPC-based energy management strategy is proposed in this paper, which minimizes the system energy losses of the whole operating process and ensures the battery current and SC SOC in a suitable range. In addition, the neural networks (NN) are applied in this paper for real-time implementation, which are trained by using MPC optimization results. To do this, the loss models of the battery, SC and DC/DC converter are built and Simulation is carried out in MATLAB/Simulink, which shows that the proposed EMS can keep the SC SOC in a suitable range. At the same time, the proposed online energy management method can achieve excellent results of MPC optimization.",smart cities
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",smart cities
10.1016/j.procs.2018.07.138,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Building An Anomaly Detection Engine (ADE) for IoT Smart Applications,https://api.elsevier.com/content/abstract/scopus_id/85051386119,"Data Analytics is by far the component with more added value in Internet of Things (IoT) networks. One aspect of data analytics is anomaly detection within data points received in some cases in real time that help to conduct predictive maintenance, weather monitoring or cyber security forensics for instance. Although there exists a number of web dashboards that allow IoT users to visualize data in time domain and perform statistical analysis, anomaly detection is often absent else if present not that straightforward, reliable and accurate. The development and implementation of Anomaly Detection Engine (ADE) poses a number of challenges that are in fact addressed in this paper. The research work exposes the multifaceted aspect of IoT networks and applications based on real life use cases and the difficulties engendered in mounting an ADE from both software system engineering and network convergence perspectives. Moreover a comparative description of diverse time series models adopted in anomaly detection is undertaken. It was noticed that there is neither one size fit all solution nor a plug n play alternative and that the unsupervised mode in machine learning as a model for time series analysis is the most versatile and efficient technique for IoT analytics developers.",smart cities
10.1016/j.procs.2018.04.110,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Fall detection system for elderly people using IoT and Big Data,https://api.elsevier.com/content/abstract/scopus_id/85051262294,"Falls represent a major public health risk worldwide for the elderly people. A fall not assisted in time can cause functional impairment in an elder and a significant decrease in his mobility, independence and life quality. In that sense, the present work proposes an innovative IoT-based system for detecting falls of elderly people in indoor environments, which takes advantages of low-power wireless sensor networks, smart devices, big data and cloud computing. For this purpose, a 3D-axis accelerometer embedded into a 6LowPAN device wearable is used, which is responsible for collecting data from movements of elderly people in real-time. To provide high efficiency in fall detection, the sensor readings are processed and analyzed using a decision trees-based Big Data model running on a Smart IoT Gateway. If a fall is detected, an alert is activated and the system reacts automatically by sending notifications to the groups responsible for the care of the elderly people. Finally, the system provides services built on cloud. From medical perspective, there is a storage service that enables healthcare professional to access to falls data for perform further analysis. On the other hand, the system provides a service leveraging this data to create a new machine learning model each time a fall is detected. The results of experiments have shown high success rates in fall detection in terms of accuracy, precision and gain.",smart cities
10.1016/j.epsr.2017.09.003,Journal,Electric Power Systems Research,scopus,2018-01-01,sciencedirect,New online load forecasting system for the Spanish Transport System Operator,https://api.elsevier.com/content/abstract/scopus_id/85029511531,"This paper presents the implementation of a new online real-time hybrid load-forecasting model based on an autoregressive model and neural networks. This new system is currently running at the Spanish Transport System Operator (REE) and provides an hourly forecast for the current day and the next nine days timely every hour for the national system as well as 18 regions of Spain. These requirements impose a heavy computational burden that needs to be considered during the design phase. The system is developed to improve forecasting accuracy specifically on difficult days like hot, cold and special days. In order to achieve this goal, a deep analysis of the temperature series from 59 stations is made for each region and the relevant series are included individually in the model. Special days are also analyzed and a thorough classification of days is proposed for the Spanish national and regional system. The model is designed and tested with data from 2005 to 2015. The results provided for the period from December 2014 to October 2015 show how the addition of the proposed model to the TSO’s ensemble causes a 5% RMSE overall error reduction and a 15% reduction on the 59 difficult days considered in the testing period.",smart cities
10.1016/j.jaerosci.2017.08.007,Journal,Journal of Aerosol Science,scopus,2018-01-01,sciencedirect,Comparing the performance of 3 bioaerosol samplers for influenza virus,https://api.elsevier.com/content/abstract/scopus_id/85028451741,"Respiratory viral diseases can be spread when a virus-containing particle (droplet) from one individual is aerosolized and subsequently comes into either direct or indirect contact with another individual. Increasing numbers of studies are examining the occupational risk to healthcare workers due to proximity to patients. Selecting the appropriate air sampling method is a critical factor in assuring the analytical performance characteristics of a clinical study. The objective of this study was to compare the physical collection efficiency and virus collection efficiency of a 5mL compact SKC BioSampler®, a gelatin filter, and a glass fiber filter, in a laboratory setting. The gelatin filter and the glass fiber filter were housed in a home-made filter holder. Submersion (with vortexing and subsequent centrifugation) was used for the gelatin and glass fiber filters. Swabbing method was also tested to retrieve the viruses from the glass fiber filter. Experiments were conducted using the H1N1 influenza A virus A/Puerto Rico/8/1934 (IAV-PR8), and viral recovery was determined using culture and commercial real-time-PCR (BioFire and Xpert). An atomizer was used to aerosolize a solution of influenza virus in PBS for measurement, and two Scanning Mobility Particle Sizers were used to determine particle size distributions. The SKC BioSampler demonstrated a U-shaped physical collection efficiency, lowest for particles around 30–50nm, and highest at 10nm and 300–350nm within the size range examined. The physical collection efficiency of the gelatin filter was strongly influenced by air flow and time: a stable collection across all particle sizes was only observed at 2L/min for the 9min sampling time, otherwise, degradation of the filter was observed. The glass fiber filter demonstrated the highest physical collection efficiency (100% for all sizes) of all tested samplers, however, its overall virus recovery efficiency fared the worst (too low to quantify). The highest viral collection efficiencies for the SKC BioSampler and gelatin filter were 5% and 1.5%, respectively. Overall, the SKC BioSampler outperformed the filters. It is important to consider the total concentration of viruses entering the sampler when interpreting the results.",smart cities
10.1016/j.tiv.2017.08.021,Journal,Toxicology in Vitro,scopus,2017-12-01,sciencedirect,Dose-response in a high density three-dimensional liver device with real-time bioenergetic and metabolic flux quantification,https://api.elsevier.com/content/abstract/scopus_id/85028926263,"Real-time dose-response curves for fructose have been non-invasively determined in primary rat hepatocyte alginate spheroids cultured in a NMR-compatible fluidized-bed bioreactor. Using 13C–labeled glucose and glycine culture medium, fructose dose was compared to glucose uptake and glycogen synthesis rate using 13C NMR spectroscopy, and to ATP and fructose-1-phosphate concentration using 31P NMR spectroscopy. A highly efficient multicoaxial perfusion system maintains high density 3-D hepatocyte cultures, permitting 13C and 31P NMR spectral time courses with 1min time points. The perfusion system was turned off to demonstrate its efficiency and effect on the metabolites. Within 16min, glycogen plummeted, lactate became the largest 13C–glucose metabolite via anaerobic glycolysis, while glutathione was the largest 13C–glycine metabolite. ATP depletion and fructose-1-phosphate formation demonstrated a dose response with a 3h EC50 of 19mM±8.9mM and 17.4mM±3.7mM, respectively. Computational modeling of mass transfer corroborated experimental results and helped determine the optimal bioreactor loading densities, oxygen concentration, and perfusion rates to maintain physiologically-relevant nutrient levels. The total bioreactor plus perfusion loop has a dead volume of 2ml, and contains 5 million hepatocytes. Due to the non-invasive measurements, there is a reduction of animal tissue by an order-of-magnitude, depending on the number of time points in an experiment. This dynamic flux approach may have generic utility for dose-response studies monitoring multiple metabolic reactions in other primary mammalian cells, such as human, that have strict oxygen demands.",smart cities
10.1016/j.comcom.2017.08.005,Journal,Computer Communications,scopus,2017-11-01,sciencedirect,A reinforcement learning-based link quality estimation strategy for RPL and its impact on topology management,https://api.elsevier.com/content/abstract/scopus_id/85031298674,"Over the last few years, standardisation efforts are consolidating the role of the Routing Protocol for Low-Power and Lossy Networks (RPL) as the standard routing protocol for IPv6-based Wireless Sensor Networks (WSNs). Although many core functionalities are well defined, others are left implementation dependent. Among them, the definition of an efficient link-quality estimation (LQE) strategy is of paramount importance, as it influences significantly both the quality of the selected network routes and nodes’ energy consumption. In this paper, we present RL-Probe, a novel strategy for link quality monitoring in RPL, which accurately measures link quality with minimal overhead and energy waste. To achieve this goal, RL-Probe leverages both synchronous and asynchronous monitoring schemes to maintain up-to-date information on link quality and to promptly react to sudden topology changes, e.g. due to mobility. Our solution relies on a reinforcement learning model to drive the monitoring procedures in order to minimise the overhead caused by active probing operations. The performance of the proposed solution is assessed by means of simulations and real experiments. Results demonstrated that RL-Probe helps in effectively improving packet loss rates, allowing nodes to promptly react to link quality variations as well as to link failures due to node mobility.",smart cities
10.1016/j.cag.2017.08.004,Journal,Computers and Graphics (Pergamon),scopus,2017-11-01,sciencedirect,Automatic large-scale data acquisition via crowdsourcing for crosswalk classification: A deep learning approach,https://api.elsevier.com/content/abstract/scopus_id/85028699273,"Correctly identifying crosswalks is an essential task for the driving activity and mobility autonomy. Many crosswalk classification, detection and localization systems have been proposed in the literature over the years. These systems use different perspectives to tackle the crosswalk classification problem: satellite imagery, cockpit view (from the top of a car or behind the windshield), and pedestrian perspective. Most of the works in the literature are designed and evaluated using small and local datasets, i.e. datasets that present low diversity. Scaling to large datasets imposes a challenge for the annotation procedure. Moreover, there is still need for cross-database experiments in the literature because it is usually hard to collect the data in the same place and conditions of the final application. In this paper, we present a crosswalk classification system based on deep learning. For that, crowdsourcing platforms, such as OpenStreetMap and Google Street View, are exploited to enable automatic training via automatic acquisition and annotation of a large-scale database. Additionally, this work proposes a comparison study of models trained using fully-automatic data acquisition and annotation against models that were partially annotated. Cross-database experiments were also included in the experimentation to show that the proposed methods enable use with real world applications. Our results show that the model trained on the fully-automatic database achieved high overall accuracy (94.12%), and that a statistically significant improvement (to 96.30%) can be achieved by manually annotating a specific part of the database. Finally, the results of the cross-database experiments show that both models are robust to the many variations of image and scenarios, presenting a consistent behavior.",smart cities
10.1016/j.asoc.2017.06.005,Journal,Applied Soft Computing Journal,scopus,2017-10-01,sciencedirect,Estimation of pellet size and strength of limestone and manganese concentrate using soft computing techniques,https://api.elsevier.com/content/abstract/scopus_id/85021058464,"This paper presents a soft computing approach to estimate wet or green pellet size and strength and signifies the importance of individual process parameter. A huge portion of available minerals and materials is in the form of fine powder that makes their management and utilization a tedious job. Pelletization, a size enlargement technique, is used to tackle aforementioned problems and provides benefits such as ease of handling and storage, convenient transportation and improved process efficiency. Besides other characteristics, pellet size and strength are of prime significance and their accurate estimation can enhance the product quality. Real-life constraints (e.g., time in conducting experiments, repetition of experiments considering measurement errors, availability of resources, etc.) pose difficulties in generating sufficient experimental data at the laboratory. Hence, the concept of random population generation of genetic algorithm is exploited to fulfill data requirement where fitness functions are formulated using multiple regression. Better visualisation of pellets attributes and operating conditions is done through self-organizing map which also helped in deducing some important facts. Sensitivity analysis and construction of learning curves is also performed in present study. Finally, multilayer perceptron, a popular supervised neural network model, is applied on synthetic data to approximate pellet properties. Agreement between estimated and corresponding experimental values ascertained that neural network based system can be employed as an effective and credible tool to anticipate characteristics of wet pellets.",smart cities
10.1016/j.ijtst.2017.07.004,Journal,International Journal of Transportation Science and Technology,scopus,2017-09-01,sciencedirect,Development of a global road safety performance function using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85038097773,"This paper explores the idea of applying a machine learning approach to develop a global road safety performance function (SFP) that can be used to predict the expected crash frequencies of different highways from different regions. A deep belief network (DBN) – one of the most popular deep learning models is introduced as an alternative to the traditional regression models for crash modelling. An extensive empirical study is conducted using three real world crash data sets covering six classes of highways as defined by location (urban vs. rural), number of lanes, access control, and region. The study involves a number of experiments aiming at addressing several critical questions pertaining to the relative performance of the DBN in terms of network structure, training method, data size, and generalization ability, as compared to the traditional regression models. The experimental results have shown that a DBN model could be trained with different crash datasets with prediction performance being at least comparable to that of the locally calibrated negative binomial (NB) model.",smart cities
10.1016/j.jprot.2017.06.020,Journal,Journal of Proteomics,scopus,2017-08-23,sciencedirect,iTRAQ-based quantitative proteomic analysis reveals multiple effects of Emodin to Haemophilus parasuis,https://api.elsevier.com/content/abstract/scopus_id/85025438874,"Haemophilus parasuis, a symbiotic bacteria of upper respiratory tract of swine, is the etiological agent of Glässer's disease, which is characterized by fibrinous polyserositis. Emodin, exhibits antibacterial activity against H. parasuis, yet the action mode has not been fully understood. In present study, isobaric tag for relative and absolute quantification (iTRAQ) method was applied to analyze the global protein alteration of H. parasuis in response to 16μg/mL Emodin. In total, 338 proteins exhibiting significant differential expressions were identified. It was speculated that, through application of bioinformatics analysis to theses differentially expressed proteins, Emodin mainly inhibited some key proteins expression of ABC transport system, carbohydrate metabolism pathway and bacterial cell division by inhibiting the ribosome synthesis, resulting in the growth inhibition of H. parasuis. Remarkably, nine virulence-associated proteins were detected differently expressed, further experiments revealed that after treatment with Emodin, H. parasuis could be inhibited to adhere to and invade into porcine kidney epithelial cells (PK-15 line) and exhibited increased sensitivity to serum complement in a concentration-dependent manner. Phagocytosis assay showed Emodin also could enhance phagocytic activity of porcine alveolar macrophages PAM to H. parasuis. These results indicated that Emodin also can attenuate virulence of H. parasuis and reduce infection.
               
                  Biological significance
                  The Glässer's disease caused by H. parasuis has become a typical bacterial disease and cause serious economic loss to the swine industry around the world. Antibiotics are extensively used to control the infection, but increasing antibiotic resistance has been a severe problem. Hence, novel treatment agents are needed. So far, few antibacterial agents were reported that could control H. parasuis infection. In the present study, the state-of-the-art quantitative proteomic technology was applied to uncover underlying action mechanism of Emodin. This study extends understanding of antibacterial effect of Emodin to H. parasuis at molecular level and provides useful information for further investigations. Moreover, our results provide theoretical foundation for the practical application of Emodin.",smart cities
10.1016/j.biopha.2017.05.142,Journal,Biomedicine and Pharmacotherapy,scopus,2017-08-01,sciencedirect,Role of growth factor receptor-bound 2 in CCl<inf>4</inf>-induced hepatic fibrosis,https://api.elsevier.com/content/abstract/scopus_id/85020413129,"Background
                  Growth Factor Receptor-bound 2 (GRB2) plays a crucial role in regulation of cellular function including proliferation and differentiation, and we previously identified GRB2 as promoting HSCs (HSCs) proliferation. However, the underlying mechanisms that are involving in the regulation of GRB2 in hepatic fibrogenesis remain unknown.
               
                  Methods
                  In the present study, we tested the function of GRB2 in hepatic fibrosis. Hepatic fibrosis was induced by subcutaneous CCl4 administration at a dose of 3mL/kg in rats. The rat HSC cell line HSC-T6 were cultured for proliferation investigation by CCK-8 and BrdU incorporation method. The levels of GRB2, HMGB1, PI3K/AKT, COL1A1 and α-SMA were analyzed by western blot or real-time PCR.
               
                  Results
                  showed that the expression of GRB2 and HMGB1 was obviously increased in liver tissues of hepatic fibrosis rats accompanied by up-regulation of COL1A1 and α-SMA. In cultured HSCs, application of exogenous HMGB1 induced cell proliferation and cell proliferation rate concomitantly with up-regulation of GRB2 expression and PI3K/AKT phosphorylation. The effects of HMGB1-induced proliferation of HSCs and up-regulation of COL1A1 and α-SMA were abolished by GRB2 siRNA. HMGB1-induced proliferation of HSCs and up-regulation of COL1A1 and α-SMA was reversed in the presence of LY294002, an inhibitor of PI3K inhibitor.
               
                  Conclusions
                  These findings suggest that GRB2 plays an important role in CCl4-induced hepatic fibrosis by regulating HSCs’ function, and up-regulation of GRB2 induced by HMGB1 is mediated via the PI3K/AKT pathway.",smart cities
10.1016/j.jpba.2017.01.012,Journal,Journal of Pharmaceutical and Biomedical Analysis,scopus,2017-04-15,sciencedirect,"Universal efavirenz determination in transport study, rat placenta perfusion and placenta lysate by HPLC-UV",https://api.elsevier.com/content/abstract/scopus_id/85009212544,"Efavirenz is an antiretroviral drug used in the treatment of HIV-positive patients. A simple, fast and sensitive high-performance liquid chromatography (HPLC) method was developed in order to determine efavirenz in three types of samples provided from pharmacokinetic studies. The analysis took 5min and was performed using a C18 analytical column (Discovery HS C18, 150×4.6mm, particle size of 5μm) in isocratic mode with a mobile phase containing acetonitrile and water (65:35, v/v), a flow rate of 1.6mLmin−1, a sample volume of 10μL and UV detection at 245nm. Three different sample matrices (Opti-MEM medium, Krebs perfusion liquid and tissue lysate) and their treatment (dilution, SPE) were considered. The validated method was applied for the analysis of 805 real samples arising from in vitro transcellular transport assays and in vivo organ perfusion experiments in order to evaluate the interaction of efavirenz with ATP-dependent drug efflux transporters. The lack of interaction of efavirenz with ABCB1, ABCG2 and ABCC2 transporters as well as technical aspects of this analysis, including the adhesion of efavirenz to the plastic materials and the stability of the drug during different tissue lysis approaches are discussed.",smart cities
10.1016/j.egypro.2017.03.271,Conference Proceeding,Energy Procedia,scopus,2017-03-01,sciencedirect,Predicting Large Scale Fine Grain Energy Consumption,https://api.elsevier.com/content/abstract/scopus_id/85017254936,"Today a large volume of energy-related data have been continuously collected. Extracting actionable knowledge from such data is a multi-step process that opens up a variety of interesting and novel research issues across two domains: energy and computer science. The computer science aim is to provide energy scientists with cutting-edge and scalable engines to effectively support them in their daily research activities. This paper presents SPEC, a scalable and distributed predictor of fine grain energy consumption in buildings. SPEC exploits a data stream methodology analysis over a sliding time window to train a prediction model tailored to each building. The building model is then exploited to predict the upcoming energy consumption at a time instant in the near future. SPEC currently integrates the artificial neural networks technique and the random forest regression algorithm. The SPEC methodology exploits the computational advantages of distributed computing frameworks as the current implementation runs on Spark. As a case study, real data of thermal energy consumption collected in a major city have been exploited to preliminarily assess the SPEC accuracy. The initial results are promising and represent a first step towards predicting fine grain energy consumption over a sliding time window.",smart cities
10.1016/j.apacoust.2016.08.002,Journal,Applied Acoustics,scopus,2017-02-01,sciencedirect,Urban sound event classification based on local and global features aggregation,https://api.elsevier.com/content/abstract/scopus_id/84997112283,"The automatic content-based classification of complex and dynamic urban sound is an important aspect of various emerging applications, such as surveillance, urban soundscape understanding and noise source identification, therefore the research topic has gained a lot of attention in recent years. The aim of this paper is to develop efficient machine learning-based scheme for urban sound classification in real-life noise conditions. Unlike conventional sound event classification methods that mainly address local temporal-spectral patterns, we propose an aggregation scheme to combine both local and global acoustic features. For characterizing local patterns, we employ feature learning method to extract class-dependent temporal-spectral structures; on the other hand, long-term descriptive statistics are employed to exploit global features of sound events, e.g. variability and recurrence, which also carry rich discriminant information. In order to aggregate the heterogeneous acoustic information for classification, we introduce mixture of experts model (MoE) which effectively formulates relationship between local and global information. At validation stage, we conduct experiments on 
                        
                           UrbanSound
                           8
                           K
                        
                      database which consists of 10 categories of urban sound events with 8732 real-world clips. It is noteworthy that the 10 classes of crowdsourced recordings, including air conditioner, car horn, children playing, dog bark, drilling, engine idling, gunshot, jackhammer, siren and street music, are most common urban sounds closely related to urban life. According to experimental results, the proposed scheme achieved superior performance compared with 3 other latest approaches and it can be a fundamental building block of various urban multimedia information processing systems that help to improve quality of life.",smart cities
10.1016/j.procs.2017.10.053,Conference Proceeding,Procedia Computer Science,scopus,2017-01-01,sciencedirect,Simulation Game as a Reference to Smart City Management,https://api.elsevier.com/content/abstract/scopus_id/85040001312,"The purpose of this research is to know exactly what a ‘Smart City’ and its aspects are. Furthermore, to ensure this ‘Smart City’ aspects and their problems can be implemented in a game, so the game will be able to teach people about missed problem solving solutions. This research paper will discuss about the influence gained from playing a game upon city management skills, and careful planning on what must be done first, in order to maintain or increase the well-being of the citizen and the city welfare. By implementing real life applicable condition in the game which will be played by a person through a sandbox simulation style of gameplay, the player will be able to learn and experience certain types of city problems and the solutions to mitigate those problems without actually making it occur in a real city with real casualties, so it will be a safe vessel to gain new knowledge or to rediscover old effective methods, regarding city management, through a game. The results will portray, how can ‘Smart City’ aspects be implemented into a game, and how a city management simulation game can influence other people’ actions on their city management knowledge.",smart cities
10.1016/B978-0-12-811318-9.00032-6,Book,Handbook of Neural Computation,scopus,2017-01-01,sciencedirect,A Comparative Study of Image Segmentation Algorithms and Descriptors for Building Detection,https://api.elsevier.com/content/abstract/scopus_id/85032380931,"Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixel-wise decisions. This chapter presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings in aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability, and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing.",smart cities
10.1016/j.egypro.2017.07.406,Conference Proceeding,Energy Procedia,scopus,2017-01-01,sciencedirect,Developing neural networks to investigate relationships between lighting quality and lighting glare indices,https://api.elsevier.com/content/abstract/scopus_id/85029908373,"The present work compares the ability of the two most used glare indices, the Daylight Glare Probability (DGP) and the International Commission on Illumination (CIE) Glare Index (CGI), using Multiple Correspondence Analysis (MCA) and Artificial Neural Networks (ANN). The research investigates the efficiency of indexes in predictive indoor lighting quality. This study was carried out by analyzing data from a survey administered to ninety students in real design classrooms in the city of Biskra, Algeria. The experiment was conducted using three different lighting indoor conditions: natural and artificial lighting and mixed lighting. The true prediction of the Daylight Glare Probability for the variable Comfortable was 60.60%, and for (CIE) Glare Index the prediction values were equal to 44.60% for the same variable.",smart cities
10.1016/j.engappai.2016.10.015,Journal,Engineering Applications of Artificial Intelligence,scopus,2017-01-01,sciencedirect,Fault diagnosis of marine 4-stroke diesel engines using a one-vs-one extreme learning ensemble,https://api.elsevier.com/content/abstract/scopus_id/84994718316,"This paper proposes a novel approach for intelligent fault diagnosis for stroke Diesel marine engines, which are commonly used in on-road and marine transportation. The safety and reliability of a ship's work rely strongly on the performance of such an engine; therefore, early detection of any type of failure that affects the engine is of crucial importance. Automatic diagnostic systems are of special importance because they can operate continuously in real time, thereby providing efficient monitoring of the engine's performance. We introduce a fully automatic machine learning-based system for engine fault detection. For this purpose, we monitor various signals that are emitted by the engine, and we use them as an input for a pattern classification algorithm. This action is realized by an ensemble of Extreme Learning Machines that work in a decomposition mode. Because we address 14 different faults and a correct operation mode, we must handle a 15-class problem. We tackle this task by binarization in one-vs-one mode, where each Extreme Learning Machine is trained on a pair of classes. Next, Error-Correcting Output Codes are used to reconstruct the original multi-class task. The results from experiments that were conducted on a real-life dataset demonstrate that the proposed approach delivers superior classification accuracy and a low response time in comparison with a number of state-of-the-art methods and thus is a suitable choice for a real-life implementation on board a ship.",smart cities
10.1016/j.comnet.2016.07.010,Journal,Computer Networks,scopus,2016-12-24,sciencedirect,Multi-criteria optimization of wireless connectivity over sparse networks,https://api.elsevier.com/content/abstract/scopus_id/84994311143,"Opportunistic networking is at the basis of cyber-physical Mobile Networks in Proximity (MNP), through its unique perspective over mobility and the incorporation of socio-inspired networking algorithms. However, results in the field are mostly theoretical, proven to account for stricter hit rate and latency requirements in specific environments. They generally assume that two devices being in proximity automatically see one-another, an assumption which might not stand under real-world conditions (Bluetooth assumes a peering session and close-proximity, WiFi Direct implementations are different between manufacturers, etc.).
                  Our previous studies in the area show that WiFi is still the most feasible media for opportunistic contacts. WiFi-enabled devices, with out-of-the-box networking capabilities, can connect in an ad-hoc opportunistic network, over wireless routers, and thus support a cyber-physical infrastructure for opportunistically spreading information.
                  In this article, we propose a machine learning algorithm that aims to increase the number of contacts between mobile nodes by using a smarter WiFi access point selection heuristic. The algorithm is based on properly balancing signal strength, latency, bandwidth, and, most importantly, the number of friends predicted to connect to the respective access point. We show through simulations based on real-life tracing data-sets that our proposed solution not only increases the likelihood of opportunistic contacts, but it also evenly distributes social subgraphs of users over wireless networks while improving the overall hit rate.",smart cities
10.1016/j.trc.2016.10.019,Journal,Transportation Research Part C: Emerging Technologies,scopus,2016-12-01,sciencedirect,Short-term speed predictions exploiting big data on large urban road networks,https://api.elsevier.com/content/abstract/scopus_id/84994322993,"Big data from floating cars supply a frequent, ubiquitous sampling of traffic conditions on the road network and provide great opportunities for enhanced short-term traffic predictions based on real-time information on the whole network. Two network-based machine learning models, a Bayesian network and a neural network, are formulated with a double star framework that reflects time and space correlation among traffic variables and because of its modular structure is suitable for an automatic implementation on large road networks. Among different mono-dimensional time-series models, a seasonal autoregressive moving average model (SARMA) is selected for comparison. The time-series model is also used in a hybrid modeling framework to provide the Bayesian network with an a priori estimation of the predicted speed, which is then corrected exploiting the information collected on other links. A large floating car data set on a sub-area of the road network of Rome is used for validation. To account for the variable accuracy of the speed estimated from floating car data, a new error indicator is introduced that relates accuracy of prediction to accuracy of measure. Validation results highlighted that the spatial architecture of the Bayesian network is advantageous in standard conditions, where a priori knowledge is more significant, while mono-dimensional time series revealed to be more valuable in the few cases of non-recurrent congestion conditions observed in the data set. The results obtained suggested introducing a supervisor framework that selects the most suitable prediction depending on the detected traffic regimes.",smart cities
10.1016/j.brainres.2016.10.006,Journal,Brain Research,scopus,2016-12-01,sciencedirect,Expression and cell distribution of leukotriene B4 receptor 1 in the rat brain cortex after experimental subarachnoid hemorrhage,https://api.elsevier.com/content/abstract/scopus_id/84991709414,"Convincing evidence supports that nuclear factor kappa B (NF-κB)-meditated inflammation contributes to the adverse prognosis of aneurysmal subarachnoid hemorrhage (SAH), and pathologic neutrophil accumulation after SAH in the brain parenchyma enhances the inflammatory process. Leukotriene B4 (LTB4) is a highly potent lipid chemoattractant of neutrophils, and its biological effects are mediated primarily through the high-affinity LTB4 receptor 1 (BLT1). It is verified that NF-κB-dependent BLT1 mediates LTB4 signaling and LTB4 stimulates NF-κB-dependent inflammation via BLT1. This study aimed to determine the expression and cell distribution of BLT1 in the brain cortex after SAH and investigate the potential relationship between protein expressions of BLT1 and NF-κB. Male Sprague-Dawley rats were randomly assigned into sham group and SAH groups at 6h, 12h and on day 1, day 2 and day 3 (n=6 for each subgroup). SAH groups suffered experimental SAH by injecting 0.3ml autologous blood into the prechiasmatic cistern. BLT1 expression was measured by real-time PCR, western blot, immunohistochemistry and immunofluorescence. Nuclear expression of p65 protein, the major subunit of NF-κB, was also detected by western blot. Our data showed that the expression levels of BLT1 and nuclear p65 protein were both markedly increased after SAH. Moreover, there was a significant positive correlation between BLT1 and nuclear p65 protein expressions in the same specific time course. Double immunofluorescence staining showed that BLT1 were mainly expressed in neurons, microglia and endothelial cells rather than astrocytes after SAH. These results suggest that BLT1 may participate in the NF-κB-mediated inflammatory response after SAH, and there might be important implications for further studies using specific BLT1 antagonists to attenuate the NF-κB-mediated inflammation after SAH.",smart cities
10.1016/j.watres.2016.10.020,Journal,Water Research,scopus,2016-12-01,sciencedirect,Enhanced detection of pathogenic enteric viruses in coastal marine environment by concentration using methacrylate monolithic chromatographic supports paired with quantitative PCR,https://api.elsevier.com/content/abstract/scopus_id/84991227463,"Currently, around 50% of the world's population lives in towns and cities within 100 km of the coast. Monitoring of viruses that are frequently present in contaminated coastal environments, such as rotavirus (RoV) and norovirus (NoV), which are also the major cause of human viral gastroenteritis, is essential to ensure the safe use of these water bodies. Since exposure to as few as 10–100 particles of RoV or NoV may induce gastrointestinal disease, there is a need to develop a rapid and sensitive diagnostic method for their detection in coastal water samples. In this study, we evaluate the application of methacrylate monolithic chromatographic columns, commercially available as convective interaction media (CIM®), to concentrate pathogenic enteric viruses from saline water samples prior to virus quantification by one-step reverse transcription quantitative PCR (RT-qPCR). Using RoV and NoV as model enteric viruses, we present our results on the most effective viral concentration conditions from saline water matrices using butyl (C4) hydrophobic interaction monolithic support (CIM® C4). C4 monolithic columns exhibit a good capacity to bind both RoV and NoV and both viruses can be eluted in a single step. Our protocol using a 1 ml C4 column enables processing of 400 ml saline water samples in less than 60 min and increases the sensitivity of RoV and NoV detection by approximately 50-fold and 10-fold respectively. The protocol was also scaled up using larger capacity 8 ml C4 columns to process 4000 ml of seawater samples with concentration factors of 300-fold for RoV and 40-fold for NoV, without any significant increase in processing time. Furthermore, C4 monolithic columns were adapted for field use in an on-site application of RoV concentration from seawater samples with performance equivalent to that of the reference laboratory setup. Overall, the results from successful deployment of CIM C4 columns for concentration of rotavirus and norovirus in seawater samples reiterate the utility of monolithic supports as efficient, scalable and modular preparative tools for processing environmental water samples to enhance viral detection using molecular methods.",smart cities
10.1016/j.ins.2016.08.050,Journal,Information Sciences,scopus,2016-12-01,sciencedirect,Pedestrian detection by learning a mixture mask model and its implementation,https://api.elsevier.com/content/abstract/scopus_id/84989928835,"Pedestrian detection from videos is a useful technique in intelligent transportation systems. Some key challenges of accurate pedestrian detection are the large variations in pedestrian appearance as the pedestrians assume different poses and the different camera views that are involved. This makes the generic visual descriptors unreliable for real-world pedestrian detection. In this paper, we propose a high-level human-specific descriptor for detecting pedestrians in multiple videos. More specifically, by obtaining the feature matrix from a sliding window, we use multiple mapping vectors to project the original feature matrix into different mask spaces. Inspired by the part-based model [12], it is natural to formulate the pedestrian detection into a multiple-instance learning (MIL) framework. Afterward, we adopt an MI-SVM [9] to solve it. To evaluate the proposed detection algorithm, we implement the pedestrian detection algorithm in FPGA, which can process over 30 fps. Moreover, our method outperforms many existing object detection algorithms in terms of accuracy.",smart cities
10.1016/j.biopha.2016.09.093,Journal,Biomedicine and Pharmacotherapy,scopus,2016-12-01,sciencedirect,CD200Fc attenuates inflammatory responses and maintains barrier function by suppressing NF-κB pathway in cigarette smoke extract induced endothelial cells,https://api.elsevier.com/content/abstract/scopus_id/84989320489,"Background
                  Recent evidence suggests that CD200 fusion protein (CD200Fc), a CD200R1 agonist may attenuate inflammatory responses in autoimmune diseases and neuro-degeneration. While, little is known about the function of CD200Fc in cigarette smoke extract (CSE)-induced mouse Cardiac Microvascular Endothelial Cells (mCMECs). The present study was designed to elucidate the effects of CD200Fc on CSE-induced vascular endothelial barrier (VEB) dysfunction and inflammatory responses, which is a highly clinically relevant model of smoking related cardiovascular diseases.
               
                  Methods
                  mCMECs were pre-treated with 1, 10 and 100μg/ml CD200Fc for 24h respectively, and then treated with 250μg/ml CSE for different times (24h or 120min). The transepithelial electrical resistance (TEER) and transport of fluorescent markers were used to measure VEB function in CSE-induced mCMECs. Western blot and immunofluorescent staining analysis were used to detect the expression of tight junction proteins, such as Zona Occludens-1 (ZO-1) and Claudin-1 in CSE-induced mCMECs. We measured the expression of pro-inflammatory cytokines in CSE-induced mCMECs by using ELISA and RT-PCR. In addition, the NF-κB activity in CSE-induced mCMECs were investigated by using nuclear/cytosol fractionation and western blot analysis.
               
                  Results
                  In vitro treatment with CSE increased the transport of fluorescent markers and decreased TEER levels in mCMECs, respectively, which were attenuated by CD200Fc (10 and 100μg/ml) pretreatment. The CSE-induced up-regulation of pro-inflammatory cytokines such as Cyclooxygenase-2 (COX-2), inducible nitric oxide synthase (iNOS), platelet endothelial cell adhesion molecule-1 (PECAM-1), vascular cell adhesion molecule-1 (ICAM-1), Prostaglandin E2 (PGE2), tumor necrosis factor-α (TNF-α), interleukin-6 (IL-6) and IL-8 in mCMECs was also abrogated by CD200Fc (10 and 100μg/ml) pretreatment. CD200Fc also inhibited CSE-induced nuclear factor kappa-light-chain-enhancer of activated B cells (NF-κB) activation in mCMECs, such as inhibition of its DNA binding activity, phosphorylated expression, and translocation to nucleus.
               
                  Conclusion
                  Thus, CD200Fc exert anti-inflammatory effect and protect VEB function in CSE-induced mCMECs. The vasoprotective effects of CD200Fc may be specifically beneficial in pathophysiological conditions associated with smoking related cardiovascular diseases.",smart cities
10.1016/j.cognition.2016.08.011,Journal,Cognition,scopus,2016-12-01,sciencedirect,Strategies for memory-based decision making: Modeling behavioral and neural signatures within a cognitive architecture,https://api.elsevier.com/content/abstract/scopus_id/84984817875,"How do people use memories to make inferences about real-world objects? We tested three strategies based on predicted patterns of response times and blood-oxygen-level-dependent (BOLD) responses: one strategy that relies solely on recognition memory, a second that retrieves additional knowledge, and a third, lexicographic (i.e., sequential) strategy, that considers knowledge conditionally on the evidence obtained from recognition memory. We implemented the strategies as computational models within the Adaptive Control of Thought-Rational (ACT-R) cognitive architecture, which allowed us to derive behavioral and neural predictions that we then compared to the results of a functional magnetic resonance imaging (fMRI) study in which participants inferred which of two cities is larger. Overall, versions of the lexicographic strategy, according to which knowledge about many but not all alternatives is searched, provided the best account of the joint patterns of response times and BOLD responses. These results provide insights into the interplay between recognition and additional knowledge in memory, hinting at an adaptive use of these two sources of information in decision making. The results highlight the usefulness of implementing models of decision making within a cognitive architecture to derive predictions on the behavioral and neural level.",smart cities
10.1016/j.epsr.2016.07.018,Journal,Electric Power Systems Research,scopus,2016-12-01,sciencedirect,Classification for consumption data in smart grid based on forecasting time series,https://api.elsevier.com/content/abstract/scopus_id/84981303127,"One of the most important tasks of present day smart grid implementations is to classify different types of consumers (households, office buildings and industrial plants) because they may be served by the power supplier with different parameters, rates, contracts.
                  In this paper, we propose a novel classification scheme for smart grid systems where the collected data are processed in order to increase the efficiency of electricity transportation as well as demand-supply management. The new scheme is based on forecasting the consumption time series obtained from a smart meter. Class assignment is determined using the forecast error. Different linear and nonlinear methods were tested based on the corresponding assumptions on the statistical behavior of the underlying consumption time series.
                  Performance tests were carried out with simulations in order to demonstrate the capabilities and to compare the achieved performance of the proposed scheme with existing solutions. The simulations have been executed using (i) artificially generated consumption data, which data came from a bottom-up semi-Markov model and (ii) real, measured power consumption data as well. The parameters of the model have been validated on real data. The numerical results have demonstrated that our method can better model and classify the consumption patterns of office-buildings than the existing methods. As a result, the proposed method may prove to be a promising classification tool.",smart cities
10.1016/j.ssci.2015.09.022,Journal,Safety Science,scopus,2016-12-01,sciencedirect,"A dynamic decision support system based on geographical information and mobile social networks: A model for tsunami risk mitigation in Padang, Indonesia",https://api.elsevier.com/content/abstract/scopus_id/84956994304,"In coastal cities, population and property are concentrated in small areas, with abundant resources and convenient transportation, but also with potential tsunami risk, as shown by the tsunami disasters of 2004, 2010 in Indonesia. Coastal area citizens need to evacuate to a safe place as soon as tsunamis occur. The prime evacuation time is very critical for them, but it is delayed in practice by complex information transfer processes. In recent years, spatial information has become an important resource used in dynamic decision support for emergencies, and smart phones have become a primary social communication device during interactions in emergencies. This paper outlines the design and development of a prototype geographical information system centric, social media based dynamic decision support system (GIS-SM-DDSS) that integrates geographical information with Twitter technology to enable self-organized information networks to support decision making and collective actions in emergency situations. The actors include government policy makers, policy managers, highly influential social leaders in local communities, and policy executors and urban citizens impacted by disasters. The main system functions include dynamic disaster risk analysis, timely dissemination of evacuation strategies to community residents, and real-time detection of environmental risk and evacuation support. This system is designed as a field experiment in Padang, Indonesia, to help public officials design tsunami risk maps with timely evacuation routes and transmit these maps to influential leaders in local neighborhoods that are exposed to tsunami risk. Each neighborhood leader would then tweet the detailed route to citizens that follow the tweet. The proposed has potential to support evacuation strategies and real-time guidance of communities at risk during disaster.",smart cities
10.1016/j.knosys.2016.08.031,Journal,Knowledge-Based Systems,scopus,2016-11-15,sciencedirect,Cognitive pilot-aircraft interface for single-pilot operations,https://api.elsevier.com/content/abstract/scopus_id/84994092791,"Considering the foreseen expansion of the air transportation system within the next two decades and the opportunities offered by higher levels of automation, Single-Pilot Operations (SPO) are regarded as viable alternatives to conventional two-pilot operations for commercial transport aircraft. In comparison with current operations, SPO require higher cognitive efforts, which potentially result in increased human error rates. This article proposes a novel Cognitive Pilot-Aircraft Interface (CPAI) concept, which introduces adaptive knowledge-based system functionalities to assist single pilots in the accomplishment of mission-essential and safety-critical tasks in modern commercial transport aircraft. The proposed CPAI system implementation is based on real-time detection of the pilot’s physiological and cognitive states, allowing the avoidance of pilot errors and supporting enhanced synergies between the human and the avionics systems. These synergies yield significant improvements in the overall performance and safety levels. A CPAI working process consisting of sensing, estimation and reconfiguration steps is developed to support the assessment of physiological and external conditions, a dynamic allocation of tasks and adaptive alerting. Suitable mathematical models are introduced to estimate the mental demand associated to each piloting task and to assess the pilot cognitive states. Suitably implemented decision logics allow a continuous and optimal adjustment of the automation levels as a function of the estimated cognitive states. Representative numerical simulation test cases provide a preliminary validation of the CPAI concept. In particular, the continuous adaptation of the flight deck's automation successfully maintains the pilot's task load within an optimal range, mitigating the onset of hazardous fatigue levels. It is anticipated that by including suitably designed Psychophysiological-Based Integrity Augmentation (PBIA) functionalities the CPAI system will allow to fulfil the evolving aircraft certification requirements and hence support the implementation of SPO in commercial transport aircraft.",smart cities
10.1016/j.etp.2016.08.005,Journal,Experimental and Toxicologic Pathology,scopus,2016-11-01,sciencedirect,In vivo protective effect of phosphatidylcholine on carbon tetrachloride induced nephrotoxicity,https://api.elsevier.com/content/abstract/scopus_id/84994182482,"Phosphatidylcholine (PC) from egg yolk is a bioactive substance with various beneficial effects, including anti-inflammatory and anti-oxidant effects. Recently, this substance has been reported to prevent acute hepatotoxicity. In the present study, we aimed to evaluate the putative protective effect of PC on carbon tetrachloride (CCl4)-induced nephrotoxicity in ICR mice. Many previous studies demonstrated that CCl4 induces nephrotoxicity resulting in renal oxidative damage. CCl4 in corn oil (0.1ml, 1.2g/kg) was intra-peritoneally injected into 7-week-old ICR mice twice a week. PC in corn oil (0.1ml, 100mg/kg) was then orally injected daily for a week. In 7 days, blood urea nitrogen (BUN) and creatinine concentrations had significantly increased in the CCl4 group compared to the control group, whereas the PC and CCl4 co-injected group had significantly decreased BUN and creatinine concentrations compared to the CCl4 group. Comparative analysis of histopathological injuries revealed that PC abrogated the nephrotoxicity of CCl4 at 7 days. Accordingly, PC also improved renal fibrosis induced by CCl4. Various biomarkers associated with oxidative damage appeared to be up-regulated in the CCl4 group, whereas in the PC and CCl4 co-injected group, levels of oxidative damage significantly decreased. Aquaporin1 (AQP1), an important water transport protein in the kidney, was down regulated in the CCl4 group compared to the control group. PC counteracted this effect. These results strongly suggest that PC can protect against oxidative damage induced by CCl4 in the kidney and enhance recovery from renal disorders.",smart cities
10.1016/j.trc.2016.09.015,Journal,Transportation Research Part C: Emerging Technologies,scopus,2016-11-01,sciencedirect,An efficient realization of deep learning for traffic data imputation,https://api.elsevier.com/content/abstract/scopus_id/84991628583,"Traffic data provide the basis for both research and applications in transportation control, management, and evaluation, but real-world traffic data collected from loop detectors or other sensors often contain corrupted or missing data points which need to be imputed for traffic analysis. For this end, here we propose a deep learning model named denoising stacked autoencoders for traffic data imputation. We tested and evaluated the model performance with consideration of both temporal and spatial factors. Through these experiments and evaluation results, we developed an algorithm for efficient realization of deep learning for traffic data imputation by training the model hierarchically using the full set of data from all vehicle detector stations. Using data provided by Caltrans PeMS, we have shown that the mean absolute error of the proposed realization is under 10veh/5-min, a better performance compared with other popular models: the history model, ARIMA model and BP neural network model. We further investigated why the deep leaning model works well for traffic data imputation by visualizing the features extracted by the first hidden layer. Clearly, this work has demonstrated the effectiveness as well as efficiency of deep learning in the field of traffic data imputation and analysis.",smart cities
10.1016/j.autcon.2016.03.012,Journal,Automation in Construction,scopus,2016-11-01,sciencedirect,"SmartSite: Intelligent and autonomous environments, machinery, and processes to realize smart road construction projects",https://api.elsevier.com/content/abstract/scopus_id/84969580061,"This article presents an overview of the SmartSite research project that adopts machine learning, decision theory and distributed artificial intelligence to design and test a multi-agent system (MAS) for asphalt road construction. SmartSite puts major emphasis on sensing and communication technologies that integrate real-time automated information exchange in the supply chain of road construction. As part of the larger SmartSite project, this article introduces a novel real-time path planning system for compactors and presents the results of several simulation and field realistic experiments conducted to evaluate the system in a sophisticated simulation and harsh construction environment, respectively. The system operates based on Belief-Desire-Intention (BDI) software agents and real-time sensory inputs. The newly developed integrated and information rich process benefits asphalt compactor operators, as they are now capable to control their machinery and react to changing environmental, material-related and process-related disturbances or changes. This improves the quality of the delivery and laying of asphalt material, prevents compactors from over-compacting certain road segments, increases the road's pavement longevity during the operational life cycle phase; refocuses the work tasks of the site managers, and reduces the construction budget and schedule. The system's ability to maneuver an asphalt roller during real-word operation also makes it an important step towards a fully automated asphalt compactor.",smart cities
10.1016/j.neuron.2016.08.032,Journal,Neuron,scopus,2016-10-05,sciencedirect,Hunger-Driven Motivational State Competition,https://api.elsevier.com/content/abstract/scopus_id/84992755787,"Behavioral choice is ubiquitous in the animal kingdom and is central to goal-oriented behavior. Hypothalamic Agouti-related peptide (AgRP) neurons are critical regulators of appetite. Hungry animals, bombarded by multiple sensory stimuli, are known to modify their behavior during times of caloric need, rapidly adapting to a consistently changing environment. Utilizing ARCAgRP neurons as an entry point, we analyzed the hierarchical position of hunger related to rival drive states. Employing a battery of behavioral assays, we found that hunger significantly increases its capacity to suppress competing motivational systems, such as thirst, anxiety-related behavior, innate fear, and social interactions, often only when food is accessible. Furthermore, real-time monitoring of ARCAgRP activity revealed time-locked responses to conspecific investigation in addition to food presentation, further establishing that, even at the level of ARCAgRP neurons, choices are remarkably flexible computations, integrating internal state, external factors, and anticipated yield.
               
                  Video Abstract",smart cities
10.1016/j.asoc.2016.06.031,Journal,Applied Soft Computing Journal,scopus,2016-10-01,sciencedirect,An online learning approach to eliminate Bus Bunching in real-time,https://api.elsevier.com/content/abstract/scopus_id/84976407092,"Recent advances in telecommunications created new opportunities for monitoring public transport operations in real-time. This paper presents an automatic control framework to mitigate the Bus Bunching phenomenon in real-time. The framework depicts a powerful combination of distinct Machine Learning principles and methods to extract valuable information from raw location-based data. State-of-the-art tools and methodologies such as Regression Analysis, Probabilistic Reasoning and Perceptron's learning with Stochastic Gradient Descent constitute building blocks of this predictive methodology. The prediction's output is then used to select and deploy a corrective action to automatically prevent Bus Bunching. The performance of the proposed method is evaluated using data collected from 18 bus routes in Porto, Portugal over a period of one year. Simulation results demonstrate that the proposed method can potentially reduce bunching by 68% and decrease average passenger waiting times by 4.5%, without prolonging in-vehicle times. The proposed system could be embedded in a decision support system to improve control room operations.",smart cities
10.1016/j.eswa.2016.03.024,Journal,Expert Systems with Applications,scopus,2016-10-01,sciencedirect,Building detection from orthophotos using a machine learning approach: An empirical study on image segmentation and descriptors,https://api.elsevier.com/content/abstract/scopus_id/84963795376,"Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixelwise decisions. This paper presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings on aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Moreover, we introduce a principled evaluation that allows selecting the best pair segmentation algorithm-region descriptor for the task of building detection. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing such as intelligent unmanned aerial vehicle navigation and automatic 3D city modeling.",smart cities
10.1016/j.gene.2016.05.010,Journal,Gene,scopus,2016-09-30,sciencedirect,Age-related gene expression change of GABAergic system in visual cortex of rhesus macaque,https://api.elsevier.com/content/abstract/scopus_id/84969924887,"Degradation of visual function is a common phenomenon during aging and likely mediated by change in the impaired central visual pathway. Treatment with GABA or its agonist could recover the ability of visual neurons in the primary visual cortex of senescent macaques. However, little is known about how GABAergic system change is related to the aged degradation of visual function in nonhuman primate. With the use of quantitative PCR method, we measured the expression change of 24 GABA related genes in the primary visual cortex (Brodmann's 17) of different age groups. In this study, both of mRNA and protein of glutamic acid decarboxylase (GAD65) were measured by real-time RT-PCR and Western blot, respectively. Results revealed that the level of GAD65 message was not significantly altered, but the proteins were significantly decreased in the aged monkey. As GAD65 plays an important role in GABA synthesis, the down-regulation of GAD65 protein was likely the key factor leading to the observed GABA reduction in the primary visual cortex of the aged macaques. In addition, 7 of 14 GABA receptor genes were up-regulated and one GABA receptor gene was significantly reduced during aging process even after Banjamini correction for multiple comparisons (P
                     <0.05). These results suggested that the dysregulation of GAD65 protein might contribute to some age-related neural visual dysfunctions and most of GABA receptor genes induce a clear indication of compensatory effect for the reduced GABA release in the healthy aged monkey cortex.",smart cities
10.1016/j.jngse.2016.09.044,Journal,Journal of Natural Gas Science and Engineering,scopus,2016-09-01,sciencedirect,Bio-inspired optimal site selection of LPG stations for gas-driven cars in an urban region,https://api.elsevier.com/content/abstract/scopus_id/84989287958,"Siting new liquefied petroleum gas (LPG) stations in a metropolitan region to support the initiative of air pollution control is intimately tied to where these LPG stations are located for filling up those vehicles. Unlike traditional siting and routing problems, the LPG stations must be sited to serve the consumers with the highest mobility instead of meeting the regular consumers’ demand. To optimize the spatial allocation of LPG stations in an intelligent transportation network with consideration of the economies of scale, this study presents a bio-inspired computational intelligence algorithm based on the gravity model to express the behavior of drivers in search of a set of neighboring LPG stations. The practical implementation of the proposed method was evaluated using a real-world case study, in which the planning objective is to minimize the expected distance for fueling vehicles. A Monte Carlo simulation is performed to determine the effect of the uncertainty that is caused by the mobility of LPG cars and parameters in the gravity model on the optimal results. The results reveal that the optimal number of LGP stations in the case study is approximately 15, and the minimized expected distance for fueling is 2500 m. The proposed method is useful when the behavior of customers cannot be ignored in siting problems.",smart cities
10.1016/j.scitotenv.2016.04.047,Journal,Science of the Total Environment,scopus,2016-08-01,sciencedirect,Antibiotic resistance spread potential in urban wastewater effluents disinfected by UV/H<inf>2</inf>O<inf>2</inf> process,https://api.elsevier.com/content/abstract/scopus_id/84963655319,"Urban wastewater treatment plants (UWTPs) are among the main hotspots of antibiotic resistance (AR) spread into the environment and the role of conventional and new disinfection processes as possible barrier to minimise the risk for AR transfer is presently under investigation. Accordingly, the aim of this work was to evaluate the effect of an advanced oxidation process (AOP) (specifically UV/H2O2) on AR transfer potential. UV/H2O2 disinfection experiments were carried out on real wastewater samples to evaluate the: i) inactivation of total coliforms, Escherichia coli and antibiotic resistant E. coli as well as ii) possible removal of target antibiotic resistance genes (ARGs) (namely, bla
                     TEM, qnrS and tetW). In particular, DNA was extracted from both antibiotic resistant E. coli bacterial cells (intracellular DNA), grown on selective culture media, and the whole water suspension (total DNA) collected at different treatment times. Polymerase chain reaction (PCR) assay was performed to detect the absence/presence of the selected ARGs. Real Time quantitative Polymerase Chain Reaction (qPCR) was used to quantify the investigated ARGs in terms of copiesmL−1. In spite of the bacterial inactivation and a decrease of ARGs in intracellular DNA after 60min treatment, UV/H2O2 process was not effective in ARGs removal from water suspension (total DNA). Particularly, an increase up to 3.7×103
                     copiesmL−1 (p
                     >0.05) of bla
                     TEM gene was observed in total DNA after 240min treatment, while no difference (p
                     >0.05) was found for qnrS gene between the initial (5.1×104
                     copiesmL−1) and the final sample (4.3×104
                     copiesmL−1). On the base of the achieved results, the investigated disinfection process may not be effective in minimising AR spread potential into the environment. The death of bacterial cells, which results in DNA release in the treated water, may pose a risk for AR transfer to other bacteria present in the receiving water body.",smart cities
10.1016/j.compind.2015.10.005,Journal,Computers in Industry,scopus,2016-05-01,sciencedirect,A methodology for traffic-related Twitter messages interpretation,https://api.elsevier.com/content/abstract/scopus_id/84951335378,"This paper addresses the problem of interpreting tweets that describe traffic-related events and that are distributed by government agencies in charge of road networks or by news agencies. Processing such tweets is of interest for two reasons. First, albeit phrased in natural language, such tweets use a much more regular and well-behaved prose than generic user-generated tweets. This characteristic facilitates automating their interpretation and achieving high precision and recall. Second, government agencies and news agencies use Twitter channels to distribute real-time traffic conditions and to alert drivers about planned changes on the road network and about future events that may affect traffic conditions. Hence, such tweets provide exactly the kind of information that proactive truck fleet monitoring and similar applications require. The main contribution of the paper is an automatic tweet interpretation tool, based on Machine Learning techniques, that achieves good performance for traffic-related tweets distributed by traffic authorities and news agencies. The paper also covers in detail experiments with real traffic-related tweets to access the precision and recall of the tool.",smart cities
10.1016/j.trb.2016.01.004,Journal,Transportation Research Part B: Methodological,scopus,2016-04-01,sciencedirect,Reinforcement learning approach for train rescheduling on a single-track railway,https://api.elsevier.com/content/abstract/scopus_id/84960471709,"Optimal rail network infrastructure and rolling stock utilization can be achieved with use of different scheduling tools by extensive planning a long time before actual operations. The initial train timetable takes into account possible smaller disturbances, which can be compensated within the schedule. Bigger disruptions, such as accidents, rolling stock breakdown, prolonged passenger boarding, and changed speed limit cause delays that require train rescheduling. In this paper, we introduce a train rescheduling method based on reinforcement learning, and more specifically, Q-learning. We present here the Q-learning principles for train rescheduling, which consist of a learning agent and its actions, environment and its states, as well as rewards. The use of the proposed approach is first illustrated on a simple rescheduling problem comprising a single-lane track with three trains. The evaluation of the approach is performed on extensive set of experiments carried out on a real-world railway network in Slovenia. The empirical results show that Q-learning lead to rescheduling solutions that are at least equivalent and often superior to those of several basic rescheduling methods that do not rely on learning agents. The solutions are learned within reasonable computational time, a crucial factor for real-time applications.",smart cities
10.1016/j.jnca.2016.02.002,Journal,Journal of Network and Computer Applications,scopus,2016-04-01,sciencedirect,A DTN routing strategy based on neural networks for urban bus transportation system,https://api.elsevier.com/content/abstract/scopus_id/84959458445,"Routing in Delay/Disruption Tolerant Networks (DTNs) is a challenge because it must deal with possible unconnected end-to-end paths at the time of sending a message to a destination. An efficient selection of a contact node to forward a message is a key in the routing process. Prediction techniques can be used to assist in routing decisions. In this work we present a multi-copy routing strategy for a DTN built on the top of an Urban Bus Transportation System (UBTS). Using the buses as nodes, the contact history of nodes can be used to improve the DTN communication. The strategy relies on a journey predictor to build a multi-graph of predicted journeys to the destinations. It calls a next node contact predictor based on Artificial Neural Networks (ANNs) to compute each vertex of the multi-graph. A minimal delay criterion is applied to select the best journey. A copy control algorithm is used to improve the performance of the system. Experiments were carried out with real contacts of a quasi-opportunist scenario. The proposal outperformed the MaxProp strategy in the most cases considering the number of delivered messages, the delivery delay and the delivery cost.",smart cities
10.1016/j.is.2015.09.001,Journal,Information Systems,scopus,2016-04-01,sciencedirect,Labeling sensing data for mobility modeling,https://api.elsevier.com/content/abstract/scopus_id/84957559944,"In urban environments, sensory data can be used to create personalized models for predicting efficient routes and schedules on a daily basis; and also at the city level to manage and plan more efficient transport, and schedule maintenance and events. Raw sensory data is typically collected as time-stamped sequences of records, with additional activity annotations by a human, but in machine learning, predictive models view data as labeled instances, and depend upon reliable labels for learning. In real-world sensor applications, human annotations are inherently sparse and noisy. This paper presents a methodology for preprocessing sensory data for predictive modeling in particular with respect to creating reliable labeled instances. We analyze real-world scenarios and the specific problems they entail, and experiment with different approaches, showing that a relatively simple framework can ensure quality labeled data for supervised learning. We conclude the study with recommendations to practitioners and a discussion of future challenges.",smart cities
10.1016/j.neucom.2015.08.099,Journal,Neurocomputing,scopus,2016-03-12,sciencedirect,Learning for an aesthetic model for estimating the traffic state in the traffic video,https://api.elsevier.com/content/abstract/scopus_id/84958854588,"With the increasing number of vehicles running on the urban roads, the traffic jam becomes much more serious. Properly estimating the traffic jam level from traffic videos is essential for the department of transportation management and drivers. Currently, for estimating the traffic state on videos, most solutions are built on evaluating traffic flow by counting the running vehicles per time unit or detecting their moving speed. However, the main challenge of these solutions is on the vehicle tracking method, in which the vehicles are necessary to be effectively and integrally segmented from the scenes. The solutions should tradeoff the accuracy of the estimation results and the efficiency of the method. In this paper, we propose a learning-based aesthetic model to estimate the traffic state on videos. The model uses multiple video-based perceptual features about traffic state to train the random forest classifier with the labeled data, and estimates traffic state by data classification. The evaluation experiments are conducted on a testing image set, and the results show that the traffic state estimation accuracy of the proposed model is higher than 98% and the efficiency performance is achieved in real-time.",smart cities
10.1016/j.artmed.2016.01.006,Journal,Artificial Intelligence in Medicine,scopus,2016-03-01,sciencedirect,Knowledge-light adaptation approaches in case-based reasoning for radiotherapy treatment planning,https://api.elsevier.com/content/abstract/scopus_id/84958231564,"Objective
                  Radiotherapy treatment planning aims at delivering a sufficient radiation dose to cancerous tumour cells while sparing healthy organs in the tumour-surrounding area. It is a time-consuming trial-and-error process that requires the expertise of a group of medical experts including oncologists and medical physicists and can take from 2 to 3h to a few days. Our objective is to improve the performance of our previously built case-based reasoning (CBR) system for brain tumour radiotherapy treatment planning. In this system, a treatment plan for a new patient is retrieved from a case base containing patient cases treated in the past and their treatment plans. However, this system does not perform any adaptation, which is needed to account for any difference between the new and retrieved cases. Generally, the adaptation phase is considered to be intrinsically knowledge-intensive and domain-dependent. Therefore, an adaptation often requires a large amount of domain-specific knowledge, which can be difficult to acquire and often is not readily available. In this study, we investigate approaches to adaptation that do not require much domain knowledge, referred to as knowledge-light adaptation.
               
                  Methodology
                  We developed two adaptation approaches: adaptation based on machine-learning tools and adaptation-guided retrieval. They were used to adapt the beam number and beam angles suggested in the retrieved case. Two machine-learning tools, neural networks and naive Bayes classifier, were used in the adaptation to learn how the difference in attribute values between the retrieved and new cases affects the output of these two cases. The adaptation-guided retrieval takes into consideration not only the similarity between the new and retrieved cases, but also how to adapt the retrieved case.
               
                  Results
                  The research was carried out in collaboration with medical physicists at the Nottingham University Hospitals NHS Trust, City Hospital Campus, UK. All experiments were performed using real-world brain cancer patient cases treated with three-dimensional (3D)-conformal radiotherapy. Neural networks-based adaptation improved the success rate of the CBR system with no adaptation by 12%. However, naive Bayes classifier did not improve the current retrieval results as it did not consider the interplay among attributes. The adaptation-guided retrieval of the case for beam number improved the success rate of the CBR system by 29%. However, it did not demonstrate good performance for the beam angle adaptation. Its success rate was 29% versus 39% when no adaptation was performed.
               
                  Conclusions
                  The obtained empirical results demonstrate that the proposed adaptation methods improve the performance of the existing CBR system in recommending the number of beams to use. However, we also conclude that to be effective, the proposed adaptation of beam angles requires a large number of relevant cases in the case base.",smart cities
10.1016/j.neucom.2015.12.013,Journal,Neurocomputing,scopus,2016-02-29,sciencedirect,A distributed spatial-temporal weighted model on MapReduce for short-term traffic flow forecasting,https://api.elsevier.com/content/abstract/scopus_id/84955646724,"Accurate and timely traffic flow prediction is crucial to proactive traffic management and control in data-driven intelligent transportation systems (D2ITS), which has attracted great research interest in the last few years. In this paper, we propose a Spatial–Temporal Weighted K-Nearest Neighbor model, named STW-KNN, in a general MapReduce framework of distributed modeling on a Hadoop platform, to enhance the accuracy and efficiency of short-term traffic flow forecasting. More specifically, STW-KNN considers the spatial–temporal correlation and weight of traffic flow with trend adjustment features, to optimize the search mechanisms containing state vector, proximity measure, prediction function, and 
                        K
                      selection. Furthermore, STW-KNN is implemented on a widely adopted Hadoop distributed computing platform with the MapReduce parallel processing paradigm, for parallel prediction of traffic flow in real time. Finally, with extensive experiments on real-world big taxi trajectory data, STW-KNN is compared with the state-of-the-art prediction models including conventional K-Nearest Neighbor (KNN), Artificial Neural Networks (ANNs), Naïve Bayes (NB), Random Forest (RF), and C4.5. The results demonstrate that the proposed model is superior to existing models on accuracy by decreasing the mean absolute percentage error (MAPE) value more than 11.59% only in time domain and even achieves 89.71% accuracy improvement with the MAPEs of between 3.34% and 6.00% in both space and time domains, and also significantly improves the efficiency and scalability of short-term traffic flow forecasting over existing approaches.",smart cities
10.1016/j.eswa.2015.08.048,Journal,Expert Systems with Applications,scopus,2016-02-01,sciencedirect,Time-evolving O-D matrix estimation using high-speed GPS data streams,https://api.elsevier.com/content/abstract/scopus_id/84945288965,"Portable digital devices equipped with GPS antennas are ubiquitous sources of continuous information for location-based Expert and Intelligent Systems. The availability of these traces on the human mobility patterns is growing explosively. To mine this data is a fascinating challenge which can produce a big impact on both travelers and transit agencies.
                  This paper proposes a novel incremental framework to maintain statistics on the urban mobility dynamics over a time-evolving origin-destination (O-D) matrix. The main motivation behind such task is to be able to learn from the location-based samples which are continuously being produced, independently on their source, dimensionality or (high) communicational rate. By doing so, the authors aimed to obtain a generalist framework capable of summarizing relevant context-aware information which is able to follow, as close as possible, the stochastic dynamics on the human mobility behavior. Its potential impact ranges Expert Systems for decision support across multiple industries, from demand estimation for public transportation planning till travel time prediction for intelligent routing systems, among others.
                  The proposed methodology settles on three steps: (i) Half-Space trees are used to divide the city area into dense subregions of equal mass. The uncovered regions form an O-D matrix which can be updated by transforming the trees’leaves into conditional nodes (and vice-versa). The (ii) Partioning Incremental Algorithm is then employed to discretize the target variable’s historical values on each matrix cell. Finally, a (iii) dimensional hierarchy is defined to discretize the domains of the independent variables depending on the cell’s samples.
                  A Taxi Network running on a mid-sized city in Portugal was selected as a case study. The Travel Time Estimation (TTE) problem was regarded as a real-world application. Experiments using one million data samples were conducted to validate the methodology. The results obtained highlight the straightforward contribution of this method: it is capable of resisting to the drift while still approximating context-aware solutions through a multidimensional discretization of the feature space. It is a step ahead in estimating the real-time mobility dynamics, regardless of its application field.",smart cities
10.1016/j.trpro.2016.11.102,Conference Proceeding,Transportation Research Procedia,scopus,2016-01-01,sciencedirect,Application of Data Mining Techniques for Traffic Density Estimation and Prediction,https://api.elsevier.com/content/abstract/scopus_id/85011027191,"Advanced Traveller Information Systems (ATIS) is one of the functional areas of Intelligent Transportation Systems (ITS) and it aims at providing real time traffic information to the travellers for making better travel decisions. This information would be most effective if provided to travellers during or before the start of their trip. Therefore, accurate prediction models are required in ATIS for conveying reliable information about the future state of traffic. Different methods used for the prediction of traffic parameters include historic averaging, regression analysis, Kalman filtering, time series analysis, machine learning, etc. The objective of this research is to explore the use of automated sensor data and data driven techniques for traffic state prediction under Indian traffic conditions. Travel time and traffic density (as an indicator of congestion) are used commonly to inform users about the state of a traffic system. However, these two parameters are spatial in nature and direct measurement from field is difficult. Therefore, estimation of these parameters from location based data is a challenge in many of the ITS implementations. The present study addresses the problem of estimation of traffic density with the help of location based sensors which are capable of measuring parameters such as volume and Time Mean Speed (TMS). Machine learning techniques namely, k-Nearest Neighbour (k-NN) and Artificial Neural Network (ANN) are selected as the estimation and prediction tool in this study, based on acceptable performance of the same in earlier studies.",smart cities
10.1016/bs.host.2016.07.003,Book Series,Handbook of Statistics,scopus,2016-01-01,sciencedirect,Cognitive Systems for the Food–Water–Energy Nexus,https://api.elsevier.com/content/abstract/scopus_id/84994682733,"Providing for the food, water, and energy needs of a growing world population is a grand challenge. The way we choose to address this challenge as a society will have far-reaching impacts, for instance, on public health, national security, and the global climate. The interactions between the food, water, and energy systems offer us an opportunity to improve efficiency, but can also make the system more complex. Cognitive systems can help mitigate this complexity and thus improve efficiency.
                  What food, water, and energy have in common is that they are often not produced where they are consumed, they are costly to transport, and they are hard to store efficiently in large quantities. And this is where cognitive computing comes in: if you cannot store a resource you must have good forecasts of supply and demand. This requires handling large scale datasets from multiple sources, using machine learning methods to build forecasting models, and leveraging optimization techniques to help incorporate forecasting results into a decision-making process.
                  We will use energy as an example throughout the bulk of this chapter with the understanding that the same methods, challenges, and solutions can be applied more broadly to food, water, and other constrained resources.
                  
                     Sense: We will first discuss methods to make the most of sensor data. For example, it is expensive to deploy large networks of ground sensors (e.g., weather stations), and it is therefore beneficial to make use of sensors that can cover large areas, like radar or satellite images. However, it is challenging to estimate ground conditions based on satellite measurements alone. We will discuss machine learning algorithms that can learn the mapping from wide area sensor data to local conditions based on only a few ground-truth measurements. Applications include, for example, to estimate rainfall based on radar measurements, or to estimate solar power generation based on satellite images of clouds.
                  
                     Predict: Next, we will discuss forecasting methods ranging from a few minutes ahead to days or even years ahead. We will discuss forecasting methods for energy demand, solar energy generation, and wind generation. Different methods are effective for these different technologies as well as different forecasting horizons. Very short-range forecasts might use autoregressive models, while mid- to long-range forecasts may require physical models. We also discuss hybrid methods that combine expert knowledge with machine learning.
                  
                     React: Finally, we will discuss how to use the outputs of these analytics tools to serve decision-making processes. How optimization can help improve infrastructure planning and economic dispatch of power generation. And how cognitive systems can help system operators to make sense of messy data from multiple sources, provide recommended actions, and enable better decision making.
                  We will highlight several different mathematical methods, including autoregressive models, generalized additive models, fully connected neural networks, deep learning, convolutional neural networks, and nonlinear optimization in the context of energy. We will conclude the chapter with an outlook on how current trends in the cognitive computing will impact the broader challenge of managing constrained resources.",smart cities
10.1016/j.trpro.2016.05.240,Conference Proceeding,Transportation Research Procedia,scopus,2016-01-01,sciencedirect,Advanced Driver Assistance System for Road Environments to Improve Safety and Efficiency,https://api.elsevier.com/content/abstract/scopus_id/84991383337,"The advances in Information Technologies have led to more complex road safety applications. These systems provide multiple possibilities for improving road transport. The integrated system that this paper presents deals with two aspects that have been identified as key topics: safety and efficiency. To this end, the development and implementation of an integrated advanced driver assistance system (ADAS) for rural and intercity environments is proposed. The system focuses mainly on single-carriageways roads, given the complexity of these environments compared to motorways and the high number of severe and fatal accidents on them. The proposed system is based on advanced perception techniques, vehicle automation and communications between vehicles (V2V) and with the infrastructure (V2I). Sensor fusion architecture based on computer vision and laser scanner technologies are developed. It allows real time detection and classification of obstacles, and the identification of potential risks. The driver receives this information and some warnings generated by the system. In case, he does not react in a proper way, the vehicle could perform autonomous actions (both on speed control or steering maneuvers) to improve safety and/or efficiency. Furthermore, a multimodal V2V and V2I communication system, based on GeoNetworking, facilitates the flow of information between vehicles and assists in the detection and information broadcasting processes. All this, combined with vehicle positioning, detailed digital maps and advanced map-matching algorithms, establish the decision algorithms of different ADAS systems.
                  The applications developed include: adaptive cruise control with consumption optimization, overtaking assistance system in single-carriageways roads that takes into account appropriate speed evolution and identifies most suitable road stretches for the maneuver; assistance system in intersections with speed control during approximation maneuvers, and collision avoidance system with the possibility of evasive maneuvers. To this end, mathematical vehicle dynamics models have been used to ensure the stability, and propulsion system models are used to establish efficient patterns, Artificial Intelligence and simulation are used for experimentation and evaluation of algorithms to be implemented in the control unit. Finally, the system is designed to warn the driver if a risk is detected and, if necessary, to take control of the vehicle. The system has been implemented on a passenger car and has been tested in specific scenarios on a test track with satisfactory results.",smart cities
10.1016/j.procs.2016.04.205,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,Evaluating Hamming Distance as a CRC-based Side-channel Detection Measure in Wi-Fi Networks,https://api.elsevier.com/content/abstract/scopus_id/84971330231,"Wireless technology has become a main player in communication through its desirable mobility characteristic. However, like many technologies, there are ways that it can be exploited. One of these ways is through side-channel communication, whereby secret messages are passed along by the purposeful corruption of frames. These side channels can be established by intentionally corrupting the Frame Check Sequence (FCS) field by using a Cyclic Redundancy Check (CRC) polynomial that is different from the standard CRC polynomial. Malicious nodes can exploit the fact that normal unsuspecting nodes will drop these frames since they appear as naturally corrupted frames. This paper presents a CRC Hamming distance metric as a feature for the detection of this type of side-channel communication. We previously proposed the use of Hamming distance as a metric to compare CRC values that are generated by different CRC polynomials. The hypothesis is that the mean Hamming distance between two CRC values generated by two different CRC polynomials would be significantly far apart than the mean Hamming distance of a CRC value of a frame that was naturally corrupted but was generated by the same CRC polynomial. Previously, to test that hypothesis, we used F-Scores on real data experiments under varying noisy conditions and side-channel throughput to show that there is a consistent and significant difference between the mean Hamming values of naturally corrupted frames to those that use the Koopman polynomial to calculate the CRC for side-channel communications. In the present work we evaluate the Hamming distance using Perceptron Learning and the Pocket Algorithm to classify packets as side-channel or otherwise.",smart cities
10.1016/j.neucom.2015.06.086,Journal,Neurocomputing,scopus,2016-01-01,sciencedirect,Finding regions of interest using location based social media,https://api.elsevier.com/content/abstract/scopus_id/84947862746,"The discovery of regions of interest in city groups is increasingly important in recent years. In this light, we propose and investigate a novel problem called Region Discovery query (RD query) that finds regions of interest with respect to a user׳s current geographic location. Given a set of spatial objects O and a query location q, if a circular region ω is with high spatial-object density and is spatially close to q, it is returned by the query and is recommended to users. This type of query can bring significant benefit to users in many useful applications such as trip planning and region recommendation. The RD query faces a big challenge: how to prune the search space in the spatial and density domains. To overcome the challenge and process the RD query efficiently, we propose a novel collaboration search method and we define a pair of bounds to prune the search space effectively. The performance of the RD query is studied by extensive experiments on real and synthetic spatial data.",smart cities
10.1016/j.atherosclerosis.2015.10.102,Journal,Atherosclerosis,scopus,2016-01-01,sciencedirect,Apelin: A novel inhibitor of vascular calcification in chronic kidney disease,https://api.elsevier.com/content/abstract/scopus_id/84946569395,"Background
                  Vascular calcification (VC) is closely related to cardiovascular events in chronic kidney disease (CKD). Apelin has emerged as a potent regulator of cardiovascular function, but its role in VC during CKD remains unknown. We determined whether apelin plays a role in phosphate-induced mineralization of human aortic smooth muscle cells (HASMCs) and in adenine-induced CKD rats with aortic calcification.
               
                  Methods and results
                  In vitro, apelin-13 was found to inhibit calcium deposition in HASMCs (Pi+ Apelin+ group vs Pi+ Apelin− group: 50.1 ± 6.21 ug/mg vs 146.67 ± 10.02 ug/mg protein, p = 0.012) and to suppress the induction of the osteoblastic transformation genes BMP-2, osteoprotegerin (OPG) and Cbfa1. This effect was mediated by interference of the sodium-dependent phosphate cotransporter (Pit-1) expression and phosphate uptake. In vivo, decreased plasma apelin levels (adenine+ apelin− vs vehicle: 0.37 ± 0.09 ng/ml vs 0.68 ± 0.16 ng/ml, p = 0.003) and downregulation of APJ in the aorta were found in adenine-induced CKD rats with hyperphosphatemia (adenine+ apelin− vs vehicle: 6.91 ± 0.23 mmoL/L vs 2.3 ± 0.07 mmoL/L, p = 0.001) and aortic calcification. Exogenous supplementation of apelin-13 normalized the level of the apelin/APJ system and significantly ameliorated aortic calcification, as well as the suppression of Runx2, OPG and Pit-1 expression.
               
                  Conclusions
                  Apelin ameliorates VC by suppressing osteoblastic differentiation of VSMCs through downregulation of Pit-1. These results suggest apelin may have potential therapeutic value for treatment of VC in CKD.",smart cities
10.1016/j.ceca.2015.08.005,Journal,Cell Calcium,scopus,2015-12-01,sciencedirect,P11 modulates calcium handling through 5-HT<inf>4</inf>R pathway in rat ventricular cardiomyocytes,https://api.elsevier.com/content/abstract/scopus_id/84947866021,"Background
                  The role of the serotonin receptor 4 (5-HT4R) pathway in cardiac excitation-contraction coupling (ECC) remains unclear. In the brain, induction of the calcium (Ca2+)-binding protein p11 enhances 5-HT4R translocation and signaling and could therefore be considered as a modulator of the 5-HT4R pathway in the myocardium. p11 expression is increased by brain-derived neurotrophic factor (BDNF) or antidepressant drugs (imipramine). Thus, we investigated whether p11 regulates the 5-HT4R pathway in the heart in physiological conditions or under pharmacological induction and the effects on calcium handling.
               
                  Methods and results
                  p11 expression was induced in vivo in healthy Wistar rats by imipramine (10mg/kg/21 days) and in vitro in left ventricular cardiomyocytes exposed to BDNF (50ng/ml/8h). Cell shortening and real-time Ca2+ measurements were processed on field-stimulated intact cardiomyocytes with the selective 5-HT4R agonist, prucalopride (1μM). Both imipramine and BDNF-induced cardiomyocyte p11 expression unmasked a strong response to prucalopride characterized by an increase of both cell shortening and Ca2+ transient amplitude compared to basal prucalopride associated with a high propensity to trigger diastolic Ca2+ events. Healthy rats treated with BDNF (180 ng/day/14 days) exhibited a sustained elevated heart rate following a single injection of prucalopride (0.1mg/kg) which was not observed prior to treatment.
               
                  Conclusions
                  We have identified a novel role for p11 in 5-HT4R signaling in healthy rat ventricular cardiomyocytes. Increased p11 expression by BDNF and imipramine unraveled a 5-HT4R-mediated modulation of cardiac Ca2+ handling and ECC associated with deleterious Ca2+ flux disturbances. Such mechanism could partly explain some cardiac adverse effects induced by antidepressant treatments.",smart cities
10.1016/j.simpat.2015.05.011,Journal,Simulation Modelling Practice and Theory,scopus,2015-11-01,sciencedirect,A flexible framework for accurate simulation of cloud in-memory data stores,https://api.elsevier.com/content/abstract/scopus_id/84947019341,"In-memory (transactional) data stores, also referred to as data grids, are recognized as a first-class data management technology for cloud platforms, thanks to their ability to match the elasticity requirements imposed by the pay-as-you-go cost model. On the other hand, determining how performance and reliability/availability of these systems vary as a function of configuration parameters, such as the amount of cache servers to be deployed, and the degree of in-memory replication of slices of data, is far from being a trivial task. Yet, it is an essential aspect of the provisioning process of cloud platforms, given that it has an impact on the amount of cloud resources that are planned for usage. To cope with the issue of predicting/analysing the behavior of different configurations of cloud in-memory data stores, in this article we present a flexible simulation framework offering skeleton simulation models that can be easily specialized in order to capture the dynamics of diverse data grid systems, such as those related to the specific (distributed) protocol used to provide data consistency and/or transactional guarantees. Besides its flexibility, another peculiar aspect of the framework lies in that it integrates simulation and machine-learning (black-box) techniques, the latter being used to capture the dynamics of the data-exchange layer (e.g. the message passing layer) across the cache servers. This is a relevant aspect when considering that the actual data-transport/networking infrastructure on top of which the data grid is deployed might be unknown, hence being not feasible to be modeled via white-box (namely purely simulative) approaches. We also provide an extended experimental study aimed at validating instances of simulation models supported by our framework against execution dynamics of real data grid systems deployed on top of either private or public cloud infrastructures. Particularly, our validation test-bed has been based on an industrial-grade open-source data grid, namely Infinispan by JBoss/Red-Hat, and a de-facto standard benchmark for NoSQL platforms, namely YCSB by Yahoo. The validation study has been conducted by relying on both public and private cloud systems, scaling the underlying infrastructure up to 100 (resp. 140) Virtual Machines for the public (resp. private) cloud case. Further, we provide some experimental data related to a scenario where our framework is used for on-line capacity planning and reconfiguration of the data grid system.",smart cities
10.1016/j.apor.2015.09.010,Journal,Applied Ocean Research,scopus,2015-10-01,sciencedirect,Neural adaptive robust control of underactuated marine surface vehicles with input saturation,https://api.elsevier.com/content/abstract/scopus_id/84945290024,"This paper proposes a saturated tracking controller for underactuated autonomous marine surface vehicles with limited torque. First, a second-order open-loop error dynamic model is developed in the actuated degrees of freedom to simplify the design procedure. Then, a saturated tracking controller is designed by utilizing generalized saturation functions to reduce the risk of actuator saturation. This, in turn, improves the transient performance of the control system. A multi-layer neural network and adaptive robust control techniques are also employed to preserve the controller robustness against unmodeled dynamics and environmental disturbances induced by waves and ocean currents. A Lyapunov stability analysis shows that all signals of the closed-loop system are bounded and tracking errors are semi-globally uniformly ultimately bounded. Finally, simulation results are provided for a hovercraft vehicle to illustrate the effectiveness of the proposed controller as a qualified candidate for real implementations in offshore applications.",smart cities
10.1016/j.joca.2015.04.026,Journal,Osteoarthritis and Cartilage,scopus,2015-09-01,sciencedirect,Characterization of diabetic osteoarthritic cartilage and role of high glucose environment on chondrocyte activation: Toward pathophysiological delineation of diabetes mellitus-related osteoarthritis,https://api.elsevier.com/content/abstract/scopus_id/84940452582,"Objective
                  To examine the relationship between osteoarthritis (OA) and type 2 diabetes mellitus (DM).
               
                  Methods
                  OA cartilage from DM and non-DM patients undergoing knee replacement were stimulated by IL-1β for 24 h and release of interleukin-6 (IL-6) and prostaglandin E2 (PGE2) was measured. Primary cultured murine chondrocytes were stimulated for 24 and 72 h with or without IL-1β (5 ng/mL) under normal-glucose (5.5 mM) or high-glucose (25 mM) conditions. The expression and release of pro-inflammatory mediators (IL-6, cyclooxygenase 2 [COX2]/PGE2) were analyzed by quantitative RT-PCR and ELISA/EIA. Glucose uptake was assessed with (14C)-2-deoxyglucose. Reactive oxygen species (ROS) and nitric oxide (NO) production were measured. To analyze the mechanism of IL-1β-induced inflammation, cells were pretreated or treated with inhibitors of glucose transport (cytochalasin B), the polyol pathway (epalrestat), mitochondrial oxidative stress (MitoTEMPO) or nitric oxide synthase (l-NAME).
               
                  Results
                  With IL-1β stimulation, IL-6 and PGE2 release was greater in human DM than non-DM OA cartilage (2.7- and 3-fold, respectively) (P < 0.05). In vitro, with IL-1β stimulation, IL-6 and COX2 mRNA expression, IL-6 and PGE2 release, and ROS and NO production were greater under high-than normal-glucose conditions in cultured chondrocytes. IL-1β–increased IL-6 release was reduced with cytochalasin B, epalrestat, l-NAME or MitoTEMPO treatment (−45%, −62%, −38% and −40%, respectively).
               
                  Conclusion
                  OA cartilages from DM patients showed increased responsiveness to IL-1β–induced inflammation. Accordingly, high glucose enhanced IL-1β–induced inflammation in cultured chondrocytes via oxidative stress and the polyol pathway. High glucose and diabetes may thus participate in the increased inflammation in OA.",smart cities
10.1016/j.jenvman.2015.06.003,Journal,Journal of Environmental Management,scopus,2015-09-01,sciencedirect,Developing the remote sensing-based early warning system for monitoring TSS concentrations in Lake Mead,https://api.elsevier.com/content/abstract/scopus_id/84934926165,"Adjustment of the water treatment process to changes in water quality is a focus area for engineers and managers of water treatment plants. The desired and preferred capability depends on timely and quantitative knowledge of water quality monitoring in terms of total suspended solids (TSS) concentrations. This paper presents the development of a suite of nowcasting and forecasting methods by using high-resolution remote-sensing-based monitoring techniques on a daily basis. First, the integrated data fusion and mining (IDFM) technique was applied to develop a near real-time monitoring system for daily nowcasting of the TSS concentrations. Then a nonlinear autoregressive neural network with external input (NARXNET) model was selected and applied for forecasting analysis of the changes in TSS concentrations over time on a rolling basis onward using the IDFM technique. The implementation of such an integrated forecasting and nowcasting approach was assessed by a case study at Lake Mead hosting the water intake for Las Vegas, Nevada, in the water-stressed western U.S. Long-term monthly averaged results showed no simultaneous impact from forest fire events on accelerating the rise of TSS concentration. However, the results showed a probable impact of a decade of drought on increasing TSS concentration in the Colorado River Arm and Overton Arm. Results of the forecasting model highlight the reservoir water level as a significant parameter in predicting TSS in Lake Mead. In addition, the R-squared value of 0.98 and the root mean square error of 0.5 between the observed and predicted TSS values demonstrates the reliability and application potential of this remote sensing-based early warning system in terms of TSS projections at a drinking water intake.",smart cities
10.1016/j.dss.2015.08.001,Journal,Decision Support Systems,scopus,2015-08-24,sciencedirect,A decision support system tool for the transportation by barge of import containers: A case study,https://api.elsevier.com/content/abstract/scopus_id/84939799098,"In this paper, we present a DSS that generates schedules for the transportation of containers by barge in the hinterland, in particular from sea terminals to an inland terminal. As a case study, we propose the transportation from the ports of Rotterdam and Antwerp to a terminal in the south of the Netherlands, where the problem is typical. This problem is modeled as a heterogeneous fleet vehicle routing problem. The main decision is based on the trade-off of either consolidating containers to generate economies of scale with barges or alternatively dispatch, expensively and quickly, single containers by truck. The DSS is flexible as it can be applied to different settings by properly tuning the several parameters in the model. With numerical experiments, based on real world data, we evaluate the effectiveness of this system and its applicability.",smart cities
10.1016/j.jweia.2015.02.004,Journal,Journal of Wind Engineering and Industrial Aerodynamics,scopus,2015-06-01,sciencedirect,An EMD-recursive ARIMA method to predict wind speed for railway strong wind warning system,https://api.elsevier.com/content/abstract/scopus_id/84925012310,"To protect running trains against the strong crosswind along Chinese Qinghai–Tibet railway, a strong wind warning system is developed. As one of the most important technologies of the developed system, a new short-term wind speed forecasting method is proposed by adopting the Empirical Mode Decomposition (EMD) and the improved Recursive Autoregressive Integrated Moving Average (RARIMA) model. The proposed forecasting method consists of three computational steps as: (a) use the EMD method to decompose the original wind speed data into a group of wind speed sub-layers; (b) build the forecasting models for all the decomposed sub-layers by utilizing the RARIMA algorithm; (c) employ the built RARIMA models to predict the wind speed in the sub-layers; and (d) summarize the predicted results of the wind speed sub-layers to get the final forecasting results for the original wind speed. Since the wind speed forecasting method is proposed for the real-time warning system, the forecasting accuracy and the time performance of the forecasting computation are both considered. Two experiments show that: (a) the proposed method has better forecasting performance than the traditional Autoregressive Integrated Moving Average (ARIMA) model, the Persistent Random Walk Model (PRWM) and the Back Propagation (BP) neural networks; and (b) the proposed method has satisfactory performance in both of the accuracy and the time performance.",smart cities
10.1016/j.bios.2014.09.037,Journal,Biosensors and Bioelectronics,scopus,2015-05-05,sciencedirect,An impedance immunosensor based on low-cost microelectrodes and specific monoclonal antibodies for rapid detection of avian influenza virus H5N1 in chicken swabs,https://api.elsevier.com/content/abstract/scopus_id/84922453296,"Early screening of suspected cases is the key to control the spread of avian influenza (AI) H5N1. In our previous studies, an impedance biosensor with an interdigitated array microelectrode based biochip was developed and validated with pure AI H5 virus, but had limitations in cost and reliability of the biochip, specificity of the antibody against Asian in-field H5N1 virus and detection of H5N1 virus in real samples. The purpose of this study is to develop a low-cost impedance immunosensor for rapid detection of Asian in-field AI H5N1 virus in chicken swabs within 1h and validate it with the H5N1 virus. Specific monoclonal antibodies against AI H5N1 virus were developed by fusion of mouse myeloma cells with spleen cells isolated from an H5N1-virus-immunized mouse. Dot-ELISA analysis demonstrated that the developed antibodies had good affinity and specificity with the H5N1 virus. The microelectrodes were redesigned with compact size, fabricated using an improved wet-etching micro-fabrication process with a higher qualified production rate of 70–80%, and modified with the antibodies by the Protein A method. Equivalent circuit analysis indicated that electron transfer resistor was effective with the increase in impedance after capturing of the H5N1 viruses. Linear relationship between impedance change and logarithmic value of H5N1 virus at the concentrations from 2−1 to 24 HAU/50μl was found and the lower limit of detection was 2−1 HAU/50μl. No obvious interferences from non-target viruses such as H6N2, H9N2, Newcastle disease virus, and infectious bronchitis virus were found. Chicken swab tests showed that the impedance immunosensor had a comparable accuracy with real-time RT-PCR compared to viral isolation.",smart cities
10.1016/j.ifacol.2015.06.162,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-05-01,sciencedirect,Supporting urban home health care in daily business and times of disasters,https://api.elsevier.com/content/abstract/scopus_id/84953882203,"Home health care (HHC) services are of vital importance for today's society. They allow old and frail people a self-determined living in their familiar environment. Due to the current demographic and social developments further increases in demand for HHC must be expected. Additionally, people with limited mobility or relying on medical supply usually need consistent care. Thus, HHC service providers will be faced with two challenges: an increased organizational effort due to the rising demand and the need for an anticipatory risk management. Previous research combining optimization and risk management in the field of HHC limits itself to rural regions, where nurses are solely using cars. The presented work specifically aims to deal with the peculiarities of urban regions. Together with the Austrian Red Cross (ARC), a vulnerability analysis has been conducted in order to identify the critical success factors and processes of HHC as well as potential threats. To support the daily scheduling, a Tabu Search (TS) based metaheuristic has been implemented. As nurses can choose between different transport modes (public transport, car, bike, and walking), time-dependent multimodal transport has been considered. The TS has been tested with real-world data from the ARC in Vienna to support both, daily business and scheduling in times of disasters. Significant reductions of travel and waiting times can be obtained, such that more time remains for serving the clients. Through sensitivity analysis the effects of disasters (esp. blackout, pandemics, and heat waves) are visualized and the operational limits during such events are shown.",smart cities
10.1016/j.lfs.2015.01.033,Journal,Life Sciences,scopus,2015-05-01,sciencedirect,Acute effects of oral olanzapine treatment on the expression of fatty acid and cholesterol metabolism-related gene in rats,https://api.elsevier.com/content/abstract/scopus_id/84925855714,"Aims
                  Second-generation antipsychotic drugs (SGAs) have a high risk for serious metabolic side-effects including dyslipidemia. This study aimed to investigate the acute effects of oral olanzapine treatment on the expression of genes for fatty acid and cholesterol biosynthesis in rats.
               
                  Main methods
                  Female Sprague–Dawley rats were treated orally with olanzapine (1mg/kg, equivalent to a human clinical dose of 10mg) via self-administration aimed to measure pharmacokinetics. Based on the pharmacokinetic analysis, the acute effects of olanzapine on sterol regulatory element binding protein (SREBP)-related fatty acid/cholesterol metabolism genes were investigated in the liver and perirenal white adipose tissue (WAT) by Real-time quantitative PCR.
               
                  Key findings
                  A pharmacokinetic analysis demonstrated that the maximum concentration of olanzapine in plasma (Cmax) occurred at 6h with a peak concentration of 276.5ng/ml after a single oral treatment and with a plasma elimination half-life of 3.5h after peak. The mRNA expression of SREBP-2 and target genes for cholesterol synthesis and transport was increased 1.9 8.8 fold compared with the control at 6h after olanzapine administration but returned to basal level at 12h post-treatment, while the increased mRNA expression of SREBP-1c and its targeted fatty acid-related genes appeared at both 6h and 12h post-treatment.
               
                  Significance
                  The present study provided evidence that olanzapine at a clinically-relevant dose caused abnormal expression of genes involved in lipid metabolism in the liver and WAT. These results suggest that olanzapine may cause dyslipidemia side-effects through direct effects on lipid biosynthesis and efflux genes associated with SREBP-stimulated transcriptional changes.",smart cities
10.1016/j.jss.2014.11.031,Journal,Journal of Surgical Research,scopus,2015-04-01,sciencedirect,Ketamine reduces lipopolysaccharide-induced high-mobility group box-1 through heme oxygenase-1 and nuclear factor erythroid 2-related factor 2/ p38 mitogen-activated protein kinase,https://api.elsevier.com/content/abstract/scopus_id/84924870731,"This article has been retracted: please see Elsevier Policy on Article Withdrawal (http://www.elsevier.com/locate/withdrawalpolicy).
                  This article has been retracted by the Editor-in-Chief because several results reported in the manuscript were plagiarized from the following article published in 2014 by Zhang et al.:
                  Zhang Z, Zhang L, Zhou C, Wu H. Ketamine inhibits LPS-induced HGMB1 release in vitro and in vivo. Int Immunopharmacol 2014;23:14–26.
                  The editor was contacted by the editor of International Immunopharmacology, who had been alerted regarding the presence of duplicate figures in the two articles. Examination of the articles confirmed that data in Figures 1, 2, and 11 in the paper by Wang et al. appeared to have been plagiarized from the paper by Zhang et al. The corresponding author of the paper by Wang et al. was not able to provide a satisfactory explanation or the original related data to refute the allegation.",smart cities
10.1016/j.compenvurbsys.2014.11.005,Journal,"Computers, Environment and Urban Systems",scopus,2015-03-01,sciencedirect,A location aware system for integrated management of Rhynchophorus ferrugineus in urban systems,https://api.elsevier.com/content/abstract/scopus_id/84949118217,"The red palm weevil (RPW), Rhynchophorus ferrugineus (Coleoptera: Curculionidae), an invasive species for many countries, is one of the most dangerous pests of ornamental palms in urban landscapes. When infested by the RPW, all untreated palms typically die. RPW monitoring is difficult, and when the pest is detected, management to save the infested palm becomes intricate. For this reason, an efficient and integrated RPW monitoring, such as a location-aware system (LAS), combined with the scientific knowledge of experts on the palm’s physiology and the RPW biological cycle must be designed, developed and implemented. In the current study, an innovative integrated RPW management in urban landscapes under real conditions is presented. Based on the LAS, this study investigates the effectiveness of monitoring RPW infestations in palms, such as the Phoenix canariensis, under field conditions at the Pedion Areos park, which is located in central Athens, the capital of the Hellenic Republic. The goal of this study is to address the specific needs of RPW management and control by facilitating the treatment process adopted by experts combined with an appropriate spatial decision support system (SDSS), which accounts for the RPW population dynamics and spatio-temporal characteristics of the infested areas. The process of estimating the infestation risk is based on a ten-point scale classification, which is incorporated into the LAS. The results from the aforementioned moderate-scaled field experiment conducted for evaluation purposes showed that the LAS is an innovative, simple, and easy to use integrated platform that can be used for early detection, rapid monitoring and assessment of RPW in urban landscapes. Finally, the results from this four-year experiment showed that the diameter and height of the trunk of canary palms play a significant role in the susceptibility to RPW infestations and the recovery of infested canary palms; the results also demonstrated that control of RPW in urban landscapes is possible.",smart cities
10.1016/j.burns.2014.05.008,Journal,Burns,scopus,2015-03-01,sciencedirect,Anti-inflammative effect of glycyrrhizin on rat thermal injury via inhibition of high-mobility group box 1 protein,https://api.elsevier.com/content/abstract/scopus_id/84923029635,"Aim
                  Glycyrrhizin (Gly) has been reported as an inhibitor of extracellular HMGB1 (high-mobility group box 1 protein) cytokine's activity, and protects spinal cord, liver, heart and brain against ischemia-reperfusion-induced injury in rats. The purpose of this study was to investigate the protective effect of Gly in rat skin thermal injury model and to elucidate the underlying mechanisms.
               
                  Methods
                  Twenty-four male Sprague-Dawley rats (200–250g) were randomly divided into control group, vehicle-treated and Gly-treated burn groups, each group contained eight animals. In the latter two groups, rats were subjected to 30% TBSA (Total Body Surface Area) full-thickness scald injury. In Gly-treated burn group, glycyrrhizin (60mg/kg) was administered intraperitoneally immediately after and at 24th hour burn; in vehicle-treated burn group, Ringer's solution (4ml/kg, as a vehicle) was administered intraperitoneally immediately after and at 24th hour burn. The animals were sacrificed at 48h after injury. Aortic blood samples were obtained to detect tumor necrosis factor-α (TNF-α) and interleukin-1β (IL-1β) with ELISA (Enzyme-Linked Immuno Sorbent Assay) kits. Lung, liver and kidney tissue samples were collected to determine the expression of HMGB1 mRNA and protein. HMGB1 mRNA level was semiquantitatively measured by Real-Time PCR using β-actin as an internal standard, and protein expression of HMGBI was determined by Western blot.
               
                  Results
                  Severe skin scald injury caused a significant increase in plasma TNF-α and IL-1β versus the control group (P
                     <0.001) in 48h after burns. Intraperitoneal administration of Gly (60mg/kg) significantly reduced the levels of serum TNF-α and IL-1β (P
                     <0.01). Gly treatment reduced these biochemical indices accompanied by lower level of HMGB1 protein (P
                     <0.05) and mRNA expression (P
                     <0.01).
               
                  Conclusion
                  These results demonstrate that Gly possesses an anti-inflammation effect to protect the remote organs from burn-induced injury.",smart cities
10.1016/j.molimm.2014.11.008,Journal,Molecular Immunology,scopus,2015-03-01,sciencedirect,IGF-1 attenuates LPS induced pro-inflammatory cytokines expression in buffalo (Bubalus bubalis) granulosa cells,https://api.elsevier.com/content/abstract/scopus_id/84920101010,"Interaction between immune and endocrine system is a diverse process influencing cellular function and homeostasis in animals. Negative energy balance (NEB) during postpartum period in dairy animals usually suppresses these systems resulting in reproductive tract infection and infertility. These negative effects could be due to competition among endocrine and immune signaling pathways for common signaling molecules. The present work studied the effect of IGF-1 (50ng/ml) on LPS (1μg/ml) mediated pro-inflammatory cytokine expression (IL-1β, TNF-α, IL-6) and aromatase (CYP19A1) genes’ expressions as well as proliferation of buffalo granulosa cells. The crosstalk between LPS and IGF-1 was also demonstrated through studying the activities of downstream signaling molecules (ERK1/2, Akt, NF-κB) by western blot and immunostaining. Gene expression analysis showed that IGF-1 significantly reduced the LPS induced expression of IL-1β, TNF-α and IL-6. LPS alone inhibited the CYP19A1 expression. However, co-treatment with IGF-1 reversed the inhibitory effect of LPS on CYP19A1 expression. LPS alone did not affect granulosa cell proliferation, but co-treatment with IGF-1, and IGF-1 alone enhanced the proliferation. Western blot results demonstrated that LPS caused the nuclear translocation of the NF-κB and increased the phosphorylation of ERK1/2 and Akt maximum at 15min and 60min, respectively. Nonetheless, co-treatment with IGF-1 delayed LPS induced phosphorylation of ERK1/2 (peak at 120min), while promoting early Akt phosphorylation (peak at 5min) with no effect on NF-κB translocation. Overall, IGF-1 delayed and reversed the effects of LPS, suggesting that high IGF-1 levels may combat infection during critical periods like NEB in postpartum dairy animals.",smart cities
10.1016/j.neuron.2014.12.049,Journal,Neuron,scopus,2015-02-04,sciencedirect,Neural mechanisms of incentive salience in naturalistic human vision,https://api.elsevier.com/content/abstract/scopus_id/84922021697,"What role does reward play in real-world human vision? Reward coding in the midbrain is thought to cause the rapid prioritization of reward-associated visual stimuli. However, existing evidence for this incentive salience hypothesis in vision is equivocal, particularly in naturalistic circumstances, and little is known about underlying neural systems. Here we use human fMRI to test whether reward primes perceptual encoding of naturalistic visual stimuli and to identify the neural mechanisms underlying this function. Participants detected a cued object category in briefly presented images of city- and landscapes. Using multivoxel pattern analysis in visual cortex, we found that the encoding of reward-associated targets was enhanced, whereas encoding of reward-associated distractors was suppressed, with the strength of this effect predicted by activity in the dopaminergic midbrain and a connected cortical network. These results identify a novel interaction between neural systems responsible for reward processing and visual perception in the human brain.",smart cities
10.1016/j.scitotenv.2014.08.060,Journal,Science of the Total Environment,scopus,2015-02-01,sciencedirect,A general procedure to generate models for urban environmental-noise pollution using feature selection and machine learning methods,https://api.elsevier.com/content/abstract/scopus_id/84908609089,"The prediction of environmental noise in urban environments requires the solution of a complex and non-linear problem, since there are complex relationships among the multitude of variables involved in the characterization and modelling of environmental noise and environmental-noise magnitudes. Moreover, the inclusion of the great spatial heterogeneity characteristic of urban environments seems to be essential in order to achieve an accurate environmental-noise prediction in cities. This problem is addressed in this paper, where a procedure based on feature-selection techniques and machine-learning regression methods is proposed and applied to this environmental problem. Three machine-learning regression methods, which are considered very robust in solving non-linear problems, are used to estimate the energy-equivalent sound-pressure level descriptor (LAeq). These three methods are: (i) multilayer perceptron (MLP), (ii) sequential minimal optimisation (SMO), and (iii) Gaussian processes for regression (GPR). In addition, because of the high number of input variables involved in environmental-noise modelling and estimation in urban environments, which make LAeq prediction models quite complex and costly in terms of time and resources for application to real situations, three different techniques are used to approach feature selection or data reduction. The feature-selection techniques used are: (i) correlation-based feature-subset selection (CFS), (ii) wrapper for feature-subset selection (WFS), and the data reduction technique is principal-component analysis (PCA). The subsequent analysis leads to a proposal of different schemes, depending on the needs regarding data collection and accuracy. The use of WFS as the feature-selection technique with the implementation of SMO or GPR as regression algorithm provides the best LAeq estimation (R2
                     =0.94 and mean absolute error (MAE)=1.14–1.16dB(A)).",smart cities
10.1016/S2046-0430(16)30168-X,Journal,International Journal of Transportation Science and Technology,scopus,2015-01-01,sciencedirect,Dynamic Travel Time Prediction Models for Buses Using Only GPS Data,https://api.elsevier.com/content/abstract/scopus_id/85039937386,"Providing real-time and accurate travel time information of transit vehicles can be very helpful as it assists passengers in planning their trips to minimize waiting times. The purpose of this research is to develop and compare dynamic travel time prediction models which can provide accurate prediction of bus travel time in order to give real-time information at a given downstream bus stop using only global positioning system (GPS) data. Historical Average (HA), Kalman Filtering (KF) and Artificial Neural Network (ANN) models are considered and developed in this paper. A case has been studied by making use of the three models. Promising results are obtained from the case study, indicating that the models can be used to implement an Advanced Public Transport System. The implementation of this system could assist transit operators in improving the reliability of bus services, thus attracting more travelers to transit vehicles and helping relieve congestion. The performances of the three models were assessed and compared with each other under two criteria: overall prediction accuracy and robustness. It was shown that the ANN outperformed the other two models in both aspects. In conclusion, it is shown that bus travel time information can be reasonably provided using only arrival and departure time information at stops even in the absence of traffic-stream data.",smart cities
10.1016/j.freeradbiomed.2015.05.004,Journal,Free Radical Biology and Medicine,scopus,2015-01-01,sciencedirect,Lung endothelial barrier protection by resveratrol involves inhibition of HMGB1 release and HMGB1-induced mitochondrial oxidative damage via an Nrf2-dependent mechanism,https://api.elsevier.com/content/abstract/scopus_id/84969835759,"High-mobility group box 1 (HMGB1) contributes to lung vascular hyperpermeability during ventilator-induced lung injury. We aimed to determine whether the natural antioxidant resveratrol protected against HMGB1-induced endothelial hyperpermeability both in vitro and in vivo. We found that HMGB1 decreased vascular endothelial (VE)-cadherin expression and increased endothelial permeability, leading to mitochondrial oxidative damage in primary cultured mouse lung vascular endothelial cells (MLVECs). Both the mitochondrial superoxide dismutase 2 mimetic MnTBAP and resveratrol blocked HMGB1-induced mitochondrial oxidative damage, VE-cadherin downregulation, and endothelial hyperpermeability. In in vivo studies, anesthetized male ICR mice were ventilated for 4h using low tidal volume (6ml/kg) or high tidal volume (HVT; 30ml/kg) ventilation. The mice were injected intraperitoneally with resveratrol immediately before the onset of ventilation. We found that resveratrol attenuated HVT-associated lung vascular hyperpermeability and HMGB1 production. HVT caused a significant increase in nuclear factor-erythroid 2-related factor 2 (Nrf2) nuclear translocation and Nrf2 target gene expression in lung tissues, which was further enhanced by resveratrol treatment. HMGB1 had no effect on Nrf2 activation, whereas resveratrol treatment activated the Nrf2 signaling pathway in HMGB1-treated MLVECs. Moreover, Nrf2 knockdown reversed the inhibitory effects of resveratrol on HMGB1-induced mitochondrial oxidative damage and endothelial hyperpermeability. The inhibitory effect of resveratrol on cyclic stretch-induced HMGB1 mRNA expression in primary cultured MLVECs was also abolished by Nrf2 knockdown. In summary, this study demonstrates that resveratrol protects against lung endothelial barrier dysfunction initiated by HVT. Lung endothelial barrier protection by resveratrol involves inhibition of mechanical stretch-induced HMGB1 release and HMGB1-induced mitochondrial oxidative damage. These protective effects of resveratrol might be mediated through an Nrf2-dependent mechanism.",smart cities
10.1016/j.procs.2015.09.269,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Virtual Sign - A Real Time Bidirectional Translator of Portuguese Sign Language,https://api.elsevier.com/content/abstract/scopus_id/84962793739,"Promoting equity, equal opportunities to all and social inclusion of people with disabilities is a concern of modern societies at large and a key topic in the agenda of European Higher Education. Despite all the progress, we cannot ignore the fact that the conditions provided by the society for the deaf are still far from being perfect. The communication with deaf by means of written text is not as efficient as it might seem at first. In fact, there is a very deep gap between sign language and spoken/written language. The vocabulary, the sentence construction and the grammatical rules are quite different among these two worlds. These facts bring significant difficulties in reading and understanding the meaning of text for deaf people and, on the other hand, make it quite difficult for people with no hearing disabilities to understand sign language. The deployment of tools to assist the daily communication, in schools, in public services, in museums and other, between deaf people and the rest may be a significant contribution to the social inclusion of the deaf community. The work described in this paper addresses the development of a bidirectional translator between Portuguese Sign Language and Portuguese text. The translator from sign language to text resorts to two devices, namely the Microsoft Kinect and 5DT Sensor Gloves in order to gather data about the motion and shape of the hands. The hands configurations are classified using Support Vector Machines. The classification of the movement and orientation of the hands are achieved through the use of Dynamic Time Warping algorithm. The translator exhibits a precision higher than 90%. In the other direction, the translation of Portuguese text to Portuguese Sign Language is supported by a 3D avatar which interprets the entered text and performs the corresponding animations.",smart cities
10.1016/j.proeng.2015.08.462,Conference Proceeding,Procedia Engineering,scopus,2015-01-01,sciencedirect,Semi-supervised Energy Modeling (SSEM) for Building Clusters Using Machine Learning Techniques,https://api.elsevier.com/content/abstract/scopus_id/84948394248,"There are many data mining and machine learning techniques to manage large sets of complex energy supply and demand data for building, organization and city. As the amount of data continues to grow, new data analysis methods are needed to address the increasing complexity. Using data from the energy loss between the supply (energy production sources) and demand (buildings and cities consumption), this paper proposes a Semi-Supervised Energy Model (SSEM) to analyse different loss factors for a building cluster. This is done by deep machine learning by training machines to semi-supervise the learning, understanding and manage the process of energy losses. Semi-Supervised Energy Model (SSEM) aims at understanding the demand-supply characteristics of a building cluster and utilizes the confident unlabelled data (loss factors) using deep machine learning techniques. The research findings involves sample data from one of the university campuses and presents the output, which provides an estimate of losses that can be reduced. The paper also provides a list of loss factors that contributes to the total losses and suggests a threshold value for each loss factor, which is determined through real time experiments. The conclusion of this paper provides a proposed energy model that can provide accurate numbers on energy demand, which in turn helps the suppliers to adopt such a model to optimize their supply strategies.",smart cities
10.1016/j.procs.2015.07.309,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,WWN-8: Incremental online stereo with shape-from-X using life-long big data from multiple modalities,https://api.elsevier.com/content/abstract/scopus_id/84939200801,"When a child lives in the real world, from infancy to adulthood, his retinae receive a flood of stereo sensory stream. His muscles produce another action stream. How does the child's brain deal with such big data from multiple sensory modalities (left- and right-eye modalities) and multiple effector modalities (location, disparity map, and shape type)? This capability incrementally learns to produce simple-to-complex sensorimotor behaviors — autonomous development. We present a model that incrementally fuses such an open-ended life-long stream and updates the “brain” online so the perceived world is 3D. Traditional methods for shape- from-X use a particular type of cue X (e.g., stereo disparity, shading, etc.) to compute depths or local shapes based on a handcrafted physical model. Such a model likely results in a brit- tle system because of the fluctuation of the availability of the cue. An embodiment of the Developmental Network (DN), called Stereo Where-What Network (WWN-8), learns to per- form simultaneous attention and recognition, while developing invariances in location, disparity, shape, and surface type, so that multiple cues can automatically fill in if a particular type of cue (e.g., texture) is missing locally from the real world. We report some experiments: 1) dynamic synapse retraction and growth as a method of developing receptive fields. 2) training for recognizing 3D objects directly in cluttered natural backgrounds. 3) integration of depth perception with location and type information. The experiments used stereo images and motor actions on the order of 105 frames. Potential applications include driver assistance for road safety, mobile robots, autonomous navigation, and autonomous vision-guided manipulators.",smart cities
10.1016/j.procs.2015.07.320,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Approaching camera-based real-world navigation using object recognition,https://api.elsevier.com/content/abstract/scopus_id/84939191124,"Traditional autonomous navigation systems for transportation use laser range scanners to con- struct 3D driving scenes in terms of open and occupied voxels. Active laser range scanners suffer from a series of failures, such as inability to detect wet road surfaces, dark surfaces and objects at large distances. In contrast, passive video cameras are immune from these failures but processing is challenging. High dimensionality of the input image requires efficient Big Data analytic methods for the system to perform in real-time. In this paper we argue that object recognition is essential for a navigation system to generalize learned landmarks to new driving scenes, which is a requirement for practical driving. To overcome this difficulty we present an online learning neural network for indoor navigation using only stereo cameras. The network can learn a Finite Automaton (FA) for the driving problem. Transition of the FA depends on several information sources: sensory input (stereo camera images) and motor input (i.e. object, action, GPS, and attention). Our agent simulates the transition of the FA by developing internal representation using the Developmental Network (DN) without handcrafting states or transi- tion rules. Although the proposed network is meant for both indoor and outdoor navigation, it has been only tested in indoor environments in current work. Our experiments demonstrate the agent learned to recognize landmarks and the corresponding actions (e.g. follow the GPS input, correct current direction, and avoid obstacles). Our future work includes training and learning in outdoor driving scenarios.",smart cities
10.1016/j.procs.2015.07.305,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Building efficient probability transition matrix using machine learning from big data for personalized route prediction,https://api.elsevier.com/content/abstract/scopus_id/84939178951,"Personalized route prediction is an important technology in many applications related to intelligent vehicles and transportation systems. Current route prediction technologies used in many general navigation systems are, by and large, based on either the shortest or the fastest route selection. Personal traveling route prediction is a very challenging big data problem, as trips getting longer and variations in routes growing. It is particularly challenging for real-time in-vehicle applications, since many embedded processors have limited memory and computational power. In this paper we present a machine learning algorithm for modeling route prediction based on a Markov chain model, and a route prediction algorithm based on a probability transition matrix. We also present two data reduction algorithms, one is developed to map large GPS based trips to a compact link-based standard route representation, and another a machine learning algorithm to significantly reduce the size of a probability transition matrix. The proposed algorithms are evaluated on real-world driving trip data collected in four months, where the data collected in the first three months are used as training and the data in the fourth month are used as testing. Our experiment results show that the proposed personal route prediction system generated more than 91% prediction accuracy in average among the test trips. The data reduction algorithm gave about 8:1 reduction in link-based standard route representation and 23:1 in reducing the size of probability transition matrix.",smart cities
10.1016/j.procs.2015.05.404,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Combining data-driven methods with finite element analysis for flood early warning systems,https://api.elsevier.com/content/abstract/scopus_id/84939129775,"We developed a robust approach for real-time levee condition monitoring based on combination of data-driven methods (one-side classification) and finite element analysis. It was implemented within a flood early warning system and validated on a series of full-scale levee failure experiments organised by the IJkdijk consortium in August-September 2012 in the Netherlands. Our approach has detected anomalies and predicted levee failures several days before the actual collapse. This approach was used in the UrbanFlood decision support system for routine levee quality assessment and for critical situations of a potential levee breach and inundation. In case of emergency, the system generates an alarm, warns dike managers and city authorities, and launches advanced urgent simulations of levee stability and flood dynamics, thus helping to make informed decisions on preventive measures, to evaluate the risks and to alleviate adverse effects of a flood.",smart cities
10.1002/jps.24409,Journal,Journal of Pharmaceutical Sciences,scopus,2015-01-01,sciencedirect,A novel microwave sensor for real-time online monitoring of roll compacts of pharmaceutical powders online - A comparative case study with NIR,https://api.elsevier.com/content/abstract/scopus_id/84926368685,"Control of particulate processes is hard to achieve because of the ease with which powders tend to segregate. Thus, proper sensing methods must be employed to ensure content uniformity during operation. The role of sensing schemes becomes even more critical while operating the process continuously as measurements are essential for implementation of feedback control (Austin et al. 2013. J Pharm Sci 102(6):1895-1904; Austin et al. 2014. Anal Chim Acta 819:82-93). A microwave sensor was developed and shown to be effective in online measurement of active pharmaceutical ingredient (API) concentration in a powder blend. During powder transport and hopper storage before processing, powder blends may segregate and cause quality deviations in the subsequent tableting operation. Therefore, it is critical to know the API concentration in the ribbons as the content uniformity is fixed once the ribbon is processed. In this study, a novel microwave sensor was developed that could provide measurement of a roller compacted ribbon's API concentration online, along with its density and moisture content. The results indicate that this microwave sensor is capable of increased accuracy compared with a commercially available near-IR probe for the determination of content uniformity and density in roller compacted ribbons online.",smart cities
10.1016/j.neuron.2014.10.035,Journal,Neuron,scopus,2014-12-03,sciencedirect,The habenulo-raphe serotonergic circuit encodes an aversive expectation value essential for adaptive active avoidance of danger,https://api.elsevier.com/content/abstract/scopus_id/84919424931,"Anticipation of danger at first elicits panic in animals, but later it helps them to avoid the real threat adaptively. In zebrafish, as fish experience more and more danger, neurons in the ventral habenula (vHb) showed tonic increase in the activity to the presented cue and activated serotonergic neurons in the median raphe (MR). This neuronal activity could represent the expectation of a dangerous outcome and be used for comparison with a real outcome when the fish is learning how to escape from a dangerous to a safer environment. Indeed, inhibiting synaptic transmission from vHb to MR impaired adaptive avoidance learning, while panic behavior induced by classical fear conditioning remained intact. Furthermore, artificially triggering this negative outcome expectation signal by optogenetic stimulation of vHb neurons evoked place avoidance behavior. Thus, vHb-MR circuit is essential for representing the level of expected danger and behavioral programming to adaptively avoid potential hazard.",smart cities
10.1016/j.ijporl.2014.10.011,Journal,International Journal of Pediatric Otorhinolaryngology,scopus,2014-12-01,sciencedirect,Middle ear inflammation of rat induced by urban particles,https://api.elsevier.com/content/abstract/scopus_id/84919484386,"Objective
                  The aim of this study was to evaluate the histologic change of middle ear mucosa and the expression levels of epithelial sodium channel (ENaC) subunits and mucin production genes, after the injection of urban particulate matter (UPM) into the middle ear cavity of rats.
               
                  Methods
                  Fifty pathogen-free, male Sprague Dawley rats were assigned to the study. Transtympanic injection of UPM solution (300μg/ml, 50μl) was made into the middle ear cavity of rats. Rats were sacrificed at day 1 (group1); day 3 (group2); day 5 (group3); and day 14 (group4) after the procedure. The expression levels of ENaC subunits (α, β and γ) and mucin producing genes (MUC5AC and MUC5B) were analyzed using semi-quantitative real-time reverse transcriptase–polymerase chain reaction. Thickness of middle ear mucosa was measured and analyzed.
               
                  Result
                  After transtympanic injection, the thickness of middle ear mucosa increased significantly on day 1, 3 and 5 (p
                     <0.05) and was normalized on day 14, compared to the control group. Inflammatory changes observed in the middle ear mucosa were subepithelial widening, inflammatory cell infiltration and vascular space widening on day 1, 3 and 5. These changes had reverted to normal on day 14. The level of ENaC-α expression decreased 0.60 fold on day 1 (p
                     <0.05), but was normalized thereafter. The level of ENaC-β and γ decreased 0.39 and 0.27 fold, respectively, on day 1, was normalized on days 3 and 5, and increased 2.30 and 2.47 fold on day 14, respectively (p
                     <0.05). The level of MUC5AC expression increased 1.97-fold on day 1 (p
                     <0.05) and 2.58-fold on day 5 (p
                     <0.05), but was normalized on day 14. The level of MUC5B expression increased 5.4-fold on day 1, 3.14-fold on day 3, 3.85-fold on day 5, and 2.46-fold on day 14, respectively (p
                     <0.05).
               
                  Conclusion
                  Transtympanic injection of UPM solution into the middle ear cavity of rat induced a characteristic inflammatory response and altered gene expression related with inflammation and mucin production. These findings provide a useful clue for the understanding of how air pollutants, particularly UPM, contribute to the development of otitis media.",smart cities
10.1016/j.jcis.2014.07.024,Journal,Journal of Colloid and Interface Science,scopus,2014-11-15,sciencedirect,Responsive delivery of drug cocktail via mesoporous silica nanolamps,https://api.elsevier.com/content/abstract/scopus_id/84906518894,"After a substantial advancement in single drug nanocarrier, nanomedicine now demands an integration of nanotechnology with combination therapy to achieve synergistic therapeutic effects. In this respect, a smart and multiple drug shuttling nanotheranostic system is developed which transport diverse kinds of anticancer drugs to cancer cells in a controlled and responsive manner respectively. Synthetically, a significantly high dose of hydrophobic camptothecin (CPT) is first loaded into the porous structure of quantum dots (CdS) coupled mesoporous silica nanocomposite. Subsequently, fluorescent doxorubicin (DOX) molecules are exclusively anchored onto the surface of CdS; as a result, the fluorescence of both CdS and DOX is quenched. Upon exposing to mildly acidic conditions, the fluorescence of both species is recovered, such fluorescent “on–off” states provides an added opportunity to real time sense drug release. In-vitro cell experiment reveals an excellent anticancer efficacy of drug cocktail, merely 3μg/ml concentration of multiple drugs loaded nanocarrier reduces the cell viability to 30%. Furthermore, confocal imaging indicates a successful release of both therapeutic entities. We visualize that our newly fabricated multifunctional double drug-carrying nanoparticles can be a valuable addition to next generation of materials that simultaneously deliver cocktail of drugs with imaging functionality.",smart cities
10.1016/j.jss.2014.07.038,Journal,Journal of Systems and Software,scopus,2014-11-01,sciencedirect,A learning-based module extraction method for object-oriented systems,https://api.elsevier.com/content/abstract/scopus_id/84908163044,"Developers apply object-oriented (OO) design principles to produce modular, reusable software. Therefore, service-specific groups of related software classes called modules arise in OO systems. Extracting the modules is critical for better software comprehension, efficient architecture recovery, determination of service candidates to migrate legacy software to a service-oriented architecture, and transportation of such services to cloud-based distributed systems. In this study, we propose a novel approach to automatic module extraction to identify services in OO software systems. In our approach, first we create a weighted and directed graph of the software system in which vertices and edges represent the classes and their relations, respectively. Then, we apply a clustering algorithm over the graph to extract the modules. We calculate the weight of an edge by considering its probability of being within a module or between modules. To estimate these positional probabilities, we propose a machine-learning-based classification system that we train with data gathered from a real-world OO reference system. We have implemented an automatic module extraction tool and evaluated the proposed approach on several open-source and industrial projects. The experimental results show that the proposed approach generates highly accurate decompositions that are close to authoritative module structures and outperforms existing methods.",smart cities
10.1016/j.comcom.2014.06.004,Journal,Computer Communications,scopus,2014-09-15,sciencedirect,Multimedia over cognitive radio networks: Towards a cross-layer scheduling under Bayesian traffic learning,https://api.elsevier.com/content/abstract/scopus_id/84905095182,"Mobility and spectrum change of the cognitive radio networks (CRNs), make the traffic information exchange among the secondary users (SUs) a high-overhead task. In order to quickly estimate the queuing delay in the multimedia over CRN applications without exchanging traffic information among SUs, we are the first group to propose the use of Dirichlet-prior based fully Bayesian model in each individual SU to automatically update its statistical distribution on other SUs’ Non-Contiguous (NC)-OFDM subcarrier selection strategy. Such a statistical distribution is used to estimate the probability of queuing delay being less than a threshold. In addition, we introduce a new concept called the Time Window, to accurately determine how many packets can be transmitted simultaneously over multiple subcarriers. Then, we propose a comprehensive, intelligent cross-layer scheduling scheme that can generate the optimal subcarrier selection, power and modulation allocation for each multimedia packet. Our experiments on real video transmission validate our intelligent cross-layer scheduling schemes. The simulation results match with theoretical analysis very well, and the reconstructed video quality using our proposed scheduling scheme is superior to four other popularly used schemes.",smart cities
10.1016/j.vetpar.2013.12.020,Journal,Veterinary Parasitology,scopus,2014-07-30,sciencedirect,Combination anthelmintics effectively control ML-resistant parasites; a real-world case history,https://api.elsevier.com/content/abstract/scopus_id/84904404019,"Routine investigation into an ill-thrift situation with grazing cattle led to the discovery of the first reported case of macrocyclic lactone (ML) resistance in cattle in the USA. Research revealed that resistant parasites were originating on pastures in southeastern USA and were not an anomalous resident population on Wisconsin pastures. Prior to using anthelmintics in combination, ML-resistant Cooperia and Haemonchus spp. were shown to survive treatment with single-active MLs and were being transported in shipped cattle and seeding summer grazing pastures. Treatment and management strategies implemented in 2011 and 2012 suggested that ML-surviving parasites were introduced into the conditioning facility and surviving treatment with ML. Data also demonstrated the use of combination ML+oral levamisole was highly effective in minimizing the transport of ML-surviving parasites from southeastern USA to Wisconsin pastures. The value of fecal egg count monitoring and PCR evaluation of nematode species under production conditions are confirmed.",smart cities
10.1016/j.neucom.2013.07.051,Journal,Neurocomputing,scopus,2014-07-05,sciencedirect,Urban bicycles renting systems: Modelling and optimization using nature-inspired search methods,https://api.elsevier.com/content/abstract/scopus_id/84897916947,"Urban Bicycles Renting Systems (UBRS) are becoming a common and useful component in growing modern cities. For an efficient management and support, the UBRS infrastructure requires the optimation of vehicle routes connecting several bicycle base stations and storage centers. In this study, we model this real-world optimization problem as a capacitated Vehicle Routing Problem (VRP) with multiple depots and the simultaneous need for pickup and delivery at each base station location. Based on the VRP model specification, two nature-inspired computational techniques, evolutionary algorithms and ant colony systems, are presented and their performance in tackling the UBRS problem is investigated. In the evolutionary approach, individuals are encoded as permutations of base stations and then translated to a set of routes subject to the constraints related to vehicle capacity and node demands. In the ant-based approach, ants build complete solutions formed of several subtours servicing a subset of base stations using a single vehicle based on both apriori (the attractiveness of a move based on the known distance or other factors) and aposteriori (pheromone levels accumulated on visited edges) knowledge. Both algorithms are engaged for the UBRS problem using real data from the cities of Barcelona and Valencia. Computational experiments for several scenarios support a good performance of both population-based search methods. Comparative results indicate that better solutions are obtained on the average by the ant colony system approach for both considered cities.",smart cities
10.1016/j.intimp.2014.01.019,Journal,International Immunopharmacology,scopus,2014-04-01,sciencedirect,Protective effects of the total saponins from Dioscorea nipponica Makino against carbon tetrachloride-induced liver injury in mice through suppression of apoptosis and inflammation,https://api.elsevier.com/content/abstract/scopus_id/84896850686,"The present study was to investigate the effects and possible mechanisms of the total saponins from Dioscorea nipponica Makino (TSDN) against CCl4-induced hepato-toxicity in mice. The mice were orally administrated with TSDN for seven days and then given CCl4 (0.3%, 10ml/kg i.p.). The results showed that TSDN significantly attenuated the activities of ALT and AST, consistent with hematoxylin–eosin staining. The ALP levels and relative liver weight were significantly decreased by TSDN compared with model group. Moreover, TSDN dramatically decreased MDA, iNOS and NO levels, while the levels of GSH, GSH-Px and SOD were increased. Further investigations showed that TSDN inhibited CCl4-induced metabolic activation and CYP2E1 expression, down-regulated the levels of MAPKs phosphorylation, NF-κB, HMGB1, COX-2 as well as effectively suppressed the expressions of Caspase-3, Caspase-9, PARP and Bak. Quantitative real-time PCR assay demonstrated that TSDN obviously decreased the gene expressions of TNF-a, IL-1β, IL-6, IL-10, Fas, FasL, Bax as well as modulated Bcl-2 mRNA level. This is the first time to report the protective actions of the TSDN against CCl4-induced liver damage in mice through suppression of inflammation and apoptosis. This natural product should be developed as a new drug for treatment of liver injury in future.",smart cities
10.1016/j.toxlet.2013.12.021,Journal,Toxicology Letters,scopus,2014-03-03,sciencedirect,"Effects of 2,3,7,8-tetrachlorodibenzo-p-dioxin on secretion of steroids and STAR, HSD3B and CYP19A1 mRNA expression in chicken ovarian follicles",https://api.elsevier.com/content/abstract/scopus_id/84892551602,"The aim of the study was to investigate the in vitro effects of 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD) on steroid hormone secretion by chicken ovarian follicles and mRNA expression of genes involved in steroids synthesis. In the first in vitro experiment, white (WF) and yellowish (YF) follicles and fragments of the theca (TL) and granulosa (GL) layers of the 3 largest yellow preovulatory follicles (F3–F1) were incubated in a medium supplemented with TCDD (0.01–100nM). In the second experiment, they were incubated in a medium with TCDD (10nM), ovine LH (10ng/mL; oLH) or a combination of oLH (10ng/mL) and TCDD (10nM). It was found that TCDD decreased estradiol (E2) secretion by WF and the TL of all preovulatory follicles, testosterone (T) secretion by WF, YF, and the TL of F2 and F1 follicles, and progesterone (P4) secretion by the GL of the preovulatory follicles. It also reduced oLH-stimulated E2 and P4 secretion by all examined follicles and T by WF. Real-time qPCR revealed that TCDD affected basal and oLH-stimulated expression of STAR, HSD3B and CYP19A1 mRNAs in all investigated ovarian follicles. In conclusion, the data obtained indicate that TCDD inhibits sex steroids secretion from chicken ovarian follicles. The effects of TCDD depend on its concentration and the stage of follicle maturation, and are associated with modulation of STAR, HSD3B and CYP19A1 mRNAs expression. These results indicate that the exposure of the laying hen to TCDD by influence of ovarian steroidogenesis may impair the selection of white follicles to preovulatory hierarchy and disturb their growth and preovulatory maturation.",smart cities
10.1016/j.brainres.2013.11.023,Journal,Brain Research,scopus,2014-01-16,sciencedirect,Expression and cell distribution of receptor for advanced glycation end-products in the rat cortex following experimental subarachnoid hemorrhage,https://api.elsevier.com/content/abstract/scopus_id/84891747122,"Convincing evidence indicates that inflammation contributes to the adverse prognosis of subarachnoid hemorrhage (SAH). Some pro-inflammatory molecules such as high mobility group protein 1, S100 family of proteins, β-amyloid peptide, and macrophage antigen complex 1 have been involved in the damaging inflammation process following SAH. The receptor for advanced glycation end-products (RAGE) is a transmembrane receptor that senses these molecules and plays central role in inflammatory processes. This study aimed to determine the expression and cell distribution of RAGE in the brain cortex after SAH. Male Sprague-Dawley rats were randomly divided into sham group and SAH groups at 6h, 12h and on day 1, day 2 and day 3 (n=6 for each subgroup). SAH groups suffered experimental SAH by injection of 0.3ml autologous blood into the prechiasmatic cistern. RAGE expression was measured by Western blot, real-time PCR, immunohistochemistry and immunofluorescence. Nuclear expression of p65 protein, the major subunit of nuclear factor kappa B, was also detected. Our data demonstrated that the expression levels of RAGE and nuclear p65 protein were both markedly increased after SAH. Moreover, there was a significant positive correlation between the expression of RAGE and that of p65 protein. Double immunofluorescence staining showed that RAGE was expressed by neuron and microglia rather than astrocyte after SAH. These results suggest that RAGE may be directly involved in the inflammatory response after SAH, and there might be important implications for further studies using specific RAGE antagonists to decrease inflammation-mediated brain injury following SAH.",smart cities
10.3182/20140824-6-za-1003.01676,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2014-01-01,sciencedirect,Model based decision support system for the heap leaching process,https://api.elsevier.com/content/abstract/scopus_id/84929774253,"As one of the copper recovery processes, hydrometallurgy has gain impact due to its ability to process ore with average low grades at competitive prices compared with other metallurgical processes. Among hydrometallurgical processes the leaching stage, a process that is characterized by its significant temporal and spatial scale of operation, is critical. In spite of extensive developments in instrumentation in pyrometullurgical and concentrators plants, developments in heap leaching instrumentation has not reached the required level for a fully automated control system and furthermore for a stable operation. Computational tools, such us dynamic simulators, can help operators achieve the best performance of the heap using the available instrumentation. This paper presents the development and implementation of an integrated dynamic simulator and a decision support system (DSS) for hydrometallurgical processes with emphasis in heap leaching process. The dynamic simulator uses two dimensional models of fluid transport, transport of solutes and dissolution of copper in the leaching heap, to analyse the effects produced in the variables of interest, such as the consumption of acid, copper concentration in the PLS (Pregnant Leach Solution) and leaching times. The DSS, which is connected to the real time plant information system, gathers the information by sensors and laboratory analyses to perform an automatic on-line parameter estimation of the process and makes predictions to recommend to the operator both curing and leaching rates. Results show that the DSS achieves the identification and prediction with less than 6% of error, allowing the metallurgist to predict the leaching behaviour and take decisions with better information.",smart cities
10.1016/j.intimp.2014.11.001,Journal,International Immunopharmacology,scopus,2014-01-01,sciencedirect,Raphanus sativus L. seeds prevent LPS-stimulated inflammatory response through negative regulation of the p38 MAPK-NF-κB pathway,https://api.elsevier.com/content/abstract/scopus_id/84913530577,"The seeds of Raphanus sativus L. (RSL) have long been used as anti-inflammatory traditional medicine. However, scientific bases for the purported potential of the medicine and the associated mechanisms were barely defined. This study investigated the effects of RSL seeds on lipopolysaccharide (LPS)-stimulated inflammatory responses in vitro and in vivo. Treatment with 100μg/ml ethyl acetate fraction (REF), which was isolated from water extract of the seeds, significantly inhibited LPS-stimulated production of nitric oxide (P
                     <0.05), interleukin-6 (P
                     <0.001), and tumor necrosis factor (TNF)-α (P
                     <0.001) in RAW264.7 cells. Oral supplementation with 30mg/kg REF protected mice by 90% against LPS-induced septic death and prevented the increases of serum TNF-α and interferon-γ levels in LPS-injected mice. When REF was divided into four sub-fractions (REF-F1–F4), REF-F3 showed the greatest activity to suppress LPS-stimulated production of inflammatory mediators. We subsequently isolated an active fraction from the REF-F3 and identified sinapic acid as the main constituent. The addition of 50μg/ml active fraction markedly inhibited LPS-stimulated production of inflammatory mediators by suppressing p38 MAPK and nuclear factor-κB activation. Furthermore, supplementation with the active fraction (10mg/kg) improved the survival rate of LPS-injected mice by 80% of the untreated control. Additional experiments revealed that sinapic acid was the active component responsible for the anti-inflammatory potential of RSL seeds. Collectively, our current results suggest that both RSL seeds and sinapic acid may be attractive materials for treating inflammatory disorders caused by endotoxins.",smart cities
10.1016/j.marenvres.2014.03.007,Journal,Marine Environmental Research,scopus,2014-01-01,sciencedirect,Machine learning approaches to investigate the impact of PCBs on the transcriptome of the common bottlenose dolphin (Tursiops truncatus),https://api.elsevier.com/content/abstract/scopus_id/84906937579,"As top-level predators, common bottlenose dolphins (Tursiops truncatus) are particularly sensitive to chemical and biological contaminants that accumulate and biomagnify in the marine food chain.
                  This work investigates the potential use of microarray technology and gene expression profile analysis to screen common bottlenose dolphins for exposure to environmental contaminants through the immunological and/or endocrine perturbations associated with these agents. A dolphin microarray representing 24,418 unigene sequences was used to analyze blood samples collected from 47 dolphins during capture-release health assessments from five different US coastal locations (Beaufort, NC, Sarasota Bay, FL, Saint Joseph Bay, FL, Sapelo Island, GA and Brunswick, GA). Organohalogen contaminants including pesticides, polychlorinated biphenyl congeners (PCBs) and polybrominated diphenyl ether congeners were determined in blubber biopsy samples from the same animals. A subset of samples (n = 10, males; n = 8, females) with the highest and the lowest measured values of PCBs in their blubber was used as strata to determine the differential gene expression of the exposure extremes through machine learning classification algorithms. A set of genes associated primarily with nuclear and DNA stability, cell division and apoptosis regulation, intra- and extra-cellular traffic, and immune response activation was selected by the algorithm for identifying the two exposure extremes. In order to test the hypothesis that these gene expression patterns reflect PCB exposure, we next investigated the blood transcriptomes of the remaining dolphin samples using machine-learning approaches, including K-nn and Support Vector Machines classifiers. Using the derived gene sets, the algorithms worked very well (100% success rate) at classifying dolphins according to the contaminant load accumulated in their blubber. These results suggest that gene expression profile analysis may provide a valuable means to screen for indicators of chemical exposure.",smart cities
10.1016/j.intimp.2014.08.003,Journal,International Immunopharmacology,scopus,2014-01-01,sciencedirect,Ketamine inhibits LPS-induced HGMB1 release in vitro and in vivo,https://api.elsevier.com/content/abstract/scopus_id/84906705334,"High mobility group box 1 (HMGB1) has been identified to be a critical mediator of severe sepsis. Ketamine has been shown to reduce sepsis-induced pathological complications. These effects are because of the reduced expression and release of several inflammatory mediators. However, whether ketamine affects the expression and release of HMGB1 is not known. We investigated the effect of ketamine on HMGB1 release in lipopolysaccharide (LPS)-induced macrophages in vitro and in cecal ligation and puncture (CLP)-induced septic rats in vivo, and determined its molecular mechanism of action. RAW264.7 cells or primary macrophages were incubated with or without LPS (500ng/mL) in the presence or absence of ketamine, a p38 mitogen-activated protein kinase (p38 MAPK) inhibitor (SB203580), a nuclear factor-kappa B (NF-κB) inhibitor (pyrimidine dithiocarbamate), or small interfering RNA. The protein and expression levels of inflammatory mediators, such as HMGB1, tumor necrosis factor-α, and interleukin-1β were measured using enzyme-linked immunosorbent assays and real-time polymerase chain reaction. The effect of ketamine on NF-κB and p38 MAPK activation was evaluated using enzyme-linked immunosorbent assays, Western blot analysis, and electrophoretic mobility shift assay. Western blotting was used to observe changes in translocation of HMGB1 from the nucleus to cytoplasm. In addition, CLP-induced septic rats were treated with ketamine (0.5, 5, 10mg/kg) or saline (10mL/kg) 3h after sepsis, and the levels of HMGB1 and functional parameters of multiple organs were determined using several detection kits. Seven-day survival was also assessed. Ketamine inhibited HMGB1 release in LPS-activated RAW264.7 cells and CLP-induced septic rats. Translocation of HMGB1 from the nucleus to cytosol and expression of HMGB1 mRNA were inhibited significantly by ketamine. Ketamine inhibited the translocation of NF-κB from the cytoplasm to the nucleus and phosphorylation of p38 MAPK in LPS-activated RAW264.7 cells. Rats treated with ketamine improved survival in rats and significantly reduced CLP-induced dysfunction/injury of organs. Ketamine suppresses LPS-induced HMGB1 release in LPS-activated RAW264.7 cells and a CLP-induced model of sepsis in rats by partially inhibiting NF-κB/p38 MAPK pathways. Ketamine increased survival time induced by CLP and reduced organ dysfunction in septic peritonitis.",smart cities
10.1016/j.brainresbull.2014.05.005,Journal,Brain Research Bulletin,scopus,2014-01-01,sciencedirect,Hydrogen-rich saline controls remifentanil-induced hypernociception and NMDA receptor NR1 subunit membrane trafficking through GSK-3β in the DRG in rats,https://api.elsevier.com/content/abstract/scopus_id/84903182527,"Background
                  Although NMDAR trafficking mediated by GSK-3β involvement in transmission of pronociceptive messages in the spinal cord has been confirmed by our previous studies, whether NMDAR trafficking is implicated in peripheral sensitization remains equivocal. It is demonstrated that inflammation is associated with spinal NMDAR-containing nociceptive neurons activation and the maintenance of opioid induced pain hypersensitivity. However, whether and how hydrogen-rich saline, as an effective anti-inflammatory drug, could prevent hyperalgesia through affecting peripheral sensitization caused by NMDAR activation remains to be explored.
               
                  Methods
                  To test these effects, hydrogen-rich saline (2.5, 5 or 10ml/kg) was administrated intraperitoneally after remifentanil infusion, NMDAR antagonist MK-801 or GSK-3β inhibitor TDZD-8 was administrated intravenously before remifentanil infusion in rats. We examined time course of hydrogen concentration in blood after hydrogen-rich saline administration. Mechanical and thermal hyperalgesia were evaluated by measuring PWT and PWL for 48 post-infusion hours, respectively. Western blotting and real-time qPCR assay were applied to analyze the NR1 membrane trafficking, GSK-3β expression and activity in DRG. Inflammatory mediators (TNF-α, IL-1β, and IL-6) expressions in DRG were also analyzed.
               
                  Results
                  We found that NR1 membrane trafficking in DRG increased, possibly due to GSK-3β activation after remifentanil infusion. We also discovered that hydrogen-rich saline not 2.5ml/kg but 5 and 10ml/kg could dose-dependently attenuate mechanical and thermal hyperalgesia without affecting baseline nociceptive threshold, reduce expressions of inflammatory mediators (TNF-α, IL-1β, and IL-6) and decrease NR1 trafficking mediated by GSK-3β, and minimal effective concentration was observed to be higher than 10μmol/L, namely peak concentration in arterial blood after administration of HRS 2.5ml/kg without any influence on hyperalgesia.
               
                  Conclusion
                  Our results indicated that antihyperalgesic effect of hydrogen-rich saline might depend predominantly on its ability to reverse NR1 trafficking via inhibition of GSK-3β activity in DRG in a dose-dependent manner.",smart cities
10.1016/j.procs.2014.05.151,Conference Proceeding,Procedia Computer Science,scopus,2014-01-01,sciencedirect,Evaluation of in-vehicle decision support system for emergency evacuation,https://api.elsevier.com/content/abstract/scopus_id/84902825749,"One of the most important issues in Decision Support Systems (DSS) technology is in ensuring their effectiveness and efficiency for future implementations and use. DSS is prominent tool in disaster information system, which allows the authority to provide life safety information directly to the mobile devices of anyone physically located in the evacuation area. After that a personal DSS guides users to a safe point. Due to the large uncertainty in initial conditions and assumptions on underlying process the implementation and evaluation of such DSS are extremely hard, particularly in real environment. We propose a simulation methodology for the evaluation of in-vehicle DSS for emergency evacuation based on transport system and human decision-making modeling.",smart cities
10.1016/j.neuint.2014.05.007,Journal,Neurochemistry International,scopus,2014-01-01,sciencedirect,High-mobility group box 1 up-regulates aquaporin 4 expression via microglia-astrocyte interaction,https://api.elsevier.com/content/abstract/scopus_id/84902477277,"To clarify the mechanism of high-mobility group box (HMGB) 1-induced brain edema formation, this study focused on the effect of HMGB1 on aquaporin (AQP) 4, a water channel, in rat brain. Treatments for 6h with 100–1000ng/ml HMGB1, not showing self-toxicity, of primary-cultured rat astrocytes didnot increase AQP4 mRNA, unexpectedly. In contrast, intracerebroventricular (i.c.v.) injection of 300ng of HMGB1 significantly increased AQP4 protein after 8h and formed edema after 24h in vivo. Thus, we investigated the roles of microglia as well as astrocytes. HMGB1 (1000ng/ml) drastically increased interleukin (IL)-1β in the primary-cultured rat microglia after 2h. The exposure of microglia to conditioned medium with HMGB1 and 3mM adenosine 5′-triphosphate for 6h significantly increased AQP4 mRNA in astrocytes after 6h. Although 1000ng/ml HMGB1 didnot induce transfer of nuclear factor (NF)-κB into the nucleus in astrocytes after 1h, the conditioned medium containing IL-1β led to its nuclear import. As factors likely to be involved in the nuclear import of NF-κB besides IL-1β, nitric oxide and tumor necrosis factor-α didnot contribute under these conditions. Finally, i.c.v. injection of 30nmol parthenolide, an NF-κB inhibitor, reversed 300ng of HMGB1 injection-induced AQP4 protein increase after 8h in vivo. The effect of parthenolide and the outcomes obtained so far suggest that HMGB1 indirectly up-regulates AQP4 expression through diffusible factor(s) such as IL-1β from microglia since HMGB1 by itself didnot affect NF-κB intracellular localization in astrocytes.",smart cities
10.1016/j.envsoft.2013.11.013,Journal,Environmental Modelling and Software,scopus,2014-01-01,sciencedirect,Modeling energy consumption in automated vacuum waste collection systems,https://api.elsevier.com/content/abstract/scopus_id/84901484357,"In a world where resources are scarce and urban areas consume the vast majority of these resources, it is vital to make cities greener and more sustainable. A smart city is a city in which information and communications technology are merged with traditional infrastructures, coordinated and integrated using new digital technologies. The increasing amount of waste generated, and the collection and treatment of waste poses a major challenge to modern urban planning in general, and to smart cities in particular. To cope with this problem, automated vacuum waste collection (AVWC) uses air suction on a closed network of underground pipes to transport waste from the drop off points scattered throughout the city to a central collection point, reducing greenhouse gas emissions and the inconveniences of conventional methods (odours, noise, etc.). Since a significant part of the cost of operating AVWC systems is energy consumption, we have developed a model with the aim of applying constraint programming technology to schedule the daily emptying sequences of the drop off points in such a way that energy consumption is minimized. In this paper we describe how the problem of deciding the drop off points that should be emptied at a given time can be modeled as a constraint integer programming (CIP) problem. Moreover, we report on experiments using real data from AVWC systems installed in different cities that provide empirical evidence that CIP offers a suitable technology for reducing energy consumption in AVWC.",smart cities
10.1016/j.tust.2014.03.008,Journal,Tunnelling and Underground Space Technology,scopus,2014-01-01,sciencedirect,Supervised and unsupervised learning DSS for incident management in intelligent tunnel: A case study in Tehran Niayesh tunnel,https://api.elsevier.com/content/abstract/scopus_id/84898676901,"This paper deals with a new decision support system (DSS) for intelligent tunnel. This DSS includes two subsystems. In the first, the rules are extracted from incident severity database and micro-simulation results. Then simple fuzzy grid technique is applied to generate the rules. The accuracy degree of this subsystem is 63% in the presented experiment. In the second subsystem, these rules are trained by DSS with two modules. In the first module unsupervised learning methods such as K-mean, farthest first, self-organizing map (SOM), learning vector quantization (LVQ), hierarchical clustering and filtered clustering are implemented. The best performance in this module corresponds to hierarchical clustering with 70% accuracy on normal data. Also learning vector quantization (LVQ) provides 74% accuracy on discrete data in this module. In the second module feed forward neural network, Naïve Bayes tree, classification and regression tree (CART), and support vector machine (SVM) are applied. In this module the most accuracy is 87% on normal data regarding to feed forward neural network and also Naïve Bayes tree provides 89.3% accuracy on discrete data. To illustrate the performance of the proposed learning DSS, we use two sources of data. The first is UK road safety data bank which is applied to estimate severity of real incidents in tunnel. The second one is simulation results of Niayesh tunnel in Tehran which is implemented on Aimsun 7. Although only incident management in tunnel is focused by this paper, it is possible to find similar results on learning DSS for other user services of intelligent tunnel.",smart cities
10.1016/j.jece.2013.11.006,Journal,Journal of Environmental Chemical Engineering,scopus,2014-01-01,sciencedirect,"The mobility and speciation of lead and cadmium in Bahr El Baqar region, Egypt",https://api.elsevier.com/content/abstract/scopus_id/84897115061,"Under continuous irrigation with Bahr El Baqar drain water in Egypt, chemical speciation of Pb and Cd in soils is critical to understand, their mobility and potential toxic effects. In the present study, sorption isotherm experiments of these metals in nine representative soils were assessed at varying metal concentrations (20, 40, 60, 80 and 100mgl−1), solid to liquid ratio 5g/50ml and contact time (24h). Additionally, the kinetic experiments were performed using initial concentration of 100mgl−1 Pb or Cd and contact time of 2, 4, 8, 12 or 24h. The two experiments were carried out at 298K. Low amounts of Pb were found in exchangeable and carbonate fractions comparing with the residual, oxides and organic fractions for the most studied soils. On the other hand, the residual fraction of Cd speciation was dominant for all the studied soils, followed by carbonate fraction. Both Langmuir and Freundlich models isotherm for Pb and Cd adsorption by these soils were fitted. The second-order kinetic model was the best fit model for the adsorption mechanism in these soils. These soils are still able to be retained and more loaded with Pb and Cd, since they did not reach their saturation capacities. Taken together, continuous accumulation of these toxic metals will be exposed to the environment to real disaster under bad management in this region.",smart cities
10.1016/j.metabol.2013.12.009,Journal,Metabolism: Clinical and Experimental,scopus,2014-01-01,sciencedirect,Increased expression of oxidative enzymes in adipose tissue following PPARα-activation,https://api.elsevier.com/content/abstract/scopus_id/84896490631,"Objective
                  Evaluate the effect of fenofibrate treatment on the expression of PPARα and oxidative enzymes in adipose tissue.
               
                  Materials/methods
                  Wistar male rats were fed a balanced diet supplemented with 100mg.Kg-1 bw.day-1 fenofibrate (Sigma) during nine days. Plasma glucose, free fatty acids (FFA) leptin and insulin were determined. PPARα, ACO and CPT-1 mRNA expression and amount of PPARα and PPARγ protein were assessed in epididymal adipose tissue. Oral glucose tolerance test was evaluated into overnight fasted rats. Glucose uptake was measured in adipocytes isolated from epididymal fat pads in the presence or absence of insulin (25ng/mL).
               
                  Results
                  Fenofibrate treatment increased PPARα and PPARγ protein abundance in adipose tissue. In addition to it well- known effect on oxidative enzymes in liver, fenofibrate treatment also induces a high expression of Acyl CoA Oxidase (ACO) and Carnitine palmitoyltransferase 1 (CPT-1) in adipose tissue. Furthermore, we have shown that the fenofibrate treatment improves the glucose tolerance and enhance the glucose uptake by adipocytes.
               
                  Conclusion
                  Altogether, the data suggest that fenofibrate have a direct effect in adipose tissue contributing to the low adiposity and improvement of glucose homeostasis.",smart cities
10.1016/j.trc.2014.01.001,Journal,Transportation Research Part C: Emerging Technologies,scopus,2014-01-01,sciencedirect,Multi-criteria route planning based on a driver's preferences in multi-criteria route selection,https://api.elsevier.com/content/abstract/scopus_id/84892896347,"In this study, some different approaches were designed, implemented, and evaluated to perform multi-criteria route planning by considering a driver’s preferences in multi-criteria route selection. At first, by using a designed neuro-fuzzy toolbox, the driver’s preferences in multi-criteria route selection such as the preferred criteria in route selection, the number of route-rating classes, and the routes with the same rate were received. Next, to learn the driver’s preferences in multi-criteria route selection and to classify any route based on these preferences, a methodology was proposed using a locally linear neuro-fuzzy model (LLNFM) trained with an incremental tree based learning algorithm. In this regard, the proposed LLNFM-based methodology reached better results for running-times, as well as root mean square error (RMSE) estimations in learning and testing processes of training/checking data-set in comparison with those of the proposed adaptive neuro-fuzzy inference system (ANFIS) based methodology. Finally, the trained LLNFM-based methodology was utilized to plan and predict a driver’s preferred routes by classifying Pareto-optimal routes obtained by running the modified invasive weed optimization (IWO) algorithm between an origin and a destination of a real urban transportation network based on the driver’s preferences in multi-criteria route selection.",smart cities
10.1016/j.jpowsour.2013.08.018,Journal,Journal of Power Sources,scopus,2014-01-01,sciencedirect,Artificial neural network model of a short stack solid oxide fuel cell based on experimental data,https://api.elsevier.com/content/abstract/scopus_id/84883300551,"Solid oxide fuel cells (SOFCs) are complex systems in which electrical conduction, heat transfer, gas phase mass transport, chemical reactions and ionic conduction take place simultaneously and are tightly coupled. Mathematical models based on conservation laws have been shown to be slow and because of some parameter estimation for physical, chemical and electrochemical properties they have less accuracy. ANN models are powerful tools that bring simplicity and real-time response to SOFC modeling. Depending on the quality of the training data, ANN models can also show greater accuracy than CFD models. In this study ANN modeling of a short stack SOFC is considered. Training data are extracted and filtered from measurements on a dedicated test set-up. Given the fuel flow and composition, air flow, oven temperature and current, the model can predict the voltage and temperature profile of the cell. An optimized structure for the network is selected as: 5–11–6 for a 5 input, 6 output network with 11 hidden neurons. Prediction results of the ANN model deviate 0.2% concerning average relative error compared to the measurements.",smart cities
10.1016/j.jprocont.2013.09.014,Journal,Journal of Process Control,scopus,2013-10-28,sciencedirect,A multilayer-perceptron based method for variable selection in soft sensor design,https://api.elsevier.com/content/abstract/scopus_id/84886080853,"The paper proposes a new method for variable selection for prediction settings and soft sensors applications. The new variable selection method is based on the multi-layer perceptron (MLP) neural network model, where the network is trained a single time, maintaining low computational cost. The proposed method was successfully applied, and compared with four state-of-the-art methods in one artificial dataset and three real-world datasets, two publicly available datasets (Box–Jenkins gas furnace and gas mileage), and a dataset of a problem where the objective is to estimate the fluoride concentration in the effluent of a real urban water treatment plant (WTP). The proposed method presents similar or better approximation performance when compared to the other four methods. In the experiments, among all the five methods, the proposed method selects the lowest number of variables and variables-delays pairs to achieve the best solution. In soft sensors applications having a lower number of variables is a positive factor for decreasing implementation costs, or even making the soft sensor feasible at all.",smart cities
10.1016/j.rvsc.2013.06.024,Journal,Research in Veterinary Science,scopus,2013-10-01,sciencedirect,"The involvement of growth hormone in equine oocyte maturation, receptor localization and steroid production by cumulus-oocyte complexes in vitro",https://api.elsevier.com/content/abstract/scopus_id/84881544494,"The objectives of this study were to evaluate the effects of equine growth hormone (eGH) on nuclear and cytoplasmic maturation of equine oocytes in vitro, steroid production by cumulus cells, and expression and subcellular localization of eGH-receptors (eGH-R) on equine ovarian follicles. Cumulus–oocyte complexes (COCs) were recovered by aspirating follicles <30mm in diameter from abattoir-derived ovaries. The COCs were morphologically evaluated and randomly allocated to be cultured in either a control maturation medium or supplemented with 400ng/mL eGH, for 30h at 38.5°C in air with 5% CO2. The COCs were stained with 10μg/mL propidium iodide and 10μg/mL fluorescein isothiocyanate-labeled Lens culinaris agglutinin. Chromatin configuration and distribution of cortical granules were assessed via confocal microscopy. Compared to control, COCs incubated with eGH had: more oocytes that reached metaphase II (35/72, 48.6% vs. 60/89, 67.4%, respectively; P
                     =0.02); greater concentrations of testosterone (0.21±0.04 vs. 0.06±0.01ng/mL; P=
                     0.01), progesterone (0.05±0.01 vs. 0.02±0.00ng/mL; P
                     =0.04), and oestradiol (76.80±14.26 vs. 39.58±8.87pg/mL; P=
                     0.05) in the culture medium, but no significant differences in concentration of androstenedione. Based on Real Time RT-PCR analyses, expression of the eGH-R gene was greater in cumulus cells and COCs at the start than at the end of in vitro maturation. Positive immunostaining for eGH-R was present in cumulus cells, the oocytes and granulosa cells. In conclusion, addition of eGH to maturation medium increased rates of cytoplasmic maturation and had an important role in equine oocyte maturation, perhaps mediated by the presence of eGH-R in ovarian follicles.",smart cities
10.1016/j.gene.2013.05.041,Journal,Gene,scopus,2013-09-15,sciencedirect,The HMGB1-TLR4 axis contributes to myocardial ischemia/reperfusion injury via regulation of cardiomyocyte apoptosis,https://api.elsevier.com/content/abstract/scopus_id/84881241307,"Toll-like receptor 4 (TLR4) and its ligand high mobility group box 1 (HMGB1), are known for playing central roles in ischemia–reperfusion injury in myocardium. However, the detailed mechanisms of TLR4 and HMGB1 are not fully understood. The aim of this study was to investigate the effects and possible mechanisms of the HMGB1–TLR4 axis and cardiomyocyte apoptosis on myocardial ischemic damage. Artificial oxygen ventilated anesthetized C3H/HeN mice and C3H/HeJ mice were subjected to 30min of left anterior descending coronary artery occlusion followed by 6h of reperfusion. The myocardial infarct size, HMGB1 levels, apoptosis index, Bax, Bcl-2 and TNF-α mRNA levels were assessed. The results showed that a lowered amount of cardiomyocyte apoptosis and infarct size in the myocardium of TLR4-mutant mice after myocardial I/R and that TLR4 deficiency notably inhibited the expression of HMGB1 and TNF-a, both of which were up-regulated by ischemia/reperfusion. These findings suggest that the HMGB1–TLR4 axis plays a pathogenic role in triggering cardiomyocyte apoptosis during myocardial I/R injury and that the possible mechanism for this process is the result of released cytokines and inflammatory response involved in the HMGB1/TLR4-related pathway.",smart cities
10.1016/j.jtumed.2013.04.002,Journal,Journal of Taibah University Medical Sciences,scopus,2013-08-01,sciencedirect,Comparative study of garlic species (Allium sativum and Allium porrum) on glucose uptake in diabetic rats,https://api.elsevier.com/content/abstract/scopus_id/84886383922,"Background
                  Herbal medicines are recommended for management of diabetes in many parts of the world. Garlic is one such herb extensively used for antidiabetic activity, antimicrobial, antiarthritic, hypoglycaemic etc. Safety and efficacy of the herbal drugs used in the treatment of diabetes need to be evaluated.
               
                  Methods
                  Rat everted intestinal sac model was used to study garlic species Allium sativum and Allium porrum for their role in glucose transport. In this study test substances A. sativum and A. porrum at 2.5 and 5.0mg/ml and standard (insulin, 40μM/ml) were added to mucosal solution. Glucose concentrations were determined before and after a period of incubation. The preliminary phytochemical investigations were performed.
               
                  Results
                  Rat everted intestinal sac experiment is mainly used to indicate glucose uptake. The mucosal disappearance, serosal appearance and gut wall content of A. porrum at a dose of 2.5mg/ml (65.12%, 40.81%, 22.34%), dose of 5.0mg/ml (64.56%, 43.56%, 21.0%). Similarly A. sativum at a dose of 2.5mg/ml (67.74%, 42.05%, 25.68%), dose of 5.0mg/ml (65.97%, 43.11%, 22.86%), Insulin at a dose of 40μm/ml (60.36%, 37.84%, 22.52%) respectively. Thus A. sativum and A. porrum showed significant reduction in all the 3 parameters observed. Further A. porrum showed more potent action.",smart cities
10.1016/j.ajpath.2013.04.003,Journal,American Journal of Pathology,scopus,2013-07-01,sciencedirect,Chitinase inhibition promotes atherosclerosis in hyperlipidemic mice,https://api.elsevier.com/content/abstract/scopus_id/84879397603,"Chitinase 1 (CHIT1) is secreted by activated macrophages. Chitinase activity is raised in atherosclerotic patient sera and is present in atherosclerotic plaque. However, the role of CHIT1 in atherosclerosis is unknown. Preliminary studies of atherosclerosis in cynomolgous monkeys revealed CHIT1 to be closely correlated with areas of macrophage infiltration. Thus, we investigated the effects of a chitinase inhibitor, allosamidin, on macrophage function in vitro and on atherosclerotic development in vivo. In RAW264.7 cells, allosamidin elevated monocyte chemoattractant protein 1 and tumor necrosis factor alpha expression, and increased activator protein 1 and nuclear factor-κB transcriptional activity. Although inducible nitric oxide synthase, IL-6, and IL-1β expression were increased, Arg1 expression was decreased by chitinase inhibition, suggesting that suppression of CHIT1 activity polarizes macrophages into a M1 phenotype. Allosamidin decreased scavenger receptor AI, CD36, ABCA1, and ABCG1 expression which led to suppression of cholesterol uptake and apolipoprotein AI-mediated cholesterol efflux in macrophages. These effects were confirmed with CHIT1 siRNA transfection and CHIT1 plasmid transfection experiments in primary macrophages. Apolipoprotein E-deficient hyperlipidemic mice treated for 6 weeks with constant administration of allosamidin and fed an atherogenic diet showed aggravated atherosclerotic lesion formation. These data suggest that CHIT1 exerts protective effects against atherosclerosis by suppressing inflammatory responses and polarizing macrophages toward an M2 phenotype, and promoting lipid uptake and cholesterol efflux in macrophages.",smart cities
10.1016/j.eswa.2012.12.072,Journal,Expert Systems with Applications,scopus,2013-07-01,sciencedirect,Design of a visual perception model with edge-adaptive Gabor filter and support vector machine for traffic sign detection,https://api.elsevier.com/content/abstract/scopus_id/84874662791,"Traffic sign detection is a useful application for driving assistance systems, and it is necessary to accurately detect traffic signs before they can be identified. Sometimes, however, it is difficult to detect traffic sign, which may be obscured by other objects or affected by illumination or lightning reflections. Most previous work on this topic has been based on region of interest analysis using the color information of traffic signs. Although this provides a simple way to segment signs, this approach is weak when a sign is affected by illumination or its own color information is distorted. To overcome this, this paper introduces a robust traffic detection framework for cluttered scenes or complex city views that does not use color information. Moreover, the proposed method can detect traffic sign in the night. We establish an edge-adaptive Gabor function, which is derived from human visual perception. It is an enhanced version of the original Gabor filter, and filters out unnecessary information to provide robust recognition. It decomposes the directional information of objects and reflects specific shapes of traffic signs. Once the extracted feature is obtained, a support vector machine detects the traffic sign. Applying scale-space theory, it is possible to resolve the scaling problem of the objects that we want to find. Our system shows robust performance in traffic sign detection, and experiments on real-world scenes confirmed its properties.",smart cities
10.1016/j.wasman.2013.01.030,Journal,Waste Management,scopus,2013-05-01,sciencedirect,"Suitability analysis for siting MSW landfills and its multicriteria spatial decision support system: Method, implementation and case study",https://api.elsevier.com/content/abstract/scopus_id/84877614126,"Multicriteria spatial decision support systems (MC-SDSS) have emerged as an integration of geographical information systems (GIS) and multiple criteria decision analysis (MCDA) methods for incorporating conflicting objectives and decision makers’ (DMs’) preferences into spatial decision models. This article presents a raster-based MC-SDSS that combines the analytic hierarchy process (AHP) and compromise programming methods, such as TOPSIS (technique for order preference by similarity to the ideal solution) and Ideal Point Methods. To the best of our knowledge it is the first time that a synergy of AHP and compromise programming methods is implemented in raster-driven GIS-based landfill suitability analysis. This procedure is supported by a spatial decision support system (SDSS) that was developed within a widely used commercial GIS software package. A real case study in the Thrace region in northeast Greece serves as a guide on how to conduct a suitability analysis for a MSW landfill site with the proposed MC-SDSS. Moreover, the procedure for identifying MSW disposal sites is accomplished by performing four computational models for synthesizing the DMs per criterion preferential system. Based on the case study results, a comparison analysis is performed according to suitability index estimations. According to them Euclidean distance metric and TOPSIS present strong similarities. When compared with Euclidean distance metric, TOPSIS seems to generate results closer to that derived by Manhattan distance metric. The comparison of Chebychev distance metric with all the other approaches revealed the greatest deviations.",smart cities
10.1016/j.jhydrol.2013.02.022,Journal,Journal of Hydrology,scopus,2013-01-01,sciencedirect,Runoff forecasting using a Takagi-Sugeno neuro-fuzzy model with online learning,https://api.elsevier.com/content/abstract/scopus_id/84886101097,"A study using local learning Neuro-Fuzzy System (NFS) was undertaken for a rainfall–runoff modeling application. The local learning model was first tested on three different catchments: an outdoor experimental catchment measuring 25m2 (Catchment 1), a small urban catchment 5.6km2 in size (Catchment 2), and a large rural watershed with area of 241.3km2 (Catchment 3). The results obtained from the local learning model were comparable or better than results obtained from physically-based, i.e. Kinematic Wave Model (KWM), Storm Water Management Model (SWMM), and Hydrologiska Byråns Vattenbalansavdelning (HBV) model. The local learning algorithm also required a shorter training time compared to a global learning NFS model. The local learning model was next tested in real-time mode, where the model was continuously adapted when presented with current information in real time. The real-time implementation of the local learning model gave better results, without the need for retraining, when compared to a batch NFS model, where it was found that the batch model had to be retrained periodically in order to achieve similar results.",smart cities
10.1016/j.pmcj.2012.11.003,Journal,Pervasive and Mobile Computing,scopus,2013-01-01,sciencedirect,Enabling real-time city sensing with kernel stream oracles and MapReduce,https://api.elsevier.com/content/abstract/scopus_id/84883463862,"An algorithmic architecture for kernel-based modelling of data streams from city sensing infrastructures is introduced. It is both applicable for pre-installed, moving and extemporaneous sensors, including the “citizen-as-a-sensor” view on user-generated data. The approach is centred around a kernel dictionary implementing a general hypothesis space which is updated incrementally, accounting for memory and processing capacity limitations. It is general for both kernel-based classification and regression. An extension to area-to-point modelling is introduced to account for the data aggregated over a spatial region. A distributed implementation realised under the Map-Reduce framework is presented to train an ensemble of sequential kernel learners.",smart cities
10.1016/j.ijpe.2012.07.007,Journal,International Journal of Production Economics,scopus,2013-01-01,sciencedirect,Algorithm portfolios for logistics optimization considering stochastic demands and mobility allowance,https://api.elsevier.com/content/abstract/scopus_id/84869501144,"The vehicle routing problem with stochastic demand (VRPSD) is a well known NP-hard problem. The uncharacteristic behaviour associated with the problem enhances the computational efforts required to obtain a feasible and near-optimal solution. This paper proposes an algorithm portfolio methodology based on evolutionary algorithms, which takes into account the stochastic nature of customer demand to solve this computationally complex problem. These problems are well known to have computationally complex objective functions, which make their solutions hard to find, particularly when problem instances of large dimensions are considered. Of particular importance in such situations is the timeliness of the solution. For example, Apple was forced to delay their shipments of iPads internationally due to unprecedented demand and issues with their delivery systems in Samsung Electronics and Seiko Epson. Such examples illustrate the importance of stochastic customer demands and the timing of delivery. Moreover, most of the evolutionary algorithms, known for providing computationally efficient solutions, are unable to always provide optimal or near optimal solutions to all the VRPSD instances within allocated time interval. This is due to the characteristic variations in the computational time taken by evolutionary algorithms for same or varying size of the VRPSD instances. Therefore, this paper presents portfolios of different evolutionary algorithms to reduce the computational time taken to resolve the VRPSD. Moreover, an innovative concept of the mobility allowance (MA) in landmoves based on the levy’s distribution function has been introduced to cope with real situations existing in vehicle routing problems. The proposed portfolio approach has been evaluated for the varying instances of the VRPSD. Four of the existing metaheuristics including Genetic Algorithm (GA), Simulated Annealing (SA), Artificial Immune System (AIS), TABU Search (TS) along with new neighbourhood search, are incorporated in the portfolios. Experiments have been performed on varying dimensions of the VRPSD instances to validate the different properties of the algorithm portfolio. An illustrative example is presented to show that the set of metaheuristics allocated to certain number of processors (i.e. algorithm portfolio) performed better than their individual metaheuristics.",smart cities
10.1016/j.ijepes.2012.07.056,Journal,International Journal of Electrical Power and Energy Systems,scopus,2013-01-01,sciencedirect,Adaptive centralized protection scheme for distribution systems with DG using risk analysis for protective devices placement,https://api.elsevier.com/content/abstract/scopus_id/84866562718,"Conventional electric distribution systems are radial in nature, supplied at one end through a main source. These networks generally have a simple protection system usually implemented using fuses, re-closers, and over-current relays. Recently, great attention has been paid to applying Distributed Generation (DG) throughout electric distribution systems. Presence of such generation in a network leads to losing coordination of protection devices. Therefore, it is desired to develop an algorithm which is capable of protecting distribution systems that include DG, through diagnosis and isolation of faults. A new approach for the protection of distribution networks in the presence of DGs is presented in this paper. The algorithm is based on dividing an existing distribution network into several zones, each capable of operating in island operation. In the suggested method, risk analysis is used to optimize the protection zones by optimal placement of protective devices. Multilayer Perceptrons (MLPs) neural networks are used for determination of faults. The proposed scheme has been implemented on a selected part of a real distribution network of a large city and a MATLAB based developed software has been used to implement the proposed algorithm on the real network data.",smart cities
10.1016/j.freeradbiomed.2012.10.540,Journal,Free Radical Biology and Medicine,scopus,2012-12-15,sciencedirect,Real-time monitoring of superoxide accumulation and antioxidant activity in a brain slice model using an electrochemical cytochrome c biosensor,https://api.elsevier.com/content/abstract/scopus_id/84870210601,"The overproduction of reactive oxygen species and the resulting damage are central to the pathology of many diseases. The study of the temporal and spatial accumulation of reactive oxygen species has been limited because of the lack of specific probes and techniques capable of continuous measurement. We demonstrate the use of a miniaturized electrochemical cytochrome c (Cyt c) biosensor for real-time measurements and quantitative assessment of superoxide production and inactivation by natural and engineered antioxidants in acutely prepared brain slices from mice. Under control conditions, superoxide radicals produced from the hippocampal region of the brain in 400-μm-thick sections were well within the range of detection of the electrode. Exposure of the slices to ischemic conditions increased the superoxide production twofold and measurements from the slices were stable over a 3- to 4-h period. The stilbene derivative and anion channel inhibitor 4,4′-diisothiocyano-2,2′-disulfonic stilbene markedly reduced the extracellular superoxide signal under control conditions, suggesting that a transmembrane flux of superoxide into the extracellular space may occur as part of normal redox signaling. The specificity of the electrode for superoxide released by cells in the hippocampus was verified by the exogenous addition of superoxide dismutase (SOD), which decreased the superoxide signal in a dose-dependent manner. Similar results were seen with the addition of the SOD mimetic cerium oxide nanoparticles (nanoceria), in that the superoxide anion radical scavenging activity of nanoceria with an average diameter of 15 nm was equivalent to 527 U of SOD for each 1 μg/ml of nanoceria added. This study demonstrates the potential of electrochemical biosensors for studying real-time dynamics of reactive oxygen species in a biological model and the utility of these measurements in defining the relative contribution of superoxide to oxidative injury.",smart cities
10.1016/j.camwa.2012.01.079,Journal,Computers and Mathematics with Applications,scopus,2012-12-01,sciencedirect,Machine learning in agent-based stochastic simulation: Inferential theory and evaluation in transportation logistics,https://api.elsevier.com/content/abstract/scopus_id/84870236735,"Multiagent-based simulation is an approach to realize stochastic simulation where both the behavior of the modeled multiagent system and dynamic aspects of its environment are implemented with autonomous agents. Such simulation provides an ideal environment for intelligent agents to learn to perform their tasks before being deployed in a real-world environment. The presented research investigates theoretical and practical aspects of learning by autonomous agents within stochastic agent-based simulation. The theoretical work is based on the Inferential Theory of Learning, which describes learning processes from the perspective of a learner’s goal as a search through knowledge space. The theory is extended for approximate and probabilistic learning to account for the situations encountered when learning in stochastic environments. Practical aspects are exemplified by two use cases in autonomous logistics: learning predictive models for environment conditions in the future, and learning in the context of evolutionary plan optimization.",smart cities
10.1016/j.robot.2012.07.022,Journal,Robotics and Autonomous Systems,scopus,2012-12-01,sciencedirect,Spreading algorithm for efficient vegetation detection in cluttered outdoor environments,https://api.elsevier.com/content/abstract/scopus_id/84869087494,"This paper investigates the problem of detecting vegetation in unstructured environments for guiding an autonomous robot safely, exploiting its mobility capability in a cluttered outdoor environment. The aim is to create an adaptive learning algorithm which performs a quantitatively accurate detection that is fast enough for a real-time application. Chlorophyll-rich vegetation pixels are selected by thresholding vegetation indices, and then are considered as the seeds of a “spread vegetation”. For each seed pixel, a convex combination of color and texture dissimilarities is used to infer the difference between the pixel and its neighbors. The convex combination, trained via semi-supervised learning, models either the difference of vegetation pixels or the difference between a vegetation pixel and a non-vegetation pixel, and thus allows a greedy decision-making process to expand the spread vegetation, so-called vision-based spreading. To avoid overspreading, especially in the case of noise, a spreading scale is set. On the other hand, another vegetation spreading based on spectral reflectance is carried out in parallel. Finally, the intersection part resulting from both the vision-based and spectral reflectance-based methods is added to the spread vegetation. The approach takes into account both vision and chlorophyll light absorption properties. This enables the algorithm to capture much more detailed vegetation features than does prior art, and also give a much richer experience in the interpretation of vegetation representation, even for scenes with significant overexposure or underexposure as well as with the presence of shadow and sunshine. In all real-world experiments we carried out, our approach yields a detection accuracy of over 90%.",smart cities
10.1016/j.compind.2012.08.017,Journal,Computers in Industry,scopus,2012-12-01,sciencedirect,Evaluating alternative approaches to mobile object localization in wireless sensor networks with passive architecture,https://api.elsevier.com/content/abstract/scopus_id/84868489000,"In this study, we evaluate the performance of three types of techniques, namely neural based, Kalman filter based and trilateration based techniques, having been proposed to tackle the problem of real-time mobile sensor node tracking in a wireless sensor network with passive architecture. To investigate the performance of the aforementioned techniques under real-world circumstances, a small-scale wireless sensor network is deployed in an environment prone to multiple noise sources, multi-path and signal attenuation phenomena. The network makes use of a 433MHz MICA2 based Cricket platform, which is comprised of 6 Cricket motes, at least one of which is mobile. The network utilizes a passive architecture in which any mobile mote receives the Beacon signals to localize itself. Subsequently, a neural based approach is compared with a trilateration and a Kalman filter based technique. The results obtained corroborate the efficiency and advanced performance of the neural based approach.",smart cities
10.1016/j.jnca.2012.07.014,Journal,Journal of Network and Computer Applications,scopus,2012-11-01,sciencedirect,Termite-hill: Performance optimized swarm intelligence based routing algorithm for wireless sensor networks,https://api.elsevier.com/content/abstract/scopus_id/84867497191,"A wireless sensor network (WSN) is a large collection of sensor nodes with limited power supply, constrained memory capacity, processing capability, and available bandwidth. The main problem in event gathering in wireless sensor networks is the formation of energy-holes or hot spots near the sink. Due to the restricted communication range and high network density, events forwarding in sensor networks is very challenging, and require multi-hop data forwarding. Improving network lifetime and network reliability are the main factors to consider in the research associated with WSN. In static wireless sensor networks, sensors nodes close to the sink node run out of energy much faster than nodes in other parts of the monitored area. The nodes near the sink are more likely to use up their energy because they have to forward all the traffic generated by the nodes farther away to the sink. The uneven energy consumption results in network partitioning and limit the network lifetime. To this end, we propose an on-demand and multipath routing algorithm that utilizes the behavior of real termites on hill building termed Termite-hill which support sink mobility. The main objective of our proposed algorithm is to efficiently relay all the traffic destined for the sink, and also balance the network energy. The performance of our proposed algorithm was tested on static, dynamic and mobile sink scenarios with varying speed, and compared with other state-of-the-art routing algorithms in WSN. The results of our extensive experiments on Routing Modeling Application Simulation Environment (RMASE) demonstrated that our proposed routing algorithm was able to balance the network traffic load, and prolong the network lifetime.",smart cities
10.1016/j.cageo.2012.01.017,Journal,Computers and Geosciences,scopus,2012-11-01,sciencedirect,Ensemble modeling of transport and dispersion simulations guided by machine learning hypotheses generation,https://api.elsevier.com/content/abstract/scopus_id/84866151975,"In this article an approach is presented where machine learning classifiers are used to drive an ensemble modeling method of multiple atmospheric transport and dispersion simulations. The goal is to achieve a higher spread of the results with a lower number of ensemble simulations. Symbolic machine learning algorithms are used to define choices for the variation of meteorological input data, model parameters, model physics, based on their combined effects on the final dispersion calculations (i.e., construction of ensembles). The methodology uses an iterative approach with the aim to identify ensemble members leading to a more balanced distribution of results.
                  The methodology is tested using real meteorological data from Istanbul, Turkey, simulating atmospheric releases along the Bosphorus channel. In an extensive evaluation, different settings of the approach are compared in a series of experiments. The results indicate that the desired effect of more balanced results of the ensemble members can be achieved by the approach.",smart cities
10.1016/j.scitotenv.2012.07.014,Journal,Science of the Total Environment,scopus,2012-10-01,sciencedirect,Using recorded sound spectra profile as input data for real-time short-term urban road-traffic-flow estimation,https://api.elsevier.com/content/abstract/scopus_id/84864425621,"Road traffic has a heavy impact on the urban sound environment, constituting the main source of noise and widely dominating its spectral composition. In this context, our research investigates the use of recorded sound spectra as input data for the development of real-time short-term road traffic flow estimation models. For this, a series of models based on the use of Multilayer Perceptron Neural Networks, multiple linear regression, and the Fisher linear discriminant were implemented to estimate road traffic flow as well as to classify it according to the composition of heavy vehicles and motorcycles/mopeds. In view of the results, the use of the 50–400Hz and 1–2.5kHz frequency ranges as input variables in multilayer perceptron-based models successfully estimated urban road traffic flow with an average percentage of explained variance equal to 86%, while the classification of the urban road traffic flow gave an average success rate of 96.1%.",smart cities
10.1016/j.intimp.2012.06.014,Journal,International Immunopharmacology,scopus,2012-09-01,sciencedirect,Investigating the function of a novel protein from Anoectochilus formosanus which induced macrophage differentiation through TLR4-mediated NF-κB activation,https://api.elsevier.com/content/abstract/scopus_id/84863636852,"Anoectochilus formosanus is a therapeutic orchid appreciated as a traditional Chinese medicine in Asia. The extracts of A. formosanus have been reported to possess hepatoprotective, anti-inflammatory, and anti-tumor activates. A novel protein was isolated from A. formosanus, and its immunomodulatory effect on murine peritoneal macrophage was investigated. Macrophages obtained from ascites of thioglycollate-induced BALB/c were co-cultured with IPAF (0–20μg/ml) for 24h and then harvested for flow cytometry analysis. The cytokine/chemokine production was measured by real time PCR and ELISA. The interaction between IPAF and toll like receptors (TLRs) was investigated by TLR gene knockout (KO) mice and fluorescence labeled IPAF. The activation of NF-κB was assessed by EMSA. IPAF stimulated the TNF-α and IL-1β production, upregulated the CD86 and MHC II expression, and enhanced the phagocytic activity of macrophages. IPAF induced gene expression of IL-12 and Th1-assosiated cytokines/chemokines. The stimulating effect of IPAF was impaired, and the IPAF–macrophage interaction was reduced in TLR4−/− C57BL/10ScNJ mice. In addition, IPAF stimulated expressions of TLR signal-related genes and the activation of NF-κB. IPAF could induce classical activated macrophage differentiation via TLR4-dependent NF-κB activation and had potential of IPAF to modulate the Th1 response. These findings provided valuable information regarding the immune modulatory mechanism of A. formosanus, and indicated the possibility of IPAF as a potential peptide drug.",smart cities
10.1016/j.aap.2011.04.011,Journal,Accident Analysis and Prevention,scopus,2012-09-01,sciencedirect,How much benefit does Intelligent Speed Adaptation deliver? - An analysis of its potential contribution to safety and environment,https://api.elsevier.com/content/abstract/scopus_id/84861881609,"The UK Intelligent Speed Adaptation (ISA) project produced a rich database with high-resolution data on driver behaviour covering a comprehensive range of road environment. The field trials provided vital information on driver behaviour in the presence of ISA. The purpose of this paper is to exploit the information gathered in the field trials to predict the impacts of various forms of ISA and to assess whether ISA is viable in terms of benefit-to-cost ratio. ISA is predicted to save up to 33% of accidents on urban roads, and to reduce CO2 emissions by up to 5.8% on 70mph roads. In order to investigate the long-term impacts of ISA, two hypothetical deployment scenarios were envisaged covering a 60-year appraisal period. The results indicate that ISA could deliver a very healthy benefit-to-cost ratio, ranging from 3.4 to 7.4, depending on the deployment scenarios. Under both deployment scenarios, ISA has recovered its implementation costs in less than 15 years. It can be concluded that implementation of ISA is clearly justified from a social cost and benefit perspective. Of the two deployment scenarios, the Market Driven one is substantially outperformed by the Authority Driven one. The benefits of ISA on fuel saving and emission reduction are real but not substantial, in comparison with the benefits on accident reduction; up to 98% of benefits are attributable to accident savings. Indeed, ISA is predicted to lead to a savings of 30% in fatal crashes and 25% in serious crashes over the 60-year period modelled.",smart cities
10.1016/j.neunet.2012.02.036,Journal,Neural Networks,scopus,2012-08-01,sciencedirect,Metamodeling and the Critic-based approach to multi-level optimization,https://api.elsevier.com/content/abstract/scopus_id/84861762153,"Large-scale networks with hundreds of thousands of variables and constraints are becoming more and more common in logistics, communications, and distribution domains. Traditionally, the utility functions defined on such networks are optimized using some variation of Linear Programming, such as Mixed Integer Programming (MIP). Despite enormous progress both in hardware (multiprocessor systems and specialized processors) and software (Gurobi) we are reaching the limits of what these tools can handle in real time. Modern logistic problems, for example, call for expanding the problem both vertically (from one day up to several days) and horizontally (combining separate solution stages into an integrated model). The complexity of such integrated models calls for alternative methods of solution, such as Approximate Dynamic Programming (ADP), which provide a further increase in the performance necessary for the daily operation. In this paper, we present the theoretical basis and related experiments for solving the multistage decision problems based on the results obtained for shorter periods, as building blocks for the models and the solution, via Critic-Model-Action cycles, where various types of neural networks are combined with traditional MIP models in a unified optimization system. In this system architecture, fast and simple feed-forward networks are trained to reasonably initialize more complicated recurrent networks, which serve as approximators of the value function (Critic). The combination of interrelated neural networks and optimization modules allows for multiple queries for the same system, providing flexibility and optimizing performance for large-scale real-life problems. A MATLAB implementation of our solution procedure for a realistic set of data and constraints shows promising results, compared to the iterative MIP approach.",smart cities
10.1016/j.jtice.2011.11.006,Journal,Journal of the Taiwan Institute of Chemical Engineers,scopus,2012-05-01,sciencedirect,"Mathematical modeling, optimal design and control of an SCR reactor for NOx removal",https://api.elsevier.com/content/abstract/scopus_id/84860316497,"The elimination of nitrogen oxides (NOx) is an important issue for global environment. This paper deals with the model development, optimal design and feedback control of an SCR (selective catalytic reduction) reactor for NOx removal. A 3D dynamic simulation model for use to investigate the reaction behavior and the transport phenomena in the catalytic filter of the SCR reactor is proposed. To estimate the model's kinetic parameters from experimental data, an optimization technique that integrates Taguchi method, a real-coded genetic algorithm and a neural network auxiliary model is developed. With the proposed dynamic model, we investigated the effects of the key parameters, such as the gas hourly space velocity, operating temperature and the amount of ammonium used, on the NOx conversion and NH3 slip phenomena. To improve the NOx abatement performance, the proposed optimization technique is then applied to search for a set of best operation conditions for the SCR reactor. The obtained results indicate that the optimized SCR can achieve the NOx reduction rate up to 99.93%, which is over 9% better in performance than the previously reported one in the literature. Besides, the optimal operating temperature is considerably lower and the emission of ammonium from the reactor is insignificant. Compared with conventional designs, the proposed design is much better in energy savings and is environment-friendly. To attenuate the negative effects of environmental disturbances on reactor's performance, we implemented a direct adaptive control strategy to the SCR reactor. The stability of the control system is theoretically guaranteed with a Lyapunov-based approach. Extensive simulation results show that the learning-type, nonlinear control strategy presents significantly much better NOx reduction performance than a conventional IMC-PI controller, especially when facing process uncertainties and disturbances.",smart cities
10.1016/j.aap.2011.08.004,Journal,Accident Analysis and Prevention,scopus,2012-03-01,sciencedirect,A Bayesian network based framework for real-time crash prediction on the basic freeway segments of urban expressways,https://api.elsevier.com/content/abstract/scopus_id/84856100242,"The concept of measuring the crash risk for a very short time window in near future is gaining more practicality due to the recent advancements in the fields of information systems and traffic sensor technology. Although some real-time crash prediction models have already been proposed, they are still primitive in nature and require substantial improvements to be implemented in real-life. This manuscript investigates the major shortcomings of the existing models and offers solutions to overcome them with an improved framework and modeling method. It employs random multinomial logit model to identify the most important predictors as well as the most suitable detector locations to acquire data to build such a model. Afterwards, it applies Bayesian belief net (BBN) to build the real-time crash prediction model. The model has been constructed using high resolution detector data collected from Shibuya 3 and Shinjuku 4 expressways under the jurisdiction of Tokyo Metropolitan Expressway Company Limited, Japan. It has been specifically built for the basic freeway segments and it predicts the chance of formation of a hazardous traffic condition within the next 4–9min for a particular 250 meter long road section. The performance evaluation results reflect that at an average threshold value the model is able to successful classify 66% of the future crashes with a false alarm rate less than 20%.",smart cities
10.1016/j.asoc.2011.10.016,Journal,Applied Soft Computing Journal,scopus,2012-02-01,sciencedirect,Soft computing methods applied to train station parking in urban rail transit,https://api.elsevier.com/content/abstract/scopus_id/84655165069,"This paper presents three models – a linear model, a generalized regression neural network (GRNN) and an adaptive network based fuzzy inference system (ANFIS) – to estimate the train station parking (TSP) error in urban rail transit. We also develop some statistical indices to evaluate the reliability of controlling parking errors in a certain range. By comparing modeling errors, the subtractive clustering method other than grid partition method is chosen to generate an initial fuzzy system for ANFIS. Then, the collected TSP data from two railway stations are employed to identify the parameters of the proposed three models. The three models can make the average parking errors under an acceptable error, and tuning the parameters of the models is effective in dynamically reducing parking errors. Experiments in two stations indicate that, among the three models, (1) the linear model ranks the third in training and the second in testing, nevertheless, it can meet the required reliability for two stations, (2) the GRNN based model achieves the best performance in training, but the poorest one in testing due to overfitting, resulting in failing to meet the required reliability for the two stations, (3) the ANFIS based model obtains better performance than model 1 both in training and testing. After analyzing parking error characteristics and developing a parking strategy, finally, we confirm the effectiveness of the proposed ANFIS model in the real-world application.",smart cities
10.1016/j.psym.2011.07.004,Journal,Psychosomatics,scopus,2012-01-01,sciencedirect,Impact of Integrated and Measurement-Based Depression Care: Clinical Experience in an HIV Clinic,https://api.elsevier.com/content/abstract/scopus_id/84859559400,"Background
                  Just as in heart disease and diabetes, depression in HIV/AIDS is associated with negative outcomes. While randomized trials have shown the efficacy of treatment for depression in HIV/AIDS, the implementation of evidence-based treatments in real-world settings remains a challenge.
               
                  Objective
                  The objective of this study was to assess the effectiveness of a collaborative, measurement-based approach to depression care, including psychopharmacologic and ancillary psychological therapies in patients with HIV/AIDS and to examine whether or not effective depression treatment would also improve virologic and immunologic outcomes.
               
                  Methods
                  This was a retrospective chart review of patients referred for depression to a co-located psychiatry consultation service embedded within an infectious diseases outpatient clinic at an urban tertiary hospital. Data extracted at initial assessment and at last appointment included: axis I diagnosis, whether the patient was on an antidepressant, whether the patient was on a stimulant, BDI-II score, HIV RNA level, and CD4 cell count.
               
                  Results
                  One hundred twenty-four patient charts were included. Pre- vs. post-treatment analyses revealed significant reductions in depression (average BDI-II score of 23 to 15.7, p = 0.00001) and HIV RNA (14.1 K to 4 K copies/mL, p = 0 .003), and significant increases in CD4 count (518 to 592 cells/μL, p = 0.001). Additionally, more participants were prescribed antidepressants and stimulants at post- vs. pre-treatment.
               
                  Conclusion
                  Taking a collaborative, measurement-based approach to depression care appears to be an effective method for improving depression, virologic, and immunologic outcomes in depressed patients with HIV/AIDS illness.",smart cities
10.1016/j.vetimm.2011.07.015,Journal,Veterinary Immunology and Immunopathology,scopus,2011-11-15,sciencedirect,Transfer of maternal haptoglobin to suckling piglets,https://api.elsevier.com/content/abstract/scopus_id/82555167028,"The acute phase protein haptoglobin (Hp) exerts immune modulating functions in the innate and adaptive immune system. In pigs, serum Hp concentrations are linked to impaired growth performance. There is little information on Hp in newborn piglets and the onset of endogenous Hp synthesis. In the first experiment we analyzed Hp concentrations in colostrum from sows (n
                     =5) and serum from their off-spring (n
                     =43) during the first 12h of life. The piglets were divided in a colostrum group which was allowed to suckle and a colostrum-deprived group which received a Hp-free milk replacer. We were able to show that serum Hp in newborn piglets increased 3h after colostrum intake whereas serum Hp remained low in colostrum-deprived littermates. The absorption of colostral Hp in the jejunum could be shown via immunohistochemistry. In colostrum suckled piglets, endogenous Hp synthesis in the liver increased 9h after birth, no increase in Hp mRNA was observable during the first 12h of life in colostrum-deprived piglets. From our results we concluded that maternal Hp is transferred to newborn pigs via colostrum and the stimulus for the increase in Hp synthesis is mediated by colostrum. In a second experiment we analyzed Hp in colostrum, milk and serum from sows (n
                     =43) and their off-spring (n
                     =442) from birth until weaning. Haptoglobin was high in colostrum (1.11±0.10mg/ml) and declined to lower but stable milk levels (0.36±0.08mg/ml) until weaning. Colostral Hp and daily litter weight gain were negatively correlated (r
                     =−0.5, p
                     <0.01) whereas the relationship between piglets serum Hp and daily weight gain was weaker (r
                     =−0.22, p
                     <0.05). We therefore speculate that maternal Hp exerts systemic actions in piglets.",smart cities
10.1016/j.eswa.2011.06.014,Journal,Expert Systems with Applications,scopus,2011-11-01,sciencedirect,Fuzzy UTASTAR: A method for discovering utility functions from fuzzy data,https://api.elsevier.com/content/abstract/scopus_id/80052038606,"We propose Fuzzy UTASTAR, a method for inferring fuzzy utility functions from a partial preorder of options evaluated on multiple criteria. It is an extension of the well-known UTASTAR method capable to handle both ordinary (crisp) and fuzzy evaluation data. This property gives much flexibility to decision makers because the majority of real-life decision problems involve a considerable level of uncertainty that hinders them from assigning exact evaluations (scores) to options. In case all evaluation data are crisp the method behaves exactly as the original UTASTAR. The proposed method builds fuzzy additive value functions taking as input a partial preorder on a subset of the options, called reference set, along with their associated scores on the criteria. The resulting fuzzy utility functions can subsequently be used to estimate the (fuzzy) utility of each option, thus allowing their ranking, prioritization, selection or classification. The ranking of the options in partial preorder is as compatible as possible to the original one. The method is implemented into a decision support system and is applied to an example from the transportation domain. Results are found to be in concordance with those of the original method. To the best of our knowledge this is the first attempt to extend UTASTAR method to handle both crisp and fuzzy evaluation data.",smart cities
10.1016/j.compbiomed.2011.05.016,Journal,Computers in Biology and Medicine,scopus,2011-08-01,sciencedirect,Robust prediction of protein subcellular localization combining PCA and WSVMs,https://api.elsevier.com/content/abstract/scopus_id/79960619282,"Automated prediction of protein subcellular localization is an important tool for genome annotation and drug discovery, and Support Vector Machines (SVMs) can effectively solve this problem in a supervised manner. However, the datasets obtained from real experiments are likely to contain outliers or noises, which can lead to poor generalization ability and classification accuracy. To explore this problem, we adopt strategies to lower the effect of outliers. First we design a method based on Weighted SVMs, different weights are assigned to different data points, so the training algorithm will learn the decision boundary according to the relative importance of the data points. Second we analyse the influence of Principal Component Analysis (PCA) on WSVM classification, propose a hybrid classifier combining merits of both PCA and WSVM. After performing dimension reduction operations on the datasets, kernel-based possibilistic c-means algorithm can generate more suitable weights for the training, as PCA transforms the data into a new coordinate system with largest variances affected greatly by the outliers. Experiments on benchmark datasets show promising results, which confirms the effectiveness of the proposed method in terms of prediction accuracy.",smart cities
10.1016/j.bbrc.2011.04.008,Journal,Biochemical and Biophysical Research Communications,scopus,2011-05-06,sciencedirect,Hydrogen inhalation reduced epithelial apoptosis in ventilator-induced lung injury via a mechanism involving nuclear factor-kappa B activation,https://api.elsevier.com/content/abstract/scopus_id/79955665169,"We recently demonstrated the inhalation of hydrogen gas, a novel medical therapeutic gas, ameliorates ventilator-induced lung injury (VILI); however, the molecular mechanisms by which hydrogen ameliorates VILI remain unclear. Therefore, we investigated whether inhaled hydrogen gas modulates the nuclear factor-kappa B (NFκB) signaling pathway. VILI was generated in male C57BL6 mice by performing a tracheostomy and placing the mice on a mechanical ventilator (tidal volume of 30ml/kg or 10ml/kg without positive end-expiratory pressure). The ventilator delivered either 2% nitrogen or 2% hydrogen in balanced air. NFκB activation, as indicated by NFκB DNA binding, was detected by electrophoretic mobility shift assays and enzyme-linked immunosorbent assay. Hydrogen gas inhalation increased NFκB DNA binding after 1h of ventilation and decreased NFκB DNA binding after 2h of ventilation, as compared with controls. The early activation of NFκB during hydrogen treatment was correlated with elevated levels of the antiapoptotic protein Bcl-2 and decreased levels of Bax. Hydrogen inhalation increased oxygen tension, decreased lung edema, and decreased the expression of proinflammatory mediators. Chemical inhibition of early NFκB activation using SN50 reversed these protective effects. NFκB activation and an associated increase in the expression of Bcl-2 may contribute, in part, to the cytoprotective effects of hydrogen against apoptotic and inflammatory signaling pathway activation during VILI.",smart cities
10.1016/j.knosys.2011.01.007,Journal,Knowledge-Based Systems,scopus,2011-05-01,sciencedirect,A knowledge-based problem solving method in GIS application,https://api.elsevier.com/content/abstract/scopus_id/79952451251,"Model design for theme analysis is one of the biggest challenges in GIS. Many real applications in GIS require functioning not only in data management and visualization, but also in analysis and decision-making. Confronted with an application of planning a new metro line in a city, a typical GIS is unable to accomplish the task in the absence of human experts or artificial intelligence technologies. Apart from being models for analyzing in different themes, some applications are also instances of problem solving in AI. Therefore, in order to strengthen its ability in automatic analysis, many theories and technologies from AI can be embedded in the GIS. In this paper, a state space is defined to formalize the metro line planning problem. By utilizing the defined state evaluation function, knowledge-based rules and strategies, a heuristic searching method is developed to optimize the solutions iteratively. Experiments are implemented to illuminate the validity of this AI-enhanced automatic analysis model of GIS.",smart cities
10.1016/j.egypro.2011.02.530,Conference Proceeding,Energy Procedia,scopus,2011-01-01,sciencedirect,The CO<inf>2</inf>CRC Otway Project: Leveraging experience and exploiting new opportunities at Australia's first CCS project site,https://api.elsevier.com/content/abstract/scopus_id/79955425420,"The Cooperative Research Centre for Greenhouse Gas Technologies (CO2CRC) is undertaking Australia’s first geosequestration research and demonstration project in the onshore Otway Basin, south-eastern Australia, in order to demonstrate transport and geological storage of carbon dioxide (CO2), test scientific and regulatory concepts relating to CO2 storage and evaluate public response through stakeholder engagement.
                  Stage one of the CO2CRC Otway Project (the Project) has successfully injected over 65,000 tonnes of CO2-rich gas (80% carbon dioxide; 20% methane) into a depleted natural gas reservoir. An exhaustive data set of pre- and post-injection monitoring information has been collected across the atmospheric, near-surface and sub-surface domains. These monitoring results have been largely consistent with the modelling predictions thereby adding confidence to both the approach and validity of the sub-surface realisations. Public confidence has benefited from this and allowed the CO2CRC to look at exploiting new opportunities at the Otway Project site that serve to optimise the existing infrastructure.
                  Otway Stage two is based on injection into a heterogeneous formation with no apparent structural closure with the principal objective of understanding trapping mechanisms in deep saline formations. A research program has been developed adapting the “Huff and Puff” technique to better understand the key parameters impacting residual trapping.
                  The key challenges faced by the Project have been both technical and legislative. These have included getting the original project approved in the absence of legislation dedicated to carbon storage and managing the transition of these multi-jurisdictional legislative approvals to the new carbon storage legislation passed by the Victorian State Government in 2008.
                  The Otway Project has provided the Victorian Government with a valuable practical case study from which to draw learnings for developing policy and regulatory frameworks for carbon capture and storage (CCS). As the Victorian Government brought Australia’s first standalone carbon storage legislation (based on petroleum legislation) into operation in December 2009, some unique insights have been identified through the Otway Project. These include an understanding of stakeholder perception through the Project’s community engagement activities and more recently, on how an existing research and demonstration project could be bridged to a newly introduced legislative regime. Other jurisdictions with CCS projects are likely to find these projectbased learnings of great value, particularly, in developing regulatory frameworks and a risk communication strategy.
                  The Otway Project is currently Australia’s only active storage project and in addition to performing important storage research, is a key driver for enhancing community confidence towards CCS. These are all critical considerations for accelerating commercial deployment of CCS and the Project is playing an important part in turning research into reality.
                  We summarise Stage one of the project, capture the knowledge gained and describe the approach taken in Stage two to utilise the sub-surface and infrastructure available to address key research questions while continuing to build public confidence for CCS as a mitigation mechanism.",smart cities
10.1016/j.urology.2010.07.514,Journal,Urology,scopus,2011-01-01,sciencedirect,"Effect of Serenoa repens, lyocopene, and selenium on proinflammatory IκB-α phenotype activation: An in vitro and in vivo comparison study",https://api.elsevier.com/content/abstract/scopus_id/78650859515,"Objectives
                  To investigate the antiinflammatory activity of Serenoa repens (SeR), LY, and) on proinflammatory phenotype in rat peritoneal macrophages (Ms) stimulated with Salmonella enteritidis lipopolysaccharid (LPS) and in the prostate of rats with partial bladder outlet obstruction. SeR, combined with other compounds, such as LY and Se is used to relieve symptoms associated with benign prostatic hyperplasia (BPH). Inflammation plays a pivotal role in the pathogenesis of BPH and represents a target for anti-BPH drugs.
               
                  Methods
                  After stimulation with 1 μg/mL of LPS, peritoneal rat MΦs were coincubated with LY (2 μg/mL), Se (0.03 μg/mL), and SeR (10 μg/mL), alone or in association (LY-Se–SeR) and with RPMI. Inducible cyclooxygenase (COX-2), 5-lypoxygenase (5-LOX), inducible nitric oxide synthase (iNOS), and inhibitor κBα (IκB-α) protein were evaluated by Western blot. Nuclear factor-kappa B (NF-κB) binding activity was measured by electrophoretic mobility shift assay. Tumor necrosis factor–α (TNF-α) gene expression was investigated by real-time polymerase chain reaction. We also evaluated malondialdehyde (MDA) and nitrite levels.
               
                  Results
                  LPS stimulation produced a proinflammatory phenotype in rat peritoneal MΦs. LY, Se, and SeR inhibited the inflammatory cascade, but the Ly-Se-SeR association caused a greater inhibitory effect on the expression of COX-2, 5-LOX, and iNOS. The Ly-Se-SeR association showed a higher efficacy in reducing the loss of IκB-α, the increased NF-κB binding activity, the enhanced mRNA levels of TNF-α, the elevated MDA, and nitrite content. The LY-Se-SeR association in vivo caused a greater inhibitory effect on prostate inflammation induced in rats by partial bladder outlet obstruction.
               
                  Conclusions
                  The LY-Se-SeR association might be useful in the treatment of BPH.",smart cities
10.1016/j.ejor.2010.01.026,Journal,European Journal of Operational Research,scopus,2010-09-16,sciencedirect,A travel demand management strategy: The downtown space reservation system,https://api.elsevier.com/content/abstract/scopus_id/77949310027,"In this paper, a Travel Demand Management strategy known as the Downtown Space Reservation System (DSRS) is introduced. The purpose of this system is to facilitate the mitigation of traffic congestion in a cordon-based downtown area by requiring people who want to drive into this area to make reservations in advance. An integer programming formulation is provided to obtain the optimal mix of vehicles and trips that are characterized by a series of factors such as vehicle occupancy, departure time, and trip length with an objective of maximizing total system throughput and revenue. Based upon the optimal solution, an “intelligent” module is built using artificial neural networks that enables the transportation authority to make decisions in real time on whether to accept an incoming request. An example is provided that demonstrates that the solution of the “intelligent” module resembles the optimal solution with an acceptable error rate. Finally, implementation issues of the DSRS are addressed.",smart cities
10.1016/j.lfs.2010.06.016,Journal,Life Sciences,scopus,2010-08-01,sciencedirect,New anti-fibrotic mechanisms of n-acetyl-seryl-aspartyl-lysyl-proline in silicon dioxide-induced silicosis,https://api.elsevier.com/content/abstract/scopus_id/77955274084,"Aims
                  We previously reported that tetrapeptide N-acetyl-seryl-aspartyl-lysyl-proline (Ac-SDKP) inhibited pulmonary inflammation and fibrosis in SiO2-induced silicosis. This study aimed to explore the precise mechanism involved.
               
                  Main methods
                  Rats were divided into 3 groups: 1) sham (saline), 2) silicosis+vehicle, and 3) silicosis+Ac-SDKP [800μg/(kgd)]. SiO2 particles or saline were administered by tracheal instillation and Ac-SDKP or vehicle (saline) via a miniosmotic pump planted into the abdominal cavity 48h before instillation. Animals were observed for 4weeks. Silicotic nodule fraction (SNF) and macrophage infiltration (ED-1 positive cells) were measured by hematoxylin and eosin (H.E.) and immunohistochemical staining respectively. Collagen I and III, transforming growth factor-β1 (TGF-β1) proteins and monocyte chemotactic protein-1 (MCP-1) mRNA were detected by Western Blot (WB) and real-time RT-PCR respectively. In vitro, pulmonary fibroblasts were stimulated by TGF-β1 (5μg/ml) with or without Ac-SDKP. Phosphorylated c-Jun N-terminal Kinase (p-JNK) was detected by WB and p-JNK nuclear translocation by confocal analysis.
               
                  Key findings
                  SiO2 significantly increased the SNF, collagen I and III proteins, TGF-β1, MCP-1 mRNA and macrophage infiltration. All these pathological changes were inhibited by Ac-SDKP. TGF-β1 resulted in fibroblast proliferation, increased expression of collagen I and III proteins, p-JNK and its subsequent nuclear translocation. Addition of Ac-SDKP markedly suppressed these changes.
               
                  Significance
                  These data indicate that the anti-fibrotic effect of Ac-SDKP in silicosis is mediated by inhibiting chronic inflammation, TGF-β1 production, and TGF-β1-induced pulmonary fibroblast proliferation and collagen synthesis.",smart cities
10.1016/j.intimp.2010.04.020,Journal,International Immunopharmacology,scopus,2010-08-01,sciencedirect,Effects of hydroxyethyl starch (130kD) on brain inflammatory response and outcome during normotensive sepsis,https://api.elsevier.com/content/abstract/scopus_id/77954956543,"Background
                  During sepsis, the dysfunction of blood–brain barrier (BBB) was mediated by inflammation and subsequently caused sepsis-associated encephalopathy. Hydroxyethyl starch (HES, 130/0.4) is most widely used for volume replacement to maintain or improve tissue perfusion in patients with sepsis, trauma, and shock. This study was undertaken to investigate the effects of HES on BBB permeability, brain edema, inflammatory response and clinical outcome in septic rats.
               
                  Methods
                  Using the cecal ligation and puncture (CLP) model, Sprague–Dawley rats were treated with 15ml/kg HES or normal saline 4h after the operation. Two hours later, expressions of brain toll-like receptor (TLR)-2, TLR4 and intercellular adhesion molecule (ICAM)-1 mRNA was determined by real-time reverse transcription-polymerase chain reaction; inflammatory cytokines like tumor necrosis factor (TNF)-α and interleukin (IL)-6 by enzyme-linked immunosorbent assay; activity of nuclear factor-kappa B (NF-κB) by electrophoretic mobility shift assay; BBB permeability by Evans blue extravasation method; brain edema by wet/dry weight ratio. Weight loss, and clinical symptoms were also observed.
               
                  Results
                  Without obvious influence on systemic macrohemodynamics, HES could markedly attenuate BBB dysfunction and brain edema. Meanwhile, HES could significantly reduce TNF-α, IL-6, and ICAM-1 mRNA, inhibit NF-κB activation, and down-regulate TLR2 and TLR4 expression in the brain. In addition, CLP-induced increase in weight loss, and clinical symptoms was not reduced after treatment with HES.
               
                  Conclusions
                  HES could ameliorate BBB dysfunction and inflammation mediators by modulating brain TLR2 and TLR4 expression during sepsis. However, HES could not improve clinical outcome.",smart cities
10.1016/j.cl.2009.09.003,Journal,"Computer Languages, Systems and Structures",scopus,2010-07-01,sciencedirect,A platform for the automatic generation of attribute evaluation hardware systems,https://api.elsevier.com/content/abstract/scopus_id/72049097164,"Attribute grammars (AG) allow the addition of context-sensitive properties into context free grammars, augmenting their expressional capabilities by using syntactic and semantic notations, making them in this way a really useful tool for a considerable number of applications. AGs have extensively been utilized in applications such as artificial intelligence, structural pattern recognition, compiler construction and even text editing. Obviously, the performance of an attribute evaluation system resides in the efficiency of the syntactic and semantic subsystems. In this paper, a hardware architecture for an attribute evaluation system is presented, which is based on an efficient combinatorial implementation of Earley's parallel parsing algorithm for the syntax part of the attribute grammar. The semantic part is managed by a special purpose module that traverses the parse tree and evaluates the attributes based on a proposed stack-based approach. The entire system is described in Verilog HDL (hardware design language), in a template form that given the specification of an arbitrary attribute grammar, the HDL synthesizable source code of the system is produced on the fly by a proposed automated tool. The generated code has been simulated for validation, synthesized and tested on an Xilinx FPGA (field programmable gate arrays) board for various AGs. Our method increases the performance up to three orders of magnitude compared to previous approaches, depending on the implementation, the size of the grammar and the input string length. This makes it particularly appealing for applications where attribute evaluation is a crucial aspect, like in real-time and embedded systems. Specifically, a natural language interface is presented, based on a question-answering application from the area of airline flights.",smart cities
10.1016/j.aquatox.2009.12.014,Journal,Aquatic Toxicology,scopus,2010-05-10,sciencedirect,Effects of brevetoxin exposure on the immune system of loggerhead sea turtles,https://api.elsevier.com/content/abstract/scopus_id/77950858402,"Blooms of the toxic dinoflagellate, Karenia brevis, occur almost annually off the Florida coast. These blooms, commonly called “red tides”, produce a group of neurotoxins collectively termed brevetoxins. Many species of sealife, including sea turtles, are severely impacted by brevetoxin exposure. Effects of brevetoxins on immune cells were investigated in rescued loggerhead sea turtles, Caretta caretta, as well as through in vitro experiments using peripheral blood leukocytes (PBL) collected from captive sea turtles. In rescued animals, plasma brevetoxin concentrations were measured using a competitive ELISA. Plasma lysozyme activity was measured using a turbidity assay. Lysozyme activity correlated positively with plasma brevetoxin concentrations. Differential expression of genes affected by brevetoxin exposure was determined using two separate suppression subtractive hybridization experiments. In one experiment, genes from PBL collected from sea turtles rescued from red tide toxin exposure were compared to genes from PBL collected from healthy captive loggerhead sea turtles. In the second experiment, PBL from healthy captive loggerhead sea turtles were exposed to brevetoxin (500ng PbTx-2/ml) in vitro for 18h and compared to unexposed PBL. Results from the subtraction hybridization experiment conducted with red tide rescued sea turtle PBL indicated that genes involved in oxidative stress or xenobiotic metabolism were up-regulated. Using quantitative real-time PCR, a greater than 2-fold increase in superoxide dismutase and thioredoxin and greater than 10-fold increase in expression of thiopurine S-methyltransferase were observed. Results from the in vitro subtraction hybridization experiment indicated that genes coding for cytochrome c oxidases were the major up-regulated genes. Using quantitative real-time PCR, a greater than 8-fold increase in expression of β-tubulin and greater than 3-fold increase in expression of ubiquinol were observed. Brevetoxin exposure may have significant implications for immune function in loggerhead sea turtles.",smart cities
10.1016/j.neunet.2009.06.006,Journal,Neural Networks,scopus,2010-04-01,sciencedirect,Evaluation of atmospheric Poaceae pollen concentration using a neural network applied to a coastal Atlantic climate region,https://api.elsevier.com/content/abstract/scopus_id/76849100176,"In the South of Europe an important percentage of population suffers pollen allergies, being the Poaceae pollen the major source. One of aerobiology’s objectives is to develop statistical models enabling the short- and long-term prediction of atmospheric pollen concentrations to take preventative measures to protect allergic patients from the severity of the atmospheric pollen season. The implementation of a computational model based on supervised MLP neural network was applied for the prediction of the atmospheric Poaceae pollen concentration. There is a good correlation between the values predicted by the ANN for the training cases in comparison with the real pollen concentrations. A high coefficient of linear regression 
                        
                           (
                           
                              
                                 R
                              
                              
                                 2
                              
                           
                           )
                        
                      of 0.9696 was obtained. The accuracy of the neural network developed was tested with data from 2006 and 2007, which was not taken into account to establish the aforementioned models. Neural networks provided us a good tool to forecasting allergenic airborne pollen concentration helping the automation of the prediction system in the aerobiological information diffusion to the population suffering from allergic problems.",smart cities
10.1016/j.eswa.2009.07.025,Journal,Expert Systems with Applications,scopus,2010-03-15,sciencedirect,Find multi-objective paths in stochastic networks via chaotic immune PSO,https://api.elsevier.com/content/abstract/scopus_id/70449520180,"Path finding is a fundamental research topic in transportation planning, intelligent transportation system, routine selection, etc. It is usually simplified as the shortest path (SP) in deterministic networks. However, some parameters in real life are stochastic. In this article, a more pragmatic model for stochastic networks was proposed, which not only considers determinist variables but also the mean and variances of random variables. In order to fasten the solution of our model, a novel method was proposed, which combines artificial immune system (AIS), chaos operator, and particle swarm optimization (PSO). Numerical experiments were presented to demonstrate that this proposed model is valid, effective, and more close to real-life, and CIPSO outperforms GA and PSO in respect of route optimality and convergence time.",smart cities
10.1016/j.jenvman.2009.11.006,Journal,Journal of Environmental Management,scopus,2010-03-01,sciencedirect,Dynamic sorption of ammonium by sandy soil in fixed bed columns: Evaluation of equilibrium and non-equilibrium transport processes,https://api.elsevier.com/content/abstract/scopus_id/77949264159,"The release of excess nitrogen-containing compounds into groundwater is a major concern in aquifer recharge by the Soil Aquifer Treatment (SAT) process. Ammonium (
                        
                           N
                           
                              H
                              4
                              +
                           
                        
                     ) is one of the most nocive and common nitrogen compounds in wastewaters. In order to assess the risk of wastewater use for aquifer recharge,
                        
                           N
                           
                              H
                              4
                              +
                           
                        
                     adsorption onto Souhil wadi soil sampled from the SAT pilot plant (Nabeul, Tunisia) was studied using laboratory columns experiments. Several experiments were conducted using aqueous synthetic solutions under different aqueous ammonium concentrations and flow rates. Furthermore, a real wastewater solution was used to test the effect of competitive cations contents on 
                        
                           N
                           
                              H
                              4
                              +
                           
                        
                      adsorption. Afterwards, the Hydrus-1D model was used in inverse mode to simulate the ammonium transport through the Souhil wadi soil.
                  For the synthetic solutions, the adsorbed ammonium amount varied from 1 to 30.7 mg kg−1 for aqueous ammonium concentrations between 4.9 and 36.4 mg L−1. The linear isotherm model was found to be the most suitable for describing this adsorption. The flow rate decrease from 45 to 15 mL min−1 induced an increase in the ammonium adsorption capacity by 49%. Indeed, the lesser the flow rate is, the longer the residence time and the higher the exchange between the aqueous solution and soil matrix. The use of wastewater instead of aqueous synthetic solution decreased about 7 times the Souhil wadi adsorption capacity of ammonium because of its relatively high concentrations of competitive ions such as calcium and magnesium.
                  The use of the Hydrus-1D model showed that the chemical non-equilibrium model was the best to simulate the ammonium transport through the laboratory soil columns.",smart cities
10.1016/j.trc.2009.06.004,Journal,Transportation Research Part C: Emerging Technologies,scopus,2010-01-01,sciencedirect,Intelligent computing methods in Air Traffic Flow Management,https://api.elsevier.com/content/abstract/scopus_id/77953356855,"This research presents the application of intelligent computing models in Air Traffic Flow Management (ATFM). Firstly, multi-agent system in grid computing environment is applied to deal with the problem of ATFM synchronization. The developed system consists of software agents, which are implemented in a Computational Grid platform for congestions identification, conflicts resolution and agreements negotiation among the participating airports. A metric criterion, called Agent’s Balancing Standard (ABS), is used as a basic index to measure the effectiveness of reducing both the amount of communication among agents and the delay of flights. Secondly, a brief discussion about the Meta-Level Control model is introduced in ATFM issues to improve the efficiency of communication among the agents. The system is developed to analyze the traffic flow information received, identify its importance and process it in the most adequate order.",smart cities
10.1016/j.watres.2009.12.013,Journal,Water Research,scopus,2010-01-01,sciencedirect,Indigenous somatic coliphage removal from a real municipal wastewater by a submerged membrane bioreactor,https://api.elsevier.com/content/abstract/scopus_id/76949094804,"The membrane bioreactor (MBR) features many advantages, such as its excellent effluent quality and compactness. Moreover, the MBR is well known for its disinfectant capacity. This paper investigates virus removal performance for municipal wastewater using a submerged MBR and the operational conditions affecting the virus removal using indigenous somatic coliphages (SC) as an indicator for viruses. The results revealed that the municipal wastewater acquired by the Qinghe Municipal Wastewater Treatment Plant, Beijing, contained an SC concentration of (2.81±1.51)×104
                     PFU ml−1, which varies seasonally due to spontaneous decay. In the MBR system, the biomass process dominates SC removal. Membrane rejection is an essential supplement of biomass process for SC removal. In this paper, the relative contributions of biomass process and membrane rejection during the start-up and steady operational periods are discussed in detail. The major factors affecting SC removal are biodegradation, membrane pore size, and gel layer formation on the membrane. During long-term experiments, it was demonstrated that high inoculated sludge concentration, long hydraulic retention time, moderate fouling layer, and non-frequent chemical cleaning are favorable for high SC removal in MBR systems.",smart cities
10.1016/j.ejor.2008.11.024,Journal,European Journal of Operational Research,scopus,2009-11-16,sciencedirect,"Tactical level planning in float glass manufacturing with co-production, random yields and substitutable products",https://api.elsevier.com/content/abstract/scopus_id/67349125429,"We investigate tactical level planning problems in float glass manufacturing. Float glass manufacturing is a process that has some unique properties such as uninterruptible production, random yields, partially controllable co-production compositions, complex relationships in sequencing of products, and substitutable products. Furthermore, changeover times and costs are very high, and production speed depends significantly on the product mix. These characteristics render measurement and management of the production capacity difficult. The motivation for this study is a real life problem faced at Trakya Cam in Turkey. Trakya Cam has multiple geographically separated production facilities. Since transportation of glass is expensive, logistics costs are high. In this paper, we consider multi-site aggregate planning, and color campaign duration and product mix planning. We develop a decision support system based on several mixed integer linear programming models in which production and transportation decisions are made simultaneously. The system has been fully implemented, and has been in use at Trakya Cam since 2005.",smart cities
10.1016/j.eswa.2009.01.049,Journal,Expert Systems with Applications,scopus,2009-09-01,sciencedirect,MamMoeT: An intelligent agent-based communication support platform for multimodal transport,https://api.elsevier.com/content/abstract/scopus_id/67349254167,"In this paper, an intelligent agent-based communication support platform for multimodal transport is developed. The rationale for doing so is found in the potential of such a system to increase cost efficiency, service and safety for different transport-related actors. Although, at present several comparable systems exist, their current implementation is far from successful because of technological and economic obstacles. The new expert communication platform put forward here (called MamMoeT) addresses these two issues by using a software agent-based approach. Software agents are pieces of software representing a single user. They are autonomous, communicative and intelligent. The MamMoeT system developed can be described as a real-time decision support system in which intelligent software agents handle communicative tasks, exchange desired amounts of information among different users using common exchange protocols which act as translators between different systems.",smart cities
10.1016/j.talanta.2009.04.046,Journal,Talanta,scopus,2009-08-15,sciencedirect,Selective separation and determination of primidone in pharmaceutical and human serum samples using molecular imprinted polymer-electrospray ionization ion mobility spectrometry (MIP-ESI-IMS),https://api.elsevier.com/content/abstract/scopus_id/67649361346,"Application of electrospray ionization ion mobility spectrometry (ESI-IMS) as the detection technique for separation method based on molecular imprinted polymer (MIP) was investigated and evaluated. The method is exhaustively validated, including sensitivity, selectivity, recovery, reproducibility, and column capacity. The linear dynamic range of 0.02–2.00μgmL−1 was obtained for primidone analysis with ESI-IMS. The recovery of drug analyzed was calculated to be above 90% and the relative standard deviation (RSD), was below 3% for all experiments. Various real samples were analyzed with the coupled techniques, and the results obtained revealed the efficient clean-up of the samples using MIP separation before the analysis by ESI-IMS as a detection technique.",smart cities
10.1016/j.engappai.2009.03.001,Journal,Engineering Applications of Artificial Intelligence,scopus,2009-06-01,sciencedirect,An implementing framework for holonic manufacturing control with multiple robot-vision stations,https://api.elsevier.com/content/abstract/scopus_id/67349215793,"The paper describes a holonic control architecture and implementing issues for agile job shop assembly with networked intelligent robots, based on the dynamic simulation of material processing and transportation. The holarchy was defined considering the PROSA reference architecture relative to which in-line vision-based quality control was added by help of feature-based descriptions of the material flow. Two solutions for production planning are proposed: a knowledge-based algorithm using production rules, and an OO resolved scheduling rate planner (RSRP) based on variable-timing simulation. Failure- and recovery-management are developed as generic scenarios embedding the CNP mechanism into production self-rescheduling. Aggregate Order Holon execution is realized by OPC-based PLC software integration and event-driven product transportation. The holonic control of multiple networked robot-vision stations also features tolerance to station computer- (IBM PC-type), station controller- (robot controller), quality control- (machine vision) and communication- (LAN) failure. Fault tolerance and high availability at shop-floor level are provided due to the multiple physical communication capabilities of the robot controllers, to their multiple-axis multitasking operating capability, and to hardware redundancy of single points of failure (SPOF). Implementing solutions and experiments are reported for a 6-station robot-vision assembly cell with twin-track closed-loop pallet transportation system and product-racking RD/WR devices. Future developments will consider manufacturing integration at enterprise level.",smart cities
10.1016/j.jviromet.2009.02.006,Journal,Journal of Virological Methods,scopus,2009-06-01,sciencedirect,Development of a qPCR assay for the quantification of porcine adenoviruses as an MST tool for swine fecal contamination in the environment,https://api.elsevier.com/content/abstract/scopus_id/64949137024,"The Adenoviridae family comprises a wide diversity of viruses that may be excreted for long periods in feces or urine. Previous studies have suggested that the detection of human and animal adenoviruses as well as human and animal polyomaviruses by PCR could be used as an index of fecal contamination of human and animal origin. In this study, quantitative PCR assays targeting specifically porcine adenoviruses have been developed and applied to fecal and environmental samples, including pig slurries, urban sewage, slaughterhouse sewage and river water samples. To develop real-time quantitative PCR for the detection and quantitation of porcine adenoviruses, primers and a TaqMan probe targeting a 68-bp region of the porcine adenovirus hexon gene were designed to amplify specifically porcine adenovirus, and the conditions of the reaction were optimized. The assay detected 1–10 genome copies per test tube and was specific in showing no positive results when samples containing human or bovine adenoviruses were analyzed. Fecal samples contained mean concentrations of porcine adenoviruses of 105 GC/g while slaughterhouse wastewater samples showed mean values of 103 GC/ml. The assay detected porcine fecal pollution in samples that were highly diluted and had been collected at a considerable distance from the input source, such as river water. In general, the data presented here provide a quantitative tool for the analysis of porcine adenoviruses as indicators of the presence of porcine contamination in the environment, and support the detection of porcine adenoviruses by real-time quantitative PCR as a promising and valuable tool for source-tracking studies.",smart cities
10.1016/j.advwatres.2009.01.001,Journal,Advances in Water Resources,scopus,2009-04-01,sciencedirect,Pumping optimization of coastal aquifers based on evolutionary algorithms and surrogate modular neural network models,https://api.elsevier.com/content/abstract/scopus_id/62349136438,"Pumping optimization of coastal aquifers involves complex numerical models. In problems with many decision variables, the computational burden for reaching the optimal solution can be excessive. Artificial Neural Networks (ANN) are flexible function approximators and have been used as surrogate models of complex numerical models in groundwater optimization. However, this approach is not practical in cases where the number of decision variables is large, because the required neural network structure can be very complex and difficult to train. The present study develops an optimization method based on modular neural networks, in which several small subnetwork modules, trained using a fast adaptive procedure, cooperate to solve a complex pumping optimization problem with many decision variables. The method utilizes the fact that salinity distribution in the aquifer, depends more on pumping from nearby wells rather than from distant ones. Each subnetwork predicts salinity in only one monitoring well, and is controlled by relatively few pumping wells falling within certain control distance from the monitoring well. While the initial control area is radial, its shape is adaptively improved using a Hermite interpolation procedure. The modular neural subnetworks are trained adaptively during optimization, and it is possible to retrain only the ones not performing well. As optimization progresses, the subnetworks are adapted to maximize performance near the current search space of the optimization algorithm. The modular neural subnetwork models are combined with an efficient optimization algorithm and are applied to a real coastal aquifer in the Greek island of Santorini. The numerical code SEAWAT was selected for solving the partial differential equations of flow and density dependent transport. The decision variables correspond to pumping rates from 34 wells. The modular subnetwork implementation resulted in significant reduction in CPU time and identified an even better solution than the original numerical model.",smart cities
10.1016/j.ins.2008.10.020,Journal,Information Sciences,scopus,2009-03-29,sciencedirect,Associated evolution of a support vector machine-based classifier for pedestrian detection,https://api.elsevier.com/content/abstract/scopus_id/59149098920,"Support vector machine (SVM) has become a dominant classification technique used in pedestrian detection systems. In such systems, classifiers are used to detect pedestrians in some input frames. The performance of a SVM classifier is mainly influenced by two factors: the selected features and the parameters of the kernel function. These two factors are highly related and therefore, it is desirable that the two factors can be analyzed simultaneously, which are usually not the case in the previous work.
                  In this paper, we propose an evolutionary method to simultaneously optimize the feature set and the parameters for the SVM classifier. Specifically, adaptive genetic operators were designed to be suitable for the feature selection and parameter tuning. The proposed method is used to train a SVM classifier for pedestrian detection. Experiments in real city traffic scenes show that the proposed approach leads to higher detection accuracy and shorter detection time.",smart cities
10.1016/j.compenvurbsys.2009.01.001,Journal,"Computers, Environment and Urban Systems",scopus,2009-03-01,sciencedirect,Development of decision support tools for decentralised urban water supply management in Uganda: An Action Research approach,https://api.elsevier.com/content/abstract/scopus_id/61349151111,"This paper presents a study in which four real-life problem situations are used to explore the challenges of developing and implementing decision support tools within an urban water utility. In the study, an Action Research approach is used, with theoretical considerations leading to specific actions being implemented, which in turn yield results that are used to reflect upon the original theoretical assumptions. Results of the study emphasize the need for proper problem-structuring prior to the formulation of actions; the challenges of moving from planning to action; the importance of user involvement in the development of tools; and how a good match of people, problem-structuring, proactiveness and participatory tools development is required for effective decision support provision. The study also highlights the challenges of embedding decision support within existing work systems in organizations. The Action Research approach is shown to be useful in bridging the gap between theory and practice, aiding the development of decision support tools of immediate and practical benefit to organizations.",smart cities
10.1016/j.radmeas.2009.01.002,Journal,Radiation Measurements,scopus,2009-02-01,sciencedirect,"Response of Radon in a seismic calibration explosion, Israel",https://api.elsevier.com/content/abstract/scopus_id/67349101260,"Radon measurements were performed at shallow levels during an in-land 20-ton seismic calibration explosion experiment, simulating a 2.6-M
                     L earthquake, to investigate the influence of the explosive blast and the transitory seismic wave fields on the Radon transport in the country rock, adjacent to the focus of the explosion. The experiment was conducted in a basalt quarry in the northern margin of the Beit Shean valley (Israel). Five gamma-ray sensors were placed, at a depth of about 2m, along a line located 17–150m from the edge of the explosion zone. Measurements commenced 4 days before and continued for 9 days after the explosion with 15min integrations. A 10-s sampling was used in the interval of several hours before and after the explosion itself.
                  Diurnal variations of Radon, reflecting the typical variation pattern of Radon in the shallow environment, were registered before and after the explosion. No significant change in the overall Radon concentration was observed as a consequence of the main explosion as well as three smaller experimental shots (0.5–2tons) in the 2h prior to the calibration blast. The seismological data indicate that the transient excess pressure at the farthest Radon sensor was above 5barm−1 during 0.2–0.4s, and evidently much higher at the nearest sensors, but none of the sensors responded by recording any exceptional change in the Radon concentration. Moreover the hypothesis that additional Radon may emanate from solid grains as a result of the excess local pressure exerted by the blast is also not observed.
                  In contrast to a real earthquake event an explosion experiment has neither eventual preceding nor following geodynamic activity. Therefore the absence of significant Radon anomalies during or after the blast does not contradict assumptions, observations or conclusions as the occurrence of Radon anomalies prior or after an earthquake event due to associated long-term geodynamic processes.",smart cities
10.1016/j.mcp.2008.10.006,Journal,Molecular and Cellular Probes,scopus,2009-02-01,sciencedirect,"Selection, characterization, and application of DNA aptamers for the capture and detection of Salmonella enterica serovars",https://api.elsevier.com/content/abstract/scopus_id/59049089355,"Sensitive and specific pre-analytical sample processing methods are needed to enhance our ability to detect and quantify food borne pathogens from complex food and environmental samples. In this study, DNA aptamers were selected and evaluated for the capture and detection of Salmonella enterica serovar. Typhimurium. A total of 66 candidate sequences were enriched against S. Typhimurium outer membrane proteins (OMPs) with counter-selection against Escherichia coli OMPs and lipopolysaccharides (LPS). Specificity of the selected aptamers was evaluated by gel-shift analysis against S. Typhimurium OMP. Five Salmonella-specific aptamer candidates were selected for further characterization. A dilution-to-extinction capture protocol using pure cultures of S. Typhimurium further narrowed the field to two candidates (aptamers 33 and 45) which showed low-end detection limits of 10–40CFU. DNase protection assays applied to these aptamers confirmed sequence-specific binding to S. Typhimurium OMP preparations, while South-Western blot analysis combined with mass spectrometry identified putative membrane proteins as targets for aptamer binding. Aptamer 33 was bound to magnetic beads and used for the capture of S. Typhimurium seeded into whole carcass chicken rinse samples, followed by detection using quantitative real-time RT-PCR. In a pull-down assay format, detection limits were 101–102
                     CFU S. Typhimurium/9mL rinsate, while in a recirculation format, detection limits were 102–103
                     CFU/25mL rinsate. Reproducible detection at <101 
                     S. typhimurium CFU/g was also achieved in spike-and-recovery experiments using bovine feces. The pull-down analysis using aptamer 33 was validated on 3 naturally infected chicken litter samples confirming their applicability in the field. This study demonstrates the applicability of Salmonella specific aptamers for pre-analytical sample processing as applied to food and environmental sample matrices.",smart cities
10.1016/j.trc.2008.04.003,Journal,Transportation Research Part C: Emerging Technologies,scopus,2009-01-01,sciencedirect,Integrating mobile agent technology with multi-agent systems for distributed traffic detection and management systems,https://api.elsevier.com/content/abstract/scopus_id/58349113190,"Agent technology is rapidly emerging as a powerful computing paradigm to cope with the complexity in dynamic distributed systems, such as traffic control and management systems. However, while a number of agent-based traffic control and management systems have been proposed and the multi-agent systems have been studied, to the best of our knowledge, the mobile agent technology has not been applied to this field. In this paper, we propose to integrate mobile agent technology with multi-agent systems to enhance the ability of the traffic management systems to deal with the uncertainty in a dynamic environment. In particular, we have developed an IEEE FIPA compliant mobile agent system called Mobile-C and designed an agent-based real-time traffic detection and management system (ABRTTDMS). The system based on Mobile-C takes advantages of both stationary agents and mobile agents. The use of mobile agents allows ABRTTDMS dynamically deploying new control algorithms and operations to respond unforeseen events and conditions. Mobility also reduces incident response time and data transmission over the network. The simulation of using mobile agents for dynamic algorithm and operation deployment demonstrates that mobile agent approach offers great flexibility in managing dynamics in complex systems.",smart cities
10.1016/j.eswa.2008.07.069,Journal,Expert Systems with Applications,scopus,2009-01-01,sciencedirect,Online-SVR for short-term traffic flow prediction under typical and atypical traffic conditions,https://api.elsevier.com/content/abstract/scopus_id/58349104545,"Most literature on short-term traffic flow forecasting focused mainly on normal, or non-incident, conditions and, hence, limited their applicability when traffic flow forecasting is most needed, i.e., incident and atypical conditions. Accurate prediction of short-term traffic flow under atypical conditions, such as vehicular crashes, inclement weather, work zone, and holidays, is crucial to effective and proactive traffic management systems in the context of intelligent transportation systems (ITS) and, more specifically, dynamic traffic assignment (DTA).
                  To this end, this paper presents an application of a supervised statistical learning technique called Online Support Vector machine for Regression, or OL-SVR, for the prediction of short-term freeway traffic flow under both typical and atypical conditions. The OL-SVR model is compared with three well-known prediction models including Gaussian maximum likelihood (GML), Holt exponential smoothing, and artificial neural net models.
                  The resultant performance comparisons suggest that GML, which relies heavily on the recurring characteristics of day-to-day traffic, performs slightly better than other models under typical traffic conditions, as demonstrated by previous studies. Yet OL-SVR is the best performer under non-recurring atypical traffic conditions. It appears that for deployed ITS systems that gear toward timely response to real-world atypical and incident situations, OL-SVR may be a better tool than GML.",smart cities
10.1016/j.aca.2006.10.021,Journal,Analytica Chimica Acta,scopus,2007-09-26,sciencedirect,Flow injection on-line dilution for zinc determination in human saliva with electrothermal atomic absorption spectrometry detection,https://api.elsevier.com/content/abstract/scopus_id/34548853727,"An automated method is described for the determination of zinc in human saliva by electrothermal atomic absorption spectrometry (ET AAS) after on-line dilution of samples with a significant reduction of sample consumption per analysis (<0.4mL including the dead volume of the system). In order to fulfill this aim without changing the sample transport conduits during the experiments, a flow injection (FI) dilution system was constructed. Its principal parts are: one propulsion device (peristaltic pump, PP) for either samples, standards or washing solution all located in an autosampler tray and for the surfactant solution (Triton X-100) used as diluent, and a two-position time based solenoid injector (TBSI1) which allowed the introduction of 10μL of either solution in the diluent stream. To avoid unnecessary waste of samples, the TBSI1 also permitted the recirculation of the solutions to their respective autosampler cups. The downstream diluted solution fills a home made sampling arm assembly. The sequential deposition of 20μL aliquots of samples or standards on the graphite tube platform was carried out by air displacement with a similar time based solenoid injector (TBSI2). The dilution procedure and the injection of solutions into the atomizer are computer controlled and synchronized with the operation of the temperature program. Samples or standards solutions were submitted to two drying steps (at 90 and 130°C), followed by pyrolysis and atomization at 700 and 1700°C, respectively. The aqueous calibration was linear up to 120.0μgL−1 for diluted standard solutions/samples and its slope was similar (p
                     >0.05) to the standard addition curve, indicating lack of matrix effect. The precision tested by repeated analysis of real saliva samples was less than 3% and the detection limit (3σ) was of 0.35μgL−1. To test the accuracy of the proposed procedure, recovery tests were performed, obtaining mean recovery of added zinc of 97.8±1.3%. Furthermore, Zn values estimated by the procedure developed in this work were compared with those obtained by a standard addition flame-AAS method applied to 20 randomly selected saliva samples. No significant differences (p
                     >0.05) were obtained between the two methods. Zinc levels in saliva samples from 44 healthy volunteers, 15 male and 29 female, with ages between 20 and 51 years (mean 30.50±9.14 years) were in the range 22–98μgL−1 (mean of 55±17μgL−1), similar to some and different from others reported in the literature. It was found that zinc values for male were statistically higher (p
                     =0.006) than for female.",smart cities
10.1016/j.envsoft.2006.08.002,Journal,Environmental Modelling and Software,scopus,2007-09-01,sciencedirect,A 24-h forecast of ozone peaks and exceedance levels using neural classifiers and weather predictions,https://api.elsevier.com/content/abstract/scopus_id/34147176086,"A neural network combined to a neural classifier is used in a real time forecasting of hourly maximum ozone in the centre of France, in an urban atmosphere. This neural model is based on the MultiLayer Perceptron (MLP) structure. The inputs of the statistical network are model output statistics of the weather predictions from the French National Weather Service. These predicted meteorological parameters are very easily available through an air quality network. The lead time used in this forecasting is (t
                     +24)h. Efforts are related to a regularisation method which is based on a Bayesian Information Criterion-like and to the determination of a confidence interval of forecasting. We offer a statistical validation between various statistical models and a deterministic chemistry-transport model. In this experiment, with the final neural network, the ozone peaks are fairly well predicted (in terms of global fit), with an Agreement Index=92%, the Mean Absolute Error=the Root Mean Square Error=15μgm−3 and the Mean Bias Error=5μgm−3, where the European threshold of the hourly ozone is 180μgm−3.
                  To improve the performance of this exceedance forecasting, instead of the previous model, we use a neural classifier with a sigmoid function in the output layer. The output of the network ranges from [0,1] and can be interpreted as the probability of exceedance of the threshold. This model is compared to a classical logistic regression. With this neural classifier, the Success Index of forecasting is 78% whereas it is from 65% to 72% with the classical MLPs. During the validation phase, in the Summer of 2003, six ozone peaks above the threshold were detected. They actually were seven.
                  Finally, the model called NEUROZONE is now used in real time. New data will be introduced in the training data each year, at the end of September. The network will be re-trained and new regression parameters estimated. So, one of the main difficulties in the training phase – namely the low frequency of ozone peaks above the threshold in this region – will be solved.",smart cities
10.1016/j.envsoft.2006.09.005,Journal,Environmental Modelling and Software,scopus,2007-09-01,sciencedirect,Neural-optimal control algorithm for real-time regulation of in-line storage in combined sewer systems,https://api.elsevier.com/content/abstract/scopus_id/34147168206,"Attempts at implementing real-time control systems as a cost-effective means of minimizing the pollution impacts of untreated combined sewer overflows have largely been unsustained due to the complexity of the real-time control problem. Optimal real-time regulation of flows and in-line storage in combined sewer systems is challenging due to the need for complex optimization models integrated with urban stormwater runoff prediction and fully dynamic routing of sewer flows within 5–15min computational time increments. A neural-optimal control algorithm is presented that fully incorporates the complexities of dynamic, unsteady hydraulic modeling of combined sewer system flows and optimal coordinated, system-wide regulation of in-line storage. The neural-optimal control module is based on a recurrent Jordan neural network architecture that is trained using optimal policies produced by a dynamic optimal control module. The neural-optimal control algorithm is demonstrated in a simulated real-time control experiment for the King County combined sewer system, Seattle, Washington, USA. The algorithm exhibits an effective adaptive learning capability that results in near-optimal performance of the control system while satisfying the time constraints of real-time implementation.",smart cities
10.1016/j.patrec.2007.01.010,Journal,Pattern Recognition Letters,scopus,2007-07-01,sciencedirect,Recognizing vehicle classification information from blade sensor signature,https://api.elsevier.com/content/abstract/scopus_id/34147178432,"Traffic surveillance system capable of providing accurate real-time traffic measurements is a backbone of fully exploiting a variety of advanced traffic management systems. Vehicle classification information is one of the important measurements that we need to obtain in practice, which is invaluable for various aspects of transportation including engineering and planning. This study develops vehicle classification algorithms using inductive signatures obtained from a prototype innovative loop sensor, known as a ‘blade’. A probabilistic neural network (PNN), a neural network implementation of multivariate Bayesian classification scheme, and a heuristic classification algorithm are employed to classify vehicle types. Vehicle feature vectors representing the vehicle shapes are extracted from blade signatures, and then utilized as inputs of the proposed algorithm. The classification performances are investigated with four different types of vehicles including passenger car, pick-up truck, sports utility vehicle, and van. N-fold cross validation is applied to evaluate the performances. Encouraging result of 70.8% overall correct classification rate obtained from the PNN-based classification algorithm demonstrates the technical feasibility of the proposed algorithm for obtaining vehicle classification information.",smart cities
10.1016/j.neuroimage.2007.02.032,Journal,NeuroImage,scopus,2007-05-15,sciencedirect,Neural substrates of driving behaviour,https://api.elsevier.com/content/abstract/scopus_id/34247183634,"Driving a vehicle is an indispensable daily behaviour for many people, yet we know little about how it is supported by the brain. Given that driving in the real world involves the engagement of many cognitive systems that rapidly change to meet varying environmental demands, identifying its neural basis presents substantial problems. By employing a unique combination of functional magnetic resonance imaging (fMRI), an accurate interactive virtual simulation of a bustling central London (UK) and a retrospective verbal report protocol, we surmounted these difficulties. We identified different events that characterise the driving process on a second by second basis and the brain regions that underlie them. Prepared actions such as starting, turning, reversing and stopping were associated with a common network comprised of premotor, parietal and cerebellar regions. Each prepared action also recruited additional brain areas. We also observed unexpected hazardous events such as swerving and avoiding collisions that were associated with activation of lateral occipital and parietal regions, insula, as well as a more posterior region in the medial premotor cortex than prepared actions. By contrast, planning future actions and monitoring fellow road users were associated with activity in superior parietal, lateral occipital cortices and the cerebellum. The anterior pre-SMA was also recruited during action planning. The right lateral prefrontal cortex was specifically engaged during the processing of road traffic rules. By systematically characterising the brain dynamics underlying naturalistic driving behaviour in a real city, our findings may have implications for how driving competence is considered in the context of neurological damage.",smart cities
10.1016/j.ijpharm.2006.08.011,Journal,International Journal of Pharmaceutics,scopus,2007-01-10,sciencedirect,Delivery of <sup>125</sup>I-cobrotoxin after intranasal administration to the brain: A microdialysis study in freely moving rats,https://api.elsevier.com/content/abstract/scopus_id/33845316415,"In order to determine the contribution of intranasal (i.n.) administration to the uptake of large molecular weight (MW) substances into central nervous system (CNS), concentration in brain of the centrally acting polypeptide cobrotoxin (NT-I) versus time profiles were studied using dual-probe microdialysis in awake free-moving rats. NT-I, radiolabeled with sodium 125I-Iodide (125I-NT-I), was administered at the dose of 105μg/kg intravenously and intranasally in the same set of rat (n
                     =15). The 125I-NT-Inasal preparations were formulated with borneol/menthol eutectic mixture (+BMEM) as an absorption enhancer and without (−BMEM). After application, the dialysates sampled simultaneously from olfactory bulb and cerebellar nuclei were measured in a gamma-counter for radioactivity. The real concentrations of NT-I were recalculated by in vivo recoveries of microdialysis probes. The results showed that the area under the curve (AUC) value in cerebellar nuclei (2283.51±34.54minng/ml) following i.n. administration (+BMEM) was significantly larger than those (AUColfactory
                     =1141.92±26.42minng/ml; AUCcerebellar
                     =1364.62±19.35minng/ml) after intravenous (i.v.) bolus, respectively. A prolonged time values to peak concentrations after i.n. application (+BMEM) were observed compared with those following i.v. administration. Also, following i.n. application (+BMEM) the measured time value to peak concentration in cerebellar nuclei (85min) was statistically longer than that in olfactory bulb (75min), which could be plausibly an indication for NT-I delivery into brain via nose–brain pathway in the presence of absorption enhancer. i.n. administration (−BMEM) had little or no ability of NT-I delivering into brain. In conclusion, i.n. administration (+BMEM) significantly enhanced brain transport of NT-I with uneven distribution in discrete regions of brain compared with i.v. administration. Additionally, multi-probe microdialysis technique should be considerably valuable in brain delivery studies.",smart cities
10.3182/20070904-3-kr-2922.00028,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2007-01-01,sciencedirect,Interacting with gestures and facial expressions - Implementation and applications,https://api.elsevier.com/content/abstract/scopus_id/79961041301,"Developments in software and hardware technologies as, e.g. in microelectronics, mechatronics, speech technology, computer linguistics, computer vision, and artificial intelligence are continuously driving new embedded applications for work, leisure, and mobility. Since usability of such appliances turns out to be the main factor limiting complexity, new approaches to interface design are needed. Promising measures for building enhanced usability interfaces are non-intrusive means of interaction as, e.g. gestures and mimics. This paper describes how suitable features can be extracted from camera pictures in real time and presents some real world applications.",smart cities
10.1016/j.theriogenology.2005.07.003,Journal,Theriogenology,scopus,2006-03-01,sciencedirect,Fertility after deep intra-uterine artificial insemination of concentrated low-volume boar semen doses,https://api.elsevier.com/content/abstract/scopus_id/32044435372,"Boar semen can be successfully frozen – highly packed – in small containers (medium-straw, MS or MiniFlatPack, MFP). The use of deep intra-uterine artificial insemination (DIU-AI) can make possible the deposition of small volumes of this thawed, non re-extended semen deeply intra-uterine, close to the sperm reservoir. The present experiments studied the fertility achieved after single or double DIU-AI per oestrus, with special attention to the interval between AI and spontaneous ovulation. Semen from two boars of proven fertility was frozen in MS or MFP holding 1×109 total spermatozoa. Multiparous (2–5 parity, n
                     =42) crossbred sows were checked for oestrous behaviour after weaning and the occurrence of spontaneous ovulation was checked with transrectal ultrasonography (TUS) to establish the mean interval between onset of oestrus (OO) and ovulation which was found to be when approximately 2/3 of the oestrus period has passed. The sows were, in the following standing oestrus, subjected to DIU-AI using thawed semen from either MS (n
                     =20) or MFP (n
                     =22), inseminated without further re-extension. The sows were randomly allotted to one of three groups: (1) single DIU-AI 8h before expected ovulation (control group, n
                     =19); (2) single DIU-AI 4h before expected ovulation (treatment group S, n
                     =15); and (3) double DIU-AI 12 and 4h before expected ovulation (treatment group D, n
                     =8). Occurrence of spontaneous ovulation was confirmed by TUS, performed as during the first oestrous period and used to determine the real interval of DIU-AI and ovulation. Pregnancy was also confirmed by TUS 28 days after OO in those sows not returning to oestrus. These sows were slaughtered (30–45 days of pregnancy), and the appearance of the reproductive tract and ovaries, the number of live and dead foetuses, of implantation sites and of corpora lutea (CL) were recorded. Sows (n
                     =9) returning to oestrus (“open”) were re-inseminated (either once [n
                     =4] or twice [n
                     =5]) the following oestrus with either MFP (n
                     =5) or MS (n
                     =4) and slaughtered 12–14h post-ovulation for recovery of tubal oocytes and of spermatozoa from the uterotubal junctions (sperm reservoir), to assess the degree of effectiveness of sperm transport. Post-thaw sperm motility was 44.3±3.21% in MFP and 42.8±0.72% for MS (LSmean±S.E.M., n.s.), and did not significantly change from thawing to AI. The DIU-AI could be performed in all sows, but insertion was difficult (slow >5min) in 5/42 sows. Four of these sows returned to oestrus. Pregnancy rate averaged 35% (group D: 25%, group S: 40%, control: 36%, n.s.). The interval between DIU-AIs and spontaneous ovulation varied largely, ranging from −13 to −3h for group C, for group S from −11 to +3h and for group D from −17 to −4h. Pregnancy rates were clearly related to the interval DIU-AI and ovulation, being highest (60%, 12/20) when AI occurred between 8 and 4h before spontaneous (not expected) ovulation. The number of implantation sites ranged 6–22 (n.s. among groups), and the number of alive foetuses 2–11 (n.s. among groups). Implantation rate (total number of implantations/CL) ranged 48.0–69.7% being highest in the D-group (P
                     <0.05). The examination of the “open” sows slaughtered 12–14h post-ovulation revealed few recovered oocytes were fertilized (approximately 10%). Only 40% of oocytes had spermatozoa bound to the zona pellucida, not more than two spermatozoa per oocyte. Moreover, low sperm numbers (approximately 4000) were found in the sperm reservoirs (UTJs), irrespective of using single or double DIU-AI (n.s.). The highest values (P
                     <0.05) for these variables were recorded when DIU-AI (either single or double [second AI]) occurred 4–8h before ovulation, especially when MFP-semen was used (P
                     <0.05). In conclusion: (1) DIU-AI can be easily performed in most sows; (2) pregnancies can be obtained by the DIU-AI of low volumes of highly concentrated frozen–thawed boar semen, once or twice during oestrus, but fertility is still low, probably owing to an unsatisfactory sperm transport when expected and real ovulation differ; and (3) fertility is related to the interval DIU-AI and ovulation which should be −8 to −4h of spontaneous ovulation and to the package, MFP having shown better results in vivo. The results stress the need for careful, and frequent, control of oestrus signs.",smart cities
10.3182/20060829-3-nl-2908.00038,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2006-01-01,sciencedirect,Developing a large-scale urban decision support system,https://api.elsevier.com/content/abstract/scopus_id/79961106534,"A large-scale Decision Support System (DSS) is being developed and will be applied for Beijing city in China. The main purpose is to be able to propose best suitable measures for a given (either recurrent or non-recurrent) traffic situation, and to apply it to a real-life traffic management, with focus on the application around the Olympics Area. A major issue for operational management is to be able fast to recognize primary problems and to be quick to recommend/retrieve corresponding solutions. This paper proposes a novel self-learning approach using conjointly expert knowledge-based choice and case-based reasoning. Key aspects to support such process include: (a) problem identification that is based on a mesoscopic large-scale network dynamic simulation; (b) measures that have been successfully implemented in a priori cases would serve as new initial scenarios to the new situations, and (c) measure evaluation that can be performed according to performance indictors. Effective scenarios (measure to problem) are stored into KBEST (knowledge-based expert system) and made available for offline and online calls. System building and a calibration process are being followed, and an implementation of such system to an incident management and route guidance is foreseen and being designed.",smart cities
10.1016/j.chemosphere.2005.06.047,Journal,Chemosphere,scopus,2006-01-01,sciencedirect,Interval estimation of urban ozone level and selection of influential factors by employing automatic relevance determination model,https://api.elsevier.com/content/abstract/scopus_id/33644541501,"In this work, we focus on simulating the ground-level ozone (O3) time series and its daily maximum concentration in Hong Kong urban air by employing the multilayer perceptron (MLP) model combined with the automatic relevance determination (ARD) method (for simplicity, we name it as MLP-ARD model). Two air quality monitoring sites in Hong Kong, i.e., Tsuen Wan and Tung Chung, are selected for the numerical experiments. The MLP-ARD model based on Bayesian evidence framework can provide reliable interval estimation of real observation as well as offering efficient strategy to avoid over-fitting. The performance comparisons between MLP-ARD model and traditional artificial neural network (ANN) model based on maximum likelihood indicate that MLP-ARD model is more powerful to capture the wild fluctuation of O3 level especially during O3 episodes than the traditional model. Furthermore, it can assess and rank the input variables for the prediction according to their relative importance to the output variable, i.e., the daily maximum O3 concentration in this study. The preliminary experimental results indicate that nitric oxide (NO) and solar radiation are the most important input variables for O3 prediction at both selected sites. In addition, the previous daily maximum O3 level is also important for Tung Chung site. In this regard, MLP-ARD model is a feasible tool to interpret the real physical and chemical process of urban O3 variation.",smart cities
10.1016/j.ymthe.2005.06.438,Journal,Molecular Therapy,scopus,2005-10-01,sciencedirect,Axons mediate the distribution of arylsulfatase a within the mouse hippocampus upon gene delivery,https://api.elsevier.com/content/abstract/scopus_id/25144474418,"Axonal transport of the lysosomal enzyme arylsulfatase A (ARSA) may be an additional mechanism of enzyme distribution after in vivo brain gene transfer in an animal model of metachromatic leukodystrophy (MLD). Direct molecular demonstration of the movement of this lysosomal enzyme within axonal networks was missing. We generated lentiviral vectors carrying the ARSA cDNA tagged with hemagglutinin or the green fluorescent protein and examined the subcellular localization and anatomical distribution of the tagged enzymes within the MLD hippocampus after in vivo lentiviral gene transfer. The use of tagged ARSA allowed direct real-time observation and tracking of axon–dendritic transport of the enzyme after lentiviral gene therapy. Tagged ARSA was expressed in transduced pyramidal, granule, and hilar neurons within the lentiviral-injected side and was robustly contained in vesicles within ipsilateral axon–dendritic processes as well as in vesicles associated with contralateral axons and commissural axons of the ventral hippocampal commissure. Axonal transport of tagged ARSA led to the correction of hippocampal defects in long-term treated MLD mice, which was accompanied by enzyme uptake in nontransduced contralateral neurons, enzyme accumulation within the lysosomal compartment, and clearance of sulfatide storage deposits in this region of the MLD brain. These results contribute to the understanding of the mechanisms of distribution of lysosomal enzymes within the mammalian brain after direct gene therapy, demonstrating the use of neural processes for enzyme transport.",smart cities
10.1016/j.bcp.2005.03.034,Journal,Biochemical Pharmacology,scopus,2005-07-01,sciencedirect,Limited protective role of V-PYRRO/NO against cholestasis produced by alpha-naphthylisothiocyanate in mice,https://api.elsevier.com/content/abstract/scopus_id/20444426537,"O
                     
                        2
                     -vinyl 1-(pyrrolidin-1-yl)diazen-1-ium-1,2-diolate (V-PYRRO/NO) is a liver-selective nitric oxide donor that has been shown to protect against hepatotoxic effects of endotoxin, acetaminophen and cadmium. This study examined the effects of V-PYRRO/NO on alpha-naphthylisothiocyanate (ANIT)-induced hepatotoxicity in mice. Mice were given V-PYRRO/NO via osmotic pumps (5.4mg/ml; 0.5μl/h) starting 24h before receiving a hepatotoxic dose of ANIT (150mg/kg in olive oil, i.g.), and continuing for additional 48h (3-day pumps). V-PYRRO/NO administration partially ameliorated ANIT-induced hepatotoxicity, as evidenced by reduced serum alanine aminotransferase and alkaline phosphatase, markers of liver cell death, and by improved liver pathology. However, V-PYRRO/NO had no effect on ANIT-induced cholestasis, as ANIT-increased serum bilirubin levels and gamma-glutamyl transpeptidase activity were not ameliorated. Microarray and real time RT-PCR analysis revealed that ANIT intoxication altered expression of various genes, including genes encoding metabolic enzymes, transporter proteins, acute phase proteins, inflammation- and, apoptosis-related genes, as well as other genes related to liver injury. V-PYRRO/NO treatment attenuated ANIT-induced elevations in certain inflammation- and apoptosis-related genes, but had no effect on ANIT-induced disturbance on the expression of genes related to metabolism, transport, and acute phase proteins. Thus, the liver-selective NO donor, V-PYRRO/NO, was partially protective against ANIT-induced liver injury, without affecting ANIT-induced cholestasis and cholestasis-related gene expression.",smart cities
10.1111/j.1523-1755.2005.00304.x,Journal,Kidney International,scopus,2005-01-01,sciencedirect,Functional and molecular characterization of a peritoneal dialysis model in the C57BL/6J mouse,https://api.elsevier.com/content/abstract/scopus_id/17744400518,"Functional and molecular characterization of a peritoneal dialysis model in the C57BL/6J mouse.
               
                  Background
                  Animal models are important for understanding the physiology and pathophysiology of peritoneal transport during peritoneal dialysis (PD). Mechanistic investigations of rat and rabbit models of PD are mostly based on intervention studies using pharmacologic agents or blocking antibodies. These models may be limited by the time-course, lack of specificity, or side effects of such interventions. Genetically modified mice could provide an attractive alternative to the above models. In this study, we have characterized PD parameters and tested the effect of gender and dialysate volume and/or osmolality in the C57BL/6J mouse.
               
                  Methods
                  Mice were submitted to a 2-hour peritoneal equilibration test in order to obtain permeability parameters. The expression of the water channel aquaporin-1 (AQP1) and endothelial NO synthase (eNOS) was investigated at the protein (immunoblotting, immunostaining) and mRNA [real-time reverse-transcription-polymerase chain reaction (RT-PCR)] levels. The potential effect of gender on these parameters was also studied.
               
                  Results
                  Exposure of mice to 2 mL of 3.86% glucose dialysate yielded equilibration curves for urea and glucose, a sodium sieving, and a net ultrafiltration (UF) that were remarkably similar to those obtained in rats. The increase in dialysate volume (from 2 mL to 3 mL and 6 mL) resulted in a higher ultrafiltration and, for the highest volume, an increase in the diffusive mass transport coefficient (MTAC) for urea. The increase in dialysate glucose concentration (from 1.36% to 3.86% and 7%) resulted in increased sodium sieving and higher UF, whereas the MTAC for urea was unchanged. In comparison with males, females had a similar peritoneal transport rate for small solutes but a significantly lower sodium sieving, reflecting a lower AQP1 mRNA and protein expression in the peritoneum.
               
                  Conclusion
                  These data demonstrate the structural and functional similarity between mouse and rat models of PD, and further emphasize the relevance of mouse models to understand PD in humans. They also suggest that gender may influence water transport and AQP1 expression in the peritoneum.",smart cities
10.1016/j.annemergmed.2004.02.037,Journal,Annals of Emergency Medicine,scopus,2004-09-01,sciencedirect,Effects of neural network feedback to physicians on admit/discharge decision for emergency department patients with chest pain,https://api.elsevier.com/content/abstract/scopus_id/4344692494,"Study objective
                  Neural networks can risk-stratify emergency department (ED) patients with potential acute coronary syndromes with a high specificity, potentially facilitating ED discharge of patients to home. We hypothesized that the use of “real-time” neural networks would decrease the admission rate for ED chest pain patients.
               
                  Methods
                  We conducted a before-and-after trial. Consecutive ED patients with chest pain were evaluated before and after implementation of a neural network in an urban university ED. Data included 40 variables used in neural networks for acute myocardial infarction and acute coronary syndrome. Data were obtained in real time, and neural network outputs were provided to the treating physician while patients were in the ED. On hospital discharge, attending physicians received feedback, including neural network output, their initial clinical impression, cardiac test results, and final diagnosis. The main outcome was the actual admit/discharge decision made before versus after the implementation of the neural network.
               
                  Results
                  Before implementation, 4,492 patients were enrolled; after implementation, 432 patients were enrolled. Implementation of the neural network did not decrease the hospital admission rate (before: 62.7% [95% confidence interval (CI) 61.3% to 64.1%] versus after: 66.6% [95% CI 62.2% to 71.0%]). Additionally, the ICU admission rates were not different (11.4% [95% CI 10.5% to 12.3%] versus 9.3% [95% CI 6.6% to 12.0%]). Physician query found that the neural network changed management in only 2 cases (<1%).
               
                  Conclusion
                  The use of real-time neural network feedback did not influence the admission decision for ED patients with chest pain, most likely because the neural network output was delayed until the return of cardiac markers, and the disposition decision had already been made by that time.",smart cities
10.1016/j.envsoft.2003.10.003,Journal,Environmental Modelling and Software,scopus,2004-08-01,sciencedirect,Modelling SO<inf>2</inf> concentration at a point with statistical approaches,https://api.elsevier.com/content/abstract/scopus_id/3342982389,"In this paper, the results obtained by inter-comparing several statistical techniques for modelling SO2 concentration at a point such as neural networks, fuzzy logic, generalised additive techniques and other recently proposed statistical approaches are reported. The results of the inter-comparison are the fruits of collaboration between some of the partners of the APPETISE project funded under the Framework V Information Societies and Technologies (IST) programme. Two different cases for study were selected: the Siracusa industrial area, in Italy, where the pollution is dominated by industrial emissions and the Belfast urban area, in the UK, where domestic heating makes an important contribution. The different kinds of pollution (industrial/urban) and different locations of the areas considered make the results more general and interesting. In order to make the inter-comparison more objective, all the modellers considered the same datasets. Missing data in the original time series was filled by using appropriate techniques. The inter-comparison work was carried out on a rigorous basis according to the performance indices recommended by the European Topic Centre on Air and Climate Change (ETC/ACC). The targets for the implemented prediction models were defined according to the EC normative relating to limit values for sulphur dioxide. According to this normative, three different kinds of targets were considered namely daily mean values, daily maximum values and hourly mean values. The inter-compared models were tested on real cases of poor air quality. In the paper, the inter-compared techniques are ranked in terms of their capability to predict critical episodes. A ranking in terms of their predictability of the three different targets considered is also proposed. Several key issues are illustrated and discussed such as the role of input variable selection, the use of meteorological data, and the use of interpolated time series. Moreover, a novel approach referred to as the technique of balancing the training pattern set, which was successfully applied to improve the capability of ANN models to predict exceedences is introduced. The results show that there is no single modelling approach, which generates optimum results in terms of the full range of performance indices considered. In view of the implementation of a warning system for air quality control, approaches that are able to work better in the prediction of critical episodes must be preferred. Therefore, the artificial neural network prediction models can be recommended for this purpose. The best forecasts were achieved for daily averages of SO2 while daily maximum and hourly mean values are difficult to predict with acceptable accuracy.",smart cities
10.1016/j.mvr.2004.06.007,Journal,Microvascular Research,scopus,2004-01-01,sciencedirect,VEGF increases paracellular transport without altering the solvent-drag reflection coefficient,https://api.elsevier.com/content/abstract/scopus_id/14244265356,"Vascular endothelial growth factor (VEGF) increases microvascular permeability and has been implicated in the development of numerous pathologies including diabetic retinopathy (DR), hypoxia/ischemia, and tumor biology. The transport pathways by which water and solutes cross the endothelium in response to VEGF, however, are not completely understood. We measured, in real time, bovine retinal endothelial cell (BREC) hydraulic conductivity (Lp), 70 kDa dextran permeability (Pe), and the solvent-drag reflection coefficient (σ) before and after addition of 50 ng/ml VEGF. The diffusional permeability coefficient for dextran (Pd) was measured before pressure gradient application. The sudden application of a 10-cm H2O hydrostatic pressure gradient induced water and solute fluxes that decayed to steady-state values after approximately 2 h. Subsequently, the addition of VEGF significantly increased Lp and Pe by 4.3-fold ± 0.7-fold and 3.0-fold ± 0.3-fold, respectively, after 110 min; however, the reflection coefficient remained approximately constant throughout the experiment (approximately 0.8).
                  These observations suggest that water and dextran utilize common paracellular channels across BREC monolayers. Furthermore, the addition of VEGF increases the number or availability of channels but does not alter the selectivity of the monolayer to 70 kDa dextran.",smart cities
10.1016/S0039-9140(03)00324-2,Journal,Talanta,scopus,2003-12-04,sciencedirect,Hydride generation atomic absorption spectrometry with different flow systems and in-atomizer trapping for determination of cadmium in water and urine - Overview of existing data on cadmium vapour generation and evaluation of critical parameters,https://api.elsevier.com/content/abstract/scopus_id/0242413833,"An overview of literature data on vapour generation techniques for cadmium and comparison with own experiments by means of several different types of hydride generation–electrothermal atomic absorption spectrometric systems (HG–ETAAS) (batch, semi-batch (SB), continuous-flow (CF) and flow-injection (FI) as well as different gas–liquid separators (GLS) exhibits apparent variations and inconsistency. However, if data for optimal chemical conditions are re-plotted in another coordinates: CHCl (mol l−1) vs. the ratio of reductant-to-acid molar input rates (i.e. millimoles per minute), [BH4
                     −]:[H+], much better consistency of data is revealed: more than half of data are clustered around 0.2–0.3 mol l−1 HCl which appears an optimal acidity at moderate BH4
                     − concentrations; the tetrahydroborate molar input rates should always be in excess versus the H+ molar input rates (1.1 to tenfold); relatively high flow rates of argon purge gas are required (≥120 ml min−1); special attention to the blank control at ng l−1 levels as well as to the construction of gas–liquid separator and vapour transfer lines should be paid. ‘Milder’ conditions for HG could be provided with some of the examined systems and GLSs, thus minimizing reagent consumption, blanks, vigorous reactions, foaming, aerosol production and drift in measurements: e.g. 0.4 mol l−1 HCl—3% m/v NaBH4 with the semi-batch system and 0.25 mol l−1 HCl—2% m/v NaBH4 in continuous flow mode. Experimental system is based on the Transversely Heated Graphite Atomizer coupled with flow injection system FIAS 400. Integrated platforms are treated for permanent modification with Zr (110 μg) or W (240 μg) and then with Ir (8 μg). Temperatures of trapping, pyrolysis and atomization are 350, 500 and 1300°C, respectively. The best overall efficiency of HG, transportation and trapping is 41%. The characteristic mass for peak area measurements is m
                     o=2.8 pg and the limit of detection is 0.002 μg l−1. The long-term stability of characteristic mass (within-day, 8 h) is m
                     o=2.8±0.1 pg (R.S.D. 4.0%, n=8), whereas the corresponding between-day figures (1 mo) are m
                     o=2.8±0.2 pg (R.S.D. 6.6%, n=6). The linear range is 0.002–0.12 μg l−1 with a sample loop of 1.8 ml, being strongly impaired with smaller sample volumes in FI mode. The sample throughput rate is 10 h−1 with the semi-batch system. Applications to real human and bovine urine samples and CRMs of sea water (CASS-3), river water (SLRS-1 and SLRS-3) and urine (SRM 2670) are presented.",smart cities
10.1016/j.engappai.2003.09.011,Journal,Engineering Applications of Artificial Intelligence,scopus,2003-10-01,sciencedirect,Neural network model for rapid forecasting of freeway link travel time,https://api.elsevier.com/content/abstract/scopus_id/0347526141,"Estimation of freeway travel time with reasonable accuracy is essential for successful implementation of an advanced traveler information system (ATIS) for use in an intelligent transportation system (ITS). An ATIS consists of a route guiding system that recommends the most suitable route based on the traveler's requirements using the information gathered from various sources such as loop detectors and probe vehicles. This information can be disseminated through mass media or on on-board satellite-based navigational system. Based on the estimated travel times for various routes, the traveler can make a route choice. In this article, a neural network model is presented for forecasting the freeway link travel time using the counter propagation neural (CPN) network. The performance of the model is compared with a recently reported freeway link travel forecasting model using the backpropagation (BP) neural network algorithm. It is shown that the new model based on the CPN network, and the learning coefficients proposed by Adeli and Park, is nearly two orders of magnitude faster than the BP network. As such, the proposed freeway link travel-forecasting model is particularly suitable for real-time advanced travel information and management systems.",smart cities
10.1016/S1072-7515(02)01906-3,Journal,Journal of the American College of Surgeons,scopus,2003-06-01,sciencedirect,Focused assessment with sonography for trauma in weightlessness: A feasibility study,https://api.elsevier.com/content/abstract/scopus_id/0038322620,"Background
                  The Focused Assessment with Sonography for Trauma (FAST) examines for fluid in gravitationally dependent regions. There is no prior experience with this technique in weightlessness, such as on the International Space Station, where sonography is currently the only diagnostic imaging tool.
               
                  Study design
                  A ground-based (1 g) porcine model for sonography was developed. We examined both the feasibility and the comparative performance of the FAST examination in parabolic flight. Sonographic detection and fluid behavior were evaluated in four animals during alternating weightlessness (0 g) and hypergravity (1.8 g) periods. During flight, boluses of fluid were incrementally introduced into the peritoneal cavity. Standardized sonographic windows were recorded. Postflight, the video recordings were divided into 169 20-second segments for subsequent interpretation by 12 blinded ultrasonography experts. Reviewers first decided whether a video segment was of sufficient diagnostic quality to analyze (determinate). Determinate segments were then analyzed as containing or not containing fluid. A probit regression model compared the probability of a positive fluid diagnosis to actual fluid levels (0 to 500 mL) under both 0-g and 1.8-g conditions.
               
                  Results
                  The in-flight sonographers found real-time scanning and interpretation technically similar to that of terrestrial conditions, as long as restraint was maintained. On blinded review, 80% of the recorded ultrasound segments were considered determinate. The best sensitivity for diagnosis in 0 g was found to be from the subhepatic space, with probability of a positive fluid diagnosis ranging from 9% (no fluid) to 51% (500 mL fluid).
               
                  Conclusions
                  The FAST examination is technically feasible in weightlessness, and merits operational consideration for clinical contingencies in space.",smart cities
10.1016/S0968-090X(03)00022-6,Journal,Transportation Research Part C: Emerging Technologies,scopus,2003-01-01,sciencedirect,Detection-delay-based freeway incident detection algorithms,https://api.elsevier.com/content/abstract/scopus_id/0041662165,"Even though incident detection algorithms are designed and implemented for quickly detecting incidents, the criterion of mean detection delay has hardly been well defined and utilized in developing and evaluating incident detection algorithms. In addition, most incident detection algorithms do not have an optimal property in terms of detection delay with respect to false alarm rate. In the study presented in this paper, the incident detection problem was formulated as an optimization problem. To implement the algorithm, called the CUSUM algorithm that was derived from the optimization formulation of the incident detection problem, a simplified procedure was developed. Based on this procedure, three varieties of the CUSUM algorithm were developed and tested based on real incident data against a newly defined criterion for mean detection delay. Selected incident detection algorithms were also compared with the CUSUM algorithms. The comparison demonstrates the superiority of the CUSUM algorithms against other selected algorithms in reducing detection delay while maintaining an acceptable detection rate.",smart cities
10.1016/S0306-4379(02)00018-2,Journal,Information Systems,scopus,2002-12-01,sciencedirect,On-line knowledge- and rule-based video classification system for video indexing and dissemination,https://api.elsevier.com/content/abstract/scopus_id/0036888031,"Current information and communication technologies provide the infrastructure to transport bits anywhere, but do not indicate how to easily and precisely access and/or route information at the semantic level. To facilitate intelligent access to the rich multimedia data over the Internet, we develop an on-line knowledge- and rule-based video classification system that supports automatic “indexing” and “filtering” based on the semantic concept hierarchy. This paper investigates the use of video and audio content analysis, feature extraction and clustering techniques for further video semantic concept classification. A supervised rule-based video classification system is proposed using video automatic segmentation, annotation and summarization techniques for seamless information browsing and updating. In the proposed system, a real-time scene-change detection proxy performs an initial video-structuring process by splitting a video clip into scenes. Motional, visual and audio features are extracted in real-time for every detected scene by using on-line feature-extraction proxies. Higher semantics are then derived through a joint use of low-level features along with classification rules in the knowledge base. Classification rules are derived through a supervised learning process that relies on some representative samples from each semantic category. An indexing and filtering process can now be built using the semantic concept hierarchy to personalize multimedia data based on users’ interests. In real-time filtering, multiple video streams are blocked, combined, or sent to certain channels depending on whether or not the video streams are matched with the user's profile. We have extensively experimented and evaluated the classification and filtering techniques using basketball sports video data. In particular, in our experiment, the basketball video structure is examined and categorized into different classes according to distinct motional, visual and audio characteristics features by a rule-based classifier. The concept hierarchy describing the motional/visual/audio feature descriptors and their statistical relationships are reported in this paper along with detailed experimental results using on-line sports videos.",smart cities
10.1016/S0952-1976(01)00010-0,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-06-01,sciencedirect,Opportunistic planning for a fleet of transportation robots,https://api.elsevier.com/content/abstract/scopus_id/0035366212,"The Dynamic Transportation-Planning Problem (DTPP) embodies a class of real-world applications that involve the reactive routing and scheduling of a fleet of vehicles in response to dynamically changing transportation demands. Examples include mobile robots in a warehouse, taxis in an urban road network, or aeroplanes for medical evacuation. In contrast with the Vehicle Routing Problem, for which a plethora of techniques is available, few approaches exist that permit the efficient deployment of a large number of vehicles in a changing environment. This paper highlights the characteristic features of the problem, reviews possible approaches and existing techniques, and proposes a heuristic solution to the DTPP using a Blackboard-based approach. The resulting application is an intelligent transportation planning system (ITPS) for a fleet of automated robot taxis, based on the generic assumption-based truth maintained Blackboard shell (GATMBS) and comprising traffic simulation models as well as various monitoring and problem-solving strategies for assignment and routing. The Blackboard architecture supports the dynamic alteration of planned routes in response to changes in traffic conditions and passenger requests. A prototype of the ITPS has been validated in simulation using a small fleet of robot taxis with randomly generated road networks, background traffic load, and passenger requests.",smart cities
10.1016/S0952-1976(00)00070-1,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-01-01,sciencedirect,"Perception network for the team of indoor mobile robots: Concept, architecture, implementation",https://api.elsevier.com/content/abstract/scopus_id/0035311549,"The concept of perception network with application to the distributed perception processes taking place among mobile robots operating on the shared shop-floor is discussed. Its relationship with the distributed environment modeling is pointed out. The concept of geometrical database is combined with multiple classes of maps generated with particular physical sensors, in order to obtain the world model. The logical and functional structure of the perception network has been proposed to reflect the semantics of the transportation system consisting of the team of indoor mobile robots.",smart cities
10.1016/s0952-1976(99)00025-1,Journal,Engineering Applications of Artificial Intelligence,scopus,1999-01-01,sciencedirect,Railway track possession assignment using constraint satisfaction,https://api.elsevier.com/content/abstract/scopus_id/0033204515,"Resource allocation is the problem of allocating a set of resources to accomplish some task(s). Many real-world problems are resource-allocation problems, such as production planning and manpower planning. This paper reports on a case study on applying constraint-satisfaction techniques to solve a real-world resource allocation problem, referred to as the Railway Track Possession Assignment Problem, using the CHIP constraint language. The problem is to assign railway tracks to a given set of scheduled maintenance tasks according to a set of constraints. The manual problem-solving method is heuristic in nature. Experienced personnel were involved in the manual process. An expert system, called the Engineering Work Track Possession Assignment System (EWTPAS), was developed to carry out the assignment using constraint-satisfaction techniques. A new, two-phase resource allocation strategy based on constraint relaxation was developed and implemented in EWTPAS. EWTPAS succeeded in replacing the manual assignment process after test running for 1 year. EWTPAS is now in use. Besides having the advantage of being free of careless human errors, and the advantage of being independent of the availability of experienced staff, EWTPAS was found to be about 10 times more efficient than the manual method.",smart cities
10.1006/jcis.1998.5717,Journal,Journal of Colloid and Interface Science,scopus,1998-12-01,sciencedirect,Effects of substratum topography on bacterial adhesion,https://api.elsevier.com/content/abstract/scopus_id/0032396514,"The effect of substratum topography on bacterial surface colonization was studied using a chemically homogeneous silicon coupon. “Grooves” 10 μm deep and 10, 20, 30, and 40 μm wide were etched on the coupon perpendicular to the direction of flow. Flow (Re = 5.5) of a bacterial suspension (108cells/ml) was directed through a parallel plate flow chamber inverted on a confocal microscope. Images were collected in real time to obtain rate and endpoint colonization data for each of three strains of bacteria:Pseudomonas aeruginosaand motile and nonmotilePseudomonas fluorescens.A higher velocity experiment (Re = 16.6) and an abiotic control using hydrophilic, negatively charged microspheres were also performed. Using a colloidal deposition expression, the initial rates of attachment were compared.P. aeruginosaattached at a higher rate thanP. fluorescensmot+ which attached at a higher rate thanP. fluorescensmot−. For all bacteria the rate was independent of groove size and was greatest on the downstream edges of the grooves. Only the motile organisms were found in the bottoms of the grooves. A higher fluid velocity resulted in an increase in the initial rate of attachment. In contrast, there was no adhesion of the beads. Attachment of the bacteria appears to be predominated by transport from the bulk phase to the substratum.",smart cities
10.1016/S0921-8890(98)00005-0,Journal,Robotics and Autonomous Systems,scopus,1998-10-31,sciencedirect,A robust landmark-based system for vehicle location using low-bandwidth vision,https://api.elsevier.com/content/abstract/scopus_id/0032180335,"This paper presents novel computer algorithms, a system architecture, and the prototype implementation of a vision-based automatic vehicle location system. The objective of the vehicle location system is to keep track of the vehicle location for a human driver, and perhaps to provide the driver with real-time audio directions to his destination. The techniques developed here are equally applicable to autonomous robot navigation. The prototype system uses odometer readings and a skeleton map to perform dead reckoning, and uses low-bandwidth visual information and neural networks to recognize places for correcting cumulative dead reckoning errors. The visual information is also used to detect turns, for dead reckoning at intersections. The system is self-contained in the sense that it requires no infrastructure outside the vehicle, such as external beacons installed on roadways or satellites used by Global Positioning Systems (GPS). The system maintains a large number of location hypotheses and searches for a large number of landmarks stored in a database in real time. Hence the system is robustly able to recover the vehicle location after being lost for various reasons. The system has been tested, with success, in both day and night time, in all four seasons, and on roads in New York City, a regional highway, and on suburban streets.",smart cities
10.1016/S0273-1177(97)00399-2,Journal,Advances in Space Research,scopus,1998-01-01,sciencedirect,Gravitaxis and graviperception in Euglena gracilis,https://api.elsevier.com/content/abstract/scopus_id/0032250077,"Gravitactic orientation in the flagellate Euglena gracilis is mediated by an active physiological receptor rather than a passive alignment of the cells. During a recent space flight on the American shuttle Columbia the cells were subjected to different accelerations between 0 and 1.5 × g and tracked by computerized real-time image analysis. The dependence of orientation on acceleration followed a sigmoidal curve with a threshold at ≤0.16 × g and a saturation at about 0.32 × g. No adaptation of the cells to the conditions of weightlessness was observed over the duration of the space mission (12 days). Under terrestrial conditions graviorientation was eliminated when the cells were suspended in a medium the density of which (Ficoll) equaled that of the cell body (1.04 g/ml) and was reversed at higher densities indicating that the whole cytoplasm exerts a pressure on the respective lower membrane. There it probably activates stretch-sensitive calcium specific ion channels since gravitaxis can be affected by gadolinium which is a specific inhibitor of calcium transport in these structures. The sensory transduction chain could involve modulation of the membrane potential since ion channel blockers, ionophores and ATPase inhibitors impair graviperception.",smart cities
10.1016/s0952-1976(98)00013-x,Journal,Engineering Applications of Artificial Intelligence,scopus,1998-01-01,sciencedirect,An architectural framework for the construction of hybrid intelligent forecasting systems: Application for electricity demand prediction,https://api.elsevier.com/content/abstract/scopus_id/0032131235,"This paper presents an implemented architectural framework for the construction of hybrid intelligent forecasters for utility demand prediction. The framework has been implemented as the intelligent forecasters construction set (IFCS), which supports the intelligent techniques of fuzzy logic, artificial neural networks, and knowledge-based and case-based reasoning. IFCS is also a hybrid programming tool, which allows the developer to implement forecasters by means of object-oriented visual programming, knowledge-based programming and procedural programming. The system was implemented on the real-time expert-system shell G2, with the G2 Diagnostic Assistant (GDA) and NeurOn-Line (NOL) modules. Rules, procedures and flow diagrams are organized into a hierarchy of workspaces. The modularity of IFCS allows the subsequent addition of other modules of intelligent techniques.
                  IFCS was applied for daily power-load prediction in the city of Regina. The power-load data set was separated into subclasses, and a neural-network module consisting of backpropagation networks was applied to each of them. The data set was also modeled using a linear regression (LR) and a case-based reasoning (CBR) program, and their results were compared to those from the neural-network approach.",smart cities
10.1053/ajkd.1998.v31.pm9506688,Journal,American Journal of Kidney Diseases,scopus,1998-01-01,sciencedirect,Accuracy of dilution techniques for access flow measurement during hemodialysis,https://api.elsevier.com/content/abstract/scopus_id/0031939914,"Access flow is now widely measured by creating artificial recirculation with the dialysis lines reversed and using dilution methods that sense either ultrasound velocity, electrical impedance, optical, or thermal changes. This study identifies and quantifies factors that influence the accuracy of access flow measurements and recommends ways to reduce these errors. Two major sources of access flow measurement error are identified, arising firstly from the second pass of the indicator by recirculation through the cardiopulmonary system (cardiopulmonary recirculation, CPR), and secondly from changes in venous line blood flow (Qb) and vascular access flow induced by the pressure of venous bolus injections. These errors are considered from theory, by direct measurement of access flow in a sheep model, and by analysis of clinical data. Two extremes for the venous introduction of indicator can be considered in access flow measurements, a slow infusion, which perturbs neither the venous line flow nor access flow but increases the error attributable to the second pass of the indicator by recirculation through cardiopulmonary system, or rapid injection, which eases separation of the second pass of the indicator signal but generates changes in the venous flow and access flow. If CPR is not eliminated, the area added to that of the first pass of indicator ranges up to 40%. Good time resolution could permit the separation of the areas generated by the first and second passage of the indicator. In sheep experiments, injections of 5 or 10 mL into a venous port close to the vascular access caused Qb to change by 20% to 40%. Both the animal experiments and analysis of raw data collected during routine clinical dialysis showed that moving the injection site sufficiently far from the patient, before or into the venous bubble trap, reduced the increase in Qb to only approximately 5% during the critical time when the concentration curve is changing for most tubing brands (Baxter, Belco, Gambro, Hospal, Medisystem, and National Medical Care). Because of the smaller volume of the venous bubble chamber in Cobe tubing (Cobe, Centrysystem 3), this brand showed approximately a 20% increase in Qb. Moving the site of bolus injections to before the bubble trap in the sheep experiments also eliminated the influence of changes in access flow. An additional error in access flow measurement of 20% or more arises from the use of flow reading taken from pump setting rather than a measured flow. The discrepancy between the real flow and pump setting is attributable to needle size, vascular access conditions, or pump calibration. The results show that problems can be minimized by using a dual sensor system that retains the precise timing necessary for separation of access recirculation from CPR; by accurate measurement of dialyzer blood flow; by moving the site of injection to before the venous bubble trap, sufficiently far from the patient, and correcting for any remaining deviations in flow in the venous line concurrent with the dilution curve. (Am J Kidney Dis 1998 Mar;31(3):502-8)",smart cities
10.1016/S0169-7722(96)00060-5,Journal,Journal of Contaminant Hydrology,scopus,1997-04-01,sciencedirect,Transport of radionuclides in natural fractures: Some aspects of laboratory migration experiments,https://api.elsevier.com/content/abstract/scopus_id/0030614305,"Results are reported for a series of migration experiments performed in a hydraulically characterized, single, natural fracture in a block of granite with overall dimensions of 1 × 1 × 0.7 m (all approximate), using the conservative, poorly sorbing and strongly sorbing radionuclides 3H20, 131I, 22Na, 85Sr, 137Cs, 60Co, 154,155Eu, 237Np, and 238Pu. The volumetric flow velocity of the transport solution was 3 ml h−1, giving a residence time in the fracture of approximately 50 h. Elution profiles were obtained for 3H20, 131I, 22Na, 85Sr and 137Cs but no evidence of the other radionuclides was observed in the eluent. Results from supporting static sorption measurements on crushed geological materials and granite coupons showed in general higher sorption on alteration minerals than on granite. Sorption was lowest for 22Na and 85Sr.
                  The migration of 131I, 22Na, 85Sr through the fracture in real time was followed using end-window Geiger-Müller probes located in unused boreholes. Additional information, obtained by alpha and gamma scanning of the fracture surfaces after separating the block along the fracture, confirmed that transport had occurred along the flow path predicted from the hydraulic characterization of the fracture and that, over a 5.5 month period, the bulk of the injected 137Cs had migrated only 75 cm along the flow path. The 60Co, the rare earths and the actinides had not moved beyond the location of the injection borehole, suggesting that fracture infilling minerals played a major role in retarding radionuclide transport. Additional confirmation of the role of secondary minerals in radionuclide retardation was obtained using selective sequential extraction on the fracture surfaces. These observations support the inclusion of sorption data for fracture infilling minerals in the sorption database developed for the geosphere model for the Canadian Nuclear Fuel Waste Management Program.",smart cities
10.1016/S0968-090X(97)00007-7,Journal,Transportation Research Part C: Emerging Technologies,scopus,1997-01-01,sciencedirect,A parallel algorithm to extract information about the motion of road traffic using image analysis,https://api.elsevier.com/content/abstract/scopus_id/0031120013,"Road traffic movement is a very important source of information in traffic management. Although systems exist which can detect the presence of a vehicle and its speed under certain conditions, there is generally a lack of effective means to measure both the speed and direction of traffic movement. This is particularly true for road junctions, where conflicting traffic shares the same space and where some control strategy could be more effectively applied with the help of speed and direction estimates. The increasing use of closed circuit television (CCTV) systems has provided the opportunity to apply image processing techniques to extract such information. However, such techniques are computationally intensive in general, and the application of parallel processing methods is one of the best choices which could bring the desired acquisition of movement information into practical reality. This paper describes a parallel video-based image analysis system which is capable of extracting movement information, including direction and speed, of road vehicular traffic over any part of a road surface. The prototype has been implemented on an array of 36 transputers and an image grabber with a SUN SPARC IPC as the host machine. The software mainly consists of median filtering, feature extraction, spatio-temporal analysis, matching of image features in successive images by neural networks and aggregation of matched results. This algorithm has been tested using data for a signal-controlled junction aiming to capture an opposed turning traffic movement with promising results. It has also been shown that a real-time system based on the described algorithm is feasible.",smart cities
10.1016/0165-0114(94)00293-G,Journal,Fuzzy Sets and Systems,scopus,1995-06-23,sciencedirect,Hierarchical fuzzy control of multivariable systems,https://api.elsevier.com/content/abstract/scopus_id/0029323823,The paper considers the problem of hierarchical fuzzy control of multivariable systems. Some terms and definitions with regard to this problem are given. A method of hierarchical control is proposed in which the control actions have two components: local and global. The method is used for simulating the behaviour of an urban traffic network and the results are analysed. It is shown that the number of fuzzy relations is significantly reduced and thus real time control implementation is facilitated.,smart cities
10.1016/0140-3664(95)94479-U,Journal,Computer Communications,scopus,1995-01-01,sciencedirect,Traffic prediction and dynamic bandwidth allocation over ATM: a neural network approach,https://api.elsevier.com/content/abstract/scopus_id/0029356850,"ATM (Asynchronous Transfer Mode) has been recommended as the transport vehicle for Broadband Integrated Service Digital Networks (BISDN). The ATM technology offers a great flexibility of transmission bandwidth allocation to accommodate diverse demands of multimedia connections, which include data, voice, video, graphics and images. One major application in ATM networks is to provide real-time, low-loss and minimum-delay transmission of variable bit rate (VBR) traffic which is highly bursty, non-stationary and correlated. In this work we adopt neural network methodology to predict VBR traffic represented by a continuous autoregressive (AR) Markov model. We have found that a simple 1-5-1 backpropagation neural network can accurately predict the VBR traffic. Based on prediction results obtained from neural networks, we propose a dynamic bandwidth allocation scheme for ATM. The proposed scheme is simulated under various traffic loads and buffer sizes. Its performance in terms of cell loss, cell delay and link utilization is examined and compared with two other bandwidth allocation schemes: the static average bandwidth allocation scheme, and the optimal (ideal) bandwidth allocation scheme. Experiments show that for most of the time, performance of the proposed dynamic bandwidth allocation is much better than that of the static average bandwidth allocation, and in many cases it is very close to that of the ideal bandwidth allocation.",smart cities
10.1016/0004-3702(94)00020-2,Journal,Artificial Intelligence,scopus,1995-01-01,sciencedirect,Controlling cooperative problem solving in industrial multi-agent systems using joint intentions,https://api.elsevier.com/content/abstract/scopus_id/0029326031,"One reason why Distributed AI (DAI) technology has been deployed in relatively few real-size applications is that it lacks a clear and implementable model of cooperative problem solving which specifies how agents should operate and interact in complex, dynamic and unpredictable environments. As a consequence of the experience gained whilst building a number of DAI systems for industrial applications, a new principled model of cooperation has been developed. This model, called Joint Responsibility, has the notion of joint intentions at its core. It specifies pre-conditions which must be attained before collaboration can commence and prescribes how individuals should behave both when joint activity is progressing satisfactorily and also when it runs into difficulty. The theoretical model has been used to guide the implementation of a general-purpose cooperation framework and the qualitative and quantitative benefits of this implementation have been assessed through a series of comparative experiments in the real-world domain of electricity transportation management. Finally, the success of the approach of building a system with an explicit and grounded representation of cooperative problem solving is used to outline a proposal for the next generation of multi-agent systems.",smart cities
10.1016/S0176-1617(11)81898-5,Journal,Journal of Plant Physiology,scopus,1995-01-01,sciencedirect,Kinetics of Aluminum Uptake by Cell Suspensions of Phaseolus vulgaris L.,https://api.elsevier.com/content/abstract/scopus_id/0029138905,"The Kinetics of aluminum (Al) uptake by cell suspensions derived from an Al-resistant (Dade) an an Al-sensitive (Romano) cultivar of Phaseolus vulgaris L. were investigated. Uptake of Al from low-volume (3-mL) uptake solutions containing 75 μM AlCl 3 was rapid during the first 20 min with little additional absorption occurring over the remainder of the 180 min experimental period. In contrast studies with excised roots showed a longer rapid phase (30 min) which was followed by a linear phase of uptake. Differences in Al uptake between excised roots and cell suspensions appear to reflect the unique characteristics of our low-volume cell system rather than real differences in uptake between the two systems. The rate, extent, and saturable nature of uptake in this cell system suggested that depletion of Al from uptake solutions may have been responsible for the lacf of an observable linear phase of uptake. However, when the concentration of Al in uptake solutions was increased to 500 and 1000 μM, total accumulation of Al increased, while the general pattern of uptake was not affected. Moreover, mock-uptake experiments at these high concentrations ruled out the possibility of artifacts arising from formation of solid phase phase Al. While increasing the concentration of Al in uptake solutions provided a means of increasing Al available for uptake, Pyrocatechol violet analysis of monomeric Al indicate incomplete recovery of added Al particularly at concentrations above 300 μM. To overcome potential problems associate with the formation of complex Al species in solution, the total amount of Al in solution was increased using a high-volume (100-mL), low-concentration (75-μM AlC13) system. Under these conditions, a biphasic pattern of uptake was observed, with a rapid phase of uptake during the first 20 min, and a linear phase of uptake over the remainder of the 180 min uptake period. We were also able to isolate the linear phase of uptake after desorption in 9.0 mM citric acid. These results suggest that the basic pattern of Al uptake by cell suspensions (saturated vs. linear) is strongly affected by the speciation of Al, which is indirectly related to the volume of uptake solutions. The biphasic pattern of uptake observed in our high-volume system also supports the hypothesis that the kinetics of short-term Al uptake observed in excise roots reflect transport events occurring at the cellular level. We believe further investigation of the kinetics of Al uptake at the cellular level could provide a more direct means of measuring the uptake of Al across the plasma membrane in plants.",smart cities
10.1016/S0893-6080(05)80092-9,Journal,Neural Networks,scopus,1992-01-01,sciencedirect,Forecasting the behavior of multivariate time series using neural networks,https://api.elsevier.com/content/abstract/scopus_id/0026954346,"This paper presents a neural network approach to multivariate time-series analysis. Real world observations of flour prices in three cities have been used as a benchmark in our experiments. Feedforward connectionist networks have been designed to model flour prices over the period from August 1972 to November 1980 for the cities of Buffalo, Minneapolis, and Kansas City. Remarkable success has been achieved in training the networks to learn the price curve for each of these cities and in making accurate price predictions. Our results show that the neural network approach is a leading contender with the statistical modeling approaches.",smart cities
