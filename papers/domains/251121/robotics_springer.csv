contentType,identifier,title,publicationName,doi,publisher,publicationDate,onlineDate,abstract,url,database
Article,doi:10.1007/s12525-021-00494-z,"Artificial intelligence (AI) and robotics in travel, hospitality and leisure",Electronic Markets,10.1007/s12525-021-00494-z,Springer,2021-09-01,2021-09-03,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-021-00494-z,springer
Article,doi:10.1007/s00146-020-01123-7,"Where is the human got to go? Artificial intelligence, machine learning, big data, digitalisation, and human–robot interaction in Industry 4.0 and 5.0",AI & SOCIETY,10.1007/s00146-020-01123-7,Springer,2021-09-01,2021-01-15,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01123-7,springer
Article,doi:10.1007/s11119-021-09856-1,Field evaluations of a deep learning-based intelligent spraying robot with flow control for pear orchards,Precision Agriculture,10.1007/s11119-021-09856-1,Springer,2021-09-19,2021-09-19,"This study proposes a deep learning-based real-time variable flow control system using the segmentation of fruit trees in a pear orchard. The real-time flow rate control, undesired pressure fluctuation and theoretical modeling may differ from those in the real world. Therefore, two types of preliminary experiments were conducted to examine the linear relationship of the flow rate modeling. Through preliminary experiments, the parameters of the pulse width modulation (PWM) controller were optimized, and a field experiment was conducted to confirm the performance of the variable flow rate control system. The field test was conducted for three cases: all open, on/off control, and variable flow rate control, showing results of 56.15 ( $$\pm 17.24$$ ± 17.24 )%, 68.95 ( $$\pm 21.12)$$ ± 21.12 ) % and 57.33 ( $$\pm 21.73$$ ± 21.73 )% for each control. The result revealed that the proposed system performed satisfactorily, showing that pesticide use and the risk of pesticide exposure could be reduced.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11119-021-09856-1,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-2937-2_10,Object Recognition and Classification for Robotics Using Virtualization and AI Acceleration on Cloud and Edge,"Data Management, Analytics and Innovation",10.1007/978-981-16-2937-2_10,Springer,2022-01-01,2021-09-20,"With the development of cloud robotics, a much broader scope of multidisciplinary applications to create smart systems is now available. The “Artificially Intelligent” system's brains are in the cloud. The cloud can hold data centers, deep learning, communication support, etc. With the help of edge computing, VM-based cloudlets, deploying deep learning implementation systems are a more practical option rather than one single system doing all the tasks. The mobile applications and IoT devices often produce streaming data which requires real-time analysis and control. When the application involves end devices as hardware like Raspberry Pi and laptops working at edge, an acceleration in the result generation is also necessary. This paper presents its observations with the implementation of one such machine learning application of object detection and recognition, i.e., You-Only-Look-Once (YOLO) on a robotic environment working on the number of clients and servers ends. Differentiating cloud and edge, we have demonstrated the analysis and results where output efficiency leverage is seen with AI acceleration with toolkits like Intel's OpenVINO.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2937-2_10,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-81007-8_141,An Emotional Interaction Robot with Facial Expression Recognition Realized on Raspberry Pi and STM32,Advances in Intelligent Automation and Soft Computing,10.1007/978-3-030-81007-8_141,Springer,2022-01-01,2021-07-25,"In this paper, we propose a framework of emotional interaction robot which can recognize seven basic facial expressions of users and make responses accordingly. Considering the benefits provided by the facial expression recognition system, it is applied to the companion robot to greatly enrich the emotional communications between human and robots. The proposed framework mainly consists of two modules, the module of facial expression recognition and the interaction module. The module of facial expression recognition is implemented based on a CNN trained on the FER2013 dataset and realized on Raspberry Pi 3b+. The interaction module is realized by a TFT-LCD and a speaker controlled by the STM32 single-chip microcomputer. When receiving the signal from the control button on STM32, the recognition module reads in a frame from the video stream taken by the camera, and then performs the preprocessing and recognizes the facial expression. After successfully recognizing a kind of emotion, the recognition result is sent to the interaction model, and then it displays one of emojis stored in its SD card and plays music accordingly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81007-8_141,springer
Article,doi:10.1007/s11370-021-00387-2,Reinforcement learning-based dynamic obstacle avoidance and integration of path planning,Intelligent Service Robotics,10.1007/s11370-021-00387-2,Springer,2021-10-06,2021-10-06,"Deep reinforcement learning has the advantage of being able to encode fairly complex behaviors by collecting and learning empirical information. In the current study, we have proposed a framework for reinforcement learning in decentralized collision avoidance where each agent independently makes its decision without communication with others. In an environment exposed to various kinds of dynamic obstacles with irregular movements, mobile robot agents could learn how to avoid obstacles and reach a target point efficiently. Moreover, a path planner was integrated with the reinforcement learning-based obstacle avoidance to solve the problem of not finding a path in a specific situation, thereby imposing path efficiency. The robots were trained about the policy of obstacle avoidance in environments where dynamic characteristics were considered with soft actor critic algorithm. The trained policy was implemented in the robot operating system (ROS), tested in virtual and real environments for the differential drive wheel robot to prove the effectiveness of the proposed method. Videos are available at https://youtu.be/xxzoh1XbAl0 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00387-2,springer
Article,doi:10.1007/s11063-020-10311-x,Knowledge Acquisition and Design Using Semantics and Perception: A Case Study for Autonomous Robots,Neural Processing Letters,10.1007/s11063-020-10311-x,Springer,2021-10-01,2020-07-27,"The pervasive use of artificial intelligence and neural networks in several different research fields has noticeably improved multiple aspects of human life. The application of these techniques to machines has made them progressively more “intelligent” and able to solve tasks considered extremely complex for a human being. This technological evolution has deeply influenced the way we interact with machines. Purely symbolic artificial intelligence and techniques like ontologies, have also been successfully used in the past applied to robotics, but have also shown some limitations and failings in the knowledge construction task. In fact, the exhibited “intelligence” is rarely the result of a real autonomous decision, but it is rather hard-encoded in the machine. While a number of approaches have already been proposed in literature concerning knowledge acquisition from the surrounding environment, they are either exclusively based on low-level features or they involve solely high-level semantics-based attributes. Moreover, they often don’t use a general high-level knowledge base for grounding the acquired knowledge. In this contexts, the use of semantics technologies, such as ontologies, is mostly employed for action-oriented tasks. In this article we propose an extension of a novel approach for knowledge acquisition based on a general semantic knowledge-base and the fusion of semantics and visual information by means of neural networks and ontologies. The proposed approach has been implemented on a humanoid robotic platform and the experimental results are shown and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-020-10311-x,springer
Article,doi:10.1007/s40313-021-00829-3,A New Mechanism for Collision Detection in Human–Robot Collaboration using Deep Learning Techniques,"Journal of Control, Automation and Electrical Systems",10.1007/s40313-021-00829-3,Springer,2021-09-29,2021-09-29,"Human–robot collaboration is increasingly present not only in research environments, but also in industry and many contemporary day-to-day activities. There is a need for the automation of tasks ranging from the simplest to the most complex ones. The insertion of robotic arms provides a considerable step useful in achieving this goal. In this context, safety remains a concern, however. Among the most frequent issue in this collaboration context is human–robot collision. While focus has been on automation efficiency of the of the activities, there is a growing need to reduce or even prevent damage to the involved agents. As part of this goal, a new mechanism for detecting human–robot collisions is proposed in this article. It has been tested in a well-controlled scenario using equipment commonly present in collaborative scenarios for maintenance on a radio base station. The robot used is a UR5 robotic arm in addition to three 2D cameras and a network rack. In our experimental scenario, a person interacts with the network devices installed within the rack while conducting basic collaborative activities inserted in this context. For collision detection, deep learning models were used and evaluated. These were trained to detect overlap between humans and robots considering the view and perspectives from three different cameras. Finally, a new ensemble learning system is proposed in order to establish whether or not a collision took place. It receives as input the result of overlap detection through deep learning models. Results suggest that the proposed system is capable of detecting collisions with an average global accuracy of 89.81% of correctness in a well-controlled scenario. The effectiveness of the proposed ensemble is exposed in comparison with the use of only one of the cameras for decision-making. Finally, the proposed system is shown to detect collisions in real time and to achieve a low response time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40313-021-00829-3,springer
Article,doi:10.1007/s00146-021-01226-9,"Pasquale, Frank. New Laws of Robotics: Defending Human Expertise in the Age of AI. Cambridge, Massachusetts: The Belknap Press of Harvard University Press, 2020",AI & SOCIETY,10.1007/s00146-021-01226-9,Springer,2021-09-01,2021-05-31,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01226-9,springer
Article,doi:10.1007/s42438-021-00242-8,Review of Cathrine Hasse (2020). Posthumanist Learning: What Robots and Cyborgs Teach us About Being Ultra-social,Postdigital Science and Education,10.1007/s42438-021-00242-8,Springer,2021-07-22,2021-07-22,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42438-021-00242-8,springer
Article,doi:10.1007/s11948-021-00306-9,"Rights for Robots: Artificial Intelligence, Animal and Environmental Law (2020) by Joshua Gellers",Science and Engineering Ethics,10.1007/s11948-021-00306-9,Springer,2021-04-19,2021-04-19,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-021-00306-9,springer
Article,doi:10.1007/s10994-021-05982-z,Grounded action transformation for sim-to-real reinforcement learning,Machine Learning,10.1007/s10994-021-05982-z,Springer,2021-09-01,2021-05-13,"Reinforcement learning in simulation is a promising alternative to the prohibitive sample cost of reinforcement learning in the physical world. Unfortunately, policies learned in simulation often perform worse than hand-coded policies when applied on the target, physical system. Grounded simulation learning ( gsl ) is a general framework that promises to address this issue by altering the simulator to better match the real world (Farchy et al. 2013 in Proceedings of the 12th international conference on autonomous agents and multiagent systems (AAMAS)). This article introduces a new algorithm for gsl —Grounded Action Transformation (GAT)—and applies it to learning control policies for a humanoid robot. We evaluate our algorithm in controlled experiments where we show it to allow policies learned in simulation to transfer to the real world. We then apply our algorithm to learning a fast bipedal walk on a humanoid robot and demonstrate a 43.27% improvement in forward walk velocity compared to a state-of-the art hand-coded walk. This striking empirical success notwithstanding, further empirical analysis shows that gat may struggle when the real world has stochastic state transitions. To address this limitation we generalize gat to the stochastic gat ( sgat ) algorithm and empirically show that sgat leads to successful real world transfer in situations where gat may fail to find a good policy. Our results contribute to a deeper understanding of grounded simulation learning and demonstrate its effectiveness for applying reinforcement learning to learn robot control policies entirely in simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-021-05982-z,springer
Article,doi:10.1007/s42979-021-00817-z,Deep Reinforcement Learning of Map-Based Obstacle Avoidance for Mobile Robot Navigation,SN Computer Science,10.1007/s42979-021-00817-z,Nature,2021-08-18,2021-08-18,"Autonomous and safe navigation in complex environments without collisions is particularly important for mobile robots. In this paper, we propose an end-to-end deep reinforcement learning method for mobile robot navigation with map-based obstacle avoidance. Using the experience collected in the simulation environment, a convolutional neural network is trained to predict the proper steering operation of the robot based on its egocentric local grid maps, which can accommodate various sensors and fusion algorithms. We use dueling double DQN with prioritized experienced replay technology to update parameters of the network and integrate curriculum learning techniques to enhance its performance. The trained deep neural network is then transferred and executed on a real-world mobile robot to guide it to avoid local obstacles for long-range navigation. The qualitative and quantitative evaluations of the new approach were performed in simulations and real robot experiments. The results show that the end-to-end map-based obstacle avoidance model is easy to deploy, without any fine-tuning, robust to sensor noise, compatible with different sensors, and better than other related DRL-based models in many evaluation indicators.",https://www.nature.com/articles/s42979-021-00817-z,springer
Article,doi:10.1007/s10994-021-06019-1,Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics,Machine Learning,10.1007/s10994-021-06019-1,Springer,2021-06-24,2021-06-24,"Selecting the right tuning parameters for algorithms is a pravelent problem in machine learning that can significantly affect the performance of algorithms. Data-efficient optimization algorithms, such as Bayesian optimization, have been used to automate this process. During experiments on real-world systems such as robotic platforms these methods can evaluate unsafe parameters that lead to safety-critical system failures and can destroy the system. Recently, a safe Bayesian optimization algorithm, called  SafeOpt , has been developed, which guarantees that the performance of the system never falls below a critical value; that is, safety is defined based on the performance function. However, coupling performance and safety is often not desirable in practice, since they are often opposing objectives. In this paper, we present a generalized algorithm that allows for multiple safety constraints separate from the objective. Given an initial set of safe parameters, the algorithm maximizes performance but only evaluates parameters that satisfy safety for all constraints with high probability. To this end, it carefully explores the parameter space by exploiting regularity assumptions in terms of a Gaussian process prior. Moreover, we show how context variables can be used to safely transfer knowledge to new situations and tasks. We provide a theoretical analysis and demonstrate that the proposed algorithm enables fast, automatic, and safe optimization of tuning parameters in experiments on a quadrotor vehicle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-021-06019-1,springer
Article,doi:10.1007/s41315-021-00179-y,Robot grasping in dense clutter via view-based experience transfer,International Journal of Intelligent Robotics and Applications,10.1007/s41315-021-00179-y,Springer,2021-05-28,2021-05-28,"To perform object grasping in dense clutter, we propose a novel algorithm for grasp detection. To obtain grasp candidates, we developed instance segmentation and view-based experience transfer as part of the algorithm. Subsequently, we established an algorithm for collision avoidance and stability analysis to determine the optimal grasp for robot grasping. The strategy for the view-based experience transfer was to first find the object view and then transfer the grasp experience onto the clutter scenario. This strategy has two advantages over existing learning-based methods for finding grasp candidates. (1) our approach can effectively exclude the influence of noise or occlusion on images and precisely detect grasps that are well aligned on each target object. (2) our approach can efficiently find out optimal grasps on each target object and has the flexibility of adjusting and redefining the grasp experience based on the type of target object. We evaluated our approach using some open-source datasets and with a real-world robot experiment, which involved a six-axis robot arm with a two-jaw parallel gripper and a Kinect V2 RGB-D camera. The experimental results show that our proposed approach can be generalized to objects with complex shape, and is able to grasp on dense clutter scenarios where different types of objects are in a bin. To demonstrate our grasping pipeline, a video is provided at https://youtu.be/gQ3SO6vtTpA .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-021-00179-y,springer
Article,doi:10.1007/s43154-021-00053-6,"Ethics of Corporeal, Co-present Robots as Agents of Influence: a Review",Current Robotics Reports,10.1007/s43154-021-00053-6,Springer,2021-06-01,2021-04-14,"Purpose of Review To summarize the set of roboethics issues that uniquely arise due to the corporeality and physical interaction modalities afforded by robots, irrespective of the degree of artificial intelligence present in the system. Recent Findings One of the recent trends in the discussion of ethics of emerging technologies has been the treatment of roboethics issues as those of “embodied AI,” a subset of AI ethics. In contrast to AI, however, robots leverage human’s natural tendency to be influenced by our physical environment. Recent work in human-robot interaction highlights the impact a robot’s presence, capacity to touch, and move in our physical environment has on people, and helping to articulate the ethical issues particular to the design of interactive robotic systems. Summary The corporeality of interactive robots poses unique sets of ethical challenges. These issues should be considered in the design irrespective of and in addition to the ethics of artificial intelligence implemented in them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-021-00053-6,springer
Article,doi:10.1007/s12555-020-0069-6,Positioning of the Robotic Arm Using Different Reinforcement Learning Algorithms,"International Journal of Control, Automation and Systems",10.1007/s12555-020-0069-6,Springer,2021-04-01,2021-02-18,"Robots are programmed using either the on-line mode, in which the robot programmer manually controls the movement of the robot indicating individual trajectory points or the off mode, in which the programmer enters the program code with predefined trajectory points. Both methods are not easy to be successfully implemented in practice, which is why the research on the development of self-learning methods can be useful. In this paper, for the robot’s positioning task, the four Reinforcement Learning (RL) algorithms in six combinations are investigated. At first, the basics of these algorithms are described. Then they are used in positioning control of the robot’s arm model and the evaluation of positioning accuracy, motion trajectory, and the number of steps required to achieve the goal is taken into account. The simulation results are recorded. The same tests were repeated in laboratory conditions, in which the Mitsubishi robot was controlled. The simulation results are compared with results obtained in reality. Positive results that have been obtained indicate, that the RL algorithms can be successfully applied for the learning of positioning control of a robot arm.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12555-020-0069-6,springer
Article,doi:10.1007/s11370-021-00358-7,Combining CNN and LSTM for activity of daily living recognition with a 3D matrix skeleton representation,Intelligent Service Robotics,10.1007/s11370-021-00358-7,Springer,2021-04-01,2021-03-10,"In socially assistive robotics, human activity recognition plays a central role when the adaptation of the robot behavior to the human one is required. In this paper, we present an activity recognition approach for activities of daily living based on deep learning and skeleton data. In the literature, ad hoc features extraction/selection algorithms with supervised classification methods have been deployed, reaching an excellent classification performance. Here, we propose a deep learning approach, combining CNN and LSTM, that exploits both the learning of spatial dependencies correlating the limbs in a skeleton 3D grid representation and the learning of temporal dependencies from instances with a periodic pattern that works on raw data and so without requiring an explicit feature extraction process. These models are proposed for real-time activity recognition, and they are tested on the CAD-60 dataset. Results show that the proposed model behaves better than an LSTM model thanks to the automatic features extraction of the limbs’ correlation. “New Person” results show that the CNN-LSTM model achieves $$95.4\%$$ 95.4 % of precision and $$94.4\%$$ 94.4 % of recall, while the “Have Seen” results are $$96.1\%$$ 96.1 % of precision and $$94.7\%$$ 94.7 % of recall.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00358-7,springer
Article,doi:10.1007/s40430-021-03157-4,Task-space impedance control of a parallel Delta robot using dual quaternions and a neural network,Journal of the Brazilian Society of Mechanical Sciences and Engineering,10.1007/s40430-021-03157-4,Springer,2021-08-28,2021-08-28,"The Delta robot, widely used in fast pick-and-place applications with pure position control, is a parallel kinematic chain with three rotational inputs resulting in three pure translations at the end-effector. This paper proposes a complete task-space impedance control with inverse dynamics to give this robot compliant behavior, enabling it to be used in tasks involving physical interaction. For that purpose, the well-known usage of dual quaternion algebra for kinematics modeling is novelly integrated with a neural network to compose a compact representation for the forward kinematics function, that is singularity-free and suitable for real-time calculation. This network computes the forward kinematics more than 150 times faster than a numeric equation solving algorithm, with an average estimation error of less than 0.5 mm. The proposed algorithm is implemented in a rigid body simulator, and the performance of the complete system is analyzed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40430-021-03157-4,springer
Article,doi:10.1007/s12369-021-00819-0,Dynamic Iranian Sign Language Recognition Using an Optimized Deep Neural Network: An Implementation via a Robotic-Based Architecture,International Journal of Social Robotics,10.1007/s12369-021-00819-0,Springer,2021-08-29,2021-08-29,"Sign language is a non-verbal communication tool used by the deaf. A robust sign language recognition framework is needed to develop Human–Robot Interaction (HRI) platforms that are able to interact with humans via sign language. Iranian sign language (ISL) is composed of both static postures and dynamic gestures of the hand and fingers. In this paper, we present a robust framework using a Deep Neural Network (DNN) to recognize dynamic ISL gestures captured by motion capture gloves in Real-Time. To this end, first, a dataset of fifteen ISL classes was collected in time series; then, this dataset was virtually augmented and pre-processed using the “state-image” method to produce a unique collection of images, each image corresponding to a specific set of sequential data representing a class. Next, by implementing a continuous Genetic algorithm, an optimal deep neural network with the minimum number of weights (trainable parameters) and the maximum overall accuracy was found. Finally, the dataset was fed to the DNN to train the model. The results showed that the optimization process was successful at finding a DNN structure highly suitable for this application, with 99.7% accuracy on the verification (test) data. Then, after implementing the module in a robotic architecture, an HRI experiment was conducted to assess the system’s performance in real-time applications. Preliminary statistical analysis on the standard UTAUT model for eight participants showed that the system can recognize ISL signs quickly and accurately during human–robot interaction. The proposed methodology can be used for other sign languages as no specific characteristics of ISL were used in the preprocessing or training stage.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00819-0,springer
Article,doi:10.1007/s10015-021-00687-x,Comparison of high-dimensional neural networks using hypercomplex numbers in a robot manipulator control,Artificial Life and Robotics,10.1007/s10015-021-00687-x,Springer,2021-08-01,2021-06-15,"This study considers high-dimensional neural networks based on hypercomplex numbers that form a four-dimensional algebra over the field of real numbers, such as quaternion, coquaternion, hyperbolic-quaternion, bicomplex and dual-complex numbers. In addition, the applicability of the networks in the robot manipulator’s control system is explored. In the control system, the output of the high-dimensional neural network is used as the control input for the robot manipulator to ensure that the end-effector of the robot manipulator tracks the desired trajectory in a three-dimensional space. Computational experiments are conducted on controlling a three-link robot manipulator to evaluate the learning and control performance of the high-dimensional neural networks. The simulation results demonstrate that the quaternion-valued neural network achieves better performance in learning and control tasks compared to other networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-021-00687-x,springer
Article,doi:10.1007/s10846-021-01333-1,Deep Reinforcement Learning for a Humanoid Robot Soccer Player,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01333-1,Springer,2021-06-26,2021-06-26,"This paper investigates the use of Deep Reinforcement Learning (DRL) applied to the humanoid robot soccer environment, where a robot must learn from basic to complex skills while it interacts with the environment through images received by its own camera. To do so, the Dueling Double DQN algorithm is used: it receives the images from the robot’s camera and decides on which discrete action should be performed, such as walk forward, turn to the left or kick the ball. The first experiments were performed in a robotic simulator in which the robot could learn, with DRL, three different tasks: to walk towards the ball, to act like a penalty taker and to act like a goalkeeper. In the second experiment, the learning obtained in the task to walk towards the ball was transferred to a real humanoid robot and a similar behavior could be observed, even though the environment was not exactly the same when the domain was changed. Results showed that it is possible to use DRL to learn tasks related to the role of a humanoid robot-soccer player, such as goalkeeper and penalty taker.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-021-01333-1,springer
Article,doi:10.1007/s10586-021-03348-7,New CNN and hybrid CNN-LSTM models for learning object manipulation of humanoid robots from demonstration,Cluster Computing,10.1007/s10586-021-03348-7,Springer,2021-06-26,2021-06-26,"As the environments that human live are complex and uncontrolled, the object manipulation with humanoid robots is regarded as one of the most challenging tasks. Learning a manipulation skill from human Demonstration (LfD) is one of the popular methods in the artificial intelligence and robotics community. This paper introduces a deep learning based teleoperation system for humanoid robots that imitate the human operator’s object manipulation behavior. One of the fundamental problems in LfD is to approximate the robot trajectories obtained by means of human demonstrations with high accuracy. The work introduces novel models based on Convolutional Neural Networks (CNNs), CNNs-Long Short-Term Memory (LSTM) models combining the CNN LSTM models, and their scaled variants for object manipulation with humanoid robots by using LfD. In the proposed LfD system, six models are employed to estimate the shoulder roll position of the humanoid robot. The data are first collected in terms of teleoperation of a real Robotis-Op3 humanoid robot and the models are trained. The trajectory estimation is then carried out by the trained CNNs and CNN-LSTM models on the humanoid robot in an autonomous way. All trajectories relating the joint positions are finally generated by the model outputs. The results relating to the six models are compared to each other and the real ones in terms of the training and validation loss, the parameter number, and the training and testing time. Extensive experimental results show that the proposed CNN models are well learned the joint positions and especially the hybrid CNN-LSTM models in the proposed teleoperation system exhibit a more accuracy and stable results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10586-021-03348-7,springer
Article,doi:10.1007/s00521-021-06192-3,A deep learning framework for realistic robot motion generation,Neural Computing and Applications,10.1007/s00521-021-06192-3,Springer,2021-06-15,2021-06-15,"Humanoid robots are being developed to play the role of personal assistants. With the development of artificial intelligence technology, humanoid robots are expected to perform many human tasks, such as housework, human care, and even medical treatment. However, robots cannot currently move flexibly like humans, which affects their fine motor skill performance. This is primarily because traditional robot control methods use manipulators that are difficult to articulate well. To solve this problem, we propose a nonlinear realistic robot motion generation method based on deep learning. Our method benefits from decomposing human motions into basic motions and realistic motions using the multivariate empirical mode decomposition and learning the biomechanical relationships between them by using an autoencoder generation network. The experimental results show that realistic motion features can be learned by the generation network and motion realism can be increased by adding the learned motions to the robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06192-3,springer
Article,doi:10.1186/s13634-021-00734-6,A robot vision navigation method using deep learning in edge computing environment,EURASIP Journal on Advances in Signal Processing,10.1186/s13634-021-00734-6,Springer,2021-05-17,2021-05-17,"In the development of modern agriculture, the intelligent use of mechanical equipment is one of the main signs for agricultural modernization. Navigation technology is the key technology for agricultural machinery to control autonomously in the operating environment, and it is a hotspot in the field of intelligent research on agricultural machinery. Facing the accuracy requirements of autonomous navigation for intelligent agricultural robots, this paper proposes a visual navigation algorithm for agricultural robots based on deep learning image understanding. The method first uses a cascaded deep convolutional network and hybrid dilated convolution fusion method to process images collected by a vision system. Then, it extracts the route of processed images based on the improved Hough transform algorithm. At the same time, the posture of agricultural robots is adjusted to realize autonomous navigation. Finally, our proposed method is verified by using non-interference experimental scenes and noisy experimental scenes. Experimental results show that the method can perform autonomous navigation in complex and noisy environments and has good practicability and applicability.",https://www.biomedcentral.com/openurl?doi=10.1186/s13634-021-00734-6,springer
Article,doi:10.1007/s11042-021-10673-x,Cost-effective real-time recognition for human emotion-age-gender using deep learning with normalized facial cropping preprocess,Multimedia Tools and Applications,10.1007/s11042-021-10673-x,Springer,2021-05-01,2021-03-02,"Because of technological advancement, human face recognition has been commonly applied in various fields. There are some HCI-related applications, such as camera-ready chatbot and companion robot, require gathering more information from user’s face. In this paper, we developed a system called EAGR for emotion, age, and gender recognition, which can perceive user’s emotion, age and gender based on the face detection. The EAGR system first applies normalized facial cropping (NFC) as a preprocessing method for training data before data augmentation, then uses convolution neural network (CNN) as three training models for recognizing seven emotions (six basics plus one neutral emotion), four age groups, and two genders. For better emotion recognition, the NFC will extract facial features without hair retained. On the other hand, the NFC will extract facial features with hair retained for better age and gender recognition. The experiments were conducted on these three training models of emotion, age and gender recognitions. The recognition performance results from the testing dataset, which has been normalized for tilted head by proposed binocular line angle correction (BLAC), showed that the optimal mean accuracy rates of real-time recognition for seven emotions, four age groups and two genders were 82.4%, 74.95%, and 96.65% respectively. Furthermore, the training time can be substantially reduced via NFC preprocessing. Therefore, we believe that EAGR system is cost-effective in recognizing human emotions, ages, and genders. The EAGR system can be further applied in social applications to help HCI service provide more accurate feedback from pluralistic facial classifications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-10673-x,springer
Article,doi:10.1007/s12559-020-09716-6,SOAR Improved Artificial Neural Network for Multistep Decision-making Tasks,Cognitive Computation,10.1007/s12559-020-09716-6,Springer,2021-05-01,2020-03-06,"Recently, artificial neural networks (ANNs) have been applied to various robot-related research areas due to their powerful spatial feature abstraction and temporal information prediction abilities. Decision-making has also played a fundamental role in the research area of robotics. How to improve ANNs with the characteristics of decision-making is a challenging research issue. ANNs are connectionist models, which means they are naturally weak in long-term planning, logical reasoning, and multistep decision-making. Considering that a small refinement of the inner network structures of ANNs will usually lead to exponentially growing data costs, an additional planning module seems necessary for the further improvement of ANNs, especially for small data learning. In this paper, we propose a state operator and result (SOAR) improved ANN (SANN) model, which takes advantage of both the long-term cognitive planning ability of SOAR and the powerful feature detection ability of ANNs. It mimics the cognitive mechanism of the human brain to improve the traditional ANN with an additional logical planning module. In addition, a data fusion module is constructed to combine the probability vector obtained by SOAR planning and the original data feature array. A data fusion module is constructed to convert the information from the logical sequences in SOAR to the probabilistic vector in ANNs. The proposed architecture is validated in two types of robot multistep decision-making experiments for a grasping task: a multiblock simulated experiment and a multicup experiment in a real scenario. The experimental results show the efficiency and high accuracy of our proposed architecture. The integration of SOAR and ANN is a good compromise between logical planning with small data and probabilistic classification with big data. It also has strong potential for more complicated tasks that require robust classification, long-term planning, and fast learning. Some potential applications include recognition of grasping order in multiobject environment and cooperative grasping of multiagents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-020-09716-6,springer
Article,doi:10.1007/s10710-021-09398-5,"Tim Taylor and Alan Dorin: Rise of the self-replicators—early visions of machines, AI and robots that can reproduce and evolve",Genetic Programming and Evolvable Machines,10.1007/s10710-021-09398-5,Springer,2021-03-01,2021-02-15,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10710-021-09398-5,springer
Chapter,doi:10.1007/978-3-030-75472-3_5,Autonomous Navigation with Mobile Robots Using Deep Learning and the Robot Operating System,Robot Operating System (ROS),10.1007/978-3-030-75472-3_5,Springer,2021-01-01,2021-07-18,"Autonomous navigation is a long-standing field of robotics research, which provides an essential capability for mobile robots to execute a series of tasks on the same environments performed by human everyday. In this chapter, we present a set of algorithms to train and deploy deep networks for autonomous navigation of mobile robots using the Robot Operation System (ROS). We describe three main steps to tackle this problem: (i) collecting data in simulation environments using ROS and Gazebo; (ii) designing deep network for autonomous navigation, and (iii) deploying the learned policy on mobile robots in both simulation and real-world. Theoretically, we present deep learning architectures for robust navigation in normal environments (e.g., man-made houses, roads) and complex environments (e.g., collapsed cities, or natural caves). We further show that the use of visual modalities such as RGB, Lidar, and point cloud is essential to improve the autonomy of mobile robots. Our project website and demonstration video can be found at https://sites.google.com/site/autonomousnavigationros .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75472-3_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-75275-0_82,Visual Deep Learning-Based Mobile Robot Control: A Novel Weighted Fitness Function-Based Image Registration Model,"New Technologies, Development and Application IV",10.1007/978-3-030-75275-0_82,Springer,2021-01-01,2021-05-12,"The recent development of faster and more accurate deep learning models has enabled researchers to utilize the potential of deep learning in robotics. Convolutional neural networks used for the process of semantic segmentation are being applied to improve the traditional robotic tasks by adding an additional level of intelligence, through the execution of context-aware tasks. Having that in mind, visual servoing can now be performed in a completely new manner, by exploiting only semantic and geometric knowledge about the environment. To carry out visual servoing, the mathematical model of the error between the images generated at the current and the desired mobile robot pose (i.e. position and orientation) in the image space needs to be adequately defined. In this paper, we propose the novel mathematical model for the weighted fitness function evaluation, which is utilized for the image registration process within the visual servoing framework. By weighting the classes by their importance in the desired image, the convergence domain of the initial error in the visual servoing process can be greatly extended. The experimental evaluation is carried out on the mobile robot RAICO (Robot with Artificial Intelligence based COgnition), where it is shown that weighted fitness function enables more robust intelligent visual servoing systems with a lower possibility of failure, easier real-world implementation, and feasible object driven navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75275-0_82,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-89098-8_12,DOREP 2.0: An Upgraded Version of Robot Control Teaching Experimental Platform with Reinforcement Learning and Visual Analysis,Intelligent Robotics and Applications,10.1007/978-3-030-89098-8_12,Springer,2021-01-01,2021-10-18,"The Deep Open Robot Experiment Platform (DOREP) is an experimental system for general robot control. It includes a robot toolbox, a Linux based real-time controller and corresponding environment deployment tools. It is compatible with ROKAE robots, Universal robots, ABB robots, AUBO robots and other 6-DOF small low load general robots. It aims to provide users with a direct, high-level, more open and comprehensive programming interface. The toolbox of the original version of DOREP system contains more than 30 functions, including forward and inverse kinematics calculation, point-to-point joint and Cartesian control, trajectory generation, graphic display, 3D animation and diagnosis. On the basis of the original version, DOREP 2.0 system adds some new functional modules such as reinforcement learning and visual analysis, which further improves the performance of DOREP system. Taking the newly added module as an example, this paper expounds the functions of reinforcement learning module and visual analysis module, and applies them to simulation and experiment successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89098-8_12,springer
Article,doi:10.1007/s10846-021-01336-y,Detecting Soccer Balls with Reduced Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01336-y,Springer,2021-02-27,2021-02-27,"Object detection techniques that achieve state-of-the-art detection accuracy employ convolutional neural networks, implemented to have lower latency in graphics processing units. Some hardware systems, such as mobile robots, operate under constrained hardware situations, but still benefit from object detection capabilities. Multiple network models have been proposed, achieving comparable accuracy with reduced architectures and leaner operations. Motivated by the need to create a near real-time object detection system for a soccer team of mobile robots operating with x86 CPU-only embedded computers, this work analyses the average precision and inference time of multiple object detection systems in a constrained hardware setting. We train open implementations of MobileNetV2 and MobileNetV3 models with different underlying architectures, achieved by changing their input and width multipliers, as well as YOLOv3, TinyYOLOv3, YOLOv4 and TinyYOLOv4 in an annotated image dataset captured using a mobile robot. We emphasize the speed/accuracy trade-off in the models by reporting their average precision on a test data set and their inference time in videos at different resolutions, under constrained and unconstrained hardware configurations. Results show that MobileNetV3 models have a good trade-off between average precision and inference time in constrained scenarios only, while MobileNetV2 with high width multipliers are appropriate for server-side inference. YOLO models in their official implementations are not suitable for inference in CPUs.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-021-01336-y,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-8221-9_57,Friction Compensation in Robot Manipulator Using Artificial Neural Network,"Advances in Automation, Signal Processing, Instrumentation, and Control",10.1007/978-981-15-8221-9_57,Springer,2021-01-01,2021-03-05,"In this work, an experimental friction forces were generated and then inserted in the joints of a robot manipulator. The artificial neural network (ANN) is used for the estimation of the friction forces in the joints of the robot. The estimated friction is implemented in the compensation of the real friction. The approach demonstrated its effectiveness in the control of the robot with a tracking error converging to zero. The overall objective of this work is to compensate for the effect of the friction in a robot manipulator using artificial neural network techniques. The end of the paper investigated the effect of the factors that could degrade the performance of the system such as modeling error or noise in the measurement. However, the modeling error showed no effect on the performance as well as noise.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8221-9_57,springer
Article,doi:10.1007/s40747-021-00341-w,Lower limb movement intention recognition for rehabilitation robot aided with projected recurrent neural network,Complex & Intelligent Systems,10.1007/s40747-021-00341-w,Springer,2021-03-30,2021-03-30,"For the lower limb rehabilitation robot, how to better realize intention recognition is the key issue in the practical application. Recognition of the patient’s movement intention is a challenging research work, which needs to be studied from the shallow to the deep. Specifically, it is necessary to ensure that the movement intention of the normal person can be accurately recognized, and then improve the model to realize the recognition of the movement intention of the patients. Therefore, before studying the patient’s movement intention, it is essential to consider the normal person first, which is also for safety considerations. In recent years, a new Hill-based muscle model has been demonstrated to be capable of directly estimating the joint angle intention in an open-loop form. On this basis, by introducing a recurrent neural network (RNN), the whole prediction process can achieve more accuracy in a closed-loop form. However, for the traditional RNN algorithms, the activation function must be convex, which brings some limitations to the solution of practical problems. Especially, when the convergence speed of the traditional RNN model is limited in the practical applications, as the error continues to decrease, the convergence performance of the traditional RNN model will be greatly affected. To this end, a projected recurrent neural network (PRNN) model is proposed, which relaxes the condition of the convex function and can be used in the saturation constraint case. In addition, the corresponding theoretical proof is given, and the PRNN method with saturation constraint has been successfully applied in the experiment of intention recognition of lower limb movement compared with the traditional RNN model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00341-w,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-63403-2_48,Dynamic Target Detection and Tracking in Water for Mobile Robot Based on Deep Learning,ICGG 2020 - Proceedings of the 19th International Conference on Geometry and Graphics,10.1007/978-3-030-63403-2_48,Springer,2021-01-01,2020-12-02,"Digital image processing is an important part of information perception of mobile robots. Unlike simple geometry, the shape of real objects is always irregular. An accurate and real-time dynamic image processing strategy for mobile robots based on deep learning is developed in this paper. To ensure the dynamic target in water always in the center of the mobile robot’s vision field, a target object detection strategy is designed according to the YOLO-V3 algorithm. 2279 pictures of the target object at different draught depths and different motion directions are collected to retrain the YOLO-V3 model. After testing, the accuracy of the model reaches 94.82%. Besides, considering the high accuracy and high efficiency of the Siamese network, SiamFC (a highly representative algorithm) is selected to support dynamic target tracking. An improved target tracking algorithm based on detection and supervision feedback is designed based on IOU (Intersection over Union) concept. Also, to guarantee the smooth motion of the mobile robot, a strategy of terrain information perception and obstacle terrain passing based on lidar scanning is designed. By analyzing the results of lidar scanning, the mobile robot can judge and avoid the obstacle terrains. The real-time and accuracy of each algorithm is verified by a comprehensive experiment of dynamic target search, detection, and tracking.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63403-2_48,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-7779-6_52,Navigation Method for Pioneer P3-DX Ground Wheeled Robot in V-REP Platform Using Type-2 Fuzzy Neural Network (T2FNN) Architecture,Advances in Mechanical Processing and Design,10.1007/978-981-15-7779-6_52,Springer,2021-01-01,2020-11-26,"This article presents the navigational architecture for a Pioneer P3-DX Ground Wheeled Robot (PGWR) by applying the minimum rule-based type-2 fuzzy neural network (T2FNN) architecture to control the motion, direction and orientation of PGWR between obstacles and help the PGWR to reach the goal. The real-time obstacle distance information received from the ring of ultrasonic sensors of PGWR is feed to the T2FNN as inputs, and necessary wheel velocity control commands for obstacle avoidance are obtained as outputs form rule-based system architecture of T2FNN. The experimental results in the Virtual Robot Experimentation Platform (V-REP) software show that the T2FNN method has successfully guided the PGWR under unknown scenarios. Also, the comparison analysis has been done with the previous benchmark neural network (NN) approach and found smoother trajectory during obstacle avoidance because the T2FNN provided an additional degree of freedom over NN to handle uncertainty situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7779-6_52,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-57802-2_61,Generating 2.5D Photorealistic Synthetic Datasets for Training Machine Vision Algorithms,15th International Conference on Soft Computing Models in Industrial and Environmental Applications (SOCO 2020),10.1007/978-3-030-57802-2_61,Springer,2021-01-01,2020-08-29,"The continued success of deep convolution neural networks (CNN) in computer vision can be directly linked to vast amounts of data and tremendous processing resources for training such non-linear models. However, depending on the task, the available amount of data varies significantly. Particularly robotic systems usually rely on small amounts of data, as producing and annotating them is extremely robot and task specific (e.g. grasping) and therefore prohibitive. Recently, in order to address the aforementioned problem of small datasets in robotic vision, a common practice is to reuse features that are already learned by a CNN within a large-scale task and apply them to different small scale ones. This transfer of learning shows some promising results as an alternative, but nevertheless it can not be compared with the performance of a CNN that is specifically trained from the beginning for that specific task. Thus, many researchers turned to synthetic datasets for training, since they can be produced easily and cost effectively. The main issue of such datasets that already exist, is the lack of photorealism both in terms of background and lighting. Herein, we are proposing a framework for the generation of completely synthetic datasets that includes all types of data that state-of-the-art algorithms in object recognition, and tracking need for their training. Thus, we can improve robotic perception without deploying the robot in time-consuming real-world scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-57802-2_61,springer
Chapter,doi:10.1007/978-3-030-70594-7_13,Deep Convolutional Neural Network Processing of Images for Obstacle Avoidance,Computational Intelligence,10.1007/978-3-030-70594-7_13,Springer,2021-01-01,2021-07-02,"Deep Convolutional Neural Networks have been found to be quite successful at processing images and determining their classifications, such as distinguishing dogs from cats in a set of images. With this in mind, we implemented a deep network system for obstacle avoidance of an autonomous robot driving in a real-world lab environment. The network was first trained on the CIFAR10 dataset using a replication of Alex Krizhevsky’s network architecture. The network was then altered by replacing the final fully connected layer with a new fully connected layer with three outputs and random starting weights. The entire network was then fine-tuned using images from the actual environment that were taken by the robot’s camera as it was remotely driven in the lab by a human operator. The network learned the correct responses of left, right, or straight for each of the images with a very low error rate when checked on test images. In addition, ten tests on the actual robot showed that it could successfully and consistently drive through the lab while avoiding obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70594-7_13,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-4488-0_56,Speech Recognition Using Neural Network for Mobile Robot Navigation,Trends in Mechanical and Biomedical Design,10.1007/978-981-15-4488-0_56,Springer,2021-01-01,2020-08-21,"Automatic speech recognition (ASR) has gained a lot of popularity in the mobile robotics, where the commands could be provided to the robot wirelessly to maneuver. A navigation system combined with ASR is a complex system to carry out, because the system has difficulty in recognizing the voice commands when the environment involved already has disturbances like road noise, air conditioner, music, and passengers. The objective of this research is to operate a mobile robot with a single-arm manipulator, where the robot can perceive the speech and it can react to the individual speech commands provided by the operator swiftly and precisely. In order to recognize the speech, mel-frequency cepstral coefficient (MFCC) speech recognition algorithm is chosen and implemented in MATLAB. Various training and testing have been done in MFCC algorithm where it has to carry out the real-time processing of speech data and respond to it. Based on both the training and testing the voice commands collected from the five test subjects both male and female, the speech recognition system achieved 89% efficiency for the test database.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4488-0_56,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-80624-8_23,Artificial Intelligence and Tomorrow’s Education,"Advances in Artificial Intelligence, Software and Systems Engineering",10.1007/978-3-030-80624-8_23,Springer,2021-01-01,2021-07-08,"Nowadays, there is a rapid technological progress around the world that has enabled realities long ago unimaginable. We live in a technological era that represents new possibilities and challenges for society, and for the educational models in each country [ 1 ]. Research on smart education, which has forced the educational community to rethink on new ways of learning and teaching has been developed globally. Due to the advent of artificial intelligence (AI), the educational model for both, teachers and students will change. Nevertheless, to transform educational systems, it is necessary to update and train students, educators, and administrators effectively [ 2 ]. This research aims to describe the possible applications of AI in education from: 1) the automation of administrative tasks; 2) collection and analysis of information [ 3 ] to create smart content; 3) the implementation of virtual assistants in the teaching-learning process; 4) the potential delivery of lectures by humanoid robots with AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80624-8_23,springer
Chapter Protocol,doi:10.1007/978-3-030-77070-9_10,Smart and Intelligent Chatbot Assistance for Future Industry 4.0,Artificial Intelligence for a Sustainable Industry 4.0,10.1007/978-3-030-77070-9_10,Springer,2021-01-01,2021-10-22,"Chatbot is an implementation of artificial intelligence (AI) technology that is used to interact with human beings and make them feel like they are talking to the real person, and the chatbot helps them to solve their queries. A chatbot can provide 24 × 7 customer support so that the customer may have a good service experience by any organization. Chatbot helps to resolve the queries and respond to the questions of users. The user is providing the input to the chatbot first, and then, the same input will be processed further; this input can be in the form of text or voice. Therefore, on the basis of the given input and after processing it, the chatbot application will generate the response to the user, and the same response will be the best answer found by the chat application. This response can be in any format like text or a voice output. In this chapter, various approaches of chatbots and how they interact with users are discussed. The proposed approach is also defined using Dialogflow, and it can be accessible through mobile phones, laptops, and portable devices. Chatbots such as Facebook chatbot, WeChat chatbot, Hike chatbot called Natasha, etc. are available in the marker and will respond on the basis of their local databases (DBs). In the proposed method, the focus will be on the scalability, user interactivity, and flexibility of the system, which can be provided by adding both local and Web databases due to which our system will be more fast and accurate. Chatbot uses unification of emerging technologies like machine learning and artificial intelligence. The motive of this chapter is to improve the chatbot system to support and scale businesses and industry domain and maintain relations with customers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77070-9_10,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-5943-0_21,Intelligent Service Robot for High-Speed Railway Passengers,Data Science,10.1007/978-981-16-5943-0_21,Springer,2021-01-01,2021-09-10,"With the rapid development of road traffic, the number of high-speed rail passengers is huge, and the flow of people is dense. In epidemic situation, it is prone to intensive infection in high-speed rail carriages, which is not conducive to national prevention and control work. Based on face recognition technology, the intelligent service robot for high-speed rail passengers walks in accordance with the set route and detects the face mask of high-speed rail passengers. The face database of high-speed rail passengers is compared in real time. The passengers who do not wear masks are reminded in time to reduce the risk of infection. Moreover, the robot can accurately remind the passengers of leaving the station in time, and has the functions of automatic selling and student ticket checking. The experimental result is shown to promote the further development of high-speed rail services.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5943-0_21,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-74893-7_25,Convolutional Neural Network-Based Local Obstacle Avoidance for a Mobile Robot,"Automation 2021: Recent Achievements in Automation, Robotics and Measurement Techniques",10.1007/978-3-030-74893-7_25,Springer,2021-01-01,2021-04-30,"This paper presents collision avoidance and local motion planning modules for a mobile robot equipped with a depth camera. In this paper, we identify some limitations of the existing neural controller, and then we propose the extensions which improve the behavior of the robot. We show that the knowledge about control history is crucial to efficiently avoid collisions with the obstacles if the robot is equipped with a narrow field of view camera. We propose the architecture which utilizes CNN-based neural modules to plan the local motion of the robot. Finally, we provide the results of the experimental verification on the real robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74893-7_25,springer
Article,doi:10.1007/s10846-020-01262-5,Incremental Learning for Autonomous Navigation of Mobile Robots based on Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01262-5,Springer,2020-12-07,2020-12-07,"This paper presents an incremental learning method and system for autonomous robot navigation. The range finder laser sensor and online deep reinforcement learning are utilized for generating the navigation policy, which is effective for avoiding obstacles along the robot’s trajectories as well as for robot’s reaching the destination. An empirical experiment is conducted under simulation and real-world settings. Under the simulation environment, the results show that the proposed method can generate a highly effective navigation policy (more than 90% accuracy) after only 150k training iterations. Moreover, our system has slightly outperformed deep-Q, while having considerably surpassed Proximal Policy Optimization, two recent state-of-the art robot navigation systems. Finally, two experiments are performed to demonstrate the feasibility and effectiveness of our robot’s proposed navigation system in real-time under real-world settings.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01262-5,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-85867-4_4,AIRPA: An Architecture to Support the Execution and Maintenance of AI-Powered RPA Robots,Business Process Management: Blockchain and Robotic Process Automation Forum,10.1007/978-3-030-85867-4_4,Springer,2021-01-01,2021-08-22,"Robotic Process Automation (RPA) has quickly evolved from automating simple rule-based tasks. Nowadays, RPA is required to mimic more sophisticated human tasks, thus implying its combination with Artificial Intelligence (AI) technology, i.e., the so-called intelligent RPA. Putting together RPA with AI leads to a challenging scenario since (1) it involves professionals from both fields who typically have different skills and backgrounds, and (2) AI models tend to degrade over time which affects the performance of the overall solution. This paper describes the AIRPA project, which addresses these challenges by proposing a software architecture that enables (1) the abstraction of the robot development from the AI development and (2) the monitor, control, and maintain intelligent RPA developments to ensure its quality and performance over time. The project has been conducted in the Servinform context, a Spanish consultancy firm, and the proposed prototype has been validated with reality settings. The initial experiences yield promising results in reducing AHT (Average Handle Time) in processes where AIRPA deployed cognitive robots, which encourages exploring the support of intelligent RPA development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85867-4_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-74893-7_10,Biologically Inspired Neural Behavioral Control of the Wheeled Mobile Robot,"Automation 2021: Recent Achievements in Automation, Robotics and Measurement Techniques",10.1007/978-3-030-74893-7_10,Springer,2021-01-01,2021-04-30,"In this paper, to solve the task of neural behavioral control of a 2-wheeled mobile robot (WMR), a hierarchical structure is used. At higher levels of the hierarchic generate a desired trajectory of mobile robot motion based on the artificial potential field theory. The generated trajectory is a desired trajectory realized by the neural control algorithm, implemented on the lower level of the hierarchy. Correctness of the solution of the desired trajectory generator and the control system of the elementary robot behavior has been confirmed in numerical simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74893-7_10,springer
Chapter,doi:10.1007/978-3-030-77939-9_5,A Cascaded Deep Neural Network for Position Estimation of Industrial Robots,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_5,Springer,2021-01-01,2021-10-02,"The estimation of an object’s position and orientation from images plays an important role in the field of industrial robots and visual servo, the performance of the vision control system is deeply dependent on the image processing model and algorithm. Before deep learning is widely used in computer vision, the traditional image processing methods are successful in handling the low dimension information of image features, but the traditional image processing methods always fail in complex images with high dimension feature information. In this research chapter, our main contribution is to propose a cascaded convolution network that could obtain high precision pose estimates. Where Single Shot MultiBox Detector (SSD) is utilized to obtain the bounding box of the object to narrow down the recognition range. And a convolutional neural network is utilized to detect the orientation of the object. The method is designed for industrial detection tasks, so the optimized method can run in real-time and extract weak features of sample images. To verify the effect of the detection method based on deep learning in the industrial system, a hand-eye system is built for detecting Radio Remote Unit. A series of experiments have been carried out on the system with the proposed method and the traditional method. In general, the proposed method has advantages in accuracy and recognition rate compared with the traditional algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-89134-3_51,Terrain Attribute Recognition System for CPG-Based Legged Robot,Intelligent Robotics and Applications,10.1007/978-3-030-89134-3_51,Springer,2021-01-01,2021-10-18,"In this paper, we develop a terrain attribute recognition system for CPG-based legged robots. First, a low-cost sensing hardware device is designed to be integrated into the robot, including a tactile sensor array and RGB camera. Second, for the tactile modality, a novel terrain attribute recognition framework is proposed. A data generation strategy that adapts to the motion characteristics is presented, which transforms the original tactile signal into a structured representation, and extract meaningful features. Based on unsupervised and supervised machine learning classifiers, the recognition rates reach 94.0% and 95.5%, and the switching time is 1 to 3 steps. Third, for the recognition of terrain attributes in the visual modality, a lightweight real-time mobile attention coding network (MACNet) is proposed as an end-to-end model, which shows an exhibiting an accuracy of 88.5% on the improved GTOS mobile data set, 169FPS inference speed and 6.6 MB model parameter occupancy. Finally, these two methods are simultaneously applied to the AmphiHex-II robot for outdoor experiments. Experimental results show that each modality has its own advantages and disadvantages, and the complementary relationship between multiple modalities plays an irreplaceable role in a broader scene.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89134-3_51,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-89098-8_59,Research on Short Term Power Load Forecasting Combining CNN and LSTM Networks,Intelligent Robotics and Applications,10.1007/978-3-030-89098-8_59,Springer,2021-01-01,2021-10-18,"Accurate prediction of power load plays an important role in the optimal scheduling of resources. However, the lack of power data in the traditional automatic acquisition system inevitably affects the subsequent data analysis. With the help of on-site real-time monitoring, the integrity of data collection can be ensured. In this paper, a load forecasting model based on the fusion of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) is proposed. Through training the historical data collected by the on-duty robot, a complete network model is constructed. The network extracts the effective sequence features of the input data through CNN network, and gets the load prediction results through LSTM network. The experimental results show that the fusion network of CNN and LSTM obtains higher prediction accuracy than present algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89098-8_59,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-7213-2_2,Object Detection of Basketball Robot Based on MobileNet-SSD,"Intelligent Equipment, Robots, and Vehicles",10.1007/978-981-16-7213-2_2,Springer,2021-01-01,2021-10-19,"Object detection is one of the research hotspots in the field of computer vision. In this paper, we use the lightweight network MobileNet combined with Single Shot Multibox Detector (SSD) to realize the object detection of the robot. SSD combined with MobileNet can effectively compress the size of the network model and improve the detection rate. The method does automatic extraction on the image features first, and add different size feature maps after the basic network, and then do convolution filtering on the multi dimension feature maps to get the object coordinate value and the object category. In the experiment, compared with the original vision method based on OpenCV, the MobileNet-SSD algorithm was less affected by illumination conditions in the object recognition process, and achieved the rapid and accurate recognition of the basketball robot on the ball.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7213-2_2,springer
Article,doi:10.1007/s00521-020-05032-0,A proposed decentralized formation control algorithm for robot swarm based on an optimized potential field method,Neural Computing and Applications,10.1007/s00521-020-05032-0,Springer,2021-01-01,2020-05-22,"Lately, robot swarm has widely employed in many applications like search and rescue missions, fire forest detection and navigation in hazard environments. Each robot in a swarm is supposed to move without collision and avoid obstacles while performing the assigned job. Therefore, a formation control is required to achieve the robot swarm three tasks. In this article, we introduce a decentralized formation control algorithm based on the potential field method for robot swarm. Our formation control algorithm is proposed to achieve the three tasks: avoid obstacles in the environment, keep a fixed distance among robots to maintain a formation and perform an assigned task. An artificial neural network is engaged in the online optimization of the parameters of the potential force. Then, real-time experiments are conducted to confirm the reliability and applicability of our proposed decentralized formation control algorithm. The real-time experiment results prove that the proposed decentralized formation control algorithm enables the swarm to avoid obstacles and maintain formation while performing a certain task. The swarm manages to reach a certain goal and tracks a given trajectory. Moreover, the proposed decentralized formation control algorithm enables the swarm to escape from local minima, to pass through two narrow placed obstacles without oscillation near them. From a comparison between the proposed decentralized formation control algorithm and the traditional PFM, we obtained that NN-swarm successes to reach its goal with average accuracy 0.14 m compared to 0.22 m for the T-swarm. The NN-swarm also keeps a fixed distance between robots with a higher swarming error reaches 34.83%, while the T-swarm reaches 23.59%. Also, the NN-swarm is more accurate in tracking a trajectory with a higher tracking error reaches 0.0086 m compared to min. error of T-swarm equals to 0.01 m. Besides, the NN-swarm maintains formation much longer than T-swarm while tracking trajectory reaches 94.31% while the T-swarm reaches 81.07% from the execution time, in environments with different numbers of obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05032-0,springer
Article,doi:10.1007/s10846-020-01216-x,A Deep-Learning-based Strategy for Kidnapped Robot Problem in Similar Indoor Environment,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01216-x,Springer,2020-12-01,2020-09-18,"We present a deep-learning-based strategy that only uses a 2D LiDAR sensor to solve the kidnapped robot problem in similar indoor environments. First, we converted a set of 2D laser data into an RGB-image and an occupancy grid map and stacked them into a multi-channel image. Then, a neural network structure with five convolutional layers and four fully connected layers was designed to regress the 3-DOF robot pose. Finally, the network was trained using multi-channel images as input. We also improved the network structure to identify the scene where the robot is localized. Extensive experiments have been conducted in practice with a real mobile robot, verifying the effectiveness of the proposed strategy. Our network can obtain approximately 2m and 5^∘ accuracy indoors, and the scene classification accuracy of our network reaches up to 98 % .",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01216-x,springer
Article,doi:10.1007/s12652-020-02567-x,Special issue on machine learning for robotics,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-02567-x,Springer,2020-12-01,2020-09-25,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-02567-x,springer
Article,doi:10.1007/s41315-020-00155-y,"Introduction to the focused section on machine learning, estimation and control for intelligent robotics",International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00155-y,Springer,2020-12-01,2020-11-05,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00155-y,springer
Article,doi:10.1007/s10670-020-00331-3,"Robot Ethics 2.0. From Autonomous Cars to Artificial Intelligence—Edited by Patrick Lin, Keith Abney, Ryan Jenkins. New York: Oxford University Press, 2017. Pp xiii + 421",Erkenntnis,10.1007/s10670-020-00331-3,Springer,2020-10-22,2020-10-22,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10670-020-00331-3,springer
Article,doi:10.1007/s41297-020-00109-1,A robot took my job! How STEM education might prepare students for a rapidly changing world,Curriculum Perspectives,10.1007/s41297-020-00109-1,Springer,2020-09-01,2020-09-21,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41297-020-00109-1,springer
Article,doi:10.1007/s10710-019-09365-1,Joseph E. Aoun: Robot-proof: higher education at the age of artificial intelligence,Genetic Programming and Evolvable Machines,10.1007/s10710-019-09365-1,Springer,2020-06-01,2019-10-08,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10710-019-09365-1,springer
Article,doi:10.1007/s12369-019-00585-0,Reinforcement Learning Aided Robot-Assisted Navigation: A Utility and RRT Two-Stage Approach,International Journal of Social Robotics,10.1007/s12369-019-00585-0,Springer,2020-07-01,2019-09-13,"This work proposes a robot-assisted navigation approach based on user intent adjustment, in the context of robotic walkers. Walkers are prescribed to users with gait disorders so that they can support their body weight on the upper limbs, however, the manipulation of such devices can be cumbersome for some users. Common problems for the users are lack of dexterous upper limb control and visual impairments. These problems can render walkers’ users helpless, making them unable to operate these devices effectively and efficiently. We present a new approach to robot-assisted navigation using a utility decision and safety analysis procedure with user intent adjustments learned by reinforcement learning (RL) and supported on a rapidly-exploring random tree inspired algorithm. The proposed approach offers full control of the assistive platform to the user until obstacles are detected. In dangerous scenarios, corrections are computed in order that the assistive platform avoids collisions and follows social norms, effectively guiding the user through the environment while enforcing safer routes. The experimental validation was carried out in a virtual environment and in a real world scenario using a robotic walker built in our lab (ISR-AIWALKER). Experimental results have shown that the proposed approach provides a reliable solution to the robot-assisted navigation of a robotic walker, in particular the use of utility theory to evaluate candidate motions together with a RL model increases the safety of the user’s navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00585-0,springer
Article,doi:10.1007/s00791-020-00327-0,Parareal with a learned coarse model for robotic manipulation,Computing and Visualization in Science,10.1007/s00791-020-00327-0,Springer,2020-09-23,2020-09-23,"A key component of many robotics model-based planning and control algorithms is physics predictions, that is, forecasting a sequence of states given an initial state and a sequence of controls. This process is slow and a major computational bottleneck for robotics planning algorithms. Parallel-in-time integration methods can help to leverage parallel computing to accelerate physics predictions and thus planning. The Parareal algorithm iterates between a coarse serial integrator and a fine parallel integrator. A key challenge is to devise a coarse model that is computationally cheap but accurate enough for Parareal to converge quickly. Here, we investigate the use of a deep neural network physics model as a coarse model for Parareal in the context of robotic manipulation. In simulated experiments using the physics engine Mujoco as fine propagator we show that the learned coarse model leads to faster Parareal convergence than a coarse physics-based model. We further show that the learned coarse model allows to apply Parareal to scenarios with multiple objects, where the physics-based coarse model is not applicable. Finally, we conduct experiments on a real robot and show that Parareal predictions are close to real-world physics predictions for robotic pushing of multiple objects. Code ( https://doi.org/10.5281/zenodo.3779085 ) and videos ( https://youtu.be/wCh2o1rf-gA ) are publicly available.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00791-020-00327-0,springer
Article,doi:10.1007/s11548-020-02166-3,Deep learning-based monocular placental pose estimation: towards collaborative robotics in fetoscopy,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-020-02166-3,Springer,2020-09-01,2020-04-30,"Purpose Twin-to-twin transfusion syndrome (TTTS) is a placental defect occurring in monochorionic twin pregnancies. It is associated with high risks of fetal loss and perinatal death. Fetoscopic elective laser ablation (ELA) of placental anastomoses has been established as the most effective therapy for TTTS. Current tools and techniques face limitations in case of more complex ELA cases. Visualization of the entire placental surface and vascular equator; maintaining an adequate distance and a close to perpendicular angle between laser fiber and placental surface are central for the effectiveness of laser ablation and procedural success. Robot-assisted technology could address these challenges, offer enhanced dexterity and ultimately improve the safety and effectiveness of the therapeutic procedures. Methods This work proposes a ‘minimal’ robotic TTTS approach whereby rather than deploying a massive and expensive robotic system, a compact instrument is ‘robotised’ and endowed with ‘robotic’ skills so that operators can quickly and efficiently use it. The work reports on automatic placental pose estimation in fetoscopic images. This estimator forms a key building block of a proposed shared-control approach for semi-autonomous fetoscopy. A convolutional neural network (CNN) is trained to predict the relative orientation of the placental surface from a single monocular fetoscope camera image. To overcome the absence of real-life ground-truth placenta pose data, similar to other works in literature (Handa et al. in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016; Gaidon et al. in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016; Vercauteren et al. in: Proceedings of the IEEE, 2019) the network is trained with data generated in a simulated environment and an in-silico phantom model. A limited set of coarsely manually labeled samples from real interventions are added to the training dataset to improve domain adaptation. Results The trained network shows promising results on unseen samples from synthetic, phantom and in vivo patient data. The performance of the network for collaborative control purposes was evaluated in a virtual reality simulator in which the virtual flexible distal tip was autonomously controlled by the neural network. Conclusion Improved alignment was established compared to manual operation for this setting, demonstrating the feasibility to incorporate a CNN-based estimator in a real-time shared control scheme for fetoscopic applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-020-02166-3,springer
Article,doi:10.1007/s00345-019-03037-6,Artificial intelligence and robotics: a combination that is changing the operating room,World Journal of Urology,10.1007/s00345-019-03037-6,Springer,2020-10-01,2019-11-27,"Purpose The aim of the current narrative review was to summarize the available evidence in the literature on artificial intelligence (AI) methods that have been applied during robotic surgery. Methods A narrative review of the literature was performed on MEDLINE/Pubmed and Scopus database on the topics of artificial intelligence, autonomous surgery, machine learning, robotic surgery, and surgical navigation, focusing on articles published between January 2015 and June 2019. All available evidences were analyzed and summarized herein after an interactive peer-review process of the panel. Literature review The preliminary results of the implementation of AI in clinical setting are encouraging. By providing a readout of the full telemetry and a sophisticated viewing console, robot-assisted surgery can be used to study and refine the application of AI in surgical practice. Machine learning approaches strengthen the feedback regarding surgical skills acquisition, efficiency of the surgical process, surgical guidance and prediction of postoperative outcomes. Tension-sensors on the robotic arms and the integration of augmented reality methods can help enhance the surgical experience and monitor organ movements. Conclusions The use of AI in robotic surgery is expected to have a significant impact on future surgical training as well as enhance the surgical experience during a procedure. Both aim to realize precision surgery and thus to increase the quality of the surgical care. Implementation of AI in master–slave robotic surgery may allow for the careful, step-by-step consideration of autonomous robotic surgery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00345-019-03037-6,springer
Article,doi:10.1007/s11628-020-00423-8,Impacts of service robots on service quality,Service Business,10.1007/s11628-020-00423-8,Springer,2020-09-01,2020-08-07,"With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11628-020-00423-8,springer
Article,doi:10.1007/s41315-020-00154-z,A recurrent neural network for variable admittance control in human–robot cooperation: simultaneously and online adjustment of the virtual damping and Inertia parameters,International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00154-z,Springer,2020-12-01,2020-11-12,"In this manuscript, a recurrent neural network is proposed for variable admittance control in human–robot cooperation tasks. The virtual damping and the virtual inertia of the designed robot’s admittance controller are adjusted online and simultaneously. A Jordan recurrent neural network is designed and trained for this purpose. The network is indirectly trained using the real-time recurrent learning algorithm and based on the velocity error between the reference velocity of the minimum jerk trajectory model and the actual velocity of the robot. The performance of the proposed variable admittance controller is presented in terms of the human required effort, the task completion time, the achieved accuracy at the target, and the oscillations during the movement. Its generalization ability is evaluated experimentally by conducting cooperative tasks along numerous straight-line segments using the KUKA LWR robot and by ten subjects. Finally, a comparison with previous developed variable admittance controllers, where only the variable damping or only the virtual inertia is adjusted, is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00154-z,springer
Article,doi:10.1007/s12652-020-01693-w,Adaptive PID control of multi-DOF industrial robot based on neural network,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01693-w,Springer,2020-12-01,2020-01-08,"The control system of parallel robot, especially industrial robot, is a very complex multi-modal nonlinear system, which has the characteristics of time-varying, strong coupling and strong nonlinearity. Trajectory tracking control algorithm is a very important part of industrial robot control system. It is required that the algorithm can realize the continuous tracking of each joint of the robot and the processing and tracking of the desired trajectory. However, due to the strong influence of acceleration and speed on the trajectory tracking of industrial robots, the corresponding control difficulty and control accuracy are seriously affected. Based on the core idea of fuzzy neural network algorithm, the functional relationship between control error and arrival degree is established to improve the control quality of industrial robots. At the same time, combining with the PID feedforward control algorithm, the self-adaptive adjustment of PID parameters is realized, and the accuracy of the tracking algorithm is improved. In order to verify the superiority of the proposed trajectory tracking control algorithm over the traditional PID algorithm, the model of industrial robot is established by using the virtual simulation system Adams. At the same time, the model is simulated by joint experiment. Experimental results show that the trajectory control algorithm based on the proposed trajectory control algorithm is effective. This method has good control accuracy and stability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-01693-w,springer
Article,doi:10.1007/s10489-020-01818-w,Light-YOLOv3: fast method for detecting green mangoes in complex scenes using picking robots,Applied Intelligence,10.1007/s10489-020-01818-w,Springer,2020-12-01,2020-07-30,"When a robot picks green fruit under natural light, the color of the fruit is similar to the background; uneven lighting and fruit and leaf occlusion often affect the performance of the detection method. We take green mangoes as an experimental object. A lightweight green mangoes detection method based on YOLOv3 is proposed here. To improve the detection speed of the method, we first combine the color, texture, and shape features of green mango to design a lightweight network unit to replace the residual units in YOLOv3. Second, the improved Multiscale context aggregation (MSCA) module is used to concatenate multilayer features and make predictions, solving the problem of insufficient position information and semantic information on the prediction feature map in YOLOv3; this approach effectively improves the detection effect for the green mangoes. To address the overlap of green mangoes, soft non-maximum suppression (Soft-NMS) is used to replace non-maximum suppression (NMS), thereby reducing the missing of predicted boxes due to green mango overlaps. Finally, an auxiliary inspection green mango image enhancement algorithm (CLAHE-Mango) is proposed, is suitable for low-brightness detection environments and improves the accuracy of the green mango detection method. The experimental results show that the F1% of Light-YOLOv3 in the test set is 97.7%. To verify the performance of Light-YOLOv3 under the embedded platform, we embed one-stage methods into the Adreno 640 and Mali-G76 platforms. Compared with YOLOv3, the F1% of Light-YOLOv3 is increased by 4.5%, and the running speed is increased by 5 times, which can meet the real-time running requirements for picking robots. Through three sets of comparative experiments, we could determine that our method has the best detection results in terms of dense, backlit, direct light, night, long distance, and special angle scenes under complex lighting.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-020-01818-w,springer
Article,doi:10.1007/s10458-020-09485-4,I2RL: online inverse reinforcement learning under occlusion,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-020-09485-4,Springer,2020-11-05,2020-11-05,"Inverse reinforcement learning (IRL) is the problem of learning the preferences of an agent from observing its behavior on a task. It inverts RL which focuses on learning an agent’s behavior on a task based on the reward signals received. IRL is witnessing sustained attention due to promising applications in robotics, computer games, and finance, as well as in other sectors. Methods for IRL have, for the most part, focused on batch settings where the observed agent’s behavioral data has already been collected. However, the related problem of online IRL—where observations are incrementally accrued, yet the real-time demands of the application often prohibit a full rerun of an IRL method—has received significantly less attention. We introduce the first formal framework for online IRL, called incremental IRL (I2RL), which can serve as a common ground for online IRL methods. We demonstrate the usefulness of this framework by casting existing online IRL techniques into this framework. Importantly, we present a new method that advances maximum entropy IRL with hidden variables to the online setting. Our analysis shows that the new method has monotonically improving performance with more demonstration data as well as probabilistically bounded error, both under full and partial observability. Simulated and physical robot experiments in a multi-robot patrolling application situated in varied-sized worlds, which involves learning under high levels of occlusion, show a significantly improved performance of I2RL as compared to both batch IRL and an online imitation learning method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10458-020-09485-4,springer
Article,doi:10.1007/s10846-020-01183-3,Model-Based Reinforcement Learning Variable Impedance Control for Human-Robot Collaboration,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01183-3,Springer,2020-11-01,2020-03-10,"Industry 4.0 is taking human-robot collaboration at the center of the production environment. Collaborative robots enhance productivity and flexibility while reducing human’s fatigue and the risk of injuries, exploiting advanced control methodologies. However, there is a lack of real-time model-based controllers accounting for the complex human-robot interaction dynamics. With this aim, this paper proposes a Model-Based Reinforcement Learning (MBRL) variable impedance controller to assist human operators in collaborative tasks. More in details, an ensemble of Artificial Neural Networks (ANNs) is used to learn a human-robot interaction dynamic model, capturing uncertainties. Such a learned model is kept updated during collaborative tasks execution. In addition, the learned model is used by a Model Predictive Controller (MPC) with Cross-Entropy Method (CEM). The aim of the MPC+CEM is to online optimize the stiffness and damping impedance control parameters minimizing the human effort (i.e, minimizing the human-robot interaction forces). The proposed approach has been validated through an experimental procedure. A lifting task has been considered as the reference validation application (weight of the manipulated part: 10 kg unknown to the robot controller). A KUKA LBR iiwa 14 R820 has been used as a test platform. Qualitative performance (i.e, questionnaire on perceived collaboration) have been evaluated. Achieved results have been compared with previous developed offline model-free optimized controllers and with the robot manual guidance controller. The proposed MBRL variable impedance controller shows improved human-robot collaboration. The proposed controller is capable to actively assist the human in the target task, compensating for the unknown part weight. The human-robot interaction dynamic model has been trained with a few initial experiments (30 initial experiments). In addition, the possibility to keep the learning of the human-robot interaction dynamics active allows accounting for the adaptation of human motor system.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01183-3,springer
Article,doi:10.1007/s11548-020-02214-y,Object extraction via deep learning-based marker-free tracking framework of surgical instruments for laparoscope-holder robots,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-020-02214-y,Springer,2020-08-01,2020-06-24,"Purpose The surgical instrument tracking framework, especially the marker-free surgical instrument tracking framework, is the key to visual servoing which is applied to achieve active control for laparoscope-holder robots. This paper presented a marker-free surgical instrument tracking framework based on object extraction via deep learning (DL). Methods The surgical instrument joint was defined as the tracking point. Using DL, a segmentation model was trained to extract the end-effector and shaft portions of the surgical instrument in real time. The extracted object was transformed into a distance image by Euclidean Distance Transformation. Next, the points with the maximal pixel value in the two portions were defined as their central points, respectively, and the intersection point of the line connecting the two central points and the plane connecting the two portions was determined as the tracking point. Finally, the object could be fast extracted using the masking method, and the tracking point was fast located frame-by-frame in a laparoscopic video to achieve tracking of surgical instrument. The proposed object extraction via a DL-based marker-free tracking framework was compared with a marker-free tracking-by-detection framework via DL. Results Using seven in vivo laparoscopic videos for experiments, the mean tracking success rate was 100%. The mean tracking accuracy was (3.9 ± 2.4, 4.0 ± 2.5) pixels measured in u and v coordinates of a frame, and the mean tracking speed was 15 fps. Compared to the reported mean tracking accuracy of a marker-free tracking-by-detection framework via DL, the mean tracking accuracy of our proposed tracking framework was improved by 37% and 23%, respectively. Conclusion Accurate and fast tracking of marker-free surgical instruments could be achieved in in vivo laparoscopic videos by using our proposed object extraction via DL-based marker-free tracking framework. This work provided important guiding significance for the application of laparoscope-holder robots in laparoscopic surgeries.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-020-02214-y,springer
Article,doi:10.1007/s12369-019-00617-9,A Holistic Approach to Behavior Adaptation for Socially Assistive Robots,International Journal of Social Robotics,10.1007/s12369-019-00617-9,Springer,2020-07-01,2020-01-28,"Socially assistive robotics aims at providing users with continuous support and personalized assistance, through appropriate social interactions. The design of robots capable of supporting people in heterogeneous tasks, raises several challenges among which the most relevant are the need to realise intelligent and continuous behaviours, robustness and flexibility of services and, furthermore, the ability to adapt to different contexts and needs. Artificial intelligence plays a key role in realizing cognitive capabilities like e.g., learning, context reasoning or planning that are highly needed in socially assistive robots. The integration of several of such capabilities is an open problem. This paper proposes a novel “cognitive approach” integrating ontology-based knowledge reasoning, automated planning and execution technologies. The core idea is to endow assistive robots with intelligent features in order to reason at different levels of abstraction, understand specific health-related needs and decide how to act in order to perform personalized assistive tasks. The paper presents such a cognitive approach pointing out the contribution of different knowledge contexts and perspectives, presents detailed functioning traces to show adaptation and personalization features, and finally discusses an experimental assessment proving the feasibility of the approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00617-9,springer
Article,doi:10.1007/s10458-020-09459-6,Interactively shaping robot behaviour with unlabeled human instructions,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-020-09459-6,Springer,2020-05-08,2020-05-08,"In this paper, we propose a framework that enables a human teacher to shape a robot behaviour by interactively providing it with unlabeled instructions. We ground the meaning of instruction signals in the task-learning process, and use them simultaneously for guiding the latter. We implement our framework as a modular architecture, named TICS (Task-Instruction-Contingency-Shaping) that combines different information sources: a predefined reward function, human evaluative feedback and unlabeled instructions. This approach provides a novel perspective for robotic task learning that lies between Reinforcement Learning and Supervised Learning paradigms. We evaluate our framework both in simulation and with a real robot. The experimental results demonstrate the effectiveness of our framework in accelerating the task-learning process and in reducing the number of required teaching signals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10458-020-09459-6,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-55789-8_6,Push Recovery and Active Balancing for Inexpensive Humanoid Robots Using RL and DRL,Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices,10.1007/978-3-030-55789-8_6,Springer,2020-01-01,2020-09-04,"Push recovery of a humanoid robot is a challenging task because of many different levels of control and behaviour, from walking gait to dynamic balancing. This research focuses on the active balancing and push recovery problems that allow inexpensive humanoid robots to balance while standing and walking, and to compensate for external forces. In this research, we have proposed a push recovery mechanism that employs two machine learning techniques, Reinforcement Learning and Deep Reinforcement Learning, to learn recovery step trajectories during push recovery using a closed-loop feedback control. We have implemented a 3D model using the Robot Operating System and Gazebo. To reduce wear and tear on the real robot, we used this model for learning the recovery steps for different impact strengths and directions. We evaluated our approach in both in the real world and in simulation. All the real world experiments are performed by Polaris, a teen-sized humanoid robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-55789-8_6,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-50729-9_22,A Robot Agent that Learns Group Interaction Through a Team-Based Virtual Reality Game Using Affective Reward Reinforcement Learning,HCI International 2020 - Posters,10.1007/978-3-030-50729-9_22,Springer,2020-01-01,2020-07-10,"In the near future, robots are expected to be integrated into people’s lives, interacting with them. To develop better robotics and artificial intelligence, this research focuses on the concept of teamwork. A robot agent was implemented in a virtual reality(VR) game to play the sport roundnet, a team-based sport similar to table tennis and volleyball [ 2 ]. The agent is trained with reinforcement learning with EDA skin sensor data [ 6 ] of players. The system is evaluated using a questionnaire on the player’s feeling during the experiment and compared with agents not trained with affective data. The system is implemented in Unity3D’s ML-Agents Toolkit.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50729-9_22,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-51005-3_5,Intelligent Playful Environments in New Urban Social Landscape,Science and Technologies for Smart Cities,10.1007/978-3-030-51005-3_5,Springer,2020-01-01,2020-07-28,"The concept of Smart Cities are giving lots of opportunities for using technology to make citizens heathier and happier in the future cities. Recent development of artificial intelligence and its capacity to support people in creative and learning processes can be crucial factor in changing social landscape and lead to novel social innovations. In this paper, we are presenting art/research projects, and design experiments of interactive designer Predrag K. Nikolic exposed in various public spaces within the period of last ten years. The conceptual idea behind the projects has been to affect human behavior through novel interactions within playful mix realities and lastly in artificial reality (AIR) as new user experience phenomena in a new urban social landscape.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51005-3_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-36150-1_35,Using a Collaborative Robot to the Upper Limb Rehabilitation,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-36150-1_35,Springer,2020-01-01,2019-11-20,"Rehabilitation is a relevant process for the recovery from dysfunctions and improves the realization of patient’s Activities of Daily Living (ADLs). Robotic systems are considered an important field within the development of physical rehabilitation, thus allowing the collection of several data, besides performing exercises with intensity and repeatedly. This paper addresses the use of a collaborative robot applied in the rehabilitation field to help the physiotherapy of upper limb of patients, specifically shoulder. To perform the movements with any patient the system must learn to behave to each of them. In this sense, the Reinforcement Learning (RL) algorithm makes the system robust and independent of the path of motion. To test this approach, it is proposed a simulation with a UR3 robot implemented in V-REP platform. The main control variable is the resistance force that the robot is able to do against the movement performed by the human arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36150-1_35,springer
Article,doi:10.1007/s10846-019-01031-z,An Intelligent Hybrid Artificial Neural Network-Based Approach for Control of Aerial Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01031-z,Springer,2020-02-01,2019-05-04,"In this work, a learning model-free control method is proposed for accurate trajectory tracking and safe landing of unmanned aerial vehicles (UAVs). A realistic scenario is considered where the UAV commutes between stations at high-speeds, experiences a single motor failure while surveying an area, and thus requires to land safely at a designated secure location. The proposed challenge is viewed solely as a control problem. A hybrid control architecture – an artificial neural network (ANN)-assisted proportional-derivative controller – is able to learn the system dynamics online and compensate for the error generated during different phases of the considered scenario: fast and agile flight, motor failure, and safe landing. Firstly, it deals with unmodelled dynamics and operational uncertainties and demonstrates superior performance compared to a conventional proportional-integral-derivative controller during fast and agile flight. Secondly, it behaves as a fault-tolerant controller for a single motor failure case in a coaxial hexacopter thanks to its proposed sliding mode control theory-based learning architecture. Lastly, it yields reliable performance for a safe landing at a secure location in case of an emergency condition. The tuning of weights is not required as the structure of the ANN controller starts to learn online, each time it is initialised, even when the scenario changes – thus, making it completely model-free. Moreover, the simplicity of the neural network-based controller allows for the implementation on a low-cost low-power onboard computer. Overall, the real-time experiments show that the proposed controller outperforms the conventional controller.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-019-01031-z,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-44267-5_25,Continuous Control in Deep Reinforcement Learning with Direct Policy Derivation from Q Network,"Human Interaction, Emerging Technologies and Future Applications II",10.1007/978-3-030-44267-5_25,Springer,2020-01-01,2020-04-03,"The reinforcement learning approach allows learning desired control policy in different environments without explicitly providing system dynamics. A model-free deep Q-learning algorithm is proven to be efficient on a large set of discrete-action tasks. Extension of this method to the continuous control task usually solved with actor-critic methods which approximate a policy function with additional actor network and uses Q function to speed up policy network training. Another approach is to discretize action space which will not give a smooth policy and is not applicable for large action spaces. A direct continuous policy derivation from the Q network leads to optimization of action on each inference and training step which is not efficient but provides optimal and continuous action. Time-efficient Q function input optimization is required in order to apply this method in practice. In this work, we implement efficient action derivation method which allows using Q-learning in real-time continuous control tasks. In addition, we test our algorithm on robotics control tasks from robotics gym environments and compare this method with modern continuous RL methods. The results have shown that in some cases proposed approach learns smooth continuous policy keeping the implementation simplicity of the original discreet action space Q-learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44267-5_25,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-63955-6_21,Simulation Training Remote Control System of Industrial Robot Based on Deep Learning,"e-Learning, e-Education, and Online Training",10.1007/978-3-030-63955-6_21,Springer,2020-01-01,2020-12-13,"In order to improve the remote control performance of industrial robot simulation training, deep learning algorithm is used to optimize the design of traditional remote control system. On the basis of traditional remote control system, the configuration of hardware system is modified, and the database of control system is established. With the support of hardware system and database, the remote control of two training items of industrial robot simulation mobile training and simulation picking training are realized respectively. Through the system test experiment, the conclusion is drawn: compared with the traditional industrial robot remote control system, the control function of the design control system is improved, and the system can save about 12.5 s response time in the control process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63955-6_21,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60128-7_21,Producing an Immersive Experience Using Human-Robot Interaction Stimuli,"HCI International 2020 – Late Breaking Papers: Cognition, Learning and Games",10.1007/978-3-030-60128-7_21,Springer,2020-01-01,2020-10-04,"Human-Robot Interaction (HRI) is an emerging topic within contemporary science and this topic spans the literatures between engineering, psychology, computer science, artificial intelligence, machine learning and robotics. The study of HRI requires scenarios and other affordances from which to contextualize the HRI to study the factors that shape human attitudes, behaviors, and biases as they relate to robots. The current paper details the rationale, software/hardware, and contextual considerations associated with the creation of HRI stimuli used in experiments, specifically the creation of a set of video stimuli. These stimuli centered on the concept of an autonomous security robot (ASR) and provided a scenario wherein humans (research confederates) would interact with the ASR in a realistic scenario. A video was created to foster a realistic visual and auditory representation of the HRI encounter from a dynamic perspective – meaning shifting perspectives between a first-person experiential vantage point to a birds-eye-view of the broader situation. The scenario used involved a security context where the confederates sought access to a secure facility. The ASR’s role was to examine visitor access credentials and determine if the visitor was authorized or not. The robot’s behaviors, while scripted, were depicted as autonomous in the video and included verbal interactions/instructions as well as physical limb motions, gestures, and instructions. Several important features of the stimuli were considered in its creation, namely: realism, immersive experience, and simulated vulnerability of the human to the robot. The current paper walks through each of these considerations with details provided in our approach. To date, the HRI stimuli have been used in multiple experiments and have demonstrated flexibility in addressing multiple research questions in the domain of HRI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60128-7_21,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60337-3_8,Collision Detection in the Work of Collaborative Robots Using an Intelligent System,Interactive Collaborative Robotics,10.1007/978-3-030-60337-3_8,Springer,2020-01-01,2020-09-30,"This paper describes an approach to applying the JSM method for automatic recognition of collision situations when working with collaborative robots. The approach uses the description of situations in the form of a set of primitives that determine the position of a person in the work space and allow you to distinguish a person from surrounding objects. An intelligent JSM system requires training that can be realized in real time. In the course of experiments, the efficiency of the proposed approach was confirmed and estimates of the collision detection time were made.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60337-3_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-48989-2_56,"Crashing to Learn, Learning to Survive: Planning in Dynamic Environments via Domain Randomization",Advances in Service and Industrial Robotics,10.1007/978-3-030-48989-2_56,Springer,2020-01-01,2020-06-19,"Autonomous robots in the real world should avert collisions with pedestrians and react quickly to sudden changes in the environment. Most local planners rely on static environment maps that cannot capture such critical elements of uncertainty. Learning based methods for end-to-end navigation have become popular recently, but it is still unclear how to incorporate collision avoidance in a simple, safe and quick manner. We propose a reinforcement learning curriculum based on domain randomization to train a high performing policy entirely in simulation. The policy is first trained in a simple obstacle-free environment to quickly learn point to point navigation. The learned policy is transferred to a dynamic environment to learn collision avoidance. The key idea is to randomize the obstacle dynamics to obtain a robust planner that can be directly deployed to the real world. The resultant policy outperforms conventional planners in dynamic real world environments, even when the robot is intentionally obstructed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-48989-2_56,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-74336-3_636-1,Autonomous Weapon Systems (AWS),The Palgrave Encyclopedia of Global Security Studies,10.1007/978-3-319-74336-3_636-1,Springer,2020-01-01,2020-09-05,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-74336-3_636-1,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-3242-9_21,Sapling Health Monitoring System,Advanced Computing Technologies and Applications,10.1007/978-981-15-3242-9_21,Springer,2020-01-01,2020-05-07,"Aim is to create a system that helps in time to time analysis of field to collect real-time data of field crops about moisture, soil pH, etc. System also helps in detecting diseases if any in crops by collecting their leaf snaps. The paper briefly explains the system and its architecture which is implemented on a rover equipped to collect data and is further processed using deep learning concepts. The paper discusses the real-world implementation of this device and its work cycle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-3242-9_21,springer
Chapter,doi:10.1007/978-981-32-9990-0_5,Autonomous Robot Navigation Using Moth-Flame-Based Neuroevolution,Evolutionary Machine Learning Techniques,10.1007/978-981-32-9990-0_5,Springer,2020-01-01,2019-11-12,"Determining the best set of weights and biases for training neural networks (NN) using gradient descent techniques is a computationally challenging task. On the other hand, training of gradient descent algorithms suffers from being trapped in local optima and slow convergence speed in the last iterations. The moth-flame optimization (MFO) is a novel evolutionary method based on navigation paths of moths in nature. This algorithm showed its effectiveness in many real-world optimization problems. In this chapter, MFO is employed for training multilayer perceptron (MLP) to overcome the problems of gradient descent algorithms. This algorithm also investigates the application of the MFO for tackling the navigation of autonomous mobile robots. The results are compared with four powerful evolutionary algorithms including gray wolf optimizer (GWO), cuckoo search (CS), multiverse optimizer algorithm (MVO), and particle swarm optimization (PSO). Moreover, the results are compared to two gradient-based training MLP algorithms including Levenberg–Marquardt (LM) and back-propagation (BP). The evaluation metrics used in this book chapter are accuracy and area under the curve (AUC). The experimental results show that MFO-based MLP algorithm outperforms other algorithms and showed its capabilities effectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-32-9990-0_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-29135-8_3,The AI Driving Olympics at NeurIPS 2018,The NeurIPS '18 Competition,10.1007/978-3-030-29135-8_3,Springer,2020-01-01,2019-11-30,"Despite recent breakthroughs, the ability of deep learning and reinforcement learning to outperform traditional approaches to control physically embodied robotic agents remains largely unproven. To help bridge this gap, we present the “AI Driving Olympics” (AI-DO), a competition with the objective of evaluating the state of the art in machine learning and artificial intelligence for mobile robotics. Based on the simple and well-specified autonomous driving and navigation environment called “Duckietown,” the AI-DO includes a series of tasks of increasing complexity—from simple lane-following to fleet management. For each task, we provide tools for competitors to use in the form of simulators, logs, code templates, baseline implementations and low-cost access to robotic hardware. We evaluate submissions in simulation online, on standardized hardware environments, and finally at the competition event. The first AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems (NeurIPS) conference in December 2018. In this paper we will describe the AI-DO 1 including the motivation and design objections, the challenges, the provided infrastructure, an overview of the approaches of the top submissions, and a frank assessment of what worked well as well as what needs improvement. The results of AI-DO 1 highlight the need for better benchmarks, which are lacking in robotics, as well as improved mechanisms to bridge the gap between simulation and reality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29135-8_3,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-28619-4_60,Stochastic Motion Planning for Hopping Rovers on Small Solar System Bodies,Robotics Research,10.1007/978-3-030-28619-4_60,Springer,2020-01-01,2019-11-28,"Hopping rovers have emerged as a promising platform for the future surface exploration of small Solar System bodies, such as asteroids and comets. However, hopping dynamics are governed by nonlinear gravity fields and stochastic bouncing on highly irregular surfaces, which pose several challenges for traditional motion planning methods. This paper presents the first ever discussion of motion planning for hopping rovers that explicitly accounts for various sources of uncertainty. We first address the problem of planning a single hopping trajectory by developing (1) an algorithm for robustly solving Lambert’s orbital boundary value problems in irregular gravity fields, and (2) a method for computing landing distributions by propagating control and model uncertainties—from which, a time/energy-optimal hop can be selected using a (myopic) policy gradient. We then cast the sequential planning problem as a Markov decision process and apply a sample-efficient, off-line, off-policy reinforcement learning algorithm—namely, a variant of least squares policy iteration (LSPI)—to derive approximately optimal control policies that are safe, efficient, and amenable to real-time implementation on computationally-constrained rover hardware. These policies are demonstrated in simulation to be robust to modelling errors and outperform previous heuristics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-28619-4_60,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60337-3_29,A Modular Deep Learning Architecture for Anomaly Detection in HRI,Interactive Collaborative Robotics,10.1007/978-3-030-60337-3_29,Springer,2020-01-01,2020-09-30,"Considering humans as a non-deterministic factor makes anomaly detection in Human-Robot Interaction scenarios rather a challenging problem. Anomalous events like unexpected user interaction or unforeseen environment changes are unknown before they happen. On the other hand, the work process or user intentions could evolve in time. To address this issue, a modular deep learning approach is presented that is able to learn normal behavior patterns in an unsupervised manner. We combined the unsupervised feature extraction learning ability of an autoencoder with a sequence modeling neural network. Both models were firstly evaluated on benchmark video datasets, revealing adequate performance comparable to the state-of-the-art methods. For HRI application, a continuous training approach for real-time anomaly detection was developed and evaluated in an HRI-experiment with a collaborative robot, ToF camera, and proximity sensors. In the user study with 10 subjects irregular interactions and misplaced objects were the most common anomalies, which system was able to detect reliably.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60337-3_29,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60117-1_16,A Sociable Robotic Platform to Make Career Advices for Undergraduates,HCI International 2020 - Late Breaking Papers: Multimodality and Intelligence,10.1007/978-3-030-60117-1_16,Springer,2020-01-01,2020-10-17,"Most of the undergraduates couldn’t figure out a proper direction for their future careers since advising depends on the person and students show aversion in revealing their information to other humans. This research focused on creating a social robotic platform to interact with undergraduates in the field of computer science to realize possible career paths, as recent researches show social companion robots tend to form a stronger bond, which helps the addressee to share their information easily. The robot was created as a tabletop robot employing minimalistic design with a friendly view attached with speech synthesis for communicating purposes. Data was collected from 202 persons, who followed a degree in computer science. Data contains their experience, qualifications, and skills. Thereafter an artificial neural network was created using supervised learning to predict the career path with 95% performance accuracy. The experiment was performed by engaging 15 students from the final year who are a doing degree in computer science and they were asked to provide feedback on the interactions with the robot. The gathered responses highlighted robot animacy, interaction, technology and usefulness. Therefore, from the results it can be concluded that a majority of the students accepted the robot, interacted without hesitation and had friendly conversations with the robot where they valued the generated output from the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60117-1_16,springer
Chapter,doi:10.1007/978-981-15-4095-0_16,Robot Learning in Simulation,Deep Reinforcement Learning,10.1007/978-981-15-4095-0_16,Springer,2020-01-01,2020-06-30,"This chapter introduces a hands-on project for robot learning in simulation, including the process of setting up a task with a robot arm for objects grasping in CoppeliaSim and the deep reinforcement learning solution with soft actor-critic algorithm. The effects of different reward functions are also shown in the experimental sections, which testifies the importance of auxiliary dense rewards for solving a hard-to-explore task like the robot grasping ones. Brief discussions on robot learning applications, sim-to-real transfer, other robot learning projects and simulators are also provided at the end of this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4095-0_16,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-42058-1_32,Soft Computing-Based Control System of Intelligent Robot Navigation,Intelligent Information and Database Systems,10.1007/978-3-030-42058-1_32,Springer,2020-01-01,2020-03-04,"This paper focuses on the study of intelligent navigation techniques which are capable of navigating a mobile robot autonomously in unknown environments in real-time. We primarily focused on a soft computing-based control system of autonomous robot behaviour. The soft computing methods included artificial neural networks and fuzzy logic. Using them, it was possible to control autonomous robot behaviour. Based on defined behaviour, this device was able to deduce a corresponding reaction to an unknown situation. Real robotic equipment was represented by a Lego Mindstorms EV3 robot. The outcomes of all experiments were analysed in the conclusion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-42058-1_32,springer
Article,doi:10.1007/s10734-019-00387-3,Joseph E. Aoun: Robot-proof: higher education in the age of artificial intelligence,Higher Education,10.1007/s10734-019-00387-3,Springer,2019-12-01,2019-04-09,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10734-019-00387-3,springer
Article,doi:10.1007/s13218-019-00625-x,Special Issue on Reintegrating Artificial Intelligence and Robotics,KI - Künstliche Intelligenz,10.1007/s13218-019-00625-x,Springer,2019-12-01,2019-11-13,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00625-x,springer
Article,doi:10.1007/s13218-019-00621-1,A Philosophically Motivated View on AI and Robotics,KI - Künstliche Intelligenz,10.1007/s13218-019-00621-1,Springer,2019-12-01,2019-09-11,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00621-1,springer
Article,doi:10.1007/s10734-018-0326-2,Joseph E. Aoun: robot-proof—higher education in the age of artificial intelligence,Higher Education,10.1007/s10734-018-0326-2,Springer,2019-07-15,2018-10-27,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10734-018-0326-2,springer
Article,doi:10.1007/s42438-018-0005-8,Review of Joseph E. Aoun (2017). Robot Proof: Higher Education in the Age of Artificial Intelligence,Postdigital Science and Education,10.1007/s42438-018-0005-8,Springer,2019-04-15,2018-08-29,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42438-018-0005-8,springer
Article,doi:10.1007/s10734-018-0289-3,Joseph E. Aoun: Robot-proof: higher education in the age of artificial intelligence,Higher Education,10.1007/s10734-018-0289-3,Springer,2019-04-15,2018-06-16,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10734-018-0289-3,springer
Article,doi:10.1007/s00146-017-0703-x,Rethinking the I-You relation through dialogical philosophy in the Ethics of AI and robotics,AI & SOCIETY,10.1007/s00146-017-0703-x,Springer,2019-03-14,2017-03-09,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0703-x,springer
Article,doi:10.1007/s41315-019-00101-7,Transferring optimal contact skills to flexible manipulators by reinforcement learning,International Journal of Intelligent Robotics and Applications,10.1007/s41315-019-00101-7,Springer,2019-09-01,2019-09-03,"Flexible/soft manipulators have the potential to maneuver in confined space and reach deeply-seated targets via curvy trajectories, thus enjoy increasing popularity in minimally invasive surgery (MIS) community. We aim to automate palpation movement for this type of robots, an important procedure for disease diagnosis, where multiple force and pose requirements are to be achieved simultaneously. It’s challenging to obtain accurate models due to the system’s inherent nonlinearities and actuation hysteresis. Moreover, unknown contact transitions and high-dimensionality specific to the palpation task, pose great challenges to deriving optimal task policies. We employ the model-free reinforcement learning method for learning palpation skills through deterministic policy gradient, whose reward function was carefully shaped to accommodate all the task objectives. In addition, we design a safety check routine to avoid undesirable collisions and a dedicated initialization process for generalization to various environment conditions. We demonstrate successful implementation of the learning framework in simulation and real world. The trained policy succeeds in automating the designed tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-019-00101-7,springer
Article,doi:10.1007/s00138-018-0966-3,A hybrid image dataset toward bridging the gap between real and simulation environments for robotics,Machine Vision and Applications,10.1007/s00138-018-0966-3,Springer,2019-02-13,2018-08-01,"The primary motivation of computer vision in the robotics field is to obtain a perception level that is as close as possible to human visual system. To achieve this, the inclusion of large datasets is necessary, sometimes involving less-frequent and seemingly irrelevant data to increase the system robustness. To minimize the effort and time in forming such extensive datasets from real world, the preferred method is to utilize simulation environments, replicating real-world conditions as much as possible. Following this solution path, the machine vision problems in robotics (i.e., object detection, recognition, and manipulation) often employ synthetic images in datasets and, however, do not mix them with real-world images. When the systems are trained only using the synthetic images and tested within the simulated world, the tasks requiring object recognition in robotics can be accomplished. However, the systems trained using this procedure cannot be directly used in the real-world experiments or end-user products due to the inconsistencies between real and simulation environments. Therefore, we propose a hybrid image dataset including annotated desktop objects from real and synthetic worlds (ADORESet). This hybrid dataset provides purposeful object categories with a sufficient number of real and synthetic images. ADORESet is composed of colored images with the dimension of $$300\times 300$$ 300 × 300 pixels within 30 categories. Each class has 2500 real-world images acquired from the wild web and 750 synthetic images that are generated within Gazebo simulation environment. This hybrid dataset enables researchers to implement their own algorithms for both real-world and simulation environment conditions. ADORESet is composed of fully annotated object images. The limits of objects are manually specified, and the bounding box coordinates are provided. The successor objects are also labeled to give statistical information and the likelihood about the relations of the objects within the dataset. To further demonstrate the benefits of this dataset, it is tested in object recognition tasks by fine-tuning the state-of-the-art deep convolutional neural networks such as VGGNet, InceptionV3, ResNet, and Xception. The possible combinations regarding the data types for these models are compared in terms of time, accuracy, and loss values. As a result of the conducted object recognition experiments, training with all-real images yields approximately $$49\%$$ 49 % validation accuracy for simulation images. When the training is performed with all-synthetic images and validated using all-real images, the accuracy becomes lower than $$10\%$$ 10 % . If the complete ADORESet is employed for training and validation, the hybrid dataset validation accuracy reaches approximately to $$95\%$$ 95 % . This result proves further that including the real and synthetic images together in the training and validation sessions increases the overall system accuracy and reliability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00138-018-0966-3,springer
Article,doi:10.1007/s10514-018-9810-x,Advancing multi-vehicle deployments in oceanographic field experiments,Autonomous Robots,10.1007/s10514-018-9810-x,Springer,2019-08-15,2018-10-26,"Our research concerns the coordination and control of robotic vehicles for upper water-column oceanographic observations. In such an environment, operating multiple vehicles to observe dynamic oceanographic phenomena, such as ocean processes and marine life, from fronts to cetaceans, has required that we design, implement and operate software, methods and processes which can support opportunistic needs in real-world settings with substantial constraints. In this work, an approach for coordinated measurements using such platforms, which relate directly to task outcomes, is presented. We show the use and operational value of a new Artificial Intelligence based mixed-initiative system for handling multiple platforms along with the networked infrastructure support needed to conduct such operations in the open sea. We articulate the need and use of a range of middleware architectures, critical for such deployments and ground this in the context of a field experiment in open waters of the mid-Atlantic in the summer of 2015.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-018-9810-x,springer
Article,doi:10.1007/s00170-018-03263-z,Observations on developing reliability information utilization in a manufacturing environment with case study: robotic arm manipulators,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-018-03263-z,Springer,2019-06-19,2019-02-13,"Manufacturing environments face many unique challenges with regard to balancing high standards of both product quality and production efficiency. Proper diagnostic health assessment is essential for maximizing uptime and maintaining product and process quality. Information for diagnostic assessments, and reliability information in general, can come from a myriad of sources that can be processed and managed through numerous algorithms that range from simplistic to hypercomplex. One area that typifies the assortment of information sources in a modern manufacturing setting is found with the use of industrial robotics and automated manipulators. Although several monitoring methods and technologies have been previously proposed for this and other assets, adoption has been sporadic with returns on investment not always meeting expectations. Practical concerns regarding data limitations, variability of setup, and scarcity of ground truth points of validation from active industrial sites have contributed to this. This paper seeks to provide an overview of barriers and offer a feasible action plan for developing a practical condition monitoring information utilization program, matching available capabilities and assets to maximize knowledge gain. Observations are made on a real-world case study involving industrial 6 degrees of freedom (DOF) robots actively deployed in a manufacturing facility with a variety of operational tasks.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s00170-018-03263-z,springer
Article,doi:10.1007/s10846-019-00989-0,Evolutionary Robotics Applied to Hexapod Locomotion: a Comparative Study of Simulation Techniques,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-00989-0,Springer,2019-12-15,2019-02-07,"The Evolutionary Robotics (ER) process has been applied extensively to developing control programs to achieve locomotion in legged robots, as an automated alternative to the arduous task of manually creating control programs for such robots. The evolution of such controllers is typically performed in simulation by making use of a physics engine-based robotic simulator. Making use of such physics-based simulators does, however, have certain challenges associated with it, such as these simulators’ computational inefficiency, potential issues with lack of accuracy and the human effort required to construct such simulators. The current study therefore proposed and investigated an alternative method of simulation for a hexapod (six-legged) robot in the ER process, and directly compared this newly-proposed simulation method to traditional physics-based simulation. This alternative robotic simulator was built based solely on experimental data acquired directly from observing the behaviour of the robot. This data was used to construct a simulator for the robot based on Artificial Neural Networks (ANNs). To compare this novel simulation method to traditional physics simulation, the ANN-based simulators were used to evolve simple open-loop locomotion controllers for the robot in simulation. The real-world performance of these controllers was compared to that of controllers evolved in a more traditional physics-based simulator. The obtained results indicated that the use of ANN-based simulators produced controllers which could successfully perform the required locomotion task on the real-world robot. In addition, the controllers evolved using the ANN-based simulators allowed the real-world robot to move further than those evolved in the physics-based simulator and the ANN-based simulators were vastly more computationally efficient than the physics-based simulator. This study thus decisively indicated that ANN-based simulators offer a superior alternative to widely-used physics simulators in ER for the locomotion task considered.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-019-00989-0,springer
Article,doi:10.1007/s11432-019-9932-3,Accelerating DNN-based 3D point cloud processing for mobile computing,Science China Information Sciences,10.1007/s11432-019-9932-3,Springer,2019-09-19,2019-09-19,"3D point cloud data, which are produced by various 3D sensors such as LIDAR and stereo cameras, have been widely deployed by industry leaders such as Google, Uber, Tesla, and Mobileye, for mobile robotic applications such as autonomous driving and humanoid robots. Point cloud data, which are composed of reliable depth information, can provide accurate location and shape characteristics for scene understanding, such as object recognition and semantic segmentation. However, deep neural networks (DNNs), which directly consume point cloud data, are particularly computation-intensive because they have to not only perform multiplication-and-accumulation (MAC) operations but also search neighbors from the irregular 3D point cloud data. Such a task goes beyond the capabilities of general-purpose processors in realtime to figure out the solution as the scales of both point cloud data and DNNs increase from application to application. We present the first accelerator architecture that dynamically configures the hardware on-the-fly to match the computation of both neighbor point search and MAC computation for point-based DNNs. To facilitate the process of neighbor point search and reduce the computation costs, a grid-based algorithm is introduced to search neighbor points from a local region of grids. Evaluation results based on the scene recognition and segmentation tasks show that the proposed design harvests 16.4 × higher performance and saves 99.95% of energy than an NVIDIA Tesla K40 GPU baseline in point cloud scene understanding applications.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s11432-019-9932-3,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-03748-2_40,Reinforcement Learning-Based Two-Wheel Robot Control,Recent Advances in Intelligent Information Hiding and Multimedia Signal Processing,10.1007/978-3-030-03748-2_40,Springer,2019-01-01,2018-11-11,"In this paper, reinforcement learning (RL) with PID control is used to design the balance and self-control system to verify the feasibility of RL technology in this field. We can use straight line command and turn command via WiFi interface to control the robot. Thus the robot acts according to the received command. The system is divided into three parts: sensing module, learning control module and motor drive module. A Q-Learning algorithm is implemented by learning control module using ARM A8 embedded platform. The sensing module contains an accelerometer (ADXL345) and a gyroscope (L3G4200D) that senses the current tilt angle and angular velocity of robot. Rely on the Q-learning algorithm which based on the input data from sensing module, an optimal response control is derived in motor driving control. The realization results shown that the two-wheel robot can back to balance within 2 ms once it goes to unbalance state.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-03748-2_40,springer
Article,doi:10.1007/s40313-019-00472-z,Adaptive Neural Network-Based Backstepping Sliding Mode Control Approach for Dual-Arm Robots,"Journal of Control, Automation and Electrical Systems",10.1007/s40313-019-00472-z,Springer,2019-08-15,2019-05-30,"The paper introduces an adaptive strategy to effectively control a nonlinear dual-arm robot under external disturbances and uncertainties. By the use of the backstepping sliding mode control (BSSMC) method, the proposed algorithm first allows the manipulators to be able to robustly track the desired trajectories. Furthermore, due to the nonlinear, uncertain and unmodeled dynamics of the dual-arm robot, it is proposed to employ the radial basis function network (RBFN) to adaptively estimate the robot’s dynamic model. Though the estimation of the dynamics is approximate, the adaptation law is derived from the Lyapunov theory, which provides the controller with ability to guarantee stability of the whole system in spite of its nonlinearities, parameter uncertainties and external load variations. The effectiveness of the proposed RBFN–BSSMC approach is demonstrated by implementation in a simulation environment with realistic parameters, where the obtained results are highly promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40313-019-00472-z,springer
Article,doi:10.1186/s40942-019-0202-y,"Artificial intelligence, robotics and eye surgery: are we overfitted?",International Journal of Retina and Vitreous,10.1186/s40942-019-0202-y,BioMed Central,2019-12-16,2019-12-16,"Eye surgery, specifically retinal micro-surgery involves sensory and motor skill that approaches human boundaries and physiological limits for steadiness, accuracy, and the ability to detect the small forces involved. Despite assumptions as to the benefit of robots in surgery and also despite great development effort, numerous challenges to the full development and adoption of robotic assistance in surgical ophthalmology, remain. Historically, the first in-human–robot-assisted retinal surgery occurred nearly 30 years after the first experimental papers on the subject. Similarly, artificial intelligence emerged decades ago and it is only now being more fully realized in ophthalmology. The delay between conception and application has in part been due to the necessary technological advances required to implement new processing strategies. Chief among these has been the better matched processing power of specialty graphics processing units for machine learning. Transcending the classic concept of robots performing repetitive tasks, artificial intelligence and machine learning are related concepts that has proven their abilities to design concepts and solve problems. The implication of such abilities being that future machines may further intrude on the domain of heretofore “human-reserved” tasks. Although the potential of artificial intelligence/machine learning is profound, present marketing promises and hype exceeds its stage of development, analogous to the seventieth century mathematical “boom” with algebra. Nevertheless robotic systems augmented by machine learning may eventually improve robot-assisted retinal surgery and could potentially transform the discipline. This commentary analyzes advances in retinal robotic surgery, its current drawbacks and limitations, and the potential role of artificial intelligence in robotic retinal surgery.",https://www.biomedcentral.com/openurl?doi=10.1186/s40942-019-0202-y,springer
Article,doi:10.1007/s00170-019-03851-7,Machine learning for in-process end-point detection in robot-assisted polishing using multiple sensor monitoring,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-019-03851-7,Springer,2019-08-01,2019-05-19,"The decision on polishing operation stopping time when employing a robot-assisted polishing machine is a critical issue for the full automation of the polishing process. In this paper, a machining learning approach based on artificial neural networks was developed using multiple sensor monitoring data to realize an intelligent system capable to determine the state of the polishing process in terms of target surface roughness achievement. During the experimental tests, surface roughness measurements were performed on each polished workpiece and the acquired sensor signals were analyzed and processed by applying two kinds of feature extraction procedures: statistical features extraction and principal component analysis. By feeding diverse types of feature pattern vectors to artificial neural networks, a highly accurate classification of the polishing process state was obtained using the principal component feature pattern vectors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-019-03851-7,springer
Article,doi:10.1186/s10033-019-0373-3,Neural Network-Based Adaptive Motion Control for a Mobile Robot with Unknown Longitudinal Slipping,Chinese Journal of Mechanical Engineering,10.1186/s10033-019-0373-3,Springer,2019-07-17,2019-07-17,"When the mobile robot performs certain motion tasks in complex environment, wheel slipping inevitably occurs due to the wet or icy road and other reasons, thus directly influences the motion control accuracy. To address unknown wheel longitudinal slipping problem for mobile robot, a RBF neural network approach based on whole model approximation is presented. The real-time data acquisition of inertial measure unit (IMU), encoders and other sensors is employed to get the mobile robot’s position and orientation in the movement, which is applied to compensate the unknown bounds of the longitudinal slipping using the adaptive technique. Both the simulation and experimental results prove that the control scheme possesses good practical performance and realize the motion control with unknown longitudinal slipping.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s10033-019-0373-3,springer
Chapter,doi:10.1007/978-3-030-33274-7_11,Toward Faster Reinforcement Learning for Robotics: Using Gaussian Processes,Artificial Intelligence,10.1007/978-3-030-33274-7_11,Springer,2019-01-01,2019-10-14,"Standard robotic control works perfectly in case of ordinary conditions, but in the case of a change in the conditions (e.g. damaging of one of the motors), the robot won’t achieve its task anymore. We need an algorithm that provide the robot with the ability of adaption to unforeseen situations. Reinforcement learning provide a framework corresponds with that requirements, but it needs big data sets to learn robotic tasks, which is impractical. We discuss using Gaussian processes to improve the efficiency of the Reinforcement learning, where a Gaussian Process will learn a state transition model using data from the robot (interaction) phase, and after that use the learned GP model to simulate trajectories and optimize the robot’s controller in a (simulation) phase. PILCO algorithm considered as the most data efficient RL algorithm. It gives promising results in Cart-pole task, where a working controller was learned after seconds of (interaction) on the real robot, but the whole training time, considering the training in the (simulation) was longer. In this work, we will try to leverage the abilities of the computational graphs to produce a ROS friendly python implementation of PILCO, and discuss a case study of a real world robotic task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33274-7_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-99316-4_37,An Intrinsically Motivated Robot Explores Non-reward Environments with Output Arbitration,Biologically Inspired Cognitive Architectures 2018,10.1007/978-3-319-99316-4_37,Springer,2019-01-01,2018-08-24,"In real worlds, rewards are easily sparse because the state space is huge. Reinforcement learning agents have to achieve exploration skills to get rewards in such an environment. In that case, curiosity defined as internally generated rewards for state prediction error can encourage agents to explore environments. However, when a robot learns its policy by reinforcement learning, changing outputs of the policy cause jerking because of inertia. Jerking prevents state prediction from convergence, which would make the policy learning unstable. In this paper, we propose Arbitrable Intrinsically Motivated Exploration (AIME), which enables robots to stably learn curiosity-based exploration. AIME uses Accumulator Based Arbitration Model (ABAM) that we previously proposed as an ensemble learning method inspired by prefrontal cortex. ABAM adjusts motor controls to improve stability of reward generation and reinforcement learning. In experiments, we show that a robot can explore a non-reward simulated environment with AIME.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99316-4_37,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-35430-5_2,Robots’ Vision Humanization Through Machine-Learning Based Artificial Visual Attention,Pattern Recognition and Information Processing,10.1007/978-3-030-35430-5_2,Springer,2019-01-01,2019-11-23,"If the main challenge of robotics during the industrial air of 19^th century has consisted of automating repetitive tasks and the sophistication of these machines through digitization of these robots throughout the 20^th century, the challenge of robotics in the current century will be to make cohabit humans and robots in the same living space. However, robots would not succeed in seamlessly integrate the humans’ universe without developing the ability of perceiving similarly to humans the environment that they are supposed to share with them. In such a context, fitting the skills of the natural vision is an appealing perspective for autonomous robotics dealing with and prospecting Human-Robot interaction. The main goal of the present article is to debate the plausibility and the reality of humanizing the robots behavior focusing the perception of the surrounding environment. An implementation of the developed concept on a real humanoid robot nourishes the presented results and the related discussions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35430-5_2,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-22338-0_26,Humanoid Robots as Interviewers for Automated Credibility Assessment,"HCI in Business, Government and Organizations. Information Systems and Analytics",10.1007/978-3-030-22338-0_26,Springer,2019-01-01,2019-06-14,"Humans are poor at detecting deception under the best conditions. The need for having a decision support system that can be a baseline for data-driven decision making is obvious. Such a system is not biased like humans are, and these often subconscious human biases can impair people’s judgment. A system for helping people at border security (CBP) is the AVATAR. The AVATAR, an Embodied Conversational agent (ECA), is implemented as a self-service kiosk. Our research uses this AVATAR as the baseline and we plan to augment the automated credibility assessment task that the AVATAR performs using a Humanoid robot. We will be taking advantage of humanoid robots’ capability of realistic dialogue and nonverbal gesturing. We are also capturing data from various sensors like microphones, cameras and an eye tracker that will help in model building and testing for the task of deception detection. We plan to carry out an experiment where we compare the results of an interview with the AVATAR and an interview with a humanoid robot. Such a comparative analysis has never been done before, hence we are very eager to conduct such a social experiment. This research paper deals with the design and implementation plan for such an experiment. We also want to highlight what the considerations are while designing such a social experiment. It will help us understand how people perceive robot agent interactions in contrast to the more traditional ECA agents on screen. For example, does the physical presence of a robot encourage greater perceptions of likability, expertise, or dominance? Moreover, this research will address the question on which interaction model (ECA or robot) elicits the most diagnostic cues to detecting deception. This study may also prove very useful to researchers and organizations that want to use robots in increasing social roles and need to understand its societal and personal implications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22338-0_26,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-99885-5_1,Semantic Localization of a Robot in a Real Home,Advances in Physical Agents,10.1007/978-3-319-99885-5_1,Springer,2019-01-01,2018-11-21,"In social robotics, it is important that a mobile robot knows where it is because it provides a starting point for other activities such as moving from one room to another. As a contribution to solving this problem in the field of the semantic location of the mobile robot, we pro- pose to implement a methodology of recognition and scene learning in a real domestic environment. For this purpose, we used images from five different residences to create a dataset with which the base model was trained. The effectiveness of the implemented base model is evaluated in different scenarios. When the accuracy of the site identification decreases, the user provides feedback to the robot so that it can process the information collected from the new environment and re-identify the current location. The results obtained reinforce the need to acquire more knowledge when the environment is not recognizable by the pre-trained model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99885-5_1,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_46,3D Pose Estimation of Robot Arm with RGB Images Based on Deep Learning,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_46,Springer,2019-01-01,2019-08-03,"In the field of human-robot interaction, robot collision avoidance with the human in a shared workspace remains a challenge. Many researchers use visual methods to detect the collision between robots and obstacles on the assumption that the robot pose is known because the information about the robot is obtained from the controller and hand-eye calibration is conducted. Therefore, they focus on the motion prediction of obstacles. In this paper, a real-time method based on deep learning is proposed to directly estimate the 3D pose of the robot arm using a color image. The method aims to remove the hand-eye calibration when the system needs to be reconfigured and increase the flexibility of the system by eliminating the requirement that the camera fixed relative to the robot. Our approach has two main contributions. One is that the method estimates the 3D position of the robot base and the relative 3D positions of the predefined key points of the robot to the robot base separately different from other deep learning methods considering the limitations of the dataset. The other is that some datasets are collected through another trained network to avoid tedious calibration process, and the trained network will be reused in the pose estimation task. Finally, the experiments are conducted. The results show that a fully trained system provides an accurate 3D pose estimation for the robot arm in the camera coordinate system. The average errors of the 3D positions of the robot base and the predefined key points are 2.35 cm and 1.99 cm respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_46,springer
Article,doi:10.1631/FITEE.1800587,Autonomous flying blimp interaction with human in an indoor space,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1800587,Springer,2019-01-01,2019-01-08,"We present the Georgia Tech Miniature Autonomous Blimp (GT-MAB), which is designed to support human-robot interaction experiments in an indoor space for up to two hours. GT-MAB is safe while flying in close proximity to humans. It is able to detect the face of a human subject, follow the human, and recognize hand gestures. GT-MAB employs a deep neural network based on the single shot multibox detector to jointly detect a human user’s face and hands in a real-time video stream collected by the onboard camera. A human-robot interaction procedure is designed and tested with various human users. The learning algorithms recognize two hand waving gestures. The human user does not need to wear any additional tracking device when interacting with the flying blimp. Vision-based feedback controllers are designed to control the blimp to follow the human and fly in one of two distinguishable patterns in response to each of the two hand gestures. The blimp communicates its intentions to the human user by displaying visual symbols. The collected experimental data show that the visual feedback from the blimp in reaction to the human user significantly improves the interactive experience between blimp and human. The demonstrated success of this procedure indicates that GT-MAB could serve as a flying robot that is able to collect human data safely in an indoor environment.",http://link.springer.com/openurl/pdf?id=doi:10.1631/FITEE.1800587,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-36711-4_49,Achieving Human–Robot Collaboration with Dynamic Goal Inference by Gradient Descent,Neural Information Processing,10.1007/978-3-030-36711-4_49,Springer,2019-01-01,2019-12-09,"Collaboration with a human partner is a challenging task expected of intelligent robots. To realize this, robots need the ability to share a particular goal with a human and dynamically infer whether the goal state is changed by the human. In this paper, we propose a neural network-based computational framework with a gradient-based optimization of the goal state that enables robots to achieve this ability. The proposed framework consists of convolutional variational autoencoders (ConvVAEs) and a recurrent neural network (RNN) with a long short-term memory (LSTM) architecture that learns to map a given goal image for collaboration to visuomotor predictions. More specifically, visual and goal feature states are first extracted by the encoder of the respective ConvVAEs. Visual feature and motor predictions are then generated by the LSTM based on their current state and are conditioned according to the extracted goal feature state. During collaboration after the learning process, the goal feature state is optimized by gradient descent to minimize errors between the predicted and actual visual feature states. This enables the robot to dynamically infer situational (goal) changes of the human partner from visual observations alone. The proposed framework is evaluated by conducting experiments on a human–robot collaboration task involving object assembly. Experimental results demonstrate that a robot equipped with the proposed framework can collaborate with a human partner through dynamic goal inference even when the situation is ambiguous.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36711-4_49,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-22649-7_26,Estimating Timing of Head Movements Based on the Volume and Pitch of Speech,Human Interface and the Management of Information. Information in Intelligent Systems,10.1007/978-3-030-22649-7_26,Springer,2019-01-01,2019-06-29,"Our research aims to create two friendly communication robots to talk with elderly people in nursing facilities. If the robots synchronize their head movements in response to the elderly person, the elderly person may react favorably to the robot. Then, the elderly person can enjoy talking with these two robots. In this paper, we investigated whether the volume and pitch of the speech are useful data for estimating the timing of head movements. Because the robots need to move their heads in real time, when one of the robots or the person is talking, we focus on the volume and pitch of the speech, not the content. Moreover, it was cleared which machine learning method creates suitable classifier models for estimating the timing of head movements. The experimental results showed that Random Forest classifier was the most suitable method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22649-7_26,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-99885-5_11,Person Following Robot Behavior Using Deep Learning,Advances in Physical Agents,10.1007/978-3-319-99885-5_11,Springer,2019-01-01,2018-11-21,"Human-robot interaction (HRI) is a field with growing impact as robot applications are entering into homes, supermarkets and general human environments. Person following is an interesting capability in HRI. This paper presents a new system for a robust person following behavior inside a robot. Its perception module addresses the person detection on images using a pretrained TensorFlow SSD Convolutional Neural Network which provides robustness even on tough lighting conditions. It also includes a face detector and a FaceNet CNN to reidentify the target person. Care has been put to allow real-time operation. The control module implements two PID controllers for a reactive smooth response, moving the robot towards the target person without distracting with other people around. The entire system has been experimentally validated on a real TurtleBot2 robot, with an Asus Xtion RGBD camera.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99885-5_11,springer
Article,doi:10.1007/s13218-018-0553-9,AI and Robotics for the Human Brain Project II,KI - Künstliche Intelligenz,10.1007/s13218-018-0553-9,Springer,2018-11-01,2018-06-15,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-018-0553-9,springer
Article,doi:10.1007/s10151-018-1847-5,"Robotics, artificial intelligence and distributed ledgers in surgery: data is key!",Techniques in Coloproctology,10.1007/s10151-018-1847-5,Springer,2018-09-01,2018-09-21,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10151-018-1847-5,springer
Article,doi:10.1007/s10677-018-9909-3,"Lin, P., Abney, K., & Jenkins, R. (Eds.): Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence",Ethical Theory and Moral Practice,10.1007/s10677-018-9909-3,Springer,2018-06-01,2018-07-31,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-018-9909-3,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-24741-6_4,Automatic Calibration of Artificial Neural Networks for Zebrafish Collective Behaviours Using a Quality Diversity Algorithm,Biomimetic and Biohybrid Systems,10.1007/978-3-030-24741-6_4,Springer,2019-01-01,2019-07-06,"During the last two decades, various models have been proposed for fish collective motion. These models are mainly developed to decipher the biological mechanisms of social interaction between animals. They consider very simple homogeneous unbounded environments and it is not clear that they can simulate accurately the collective trajectories. Moreover when the models are more accurate, the question of their scalability to either larger groups or more elaborate environments remains open. This study deals with learning how to simulate realistic collective motion of collective of zebrafish, using real-world tracking data. The objective is to devise an agent-based model that can be implemented on an artificial robotic fish that can blend into a collective of real fish. We present a novel approach that uses Quality Diversity algorithms, a class of algorithms that emphasise exploration over pure optimisation. In particular, we use CVT-MAP-Elites [ 32 ], a variant of the state-of-the-art MAP-Elites algorithm [ 25 ] for high dimensional search space. Results show that Quality Diversity algorithms not only outperform classic evolutionary reinforcement learning methods at the macroscopic level (i.e. group behaviour), but are also able to generate more realistic biomimetic behaviours at the microscopic level (i.e. individual behaviour).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24741-6_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-22999-3_56,A Model-Based Reinforcement Learning Approach to Time-Optimal Control Problems,Advances and Trends in Artificial Intelligence. From Theory to Practice,10.1007/978-3-030-22999-3_56,Springer,2019-01-01,2019-06-15,"Reinforcement Learning has achieved an exceptional performance in the last decade, yet its application to robotics and control remains a field for deeper investigation due to potential challenges. These include high-dimensional continuous state and action spaces, as well as complicated system dynamics and constraints in robotic settings. In this paper, we demonstrate a pioneering experiment in applying an existing model-based RL framework, PILCO, to the problem of time-optimal control. At first, the algorithm models the system dynamics with Gaussian Processes, successfully reducing the effect of model biases. Then, policy evaluation is done through iterated prediction with Gaussian posteriors and deterministic approximate inference. Finally, analytic gradients are used for policy improvement. A simulation and an experiment of an autonomous car completing a rest-to-rest linear locomotion is documented. Time-optimality and data efficiency of the task are shown in the simulation results, and learning under real-world circumstances is proved possible with our methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22999-3_56,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-11051-2_43,Adaptive Learning for Robots in Public Spaces,Intelligent Human Systems Integration 2019,10.1007/978-3-030-11051-2_43,Springer,2019-01-01,2019-01-06,"Proper functioning of robots deployed in public spaces often require extensive knowledge of its environment of use, which is completely unknown prior to deployment. The methods for acquiring and utilizing such knowledge also varies depending on the nature of the public space and the tasks the robot needs to perform. This calls for development and application of adaptive learning methods specifically designed to take into consideration the nature and key properties of various public spaces and robotic tasks. In this paper, we study typical types of public spaces for deployment of robots, and analyze robotic tasks required in each type of space to derive common capabilities that the robots need to have. We then consider three adaptive learning methods: (1) autonomous learning, (2) unsupervised learning from real-time on-site data, and (3) guided learning. Applicability of the methods to improve each common capability and possible means of application are further discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-11051-2_43,springer
Article,doi:10.1186/s41018-018-0045-4,Search and rescue with autonomous flying robots through behavior-based cooperative intelligence,Journal of International Humanitarian Action,10.1186/s41018-018-0045-4,Springer,2018-12-05,2018-12-05,"A swarm of autonomous flying robots is implemented in simulation to cooperatively gather situational awareness data during the first few hours after a major natural disaster. In computer simulations, the swarm is successful in locating over 90% of survivors in less than an hour. The swarm is controlled by new sets of reactive behaviors which are presented and evaluated. The reactive behaviors integrate collision avoidance, battery recharge, formation control, altitude maintenance, and a variety of search methods to optimize the coverage area of camera and heart-beat locator sensors mounted on the robots. The behaviors are implemented in simulation on swarms of sizes from 1 to 20 robots. The simulation uses actual location data, including post-disaster satellite imagery, real locations of damaged and inundated buildings, and realistic victim locations based on personal interviews and accounts. The results demonstrate the value of using behavior-based swarming algorithms to control autonomous unmanned aerial vehicles for post-disaster search and assessment. Three examples of algorithms that have been effective in simulation are presented .",https://www.biomedcentral.com/openurl?doi=10.1186/s41018-018-0045-4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_10,Improved Neural Network 3D Space Obstacle Avoidance Algorithm for Mobile Robot,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_10,Springer,2019-01-01,2019-08-03,"Path planning problems are classical optimization problems in many fields, such as computers, mathematics, transportation, robots, etc., which can be described as an optimization problem in mathematics. In this paper, the mathematical model of obstacle environment is established. The characteristics of neural network algorithm, simulated annealing algorithm and adaptive variable stepsize via linear reinforcement are studied respectively. A new neural network 3D space obstacle avoidance algorithm for mobile robot is proposed, which solves the problem of the computational duration and minimum distance of the traditional neural network obstacle avoidance algorithm in solving the optimal path. According to the characteristics of the improved neural network algorithm, it is fused with a variety of algorithms to obtain the optimal path algorithm that achieves the shortest path distance and meets the requirements of obstacle avoidance security. The simulation experiment of the algorithm is simulated by Matlab. The results show that the improved neural network spatial obstacle avoidance algorithm based on the multiple algorithms proposed in this paper can effectively accelerate the convergence speed of path planning, realize the minimum path distance, and achieve very good path planning effect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_10,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-24202-2_9,Evolutionary Multi-objective Optimization for Evolving Soft Robots in Different Environments,Bio-inspired Information and Communication Technologies,10.1007/978-3-030-24202-2_9,Springer,2019-01-01,2019-07-24,"Evolutionary robotics is an approach for optimizing a robotic control system and structure based on the bio-inspired mechanism of adaptiogenesis. Conventional evolutionary robotics assigns a task and an evaluation to a virtual robot and acquires an optimal control system. In many cases, however, the robot is composed of a few rigid primitives and the morphology imitates that of real animals, insects, and artifacts. This paper proposes a novel approach to evolutionary robotics combining morphological evolution and soft robotics to optimize the control system of a soft robot. Our method calculates the relational dynamics among morphological changes and autonomous behavior for neuro-evolution (NE) with the development of a complex soft-bodied robot and the accomplishment of multiple tasks. We develop a soft-bodied robot composed of heterogeneous materials in two stages: a development stage and a locomotion stage, and we optimize these robotic structures by combining an artificial neural network (ANN) and age-fitness pareto optimization (AFP). These body structures of the robot are determined depending on three genetic rules and some voxels for evolving the ANN. In terms of our experimental results, our approach enabled us to develop some adaptive structural robots that simultaneously acquire behavior for crawling both on the ground and underwater. Subsequently, we discovered an unintentional morphology and behavior (e.g., walking, swimming, and crawling) of the soft robot through the evolutionary process. Some of the robots have high generalization ability with the ability to crawl to any target in any direction by only learning a one-directional crawling task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24202-2_9,springer
Article,doi:10.1007/s11633-018-1139-6,A Selective Attention Guided Initiative Semantic Cognition Algorithm for Service Robot,International Journal of Automation and Computing,10.1007/s11633-018-1139-6,Springer,2018-10-01,2018-09-03,"With the development of artificial intelligence and robotics, the study on service robot has made a significant progress in recent years. Service robot is required to perceive users and environment in unstructured domestic environment. Based on the perception, service robot should be capable of understanding the situation and discover service task. So robot can assist humans for home service or health care more accurately and with initiative. Human can focus on the salient things from the mass observation information. Humans are capable of utilizing semantic knowledge to make some plans based on their understanding of the environment. Through intelligent space platform, we are trying to apply this process to service robot. A selective attention guided initiatively semantic cognition algorithm in intelligent space is proposed in this paper. It is specifically designed to provide robots with the cognition needed for performing service tasks. At first, an attention selection model is built based on saliency computing and key area. The area which is highly relevant to service task could be located and referred as focus of attention (FOA). Second, a recognition algorithm for FOA is proposed based on a neural network. Some common objects and user behavior are recognized in this step. At last, a unified semantic knowledge base and corresponding reasoning engine is proposed using recognition result. Related experiments in a real life scenario demonstrated that our approach is able to mimic the recognition process in humans, make robots understand the environment and discover service task based on its own cognition. In this way, service robots can act smarter and achieve better service efficiency in their daily work.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s11633-018-1139-6,springer
Article,doi:10.1007/s11277-018-5247-y,A Minimal Dataset Construction Method Based on Similar Training for Capture Position Recognition of Space Robot,Wireless Personal Communications,10.1007/s11277-018-5247-y,Springer,2018-09-01,2018-01-13,"Recognizing capture position for non-cooperative targets is an important component of on-orbit service. Traditional machine learning works could not satisfy the requirements of space mission, which demands universality, accuracy and real-time performance. To meet those requirements, an innovative job based on deep learning called Faster Region-based Convolutional Neural Network (Faster RCNN) is introduced for space robot capture position recognizing. Based on the principle of similar training, a minimal dataset construction trick is proposed in order to solve the problem of fewer training samples in space environment. Firstly, the Deep Neural Network is pre-trained through ImageNet training set. Then, using the trained weights as the initial weight of the network, the network is fine-tuned by 1000 training samples in space environment. Finally, a simulation experiment is designed, and the experimental results indicate that the similar training principle can solve the problem of capture position recognition of non-cooperative targets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11277-018-5247-y,springer
Article,doi:10.1038/s41586-018-0307-8,Controlling an organic synthesis robot with machine learning to search for new reactivity,Nature,10.1038/s41586-018-0307-8,Nature,2018-07-19,2018-07-18,"A robot instructed by a machine learning algorithm and coupled with real-time spectroscopic systems provides fast and accurate reaction outcome predictions and reactivity assessments, leading to the discovery of new reactions. The discovery of chemical reactions is an inherently unpredictable and time-consuming process^ 1 . An attractive alternative is to predict reactivity, although relevant approaches, such as computer-aided reaction design, are still in their infancy^ 2 . Reaction prediction based on high-level quantum chemical methods is complex^ 3 , even for simple molecules. Although machine learning is powerful for data analysis^ 4 , 5 , its applications in chemistry are still being developed^ 6 . Inspired by strategies based on chemists’ intuition^ 7 , we propose that a reaction system controlled by a machine learning algorithm may be able to explore the space of chemical reactions quickly, especially if trained by an expert^ 8 . Here we present an organic synthesis robot that can perform chemical reactions and analysis faster than they can be performed manually, as well as predict the reactivity of possible reagent combinations after conducting a small number of experiments, thus effectively navigating chemical reaction space. By using machine learning for decision making, enabled by binary encoding of the chemical inputs, the reactions can be assessed in real time using nuclear magnetic resonance and infrared spectroscopy. The machine learning system was able to predict the reactivity of about 1,000 reaction combinations with accuracy greater than 80 per cent after considering the outcomes of slightly over 10 per cent of the dataset. This approach was also used to calculate the reactivity of published datasets. Further, by using real-time data from our robot, these predictions were followed up manually by a chemist, leading to the discovery of four reactions.",https://www.nature.com/articles/s41586-018-0307-8,springer
Article,doi:10.1007/s42235-018-0026-8,Multi-Layered CPG for Adaptive Walking of Quadruped Robots,Journal of Bionic Engineering,10.1007/s42235-018-0026-8,Springer,2018-03-01,2018-03-23,"This work concerns biped adaptive walking control on slope terrains with online trajectory generation. In terms of the lack of satisfactory performances of the traditional simplified single-layered Central Pattern Generator (CPG) model in engineering applications where robots face unknown environments and access feedback, this paper presents a Multi-Layered CPG (ML-CPG) model based on a half-center CPG model. The proposed ML-CPG model is used as the underlying low-level controller for a quadruped robot to generate adaptive walking patterns. Rhythm-generation and pattern formation interneurons are modeled to promptly generate motion rhythm and patterns for motion sequence control, while motoneurons are modeled to control the output strength of the joint in real time according to feedback. Referring to the motion control mechanisms of animals, a control structure is built for a quadruped robot. Multi-sensor models abstracted from the neural reflexes of animals are involved in all the layers of neurons through various feedback paths to achieve adaptability as well as the coordinated motion control of a robot’s limbs. The simulation experiments verify the effectiveness of the presented ML-CPG and multi-layered reflexes strategy.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s42235-018-0026-8,springer
Chapter,doi:10.1007/978-3-319-73008-0_43,Distributed Convolutional Neural Networks for Human Activity Recognition in Wearable Robotics,Distributed Autonomous Robotic Systems,10.1007/978-3-319-73008-0_43,Springer,2018-01-01,2018-03-14,"We investigate Hughes, Dana distributing convolutional Correll, Nikolaus neural networks (CNNs) for human activity recognition across computing nodes collocated with sensors at specific regions (body, arms and legs) on the wearer. We compare four CNN architectures. A distributed CNN is implemented on a network of Intel Edison nodes, demonstrating the capability of performing real-time classification. Two use a centralized, monolithic approach, and two are distributed across a number of computing nodes. While the accuracy of the distributed approaches are slightly worse than those of the monolithic CNNs, exploiting the hierarchy of the problem turns out to require much less memory — and therefore computation — than the monolithic CNNs, and only modest communication rates between nodes in the model, making the approach viable for a wide range of distributed systems ranging from wearable robots to multi-robot swarms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-73008-0_43,springer
Chapter ConferencePaper,doi:10.1007/978-981-10-4585-1_19,Sound Localization in 3-D Space Using Kalman Filter and Neural Network for Human like Robotics,Networking Communication and Data Knowledge Engineering,10.1007/978-981-10-4585-1_19,Springer,2018-01-01,2017-11-14,"Sound Localization is the process of identifying direction (with distance) and location of the source from which the sound is detected. It is one of the important functions of human brain. In brain sound localization is done through the neurons present in it. The sound signals from the outside world are come inside the brain through the ear. In this paper, the process of Sound Localization activity performed by human brain that incorporates realistic neuron models is discussed and the accurate position of the sound sources by using the Kalman filter and neural network is examined. The results demonstrate that finding position in 3D is more accurate as compared in 2D as its average error gets reduced. This work can be used to detect the location of the sound sources in three dimensions and can be also implemented in robots and cochlear implants for treating hearing loss.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-4585-1_19,springer
Article,doi:10.1007/s00521-016-2536-9,STMVO: biologically inspired monocular visual odometry,Neural Computing and Applications,10.1007/s00521-016-2536-9,Springer,2018-03-01,2016-08-20,"Visual odometry (VO) is a fundamental and challenging problem in both the computer vision community and the robotics community. VO refers the process of recovering the relative movements of a camera by analyzing the associated image sequence. While VO is generally formulated as descriptors-based feature tracking with outliers rejection and global optimization, these algorithms are not only computationally expensive but also lack robustness. In the paper, a biologically inspired solution to the monocular visual odometry problem was presented, which was named as shunting short-term memory monocular visual odometry. The proposed method is simple and concise in both concept and implementation. To be more specific, it utilizes the shunting short-term memory to represent the key frames and the latest observations and also to adapt to uncertainties and ambiguities. And scan matching scheme is adopted to search the movement that best explained the difference between the latest observation and the key frame. Because of the dynamic properties of the neural network, the proposed method requires neither explicit extraction of features and descriptors, nor outliers detection and bundle optimization. Theoretical analysis in the paper showed that the proposed method has Lyapunov stability and constant computational complexity. The proposed method was also compared with the classical monocular VO algorithm in real indoor environments, and the experimental results proved that the proposed method outperforms the classical method on both effectiveness and robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-016-2536-9,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-1702-6_26,Fall Detection System Based on Mobile Robot,Image and Graphics Technologies and Applications,10.1007/978-981-13-1702-6_26,Springer,2018-01-01,2018-08-12,"This paper proposed an accurate fall detection algorithm based on the feature of whole human body. The feature is extracted from convolutional neural network. The implementation of algorithm is integrated into a hardware system based on a visual mobile robot platform. To ensure the robustness and flexibility of algorithm in actual situation, a set of systemic strategies was applied on mobile robot. Finally, sufficient experiments on public dataset were conduct on our algorithm. Moreover, in a real indoor scene, experiment results proved the efficiency and precision of the designed fall detection system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-1702-6_26,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_8,Toward Real-Time Decentralized Reinforcement Learning Using Finite Support Basis Functions,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_8,Springer,2018-01-01,2018-09-07,"This paper addresses the design and implementation of complex Reinforcement Learning (RL) behaviors where multi-dimensional action spaces are involved, as well as the need to execute the behaviors in real-time using robotic platforms with limited computational resources and training times. For this purpose, we propose the use of decentralized RL, in combination with finite support basis functions as alternatives to Gaussian RBF, in order to alleviate the effects of the curse of dimensionality on the action and state spaces respectively, and to reduce the computation time. As testbed, a RL based controller for the in-walk kick in NAO robots, a challenging and critical problem for soccer robotics, is used. The reported experiments show empirically that our solution saves up to 99.94% of execution time and 98.82% of memory consumption during execution, without diminishing performance compared to classical approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-04497-8_24,An Adaptive Robotic Assistance Platform for Neurorehabilitation Therapy of Upper Limb,Advances in Computational Intelligence,10.1007/978-3-030-04497-8_24,Springer,2018-01-01,2019-01-03,"There are many human-robot physical interaction methods for physical therapy in patients of upper limbs disabilities. The use of haptic devices for this purpose is abundant, as are the different proposals for motion control in haptic guidance, as part of a clinical protocol with the patient in the loop. A conclusive result of these interaction platforms is the need to modify elements of the control strategy and the motion planning, this for each patient. In this paper, we propose a new approach to the control of human-robot physical interaction systems. To guarantee the bilateral energy flow between the robotic system and the patient under stable conditions and, without modifying the interaction platform; we propose an adaptive control structure, free of the dynamic model. The control scheme is called PID Wavenet, and identifies the dynamics using a radial basis neural network with daughter RASP1 wavelets activation function; its output is in cascaded with an infinite impulse response (IIR) filter toprune irrelevant signals and nodes as well as to recover a canonical form. Then, online adaptive of a discrete PID regulator is proposed, whose closed-loop guarantees global regulation for nonlinear dynamical plants, in our case a haptic device with the human in the loop. Effectiveness of the proposed method is verified by the real-time experiments on a Geomagic Touch haptic interface.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04497-8_24,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-70407-4_39,Making Sense of Indoor Spaces Using Semantic Web Mining and Situated Robot Perception,The Semantic Web: ESWC 2017 Satellite Events,10.1007/978-3-319-70407-4_39,Springer,2017-01-01,2017-11-08,"Intelligent Autonomous Robots deployed in human environments must have understanding of the wide range of possible semantic identities associated with the spaces they inhabit – kitchens, living rooms, bathrooms, offices, garages, etc. We believe robots should learn this information through their own exploration and situated perception in order to uncover and exploit structure in their environments – structure that may not be apparent to human engineers, or that may emerge over time during a deployment. In this work, we combine semantic web-mining and situated robot perception to develop a system capable of assigning semantic categories to regions of space. This is accomplished by looking at web-mined relationships between room categories and objects identified by a Convolutional Neural Network trained on 1000 categories. Evaluated on real-world data, we show that our system exhibits several conceptual and technical advantages over similar systems, and uncovers semantic structure in the environment overlooked by ground-truth annotators.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70407-4_39,springer
Article,doi:10.1007/s11023-017-9417-6,Reframing AI Discourse,Minds and Machines,10.1007/s11023-017-9417-6,Springer,2017-12-01,2017-01-09,"A critically important ethical issue facing the AI research community is how AI research and AI products can be responsibly conceptualised and presented to the public. A good deal of fear and concern about uncontrollable AI is now being displayed in public discourse. Public understanding of AI is being shaped in a way that may ultimately impede AI research. The public discourse as well as discourse among AI researchers leads to at least two problems: a confusion about the notion of ‘autonomy’ that induces people to attribute to machines something comparable to human autonomy, and a ‘sociotechnical blindness’ that hides the essential role played by humans at every stage of the design and deployment of an AI system. Here our purpose is to develop and use a language with the aim to reframe the discourse in AI and shed light on the real issues in the discipline.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-017-9417-6,springer
Article,doi:10.1007/s12204-017-1881-x,A real-time collision-free path planning of a rust removal robot using an improved neural network,Journal of Shanghai Jiaotong University (Science),10.1007/s12204-017-1881-x,Springer,2017-10-01,2017-09-28,"In this paper, a real-time collision-free path planning of the rust removal robot in a ship environment is proposed, which is based on an improved biologically inspired neural network algorithm. This improved algorithm is based on the biologically inspired neural network and modified with obstacle detection sensors and kinematic state templates, and is implemented in a ship rust removal robot planning system for dynamic trajectory generation. The real-time optimal trajectory is generated by the biologically inspired neural network, and the moving obstacle detection process of a ship robot working on the wall is simulated with the obstacle detection sensors models. The local real-time trajectory can be re-planned by the updated local map information, where the obstacle detection sensors are used to inspect partial environment information and update the robot nearby information in real time in the original neural network algorithm. At the same time, the method of the kinematic state templates matching and searching is used to solve the pipes’ influence of the rust removal robot climbing on the wall, which can not only provide a smooth path, but also can judge the motion direction and turning angle of the robot. Comparison of the proposed approach with the simulation shows that the improved algorithm is capable of planning a real-time collision-free path with achieving the local environmental information and judging the rust removal robot’s motion direction and turning angle. This proposed algorithm can be good used in the ship rust removal robot.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12204-017-1881-x,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-63537-8_31,A Scalable Neuro-inspired Robot Controller Integrating a Machine Learning Algorithm and a Spiking Cerebellar-Like Network,Biomimetic and Biohybrid Systems,10.1007/978-3-319-63537-8_31,Springer,2017-01-01,2017-07-16,"Combining Fable robot, a modular robot, with a neuroinspired controller, we present the proof of principle of a system that can scale to several neurally controlled compliant modules. The motor control and learning of a robot module are carried out by a Unit Learning Machine (ULM) that embeds the Locally Weighted Projection Regression algorithm (LWPR) and a spiking cerebellar-like microcircuit. The LWPR guarantees both an optimized representation of the input space and the learning of the dynamic internal model (IM) of the robot. However, the cerebellar-like sub-circuit integrates LWPR input-driven contributions to deliver accurate corrective commands to the global IM. This article extends the earlier work by including the Deep Cerebellar Nuclei (DCN) and by reproducing the Purkinje and the DCN layers using a spiking neural network (SNN) implemented on the neuromorphic SpiNNaker platform. The performance and robustness outcomes from the real robot tests are promising for neural control scalability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63537-8_31,springer
Article,doi:10.1007/s12555-015-0392-5,Cyclic error correction based Q-learning for mobile robots navigation,"International Journal of Control, Automation and Systems",10.1007/s12555-015-0392-5,Springer,2017-08-01,2017-06-27,"Similar to control systems, reinforcement learning can capture notions of optimal behavior using natural interaction experience. In the context of reinforcement learning, the temporal difference error of the generated experience measures how well the learner responds to the system. Specially sequential difference of accumulated temporal difference error can indicate the learning performance. In this paper, we fully utilize the error correction in closed-loop peculiarity by mapping a representation error to the step-size component. The proposed cyclic step-size could better control how new estimates are iteratively blended together over time, and the new estimates guide the action selection process which in turn influence the value distribution. To guide more promising action decision, an ensemble action selector is proposed which incorporates the idea of ensemble wisdom of the weak. Experimental results conducted under gridworld mobile robot navigation task demonstrate the validity, capacity of fast learning and easy-plugged implementation of the derived algorithm, leading to increasing applicability to real-life problems.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12555-015-0392-5,springer
Article,doi:10.1007/s10846-017-0468-y,Survey of Model-Based Reinforcement Learning: Applications on Robotics,Journal of Intelligent & Robotic Systems,10.1007/s10846-017-0468-y,Springer,2017-05-01,2017-01-26,"Reinforcement learning is an appealing approach for allowing robots to learn new tasks. Relevant literature reveals a plethora of methods, but at the same time makes clear the lack of implementations for dealing with real life challenges. Current expectations raise the demand for adaptable robots. We argue that, by employing model-based reinforcement learning, the—now limited—adaptability characteristics of robotic systems can be expanded. Also, model-based reinforcement learning exhibits advantages that makes it more applicable to real life use-cases compared to model-free methods. Thus, in this survey, model-based methods that have been applied in robotics are covered. We categorize them based on the derivation of an optimal policy, the definition of the returns function, the type of the transition model and the learned task. Finally, we discuss the applicability of model-based reinforcement learning approaches in new applications, taking into consideration the state of the art in both algorithms and hardware.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-017-0468-y,springer
Article,doi:10.1007/s12668-016-0323-9,Neuromorphic Robot Dream,BioNanoScience,10.1007/s12668-016-0323-9,Springer,2017-03-01,2016-10-15,"In this paper, we present the next step in our approach to neurobiologically plausible implementation of emotional reactions and behaviors for real-time autonomous robotic systems. The working metaphor we use is the “day” and the “night” phases of mammalian life. During the “day’ phase” a robotic system stores the inbound information and is controlled by a light-weight rule-based system in real time. In contrast to that, during the “night phase” information that has been stored is transferred to a supercomputing system to update the realistic neural network: emotional and behavioral strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12668-016-0323-9,springer
Article,doi:10.1007/s00521-015-2107-5,Diagonal recurrent neural networks for parameters identification of terrain based on wheel–soil interaction analysis,Neural Computing and Applications,10.1007/s00521-015-2107-5,Springer,2017-04-01,2015-12-24,"Wheeled mobile robots (WMR) are often applied to travel on outdoor unstructured environment, such as loose soil or variable field terrain. Learning the knowledge of terrain has played a significant role for better mobility and stability of WMR. In this study, a diagonal recurrent neural network-based adaptive method is proposed to identify terrain parameters by the platform of a single driving wheel. According to the classical terramechanics model of wheel–soil interaction, a decoupling simplification model is developed by closed-form analytical equations. Five unknown terrain parameters are divided into two groups and included in two complex nonlinear equations. These parameters are used to compute the model outputs of force and torque of wheel–soil interaction. Dynamic back propagation algorithm is applied to update these parameters for compensating the errors between the prediction of neural network and measurable data in real time. The results of simulation show that the terrain parameters can be obtained and approximate the experimental value of terrain parameters when the predictive errors converge to zero.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-015-2107-5,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-68792-6_33,A Deep Learning Approach for Object Recognition with NAO Soccer Robots,RoboCup 2016: Robot World Cup XX,10.1007/978-3-319-68792-6_33,Springer,2017-01-01,2017-11-01,"The use of identical robots in the RoboCup Standard Platform League (SPL) made software development the key aspect to achieve good results in competitions. In particular, the visual detection process is crucial for extracting information about the environment. In this paper, we present a novel approach for object detection and classification based on Convolutional Neural Networks (CNN). The approach is designed to be used by NAO robots and is made of two stages: image region segmentation, for reducing the search space, and Deep Learning, for validation. The proposed method can be easily extended to deal with different objects and adapted to be used in other RoboCup leagues. Quantitative experiments have been conducted on a data set of annotated images captured in real conditions from NAO robots in action. The used data set is made available for the community.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68792-6_33,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-70136-3_8,Cloud-Based Knowledge Sharing in Cooperative Robot Tracking of Multiple Targets with Deep Neural Network,Neural Information Processing,10.1007/978-3-319-70136-3_8,Springer,2017-01-01,2017-10-26,"Cooperative robot tracking of multiple targets plays an important role in many realistic robot applications. In order to minimize the time during which any target is not tracked, target trading among robots at runtime is a common phenomenon. After a period of successful tracking, the robot can gain a lot of knowledge about the target details, for example, the appearance changes caused by motion and illumination. However, the accumulated knowledge is dropped simply in existing research while robots trading targets, which makes each robot has to learn the knowledge of target details from scratch. The absence of knowledge sharing heavily influences the tracking accuracy in practice. In this paper, we propose a novel approach named Cloudroid Tracking which enables knowledge sharing through the support of the back-end cloud infrastructure. Our approach adopts the deep neural network (DNN) and its online tuning mechanisms to enable the knowledge accumulation. The dynamic connection of multiple DNNs on the cloud infrastructure and multiple robots is enabled. No matter how the target changes, the robot can connect to the corresponding neural network which is responsible for a specific target. The experimental results on both open dataset and real robots show that our approach can promote the accuracy for robot tracking significantly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70136-3_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_17,Robot Localization and Orientation Detection Based on Place Cells and Head-Direction Cells,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_17,Springer,2017-01-01,2017-10-24,"Place cells and head-direction cells play important roles in animal navigation and have distinguishable firing properties in biology. Recently, a slowness principle has been argued as the fundamental learning mechanism behind these firing activities. Based on this principle, we extend previous work, which produced only a continuum of place and head-direction cells and mixtures thereof, to achieve a clean separation of two different cell types from just one exploration. Due to the unsupervised learning strategy, these firing activities do not contain explicit information of position or orientation of an agent. In order to read out these intangible activities for real robots, we propose that place cell activities can be utilized to build a self-organizing topological map of the environment and thus for robot localization. At the same time, the robot’s current orientation can be read out from the head-direction cell activities. The final experimental results demonstrate the feasibility and effectiveness of the proposed methods, which provide a basis for robot navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_17,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_2,Mixing Actual and Predicted Sensory States Based on Uncertainty Estimation for Flexible and Robust Robot Behavior,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_2,Springer,2017-01-01,2017-10-24,"In this paper, we propose a method to dynamically modulate the input state of recurrent neural networks (RNNs) so as to realize flexible and robust robot behavior. We employ the so-called stochastic continuous-time RNN (S-CTRNN), which can learn to predict the mean and variance (or uncertainty) of subsequent sensorimotor information. Our proposed method uses this estimated uncertainty to determine a mixture ratio for combining actual and predicted sensory states of network input. The method is evaluated by conducting a robot learning experiment in which a robot is required to perform a sensory-dependent task and a sensory-independent task. The sensory-dependent task requires the robot to incorporate meaningful sensory information, and the sensory-independent task requires the robot to ignore irrelevant sensory information. Experimental results demonstrate that a robot controlled by our proposed method exhibits flexible and robust behavior, which results from dynamic modulation of the network input on the basis of the estimated uncertainty of actual sensory states.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_2,springer
Article,doi:10.1007/s13218-016-0443-y,Looking Back on 20 Years of RoboCup,KI - Künstliche Intelligenz,10.1007/s13218-016-0443-y,Springer,2016-10-01,2016-07-25,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-016-0443-y,springer
Article,doi:10.1007/s13218-015-0423-7,AI and Robotics: RoboCup Evolution,KI - Künstliche Intelligenz,10.1007/s13218-015-0423-7,Springer,2016-10-01,2016-01-26,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-015-0423-7,springer
Article,doi:10.1007/s11548-015-1340-9,Erratum to: Surgical robotics beyond enhanced dexterity instrumentation: a survey of machine learning techniques and their role in intelligent and autonomous surgical actions,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-015-1340-9,Springer,2016-05-01,2016-01-11,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-015-1340-9,springer
Article,doi:10.1007/s11063-015-9435-4,Editorial: Neural Processing Letters Special Issue on “Neural Networks for Vision and Robotics” ,Neural Processing Letters,10.1007/s11063-015-9435-4,Springer,2016-04-01,2015-05-10,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-015-9435-4,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-46131-1_33,Practical Bayesian Inverse Reinforcement Learning for Robot Navigation,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-319-46131-1_33,Springer,2016-01-01,2016-09-03,"Inverse reinforcement learning (irl) provides a concise framework for learning behaviors from human demonstrations; and is highly desired in practical and difficult to specify tasks such as normative robot navigation. However, most existing irl algorithms are often ladened with practical challenges such as representation mismatch and poor scalability when deployed in real world tasks. Moreover, standard reinforcement learning (rl) representations often do not allow for incorporation of task constraints common for example in robot navigation. In this paper, we present an approach that tackles these challenges in a unified manner and delivers a learning setup that is both practical and scalable. We develop a graph-based spare representation for rl and a scalable irl algorithm based on sampled trajectories. Experimental evaluation in simulation and from a real deployment in a busy airport demonstrate the strengths of the learning setup over existing approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46131-1_33,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4899-7502-7_738-1,Robot Learning,Encyclopedia of Machine Learning and Data Mining,10.1007/978-1-4899-7502-7_738-1,Springer,2016-01-01,2016-08-04,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4899-7502-7_738-1,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-47437-3_28,Emotion in Robots Using Convolutional Neural Networks,Social Robotics,10.1007/978-3-319-47437-3_28,Springer,2016-01-01,2016-10-07,"These years, emotion recognition has been one of the hot topics in computer science and especially in Human-Robot Interaction (HRI) and Robot-Robot Interaction (RRI). By emotion (recognition and expression), robots can recognize human behavior and emotion better and can communicate in a more human way. On that point are some research for unimodal emotion system for robots, but because, in the real world, Human emotions are multimodal then multimodal systems can work better for the recognition. Yet, beside this multimodality feature of human emotion, using a flexible and reliable learning method can help robots to recognize better and makes more beneficial interaction. Deep learning showed its force in this area and here our model is a multimodal method which use 3 main traits (Facial Expression, Speech and gesture) for emotion (recognition and expression) in robots. We implemented the model for six basic emotion states and there are some other states of emotion, such as mix emotions, which are really laborious to be picked out by robots. Our experiments show that a significant improvement of identification accuracy is accomplished when we use convolutional Neural Network (CNN) and multimodal information system, from 91 % reported in the previous research [ 27 ] to 98.8 %.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-47437-3_28,springer
Article,doi:10.1007/s11063-015-9452-3,An Evolutionary Radial Basis Function Neural Network with Robust Genetic-Based Immunecomputing for Online Tracking Control of Autonomous Robots,Neural Processing Letters,10.1007/s11063-015-9452-3,Springer,2016-08-01,2015-06-25,This paper presents an evolutionary radial basis function neural network with genetic algorithm and artificial immune system (GAAIS-RBFNN) for tracking control of autonomous robots. Both the GAAIS-RBFNN computational intelligence and online tracking controller are implemented in one field-programmable gate array (FPGA) chip to cope with the optimal control problem of real-world mobile robotics. The hybrid GAAIS paradigm incorporated with Taguchi quality method is employed to determine the optimal structure of RBFNN. The control parameters of tracking controller are online tuned by minimizing the performance index using the proposed GAAIS-RBFNN to achieve trajectory tracking. Experimental results and comparative works are conducted to show the effectiveness and merit of the proposed FPGA-based GAAIS-RBFNN tracking controller using system-on-a-programmable-chip technology. This FPGA-based online hybrid GAAIS-RBFNN intelligent controller outperforms the existing bio-inspired RBFNN controllers using individual GA and AIS algorithms.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-015-9452-3,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-44778-0_40,Dynamical Linking of Positive and Negative Sentences to Goal-Oriented Robot Behavior by Hierarchical RNN,Artificial Neural Networks and Machine Learning – ICANN 2016,10.1007/978-3-319-44778-0_40,Springer,2016-01-01,2016-08-13,"Meanings of language expressions are constructed not only from words grounded in real-world matters, but also from words such as “not” that participate in the construction by working as logical operators. This study proposes a connectionist method for learning and internally representing functions that deal with both of these word groups, and grounding sentences constructed from them in corresponding behaviors just by experiencing raw sequential data of an imposed task. In the experiment, a robot implemented with a recurrent neural network is required to ground imperative positive and negative sentences given as a sequence of words in corresponding goal-oriented behavior. Analysis of the internal representations reveals that the network fulfilled the requirement by extracting XOR problems implicitly included in the target sequences and solving them by learning to represent the logical operations in its nonlinear dynamics in a self-organizing manner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44778-0_40,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-50115-4_29,EUROPtus: A Mixed-Initiative Controller for Multi-vehicle Oceanographic Field Experiments,2016 International Symposium on Experimental Robotics,10.1007/978-3-319-50115-4_29,Springer,2017-01-01,2017-03-21,"Our research concerns the mixed-initiative coordination of air and underwater vehicles interacting over inter-operated radio and underwater communication networks for novel oceanographic field studies. In such an environment, operating multiple vehicles to observe dynamic oceanographic events such as fronts, plumes, blooms and cetaceans has required that we design, implement and operate software, methods and processes which can support ephemeral and unpredictable observations (including those of moving animals) in real-world settings with substantial constraints. We articulate an approach for coordinated measurements using such platforms, which relate directly to task outcomes. We show the use and operational value of a new Artificial Intelligence (AI) based mixed-initiative system, EUROPtus , for handling multiple platforms from a recent field experiment in open waters of the mid-Atlantic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-50115-4_29,springer
Chapter,doi:10.1007/978-3-319-53327-8_14,Multiagent Approach to Control a Multisection Trunk-Type Manipulator,Smart Electromechanical Systems: The Central Nervous System,10.1007/978-3-319-53327-8_14,Springer,2017-01-01,2017-03-21,"Purpose We consider a multisection trunk type manipulator built on the basis of parallel structure mechanisms, for example, on the basis of tripods or hexapods. Control of such a manipulator is a serious problem, as, in addition to control of each section of the manipulator, it is necessary to control the entire structure. To resolve this problem we suggest using a multiagent approach, neural networks and neuro-fuzzy technologies. We introduce an automatic control system for the trunk type manipulator, as well as the functions implemented by the coordinator and agents of this system. Results We investigate the efficiency of the adaptive agent built on the basis of a neural network inverse model of the control object, as well as on the basis of the reference model of the object in the form of another multilayer neural network . Practical value The presented in the article the automatic control system for the trunk type manipulator can be used to create intelligent robotic system capable to react to changing uncertain conditions in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-53327-8_14,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-66471-2_3,Emotion Recognition System for Human-Robot Interface: Comparison of Two Approaches,Interactive Collaborative Robotics,10.1007/978-3-319-66471-2_3,Springer,2017-01-01,2017-08-11,This paper describes a system for automatic emotion recognition developed to enhance the communication capabilities of an anthropomorphic robot. Two versions of the classification algorithm are proposed and compared. The first version is based on a classic approach requiring the action unit estimation as a preliminary step to emotion recognition. The second version takes advantage of convolutional neural networks as a classifier. The designed system is capable of working in real time. The algorithms were implemented on C++ and tested on an extensive face expression database as well as in real conditions.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66471-2_3,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-46687-3_31,Learning Visually Guided Risk-Aware Reaching on a Robot Controlled by a GPU Spiking Neural Network,Neural Information Processing,10.1007/978-3-319-46687-3_31,Springer,2016-01-01,2016-09-29,"Risk-aware control is a new type of robust nonlinear stochastic controller in which state variables are represented by time-varying probability densities and the desired trajectory is replaced by a cost function that specifies both the goals of movement and the potential risks associated with deviations. Efficient implementation is possible using the theory of Stochastic Dynamic Operators (SDO), because for most physical systems the SDO operators are near-diagonal and can thus be implemented using distributed computation. I show such an implementation using 4.3 million spiking neurons simulated in real-time on a GPU. I demonstrate successful control of a commercial desktop robot for a visually-guided reaching task, and I show that the operators can be learned during repetitive practice using a recursive learning rule.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46687-3_31,springer
Article,doi:10.1007/s11063-015-9426-5,Introducing Synaptic Delays in the NEAT Algorithm to Improve Modelling in Cognitive Robotics,Neural Processing Letters,10.1007/s11063-015-9426-5,Springer,2016-04-01,2015-04-28,"This paper describes and tests an approach to improve the temporal processing capabilities of the neuroevolution of augmenting topologies (NEAT) algorithm. This algorithm is quite popular within the robotics community for the production of trained neural networks without having to determine a priori their size and topology. The main drawback of the traditional NEAT algorithm is that, even though it can implement recurrent synaptic connections, which allow it to perform some time related processing tasks, its capabilities are rather limited, especially when dealing with precise time dependent phenomena. NEAT’s ability to capture the underlying dynamics that correspond to complex time series still has a lot of room for improvement. To address this issue, the paper describes a new implementation of the NEAT algorithm that is able to generate artificial neural networks (ANNs) with trainable time delayed synapses in addition to its previous capacities. We show that this approach, called $$\uptau $$ τ -NEAT improves the behavior of the neural networks obtained when dealing with complex time related processes. Several examples are presented, both dealing with the generation of ANNs that are able to produce complex theoretical signals such as chaotic signals or real data series, as in the case of the monthly number of international airline passengers or monthly $$\hbox {CO}_{2}$$ CO 2 concentrations. In these examples, $$\uptau $$ τ -NEAT clearly improves over the traditional NEAT algorithm in these tasks. A final example of the integration of this approach within a robot cognitive mechanism is also presented, showing the clear improvements it could provide in the modeling required for many cognitive processes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-015-9426-5,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-39883-9_24,Robot Dream,Agent and Multi-Agent Systems: Technology and Applications,10.1007/978-3-319-39883-9_24,Springer,2016-01-01,2016-06-01,"In this position paper we present a novel approach to neurobiologically plausible implementation of emotional reactions and behaviors for real-time autonomous robotic systems. The working metaphor we use is the “day” and “night” phases of mammalian life. During the “day” phase a robotic system stores the inbound information and is controlled by a light-weight rule-based system in real time. In contrast to that, during the “night” phase the stored information is been transferred to the supercomputing system to update the realistic neural network: emotional and behavioral strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-39883-9_24,springer
Chapter,doi:10.1007/978-3-319-26485-1_28,The Seminal Speculation of a Precursor: Elements of Embodied Cognition and Situated AI in Alan Turing,Fundamental Issues of Artificial Intelligence,10.1007/978-3-319-26485-1_28,Springer,2016-01-01,2016-06-08,"Turing’s visionary contribution to cognitive science is not limited to the foundation of the symbolist approach to cognition and to the exploration of the connectionist approach: it additionally anticipated the germinal disclosure of the embodied approach. Even if Turing never directly dealt with the foundational speculation on the conceptual premises of embodiment, in his theoretical papers we find traces of the idea that a cognitive agent must develop a history of coupling with its natural and social environment, and that primitive bodily stimuli like pain and pleasure drive this coupling and elevate it to real learning by setting its normative preconditions. Turing did not consistently defend the centrality of embodiment, and ended up confounding or deemphasizing in various occasions the critical importance that he had himself implicitly recognized to the body. In line with the anti-representationist, radically enactive approaches to basic cognition, I believe that if Turing eventually failed to fully value the cognitive-developmental role played by the body, this was not because he proposed a computational and functionalist model of the mind, but because he tacitly assumed the content/vehicle dichotomy as a primitive of that model: in fact, he still believed that intelligence is a realized by decontextualized contents that can be detached and transmitted regardless of their mode of physical implementation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26485-1_28,springer
Article,doi:10.1007/s11760-015-0805-1,"Real-time, automatic shape-changing robot adjustment and gender classification","Signal, Image and Video Processing",10.1007/s11760-015-0805-1,Springer,2016-04-01,2015-07-31,"This paper introduces the results of novel theoretical and practical studies aimed at providing automatic and accurate real-time activation and adjustment of shape-changing robots in accord to the shape of the body of the user. The proposed method consists of scanning, classifying the instances according to gender and size, performing analysis on both the user’s body and the prospective garment, which is be virtually fitted, modelling, extracting measurements and assigning reference points on them, segmenting the 3D visual data imported from the shape-changing robot, and finally, superimposing, adopting and depicting the resulting garment model on the user’s body. The estimation process of the positions of the moving actuators for adjusting the shape-changing robots tries to determine which input values could result in the closest representation of the desired sizes and distances through devising the mathematical description of a map relating them to each other. In order to classify the data obtained by the 3D scanner, first maximum likelihood function is used for selecting one of the shape-changing robots, according to the presumed gender and size, to be activated, and subsequently, support vector machine is utilized so as to find out which shape template from the dictionary best matches the scanning instance being considered. As a use case, the proposed method is applied to the visual data obtained by scanning Fits.me’s shape-changing robots using 3D laser scanner. The methods currently used are manual, whereas the proposed method is automatic and the experimental results show that it is the accurate and reliable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11760-015-0805-1,springer
Article,doi:10.1007/s10015-015-0258-1,Reinforcement learning in dynamic environment: abstraction of state-action space utilizing properties of the robot body and environment,Artificial Life and Robotics,10.1007/s10015-015-0258-1,Springer,2016-03-01,2016-01-18,"In this paper, we address the autonomous control of a 3D snake-like robot through the use of reinforcement learning, and we apply it in a dynamic environment. In general, snake-like robots have high mobility that is realized by many degrees of freedom, and they can move over dynamically shifting environments such as rubble. However, this freedom and flexibility leads to a state explosion problem, and the complexity of the dynamic environment leads to incomplete learning by the robot. To solve these problems, we focus on the properties of the actual operating environment and the dynamics of a mechanical body. We design the body of the robot so that it can abstract small, but necessary state-action space by utilizing these properties, and we make it possible to apply reinforcement learning. To demonstrate the effectiveness of the proposed snake-like robot, we conduct experiments; from the experimental results we conclude that learning is completed within a reasonable time, and that effective behaviors for the robot to adapt itself to an unknown 3D dynamic environment were realized.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-015-0258-1,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-44781-0_5,Deep Learning for Emotion Recognition in Faces,Artificial Neural Networks and Machine Learning – ICANN 2016,10.1007/978-3-319-44781-0_5,Springer,2016-01-01,2016-08-13,"Deep Learning (DL) has shown real promise for the classification efficiency for emotion recognition problems. In this paper we present experimental results for a deeply-trained model for emotion recognition through the use of facial expression images. We explore two Convolutional Neural Network (CNN) architectures that offer automatic feature extraction and representation, followed by fully connected softmax layers to classify images into seven emotions. The first architecture explores the impact of reducing the number of deep learning layers and the second splits the input images horizontally into two streams based on eye and mouth positions. The first proposed architecture produces state of the art results with an accuracy rate of 96.93 % and the second architecture with split input produces an average accuracy rate of 86.73 %, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44781-0_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-31153-1_14,On-line Evolution of Foraging Behaviour in a Population of Real Robots,Applications of Evolutionary Computation,10.1007/978-3-319-31153-1_14,Springer,2016-01-01,2016-04-02,"This paper describes a study in evolutionary robotics conducted completely in hardware without using simulations. The experiments employ on-line evolution, where robot controllers evolve on-the-fly in the robots’ environment as the robots perform their tasks. The main issue we consider is the feasibility of tackling a non-trivial task in a realistic timeframe. In particular, we investigate whether a population of six robots can evolve foraging behaviour in one hour. The experiments demonstrate that this is possible and they also shed light on some of the important features of our evolutionary system. Further to the specific results we also advocate the system itself. It provides an example of a replicable and affordable experimental set-up for other researches to engage in research into on-line evolution in a population of real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-31153-1_14,springer
Article,doi:10.1186/1471-2202-16-S1-P169,ROS-MUSIC toolchain for spiking neural network simulations in a robotic environment,BMC Neuroscience,10.1186/1471-2202-16-S1-P169,BioMed Central,2015-12-18,2015-12-18,,https://www.biomedcentral.com/openurl?doi=10.1186/1471-2202-16-S1-P169,springer
Article,doi:10.1186/1471-2202-16-S1-P104,Spiking neural network configuration designed for switching between basic forms of movement in a biped robot,BMC Neuroscience,10.1186/1471-2202-16-S1-P104,BioMed Central,2015-12-18,2015-12-18,,https://www.biomedcentral.com/openurl?doi=10.1186/1471-2202-16-S1-P104,springer
Article,doi:10.1186/2050-5736-2-S1-A25,Robotics and machine learning approaches to improve robustness of USgFUS: FUTURA,Journal of Therapeutic Ultrasound,10.1186/2050-5736-2-S1-A25,BioMed Central,2014-12-10,2014-12-10,,https://www.biomedcentral.com/openurl?doi=10.1186/2050-5736-2-S1-A25,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-16199-0_55,"Neural Network Fusion of Color, Depth and Location for Object Instance Recognition on a Mobile Robot",Computer Vision - ECCV 2014 Workshops,10.1007/978-3-319-16199-0_55,Springer,2015-01-01,2015-03-20,"The development of mobile robots for domestic assistance requires solving problems integrating ideas from different fields of research like computer vision, robotic manipulation, localization and mapping. Semantic mapping, that is, the enrichment a map with high-level information like room and object identities, is an example of such a complex robotic task. Solving this task requires taking into account hard software and hardware constraints brought by the context of autonomous mobile robots, where short processing times and low energy consumption are mandatory. We present a light-weight scene segmentation and object instance recognition algorithm using an RGB-D camera and demonstrate it in a semantic mapping experiment. Our method uses a feed-forward neural network to fuse texture, color and depth information. Running at 3 Hz on a single laptop computer, our algorithm achieves a recognition rate of 97 % in a controlled environment, and 87 % in the adversarial conditions of a real robotic task. Our results demonstrate that state of the art recognition rates on a database does not guarantee performance in a real world experiment. We also show the benefit in these conditions of fusing several recognition decisions and data from different sources. The database we compiled for the purpose of this study is publicly available.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-16199-0_55,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-19719-7_25,Real Time Parallel Robot Direct Kinematic Problem Computation Using Neural Networks,10th International Conference on Soft Computing Models in Industrial and Environmental Applications,10.1007/978-3-319-19719-7_25,Springer,2015-01-01,2015-05-27,"The calculation of the Direct Kinematic Problem (DKP) is one of the main issues in real-world applications of Parallel Robots, as iterative procedures have to be applied to compute the pose of the robot. Being this issue critical to robot Real-Time control, in this work a methodology to use Artificial Neural Networks to approximate the DKP is proposed and a comprehensive study is carried out to demonstrate experimentally the Real-Time performance benefits of the approach in a 3PRS parallel robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19719-7_25,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-16841-8_51,Robust Camera Calibration for the MiroSot and the AndroSot Vision Systems Using Artificial Neural Networks,Robot Intelligence Technology and Applications 3,10.1007/978-3-319-16841-8_51,Springer,2015-01-01,,"The MirosSot and the AndroSot soccer robots have the ability to recognize, and navigate within, their environments without human intervention. An overhead global camera, usually at a fixed position, is used for the robot’s vision. Because of the lens distortion, images obtained from the camera do not accurately represent the robot’s environment. The distortions affect the coordinates. A technique to calibrate the camera is required to transform the skewed coordinates of the objects in the image to the physical coordinates, which define their real-world position. In this study, a method is proposed for camera calibration using an artificial neural network (ANN) in a two-step process. First, ANN was used to select the camera height and the lens focal lengths for high accuracy. Second, ANN was used to map a coordinate transformation from the camera coordinates to the physical coordinates. During the learning process, the weight of each node in the ANN model changed until the best architecture is reached. The experiments thus resulted in an optimum ANN architecture of 2×4×25×2. The accuracy and efficiency of the camera calibration method were obtained by relearning using the ANN whenever changes to the environmental occurred. Relearning was done using the new input data set for each respective environmental change. Based on our experiments, the average transformation error of the calibration method, using many types of camera, camera positions, camera heights, lens sizes, and focal lengths, was 0.18283 cm.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-16841-8_51,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-15847-1_7,Hive Collective Intelligence for Cloud Robotics: A Hybrid Distributed Robotic Controller Design for Learning and Adaptation,"Progress in Automation, Robotics and Measuring Techniques",10.1007/978-3-319-15847-1_7,Springer,2015-01-01,,"The recent advent of Cloud Computing, inevitably gave rise to Cloud Robotics. Whilst the field is arguably still in its infancy, great promise is shown regarding the problem of limited computational power in Robotics. This is the most evident advantage of Cloud Robotics, but, other much more significant yet subtle advantages can now be identified. Moving away from traditional Robotics, and approaching Cloud Robotics through the prism of distributed systems or Swarm Intelligence offers quite an interesting composure; physical robots deployed across different areas, may delegate tasks to higher intelligence agents residing in the cloud. This design has certain distinct attributes, similar with the organisation of a Hive or bee colony. Such a parallelism is crucial for the foundations set hereinafter, as they express through the hive design, a new scheme of distributed robotic architectures. Delegation of agent intelligence, from the physical robot swarms to the cloud controllers, creates a unique type of Hive Intelligence, where the controllers residing in the cloud, may act as the brain of a ubiquitous group of robots, whilst the robots themselves act as proxies for the Hive Intelligence. The sensors of the hive system providing the input and output are the robots, yet the information processing may take place collectively, individually or on a central hub, thus offering the advantages of a hybrid swarm and cloud controller. The realisation that radical robotic architectures can be created and implemented with current Artificial Intelligence models, raises interesting questions, such as if robots belonging to a hive, can perform tasks and procedures better or faster, and if can they learn through their interactions, and hence become more adaptive and intelligent.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-15847-1_7,springer
Chapter,doi:10.1007/978-3-319-13407-9_21,Hand Gesture Recognition System Based in Computer Vision and Machine Learning,Developments in Medical Image Processing and Computational Vision,10.1007/978-3-319-13407-9_21,Springer,2015-01-01,2015-04-08,"Hand gesture recognition is a natural way of human computer interaction and an area of very active research in computer vision and machine learning. This is an area with many different possible applications, giving users a simpler and more natural way to communicate with robots/systems interfaces, without the need for extra devices. So, the primary goal of gesture recognition research applied to Human-Computer Interaction (HCI) is to create systems, which can identify specific human gestures and use them to convey information or controlling devices. For that, vision-based hand gesture interfaces require fast and extremely robust hand detection, and gesture recognition in real time. This paper presents a solution, generic enough, with the help of machine learning algorithms, allowing its application in a wide range of human-computer interfaces, for real-time gesture recognition. Experiments carried out showed that the system was able to achieve an accuracy of 99.4 % in terms of hand posture recognition and an average accuracy of 93.72 % in terms of dynamic gesture recognition. To validate the proposed framework, two applications were implemented. The first one is a real-time system able to help a robotic soccer referee judge a game in real time. The prototype combines a vision-based hand gesture recognition system with a formal language definition, the Referee CommLang , into what is called the Referee Command Language Interface System (ReCLIS). The second one is a real-time system able to interpret the Portuguese Sign Language. Sign languages are not standard and universal and the grammars differ from country to country. Although the implemented prototype was only trained to recognize the vowels, it is easily extended to recognize the rest of the alphabet, being a solid foundation for the development of any vision-based sign language recognition user interface system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-13407-9_21,springer
Article,doi:10.1134/S2079059715060179,Analysis of the cognitive properties of neural systems based on biofeedback,Russian Journal of Genetics: Applied Research,10.1134/S2079059715060179,Springer,2015-11-01,2015-12-17,"Problems of cognitive system reengineering, i.e., the development of devices with cognitive properties on the basis of their biological prototypes, cannot be solved without understanding the basic features of the architecture of biological systems, information properties, and molecular organization of the primitive units forming the architecture: nerve cells. The construction of learning models makes it possible to study the activity of individual cells, not only in terms of behavioral responses to natural stimuli but also in experiments on isolated preparations with excitation of peripheral bodies and isolated cell structures. The software-tool complex NeuroFeedBack was developed; it includes a system of living neurons and a neurocomputer interface feedback. The complex provides the reception and processing of input signals from neurons, their visualization and storage, as well as the generation of output reinforcing stimuli applied to the neurons. Analysis of the functional activity of neurons of the right parietal ganglion of the Lymnaea stagnalis mollusk was performed with the complex in three models of reinforcement. It was shown that optimization of neural activity occurred under conditions of biofeedback, allowing the neuron to minimize the quantity of the reinforcing stimuli. The results provided grounds for the design of a hybrid robotic system in which living neural systems using a neurocomputer interface could solve navigation tasks, controlling a real-time mechanoelectronical device operating in a real environment. In the experiment, the use of the proposed programs of hybrid reinforcements allowed the robot to find a glowing light bulb and reach it in a few minutes.",http://link.springer.com/openurl/pdf?id=doi:10.1134/S2079059715060179,springer
Article,doi:10.1007/s10514-015-9459-7,Learning state representations with robotic priors,Autonomous Robots,10.1007/s10514-015-9459-7,Springer,2015-10-01,2015-07-19,"Robot learning is critically enabled by the availability of appropriate state representations. We propose a robotics-specific approach to learning such state representations. As robots accomplish tasks by interacting with the physical world, we can facilitate representation learning by considering the structure imposed by physics; this structure is reflected in the changes that occur in the world and in the way a robot can effect them. By exploiting this structure in learning, robots can obtain state representations consistent with the aspects of physics relevant to the learning task. We name this prior knowledge about the structure of interactions with the physical world robotic priors . We identify five robotic priors and explain how they can be used to learn pertinent state representations. We demonstrate the effectiveness of this approach in simulated and real robotic experiments with distracting moving objects. We show that our method extracts task-relevant state representations from high-dimensional observations, even in the presence of task-irrelevant distractions. We also show that the state representations learned by our method greatly improve generalization in reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-015-9459-7,springer
Article,doi:10.1007/s12559-014-9311-y,Towards Autonomous Robots Via an Incremental Clustering and Associative Learning Architecture,Cognitive Computation,10.1007/s12559-014-9311-y,Springer,2015-08-01,2014-11-26,"This paper presents a novel architecture for associative learning and recall of different sensor and actuator patterns. A modular design allows the inclusion of various input and output modalities. The approach is a generic one that can deal with any kind of multidimensional real-valued data. Sensory data are incrementally grouped into clusters, which represent different categories of the input data. Clusters of different sensors or actuators are associated with each other based on the co-occurrence of corresponding inputs. Upon presenting a previously learned pattern as a cue, associated patterns can be recalled. The proposed architecture has been evaluated in a practical situation in which a robot had to associate visual patterns in the form of road signs with different configurations of its arm joints. This experiment assessed how long it takes to learn stable representations of the input patterns and tested the recall performance for different durations of learning. Depending on the dimensionality of the data, stable representations require many inputs to be formed and only over time similar small clusters are combined into larger clusters. Nevertheless, sufficiently good recall can be achieved earlier when the topology is still in an immature state and similar patterns are distributed over several clusters. The proposed architecture tolerates small variations in the inputs and can generalise over the varying perceptions of specific patterns but remains sensitive to fine geometrical shapes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-014-9311-y,springer
Article,doi:10.1007/s10514-015-9432-5,Real-time WiFi localization of heterogeneous robot teams using an online random forest,Autonomous Robots,10.1007/s10514-015-9432-5,Springer,2015-08-01,2015-01-18,"In this paper we present a WiFi-based solution to the localization and mapping problem for teams of heterogeneous robots operating in unknown environments. By exploiting wireless signal strengths broadcast from access points, a robot with a large sensor payload creates a WiFi signal map that can then be shared and utilized for localization by sensor-deprived robots. In our approach, WiFi localization is cast as a classification problem. An online clustering algorithm processes incoming WiFi signals that are then incorporated into an online random forest (ORF). The algorithm’s robustness is increased by a Monte Carlo localization algorithm whose sensor model exploits the results of the ORF classification. The proposed algorithm is shown to run in real-time, allowing the robots to operate in completely unknown environments, where a priori information such as a blue-print or the access points’ location is unavailable. A comprehensive set of experiments not only compares our approach with other algorithms, but also validates the results across different scenarios covering both indoor and outdoor environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-015-9432-5,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-26561-2_1,Deep Feature-Action Processing with Mixture of Updates,Neural Information Processing,10.1007/978-3-319-26561-2_1,Springer,2015-01-01,2015-11-18,"This paper explores the possibility of combining an actor and critic in one architecture and uses a mixture of updates to train them. It describes a model for robot navigation that uses architecture similar to an actor-critic reinforcement learning architecture. It sets up the actor as a layer seconded by another layer which deduce the value function. Therefore, the effect is to have similar to a critic outcome combined with the actor in one network. The model hence can be used as the base for a truly deep reinforcement learning architecture that can be explored in the future. More importantly this work explores the results of mixing conjugate gradient update with gradient update for the mentioned architecture. The reward signal is back propagated from the critic to the actor through conjugate gradient eligibility trace for the second layer combined with gradient eligibility trace for the first layer. We show that this mixture of updates seems to work well for this model. The features layer have been deeply trained by applying a simple PCA on the whole set of images histograms acquired during the first running episode. The model is also able to adapt to a reduced features dimension autonomously. Initial experimental result on real robot shows that the agent accomplished good success rate in reaching a goal location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26561-2_1,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-19719-7_26,Reinforcement Learning in Single Robot Hose Transport Task: A Physical Proof of Concept,10th International Conference on Soft Computing Models in Industrial and Environmental Applications,10.1007/978-3-319-19719-7_26,Springer,2015-01-01,2015-05-27,"In this paper we address the physical realization of proof of concept experiments demonstrating the suitability of the controllers learned by means of Reinforcement Learning (RL) techniques to accomplish tasks involving Linked Multi-Component Robotic System (LMCRS). In this paper, we deal with the task of transporting a hose by a single robot as a prototypical example of LMCRS, which can be extended to much more complex tasks. We describe how the complete system has been designed and built, explaining its different main components: the RL controller, the communications, and finally, the monitoring system. A previously learned RL controller has been tested solving a concrete problem with a determined state space modeling and discretization step. This physical realization validates our previous published works carried out through computer simulations, giving a strong argument in favor of the suitability of RL techniques to deal with real LMCRS systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19719-7_26,springer
Article,doi:10.1007/s10489-014-0567-4,Online exploratory behavior acquisition model based on reinforcement learning,Applied Intelligence,10.1007/s10489-014-0567-4,Springer,2015-01-01,2014-07-27,"Discernment behavior is an exploratory behavior that supports object feature extraction and is a fundamental tool used by robots to orient themselves, operate objects, and establish knowledge. The main contribution of this paper is to propose an active perception model and analyzes the acquired motion patterns. In this study, we propose an active perception model in which a robot autonomously learns discernment behavior by interacting with multiple objects in its environment. During such interactions, the robot receives reinforcement signals according to the cluster distance of the observed data. In other words, we use a reinforcement learning approach to reward the successful recognition of objects. We apply our proposed model to a mobile robot simulation to observe its effectiveness. Results show that our proposed model effectively established intelligent strategies based on the relationship between object features and the robot’s configuration. In addition, we perform our experiments using real mobile robots and observe the suitability of the observed learned behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-014-0567-4,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-26555-1_4,Efficient Motor Babbling Using Variance Predictions from a Recurrent Neural Network,Neural Information Processing,10.1007/978-3-319-26555-1_4,Springer,2015-01-01,2015-12-09,"We propose an exploratory form of motor babbling that uses variance predictions from a recurrent neural network as a method to acquire the body dynamics of a robot with flexible joints. In conventional research methods, it is difficult to construct real robots because of the large number of motor babbling motions required. In motor babbling, different motions may be easy or difficult to predict. The variance is large in difficult-to-predict motions, whereas the variance is small in easy-to-predict motions. We use a Stochastic Continuous Timescale Recurrent Neural Network to predict the accuracy and variance of motions. Using the proposed method, a robot can explore motions based on variance. To evaluate the proposed method, experiments were conducted in which the robot learns crank turning and door opening/closing tasks after exploring its body dynamics. The results show that the proposed method is capable of efficient motion generation for any given motion tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26555-1_4,springer
Article,doi:10.1007/s10846-014-0050-9,From the Editor-in-Chief,Journal of Intelligent & Robotic Systems,10.1007/s10846-014-0050-9,Springer,2014-09-01,2014-04-04,,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-014-0050-9,springer
Article,doi:10.1007/s13218-013-0278-8,"AI, Robotics and the Role of ECCAI",KI - Künstliche Intelligenz,10.1007/s13218-013-0278-8,Springer,2013-11-01,2013-10-10,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-013-0278-8,springer
Article,doi:10.1007/s10676-012-9305-y,"David J. Gunkel: The machine question: critical perspectives on AI, robots, and ethics",Ethics and Information Technology,10.1007/s10676-012-9305-y,Springer,2013-09-01,2012-11-03,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-012-9305-y,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4020-8265-8_100626,Machine Learning in Robots,Encyclopedia of Sciences and Religions,10.1007/978-1-4020-8265-8_100626,Springer,2013-01-01,,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-8265-8_100626,springer
Article,doi:10.1007/s00500-013-1121-8,Neural network learning from demonstration and epipolar geometry for visual control of a nonholonomic mobile robot,Soft Computing,10.1007/s00500-013-1121-8,Springer,2014-05-01,2013-09-12,"The control of a robot system using camera information is a challenging task regarding unpredictable conditions, such as feature point mismatch and changing scene illumination. This paper presents a solution for the visual control of a nonholonomic mobile robot in demanding real world circumstances based on machine learning techniques. A novel intelligent approach for mobile robots using neural networks (NNs), learning from demonstration (LfD) framework, and epipolar geometry between two views is proposed and evaluated in a series of experiments. A direct mapping from the image space to the actuator command is conducted using two phases. In an offline phase, NN–LfD approach is employed in order to relate the feature position in the image plane with the angular velocity for lateral motion correction. An online phase refers to a switching vision based scheme between the epipole based linear velocity controller and NN–LfD based angular velocity controller, which selection depends on the feature distance from the pre-defined interest area in the image. In total, 18 architectures and 6 learning algorithms are tested in order to find optimal solution for robot control. The best training outcomes for each learning algorithms are then employed in real time so as to discover optimal NN configuration for robot orientation correction. Experiments conducted on a nonholonomic mobile robot in a structured indoor environment confirm an excellent performance with respect to the system robustness and positioning accuracy in the desired location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-013-1121-8,springer
Article,doi:10.1007/s11771-013-1601-0,Dyna-QUF: Dyna-Q based univector field navigation for autonomous mobile robots in unknown environments,Journal of Central South University,10.1007/s11771-013-1601-0,Springer,2013-05-01,2013-05-04,"A novel approach was presented to solve the navigation problem of autonomous mobile robots in unknown environments with dense obstacles based on a univector field method. In an obstacle-free environment, a robot is ensured to reach the goal position with the desired posture by following the univector field. Contrariwise, the univector field cannot guarantee that the robot will avoid obstacles in environments. In order to create an intelligent mobile robot being able to perform the obstacle avoidance task while following the univector field, Dyna-Q algorithm is developed to train the robot in learning moving directions to attain a collision-free path for its navigation. Simulations on the computer as well as experiments on the real world prove that the proposed algorithm is efficient for training the robot in reaching the goal position with the desired final orientation.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s11771-013-1601-0,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-11179-7_103,Development of a Dynamically Extendable SpiNNaker Chip Computing Module,Artificial Neural Networks and Machine Learning – ICANN 2014,10.1007/978-3-319-11179-7_103,Springer,2014-01-01,,"The SpiNNaker neural computing project has created a hardware architecture capable of scaling up to a system with more than a million embedded cores, in order to simulate more than one billion spiking neurons in biological real time. The heart of this system is the SpiNNaker chip, a multi-processor System-on-Chip with a high level of interconnectivity between its processing units. Here we present a Dynamically Extendable SpiNNaker Chip Computing Module that allows a SpiNNaker machine to be deployed on small mobile robots. A non-neural application, the simulation of the movement of a flock of birds, was developed to demonstrate the general purpose capabilities of this new platform. The developed SpiNNaker machine allows the simulation of up to one million spiking neurons in real time with a single SpiNNaker chip and is scalable up to 256 computing nodes in its current state.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-11179-7_103,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-07176-3_26,Globalised Dual Heuristic Dynamic Programming in Tracking Control of the Wheeled Mobile Robot,Artificial Intelligence and Soft Computing,10.1007/978-3-319-07176-3_26,Springer,2014-01-01,,"The paper presents an application of the Approximate Dynamic Programming algorithm in Globalised Dual Heuristic Dynamic Programming configuration in the tracking control problem of the wheeled mobile robot Pioneer 2-DX. The Globalised Dual Heuristic Dynamic Programming algorithm is realised in the form of two structures, the actor and the critic, that can be implemented in the form of any adaptive algorithm, e.g. Artificial Neural Networks. The actor generates the suboptimal control law, the critic approximates the value function and its difference with respect to the states, what is equal to evaluation of the realised control law. The discrete tracking control system is composed of the Globalised Dual Heuristic Dynamic Programming algorithm, the PD controller and the supervisory term, which structure derives from the stability analysis realised using the Lapunov stability theorem. The proposed control system works on-line and its performance was verified using the wheeled mobile robot Pioneer 2-DX.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-07176-3_26,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-38637-4_17,Interplay between Natural and Artificial Intelligence in Training Autistic Children with Robots,Natural and Artificial Models in Computation and Biology,10.1007/978-3-642-38637-4_17,Springer,2013-01-01,,"The need to understand and model human-like behavior and intelligence has been embraced by a multidisciplinary community for several decades. The success so far has been shown in solutions for a concrete task or a competence, and these solutions are seldom a truly multidisciplinary effort. In this paper we analyze the needs and the opportunities for combining artificial intelligence and bio-inspired computation within an application domain that provides a cluster of solutions instead of searching for a solution to a single task. We analyze applications of training children with autism spectrum disorder (ASD) with a humanoid robot, because it must include multidisciplinary effort and at the same time there is a clear need for better models of human-like behavior which will be tested in real life scenarios through these robots. We designed, implemented, and carried out three applied behavior analysis (ABA) based robot interventions. All interventions aim to promote self initiated social behavior in children with ASD. We found out that the standardization of the robot training scenarios and using unified robot platforms can be an enabler for integrating multiple intelligent and bio-inspired algorithms for creation of tailored, but domain specific robot skills and competencies. This approach might set a new trend to how artificial and bio-inspired robot applications develop. We suggest that social computing techniques are a pragmatic solution to creation of standardized training scenarios and therefore enable the replacement of perceivably intelligent robot behaviors with truly intelligent ones.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-38637-4_17,springer
Chapter,doi:10.1007/978-3-642-33926-4_39,"A Sociology of Intelligent, Autonomous Cothinkers and Coagents",Intelligent Autonomous Systems 12,10.1007/978-3-642-33926-4_39,Springer,2013-01-01,,"Scientific and technological progress has brought robots where machine-based cognition and cooperation abilities start to emerge; not only between robots and humans but also among multiple robots themselves. In order to technically improve performances in latter case, as well as, by analogy, to better understand how humans can interact with one another and grow communities, time as come to further, scientifically and technically develop sociology-related knowledge and ontologies. Critical theoretical bases for cognition have been built and demonstrated, both in the human and machine-based cases, providing valuable contributions in this regard. Now sociable competences are considered, allowing for incrementally binding individuals and small groups into holistic units of increasing scope. Ultimately, what is also considered here is a kind of common, meta-human, secular framework where robots and humans can best co-think and co-act. Concepts have now been complemented and validated by real size implementation and experimentation in the domain of homes, as well as industrial and public environments. This should motivate the reader to get familiar with the proposed formal, quantitative MCS framework, thereby getting better insight in judgment and better ability to quantify requirements.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-33926-4_39,springer
Article,doi:10.1007/s11370-014-0155-9,Hybrid trigonometric compound function neural networks for tracking control of a nonholonomic mobile robot,Intelligent Service Robotics,10.1007/s11370-014-0155-9,Springer,2014-10-01,2014-05-27,"The purpose of this paper is to propose a hybrid trigonometric compound function neural network (NN) to improve the NN-based tracking control performance of a nonholonomic mobile robot with nonlinear disturbances. In the mobile robot control system, two NN controllers embedded in the closed-loop control system have the simple continuous learning and rapid convergence capability without the dynamics information of the mobile robot to realize the tracking control of the mobile robot. The neuron functions of the hidden layer in the three-layer feedforward network structure consist of the compound cosine function and the compound sine function combining a cosine or a sine function with a unipolar sigmoid function. The main advantages of this NN-based mobile robot control system are better real-time control capability and control accuracy by use of the proposed NN controllers for a nonholonomic mobile robot with nonlinear disturbances. Through simulation experiments applied to the nonholonomic mobile robot with the nonlinear disturbances of dynamics uncertainty and external disturbances, the simulation results show that the proposed NN control system of a nonholonomic mobile robot has better real-time control capability and control accuracy than the compound cosine function NN control system of a nonholonomic mobile robot and then verify the effectiveness of the proposed hybrid trigonometric compound function NN controller for improving the tracking control performance of a nonholonomic mobile robot with nonlinear disturbances.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-014-0155-9,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-08201-1_16,A Multi-agent Efficient Control System for a Production Mobile Robot,Neural Networks and Artificial Intelligence,10.1007/978-3-319-08201-1_16,Springer,2014-01-01,,"This paper presents the results of the experiments of a multi-agent control architecture for the efficient control of a multi-wheeled mobile platform. Multi-agent system incorporates multiple Q-learning agents, which permits them to effectively control every wheel relative to other wheels. The learning process was divided into two steps: module positioning – where the agents learn to minimize the error of orientation and cooperative movement – where the agents learn to adjust the desired velocity in order to conform to the desired position in formation. From this decomposition every module agent will have two control policies for forward and angular velocity, respectively. The experiments were carried out with a real robot. Our results indicate the successful application of the proposed control architecture for the real production robot.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-08201-1_16,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-08864-8_15,Simulating the Emergence of Early Physical and Social Interactions : A Developmental Route through Low Level Visuomotor Learning,From Animals to Animats 13,10.1007/978-3-319-08864-8_15,Springer,2014-01-01,,"In this paper, we propose a bio-inspired and developmental neural model that allows a robot, after learning its own dynamics during a babbling phase, to gain imitative and shape recognition abilities leading to early attempts for physical and social interactions. We use a motor controller based on oscillators. During the babbling step, the robot learns to associate its motor primitives (oscillators) to the visual optical flow induced by its own arm. It also statically learn to recognize its arm by selecting moving local view (feature points) in the visual field. In real indoor experiments we demonstrate that, using the same model, early physical (reaching objects) and social (immediate imitation) interactions can emerge through visual ambiguities induced by the external visual stimuli.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-08864-8_15,springer
Chapter ConferencePaper,doi:10.1007/978-3-662-43645-5_2,Heuristically-Accelerated Reinforcement Learning: A Comparative Analysis of Performance,Towards Autonomous Robotic Systems,10.1007/978-3-662-43645-5_2,Springer,2014-01-01,2014-06-28,"This paper presents a comparative analysis of three Reinforcement Learning algorithms (Q-learning, Q( $$\lambda $$ )-learning and QS-learning) and their heuristically-accelerated variants (HAQL, HAQ( $$\lambda $$ ) and HAQS) where heuristics bias action selection, thus speeding up the learning. The experiments were performed in a simulated robot soccer environment which reproduces the conditions of a real competition league environment. The results clearly demonstrate that the use of heuristics substantially improves the performance of the learning algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-43645-5_2,springer
Article,doi:10.1007/s11370-013-0136-4,Tracking control of a nonholonomic mobile robot using compound cosine function neural networks,Intelligent Service Robotics,10.1007/s11370-013-0136-4,Springer,2013-10-01,2013-09-26,"The purpose of this paper is to propose a compound cosine function neural network with continuous learning algorithm for the velocity and orientation angle tracking control of a nonholonomic mobile robot with nonlinear disturbances. Herein, two neural network (NN) controllers embedded in the closed-loop control system have the simple continuous learning and rapid convergence capability without the dynamics information of the mobile robot to realize the adaptive control of the mobile robot. The neuron function of the hidden layer in the three-layer feed-forward network structure is on the basis of combining a cosine function with a unipolar sigmoid function. The developed neural network controllers have simple algorithm and fast learning convergence because the weight values are only adjusted between the nodes in hidden layer and the output nodes, while the weight values between the input layer and the hidden layer are one, i.e. constant, without the weight adjustment. Therefore, the main advantages of this control system are the real-time control capability and the robustness by use of the proposed neural network controllers for a nonholonomic mobile robot with nonlinear disturbances. Through simulation experiments applied to the nonholonomic mobile robot with the nonlinear disturbances which are considered as dynamics uncertainty and external disturbances, the simulation results show that the proposed NN control system of nonholonomic mobile robots has real-time control capability, better robustness and higher control precision. The compound cosine function neural network provides us with a new way to solve tracking control problems for mobile robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-013-0136-4,springer
Article,doi:10.1007/s10514-013-9328-1,DCOB: Action space for reinforcement learning of high DoF robots,Autonomous Robots,10.1007/s10514-013-9328-1,Springer,2013-05-01,2013-03-29,"Reinforcement learning (RL) for robot control is an important technology for future robots since it enables us to design a robot’s behavior using the reward function. However, RL for high degree-of-freedom robot control is still an open issue. This paper proposes a discrete action space DCOB which is generated from the basis functions (BFs) given to approximate a value function. The remarkable feature is that, by reducing the number of BFs to enable the robot to learn quickly the value function, the size of DCOB is also reduced, which improves the learning speed. In addition, a method WF-DCOB is proposed to enhance the performance, where wire-fitting is utilized to search for continuous actions around each discrete action of DCOB. We apply the proposed methods to motion learning tasks of a simulated humanoid robot and a real spider robot. The experimental results demonstrate outstanding performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-013-9328-1,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-40846-5_33,How Do You Help a Robot to Find a Place? A Supervised Learning Paradigm to Semantically Infer about Places,Hybrid Artificial Intelligent Systems,10.1007/978-3-642-40846-5_33,Springer,2013-01-01,,"In this paper a visual place recognition algorithm suitable for semantic inference is presented. It combines place and object classification attributes suitable for the recognition of congested and cluttered scenes. The place learning task is undertaken by a method capable of abstracting appearance information from the places to be memorized. The detected visual features are treated as a bag of words and quantized by a clustering algorithm to form a visual vocabulary of the explored places. Each query image is represented by a consistency histogram spread over the memorized vocabulary. Simultaneously, an object recognition approach based on Hierarchical Temporal Memory network, updates the robot’s belief of its current position exploiting the features of scattered objects within the scene. The input images which are introduced to the network undergo a saliency computation step and are subsequently thresholded based on an entropy metric for detecting multiple objects. The place and object decisions are fused by voting to infer the semantic attributes of a particular place. The efficiency of the proposed framework has been experimentally evaluated on a real dataset and proved capable of accurately recognizing multiple dissimilar places.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-40846-5_33,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-45008-2_4,Online Gait Learning for Modular Robots with Arbitrary Shapes and Sizes,Theory and Practice of Natural Computing,10.1007/978-3-642-45008-2_4,Springer,2013-01-01,,"This paper addresses a principal problem of in vivo evolution of modular multi-cellular robots. To evolve robot morphologies and controllers in real-space and real-time we need a generic learning mechanism that enables arbitrary modular shapes to obtain a suitable gait quickly after ‘birth’. In this study we investigate a reinforcement learning method and conduct simulation experiments using robot morphologies with different size and complexity. The experiments give insights into the online dynamics of gait learning, the distribution of lucky / unlucky runs and their dependence on the size and complexity of the modular robotic organisms.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-45008-2_4,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4419-1428-6_5526,Robot Reinforcement Learning,Encyclopedia of the Sciences of Learning,10.1007/978-1-4419-1428-6_5526,Springer,2012-01-01,,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4419-1428-6_5526,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4419-1428-6_4815,Machine Learning in Robots,Encyclopedia of the Sciences of Learning,10.1007/978-1-4419-1428-6_4815,Springer,2012-01-01,,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4419-1428-6_4815,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-32060-6_45,Adaptivity on the Robot Brain Architecture Level Using Reinforcement Learning,RoboCup 2011: Robot Soccer World Cup XV,10.1007/978-3-642-32060-6_45,Springer,2012-01-01,"The design and implementation of a robot brain often requires making decisions between different modules with similar functionality. Many implementations and components are easy to create or can be downloaded, but it is difficult to assess which combination of modules work well and which does not. This paper discusses a reinforcement learning mechanism where the robot is choosing between the different components using empirical feedback and optimization criteria. With the interval estimation algorithm the robot deselects poorly functioning modules and retains only the best ones. A discount factor ensures that the robot keeps adapting to new circumstances in the real world. This allows the robot to adapt itself continuously on the architecture level and also allows working with large development teams creating several different implementations with similar functionalities to give the robot biggest chance to solve a task. The architecture is tested in the RoboCup@Home setting and can handle failure situations.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-32060-6_45,springer
Chapter,doi:10.1007/978-1-4614-3064-3_1,Grounding Language through Evolutionary Language Games,Language Grounding in Robots,10.1007/978-1-4614-3064-3_1,Springer,2012-01-01,"This chapter introduces a new experimental paradigm for studying issues in the grounding of language and robots, and the integration of all aspects of intelligence into a single system. The paradigm is based on designing and implementing artificial agents so that they are able to play language games about situations they perceive and act upon in the real world. The agents are not pre-programmed with an existing language but with the necessary cognitive functions to self-organize communication systems from scratch, to learn them from human language users if there are sufficiently frequent interactions, and to participate in the on-going cultural evolution of language.",2012-01-18,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4614-3064-3_1,springer
Article,doi:10.1007/s11227-011-0738-6,Towards a Multiple-Lookahead-Levels agent reinforcement-learning technique and its implementation in integrated circuits,The Journal of Supercomputing,10.1007/s11227-011-0738-6,Springer,2012-10-01,"Reinforcement learning (RL) techniques have contributed and continue to tremendously contribute to the advancement of machine learning and its many related recent applications. As it is well known, some of the main limitations of existing RL techniques are, in general, their slow convergence and their computational complexity. The contributions of this paper are two-fold: (1) First, it introduces a technique for reinforcement learning using multiple lookahead levels that grants an autonomous agent more visibility in its environment and helps it learn faster. This technique extends the Watkins’s Q-Learning algorithm by using the Multiple-Lookahead-Levels (MLL) model equation that we develop and present here. An analysis of the convergence of the MLL equation and proof of its effectiveness are performed. A method to compute the improvement rate of the agent’s learning speed between different look-ahead levels is also proposed and implemented. Here, both the time and space complexities are examined. Results show that the number of steps, required to achieve the goal, per learning path exponentially decreases with the learning path number (time). Results also show that the number of steps per learning path, to some degree, is less at any time when the number of look-ahead levels is higher (space). Furthermore, we perform the analysis of the MLL system in the time domain and prove its temporal stability using Lyapunov theory. (2) Second, based on this Lyapunov stability analysis, we subsequently, and for the first time, propose a circuit architecture for the MLL technique’s software configurable hardware system design for real-time applications.",2012-01-17,http://link.springer.com/openurl/pdf?id=doi:10.1007/s11227-011-0738-6,springer
Chapter ConferencePaper,doi:10.1007/978-1-4471-2467-2_209,Online Actor-Critic Learning for Motion Control of Non-holonomic Mobile Robot,"Electrical, Information Engineering and Mechatronics 2011",10.1007/978-1-4471-2467-2_209,Springer,2012-01-01,"This paper presents a control structure designed for non-holonomic mobile robots by an online algorithm based on policy iteration for learning the continuous-time (CT) optimal control solution with infinite horizon cost. The algorithm learns online in real-time to the solution of Hamilton–Jacobi–Bellman (HJB) equation which has been used for optimal control design. This method finds in real-time suitable approximations of both the optimal cost and control policy, while also guaranteeing closed-loop stability, which implemented as an actor/critic structure involves simultaneous continuous-time adaptation of both actor and critic neural networks (NNs). Simulation examples show the effectiveness of the new algorithm.",2012-03-13,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-2467-2_209,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-33269-2_60,Learning How to Select an Action: A Computational Model,Artificial Neural Networks and Machine Learning – ICANN 2012,10.1007/978-3-642-33269-2_60,Springer,2012-01-01,"Neurophysiological experimental results suggest that basal ganglia plays crucial role in action selection while dopamine modifies this process. There are computational models based on these experimental results for action selection. This work focuses on modification of action selection by dopamine release. In the model, a dynamical system is considered for action selection and modification of action selection process is realized by reinforcement learning. The ability of the proposed dynamical system is investigated by bifurcation analysis. Based on the results of this bifurcation analysis, the effect of reinforcement learning on action selection is discussed. The model is implemented on a mobile robot and a foraging task is realized where an exploration in an unfamiliar environment with training in the world is accomplished. Thus, this work fulfills its aim of showing the efficiency of brain-inspired computational models in controlling intelligent agents.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-33269-2_60,springer
Article,doi:10.1007/s10846-011-9627-8,Odometry-Based Viterbi Localization with Artificial Neural Networks and Laser Range Finders for Mobile Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-011-9627-8,Springer,2012-04-01,"This paper proposes an approach that solves the Robot Localization problem by using a conditional state-transition Hidden Markov Model (HMM). Through the use of Self Organized Maps (SOMs) a Tolerant Observation Model (TOM) is built, while odometer-dependent transition probabilities are used for building an Odometer-Dependent Motion Model (ODMM). By using the Viterbi Algorithm and establishing a trigger value when evaluating the state-transition updates, the presented approach can easily take care of Position Tracking (PT), Global Localization (GL) and Robot Kidnapping (RK) with an ease of implementation difficult to achieve in most of the state-of-the-art localization algorithms. Also, an optimization is presented to allow the algorithm to run in standard microprocessors in real time, without the need of huge probability gridmaps.",2011-08-26,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-011-9627-8,springer
Article,doi:10.1007/s10514-012-9315-y,Fast motion planning from experience: trajectory prediction for speeding up movement generation,Autonomous Robots,10.1007/s10514-012-9315-y,Springer,2013-01-01,"Trajectory planning and optimization is a fundamental problem in articulated robotics. Algorithms used typically for this problem compute optimal trajectories from scratch in a new situation. In effect, extensive data is accumulated containing situations together with the respective optimized trajectories—but this data is in practice hardly exploited. This article describes a novel method to learn from such data and speed up motion generation, a method we denote tajectory pediction. The main idea is to use demonstrated optimal motions to quickly predict appropriate trajectories for novel situations. These can be used to initialize and thereby drastically speed-up subsequent optimization of robotic movements. Our approach has two essential ingredients. First, to generalize from previous situations to new ones we need a situation descriptor—we construct features for such descriptors and use a sparse regularized feature selection approach to improve generalization. Second, the transfer of previously optimized trajectories to a new situation should not be made in joint angle space—we propose a more efficient task space transfer. We present extensive results in simulation to illustrate the benefits of the new method, and demonstrate it also with real robot hardware. Our experiments in diverse tasks show that we can predict good motion trajectories in new situations for which the refinement is much faster than an optimization from scratch.",2013-01-12,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-012-9315-y,springer
Article,doi:10.1007/s10846-011-9624-y,Modelling Shared Attention Through Relational Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-011-9624-y,Springer,2012-04-01,"Shared attention is a type of communication very important among human beings. It is sometimes reserved for the more complex form of communication being constituted by a sequence of four steps: mutual gaze, gaze following, imperative pointing and declarative pointing. Some approaches have been proposed in Human−Robot Interaction area to solve part of shared attention process, that is, the most of works proposed try to solve the first two steps. Models based on temporal difference, neural networks, probabilistic and reinforcement learning are methods used in several works. In this article, we are presenting a robotic architecture that provides a robot or agent, the capacity of learning mutual gaze, gaze following and declarative pointing using a robotic head interacting with a caregiver. Three learning methods have been incorporated to this architecture and a comparison of their performance has been done to find the most adequate to be used in real experiment. The learning capabilities of this architecture have been analyzed by observing the robot interacting with the human in a controlled environment. The experimental results show that the robotic head is able to produce appropriate behavior and to learn from sociable interaction.",2011-08-18,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-011-9624-y,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-28942-2_10,Decentralized Multi-tasks Distribution in Heterogeneous Robot Teams by Means of Ant Colony Optimization and Learning Automata,Hybrid Artificial Intelligent Systems,10.1007/978-3-642-28942-2_10,Springer,2012-01-01,"This paper focuses on the general problem of coordinating multiple robots. More specifically, it addresses the self-election of heterogeneous specialized tasks by autonomous robots. In this paper we focus on a specifically distributed or decentralized approach as we are particularly interested on decentralized solution where the robots themselves autonomously and in an individual manner, are responsible of selecting a particular task so that all the existing tasks are optimally distributed and executed. In this regard, we have established an experimental scenario to solve the corresponding multi-tasks distribution problem and we propose a solution using two different approaches by applying Ant Colony Optimization-based deterministic algorithms as well as Learning Automata-based probabilistic algorithms. We have evaluated the robustness of the algorithm, perturbing the number of pending loads to simulate the robot’s error in estimating the real number of pending tasks and also the dynamic generation of loads through time. The paper ends with a critical discussion of experimental results.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-28942-2_10,springer
Article,doi:10.1007/s11071-011-0027-1,ZMP based neural network inspired humanoid robot control,Nonlinear Dynamics,10.1007/s11071-011-0027-1,Springer,2012-01-01,"This paper concerns ZMP-based control that is inspired by artificial neural networks for humanoid robot walking on varying sloped surfaces. Humanoid robots are currently one of the most exciting research topics in the field of robotics, and maintaining stability while they are standing, walking or moving is a key concern. To ensure a steady and smooth walking gait of such robots, a feedforward type of neural network architecture, trained by the back-propagation algorithm, is employed. The inputs and outputs of the neural network architecture are the ZMP x and ZMP y errors of the robot, and the x , y positions of the robot, respectively. The neural network developed allows the controller to generate the desired balance of the robot positions, resulting in a steady gait for the robot as it moves around on a flat floor, and when it is descending or ascending slopes. In this paper, experiments of humanoid robot walking are carried out, in which the actual position data from a prototype robot are measured in real-time situations, and fed into a neural network inspired controller designed for stable bipedal walking. In addition, natural walking motions on the different surfaces with varying slopes are obtained and the performance of the resulting controller is shown to be satisfactory.",2011-04-07,http://link.springer.com/openurl/pdf?id=doi:10.1007/s11071-011-0027-1,springer
Article,doi:10.1007/s00146-011-0366-y,Special issue on social impact of AI: killer robots or friendly fridges,AI & SOCIETY,10.1007/s00146-011-0366-y,Springer,2011-10-11,,2011-10-11,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-011-0366-y,springer
Article,doi:10.1007/s10846-010-9433-8,From the Editor-in-Chief,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9433-8,Springer,2010-10-01,,2010-05-12,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-010-9433-8,springer
Article,doi:10.1007/s10489-010-0212-9,A neural network based retrainable framework for robust object recognition with application to mobile robotics,Applied Intelligence,10.1007/s10489-010-0212-9,Springer,2011-10-01,"In this paper, we address object recognition for a mobile robot which is deployed in a multistory building. To move to another floor, a mobile robot should recognize various objects related to an elevator, e.g., elevator control, call buttons, and LED displays. To this end, we propose a neural network based retrainable framework for object recognition, which consists of four components—preprocessing, binary classification, object identification, and outlier rejection. The binary classifier, a key component of our system, is a neural network that can be retrained, the motivation of which is to adapt to varying environments, especially with illuminations. Without incurring any extra process to prepare new training samples for retraining, they are freely obtained as a result of the outlier rejection component, being extracted on-line. To realize a practical system, we adopt a parallel architecture integrating both recognition and retraining processes for seamless object recognition, and furthermore detect and cope with the deterioration of a retrained neural network to ensure high reliability. We demonstrate the positive effect of retraining on the object recognition performance by conducting experiments over hundreds of images obtained in daytime and nighttime.",2010-02-26,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10489-010-0212-9,springer
Article,doi:10.1007/s12369-011-0113-z,Learning the Selection of Actions for an Autonomous Social Robot by Reinforcement Learning Based on Motivations,International Journal of Social Robotics,10.1007/s12369-011-0113-z,Springer,2011-11-01,"Autonomy is a prime issue on robotics field and it is closely related to decision making. Last researches on decision making for social robots are focused on biologically inspired mechanisms for taking decisions. Following this approach, we propose a motivational system for decision making, using internal (drives) and external stimuli for learning to choose the right action. Actions are selected from a finite set of skills in order to keep robot’s needs within an acceptable range. The robot uses reinforcement learning in order to calculate the suitability of every action in each state. The state of the robot is determined by the dominant motivation and its relation to the objects presents in its environment. The used reinforcement learning method exploits a new algorithm called Object Q-Learning. The proposed reduction of the state space and the new algorithm considering the collateral effects (relationship between different objects) results in a suitable algorithm to be applied to robots living in real environments. In this paper, a first implementation of the decision making system and the learning process is implemented on a social robot showing an improvement in robot’s performance. The quality of its performance will be determined by observing the evolution of the robot’s wellbeing.",2011-09-29,http://link.springer.com/openurl/pdf?id=doi:10.1007/s12369-011-0113-z,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-24769-9_27,Market-Based Dynamic Task Allocation Using Heuristically Accelerated Reinforcement Learning,Progress in Artificial Intelligence,10.1007/978-3-642-24769-9_27,Springer,2011-01-01,"This paper presents a Multi-Robot Task Allocation (MRTA) system, implemented on a RoboCup Small Size League team, where robots participate of auctions for the available roles, such as attacker or defender, and use Heuristically Accelerated Reinforcement Learning to evaluate their aptitude to perform these roles, given the situation of the team, in real-time. The performance of the task allocation mechanism is evaluated and compared in different implementation variants, and results show that the proposed MRTA system significantly increases the team performance, when compared to pre-programmed team behavior algorithms.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-24769-9_27,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-20206-3_16,Dual Adaptive Neurocontrol of Mobile Robots Using the Unscented Transform: Monte Carlo and Experimental Validation,Computational Intelligence,10.1007/978-3-642-20206-3_16,Springer,2011-01-01,"In contrast to most adaptive schemes, dual adaptive controllers do not rely on the heuristic certainty equivalence assumption, but aim to strike a balance between estimation and control at all times. Yet, few such controllers have ever been implemented and tested in practice, especially within the context of intelligent control, and to the best of our knowledge none on mobile robots. With the help of Mont Carlo simulation and real-life experiments, this article presents and validates a novel dual adaptive neurocontroller based on the unscented transform, for the dynamic control of nonholonomic wheeled mobile robots. The robot nonlinear dynamic functions are unknown to the controller and a multilayer perceptron neural network, trained via an unscented Kalman predictor, is used for their approximation in real-time. Moreover, the proposed novel dual adaptive control law employs the unscented transform to improve further the system’s performance.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-20206-3_16,springer
Article,doi:10.1007/s00521-009-0294-7,Application of neural processing paradigm in visual landmark recognition and autonomous robot navigation,Neural Computing and Applications,10.1007/s00521-009-0294-7,Springer,2010-03-01,"This article addresses the issue of visual landmark recognition in autonomous robot navigation along known routes, by intuitively exploiting the functions of the human visual system and its navigational ability. A feedforward–feedbackward architecture has been developed for recognising visual landmarks in real time. It integrates the theoretical concepts from the pre-attentive and attentive stages in the human visual system, the selective attention adaptive resonance theory neural network and its derivatives, and computational approaches towards object recognition in computer vision. The architecture mimics the pre-attentive and attentive stages in the context of object recognition, embedding neural network processing paradigm into a computational template-matching approach in computer vision. The real-time landmark recognition capability is achieved by mimicking the pre-attentive stage, where it models a selective attention mechanism for optimal computational resource allocation, focusing only on the regions of interest to address the computational restrictive nature of current computer processing power. Similarly, the recognition of visual landmarks in both clean and cluttered backgrounds is implemented in the attentive stage by developing a memory feedback modulation (MFM) mechanism that enables knowledge from the memory to interact and enhance the efficiency of earlier stages in the architecture. Furthermore, it also incorporates both top-down and bottom-up facilitatory and inhibition pathways between the memory and the earlier stages to enable the architecture to recognise a 2D landmark, which is partially occluded by adjacent features in the surroundings. The results show that the architecture is able to recognise objects in cluttered backgrounds using real-images in both indoor and outdoor scenes. Furthermore, the architecture application in autonomous robot navigation has been demonstrated through a number of real-time trials in both indoor and outdoor environments.",2009-08-20,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-009-0294-7,springer
Article,doi:10.1007/s10846-010-9462-3,Adaptive Impedance Control for Upper-Limb Rehabilitation Robot Using Evolutionary Dynamic Recurrent Fuzzy Neural Network,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9462-3,Springer,2011-06-01,"Control system implementation is one of the major difficulties in rehabilitation robot design. A newly developed adaptive impedance controller based on evolutionary dynamic fuzzy neural network (EDRFNN) is presented, where the desired impedance between robot and impaired limb can be regulated in real time according to the impaired limb’s physical recovery condition. Firstly, the impaired limb’s damping and stiffness parameters for evaluating its physical recovery condition are online estimated by using a slide average least squares (SALS)identification algorithm. Then, hybrid learning algorithms for EDRFNN impedance controller are proposed, which comprise genetic algorithm (GA), hybrid evolutionary programming (HEP) and dynamic back-propagation (BP) learning algorithm. GA and HEP are used to off-line optimize DRFNN parameters so as to get suboptimal impedance control parameters. Dynamic BP learning algorithm is further online fine-tuned based on the error gradient descent method. Moreover, the convergence of a closed loop system is proven using the discrete-type Lyapunov function to guarantee the global convergence of tracking error. Finally, simulation results show that the proposed controller provides good dynamic control performance and robustness with regard to the change of the impaired limb’s physical condition.",2010-09-15,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-010-9462-3,springer
Article,doi:10.1007/s12555-010-0120-0,Position control of a mobile inverted pendulum system using radial basis function network,"International Journal of Control, Automation and Systems",10.1007/s12555-010-0120-0,Springer,2010-02-01,This article presents the implementation of position control of a mobile inverted pendulum (MIP) system by using the radial basis function (RBF) network. The MIP has two wheels to move on the plane and to balance the pendulum. The MIP is a nonlinear system whose dynamics is nonholonomic. The goal of this study was to control the MIP to maintain the balance of the pendulum while tracking a desired position of the cart. The reference compensation technique scheme is used as a neural network control method for the MIP. The back-propagation learning algorithm of the RBF network is derived for online learning and control. The control algorithm has been embedded on a DSP 2812 board to achieve real-time control. Experimental results are conducted and show successful control performances of both balancing and tracking the desired position of the MIP.,2010-02-17,http://link.springer.com/openurl/pdf?id=doi:10.1007/s12555-010-0120-0,springer
Article,doi:10.1007/s10677-009-9186-2,"Health Care, Capabilities, and AI Assistive Technologies",Ethical Theory and Moral Practice,10.1007/s10677-009-9186-2,Springer,2010-04-01,"Scenarios involving the introduction of artificially intelligent (AI) assistive technologies in health care practices raise several ethical issues. In this paper, I discuss four objections to introducing AI assistive technologies in health care practices as replacements of human care. I analyse them as demands for felt care, good care, private care, and real care. I argue that although these objections cannot stand as good reasons for a general and a priori rejection of AI assistive technologies as such or as replacements of human care, they demand us to clarify what is at stake, to develop more comprehensive criteria for good care, and to rethink existing practices of care. In response to these challenges, I propose a (modified) capabilities approach to care and emphasize the inherent social dimension of care. I also discuss the demand for real care by introducing the ‘Care Experience Machine’ thought experiment. I conclude that if we set the standards of care too high when evaluating the introduction of AI assistive technologies in health care, we have to reject many of our existing, low-tech health care practices.",2009-07-17,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-009-9186-2,springer
Article,doi:10.1007/s11633-010-0055-1,Action control of soccer robots based on simulated human intelligence,International Journal of Automation and Computing,10.1007/s11633-010-0055-1,Springer,2010-02-01,"A multi-modal action control approach is proposed for an autonomous soccer robot when the bottom hardware is unchangeable. Different from existing methods, the proposed control approach defines actions with the principle of “perception-planning-action” inspired by human intelligence. Character extraction is used to divide the perception input into different modes. Different control modes are built by combining different control methods for the linear velocity and angular velocity. Based on production rules, the motion control is realized by connecting different perceptions to the corresponding control mode. Simulation and real experiments are conducted with the middle-sized robot Frontier-I, and the proposed method is compared with a proportional-integral-derivative (PID) control method to display its feasibility and performance. The results show that the multi-modal action control method can make robots react rapidly in a dynamic environment.",2010-02-14,http://link.springer.com/openurl/pdf?id=doi:10.1007/s11633-010-0055-1,springer
Chapter,doi:10.1007/978-3-642-04025-2_9,Skill Transfer of a Mobile Robot Obtained by Reinforcement Learning to a Different Mobile Robot,Brain-Inspired Information Technology,10.1007/978-3-642-04025-2_9,Springer,2010-01-01,"Reinforcement learning (RL) is suitable for navigation of a mobile robot. We overcame some difficulties of RL which are large computational cost and determination of parameter values for RL with the help of a genetic algorithm (GA) and method of parameter prediction based on results of GA and complexity measure. As a result of these proposals, we succeeded in navigating the real robot practically. In our previous studies, we just one kind of mobile robot, which has three wheels. Our RL method can decrease the computational cost for learning of navigation and development of mobile robots, provided the skill obtained by RL for one mobile robot can be transferred to other mobile robots. To verify the generalization capability of RL in navigation of a mobile robot, the present paper proposes to transfer the skill obtained by RL to a different kind of a mobile robot. We carried out the experiment and we succeeded in transferring the skill obtained by RL to a different mobile robot.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-04025-2_9,springer
Article,doi:10.1007/s00521-008-0181-7,"Neural networks for control, robotics and diagnostics",Neural Computing and Applications,10.1007/s00521-008-0181-7,Springer,2008-08-01,,2008-03-04,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-008-0181-7,springer
Article,doi:10.1007/s10472-008-9105-6,"Editorial: Annals of Mathematics and Artificial Intelligence special issue on multi-robot coverage, search, and exploration",Annals of Mathematics and Artificial Intelligence,10.1007/s10472-008-9105-6,Springer,2008-04-01,,2009-03-04,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10472-008-9105-6,springer
Article,doi:10.1007/s12293-009-0015-x,Fast reinforcement learning for simple physical robots,Memetic Computing,10.1007/s12293-009-0015-x,Springer,2009-09-25,"In the past few years, the field of autonomous robot has been rigorously studied and non-industrial applications of robotics are rapidly emerging. One of the most interesting aspects of this field is the development of the learning ability which enables robots to autonomously adapt to given environments without human guidance. As opposed to the conventional methods of robots’ control, where human logically design the behavior of a robot, the ability to acquire action strategies through some learning processes will not only significantly reduce the production costs of robots but also improves the applicability of robots in wider tasks and environments. However, learning algorithms usually require large calculation cost, which make them unsuitable for robots with limited resources. In this study, we propose a simple two-layered neural network that implements a novel and fast Reinforcement Learning. The proposed learning method requires significantly less calculation resources, hence is applicable to small physical robots running in the real world environments. For this study, we built several simple robots and implemented the proposed learning mechanism to them. In the experiments, to evaluate the efficacy of the proposed learning mechanism, several robots were simultaneously trained to acquire obstacle avoidance strategies in the same environment, thus, forming a dynamic environment where the learning task is substantially harder than in the case of learning in a static environment and promising result was obtained.",2009-09-25,http://link.springer.com/openurl/pdf?id=doi:10.1007/s12293-009-0015-x,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-15992-3_5,Learning and Fast Object Recognition in Robot Skill Acquisition: A New Method,Advances in Pattern Recognition,10.1007/978-3-642-15992-3_5,Springer,2010-01-01,"Invariant object recognition aims at recognising an object independently of its position, scale and orientation. This is important in robot skill acquisition during grasping operations especially when working in unstructured environments. In this paper we present an approach to aid the learning of manipulative skills on-line. We introduce and approach based on an ANN for object learning and recognition using a descriptive vector built on recurrent patterns. Experimental learning results using a fast camera are presented. Some simple parts (i.e. circular, squared and radiused-square) were used for comparing different connectionist models (Backpropagation, Perceptron and FuzzyARTMAP) and to select the appropriate model. Later during experiments, complex figures were learned using the chosen FuzzyARTMAP algorithm showing a 93.8% overall efficiency and 100% recognition rate with not so complex parts. Recognition times were lower than 1 ms, which clearly indicates the suitability of the approach to be implemented in robotic real-world operations.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-15992-3_5,springer
Chapter ConferencePaper,doi:10.1007/978-90-481-9112-3_11,An Intelligent Control System Based on Non-Invasive Man Machine Interaction,Innovations in Computing Sciences and Software Engineering,10.1007/978-90-481-9112-3_11,Springer,2010-01-01,This paper presents further development of intelligent multi-agent based e-health care system for people with movement disabilities. The research results present further development of multi-layered model of this system with integration of fuzzy neural control of speed of two wheelchair type robots working in real time by providing movement support for disabled individuals. An approach of filtering of skin conductance (SC) signals using Nadaraya-Watson kernel regression smoothing for emotion recognition of disabled individuals is described and implemented in the system by R software tool. The unsupervised clustering by self organizing maps (SOM) of data sample of physiological parameters extracted from SC signals was proposed in order to reduce teacher noise as well as to increase of speed and accuracy of learning process of multi-layer perceptron (MLP) training.,2010-05-20,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-90-481-9112-3_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-01513-7_30,Reinforcement Learning Control of a Real Mobile Robot Using Approximate Policy Iteration,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01513-7_30,Springer,2009-01-01,"Machine learning for mobile robots has attracted lots of research interests in recent years. However, there are still many challenges to apply learning techniques in real mobile robots, e.g., generalization in continuous spaces, learning efficiency and convergence, etc. In this paper, a reinforcement learning path-following control strategy based on approximate policy iteration (API) is developed for a real mobile robot. It has some advantages such as optimized control policies can be obtained without much a priori knowledge on dynamic models of mobile robot, etc. Two kinds of API-based control method, i.e., API with linear approximation and API with kernel machines, are implemented in the path following control task and the efficiency of the proposed control strategy is illustrated in the experimental studies on the real mobile robot based on the Pioneer3-AT platform. Experimental results verify that the API-based learning controller has better convergence and path following accuracy compared to conventional PD control methods. Finally, the learning control performance of the two API methods is also evaluated and compared.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-01513-7_30,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-10817-4_114,The Study on Optimal Gait for Five-Legged Robot with Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-642-10817-4_114,Springer,2009-01-01,"The research of legged robot was rapidly developed. It can be seen from recent ideas about new systems of robot movement that take ideas from nature, called biology inspired. This type of robot begins replacing wheeled robot with various functions and interesting maneuvers ability. However, designers should decide how many legs are required to realize the ideas. One of the ideas that are rarely developed is odd number of legs. This research focused on five legs robot that inspired from starfish. To realize the intelligent system in robot that does not depend on the model, this research used reinforcement learning algorithm to find the optimal gait when robot is walking. In order to achieve this goal, trial and error have been used to provide learning through an interaction between robot and environment based on a policy of reward and punishment. The algorithm is successfully implemented to get the optimal gait on a five-legged robot.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-10817-4_114,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-17248-9_14,A Software Framework for Multi Player Robot Games,Social Robotics,10.1007/978-3-642-17248-9_14,Springer,2010-01-01,"Robot games have been proposed as a way to motivate people to do physical exercises while playing. Although this area is very new, both commercial and scientific robot games have been developed mainly based on interaction with a single user and a robot. The goal of this paper is to describe a generic software framework which can be used to create games where multiple players can play against a mobile robot. The paper shows how an adaptive AI system (D2) developed for real-time strategy (RTS) computer games can be successfully applied in a robotics context using the robotics control framework Player/Stage. D2 is based on Case-Based Planning which learns from demonstration. Using the proposed framework, the paper shows how a robot learns a strategy for an implementation of a simple game.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-17248-9_14,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_123,Using Spiking Neural Networks for the Generation of Coordinated Action Sequences in Robots,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_123,Springer,2009-01-01,"SNNs have been tested as possible candidates for the implementation of robot controllers, in particular behaviour based controllers, but in most approaches their real power, related to their inherent temporal processing, and, especially, temporal pattern generating capabilities, have been ignored. This paper is concerned with showing how SNNs in their most dynamic form can be easily evolved to provide the adaptable or sensor and context modulated pattern generating capabilities required for the generation of action sequences in robots. In fact, the objective is to have a structure that can provide a sequence of actions or a periodic pattern that extends in time from a very time limited sensorial cue.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-02490-0_123,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-11876-0_39,Cooperative Multi-robot Map Merging Using Fast-SLAM,RoboCup 2009: Robot Soccer World Cup XIII,10.1007/978-3-642-11876-0_39,Springer,2010-01-01,"Multi-robot map merging is an essential task for cooperative robot navigation. In the realistic case, the robots do not know the initial positions of the others and this adds extra challenges to the problem. Some approaches search transformation parameters using the local maps and some approaches assume the robots will observe each other and use robot to robot observations. This work extends a previous work which is based on EKF-SLAM to the Fast-SLAM algorithm. The robots can observe each other and non-unique landmarks using visual sensors and merge maps by propagating uncertainty. Another contribution is the calibration of noise parameters with supervised data using the Evolutionary Strategies method. The developed algorithms are tested in both simulated and real robot experiments and the improvements and applicability of the developed methods are shown with the results.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-11876-0_39,springer
Article,doi:10.1007/s10514-009-9132-0,Learning model-free robot control by a Monte Carlo EM algorithm,Autonomous Robots,10.1007/s10514-009-9132-0,Springer,2009-08-01,"We address the problem of learning robot control by model-free reinforcement learning (RL). We adopt the probabilistic model for model-free RL of Vlassis and Toussaint (Proceedings of the international conference on machine learning, Montreal, Canada, 2009 ), and we propose a Monte Carlo EM algorithm (MCEM) for control learning that searches directly in the space of controller parameters using information obtained from randomly generated robot trajectories. MCEM is related to, and generalizes, the PoWER algorithm of Kober and Peters (Proceedings of the neural information processing systems, 2009 ). In the finite-horizon case MCEM reduces precisely to PoWER, but MCEM can also handle the discounted infinite-horizon case. An interesting result is that the infinite-horizon case can be viewed as a ‘randomized’ version of the finite-horizon case, in the sense that the length of each sampled trajectory is a random draw from an appropriately constructed geometric distribution. We provide some preliminary experiments demonstrating the effects of fixed (PoWER) vs randomized (MCEM) horizon length in two simulated and one real robot control tasks.",2009-08-11,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10514-009-9132-0,springer
Chapter,doi:10.1007/978-1-4020-8919-0_17,Behavior Emergence in Autonomous Robot Control by Means of Evolutionary Neural Networks,Advances in Computational Algorithms and Data Analysis,10.1007/978-1-4020-8919-0_17,Springer,2009-01-01,"We study the emergence of intelligent behavior of a simple mobile robot. Robot control system is realized by mechanisms based on neural networks and evolutionary algorithms. The evolutionary algorithm is responsible for the adaptation of a neural network parameters based on the robot's performance in a simulated environment. In experiments, we demonstrate the performance of evolutionary algorithm on selected problems, namely maze exploration and discrimination of walls and cylinders. A comparison of different networks architectures is presented and discussed.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4020-8919-0_17,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_15,Hybrid Design Principles and Time Constants in the Construction of Brain-Based Robotics: A Real-Time Simulator of Oscillatory Neural Networks Interacting with the Real Environment via Robotic Devices,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_15,Springer,2009-01-01,"One of most important concepts in robotics and artificial intelligence is the embodied approach, focusing on the importance of having a body that functionally connects to the external world. This setup suggests that the intelligence develops through sensorimotor skills and through situations that would actually be confronted in the environment. We support this concept and propose to further extend it to embodiment in the time domain. Nervous systems have variable processing times. The different time courses proceed in the nervous system in parallel, and individual circuits independently and cooperatively work under the constraints of temporal properties. We here propose an experimental platform of oscillatory neural networks having real-time communication with the environment through the robot’s body. The synchronization mechanism of oscillations in neural activities have the advantage of synthetic controls known in motor coordination, but we extend this to circuits for cognitive functions like episodic memory formation and decision making of the robotic behavior by using the theta phase coding mechanism. A slow oscillation, like the theta rhythm, enables behavioral temporal sequences to be compressed in sequential firings during each oscillation cycle, and this helps to represent cognitive information in episodes composed of past-present-future structures. The temporal structure is crucial for recognition of the current context and adaptability in dynamic environments, and it smoothly controls sensorimotor local circuits with faster time scales. This work represents a tiny step towards constructing the brain by focusing on the temporal structure, yet this approach may elucidate the new nature of the brain-based intelligence.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-02490-0_15,springer
Article,doi:10.1007/s10846-007-9175-4,From the Editor-in-Chief,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9175-4,Springer,2007-12-01,,2007-11-12,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-007-9175-4,springer
Article,doi:10.1007/s10958-007-0494-6,Editor’s preface,Journal of Mathematical Sciences,10.1007/s10958-007-0494-6,Springer,2007-11-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10958-007-0494-6,springer
Article,doi:10.1007/s10514-007-9025-z,Introduction to the special issue on the science behind embodied AI : The robots of the AAAI competition and exhibition,Autonomous Robots,10.1007/s10514-007-9025-z,Springer,2007-05-01,,2007-02-07,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10514-007-9025-z,springer
Article,doi:10.1007/s10489-006-0007-1,Movement prediction from real-world images using a liquid state machine,Applied Intelligence,10.1007/s10489-006-0007-1,Springer,2007-04-01,"The prediction of time series is an important task in finance, economy, object tracking, state estimation and robotics. Prediction is in general either based on a well-known mathematical description of the system behind the time series or learned from previously collected time series. In this work we introduce a novel approach to learn predictions of real world time series like object trajectories in robotics. In a sequence of experiments we evaluate whether a liquid state machine in combination with a supervised learning algorithm can be used to predict ball trajectories with input data coming from a video camera mounted on a robot participating in the RoboCup. The pre-processed video data is fed into a recurrent spiking neural network. Connections to some output neurons are trained by linear regression to predict the position of a ball in various time steps ahead. The main advantages of this approach are that due to the nonlinear projection of the input data to a high-dimensional space simple learning algorithms can be used, that the liquid state machine provides temporal memory capabilities and that this kind of computation appears biologically more plausible than conventional methods for prediction. Our results support the idea that learning with a liquid state machine is a generic powerful tool for prediction.",2006-11-13,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10489-006-0007-1,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-74024-7_5,Imitative Reinforcement Learning for Soccer Playing Robots,RoboCup 2006: Robot Soccer World Cup X,10.1007/978-3-540-74024-7_5,Springer,2007-01-01,"In this paper, we apply Reinforcement Learning (RL) to a real-world task. While complex problems have been solved by RL in simulated worlds, the costs of obtaining enough training examples often prohibits the use of plain RL in real-world scenarios. We propose three approaches to reduce training expenses for real-world RL. Firstly, we replace the random exploration of the huge search space, which plain RL uses, by guided exploration that imitates a teacher. Secondly, we use experiences not only once but store and reuse them later on when their value is easier to assess. Finally, we utilize function approximators in order to represent the experience in a way that balances between generalization and discrimination. We evaluate the performance of the combined extensions of plain RL using a humanoid robot in the RoboCup soccer domain. As we show in simulation and real-world experiments, our approach enables the robot to quickly learn fundamental soccer skills.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-74024-7_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-69162-4_99,Integrated Model for Informal Inference Based on Neural Networks,Neural Information Processing,10.1007/978-3-540-69162-4_99,Springer,2008-01-01,"Inference is one of human’s high-level functionalities and it is not easy to implement in machine. It is believed that inference is not results of single neuron’s activity. Instead, it is a complex activity generated by multiple neural networks. Unlike computer, it is more flexible and concludes differently even for the similar situations in case of human. In this paper, these characteristics are defined as “informality.” Informality in inference can be implemented using the interaction of multiple neural networks with the inclusion of internal or subjective properties. Simple inference tasks such as pattern recognition and robot control are solved based on the informal inference ideas. Especially, fuzzy integral and behavior network methods are adopted to realize that. Experimental results show that the informal inference can perform better with more flexibility compared to the previous static approaches.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-69162-4_99,springer
Chapter,doi:10.1007/978-3-540-77296-5_33,Intelligent Mobile Manipulators in Industrial Applications:Experiences and Challenges,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_33,Springer,2007-01-01,"This paper describes how industrial applications were targeted and successfully implemented by robotic manipulators that have been developed from studies in embodied artificial intelligent systems. The goal was to design mobile, flexible and self-learning manipulators that allow to perform multiple tasks with very short preparation time, a reasonable working speed and, at the same time, in a human-like manner. The advantages and disadvantages of these solutions compared to traditional industrial robot applications had to be considered continuously to concentrate on the right market segments, applications and customers. Thus, in addition to develop the appropriate requirements of real-time executions, risk analyses and usability, studies were established and implemented in collaboration with scientists, integrators and end customers. Acceptance, impacts of the revolution in personal intelligent robotics as well as challenges to overcome in the future are discussed.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-77296-5_33,springer
Chapter,doi:10.1007/978-3-540-78317-6_17,Multilayer Perceptron Adaptive Dynamic Control of Mobile Robots: Experimental Validation,European Robotics Symposium 2008,10.1007/978-3-540-78317-6_17,Springer,2008-01-01,"This paper presents experimental results acquired from the implementation of an adaptive control scheme for nonholonomic mobile robots, which was recently proposed by the same authors and tested only by simulations. The control system comprises a trajectory tracking kinematic controller, which generates the reference wheel velocities, and a cascade dynamic controller, which estimates the robot’s uncertain nonlinear dynamic functions in real-time via a multilayer perceptron neural network. In this manner precise velocity tracking is attained, even in the presence of unknown and/or time-varying dynamics. The experimental mobile robot, designed and built for the purpose of this research, is also presented in this paper.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-78317-6_17,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-68847-1_34,A Framework for Learning in Humanoid Simulated Robots,RoboCup 2007: Robot Soccer World Cup XI,10.1007/978-3-540-68847-1_34,Springer,2008-01-01,"One of the most important characteristics of intelligent activity is the ability to change behaviour according to many forms of feedback. Through learning an agent can interact with its environment to improve its performance over time. However, most of the techniques known that involves learning are time expensive, i.e., once the agent is supposed to learn over time by experimentation, the task has to be executed many times. Hence, high fidelity simulators can save a lot of time. In this context, this paper describes the framework designed to allow a team of real RoboNova-I humanoids robots to be simulated under USARSim environment. Details about the complete process of modeling and programming the robot are given, as well as the learning methodology proposed to improve robot’s performance. Due to the use of a high fidelity model, the learning algorithms can be widely explored in simulation before adapted to real robots.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-68847-1_34,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-87559-8_15,Embedded Neural Network for Swarm Learning of Physical Robots,Artificial Neural Networks - ICANN 2008,10.1007/978-3-540-87559-8_15,Springer,2008-01-01,"In this study we ran real time learning of multiple physical autonomous robots situated in a real dynamic environment. Each robot has an onboard micro controller where a simple neural network is embedded. The neural network was built with the consideration of the power and calculation resources limitation which is a general characteristic of simple robots. In the experiments, several autonomous robots were placed in one environment, where each of them was given a specific task which was expressed as the evaluation function for the robot’s neural network. The learning processes of the robots were started simultaneously from their randomized initial conditions. The presence of several robots consequently formed a dynamic environment, in which an action of one robot affected the learning process of others. We demonstrated the efficiency of the embedded learning mechanism with respect to different environmental factors.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-87559-8_15,springer
Article,doi:10.1038/npre.2007.1234.1,Semiotic Dynamics Solves the Symbol Grounding Problem,Nature Precedings,10.1038/npre.2007.1234.1,Nature,2007-10-17,"Language requires the capacity to link symbols (words, sentences) through the intermediary of internal representations to the physical world, a process known as symbol grounding. One of the biggest debates in the cognitive sciences concerns the question how human brains are able to do this. Do we need a material explanation or a system explanation? John Searle’s well known Chinese Room thought experiment, which continues to generate a vast polemic literature of arguments and counter-arguments, has argued that autonomously establishing internal representations of the world (called ’intentionality’ in philosophical parlance) is based on special properties of human neural tissue and that consequently an artificial system, such as an autonomous physical robot, can never achieve this. Here we study the Grounded Naming Game as a particular example of symbolic interaction and investigate a dynamical system that autonomously builds up and uses the semiotic networks necessary for performance in the game. We demonstrate in real experiments with physical robots that such a dynamical system indeed leads to a successful emergent communication system and hence that symbol grounding and intentionality can be explained in terms of a particular kind of system dynamics. The human brain has obviously the right mechanisms to participate in this kind of dynamics but the same dynamics can also be embodied in other types of physical systems.",2007-10-17,https://www.nature.com/articles/npre.2007.1234.1.pdf,springer
Article,doi:10.1007/BF03179036,Intelligent phase plane switching control of a pneumatic muscle robot arm with Magneto-Rheological Brake,Journal of Mechanical Science and Technology,10.1007/BF03179036,Springer,2007-08-01,"Pneumatic cylinders are one kind of low cost actuation sources which have been applied in industrial and robotics field, since they have a high power/weight ratio, a high-tension force and a long durability. To overcome the shortcomings of conventional pneumatic cylinders, a number of newer pneumatic actuators have been developed such as McKibben Muscle, Rubber Actuator and Pneumatic Artificial Muscle (PAM) Manipulators. However, some limitations still exist, such as the air compressibility and the lack of damping ability of the actuator bring the dynamic delay of the pressure response and cause the oscillatory motion. In addition, the nonlinearities in the PAM manipulator still limit the controllability. Therefore, it is not easy to realize motion with high accuracy and high speed and with respect to various external inertia loads. To overcome these problems, a novel controller which harmonizes a phase plane switching control method (PPSC) with conventional PID controller and the adaptabilities of neural network is newly proposed. In order to realize satisfactory control performance a variable damper, Magneto-Rheological Brake (MRB), is equipped to the joint of the robot. The mixture of conventional PID controller and an intelligent phase plane switching control using neural network (IPPSC) brings us a novel controller. The experiments were carried out in a robot arm, which is driven by two PAM actuators, and the effectiveness of the proposed control algorithm was demonstrated through experiments, which had proved that the stability of the manipulator can be improved greatly in a high gain control by using MRB with 1PPSC and without regard for the changes of external inertia loads.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF03179036,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-74024-7_8,Autonomous Learning of Ball Trapping in the Four-Legged Robot League,RoboCup 2006: Robot Soccer World Cup X,10.1007/978-3-540-74024-7_8,Springer,2007-01-01,"This paper describes an autonomous learning method used with real robots in order to acquire ball trapping skills in the four-legged robot league. These skills involve stopping and controlling an oncoming ball and are essential to passing a ball to each other. We first prepare some training equipment and then experiment with only one robot. The robot can use our method to acquire these necessary skills on its own, much in the same way that a human practicing against a wall can learn the proper movements and actions of soccer on his/her own. We also experiment with two robots, and our findings suggest that robots communicating between each other can learn more rapidly than those without any communication.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-74024-7_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-74913-4_30,Evolution and Learning in an Intrinsically Motivated Reinforcement Learning Robot,Advances in Artificial Life,10.1007/978-3-540-74913-4_30,Springer,2007-01-01,"Studying the role played by evolution and learning in adaptive behavior is a very important topic in artificial life research. This paper investigates the interplay between learning and evolution when agents have to solve several different tasks, as it is the case for real organisms but typically not for artificial agents. Recently, an important thread of research in machine learning and developmental robotics has begun to investigate how agents can solve different tasks by composing general skills acquired on the basis of internal motivations. This work presents a hierarchical, neural-network, actor-critic architecture designed for implementing this kind of intrinsically motivated reinforcement learning in real robots. We compare the results of several experiments in which the various components of the architecture are either trained during lifetime or evolved through a genetic algorithm. The most important results show that systems using both evolution and learning outperform systems using either one of the two, and that, among the former, systems evolving internal reinforcers for learning building-block skills have a higher evolvability than those directly evolving the related behaviors.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-74913-4_30,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-74205-0_105,Research of the Fault Diagnosis Method for the Thruster of AUV Based on Information Fusion,Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-540-74205-0_105,Springer,2007-01-01,"Aiming at the problem of thruster fault diagnosis of AUV, the motion condition model of AUV based on the improved dynamic recursive Elman neural network, and the performance model of thruster based on the Radial Basis Function network were established. And the fault fusion diagnosis method was proposed according to the overall and local fault detection. Through comparing the output value of motion condition model with the measured value of actual speed and angle, it obtained the overall fault information. Also, it obtained the direct fault information through analyzing the residual which was produced by comparing the output of the performance model with the measured value of the actual voltage and current of the each thruster. According to the decision level information fusion of two kinds of information, it realized the fault diagnosis of thrusters and analyzed the fault degree and reliability. The results of the fault-simulation experiment show that the proposed fault fusion diagnosis method for the thruster of AUV is feasible and effective.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-74205-0_105,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-71629-7_77,Neural Network Control for Visual Guidance System of Mobile Robot,Adaptive and Natural Computing Algorithms,10.1007/978-3-540-71629-7_77,Springer,2007-01-01,"This paper describes a neural network control for a visual guidance system of a mobile robot to follow a guideline. Without complicated geometric reasoning from the image of a guideline to the robot-centered representation of a bird’s eye view in conventional studies, the proposed system transfers the input of image information into the output of a steering angle directly. The neural network controller replaces the nonlinear relation of image information to a steering angle of robot on the real ground. For image information, the feature points of guideline are extracted from a camera image. In a straight and curved guideline, the driving performances by the proposed technology are measured in simulation and experimental test.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-71629-7_77,springer
Article,doi:10.1007/s10846-006-9053-5,A Multiple Models Approach for Adaptation and Learning in Mobile Robots Control,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9053-5,Springer,2006-09-01,The paper proposes a multiple models based control methodology for the solution of the tracking problem for mobile robots. The proposed method utilizes multiple models of the robot for its identification in an adaptive and learning control framework. Radial Basis Function Networks (RBFNs) are considered for the multiple models in order to exploit the non-linear approximation capabilities of the nets for modeling the kinematic behaviour of the vehicle and for reducing unmodelled tracking errors contributions. The training of the nets and the control performance analysis have been done in a real experimental setup. The experimental results are satisfactory in terms of tracking errors and computational efforts and show the improvement in the tracking performance when the proposed methodology is used for tracking tasks in dynamical uncertain environments.,2006-09-15,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-006-9053-5,springer
Chapter,doi:10.1007/0-387-28111-8_1,Genetic Programming: Theory and Practice,Genetic Programming Theory and Practice III,10.1007/0-387-28111-8_1,Springer,2006-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1007/0-387-28111-8_1,springer
Chapter ConferencePaper,doi:10.1007/3-540-29344-2_40,Spiking Neural Network for Behavior Learning of A Mobile Robot,Proceedings of the 3rd International Symposium on Autonomous Minirobots for Research and Edutainment (AMiRE 2005),10.1007/3-540-29344-2_40,Springer,2006-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-29344-2_40,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-25940-4_56,Autonomous Robot Controllers Capable of Acquiring Repertoires of Complex Skills,RoboCup 2003: Robot Soccer World Cup VII,10.1007/978-3-540-25940-4_56,Springer,2004-01-01,,"Due to the complexity and sophistication of the skills needed in real world tasks, the development of autonomous robot controllers requires an ever increasing application of learning techniques. To date, however, learning steps are mainly executed in isolation and only the learned code pieces become part of the controller. This approach has several drawbacks: the learning steps themselves are undocumented and not executable. In this paper, we extend an existing control language with constructs for specifying control tasks, process models, learning problems, exploration strategies, etc. Using these constructs, the learning problems can be represented explicitly and transparently and, as they are part of the overall program implementation, become executable. With the extended language we rationally reconstruct large parts of the action selection module of the agilo 2001 autonomous soccer robots.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-25940-4_56,springer
Article,doi:10.1007/s00521-004-0424-1,Neural networks for the EMOBOT robot control architecture,Neural Computing & Applications,10.1007/s00521-004-0424-1,Springer,2004-12-01,2004-07-30,"Within the EMOBOT approach to adaptive behaviour, the task of learning to control the behaviour is one of the most interesting challenges. Learned action selection between classically implemented control mechanisms, with respect to internal values and sensor readings, provides a way to modulate a variety of behavioural capabilities. To demonstrate the potential of the learning emotional controller, we chose a 10-5-12 MLP to implement the σ , α controller of the EMOBOT. Since no teacher vector is available for the chosen task, the neural network is trained with a reinforcement strategy. The emotion-value-dependent reinforcement signal, together with the output of the network, is the basis with which to compute an artificial teacher vector. Then, the established gradient descent method (backpropagation of error) is applied to train the neural network. First results obtained by extensive simulations show that a still unrevealed richness in behaviour can be realised when using the neural-network-based learning emotional controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-004-0424-1,springer
Chapter ConferencePaper,doi:10.1007/11840541_16,Dynamic Generation and Switching of Object Handling Behaviors by a Humanoid Robot Using a Recurrent Neural Network Model,From Animals to Animats 9,10.1007/11840541_16,Springer,2006-01-01,,"The present study describes experiments on a ball handling behavior learning that is realized by a small humanoid robot with a dynamic neural network model, the recurrent neural network with parametric bias (RNNPB). The present experiments show that after the robot learned different types of behaviors through direct human teaching, the robot was able to switch between two types of behaviors based on the ball motion dynamics. We analyzed the parametric bias (PB) space to show that each of the multiple dynamic structures acquired in the RNNPB corresponds with taught multiple behavior patterns and that the behaviors can be switched by adjusting the PB values.",http://link.springer.com/openurl/pdf?id=doi:10.1007/11840541_16,springer
Article,doi:10.1023/A:1015762314222,Guest Editorial for Special Issue on Scalable Applications of Neural Networks to Robotics,Applied Intelligence,10.1023/A:1015762314222,Springer,2002-07-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1015762314222,springer
Article,doi:10.1023/A:1017248626916,Editorial: Advanced Robot Control Techniques and Applications,Journal of Intelligent and Robotic Systems,10.1023/A:1017248626916,Springer,2000-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1017248626916,springer
Article,doi:10.1023/A:1008946111617,Artificial Neural Networks for Robot Learning—Guest Editors' Introduction,Autonomous Robots,10.1023/A:1008946111617,Springer,1999-07-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1008946111617,springer
Chapter,doi:10.1007/3-540-44597-8_37,Using a Time-Delay Actor-Critic Neural Architecture with Dopamine-Like Reinforcement Signal for Learning in Autonomous Robots,Emergent Neural Computational Architectures Based on Neuroscience,10.1007/3-540-44597-8_37,Springer,2001-01-01,"Neuroscientists have identifed a neural substrate of predic- tion and reward in experiments with primates. The so-called dopamine neurons have been shown to code an error in the temporal prediction of rewards. Similarly, artificial systems can “learn to predict#x201D; by the so-called temporal-difference (TD) methods. Based on the general resemblance between the effective reinforcement term of TD models and the response of dopamine neurons, neuroscientists have developed a TD-learning time-delay actor-critic neural model and compared its per- formance with the behavior of monkeys in the laboratory. We have used such a neural network model to learn to predict variable-delay rewards in a robot spatial choice task similar to the one used by neuroscientists with primates. Such architecture implementing TD-learning appears as a promising mechanism for robotic systems that learn from simple human teaching signals in the real world.",2001-07-24,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-44597-8_37,springer
Chapter ConferencePaper,doi:10.1007/3-540-36268-1_1,"Research Robots for Applications in AI, Teleoperation and Entertainment",Experimental Robotics VIII,10.1007/3-540-36268-1_1,Springer,2003-01-01,"Sarcos Research Corporation, and the Center for Engineering Design at the University of Utah, have long been interested in both the fundamental and the applied aspects of robots and other computationally driven machines. We have produced substantial numbers of systems that function as products for commercial applications, and as advanced research tools specifically designed for experimental use. This paper reviews various aspects of the design and control of a number of robot-like machines ranging from our first projects, the Utah Arm and the Utah/MIT Dextrous Hand, to present work on humanoid robots and the Wearable Energetically Autonomous Robot (WEAR). Our systems have been used in: entertainment, operator remotization from hazardous environments, R&D, and medicine. In addition to the robots and their subsystems, extensive work has been devoted to command systems that drive the robots. Command systems have been: play-back supervisors, teleoperation masters, and various higher level approaches based on work from the AI community. Playback interfaces have included motion-capture mechanisms that provide movement-stream information to storage systems configured for later, repeated and coordinated, operation of many robots and associated mechanisms. Play-back command systems use human commands, from an “earlier” time, to command motions that are played out, over and over, mindlessly. Teleoperation “masters”, that operate in real-time with the robot, have ranged from simple motion capture devices, to more complex force reflective exoskeletal masters. Teleoperation interfaces have been composed of complex kinematic structures designed to perform motions compatible with operator movements and are attached via appropriate soft tissue interfaces. The masters emit lower level commands (joint angles) in real-time using the natural intelligence and sensory systems of the operator. AI-based command sources, blend higher level (simple) commands, with system and existing environmental states, to make decisions for the management of the robot. As with the playback systems, AI-based systems are programmed earlier to perform later operations. In the AI case, however, adaptive intelligence and sensory capabilities reside in the robot. Our general design approach has been to begin with the definition of desired objective behaviors, rather than the use of available components with their predefined technical specifications. With the technical specifications of the components necessary to achieve the desired behaviors defined, the components are either acquired, or in most cases, developed and built. The control system, which includes the operation of feedback approaches, acting in collaboration with physical machinery, is then defined and implemented. Control is considered a function of both feedback, and the designed-in performance of the robot’s physical machinery. It has not been true that bad performance from physical machine elements can be simply compensated out via innovative control methods and faster computers. After the completion of many projects we believe that the final frontier(s) of robotics reside at both ends of the brain and brawn spectrum. Both frontiers (barriers) are related to autonomy - intelligence/computation and energy/power. Recently, energetic autonomy has become a major interest at Sarcos and projects are underway to develop appropriate fuel-based servo-actuators to satisfy that need. Our objective is to develop power systems that are capable producing high performance servo-quality actuation for extended operating times without re-energizing the system. At the other end of the spectrum, we are working in collaboration with various groups to supply physical robots capable of operation under the control of advanced AI-based systems.",2003-06-30,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-36268-1_1,springer
Chapter ConferencePaper,doi:10.1007/978-3-7908-1902-1_106,Neural Network Reactive Navigation and Control of Wheeled Mobile Robot,Neural Networks and Soft Computing,10.1007/978-3-7908-1902-1_106,Springer,2003-01-01,"A neural net real-time obstacle avoidance and control approach for mobile robot has been developed and numerically implemented. A collision-free path is calculated using an efficient neural net motion planer. The output of the navigation level is fed into a neural net tracking controller that takes into account the complete dynamics of the mobile robot. The proposed neural reactive navigation approach is based on the coordination of elementary behaviors. To avoid the convex obstacles the neural navigator fuses a ‘reaching the middle of a collision-free space’ behavior and a ‘goal-seeking’ behavior. A ‘wall-following’ behavior was conducted too, which can be applied to avoid the concave obstacles. The structure of the neural-net controller for nonholonomic mobile robot is derived using a filtered error approach. The effectiveness of the proposed method is numerically verified by a series of experiments on the emulator of wheeled mobile robot Pioneer-2DX.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-7908-1902-1_106,springer
Chapter ConferencePaper,doi:10.1007/3-540-45723-2_58,Cellular Neural Networks for Mobile Robot Vision,Bio-Inspired Applications of Connectionism,10.1007/3-540-45723-2_58,Springer,2001-01-01,"We show how Cellular Neural Networks are capable of providing the necessary signal processing to guide an autonomous mobile robot in a maze drawn on the floor. In this way, a non-trivial navigation task is obtained by very simple hardware, making real autonomous operation feasible. An autonomous line-following robot was first simulated and then implemented by simulating the CNN with a DSP.",2001-06-12,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-45723-2_58,springer
Chapter,doi:10.1007/978-3-7908-1856-7_3,Evolving ANN Controllers for Smart Mobile Robots,Future Directions for Intelligent Systems and Information Sciences,10.1007/978-3-7908-1856-7_3,Springer,2000-01-01,Abstract In this work we present an overview of the application of evolution for obtaining autonomous robot controllers. It concentrates on controllers for behavior based robots implemented through Artificial Neural Networks. Specific approaches for taking into account temporal relationships are presented as well as a methodology for the progressive implementation of controllers comprising multiple behaviors. In addition we will consider the problem of transferring simulation results to real robots and the conditions that must be met for this process to be effective. Some examples of the application of these techniques to simple problems are included.,,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-7908-1856-7_3,springer
Article,doi:10.1007/s005210050014,Neural Networks for Mobile Robot Localisation using Infra-Red Range Sensing,Neural Computing & Applications,10.1007/s005210050014,Springer,1999-05-01,"For a robot to be fully autonomous whilst mobile, it is necessary for it to be able to determine its position in its environment. Most of the work on this problem has concentrated on using geometrical techniques which are typically implemented as part of a Kalman filter cycle. This paper examines the possibility of using a neural network to assist in the task of estimating the position of the robot. This is beneficial because it does not require beacons to be placed in the environment or the use of an explicit map of the environment. It does not require knowledge of the previous estimate of the robot’s position. In this paper, Radial Basis Function networks and Multi-Layer Perceptrons are trained to estimate the functional relationship between preprocessed range sensor data and the position of the robot. This approach is assessed using both simulated and real range data.",2014-03-03,http://link.springer.com/openurl/pdf?id=doi:10.1007/s005210050014,springer
Chapter ConferencePaper,doi:10.1007/3-540-45327-X_50,Essex Wizards’99 Team Description,RoboCup-99: Robot Soccer World Cup III,10.1007/3-540-45327-X_50,Springer,2000-01-01,"This paper describes the Essex Wizards team participated in the RoboCup’99 simulator league. It is mainly concentrated on a multi-threaded implementation of simulated soccer agents to achieve real-time performance. Simulated robot agents work at three distinct phases: sensing, thinking and acting. POSIX threads are adopted to implement them concurrently. The issues of decision-making and co-operation are also addressed",2003-02-11,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-45327-X_50,springer
Chapter ConferencePaper,doi:10.1007/3-540-45105-6_59,Integration of Genetic Programming and Reinforcement Learning for Real Robots,Genetic and Evolutionary Computation — GECCO 2003,10.1007/3-540-45105-6_59,Springer,2003-01-01,"We propose an integrated technique of genetic programming (GP) and reinforcement learning (RL) that allows a real robot to execute real-time learning. Our technique does not need a precise simulator because learning is done with a real robot. Moreover, our technique makes it possible to learn optimal actions in real robots. We show the result of an experiment with a real robot AIBO and represents the result which proves proposed technique performs better than traditional Q-learning method.",2003-06-18,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-45105-6_59,springer
Chapter ConferencePaper,doi:10.1007/978-3-540-45135-8_10,Towards a Life-Long Learning Soccer Agent,RoboCup 2002: Robot Soccer World Cup VI,10.1007/978-3-540-45135-8_10,Springer,2003-01-01,"One problem in robotic soccer (and in robotics in general) is to adapt skills and the overall behavior to a changing environment and to hardware improvements. We applied hierarchical reinforcement learning in an SMDP framework learning on all levels simultaneously. As our experiments show, learning simultaneously on the skill level and on the skill selection level is advantageous since it allows for a smooth adaption to a changing environment. Furthermore, the skills we trained turn also out to be quite competitive when run on the real robotic players of the players of our CS Freiburg team.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-540-45135-8_10,springer
Article,doi:10.1023/A:1015522622034,A New Conceptual Approach to the Design of Hybrid Control Architecture for Autonomous Mobile Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1015522622034,Springer,2002-05-01,"A detailed analysis and comparison of various control architectures is presented in order to meet the challenging design requirements targeted. All the present advanced control systems have certain advantages and disadvantages compared with each other. Due to the lack of an optimal control system with desired capabilities, such a control system has been the focus of recent robotics research programs. The new approach proposed in this paper is a hybrid control system that takes the advantages of various control structure types thereby integrating them in a way that results in an overall increase in synergy. The proposed control architecture presents a new approach to the design of supervisory control system that utilizes reactive, deliberative, distributed and centralised control approaches, and uses fuzzy logic as well as modular hierarchical structure. The architecture carries out supervision, modification and execution of commands generated by the centralised command arbitration module by conducting fuzzy logic integration of activated behaviours from distributed, independent asynchronous decision making processes that takes information from the user, sensory system and task description, thus providing goal-oriented, real-time responsive and tele-operable control system architecture. The resulting control system was experimented on and it was observed that not only was the response time sufficiently short, but also it exhibited robustness, flexibility, adaptability, portability and expandability.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1015522622034,springer
Article,doi:10.1023/A:1015008417172,Reinforcement Learning Agents,Artificial Intelligence Review,10.1023/A:1015008417172,Springer,2002-05-01,"Reinforcement Learning (RL) is learning through directexperimentation. It does not assume the existence of a teacher thatprovides examples upon which learning of a task takes place. Instead, inRL experience is the only teacher. With historical roots on the study ofbiological conditioned reflexes, RL attracts the interest of Engineersand Computer Scientists because of its theoretical relevance andpotential applications in fields as diverse as Operational Research andIntelligent Robotics. Computationally, RL is intended to operate in a learning environmentcomposed by two subjects: the learner and a dynamic process. Atsuccessive time steps, the learner makes an observation of the processstate, selects an action and applies it back to the process. Its goal isto find out an action policy that controls the behavior of the dynamicprocess, guided by signals (reinforcements) that indicate how badly orwell it has been performing the required task. These signals are usuallyassociated to a dramatic condition – e.g., accomplishment of a subtask(reward) or complete failure (punishment), and the learner tries tooptimize its behavior by using a performance measure (a function of thereceived reinforcements). The crucial point is that in order to do that,the learner must evaluate the conditions (associations between observedstates and chosen actions) that led to rewards or punishments. Starting from basic concepts, this tutorial presents the many flavorsof RL algorithms, develops the corresponding mathematical tools, assesstheir practical limitations and discusses alternatives that have beenproposed for applying RL to realistic tasks.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1015008417172,springer
Article,doi:10.1023/A:1008984312527,Repeatability of Real World Training Experiments: A Case Study,Autonomous Robots,10.1023/A:1008984312527,Springer,1999-06-01,"We present a case study of reinforcement learning on a real robot that learns how to back up a trailer and discuss the lessons learned about the importance of proper experimental procedure and design. We identify areas of particular concern to the experimental robotics community at large. In particular, we address concerns pertinent to robotics simulation research, implementing learning algorithms on real robotic hardware, and the difficulties involved with transferring research between the two.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1008984312527,springer
Chapter ConferencePaper,doi:10.1007/978-1-4471-0811-5_27,A Hybrid Framework for Indoor Robot Navigation,Neural Nets WIRN VIETRI-98,10.1007/978-1-4471-0811-5_27,Springer,1999-01-01,"This paper introduces a hybrid system for modeling, learning and recognition of sequences of “states” in indoor robot navigation. States are broadly defined as local relevant situations (in the real world) in which the robot happens to be during the navigation. The hybrid is based on parallel Recurrent Neural Networks trained to perform a-posteriori state probability estimates of an underlying Hidden Markov Model given a sequence of sensory (e.g. sonar) observations. The approach is suitable for navigation and for map learning. Encouraging experiments of recognition of noisy sequences acquired by a mobile robot equipped with 16 sonars are presented.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4471-0811-5_27,springer
Article,doi:10.1023/A:1007933917719,Human-Machine Collaboration in Robotics: Integrating Virtual Tools with a Collision Avoidance Concept using Conglomerates of Spheres,Journal of Intelligent and Robotic Systems,10.1023/A:1007933917719,Springer,1997-04-01,"This paper describes how virtual tools that represent real robot end-effectors are used in conjunction with a generalized conglomerate-of-spheres approach to collision avoidance in such a way that telerobotic trajectory planning can be accomplished using simple gesture phrases such as ‘put that there while avoiding that’. In this concept, an operator (or set of collaborators) need not train for cumbersome telemanipulation on several multiple-link robots, nor do robots need a priori knowledge of operator intent and exhaustive algorithms for evaluating every aspect of a detailed environment model. The human does what humans do best during task specification, while the robot does what machines do best during trajectory planning and execution. Four telerobotic stages were implemented to demonstrate this strategic supervision concept that will facilitate collaborative control between humans and machines. In the first stage, virtual reality tools are selected from a ‘toolbox’ by the operator(s) and then these virtual tools are computationally interwoven into the live video scene with depth correlation. Each virtual tool is a graphic representation of a robot end-effector (gripper, cutter, or other robot tool) that carries tool-use attributes on how to perform a task. An operator uses an instrumented glove to virtually retrieve the disembodied tool, in the shared scene, and place it near objects and obstacles while giving key-point gesture directives, such as ‘cut there while avoiding that’. Collaborators on a network may alter the plan by changing tools or tool positioning to achieve preferred results from their own perspectives. When parties agree, from wherever they reside geographically, the robot(s) create and execute appropriate trajectories suitable to their own particular links and joints. Stage two generates standard joint-interpolated trajectories, and later creates potential field trajectories if necessary. Stage three tests for collisions with obstacles identified by the operator and modeled as conglomerates of spheres. Stage four involves automatic grasping (or cutting etc.) once the robot camera acquires a close-up view of the object during approach. In this paper particular emphasis is placed on the conglomerate-of-spheres approach to collision detection as integrated with the virtual tools concept for a Puma 560 robot by the Virtual Tools and Robotics Group in the Computer Integrated Manufacturing Laboratory at The Pennsylvania State University (Penn State).",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1007933917719,springer
Article,doi:10.1007/BF03037313,Evolvable hardware: A robot navigation system testbed,New Generation Computing,10.1007/BF03037313,Springer,1998-06-01,"Recently there has been great interest in the design and study of evolvable systems based on Artificial Life principles in order to monitor and control the behavior of physically embedded systems such as mobile robots, plants and intelligent home devices. At the same time new integrated circuits called software-reconfigurable devices have been introduced which are able to adapt their hardware almost continuously to changes in the input data or processing. When the configuration phase and the execution phase are concurrent, the software-reconfigurable device is called evolvable hardware (EHW). This paper examines an evolutionary navigation system for a mobile robot using a Boolean function approach implemented on gate-level evolvable hardware (EHW). The task of the mobile robot is to reach a goal represented by a colored ball while avoiding obstacles during its motion. We show that the Boolean function approach using dedicated evolution rules is sufficient to build the desired behavior and its hardware implementation using EHW allows to decrease the learning time for on-line training. We demonstrate the effectiveness of the generalization ability of the Boolean function approach using EHW due to its representation and evolution mechanism. The results show that the evolvable hardware configuration learned off-line in a simple environment creates a robust robot behavior which is able to perform the desired behaviors in more complex environments and which is insensitive to the gap between the real and simulated world.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF03037313,springer
Chapter ConferencePaper,doi:10.1007/978-1-4471-1599-1_174,Reinforcement Learning of Collision-free Motions for a Robot Arm with a Sensing Skin,ICANN 98,10.1007/978-1-4471-1599-1_174,Springer,1998-01-01,"Sensory information is fundamental for autonomous robots that face unknown environments. On-line sensing allows a robot arm to modify its motion in real time to cope better with the environment. Reactive systems (e.g., [1]) are appropriate to generate on-line motions from local sensory data. A reactive controller can be implemented automatically by using artificial neural networks and reinforcement learning (RL) [2,3,4]. RL allows a neural network to acquire reaction rules while the robot arm interacts with its environment. We have previously demonstrated the feasibility of RL to acquire sensor-based reaching strategies for simulated multi-link planar manipulators [5]. In this paper, we extend this work to a real manipulator, namely a Zebra ZERO, that has a whole-arm sensing skin with sonar proximity sensors (see Fig. 1a). We describe a neural reactive controller that learns goal-oriented obstacle-avoiding motion strategies for such a manipulator in unknown 3D environments. The controller is made up of two main modules: a reinforcement-based action generator (AG) and a goal vector generator (GG). The AG uses local sensory data and position information to determine an appropriate deviation from the goal vector given by the GG. The task of collision-free reaching can be decomposed into two sequential subtasks: Negotiate Obstacles (NO subtask) and Move to Goal position (MG subtask). When the robot arm is not near the goal position and detects an obstacle in its way to the goal, the best strategy is to focus on negotiating the obstacle—moving along an efficient trajectory is not so important.",2013-07-02,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4471-1599-1_174,springer
Article,doi:10.1023/A:1018237008823,Purposive Behavior Acquisition for a Real Robot by Vision-Based Reinforcement Learning,Machine Learning,10.1023/A:1018237008823,Springer,1996-05-01,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a state-action deviation problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1018237008823,springer
Article,doi:10.1007/BF00117447,Purposive behavior acquisition for a real robot by vision-based reinforcement learning,Machine Learning,10.1007/BF00117447,Springer,1996-05-01,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a “state-action deviation” problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF00117447,springer
Chapter,doi:10.1007/978-1-4613-0471-5_7,Purposive Behavior Acquisition for a Real Robot by Vision-Based Reinforcement Learning,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_7,Springer,1996-01-01,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a “state-action deviation” problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4613-0471-5_7,springer
Chapter ConferencePaper,doi:10.1007/3-540-61732-9_52,Programming by demonstration: A machine learning approach to support skill acquision for robots,Artificial Intelligence and Symbolic Mathematical Computation,10.1007/3-540-61732-9_52,Springer,1996-01-01,"Programming by Demonstration (PbD) is a programming method that allows to add new functionalities to a system by simply showing the desired task or skill in form of few examples. In the domain of robotics this paradigm offers the potential to reduce the complexity of robot task programming and to make programming more ”natural”. In case of programming an assembly task PbD allows with the help of a video or a laser camera and a data glove the automatic generation the necessary robot program for the assembly task. In addition, the demonstration of the task with few different assembly situations and strategies may achieve a generalized assembly function for all possible variants of the class. In order to realize such a PbD system at least two major problems have to be solved. First, the sensor data trace of a demonstration has to be interpreted and transformed into a high-level situation-action representation. This task is not yet well understood nor solved in general. Second, if a generalization is required, induction algorithms must be applied to the sensor data trace, to find the most general user-intended robot function from only few examples. In this paper mainly the second problem is focused. The described experimental PbD environment consists of an industrial robot, a 6D space mouse used as input device, and some sensors. Various data can be recorded during a demonstration for further processing in the PbD system implemented on a workstation. The objective is to exploit the possibilities of integrating learning and clustering algorithms for automated robot programming. In particular it is investigated how human interaction with the PbD system as well as user-initiated dialogs can support inductive learning to acquire generalized assembly programs and skills.",2005-06-02,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-61732-9_52,springer
Article,doi:10.1023/A:1007932011161,"The Development, Control and Operation of an Autonomous Robotic Excavator",Journal of Intelligent and Robotic Systems,10.1023/A:1007932011161,Springer,1998-01-01,"The excavation of foundations, general earthworks and earth removal tasks are activities which involve the machine operator in a series of repetitive operations, suggesting opportunities for the automation through the introduction of robotic technologies with subsequent improvements in machine utilisation and throughput. The automation of the earth removal process is also likely to provide a number of other benefits such as a reduced dependence on operator skills and a lower operator work load, both of which might be expected to contribute to improvements in quality and, in particular, the removal of the need for a local operator when working in hazardous environments. The Lancaster University Computerised Intelligent Excavator or LUCIE has demonstrated the achievement of automated and robotic excavation through the implementation of an integrated, real-time, artificial intelligence based control system utilising a novel form of motion control strategy for movement of the excavator bucket through ground. Having its origins in the systematic observation of a range of machine operators of differing levels of expertise, the control strategy as evolved enables the autonomous excavation of a high quality rectangular trench in a wide variety of types and conditions of ground and the autonomous removal of obstacles such as boulders along the line of that trench. The paper considers the development of the LUCIE programme since its inception and sets out in terms of the machine kinematics the evolution and development of the real-time control strategy from an implementation on a one-fifth scale model of a back-hoe arm to a full working system on a JCB801 360° tracked excavator.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1007932011161,springer
Chapter ConferencePaper,doi:10.1007/3-540-63173-9_50,Memory-based neural network and its application to a mobile robot with evolutionary and experience learning,Evolvable Systems: From Biology to Hardware,10.1007/3-540-63173-9_50,Springer,1997-01-01,"Use of the neural network in pattern recognition problem has many beneficial aspects, including advantages in learning, generalization, and robustness. However, the use of neural networks also has drawbacks. Problems encountered during the use of neural networks include an extended learning period and the inability of the users to process data. In an attempt to overcome these disadvantages, we propose a memory-based implementation of neural networks. Our method realizes neural network-like properties such as learning, generalization and robustness and is free from the weak points of the neural network. In our approach, training data are stored in a memory in the form of distributed manner by the use of several random number tables. On-line learning can be realized easily in our approach. This method was applied to a behavior-learning mobile robot. This robot acquires instinctive behavior by evolutionary method.",2005-06-08,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-63173-9_50,springer
Chapter ConferencePaper,doi:10.1007/BFb0032597,Implementation of a basic reactive behavior in mobile robotics through artificial neural networks,Biological and Artificial Computation: From Neuroscience to Technology,10.1007/BFb0032597,Springer,1997-01-01,"In this work we describe the design and implementation in a Nomad200 mobile robot of a reactive behavior aimed at wall following. A detailed analysis of the application domain has allowed us to modularize the design, conjugating in its. synthesis the potential of artificial neural networks for sensorial abstraction with other decision modules. We have carried out several experiments both in simulated and in real environments, obtaining very good results in different and unfavorable situations, which proves the robustness and flexibility of the system.",2005-06-18,http://link.springer.com/openurl/pdf?id=doi:10.1007/BFb0032597,springer
Article,doi:10.1007/BF00245422,A real-time planning algorithm for obstacle avoidance of redundant robots,Journal of Intelligent and Robotic Systems,10.1007/BF00245422,Springer,1996-07-01,"A computationally efficient, obstacle avoidance algorithm for redundant robots is presented in this paper. This algorithm incorporates the neural networks and pseudodistance function D _p in the framework of resolved motion rate control. Thus, it is well suited for real-time implementation. Robot arm kinematic control is carried out by the Hopfield network. The connection weights of the network can be determined from the current value of Jacobian matrix at each sampling time, and joint velocity commands can be generated from the outputs of the network. The obstacle avoidance task is achieved by formulating the performance criterion as D _p> d _min ( d _min represents the minimal distance between the redundant robot and obstacles). Its calculation is only related to some vertices which are used to model the robot and obstacles, and the computational times are nearly linear in the total number of vertices. Several simulation cases for a four-link planar manipulator are given to prove that the proposed collision-free trajectory planning scheme is efficient and practical.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF00245422,springer
Article,doi:10.1023/A:1008874222544,Fractal Fitness Landscape and Loss of Robustness in Evolutionary Robot Navigation,Autonomous Robots,10.1023/A:1008874222544,Springer,1998-05-01,"An autonomous robot “Khepera” was simulated with a sensory-motor model, which evolves in the genetic algorithm (GA) framework, with the fitness evaluation in terms of the navigation performance in a maze course. The sensory-motor model is a developed neural network decoded from a graph-represented chromosome, which is evolved in the GA process with several genetic operators. It was found that the fitness landscape is very rugged when it is observed at the starting point of the course. A hypothesis for this ruggedness is proposed, and is supported by the measurement of fractal dimension. It is also observed that the performance is sometimes plagued by “Loss of Robustness,” after the robot makes major evolutionary jumps. Here, the robustness is quantitatively defined as a ratio of the averaged fitness of the evolved robot navigating in perturbed environments over the fitness of the evolved robot in the referenced environment. Possible explanation of robustness loss is the over-adaptation occurred in the environment where the evolution was taken place. Testing some other possibilities for this loss of robustness, many simulation experiments were conducted which smooth out the discrete factors in the model and environment. It was found that smoothing the discrete factors does not solve the loss of robustness. An effective method for maintaining the robustness is the use of averaged fitness over different navigation conditions. The evolved models in the simulated environment were tested by down-loading the models into the real Khepera robot. It is demonstrated that the tendency of fitness values observed in the simulation were adequately regenerated.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1008874222544,springer
Chapter ConferencePaper,doi:10.1007/3-540-64473-3_65,Development of self-learning vision-based mobile robots for acquiring soccer robots behaviors,RoboCup-97: Robot Soccer World Cup I,10.1007/3-540-64473-3_65,Springer,1998-01-01,"An input generalization problem is one of the most important ones in applying reinforcement learning to real robot tasks. To cope with this problem, we propose a self-partitioning state space algorithm which can make non-uniform quantization of the multidimensional continuous state space. This method recursively splits its continuous state space into some coarse spaces called tentative states. It begins by supposing that such tentative states are regarded as the states for Q-learning. It collects Q values and statistical evidence regarding immediate rewards r and Q values within this tentative state space. When it finds out that a tentative state is relevant by the statistical test on minimum description length criterion, it partitions this coarse space into finer spaces. These procedures can make non-uniform quantization of the state space. Our method can be applied to non-deterministic domain because Q-learning is used to find out the optimal policy for accomplishing the given task. To show that our algorithm has generalization capability, we apply our method to two tasks in which a soccer robot shoots a ball into a goal and prevent a ball from entering a goal. To show the validity of this method, the experimental results for computer simulation and a real robot are shown.",2005-07-29,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-64473-3_65,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-72198-4_10,Development of Self-Learning Vision-Based Mobile Robots for Acquiring Soccer Robots Behaviors,Distributed Autonomous Robotic Systems 3,10.1007/978-3-642-72198-4_10,Springer,1998-01-01,"An input generalization problem is one of the most important ones in applying reinforcement learning to real robot tasks. To cope with this problem, we propose a self-partitioning state space algorithm which can make non-uniform quantization of the multidimensional continuous state space. This method recursively splits its continuous state space into some coarse spaces called tentative states based on the relevance test for immediate reward r and discounted future reward Q which are collected during Q-learning process. When it finds out that a tentative state is relevant by the statistical test on a minimum description length (hereafter, MDL), it partitions this coarse space into finer spaces. To show that our algorithm has generalization capability, we apply our method to two tasks in which a soccer robot shoots a ball into a goal and prevent a ball from entering a goal. To show the validity of this method, the experimental results for computer simulation and a real robot are shown.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-72198-4_10,springer
Chapter ConferencePaper,doi:10.1007/3-540-49240-2_7,Continual Robot Learning with Constructive Neural Networks,Learning Robots,10.1007/3-540-49240-2_7,Springer,1998-01-01,"In this paper, we present an approach for combining reinforcement learning, learning by imitation, and incremental hierarchical development. We apply this approach to a realistic simulated mobile robot that learns to perform a navigation task by imitating the movements of a teacher and then continues to learn by receiving reinforcement. The behaviours of the robot are represented as sensation-action rules in a constructive high-order neural network. Preliminary experiments are reported which show that incremental, hierarchical development, bootstrapped by imitative learning, allows the robot to adapt to changes in its environment during its entire lifetime very efficiently, even if only delayed reinforcements are given.",2000-06-09,http://link.springer.com/openurl/pdf?id=doi:10.1007/3-540-49240-2_7,springer
Article,doi:10.1007/BF00117445,Learning controllers for industrial robots,Machine Learning,10.1007/BF00117445,Springer,1996-05-01,"One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn't sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristic allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the “peg-into-hole” task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF00117445,springer
Article,doi:10.1023/A:1018228822027,Learning Controllers for Industrial Robots,Machine Learning,10.1023/A:1018228822027,Springer,1996-05-01,"One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn't sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristic allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the peg-into-hole task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs.",,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1018228822027,springer
Chapter,doi:10.1007/978-1-4613-0471-5_5,Learning Controllers for Industrial Robots,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_5,Springer,1996-01-01,"One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn’t sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristic allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the “peg-into-hole” task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4613-0471-5_5,springer
Article,doi:10.1007/BF00993825,A reply to Towell's book review of Neural Network Perception for Mobile Robot Guidance,Machine Learning,10.1007/BF00993825,Springer,1995-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF00993825,springer
Article,doi:10.1007/BF00993824,"Neural network perception for mobile robot guidance by Dean A. Pomerleau. Kluwer Academic Publishers, 1993",Machine Learning,10.1007/BF00993824,Springer,1995-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF00993824,springer
Article,doi:10.1023/A:1022878708705,"
              Book Review:
              Neural Network Perception For Mobile Robot Guidance
              by Dean A. Pomerleau. Kluwer Academic Publishers, 1993
            ",Machine Learning,10.1023/A:1022878708705,Springer,1995-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1022878708705,springer
Article,doi:10.1023/A:1022830825544,"A Reply to Towell's Book Review of Neural Network Perception for Mobile Robot Guidance
",Machine Learning,10.1023/A:1022830825544,Springer,1995-01-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1022830825544,springer
Article,doi:10.1007/BF01069333,Knowledge representations in robot artificial intelligence systems,Cybernetics,10.1007/BF01069333,Springer,1979-03-01,,,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF01069333,springer
Chapter,doi:10.1007/978-1-4615-9882-4_41,Hexapod Walking Robots with Artificial Intelligence Capabilities,Theory and Practice of Robots and Manipulators,10.1007/978-1-4615-9882-4_41,Springer,1985-01-01,"The potential usefulness of walking robots for work, maintenance and exploration in difficult environments is well acknowledged. For effective performing of these tasks, walkers have to become fully robotic, i.e. to be implemented with high-level software by using artificial intelligence concepts and techniques, concurrently with well-designed mechanics and intermediate software levels for control and sensing. The four-level control architecture we devised for our first six-legged prototype (see Ro Man Sy’81) was found to be efficient, easily modifiable and extensible. However, we find it useful to add to the existing structure (level, 1; leg, 2; gait generation, 3; plan interpreter, 4; intelligence and plan generation) a 1.5 ‘Tonus’ level for effector tonicity and leg adjustment according to terrain constraints. The hardware is tending toward a full multi-microprocessor organization. A significant feature of our approach is the existence at level 3 of an interpreter for our socialized walking robot plan language LP 4.5, designed to be automatically generated by the upper level; gaits are among the primitives of LP 4.5, which makes it easy to program the robot. As implemented now, with a rotating ultrasonic telemeter, the robot is able to exhibit such autonomous behaviours as following edges, escaping, explorating an unknown universe, etc. Paddle driving is also possible under plan control. An equilibrium sensing organ allows the maintenance of the platform horizontal on uneven ground. Methods experimented for producing level-4 intelligent behaviours on a difficult terrain include heuristic graph-search procedures (e.g. A*) and multi-level expert system advanced techniques. A stronger prototype, which carries a payload of 40 kg, has been built. The mechanical design is similar with Cartesian two-motors planar legs exhibiting lateral compliances; however, the leg mechanism is directly Cartesian, without the original triangle-and-pantograph system of the first prototype. The computer systems are compatible. This heavier robot can bear complex sensing systems and perform quasi-real-scale terrain experiments, such as feasibility studies for plant maintenance.",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-4615-9882-4_41,springer
Chapter ConferencePaper,doi:10.1007/BFb0027599,Reinforcement learning of assembly robots,Experimental Robotics III,10.1007/BFb0027599,Springer,1994-01-01,"This paper presents a new approach to learning a compliance control law for robotic assembly tasks. In this approach, a task performance index of assembly operations is defined and the adaptive reinforcement learning algorithm [1] is applied for real-time learning. A simple box palletizing task is used as an example, where a robot is required to move a rectangular part to the corner of a box. In the experiment, the robot is initially provided with only predetermined velocity command to follow the nominal trajectory. However, at each attempt, the box is randomly located and the part is randomly oriented within the grasp of the end-effector. Therefore, compliant motion control is required to guide the part to the corner of the box while avoiding excessive reaction forces caused by the collision with a wall. After repeating failures in performing the task, the robot can successfully learn force feedback gains to modify its nominal motion. Our results show that the new learning method can be used to learn a compliance control law effectively.",2005-06-18,http://link.springer.com/openurl/pdf?id=doi:10.1007/BFb0027599,springer
