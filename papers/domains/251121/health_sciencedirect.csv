id,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1016/j.eswa.2021.115975,Journal,Expert Systems with Applications,scopus,2022-03-01,sciencedirect,Optimizing the early glaucoma detection from visual fields by combining preprocessing techniques and ensemble classifier with selection strategies,https://api.elsevier.com/content/abstract/scopus_id/85117908294,"Artificial Intelligence is booming and many issues of research are being explored to improve technical performance in health systems. But also making them suitable for targeted medical practices. Their cost must also be justified by real added value for medical practitioners and patients. Extracting accurate information from datasets usually comes up against the amount of data and its distribution, which greatly affect the performance of the classifiers. Unbalanced classes or insignificant data features do not provide information for classifiers. Medical data like those of visual field (VF) most suffer from these problems. These factors limit the performance of individual classifiers. However, ensemble methods such as the bagging classifier (BC) can overcome these limitations and return good performances. BC is simple to process and very favorable to the combination with dynamic/static selection strategies (BC-DS/SS) which considerably improves its performance. By remaining sensitive to the problem of data distribution, this combination requires a fusion with pre-processing techniques such as feature selection and data rebalancing to be efficient. Thus, combining pre-processing techniques with the BC-DS/SS ensemble classifiers would allow to extract more accurate information from VF datasets. The stake of this classifier combining pre-processing techniques and ensemble methods with selection strategies named 
                        
                           
                              
                                 C
                              
                              
                                 2
                              
                           
                           P
                           E
                           M
                           
                              
                                 S
                              
                              
                                 2
                              
                           
                        
                      (C2 relates to Classifier Combining, PEM refers to Pre-processing and Ensemble Methods and S2 refers to Selection Strategies) consists of: (1) optimizing the performances while reducing the over-fitting, (2) saving in processing time and more importantly (3) predicting more efficiently the targeted class which often is the minority in unbalanced datasets. The experiments of our approach on VF datasets allowed to predict early glaucoma with greater efficiency compared to the state of the art.",health
10.1016/j.ces.2021.117205,Journal,Chemical Engineering Science,scopus,2022-02-02,sciencedirect,"Developments of leak detection, diagnostics, and prediction algorithms in multiphase flows",https://api.elsevier.com/content/abstract/scopus_id/85118896502,"Leak detection, diagnostics, and prediction constitute a crucial phase of the flow assurance risk management process for onshore and offshore pipelines. There are a variety of techniques and algorithms that can be deployed to address each aspect. To date, most review papers have concentrated on steady-state and single-phase flow conditions. The goal of the current review is therefore to carry out a thorough analysis of the available leak detection and diagnosis methods by focusing on (i) multiphase flow and transient flow conditions, (ii) model-based and data-driven techniques, (iii) prediction tools, and (iv) performance measures. Detailed assessment of leak detection methods based on accuracy, complexity, data requirement, and cost of installation are discussed. Data-driven techniques are utterly dependent on qualitative and quantitative data available from pipeline systems. Contrastingly data-driven techniques, model-based techniques require less data to achieve leak detection, provided that a nearly accurate base model is available. Different methodologies and technologies can be combined in order to produce the best detection and diagnosis outputs. In many cases, statistical analysis was combined with the Real Time Transient Method (RTTM), which helped to minimize false alarms. The material in this review can be used as a robust guide for the design of diagnostic systems and further research.",health
10.1016/j.talanta.2021.123030,Journal,Talanta,scopus,2022-02-01,sciencedirect,A turn-on NIR fluorescence sensor for gossypol based on Yb-based metal-organic framework,https://api.elsevier.com/content/abstract/scopus_id/85118877273,"The development of analytical method for selective and sensitive detection of gossypol (Gsp), an extraction from the cotton plants, is important but still challenging in food safety and medical field. Herein, we reported a turn-on near infrared (NIR) fluorescence detection strategy for Gsp based on a metal-organic framework (MOF), QBA-Yb, which was prepared from 4,4’-(quinolone-5, 8-diyl) benzoate with Yb(NO3)3·5H2O by solvothermal synthesis. The Gsp acted as another “antenna” to sensitize the luminescence of Yb3+, leading to the turn-on NIR emission upon 467 nm excitation. As Gsp concentration increased, the NIR emission at 973 nm enhanced gradually, thus enabling highly sensitive Gsp detection in a turn-on way. The experiment and theoretical calculation results revealed the presence of strong hydrogen bonds between Gsp molecules and the MOF skeleton. The developed QBA-Yb probe showed excellent characteristics for detection of Gsp molecules, accompanied by wide linear range (5–160 μg/mL), low detection limit (0.65 μg/mL) and short response time (within 10 min). We have further demonstrated that the QBA-Yb probe was successfully applied for the determination of Gsp in real samples of cottonseeds.",health
10.1016/j.tiv.2021.105271,Journal,Toxicology in Vitro,scopus,2022-02-01,sciencedirect,Identification of the function and regulatory network of circ_009773 in DNA damage induced by nanoparticles of neodymium oxide,https://api.elsevier.com/content/abstract/scopus_id/85118591780,"The health hazards of nanoparticles of neodymium oxide (NPs-Nd2O3) have aroused public concern in recent years. Exposure to NPs-Nd2O3 can change the level of reactive oxygen species (ROS) that cause DNA damage and alter whole transcriptome expression profiles for micro (mi)RNA, circular (circ)RNA, long noncoding (lnc)RNA, and mRNA. However, there have been no reports to our knowledge about the role of circRNAs in DNA damage caused by NPs-Nd2O3. In our study, we analyzed the circRNA expression profile of human bronchial epithelial cells(16HBE)exposed to 40 μg/ml NPs-Nd2O3. Our results indicated that exposure produced 1025 up-regulated and 890 down-regulated circRNAs. Real-time quantitative polymerase chain reaction (qRT-PCR) was applied to verify some of the significantly changed circRNAs and demonstrated that circ_009773 was apparently down-regulated. Through exploration of its host gene function, we found that circ_009773 may be related to DNA damage. Functional experiments found that circ_009773 regulated NPs-Nd2O3-induced DNA damage in 16HBE cells. A circ_009773-associated competing endogenous (ce)RNA network was constructed based on one differentially expressed (DE) circRNA, 74 DE miRNAs and 208 DE mRNAs. Module analysis identified hub genes related to DNA damage and repair and a protein-protein interaction (PPI) network was created.",health
10.1016/j.ress.2021.108119,Journal,Reliability Engineering and System Safety,scopus,2022-02-01,sciencedirect,Prognostics and Health Management (PHM): Where are we and where do we (need to) go in theory and practice,https://api.elsevier.com/content/abstract/scopus_id/85117331443,"We are performing the digital transition of industry, living the 4th industrial revolution, building a new World in which the digital, physical and human dimensions are interrelated in complex socio-cyber-physical systems. For the sustainability of these transformations, knowledge, information and data must be integrated within model-based and data-driven approaches of Prognostics and Health Management (PHM) for the assessment and prediction of structures, systems and components (SSCs) evolutions and process behaviors, so as to allow anticipating failures and avoiding accidents, thus, aiming at improved safe and reliable design, operation and maintenance.
                  There is already a plethora of methods available for many potential applications and more are being developed: yet, there are still a number of critical problems which impede full deployment of PHM and its benefits in practice. In this respect, this paper does not aim at providing a survey of existing works for an introduction to PHM nor at providing new tools or methods for its further development; rather, it aims at pointing out main challenges and directions of advancements, for full deployment of condition-based and predictive maintenance in practice.",health
10.1016/j.eswa.2021.115937,Journal,Expert Systems with Applications,scopus,2022-02-01,sciencedirect,Genetic Neural Architecture Search for automatic assessment of human sperm images,https://api.elsevier.com/content/abstract/scopus_id/85117152898,"Male infertility is a disease that affects approximately 7% of men. Sperm morphology analysis (SMA) is one of the main diagnosis methods for this problem. However, manual SMA is an inexact, subjective, non-reproducible, and hard to teach process. Therefore, in this paper, we introduce a novel automatic SMA technique that is based on the neural architecture search algorithm, named Genetic Neural Architecture Search (GeNAS). For this purpose, we used a collection of images termed MHSMA dataset, which contains 1540 sperm images that have been collected from 235 patients with infertility problems. In detail, GeNAS consists of a special genetic algorithm that acts as a meta-controller which explores the constrained search space of plain convolutional neural network architectures. Every individual of this genetic algorithm is a convolutional neural network trained to predict morphological deformities in different segments of human sperm (head, vacuole, and acrosome). The fitness of each individual is calculated by a novel proposed method, named GeNAS Weighting Factor (GeNAS-WF). This technique is specially designed to evaluate the fitness of neural networks which, during their learning process, validation accuracy highly fluctuates. To speed up the algorithm, a hashing method is practiced to save each trained neural architecture fitness, so we could reuse them during fitness evaluation. In terms of running time and computational power, our proposed architecture search method is far more efficient than most of the other existing neural architecture search algorithms. Moreover, whereas most of the existing neural architecture search algorithms are designed to work well with well-prepared benchmark datasets, the overall paradigm of GeNAS is specially designed to address the challenges of real-world datasets, particularly shortage of data and class imbalance. In our experiments, the best neural architecture found by GeNAS has reached an accuracy of 91.66%, 77.33%, and 77.66% in the vacuole, head, and acrosome abnormality detection, respectively. In comparison to other proposed algorithms for MHSMA dataset, GeNAS achieved state-of-the-art results.",health
10.1016/j.future.2021.08.030,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,A wearable-based posture recognition system with AI-assisted approach for healthcare IoT,https://api.elsevier.com/content/abstract/scopus_id/85115908462,"Human posture recognition is a challenging task in the medical healthcare industry, when pursuing intelligence, accuracy, security, privacy, and efficiency, etc. Currently, the main posture recognition methods are captured-behaviors-based visual image analysis and wearable devices-based signal analysis. However, these methods suffer from issues such as high misjudgment rate, high-cost and low-efficiency. To address these issues, we propose a collaborative AI-IoT-based solution (namely, WMHPR) that embeds with advanced AI-assisted approach. In WMHPR, we propose the multi-posture recognition (MPR), an offline algorithm is implemented on wearable hardware, to identify posture based on multi-dimensions data. Meanwhile, an AI-based algorithm running on the cloud server (online), named Cascade-AdaBoosting-CART (CACT), is proposed to further enhance the reliability and accuracy of MPR. We recruit 20 volunteers for real-life experiments to evaluate the effectiveness, and the results show our solution is significantly outstanding in terms of accuracy and reliability while comparing with other typical algorithms.",health
10.1016/j.is.2021.101878,Journal,Information Systems,scopus,2022-02-01,sciencedirect,Electronic health records based reinforcement learning for treatment optimizing,https://api.elsevier.com/content/abstract/scopus_id/85115385699,"Electronic Health Records (EHRs) have become one of the main sources of evidence to evaluate clinical actions, improve medical quality, predict disease-risk, and optimize treatment effects. However, EHRs present several modeling challenges, including heterogeneous data types and dynamic characteristics. Reinforcement learning provides an efficient way for sequential decision-making. Powered by model-based reinforcement learning approach, we propose an EHRs-based reinforcement learning algorithm to optimize sequential treatment strategies for diseases, such as sepsis, diabetes, and their complications. We conduct our experiments with this algorithm to optimize physicians’ historical treatment strategies and achieve better glucose control for diabetic ketoacidosis (DKA) patients, which is one serious complication of diabetes. The research includes the modeling process and reinforcement learning process. During the EHRs modeling process, besides considering the necessary physiological variables, we also consider the major disease factors to enhance the interpretability of the model. In the reinforcement learning process, a deep Q network is employed to explore the optimal insulin dose for patients. Moreover, inspired by the real medical scenes, we extend the algorithm to cooperative learning environment. We use the joint policy of the two agents to simulate doctor consultations, and achieve better treatment performances in terms of policy and blood glucose control than single agent and clinicians.",health
10.1016/j.future.2021.09.010,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,XSRU-IoMT: Explainable simple recurrent units for threat detection in Internet of Medical Things networks,https://api.elsevier.com/content/abstract/scopus_id/85115376405,"The Internet of Medical Things (IoMT) is increasingly replacing the traditional healthcare systems. However, less focus has been paid to their security against cyber-threats in the implementation of the IoMT and its networks. One of the key reasons can be the challenging task of optimizing typical security solutions to the IoMT networks. And despite the rising admiration of machine learning and deep learning methods in the cyber-security domain (e.g., a threat detection system), most of these methods are acknowledged as a black-box model. The explainable AI (XAI) has become progressively vital to understand the employed learning models to improve trust level and empower security experts to interpret the prediction decisions. The authors propose a highly efficient model named XSRU-IoMT, for effective and timely detection of sophisticated attack vectors in IoMT networks. The proposed model is developed using novel bidirectional simple recurrent units (SRU) using the phenomenon of skip connections to eradicate the vanishing gradient problem and achieve a fast training process in recurrent networks. We also explore the concepts of XAI to improve trust level by providing explanations of the predictive decisions and enabling humans and security experts to understand the causal reasoning and underlying data evidence. The evaluation results on the ToN_IoT dataset demonstrate the effectiveness and superiority of the proposed XSRU-IoMT model as compared to the state-of-the-art compelling detection models, suggesting its usefulness as a viable deployment model in real-IoMT networks.",health
10.1016/j.ymssp.2021.108217,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-01,sciencedirect,Robustness enhancement of machine fault diagnostic models for railway applications through data augmentation,https://api.elsevier.com/content/abstract/scopus_id/85111801223,"The performance of machine learning based machine fault diagnosis (MFD) models could be impaired due to operating condition variations encountered in the real-world industrial environment, such as variations of operating speeds and loads. One major reason for this robustness problem is a lack of adequate training data, especially faulty data, measured in various operating conditions. To cover this gap, we propose a novel data augmentation framework for robustness enhancement in railway MFD applications. First, multibody dynamic simulation (MBS) for physical modeling is applied to simulate arbitrary faulty and operating conditions. Second, fast weighted feature-space averaging (FWFSA) as a new data augmentation technique is developed to augment the simulated faulty data, producing infinite reality-augmented simulation data. The proposed MBS-FWFSA can fit in arbitrary MFD algorithms and transfer-learning settings with minimal effort. Moreover, an in-depth empirical study has been carried out to investigate the causality between condition variations and robustness. A new metric has been defined to evaluate robustness. The experiments also revealed the effect of the proposed MBS-FWFSA and its outperformance against several state-of-the-art augmentation methods. The code and data used in this paper have been shared in our GitHub repository: https://github.com/quickhdsdc/Robustness-Enhancement-of-Machine-Fault-Diagnostic-Models.",health
10.1016/j.bios.2021.113724,Journal,Biosensors and Bioelectronics,scopus,2022-01-15,sciencedirect,Pd–Fe<inf>3</inf>O<inf>4</inf> Janus nanozyme with rational design for ultrasensitive colorimetric detection of biothiols,https://api.elsevier.com/content/abstract/scopus_id/85117699782,"Although nanozyme-based colorimetric assays have been broadly used for biosensing, some limitations such as low catalytic activity of nanozyme, poor sensitivity to analytes and lack of understanding the structure-activity relationship remain unsolved. In this work, we developed an ultrasensitive colorimetric method for biothiols detection based on density functional theory-assisted design of janus Pd–Fe3O4 nanozyme. The Pd–Fe3O4 dumbbell-like nanoparticles (DBNPs) prepared by seed-mediated approach shows a uniform heterodimeric nanostructure. Ultrasensitive biothiols detection is achieved from two aspects. On one hand, due to the synergistic effect between Pd and Fe3O4 in the dumbbell structure, Pd–Fe3O4 DBNPs show enhanced peroxidase-mimic activity compared to the individual components. On the other hand, when the target biothiols molecule is present, its inhibition effect on the janus Pd–Fe3O4 nanozyme is also significantly enhanced. The above results are confirmed both in experiment and theoretical calculation. Based on the rational design, a simple, highly selective and urtrasensitive colorimetric and quantitative assay for biothiols is developed. The limit of detection (LOD) can reach as low as 3.1 nM in aqueous solution. This assay is also successfully applied to the detection of biothiols in real urine samples. Moreover, the Pd–Fe3O4 nanozyme is used to discriminate biothiols levels in normal and cancer cells with high sensitivity at the cell density of 15,000/mL, which demonstrates its great potential in biological and clinical analysis. This work not only shows the great promise of janus bimetallic nanozymes’ excellent functionalities but also provides rational guidelines to design high-performance nanozymes for biosensing and biomedical applications.",health
10.1016/j.jhazmat.2021.126838,Journal,Journal of Hazardous Materials,scopus,2022-01-15,sciencedirect,Fluonanobody-based nanosensor via fluorescence resonance energy transfer for ultrasensitive detection of ochratoxin A,https://api.elsevier.com/content/abstract/scopus_id/85112552832,"Ochratoxin A (OTA) contamination in food is a serious threat to public health. There is an urgent need for development of rapid and sensitive methods for OTA detection, to minimize consumer exposure to OTA. In this study, we constructed two OTA-specific fluonanobodies (FluoNbs), with a nanobody fused at the carboxyl-terminal (SGFP-Nb) or the amino-terminal (Nb-SGFP) of superfolder green fluorescence protein. SGFP-Nb, which displayed better fluorescence performance, was selected as the tracer for OTA, to develop a FluoNb-based nanosensor (FN-Nanosens) via the fluorescence resonance energy transfer, where the SGFP-Nb served as the donor and the chemical conjugates of OTA-quantum dots served as the acceptor. After optimization, FN-Nanosens showed a limit of detection of 5 pg/mL, with a linear detection range of 5–5000 pg/mL. FN-Nanosens was found to be highly selective for OTA and showed good accuracy and repeatability in recovery experiments using cereals with various complex matrix environments. Moreover, the contents of OTA in real samples measured using FN-Nanosens correlated well with those from the liquid chromatography with tandem mass spectrometry. Therefore, this work illustrated that the FluoNb is an ideal immunosensing tool and that FN-Nanosens is reliable for rapid detection of OTA in cereals with ultrahigh sensitivity.",health
10.1016/j.measurement.2021.110332,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2022-01-01,sciencedirect,Joint distribution adaptation with diverse feature aggregation: A new transfer learning framework for bearing diagnosis across different machines,https://api.elsevier.com/content/abstract/scopus_id/85118335519,"On account of lacking labeled samples for the bearing fault diagnosis in real engineering applications, transfer learning is widely investigated for transferring diagnosis information. A more challenging but realistic scenario called transfer across different machines (TDM) is investigated in this paper where previous approaches may degenerate greatly with more drastic domain shifts. A joint distribution adaptation-based transfer network with diverse feature aggregation (JDFA) is proposed, where the diverse feature aggregation module is added to enhance feature extraction capability across large domain gaps. Then the joint maximum mean discrepancy between source and target domain samples is adopted to reduce the distribution discrepancy automatically. Extensive TDM transfer learning experiments are conducted. The average accuracy reaches 99.178% that is much higher than state-of-the-art methods, demonstrating the proposed JDFA framework can effectively achieve superior diagnostic performance, and significantly promote fault diagnosis research under TDM scenario in view of applicability and practicability of algorithms.",health
10.1016/j.autcon.2021.103992,Journal,Automation in Construction,scopus,2022-01-01,sciencedirect,Automated semantic segmentation of bridge point cloud based on local descriptor and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85117420951,"In recent years, monitoring the health condition of existing bridges has become a common requirement. By providing an information management system, Bridge Information Model (BrIM) can highly improve the efficiency of health inspection and the reliability of condition evaluation. However, the current modeling processes still largely rely on manual work, where the cost outweighs the benefits. The main barrier lies in the challenging step of semantic segmentation of point clouds. Efforts have been made to identify and segment the structural components of bridges in existing research. But these methods are either dependent on manual data preprocessing or need big training dataset, which, however, has rendered them unpractical in real-world applications. This paper presents a combined local descriptor and machine learning based method to automatically detect structural components of bridges from point clouds. Based on the geometrical features of bridges, we design a multi-scale local descriptor, which is then used to train a deep classification neural network. In the end, a result refinement algorithm is adopted to optimize the segmentation results. Experiments on real-world reinforced concrete (RC) slab and beam-slab bridges show an average precision of 97.26%, recall of 98.00%, and intersection over union (IoU) of 95.38%, which significantly outperforms PointNet. This method has provided a potential solution to semantic segmentation of infrastructures by small sample learning and will contribute to the fulfillment of the automatic BrIM generation of typical highway bridges from the point cloud in the future.",health
10.1016/j.bspc.2021.103123,Journal,Biomedical Signal Processing and Control,scopus,2022-01-01,sciencedirect,Real-time application based CNN architecture for automatic USCT bone image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85114454344,"Artificial Intelligence (AI) in medical image analysis has achieved excellent success in automatic diagnosis in the same way as clinician, especially in the ultrasound field. In this work, we develop a new segmentation application based on various Convolutional Neural Network (CNN) models for Ultrasonic Computed Tomographic (USCT) images. To evaluate the proposed segmentation system, we use different state-of-the-art models for better segmentation performances to train and test the suggested system. We ensure in this work a USCT data augmentation technique based on the Haar wavelet transform and the improved k-means algorithms. Thus, we offer a free dataset for USCT researchers. Moreover, the proposed CNN system is trained and tested using the networks of Adadelta and Adam optimizers. The whole system is implemented on a CPU and a GPU for complexity analysis. High segmentation accuracy has been achieved using the Adadelta optimizer, reaching 99.24%, 99.19%, 99.13% and 99.10% for VGG-Segnet, VGG-Unet, Fully CNN (FCN)-8 and FCN-32 models, respectively. To obtain better results, we use the Adam optimizer to train and test different architectures, and we obtain more competitive results attaining 99.55%, 99.31%, 99.35% and 99.45% for VGG-Segnet, VGG-Unet, FCN-8 and FCN-32, respectively. The achieved results outperform the state of the art in terms of accuracy and time speed up. Moreover, our proposed CNN segmentation confirms the low computational complexity of the system. In addition, our system proves to be a good candidate for medical real-time applications thanks to its implementation on the GPU.",health
10.1016/j.future.2021.08.015,Journal,Future Generation Computer Systems,scopus,2022-01-01,sciencedirect,Empathic conversational agents for real-time monitoring and co-facilitation of patient-centered healthcare,https://api.elsevier.com/content/abstract/scopus_id/85114349934,"Healthcare systems across the world are transitioning into patient-centered healthcare models to ensure improved health outcomes, increased operational efficiencies and respectful patient engagement. Digital health technologies are at the forefront of this transition in facilitating a role for the patient in the clinical dimensions of the healthcare trajectory, from diagnosis and interventions to treatment and recovery. Despite this prevalence in the clinical space, the non-clinical needs of patient mental health and wellbeing are frequently overlooked by contemporary patient-centered healthcare models. Conversational agents (or chatbots) are digital dialogue systems that are widespread and widely used in sequential information provision and information acquisition tasks. Given the intimate nature of this human-machine interaction, conversational agents can be effectively utilized to support and sustain patient mental health and wellbeing. In this paper, we propose an empathic conversational agent framework based on an ensemble of natural language processing techniques and artificial intelligence algorithms for real-time monitoring and co-facilitation of patient-centered healthcare for improved mental health and wellbeing outcomes. The technical contributions of this framework are; detection of patient emotions, prediction of patient emotion transitions, detection of group emotions, formulation of patient behavioral metrics, and resource recommendations based on patient concerns. The architectural contributions of the framework are intelligent communication channels that stream empathic conversational elements and resource recommendations for the multi-user conversations and co-facilitation updates for the human healthcare provider interface. The framework was empirically evaluated on a benchmark dataset and further validated based on a clinical protocol designed for its application in an online support group setting for cancer patients and caregivers in Canada. The results of these experiments confirm the effectiveness of this framework, its contributory role and practical value in realizing a patient-centered healthcare model for improved mental health and wellbeing outcomes.",health
10.1016/j.future.2021.08.019,Journal,Future Generation Computer Systems,scopus,2022-01-01,sciencedirect,Deep cognitive diagnosis model for predicting students’ performance,https://api.elsevier.com/content/abstract/scopus_id/85114246185,"Cognitive model is playing very important role in predicting students’ performance and recommending learning resources. Thus, it has received a great deal of attention from researchers. However, most of the existing work design models from the aspect of students, ignoring the internal relation between problems and skills. To address this problem, we propose a deep cognitive diagnosis framework to obtain students’ mastery of skills and problems by enhancing traditional cognitive diagnosis methods with deep learning. First, we model the skill proficiency of students according to their responses to objective and subjective problems. Second, students’ mastery on problems is modeled based on attention mechanism and neural network, considering both the importance and the interactions of skills. Finally, considering the facts that students may carelessly select or simply guess the answer, we predict students’ performance via the proposed model. Extensive experiments are carried out on two real-world data sets, and the results have proved the effectiveness and interpretability of this work.",health
10.1016/j.bspc.2021.103107,Journal,Biomedical Signal Processing and Control,scopus,2022-01-01,sciencedirect,MFCC-based Recurrent Neural Network for automatic clinical depression recognition and assessment from speech,https://api.elsevier.com/content/abstract/scopus_id/85114129743,"Clinical depression or Major Depressive Disorder (MDD) is a common and serious medical illness. In this paper, a deep Recurrent Neural Network-based framework is presented to detect depression and to predict its severity level from speech. Low-level and high-level audio features are extracted from audio recordings to predict the 24 scores of the Patient Health Questionnaire and the binary class of depression diagnosis. To overcome the problem of the small size of Speech Depression Recognition (SDR) datasets, expanding training labels and transferred features are considered. The proposed approach outperforms the state-of-art approaches on the DAIC-WOZ database with an overall accuracy of 76.27% and a root mean square error of 0.4 in assessing depression, while a root mean square error of 0.168 is achieved in predicting the depression severity levels. The proposed framework has several advantages (fastness, non-invasiveness, and non-intrusion), which makes it convenient for real-time applications. The performances of the proposed approach are evaluated under a multi-modal and a multi-features experiments. MFCC based high-level features hold relevant information related to depression. Yet, adding visual action units and different other acoustic features further boosts the classification results by 20% and 10% to reach an accuracy of 95.6% and 86%, respectively. Considering visual-facial modality needs to be carefully studied as it sparks patient privacy concerns while adding more acoustic features increases the computation time.",health
10.1016/j.mechmachtheory.2021.104445,Journal,Mechanism and Machine Theory,scopus,2022-01-01,sciencedirect,Semi-supervised hierarchical attribute representation learning via multi-layer matrix factorization for machinery fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85113950527,"Data-driven fault diagnosis methods have become a research hotspot recently. However, the following two problems are still barring them from the application: (1) Most of the existing models rely deeply on sufficient labeled samples and neglect the high cost of labeled data collection in reality; (2) The existing models usually focus on the single-level attribute of the sample and ignore the latent hierarchical fault attributes. To address these issues, a novel semi-supervised multi-layer non-negative matrix factorization (SMNMF) method is proposed in this study. The fault pattern and severity identification problems are converted into a hierarchical fault attribute representation task, which can reduce the complexity of the classification task and improve the fault diagnosis accuracy. The hierarchical attribute representations of different fault locations and sizes are learned from the time-frequency distribution (TFD) of signals by a newly constructed two-layer non-negative matrix factorization model. The graph-based semi-supervised learning method is adopted to lead the attributes of the hierarchy structure and carry out label propagation from labeled samples to unlabeled samples for more accurate fault diagnosis. The fault diagnosis experiments executed in the aeroengine bearings and a diesel engine demonstrated the feasibility and superiority of the proposed method.",health
10.1016/j.inffus.2021.07.013,Journal,Information Fusion,scopus,2022-01-01,sciencedirect,Interpretable learning based Dynamic Graph Convolutional Networks for Alzheimer's Disease analysis,https://api.elsevier.com/content/abstract/scopus_id/85111766632,"Graph Convolutional Networks (GCNs) are widely applied in classification tasks by aggregating the neighborhood information of each sample to output robust node embedding. However, conventional GCN methods do not update the graph during the training process so that their effectiveness is always influenced by the quality of the input graph. Moreover, previous GCN methods lack the interpretability to limit their real applications. In this paper, a novel personalized diagnosis technique is proposed for early Alzheimer’s Disease (AD) diagnosis via coupling interpretable feature learning with dynamic graph learning into the GCN architecture. Specifically, the module of interpretable feature learning selects informative features to provide interpretability for disease diagnosis and abandons redundant features to capture inherent correlation of data points. The module of dynamic graph learning adjusts the neighborhood relationship of every data point to output robust node embedding as well as the correlations of all data points to refine the classifier. The GCN module outputs diagnosis results based on the learned inherent graph structure. All three modules are jointly optimized to perform reliable disease diagnosis at an individual level. Experiments demonstrate that our method outputs competitive diagnosis performance as well as provide interpretability for personalized disease diagnosis.",health
10.1016/j.eswa.2021.115863,Journal,Expert Systems with Applications,scopus,2021-12-30,sciencedirect,Auto-detection of acoustic emission signals from cracking of concrete structures using convolutional neural networks: Upscaling from specimen,https://api.elsevier.com/content/abstract/scopus_id/85114837702,"Acoustic emission (AE) monitoring has gained significant interest as a promising method for monitoring of changes in structural integrity and durability. Long-term AE monitoring needs to detect and distinguish crack signals from ambient noise (or dummy) signals; however, it is still a daunting task which currently limits field implementation of the AE method. Herein, we explore the feasibility of using convolutional neural network (CNN) models to detect AE crack signals from ambient signals. The trained models are validated both with noise-embedded synthesized signals and with upscaled physical model experiments simulating earthquake loading to a scaled model foundation by using a large-scale shaking table. The 2D CNN model trained the laboratory-synthesized signal sets effectively captured the crack and crack-free signals in all cases including the upscaled physical model experiments. This study presents a simple but robust CNN model for pre-filtering of crack signals and a novel training method for enhanced accuracy, which can be applied for real-time structural health monitoring of concrete-based structures.",health
10.1016/j.knosys.2021.107568,Journal,Knowledge-Based Systems,scopus,2021-12-25,sciencedirect,An interpretable deep neural network for colorectal polyp diagnosis under colonoscopy,https://api.elsevier.com/content/abstract/scopus_id/85117067571,"Colorectal cancer (CRC) is the third leading cause of cancer deaths in the world, which mostly stems from precancerous polyps. Early detection and accurate classification of polyps play a vital role in colonoscopy. It makes sense to automatically detect the polyp and give a real-time classification feedback according to popular Yamada classification guidance during colonoscopy progress. We propose an interpretable deep neural network method, called multi-task real-time deep neural network with Shapley additive explanations, for polyp detection, polyp classification and polyp segmentation under colonoscopy. To the best of our knowledge, this is the first time to perform polyp classification according to Yamada classification guidance under colonoscopy with a deep learning method. To validate the performance of our proposed method, we conduct various comparative experiments on popular CVC-CLINIC and CVC-COLON datasets. We adopt various performance indicators, including area under receiver operating characteristics curve (AUC), precision, recall, F1 score, accuracy, and mean intersection over union (mIoU). The proposed method achieves satisfactory real-time performance in terms of polyp detection module, polyp classification module and polyp segmentation module. The experimental results show the overwhelming performance of our proposed method compared with other deep learning methods. We have achieved satisfying operating efficiency and interpretable feedback to meet the requirements of the colorectal surgeon, which provides an valuable decision support and reduces the rate of missed diagnosis and misdiagnosis of polyps in the process of colonoscopy.",health
10.1016/j.neuroimage.2021.118687,Journal,NeuroImage,scopus,2021-12-15,sciencedirect,Recycling diagnostic MRI for empowering brain morphometric research – Critical &amp; practical assessment on learning-based image super-resolution,https://api.elsevier.com/content/abstract/scopus_id/85118489798,"Preliminary studies have shown the feasibility of deep learning (DL)-based super-resolution (SR) technique for reconstructing thick-slice/gap diagnostic MR images into high-resolution isotropic data, which would be of great significance for brain research field if the vast amount of diagnostic MRI data could be successively put into brain morphometric study. However, less evidence has addressed the practicability of the strategy, because lack of a large-sample available real data for constructing DL model. In this work, we employed a large cohort (n = 2052) of peculiar data with both low through-plane resolution diagnostic and high-resolution isotropic brain MR images from identical subjects. By leveraging a series of SR approaches, including a proposed novel DL algorithm of Structure Constrained Super Resolution Network (SCSRN), the diagnostic images were transformed to high-resolution isotropic data to meet the criteria of brain research in voxel-based and surface-based morphometric analyses. We comprehensively assessed image quality and the practicability of the reconstructed data in a variety of morphometric analysis scenarios. We further compared the performance of SR approaches to the ground truth high-resolution isotropic data. The results showed (i) DL-based SR algorithms generally improve the quality of diagnostic images and render morphometric analysis more accurate, especially, with the most superior performance of the novel approach of SCSRN. (ii) Accuracies vary across brain structures and methods, and (iii) performance increases were higher for voxel than for surface based approaches. This study supports that DL-based image super-resolution potentially recycle huge amount of routine diagnostic brain MRI deposited in sleeping state, and turning them into useful data for neurometric research.",health
10.1016/j.eswa.2021.115631,Journal,Expert Systems with Applications,scopus,2021-12-15,sciencedirect,Combining deep learning with geometric features for image-based localization in the Gastrointestinal tract,https://api.elsevier.com/content/abstract/scopus_id/85112632583,"Tracking monocular colonoscope in the GastroIntestinal (GI) tract is challenging as the obtained images suffer from deformation, blurred textures, and significant changes in appearance. These drawbacks greatly restrict the tracking ability of conventional geometry-based methods, which are heavily dependent on the performance of corner points extraction from the image. Even though end-to-end Deep Learning (DL) can overcome these issues, limited labeling data is a roadblock to the state-of-the-art DL-based method. To handle these drawbacks, we propose a novel approach to combine the DL-based method with the traditional geometry-based approach to achieve better localization with small training data. In this work, a DL network is trained with the images of the pre-operative endoscopy/colonoscopy. Siamese architecture is introduced to perform the zone labeling of the image based on the anatomical segmentation with expert knowledge. Then, using the image in the therapeutic intervention, our method predicts the 6 degrees of freedom scope pose and recover geometric reference to the images from the pre-operative endoscopy/colonoscopy. The DL network predicts the zone of the testing image, and the pre-generated triangulated map points within the zone in the training set are registered with the bundle adjustment algorithm. The proposed hybrid method is tested on the synthetic data sets and the real-world in-vivo data sets. Further, the results achieved through various experiments validate that the proposed method outperforms traditional geometry-based only or DL-based only localization techniques.",health
10.1016/j.jep.2021.114514,Journal,Journal of Ethnopharmacology,scopus,2021-12-05,sciencedirect,Total flavonoids of Taraxacum mongolicum inhibit non-small cell lung cancer by regulating immune function,https://api.elsevier.com/content/abstract/scopus_id/85112690875,"Ethnopharmacological relevance
                  
                     Taraxacum mongolicum Hand.-Mazz. has been used in lung cancer treatment in Chinese medicine. However, its specific mechanism of action has not yet been reported, and developing pharmaceutical anti-cancer resources is important. Here, we aimed to elucidate the anti-tumor effects of dandelion in vitro and in vivo and assess its effects on immune function in lung cancer patients.
               
                  Aim of the study
                  In the present study, we mainly observed the therapeutic effects of total flavonoids from Taraxacum mongolicum Hand.-Mazz. (TFTM) on non-small cell lung cancer and its influence on the body's immune function.
               
                  Materials and methods
                  
                     In vitro experiments on A549 and H1299 cells were performed using the CCK8 method; the proliferation and migration of cells were observed to investigate the wound healing effects of TFTM, and flow cytometry was used to detect the apoptotic rate of TFTM on lung cancer cells. In vivo experiments were preformed to establish a non-small cell lung cancer mouse model using subcutaneously transplanted Lewis cells, and the body weight and tumor growth of the mice were recorded. Hematoxylin and eosin staining was performed for tumor tissue to assess pathological changes. The thymus, spleen, and lungs were isolated for to calculate organ index. The CD4+, CD8+, and CD4+/CD8+ levels were detected in mouse spleen using flow cytometry, and IL-2, IL-3, IFN-γ, and TNF-α levels were determined in serum using enzyme-linked immunosorbent assay. Expressions of IL-2, IL-3, IFN-γ, and TNF-α were detected using quantitative real-time PCR in tumor tissues, and Ki67 expression was observed by immunofluorescence.
               
                  Results
                  At 24 h, TFTM (100 and 200 μg/mL) had the best inhibitory effect on the proliferation of A549 and H1299 cells. The cell migration rate significantly reduced (P < 0.01), and the tumor inhibition rate increased (P < 0.01) and promoted apoptosis (P < 0.01). The mouse thymus index significantly increased (P < 0.05) and mouse spleen index reduced (P < 0.05). The CD4+, CD8+, and CD4+/CD8+ levels in Lewis lung cancer mouse model increased, as did the levels of IL-2, IL-3, IFN-γ, and TNF-α in the serum and tumor of mice; Ki67 expression in tumor tissues significantly reduced (P < 0.01).
               
                  Conclusion
                  TFTM has an inhibitory effect on lung cancer. The mechanism may be that it improves the host's protective immune response by having a milder tumor growth inhibitory effect than cyclophosphamide.",health
10.1016/j.compeleceng.2021.107440,Journal,Computers and Electrical Engineering,scopus,2021-12-01,sciencedirect,Security and privacy-aware Artificial Intrusion Detection System using Federated Machine Learning,https://api.elsevier.com/content/abstract/scopus_id/85116891961,"Beyond 5G networks integrating 5G technology offer efficient services globally with sustainable higher capacity and much lower latency across various applications. Moving into the beyond 5G networks, edge intelligence solutions with data-driven machine learning algorithms and cybersecurity paradigms have become crucial among various real-time applications, including smart transportation, smart health, etc. Since the data gets transferred continuously from the edge devices to the dedicated computing in any edge computing environment, it experiences a higher risk of vulnerability and complexity measures. In this view, this paper firstly defines a federated machine learning mechanism for privacy-enhanced edge intelligence model Beyond 5G networks with Paillier Homomorphic Encryption and differential privacy. Secondly, an Artificial Immune Intrusion Detection System has been designed to monitor and classify the nodes resulting in an anomaly in the edge network so that the network can experience smooth and secure data transmission as per the requirement. The experiments and comparison results show that the proposed system is more optimal and secure than the existing edge security models.",health
10.1016/j.jneumeth.2021.109371,Journal,Journal of Neuroscience Methods,scopus,2021-12-01,sciencedirect,Development of deep learning models for microglia analyses in brain tissue using DeePathology™ STUDIO,https://api.elsevier.com/content/abstract/scopus_id/85116054792,"Background
                  Interest in artificial intelligence-driven analysis of medical images has seen a steep increase in recent years. Thus, our paper aims to promote and facilitate the use of this state-of-the-art technology to fellow researchers and clinicians.
               
                  New method
                  We present custom deep learning models generated in DeePathology™ STUDIO without the need for background knowledge in deep learning and computer science underlined by practical suggestions.
               
                  Results
                  We describe the general workflow in this commercially available software and present three real-world examples how to detect microglia on IBA1-stained mouse brain sections including their differences, validation results and analysis of a sample slide.
               
                  Comparison with existing methods
                  Deep-learning assisted analysis of histological images is faster than classical analysis methods, and offers a wide variety of detection possibilities that are not available using methods based on staining intensity.
               
                  Conclusions
                  Reduced researcher bias, increased speed and extended possibilities make deep-learning assisted analysis of histological images superior to traditional analysis methods for histological images.",health
10.1016/j.media.2021.102214,Journal,Medical Image Analysis,scopus,2021-12-01,sciencedirect,S-CUDA: Self-cleansing unsupervised domain adaptation for medical image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85113761483,"Medical image segmentation tasks hitherto have achieved excellent progresses with large-scale datasets, which empowers us to train potent deep convolutional neural networks (DCNNs). However, labeling such large-scale datasets is laborious and error-prone, which leads the noisy (or incorrect) labels to be an ubiquitous problem in the real-world scenarios. In addition, data collected from different sites usually exhibit significant data distribution shift (or domain shift). As a result, noisy label and domain shift become two common problems in medical imaging application scenarios, especially in medical image segmentation, which degrade the performance of deep learning models significantly. In this paper, we identify a novel problem hidden in medical image segmentation, which is unsupervised domain adaptation on noisy labeled data, and propose a novel algorithm named “Self-Cleansing Unsupervised Domain Adaptation” (S-CDUA) to address such issue. S-CUDA sets up a realistic scenario to solve the above problems simultaneously where training data (i.e., source domain) not only shows domain shift w.r.t. unsupervised test data (i.e., target domain) but also contains noisy labels. The key idea of S-CUDA is to learn noise-excluding and domain invariant knowledge from noisy supervised data, which will be applied on the highly corrupted data for label cleansing and further data-recycling, as well as on the test data with domain shift for supervised propagation. To this end, we propose a novel framework leveraging noisy-label learning and domain adaptation techniques to cleanse the noisy labels and learn from trustable clean samples, thus enabling robust adaptation and prediction on the target domain. Specifically, we train two peer adversarial networks to identify high-confidence clean data and exchange them in companions to eliminate the error accumulation problem and narrow the domain gap simultaneously. In the meantime, the high-confidence noisy data are detected and cleansed in order to reuse the contaminated training data. Therefore, our proposed method can not only cleanse the noisy labels in the training set but also take full advantage of the existing noisy data to update the parameters of the network. For evaluation, we conduct experiments on two popular datasets (REFUGE and Drishti-GS) for optic disc (OD) and optic cup (OC) segmentation, and on another public multi-vendor dataset for spinal cord gray matter (SCGM) segmentation. Experimental results show that our proposed method can cleanse noisy labels efficiently and obtain a model with better generalization performance at the same time, which outperforms previous state-of-the-art methods by large margin. Our code can be found at https://github.com/zzdxjtu/S-cuda.",health
10.1016/j.jenvman.2021.113594,Journal,Journal of Environmental Management,scopus,2021-12-01,sciencedirect,A hybrid computational intelligence approach for bioremediation of amoxicillin based on fungus activities from soil resources and aflatoxin B1 controls,https://api.elsevier.com/content/abstract/scopus_id/85113717787,"Nowadays, releasing the Emerging Pollutants (EPs) in the nature is one of the main reasons for many health and environmental disasters. Amoxicillin as an antibiotic is one of the EPs and categorized as the Endocrine Disrupting Compounds (EDCs) in hazardous materials. Accumulation of amoxicillin in the soil bulk increases the cancer risk, drug resistances and other epidemiological diseases. Hence, the soil bioremediation of antibiotics can be a solution for this problem which is more environmental-friendly system. This study technically creates a bio-engine setup in soil bulk for remediation of amoxicillin based on Aspergillus Flavus (AF) activities and Removal Percentage (RP) of amoxicillin with Aflatoxin B1 Generation (AG) controls. The main novelty is to propose a hybrid computational intelligence approach to do optimization for mechanical and biological aspects and to predict the behavior of bio-engine's effective mechanical and biological features in an intelligent way. The optimization model is formulated by the Central Composite Design (CCD) which is set by the Response Surface Methodology (RSM). The prediction model is formulated by the Random Forest (RF), Adaptive Neuro Fuzzy Inference System (ANFIS) and Random Tree (RT) algorithms. According to the experimental practices from real soil samples in different times and places, concentration of amoxicillin and Aflatoxin B1 are set equal to 25 mg/L (ppm) and 15 μg/L (ppb). Likewise, the outcomes of experiments in CCD-RSM computations are evaluated by curve fitting comparisons between linear, 2FI, quadratic and cubic polynomial equations with considering to regression coefficient and predicted regression coefficient values, ANOVA and optimization by sequential differentiation. Based on the results of CCD-RSM, the RP performance in the optimum conditions is measured around 86% and in 25 days after runtime, the RP and AG are balanced in the safe mode. The proposed hybrid model achieves the 0.99 accuracy. The applicability of the research is done using real field evaluations from drug industrial park in Mashhad city in Iran. Finally, a broad analysis is done and managerial insights are concluded. The main findings of the present research are: (I) with application of bioremediation from fungus activities, amoxicillin amounts can be control in soil resources with minimum AG, (II) ANFIS model has the best accuracy for smart monitoring of amoxicillin bioremediation in soil environments and (III) based on the statistical assessments Aeration Intensity and AF/Biological Waste ratio are most effective on the amoxicillin removal percentage.",health
10.1016/j.irbm.2021.06.010,Journal,IRBM,scopus,2021-12-01,sciencedirect,Backpropagation Neural Network for Processing of Missing Data in Breast Cancer Detection,https://api.elsevier.com/content/abstract/scopus_id/85110572168,"Background
                  A complete dataset is essential for biomedical implementation. Due to the limitation of objective or subjective factors, missing data often occurs, which exerts uncertainty in the subsequent data processing. Commonly used methods of interpolation are interpolating substitute values that keep minimum error. Some applications of statistics are usually used for handling this problem.
               
                  Methods
                  We are trying to find a higher performance interpolation method compared with the usual statistic methods, by using artificial intelligence which is in full swing today. The prediction and classification of backpropagation neural network are used in this paper, describes a missing data interpolation method to propose the interpolation model that mines association rules in the data. In the experiment, depending on a multi-layer network structure, the model is trained and tested by sample data, constantly revises network weights and thresholds. The error function decreases along the negative gradient direction and approaches the expected real output. The model is validated on the breast cancer dataset, and we select real samples from the data set for validation, moreover, add four traditional methods as a control group.
               
                  Results
                  The proposed method has great performance improvement in the interpolation of missing data. Experimental results show that the interpolation accuracy of our proposed method (84%) is higher than four traditional methods (1.33%, 74.67%, 73.33%, 77.33%) as mentioned in this paper, BPNN stays low in MSE evaluation. Finally, we analyze the performance of various methods in processing missing data.
               
                  Conclusions
                  The study in this paper has estimated missing data with high accuracy as much as possible to reduce the negative impact in the diagnosis of real life. At the same time, it can also assist in missing data processing in the biomedical field.",health
10.1016/j.jii.2021.100234,Journal,Journal of Industrial Information Integration,scopus,2021-12-01,sciencedirect,Effective multilayer hybrid classification approach for automatic bridge health assessment on large-scale uncertain data,https://api.elsevier.com/content/abstract/scopus_id/85110430509,"The health level of the bridge is critical to the safety and maintainability of the bridge. However, with the rapid increase of bridge data with complex information, manual evaluation of bridge health requires high labor and time costs and a lot of related knowledge. Meanwhile, due to the error of sensors and subjective judgment of experts, as well as the influence of the external environment of the bridge, there is great uncertainty in the evaluation of the bridge data. Thence, how to use a large amount of bridge data with large-scale uncertain labels to build a robust classification model for efficient and high-quality bridge health assessment has become an urgent task. In order to better assess the health of the bridge, we adopt a multi-layer hybrid method to iteratively determine the uncertain labels of the target dataset, evaluate the confidence of the large-scale uncertain labels, add high-confidence data to the training set, and correct the low-confidence data. Finally, we get an effective classification model with the optimized training dataset. This paper studies the learning problem of classification model on labeled data with large-scale uncertain labels, and proposes an effective hybrid classification model (HCM), which can establish a supervised classifier under the condition of detecting uncertain labels and realize error label correction. In order to measure the HCM label assignment problem, we introduce a new penalty function, which can evaluate the label consistency problem of two basic classifiers. Meanwhile, we apply the model to bridge data with uncertain labels for bridge health evaluation. Experiments conducted on synthetic data, benchmark data and real bridge datasets show that the proposed method is superior to other methods and provides an effective and convenient solution for bridge health assessment. At the same time, this method can also be used in other research fields where there are large-scale uncertain labels.",health
10.1016/j.ymssp.2021.107955,Journal,Mechanical Systems and Signal Processing,scopus,2021-12-01,sciencedirect,A novel percussion-based method for multi-bolt looseness detection using one-dimensional memory augmented convolutional long short-term memory networks,https://api.elsevier.com/content/abstract/scopus_id/85104439984,"In the past decade, bolt looseness detection has attracted much attention. Compared to common approaches that require the implementation of constant-contact sensors, several percussion-based methods have demonstrated their superiorities, including low-cost and easy-to-operate, in detecting bolt looseness. However, some drawbacks may impede the further real-world application of percussion-based methods in detecting bolt looseness. First, current percussion-based methods depend on hand-crafted features, which require the extensive experience of operators. In addition, the ability of current percussion-based methods in anti-noising and adaptability is unknown, since no related investigation has been conducted. Moreover, only single-bolt looseness is considered in the current percussion-based investigation. With these deficiencies in mind, in this paper, we propose a novel percussion-based method that uses a newly developed one-dimensional memory augmented convolutional long short-term memory (1D-MACLSTM) networks. Via the convolutional operation in the 1D-MACLSTM, we can avoid manual feature extraction, and the long short-term memory (LSTM) controller backed by external memory can enhance the ability of anti-noising and adaptability. Finally, three case studies are conducted on a pair of typical multi-bolt connections to verify the effectiveness of the proposed method, which has better performance than current percussion-based methods, particularly in a noisy environment and new scenarios.",health
10.1016/j.enconman.2021.114667,Journal,Energy Conversion and Management,scopus,2021-11-15,sciencedirect,Photovoltaic mono and bifacial module/string electrical model parameters identification and validation based on a new differential evolution bee colony optimizer,https://api.elsevier.com/content/abstract/scopus_id/85116895926,"Well estimating the electrical model parameters of the photovoltaic (PV) module/string serves to develop an accurate simulator and a fault diagnosis tool. Several based evolutionary techniques were proposed to identify the unknown circuit equivalent PV generator (PVG) parameters. Whereas most of them have not been examined to various real operating conditions of solar irradiance and PV cells temperature. That requires larger search range than the adopted one in the literature. Enlarging the search range imposes more computational time and high exploration and exploitation features. Hence, a novel hybrid differential evolution and artificial bee colony intelligence (nDEBCO) approach is proposed. In terms of convergence quality, CPU execution time, number of function evaluations (NFE), and error standard deviation (StD). The newly developed approach permits to accurately identify the PV module/string unknown parameters with suitable implementation complexity. Mono-facial CLS 220P PV string has been utilized employing an adequate experimental setup with online implementation. 1080 I-V curves have been measured and estimated, where the overall RMSE ± StD is below 0.02 ± 1e−16. The nDEBCO outperforms the present-day published works, for common case studies in the literature with two based root mean square error (RMSE) objective functions namely Lambert W function (LWF) and classic. It yields 7.73006268e− 4 of RMSE, 7.8785e− 18 of StD, and 2150 NFE under ODM with LWF for RTC France PV cell. Bifacial PV module has been evaluated and the electrical parameters have been extracted within less than 1.36 s of CPU run time and not>8.0299631e− 3 ± 6.9096e− 16 of RMSE ± StD for front and rear faces. Additionally, the parameter identification procedure has been well validated to simulate the real partial shading scenarios of the studied PV string with a RMSE less than 0.045 and 0.397% of power maximum point absolute error.",health
10.1016/j.bios.2021.113486,Journal,Biosensors and Bioelectronics,scopus,2021-11-15,sciencedirect,A mask-based diagnostic platform for point-of-care screening of Covid-19,https://api.elsevier.com/content/abstract/scopus_id/85109504460,"Diagnostics of SARS-CoV-2 infection using real-time reverse-transcription polymerase chain reaction (RT-PCR) on nasopharyngeal swabs is now well-established, with saliva-based testing being lately more widely implemented for being more adapted for self-testing approaches. In this study, we introduce a different concept based on exhaled breath condensate (EBC), readily collected by a mask-based sampling device, and detection with an electrochemical biosensor with a modular architecture that enables fast and specific detection and quantification of COVID-19. The face mask forms an exhaled breath vapor containment volume to hold the exhaled breath vapor in proximity to the EBC collector to enable a condensate-forming surface, cooled by a thermal mass, to coalesce the exhaled breath into a 200–500 μL fluid sample in 2 min. EBC RT-PCR for SARS-CoV-2 genes (E, ORF1ab) on samples collected from 7 SARS-CoV-2 positive and 7 SARS-CoV-2 negative patients were performed. The presence of SARS-CoV-2 could be detected in 5 out of 7 SARS-CoV-2 positive patients. Furthermore, the EBC samples were screened on an electrochemical aptamer biosensor, which detects SARS-CoV-2 viral particles down to 10 pfu mL−1 in cultured SARS-CoV-2 suspensions. Using a “turn off” assay via ferrocenemethanol redox mediator, results about the infectivity state of the patient are obtained in 10 min.",health
10.1016/j.cmpb.2021.106460,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,Multi-Modality guidance based surgical navigation for percutaneous endoscopic transforaminal discectomy,https://api.elsevier.com/content/abstract/scopus_id/85118353932,"Objective
                  Fluoroscopic guidance is a critical step for the puncture procedure in percutaneous endoscopic transforaminal discectomy (PETD). However, two-dimensional observations of the three-dimensional anatomic structure suffer from the effects of projective simplification. To accurately assess the spatial relations between the patient vertebra tissues and puncture needle, a considerable number of fluoroscopic images from different orientations need to be acquired by the surgeons. This process significantly increases the radiation risk for both the patient and surgeons.
               
                  Methods
                  In this paper, we propose an augmented reality (AR) surgical navigation system for PETD based on multi-modality information, which contains fluoroscopy, optical tracking, and depth camera. To register the fluoroscopic image with the intraoperative video, we design a lightweight non-invasive fiducial with markers and detect the markers based on the deep learning method. It can display the intraoperative video fused with the registered fluoroscopic images. We also present a self-adaptive calibration and transformation method between a 6-DOF optical tracking device and a depth camera, which are in different coordinate systems.
               
                  Results
                  With the substantially reduced frequency of fluoroscopy imaging, the system can accurately track and superimpose the virtual puncture needle on fluoroscopy images in real-time. From operating theatre in vivo animal experiments, the results illustrate that the system average positioning accuracy can reach 1.98mm and the orientation accuracy can reach 1.19
                        
                           
                           ∘
                        
                     . From the clinical validation results, the system significantly lower the frequency of fluoroscopy imaging (42.7%) and reduce the radiation risk for both the patient and surgeons.
               
                  Conclusion
                  Coupled with the user study, both the quantitative and qualitative results indicate that our navigation system has the potential to be highly useful in clinical practice. Compared with the existing navigation systems, which are usually equipped with a variety of large and high-cost medical equipments, such as O-arm, cone-beam CT, and robots, our navigation system does not need special equipment and can be implemented with common equipment in the operating room, such as C-arm, desktop, etc., even in small hospitals.",health
10.1016/j.cmpb.2021.106464,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,Deep embeddings and logistic regression for rapid active learning in histopathological images,https://api.elsevier.com/content/abstract/scopus_id/85118333751,"Background and Objective
                  Recognizing different tissue components is one of the most fundamental and essential works in digital pathology. Current methods are often based on convolutional neural networks (CNNs), which need numerous annotated samples for training. Creating large-scale histopathological datasets is labor-intensive, where interactive data annotation is a potential solution.
               
                  Methods
                  We propose DELR (Deep Embedding-based Logistic Regression) to enable rapid model training and inference for histopathological image analysis. DELR utilizes a pretrained CNN to encode images as compact embeddings with low computational cost. The embeddings are then used to train a Logistic Regression model efficiently. We implemented DELR in an active learning framework, and validated it on three histopathological problems (binary, 4-category, and 8-category classification challenge for lung, breast, and colorectal cancer, respectively). We also investigated the influence of active learning strategy and type of the encoder.
               
                  Results
                  On all the three datasets, DELR can achieve an area under curve (AUC) metric higher than 0.95 with only 100 image patches per class. Although its AUC is slightly lower than a fine-tuned CNN counterpart, DELR can be 536, 316, and 1481 times faster after pre-encoding. Moreover, DELR is proved to be compatible with a variety of active learning strategies and encoders.
               
                  Conclusions
                  DELR can achieve comparable accuracy to CNN with rapid running speed. These advantages make it a potential solution for real-time interactive data annotation.",health
10.1016/j.jprocont.2021.10.006,Journal,Journal of Process Control,scopus,2021-11-01,sciencedirect,OASIS-P: Operable Adaptive Sparse Identification of Systems for fault Prognosis of chemical processes,https://api.elsevier.com/content/abstract/scopus_id/85118170677,"With the increasing process complexities, data-driven fault prognosis has emerged as a promising fault management tool that predicts and manages abnormal events well in advance. In this paper, we develop a fault prognosis framework named ‘OASIS-P’ by integrating operable adaptive sparse identification of systems (OASIS), which is a data-driven adaptive modeling technique, with a risk-based process monitoring approach and contribution plots. Firstly, OASIS is employed with the risk assessment procedure for the prediction of impending faults. As the OASIS model is adaptive, it copes with the initial fault symptoms and forecasts the future behavior of the process under faulty conditions reasonably well, thereby providing an early fault prediction. Next, the fault isolation step is immediately initiated using contribution plots to identify the faulty variables. Unlike in fault diagnosis, the problem of ambiguity in interpreting contribution results due to fault propagation is not an issue in fault prognosis, if the fault isolation step is implemented at an early stage of the fault before it affects the other variables. Hence, the contribution plots together with OASIS can proactively monitor the process in real-time. As a case study, we demonstrate OASIS-P for fault prognosis of a reactor–separator system.",health
10.1016/j.cmpb.2021.106448,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,MBNM: Multi-branch network based on memory features for long-tailed medical image recognition,https://api.elsevier.com/content/abstract/scopus_id/85117201482,"Background and objectives
                  Deep learning algorithms show revolutionary potential in computer-aided diagnosis. These computer-aided diagnosis techniques often rely on large-scale, balanced standard datasets. However, there are many rare diseases in real clinical scenarios, which makes the medical datasets present a highly imbalanced long-tailed distribution, leading to the poor generalization ability of deep learning models. Currently, most algorithms to solve this problem involve more complex modules and loss functions. But for complicated tasks in the medical domain, usually suffer from issues such as increased inference time and unstable performance. Therefore, it is a great challenge to develop a computer-aided diagnosis algorithm for long-tailed medical data.
               
                  Methods
                  We proposed the Multi-Branch Network based on Memory Features (MBNM) for Long-Tailed Medical Image Recognition. MBNM includes three branches, where each branch focuses on a different learning task: 1) the regular learning branch learns the generalizable feature representations; 2) the tail learning branch gains extra intra-class diversity for the tail classes through the feature memory module and the improved reverse sampler to improve the classification performance of the tail classes; 3) the fusion balance branch integrates various decision-making advantages and introduces an adaptive loss function to re-balance the classification performance of easy and difficult samples.
               
                  Results
                  We conducted experiments on the multi-disease Ophthalmic OCT datasets with imbalance factors of 98.48 and skin image datasets Skin-7 with imbalance factors of 58.3. The Accuracy, MCR, F1-Score, Precision, and AUC of our model were significantly improved over the strong baselines in the auxiliary diagnosis scenario where the clinical medical data is extremely imbalanced. Furthermore, we demonstrated that MBNM outperforms the state-of-the-art models on the publicly available natural image datasets (CIFAR-10 and CIFAR-100).
               
                  Conclusions
                  The proposed algorithm can solve the problem of imbalanced data distribution with little added cost. In addition, the memory module does not act in the inference phase, thereby saving inference time. And it shows outstanding performance on medical images and natural images with a variety of imbalance factors.",health
10.1016/j.jbi.2021.103922,Journal,Journal of Biomedical Informatics,scopus,2021-11-01,sciencedirect,Predicting potential palliative care beneficiaries for health plans: A generalized machine learning pipeline,https://api.elsevier.com/content/abstract/scopus_id/85116551006,"Recognizing that palliative care improves the care quality and reduces the healthcare costs for individuals in their end of life, health plan providers strive to better enroll the appropriate target population for palliative care. Current research has not adequately addressed challenges related to proactively select potential palliative care beneficiaries from a population health perspective. This study presents a Generalized Machine Learning Pipeline (GMLP) to predict palliative needs in patients using administrative claims data. The GMLP has five steps: data cohort creation, feature engineering, predictive modeling, scoring beneficiaries, and model maintenance. It encapsulates principles of population health management, business domain knowledge, and machine learning (ML) process knowledge with an innovative data pull strategy. The GMLP was applied in a regional health plan using a data cohort of 17,197 patients. Multiple ML models were turned and evaluated against a custom performance metric based on the business requirement. The best model was an AdaBoost model with a precision of 71.43% and a recall of 67.98%. The post-implementation evaluation of the GMLP showed that it increased the recall of high mortality risk patients, improved their quality of life, and reduced the overall cost. The GMLP is a novel approach that can be applied agnostically to the data and specific ML algorithms. To the best of our knowledge, it is the first attempt to continuously score palliative care beneficiaries using administrative data. The GMLP and its use case example presented in the paper can serve as a methodological guide for different health plans and healthcare policymakers to apply ML in solving real-world clinical challenges, such as palliative care management and other similar risk-stratified care management workflows.",health
10.1016/j.cmpb.2021.106433,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,End-to-end multimodal clinical depression recognition using deep neural networks: A comparative analysis,https://api.elsevier.com/content/abstract/scopus_id/85116079993,"Background and Objective: Major Depressive Disorder is a highly prevalent and disabling mental health condition. Numerous studies explored multimodal fusion systems combining visual, audio, and textual features via deep learning architectures for clinical depression recognition. Yet, no comparative analysis for multimodal depression analysis has been proposed in the literature. Methods: In this paper, an up-to-date literature overview of multimodal depression recognition is presented and an extensive comparative analysis of different deep learning architectures for depression recognition is performed. First, audio features based Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) are studied. Then, early-level and model-level fusion of deep audio features with visual and textual features through LSTM and CNN architectures are investigated. Results: The performance of the proposed architectures using an hold-out strategy on the DAIC-WOZ dataset (
                        
                           80
                           %
                        
                      training, 
                        
                           10
                           %
                        
                      validation, 
                        
                           10
                           %
                        
                      test split) for binary and severity levels of depression recognition is tested. Using this strategy, a set of experiments have been performed and they have demonstrated: (1) LSTM-based audio features perform slightly better than CNN ones with an accuracy of 
                        
                           66.25
                           %
                        
                      versus 
                        
                           65.60
                           %
                        
                      for binary depression classes. (2) the model level fusion of deep audio and visual features using LSTM network performed the best with an accuracy of 
                        
                           77.16
                           %
                        
                     , a precision of 
                        
                           53
                           %
                        
                      for the depressed class, and a precision of 
                        
                           83
                           %
                        
                      for the non-depressed class. The given network obtained a normalized Root Mean Square Error (RMSE) of 0.15 for depression severity level prediction. Using a Leave-One-Subject-Out strategy, this network achieved an accuracy of 
                        
                           95.38
                           %
                        
                      for binary depression detection, and a normalized RMSE of 0.1476 for depression severity level prediction. Our best-performing architecture outperforms all state-of-the-art approaches on DAIC-WOZ dataset. Conclusions: The obtained results show that the proposed LSTM-based surpass the proposed CNN-based architectures allowing to learn temporal dynamics representations of multimodal features. Furthermore, model-level fusion of audio and visual features using an LSTM network leads to the best performance. Our best-performing architecture successfully detects depression using a speech segment of less than 8 seconds, and an average prediction computation time of less than 
                        
                           6
                           m
                           s
                        
                     ; making it suitable for real-world clinical applications.",health
10.1016/j.psep.2021.09.008,Journal,Process Safety and Environmental Protection,scopus,2021-11-01,sciencedirect,Graph convolutional networks based contamination source identification across water distribution networks,https://api.elsevier.com/content/abstract/scopus_id/85115991403,"Water distribution Networks (WDNs) are one of the most important infrastructures for modern society. Due to accidental or malicious reasons, water contamination incidents have been repeatedly reported all over the world, which not only disrupt the water supply but also endanger public health. To ensure the safety of WDNs, water quality sensors are deployed across the WDNs for real-time contamination detection and source identification. In the literature, various methods have been employed to improve the performance of contamination source identification (CSI) and recent studies show that there is a great potential to tackle the CSI problem by deep learning models. The success of deep learning based CSI methods often requires a large size of training samples being collected. In real-world situations, the number of contamination events occurring in a single WDN is rather small, especially for a newly built WDN. However, the existing CSI methods in the literature mostly focus on the study of training and applying models on the same WDNs and the knowledge of CSI gained from one WDN cannot be reused by a different WDN. To these ends, based on the application of graph convolutional networks, this paper provides a solution for cross-network CSI that can transfer the CSI knowledge learned from one WDN to a different WDN. Empirically, based on a benchmark WDN in the task of contamination source identification, we show that the proposed cross-network CSI method can achieve comparable accuracy even trained on a different WDN.",health
10.1016/j.jviromet.2021.114272,Journal,Journal of Virological Methods,scopus,2021-11-01,sciencedirect,A rapid and simple protocol for concentration of SARS-CoV-2 from sewage,https://api.elsevier.com/content/abstract/scopus_id/85113952280,"The aim of this study was to set up a simple protocol to concentrate SARS-CoV-2 from sewage, which can be implemented in laboratories with minimal equipment resources. The method avoids the need for extensive purification steps and reduces the concentration of potential inhibitors of RT-qPCR contained in sewage. The concentration method consists of a single step, in which a small volume (40 mL) of sewage sample is incubated with polyaluminum chloride (PAC)(0.00045 N Al3+ final concentration). Virus particles adsorbed to the precipitate are collected by low-speed centrifugation, after which the recovered pellet is resuspended with a saline buffer. PAC-concentrated samples are stable for at least one week at 4 °C. Therefore, they may be sent refrigerated to a diagnosis center for RNA extraction and RT-qPCR for SARS-CoV-2 RNA detection if the lab does not have such capabilities. The PAC concentration method produced an average shift of 4.5-units in quantification cycle (Cq) values compared to non-concentrated samples, indicating a 25-fold increase in detection sensitivity. The lower detection limit corresponded approximately to 100 viral copies per ml. Kappa index indicated substantial agreement between PAC and polyethylene glycol (PEG) precipitation protocols (k = 0.688, CI 0.457−0.919). This low-cost concentration protocol could be useful to aid in the monitoring of community circulation of SARS-CoV-2, especially in low- and middle-income countries, which do not have massive access to support from specialized labs for sewage surveillance.",health
10.1016/j.ins.2021.08.016,Journal,Information Sciences,scopus,2021-11-01,sciencedirect,Deep dynamic imputation of clinical time series for mortality prediction,https://api.elsevier.com/content/abstract/scopus_id/85113217555,"Missing values in clinical time-series data are pervasive and inevitable; they not only increase the complexity and difficulty of analyzing the data but also lead to biased results. To tackle these two problems, researchers have been exploring recurrent neural network (RNN)-based methods for detecting how well missing values are addressed with the aim of achieving state-of-the-art performance. However, these methods have two practical drawbacks. 1) Handling time-series data with multiple, irregular, abnormal values is difficult. 2) The patterns that may be present in the missing clinical data are not thoroughly considered. Moreover, to the best of our knowledge, none of these methods have been explicitly designed to dynamically optimize the imputation quality for better performance in the realm of clinical time-series analytics. By considering the quality of imputed values, we propose a 2-step integrated imputation-prediction model based on gated recurrent units (GRUs) for medical prediction tasks. In the first step, the missing values are imputed using a sophisticated model based on a replenished GRU with a hidden state decay mechanism (RGRU-D), which is followed by evaluation through two additional layers. In the second step, the optimized imputed values are used to predict the risk of mortality in critical patients. Our model effectively supplies missing values for the masking, time interval, bursty, and cumulative missing rate variables within an integrated deep architecture. Extensive experiments on a real-world ICU dataset demonstrate that our model performs better than the compared methods in terms of the imputation quality and prediction accuracy.",health
10.1016/j.precisioneng.2021.08.010,Journal,Precision Engineering,scopus,2021-11-01,sciencedirect,A method for predicting hobbing tool wear based on CNC real-time monitoring data and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85112751582,"Intelligent monitoring and diagnosis of tool status are of great significance for improving the manufacturing efficiency and accuracy of the workpiece. It is difficult to quickly and accurately predict the wear state of worm gear hob under different working conditions. This paper proposes a novel approach to predict hob wear status based on CNC real-time monitoring data. Based on the open platform communication unified architecture (OPC UA) technology and orthogonal test, the machine data of motor power, current, etc. related to tool wear are collected online in the worm gear machining process. And then, an improved deep belief network (DBN) is used to generate a tool wear model by training data. A growing DBN with transfer learning is introduced to automatically decide its best model structure, which can accelerate its learning process, improve training efficiency and model performance. The experiment results show that the proposed method can effectively predict hob wear status under multi-cutting conditions. To show the advantages of the proposed approach, the performance of the DBN is compared with the traditional back propagation neural network (BP) method in terms of the mean-squared error (MSE). The compared results show that this tool wear prediction method has better prediction accuracy than the traditional BP method during worm gear hobbing.",health
10.1016/j.ins.2021.08.009,Journal,Information Sciences,scopus,2021-11-01,sciencedirect,"Three-way decision and conformal prediction: Isomorphisms, differences and theoretical properties of cautious learning approaches",https://api.elsevier.com/content/abstract/scopus_id/85112505225,"The aim of this article is to study the relationship between two popular Cautious Learning approaches, namely: Three-way decision (TWD) and conformal prediction (CP). Based on the novel proposal of a technique to transform three-way decision classifiers into conformal predictors, and vice versa, we provide conditions for the equivalence between TWD and CP. These theoretical results provide error-bound guarantees for TWD, together with a formal construction to define cost-sensitive cautious classifiers based on CP. The proposed techniques are then applied and evaluated on a collection of benchmark and real-world datasets. The results of the experiments show that the proposed techniques can be used to obtain cautious learning classifiers that are competitive with, and often out-perform, state-of-the-art approaches. Further, through a qualitative medical case study we discuss the usefulness of cautious learning in the development of robust Machine Learning.",health
10.1016/j.scs.2021.103215,Journal,Sustainable Cities and Society,scopus,2021-11-01,sciencedirect,IoHT-enabled gliomas disease management using fog Computing computing for sustainable societies,https://api.elsevier.com/content/abstract/scopus_id/85111854275,"The proliferation of sensor-based applications in healthcare has given rise to Internet of Health Things (IoHT) that improves patient safety, staff morale, and operational efficiency. Edge-fog computing has seen significant development in recent years and supports the association of various intelligent things with sensors for establishing smooth data transfer. However, it becomes challenging for edge-fog computing to tackle diverse IoHT settings such as efficient disease management, emergency response management, etc. The key limitation of existing architectures is the restricted scalability and inability to meet the demands of hierarchical computing environments for IoHT. This is because latency-sensitive applications often require large quantities of data to be measured and transferred to the data centers, which causes delay and reduced output. This research proposes a novel edge-fog computing framework for the convergence of machine learning ensemble with edge-fog computing. The proposed architecture delivers healthcare as a fog system that handles data from different sources to manage the diseases effectively. The proposed framework is used for the real-life implementation and automatic detection of gliomas diseases. Glioma is a kind of tumor, which ensues in the spinal cord and a portion of the brain. Glioma instigates in the glial cells that surround the nerve cells. The proposed edge-fog framework efficiently manages the real-time data related to gliomas. This framework is configured for specific operating modes including diverse edge-fog scenarios, different user requirements, quality of service, precision, and predictive accuracy. The proposed framework is evaluated using real-time datasets from various sources and experimentally tested with reliable datasets that disclose the effectiveness of the proposed architecture. The performance of the proposed model is evaluated in terms of power consumption, latency, accuracy, and execution time, respectively.",health
10.1016/j.jenvman.2021.113387,Journal,Journal of Environmental Management,scopus,2021-11-01,sciencedirect,Nitrate removal from groundwater using a batch and continuous flow hybrid Fe-electrocoagulation and electrooxidation system,https://api.elsevier.com/content/abstract/scopus_id/85111287126,"During the last two decades nitrate contaminated groundwater has become an extensive worldwide problem with wide-reaching negative effects on human health and the environment. In this study, a combination of electrocoagulation (EC) and electrooxidation (EO) was studied as a denitrification process to efficiently remove nitrates and ammonium (a by-product produced during EC) from real polluted groundwater. Initially, EC experiments under batch operating mode were performed using iron electrodes at different applied current density values (20–40 mA cm−2). Nitrate percentage removal of 100 % was recorded, however high ammonium concentrations were performed (4.5–6.5 mg NH4
                     +-Ν L−1). Therefore, a continuous flow system was examined for the complete removal of both nitrates and EC-generated ammonium cations. The system comprised an EC reactor, a settling tank and an EO reactor. The applied current densities to the EC process were the same as those in the batch experiments, while the volumetric flow rates were 4, 6 and 8 mL min−1. Regarding the current density of the EO process was kept constant at the value of 75 mA cm−2. The percentage nitrate removal recorded during the EC process ranged between 52.0 and 100 %, while the NH4
                     +-N concentration at the outlet of the EO reduced significantly (53–100 %) depending on the applied current density and the volumetric flow rate. Also, the dissolved iron concentration in the treated water was always below the legislated limit of 0.2 mg L−1 (up to 0.027 mg L−1). These results indicate that the proposed hybrid system is capable of denitrifying real nitrate contaminated groundwater without generating toxic by-products, therefore making the water suitable for human consumption.",health
10.1016/j.actaastro.2021.07.012,Journal,Acta Astronautica,scopus,2021-11-01,sciencedirect,"A review of space surgery - What have we achieved, current challenges, and future prospects",https://api.elsevier.com/content/abstract/scopus_id/85110745640,"Major surgical events/incidents onboard are rare but can be catastrophic to any mission. National Aeronautics and Space Administration (NASA) uses the Integrated Medical Model (IMM) to develop an integrated, quantified, evidence-based decision support tool useful for crew health and mission planners to assess risk and design medical systems. In 2017, the IMM of the NASA Human Research Program included a list of 100 medical conditions that could be anticipated during space flight. Of those conditions, 27 are expected to need surgical treatment. Consequently, there has been a continuing interest in surgical capabilities for exploration space flight. The surgical system capabilities aboard all space stations and analogue flights have been designed and implemented with an emphasis on stabilisation, medical evacuation, and ATLS capabilities. However, with future missions to the Moon and Mars, evacuation is not a possibility and astronauts will need to troubleshoot, adapt, and self-administer complex surgical care autonomously.
                  This narrative review aims to examine the published work on surgical care in space, discuss the inherent challenges, and identify scope for future studies. The review evaluates and analyses results from several landmark experiments covering important technical aspects such as basic surgical skills, laparoscopic surgery, robotic surgery, and tele surgery. Relevant studies for the review were identified from the MEDLINE, PubMed, and EMBASE databases. Eligible studies were published between 1960 and June 2021 and were identified using the terms “space surgery”, “microgravity”, “zero gravity”, “weightlessness”, “parabolic flight”, “neutral buoyancy”, and “spaceflight”. Only articles in English were selected and references cited in the selected publications were followed up and included where appropriate. Documents available in the public domain and/or archives of National Space agencies were also included. The search yielded a total of 86 hits including review articles, commentaries, studies, meeting summaries and technical reports submitted to National Space agencies. Results were then filtered for eligible papers relevant to this narrative review. Challenges on a long-duration mission will be unique, unlike anything we have faced so far in the last 60 years of space travel. Despite the progress in space surgery in the last 40 years, there are several challenges to achieving a fully functional surgical care system on any mission outside Low Earth Orbit. The microgravity environment presents unique challenges related to altered physiology as well as mechanics and techniques pertinent to surgical care. Some of the challenges include but are not limited to crew selection, role of prophylactic surgery, adaptation to zero gravity, lack of ground support, training and maintenance of surgical skills and limitation of weight and volume for hardware. Ultrasound imaging, 3D printing and AI-based surgical assistance coupled with robotic surgery have shown promise, but their real efficacy and functionality remains to be tested.",health
10.1016/j.nima.2021.165681,Journal,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",scopus,2021-10-11,sciencedirect,Separation of dual-tracer PET signals using a deep stacking network,https://api.elsevier.com/content/abstract/scopus_id/85111663091,"In this study, a method based on a deep stacking network is proposed to solve the signal separation problem of dynamic dual-tracer PET. The advantage of this method is that it avoids requirements for prior information of tracers, and a staggered injection. The proposed model is pre-trained with restricted Boltzmann machines and fine-tuned in a manner, which the output of the last training epoch was used as additional input in the current epoch to update the model parameters. We train the network to learn the complex relationship between dual-tracer time-activity curves and separated single tracer data using a mean square error objective function. Monte Carlo simulations are employed to test the accuracy and robustness of the proposed method on the total counts and reconstruction algorithm. Quantification results show that the proposed method outperforms the existing approach. Experiments with real data further validate previous results on synthetic data.",health
10.1016/j.artmed.2021.102151,Journal,Artificial Intelligence in Medicine,scopus,2021-10-01,sciencedirect,Optimizing the setting of medical interactive rehabilitation assistant platform to improve the performance of the patients: A case study,https://api.elsevier.com/content/abstract/scopus_id/85114984743,"Tele-rehabilitation is an alternative to the conventional rehabilitation service that helps patients in remote areas to access a service that is practical in terms of logistics and cost, in a controlled environment. It includes the usage of mobile phones or other wireless devices that are applied to rehabilitation exercises. Such applications or software include exercises in the form of virtual games, treatment monitoring based on the rehabilitation progress and data analysis. However, nowadays, physiotherapists use a default profiling setting for patients carrying out rehabilitation, due to lack of information. Medical Interactive Rehabilitation Assistant (MIRA) is a computer-based (virtual reality) rehabilitation platform. The profile setting includes: a level of difficulty, percentage of tolerance and maximum range. To the best of our knowledge, there is a lack of optimization in the parameter values setting of MIRA exergames that could enhance patients' performance. Generally, non-optimal profile setting leads to reduced effectiveness. Therefore, this study aims to develop a method that optimizes the profile setting of each patient according to the estimated (desired) optimal results. The proposed method is developed using unsupervised and supervised machine learning techniques. We use Self-Organizing Map (SOM) to cluster patient records into several distinct clusters. K-fold cross validation is applied to construct the prediction models. Classification And Regression Tree (CART) is utilized to predict the patient's optimal input setting for playing the MIRA games. The combination of these techniques seems to improve the efficiency of the standard (default) way in predicting the optimal settings for exergames. To evaluate the proposed method, we conduct an experiment with data collected from a rehabilitation center. We use three metrics to quantify the quality of the results: R-squared (R2), Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The results of experimental analysis demonstrate that the proposed method is effective in predicting the adequate parameter setting in MIRA platform. The method has potential to be implemented as an intelligent system for MIRA prediction in healthcare. Moreover, the method could be extended to similar platforms for which data is available to train our method on.",health
10.1016/j.cmpb.2021.106379,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-10-01,sciencedirect,MFB-LANN: A lightweight and updatable myocardial infarction diagnosis system based on convolutional neural networks and active learning,https://api.elsevier.com/content/abstract/scopus_id/85114670974,"Background and objectives: 12 leads electrocardiogram (ECG) are widely used to diagnose myocardial infarction (MI). Generally, the symptoms of MI can be reflected by waveforms in the heartbeat, and the contribution of different ECG leads to different types of MI is different. Therefore, it is significant to use the heartbeat waveform features and the lead relationship features for multi-category MI diagnosis. Moreover, the challenge of individual differences and lightweight algorithms also need to be further resolved and explored in the ECG automatic diagnosis system.
                  
                     Methods: This paper presents a lightweight MI diagnosis system named multi-feature-branch lead attention neural network (MFB-LANN) via 12 leads ECG signals. It is designed based on the characteristics of the ECG lead. Specifically, 12 independent feature branches correspond to different leads, and each branch contains different convolutional layers to extract features in the heartbeat, then a novel attention module is developed named lead attention mechanism (LAM) to assign different weights to each feature branch. Finally all the weighted feature branches are fused for classification. Furthermore, to overcome individual differences, patient-specific scheme and active learning (AL) are used to train and update the model iteratively.
                  
                     Results: Experimental results based on Physikalisch-Technische Bundesanstalt (PTB) database shows that the MFB-LANN achieved satisfactory results with accuracy of 99.63% based on 5-fold cross validation under the intra-patient scheme. The patient-specific experiment yielded an average accuracy of 96.99% compared to the state-of-the-art. By contrast, the model achieved acceptable results on the hybrid database (PTB and PTB-XL), especially achieving 94.19% accuracy after the update. Moreover, the system can complete the update process and real-time diagnosis on the ARM Cortex-A72 platform.
                  
                     Conclusions: Experiments show that the proposed method for MI diagnosis has more obvious advantages compared to other recent methods, and it has great potential to be applied to the mobile medical field.",health
10.1016/j.ejon.2021.102023,Journal,European Journal of Oncology Nursing,scopus,2021-10-01,sciencedirect,Developing and validating a prediction model for lymphedema detection in breast cancer survivors,https://api.elsevier.com/content/abstract/scopus_id/85114224581,"Purpose
                  Early detection and intervention of lymphedema is essential for improving the quality of life of breast cancer survivors. Previous studies have shown that patients have symptoms such as arm tightness and arm heaviness before experiencing obvious limb swelling. Thus, this study aimed to develop a symptom-warning model for the early detection of breast cancer-related lymphedema.
               
                  Methods
                  A cross-sectional study was conducted at a tertiary hospital in Beijing between April 2017 and December 2018. A total of 24 lymphedema-associated symptoms were identified as candidate predictors. Circumferential measurements were used to diagnose lymphedema. The data were randomly split into training and validation sets with a 7:3 ratio to derive and evaluate six machine learning models. Both the discrimination and calibration of each model were assessed on the validation set.
               
                  Results
                  A total of 533 patients were included in the study. The logistic regression model showed the best performance for early detection of lymphedema, with AUC = 0.889 (0.840–0.938), sensitivity = 0.771, specificity = 0.883, accuracy = 0.825, and Brier scores = 0.141. Calibration was also acceptable. It has been deployed as an open-access web application, allowing users to estimate the probability of lymphedema individually in real time. The application can be found at https://apredictiontoolforlymphedema.shinyapps.io/dynnomapp/.
               
                  Conclusion
                  The symptom-warning model developed by logistic regression performed well in the early detection of lymphedema. Integrating this model into an open-access web application is beneficial to patients and healthcare providers to monitor lymphedema status in real-time.",health
10.1016/j.jwpe.2021.102269,Journal,Journal of Water Process Engineering,scopus,2021-10-01,sciencedirect,Plant-based versus metal-based coagulants in aquaculture wastewater treatment: Effect of mass ratio and settling time,https://api.elsevier.com/content/abstract/scopus_id/85113602078,"Azadirachta indica, or Neem, is a natural plant commonly used in medicine and pesticides due to the useful compounds it contains. This study aimed to determine the performance of Neem leaves as a natural coagulant in the removal of turbidity, total suspended solids (TSS) and colour from real aquaculture effluent. The experiment was conducted to determine the effect of mass ratio of the TSS (mg)/mass of coagulant (mg) on the removal of turbidity, TSS and colour, in which the ratio is calculated based on the TSS concentration as an index of aquaculture pollution. The experiment was carried out with a ratio range of 0.1 to 1000 mg TSS per mg coagulant and a total volume of 500 mL. The operational conditions were fixed at 180 rpm and 3 min for rapid mixing, 10 rpm and 20 min for slow mixing and settling time from 30 min to 60 min. The results showed a turbidity removal of 82.7%, TSS removal of 81.37% and colour removal of 65.8% at an optimum ratio of 1000 and coagulant dosage of 0.3 mg/L. For comparison, the performance of alum was also tested and showed higher turbidity, TSS and colour removals of 99.7%, 98.8% and 97.3%, respectively, based on the optimum ratio of 1 with a dosage of 362.7 mg/L. Both coagulants showed a similar optimum settling time of 30 min. From these results, it is clearly seen that Neem has a high potential for use as a coagulant, indicating further exploration to optimize the extraction of active compounds from the leaves.",health
10.1016/j.media.2021.102167,Journal,Medical Image Analysis,scopus,2021-10-01,sciencedirect,Computer-aided diagnosis tool for cervical cancer screening with weakly supervised localization and detection of abnormalities using adaptable and explainable classifier,https://api.elsevier.com/content/abstract/scopus_id/85111506720,"While pap test is the most common diagnosis methods for cervical cancer, their results are highly dependent on the ability of the cytotechnicians to detect abnormal cells on the smears using brightfield microscopy. In this paper, we propose an explainable region classifier in whole slide images that could be used by cyto-pathologists to handle efficiently these big images (100,000x100,000 pixels). We create a dataset that simulates pap smears regions and uses a loss, we call classification under regression constraint, to train an efficient region classifier (about 66.8% accuracy on severity classification, 95.2% accuracy on normal/abnormal classification and 0.870 KAPPA score). We explain how we benefit from this loss to obtain a model focused on sensitivity and, then, we show that it can be used to perform weakly supervised localization (accuracy of 80.4%) of the cell that is mostly responsible for the malignancy of regions of whole slide images. We extend our method to perform a more general detection of abnormal cells (66.1% accuracy) and ensure that at least one abnormal cell will be detected if malignancy is present. Finally, we experiment our solution on a small real clinical slide dataset, highlighting the relevance of our proposed solution, adapting it to be as easily integrated in a pathology laboratory workflow as possible, and extending it to make a slide-level prediction.",health
10.1016/j.asoc.2021.107702,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,OrbitNet: A new CNN model for automatic fault diagnostics of turbomachines,https://api.elsevier.com/content/abstract/scopus_id/85111487515,"Unplanned outage due to faults in a high-fidelity turbomachine such as steam turbine and centrifugal compressor often results in the reduced reliability and productivity of a factory while increasing its maintenance costs. Shaft orbit images generated from turbomachine vibration signals have been used to diagnose component faults. However, the existing methods were developed mostly by either using features extracted from orbits or utilizing simulation data which may produce inaccurate results in practical applications due to system complexity and data uncertainties. This paper presents a novel deep learning convolution neural network methodology for accurately automatic diagnostics of multiple faults in general rotating machines by adeptly integrating advanced signal processing with orbit images augmentation, considering the high non-linearity and uncertainty of sensed vibration signals. Environmental noise in vibration signals are filtered through the integration of multiresolution discrete wavelet packet transform and Bayesian hypothesis testing-based automatic thresholding. Shaft orbit images generated from the cleansed vibration data are augmented to increase their representativity and generalization. A novel multi-layer convolutional neural network model, OrbitNet, is specially designed to improve its generality and robustness while avoid possible overfitting in fault identification of various turbomachines. The proposed model retains the pattern information in the axis trajectory to the greatest extent, with the ability of accurately capturing features of various faults in different turbomachines. A generic implementation procedure is proposed for automatic fault diagnosis of rotating machinery based on the presented methodology. A comparison study is conducted to demonstrate the effectiveness and feasibility of the proposed methodology by using the sensed vibration signals collected from three real-world centrifugal compressors, two steam turbines and one generator with four different fault modes including imbalance, friction, misalignment and oil whirl.",health
10.1016/j.envsci.2021.06.011,Journal,Environmental Science and Policy,scopus,2021-10-01,sciencedirect,A Big Data and Artificial Intelligence Framework for Smart and Personalized Air Pollution Monitoring and Health Management in Hong Kong,https://api.elsevier.com/content/abstract/scopus_id/85111282536,"All people in the world are entitled to enjoy a clean environment and a good quality of life. With big data and artificial intelligence technologies, it is possible to estimate personalized air pollution exposure and synchronize it with activity, health, quality of life and behavioural data, and provide real-time, personalized and interactive alert and advice to improve the health and well-being of individual citizens. In this paper, we propose an overarching framework outlining five major challenges to personalized air pollution monitoring and health management, and respective methodologies in an integrated interdisciplinary manner. First, urban air quality data is sparse, rendering it difficult to provide timely personalized alert and advice. Second, collected data, especially those involving human inputs such as health perception, are often missing and erroneous. Third, the data collected are heterogeneous, and highly complex, not easily comprehensible to facilitate individual and collective decision-making. Fourth, the causal relationships between personal air pollutants exposure (specifically, PM2.5 and PM1.0 and NO2) and personal health conditions, and health-related quality of life perception, of young asthmatics and young healthy citizens in Hong Kong (HK), are yet to be established. Fifth, whether personalized and smart information and advice provided can induce behavioural change and improve health and quality of life are yet to be determined. To overcome these challenges, our first novelty is to develop an AI and big data framework to estimate and forecast air quality in high temporal-spatial resolution and real-time. Our second novelty includes the deployment of mobile pollution sensor platforms to substantially improve the accuracy of estimated and forecasted air quality data, and the collection of activity, health condition and perception data. Our third novelty is the development of visualization tools and comprehensible indexes, by correlating personal exposure with four types of personal data, to provide timely, personalized pollution, health and travel alerts and advice. Our fourth novelty is determining causal relationship, if any, between personal pollutants, PM1.0 and PM2.5, NO2 exposure and personal health condition, and personal health perception, based on a clinical experiment of 150 young asthmatics and 150 young healthy citizens in HK. Our fifth novelty is an intervention study to determine if smart information, presented via our proposed visualized platform, will induce personal behavioural change. Our novel big data AI-driven approach, when integrated with other analytical approaches, provides an integrated interdisciplinary framework for personalized air pollution monitoring and health management, easily transferrable to and applicable in other domains and countries.",health
10.1016/j.phymed.2021.153643,Journal,Phytomedicine,scopus,2021-10-01,sciencedirect,Atractylodis rhizoma water extract attenuates fructose-induced glomerular injury in rats through anti-oxidation to inhibit TRPC6/p-CaMK4 signaling,https://api.elsevier.com/content/abstract/scopus_id/85111151811,"Background
                  Atractylodis rhizoma, an aromatic herb for resolving dampness, is used to treat Kidney-related edema in traditional Chinese medicine for thousands years. This herb possesses antioxidant effect. However, it is not yet clear how Atractylodis rhizoma prevents glomerular injury through its anti-oxidation.
               
                  Purpose
                  Based the analysis of Atractylodis rhizoma water extract (ARE) components and network pharmacology, this study was to explore whether ARE prevented glomerular injury via its anti-oxidation to inhibit oxidative stress-driven transient receptor potential channel 6 (TRPC6) and its downstream molecule calcium/calmodulin-dependent protein kinase IV (CaMK4) signaling.
               
                  Methods
                  Liquid chromatography-tandem mass spectrometry (LC-MS/MS) was used to analyze ARE components. Network pharmacology analysis was preliminarily performed. Male Sprague-Dawley rats were given 10% fructose drinking water (100 mL/d) for 16 weeks. ARE at 720 and 1090 mg/kg was orally administered to rats for the last 8 weeks. Hydrogen peroxide (H2O2) and malondialdehyde (MDA) level, and superoxide dismutase (SOD) activity in rat kidney cortex were detected, respectively. In rat glomeruli, redox-related factors forkhead box O3 (FoxO3), SOD2 and catalase (CAT), podocyte slit diaphragm proteins podocin and nephrin, cytoskeleton proteins CD2-associated protein (CD2AP) and α-Actinin-4, as well as TRPC6, p-CaMK4 and synaptopodin protein levels were analyzed by Western Blotting. SOD2 and CAT mRNA levels were detected by qRT-PCR.
               
                  Results
                  36 components were identified in ARE. Among them, network pharmacology analysis indicated that ARE might inhibit kidney oxidative stress. Accordingly, ARE up-regulated nuclear FoxO3 expression, and then increased SOD2 and CAT at mRNA and protein levels in glomeruli of fructose-fed rats. It reduced H2O2 and MDA levels, and increased SOD activity in renal cortex of fructose-fed rats. Subsequently, ARE down-regulated TRPC6 and p-CaMK4, and up-regulated synaptopodin in glomeruli of fructose-fed rats. Furthermore, ARE increased podocin and nephrin, as well as CD2AP and α-Actinin-4, being consistent with its reduction of urine albumin-to-creatinine ratio and improvement of glomerular structure injury in this animal model.
               
                  Conclusions
                  These results suggest that ARE may prevent glomerular injury in fructose-fed rats possibly by reducing oxidative stress to inhibit TRPC6/p-CaMK4 signaling and up-regulate synaptopodin expression. Therefore, ARE may be a promising drug for treating high fructose-induced glomerular injury in clinic.",health
10.1016/j.jece.2021.106001,Journal,Journal of Environmental Chemical Engineering,scopus,2021-10-01,sciencedirect,Immobilized Ag-nanoparticles (iNPs) for environmental applications: Elucidation of immobilized silver-induced inhibition mechanism of Escherichia coli,https://api.elsevier.com/content/abstract/scopus_id/85109664907,"Although silver nanoparticles (AgNPs) appear to be promising for certain medical/pharmaceutical applications, they present significant disadvantages when it comes to environmental applications due to the need for recovery of the metal (Ag) which is considered hazardous for the environment. The present study examines the antimicrobial properties and mechanism of action of immobilized (on Al2O3) silver nanoparticles’ (1 wt% Ag-iNPs) regarding the treatment of E. coli microbial solutions. Antimicrobial experiments were conducted in semi-batch mode using a three-phase continuous flow stirred tank reactor. Every treated sample was taken from the outlet of the reactor for the time intervals of 0, 5 and 25 min. To ensure that the bactericidal property of Ag-iNPs is not attributed to the dissolution of surface silver (as free Ag+), a suitable Ag+ scavenger was used as already described in our earlier studies. Regarding the molecular analysis performed under this study, the regulation of key enzymes involved in bactericidal activity of E. coli, was examined, after their treatment either with immobilized silver nanoparticles (Ag-iNPs) or AgNO3. Specifically, 50 mL sample for each case was centrifuged (10 min at 10,000 rpm) and the pellet (≈109 cells) was immediately subjected to total RNA extraction. For real-time RT-qPCR analyses, 1 μg of total RNA was converted into cDNA. It was found that PldA gene, which encodes outer membrane’s phospholipase A (OMPLA), was up-regulated after 5 and 25 min of treatment with Ag-iNPs. OMPLA’s activation appears to be the initial step of Ag-iNPs bactericidal mechanism that ultimately leads to the creation of holes on the outer membrane (OM), irreversibly disturbing the cells’ respiration cycle. In addition, after treatment with Ag-iNPs, Blue copper oxidase CueO (encoded by cueO gene) was found to be over-produced and appears to play a key-role in the oxidative transfer of silver from the surface of Ag-iNPs to the cell. This leads to the Ag-induced displacement of copper from its native protein sites such as CusS/CusR, a fact that causes the release of labile copper and ROS inside the cell. In addition, TEM analysis of bacteria treated with Ag-iNPs revealed severe morphological changes (“holes”) on bacterial outer membrane, indicating that there is an intermediate step in the proposed antimicrobial mechanism which takes place on the surface of Ag-iNPs.",health
10.1016/j.ymssp.2021.107766,Journal,Mechanical Systems and Signal Processing,scopus,2021-10-01,sciencedirect,An artificial neural network methodology for damage detection: Demonstration on an operating wind turbine blade,https://api.elsevier.com/content/abstract/scopus_id/85102975974,"This study presents a novel artificial neural network (ANN) based methodology within a vibration-based structural health monitoring framework for robust damage detection. The ANN-based methodology establishes the nonlinear relationships between selected damage sensitive features (DSF) influenced by environmental and operational variabilities (EOVs) and their corresponding novelty indices computed by the Mahalanobis distance (MD). The ANN regression model is trained and validated based on a reference state (i.e., a healthy structure). The trained model is used to predict the corresponding MD of new observations. The prediction error between the calculated and predicted MD is used as a new novelty index for damage detection. Firstly, an artificial 2D feature set is generated to illustrate how the limitations of solely using the MD-based novelty index can be overcome by the proposed ANN-based methodology. Secondly, the methodology is implemented in data obtained from an in-operation wind turbine with different artificially induced damage scenarios in one of its blades. Finally, the performance of the proposed methodology is evaluated by the metrics of accuracy, F1-score and Matthews correlation coefficient. The results demonstrate the advantages of the proposed methodology by improving damage detectability in all the different damage scenarios despite the influence of EOVs in both the simulated and real data.",health
10.1016/j.xpro.2021.100639,Journal,STAR Protocols,scopus,2021-09-17,sciencedirect,Timesias: A machine learning pipeline for predicting outcomes from time-series clinical records,https://api.elsevier.com/content/abstract/scopus_id/85108953840,"The prediction of outcomes is a critical part of the clinical surveillance for hospitalized patients. Here, we present Timesias, a machine learning pipeline which predicts outcomes from real-time sequential clinical data. The strategy implemented in Timesias is the first-place solution in the crowd-sourcing DII (discover, innovate, impact) National Data Science Challenge involving more than 100,000 patients, achieving 0.85 as evaluated by AUROC (area under receiver operator characteristic curve) in predicting the early onset of sepsis status. Timesias is freely available via PyPI and GitHub.
                  For complete details on the use and execution of this protocol, please refer to Guan et al. (2021).",health
10.1016/j.eswa.2021.114912,Journal,Expert Systems with Applications,scopus,2021-09-15,sciencedirect,Inductive Gaussian representation of user-specific information for personalized stress-level prediction,https://api.elsevier.com/content/abstract/scopus_id/85104334512,"The accurate prediction of stress in a person’s life has a significant effect on improving personal health and the national economy. Since individuals have different historical circumstances and personality traits, stress symptoms and levels may vary from person to person. Thus, most studies on stress prediction pay attention to personalized models, which determine the personal stress level using user-specific information and heterogeneous stress-related data. However, these models cannot elaborately handle the uncertainty caused by the sparsity, data imbalance, irregularity, and high-dimensionality of user-specific information. In particular, out-of-sample users increase uncertainty. To cope with the problem, we propose a personalized stress-level prediction model with inductive Gaussian representation (PSP-IGR), which exploits heterogeneous inputs with a unified end-to-end approach. PSP-IGR extracts feature vectors from the heterogeneous inputs via Gaussian sampling, domain rules, and deep learning, depending on the characteristics of each input. Especially, PSP-IGR inductively generates a Gaussian feature vector called IGR by Gaussian sampling from the shared contents of user-specific information. Thus, PSP-IGR not only generalizes to both in-sample and out-of-sample users effectively but also deals with the uncertainty problem caused by limitations of healthcare datasets. Also, since we fuse the extracted feature vectors considering their characteristics (Gaussian and point vectors), we can preserve the expressiveness of each feature vector. Experiments on a real-world dataset, including survey results, wearable sensor signals, and contexts, demonstrate that PSP-IGR shows higher accuracy in predicting individual stress-level than previous models.",health
10.1016/j.knosys.2021.107216,Journal,Knowledge-Based Systems,scopus,2021-09-05,sciencedirect,Deep transfer learning for conditional shift in regression[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85109376376,"Deep transfer learning (DTL) has received increasing attention in smart manufacturing, whereas most current studies focus on the situation of marginal distribution shift in classification. We observe a new regression scenario in machine health monitoring systems (MHMS) with conditional distribution discrepancy across domains and try to propose a general theoretical approach for broader applications. In this paper, we propose a DTL framework CDAR, namely conditional distribution deep adaptation in regression. As only few labeled target data is available, in addition to only considering the prediction accuracy of individual samples, CDAR aims to preserve the global properties of the conditional distribution dominated by the target data. Thus, a hybrid loss function is constructed by combining the mean square error (MSE) and conditional embedding operator discrepancy (CEOD) in CDAR, and the target model is able to be finetuned by minimizing the designed loss function through back-propagation. The performance of the proposed CDAR is compared with two classical marginal distribution adaptation algorithms, TCA and DAN, and a specific method of DTL, FA. Experiments are carried out on two real-world datasets and the results verify the effectiveness of our method.",health
10.1016/S1001-9294(21)00059-6,Journal,Chinese Medical Sciences Journal,scopus,2021-09-01,sciencedirect,External and Internal Validation of a Computer Assisted Diagnostic Model for Detecting Multi-Organ Mass Lesions in CT images,https://api.elsevier.com/content/abstract/scopus_id/85118752763,"Objective
                  We developed a universal lesion detector (ULDor) which showed good performance in in-lab experiments. The study aims to evaluate the performance and its ability to generalize in clinical setting via both external and internal validation.
               
                  Methods
                  The ULDor system consists of a convolutional neural network (CNN) trained on around 80K lesion annotations from about 12K CT studies in the DeepLesion dataset and S other public organ-specific datasets. During the validation process, the test sets include two parts: the external validation dataset which was comprised of 164 sets of non-contrasted chest and upper abdomen CT scans from a comprehensive hospital, and the internal validation dataset which was comprised of 187 sets of low-dose helical CT scans from the National Lung Screening Trial (NLST). We ran the model on the two test sets to output lesion detection. Three board-certified radiologists read the CT scans and verified the detection results of ULDor. We used positive predictive value (PPV) and sensitivity to evaluate the performance of the model in detecting space-occupying lesions at all extra-pulmonary organs visualized on CT images, including liver, kidney, pancreas, adrenal, spleen, esophagus, thyroid, lymph nodes, body wall, thoracic spine, etc.
                  
               
                  Results
                  In the external validation, the lesion-level PPV and sensitivity of the model were 57.9% and 67.0%, respectively. On average, the model detected 2.1 findings per set, and among them, 0.9 were false positives. ULDor worked well for detecting liver lesions, with a PPV of 78.9% and a sensitivity of 92.7%, followed by kidney, with a PPV of 70.0% and a sensitivity of 58.3%. In internal validation with NLST test set, ULDor obtained a PPV of 75.3% and a sensitivity of 52.0% despite the relatively high noise level of soft tissue on images.
               
                  Conclusions
                  The performance tests of ULDor with the external real-world data have shown its high effectiveness in multiple-purposed detection for lesions in certain organs. With further optimisation and iterative upgrades, ULDor may be well suited for extensive application to external data.",health
10.1016/j.iot.2021.100422,Journal,Internet of Things (Netherlands),scopus,2021-09-01,sciencedirect,Identification and Authentication in Healthcare Internet-of-Things Using Integrated Fog Computing Based Blockchain Model,https://api.elsevier.com/content/abstract/scopus_id/85115027489,"The healthcare Internet-of-Things (IoT) offers many benefits including data transmission in real-time mode, the ability to monitor the physiological state of the patient in a different interval of time. Devices such as blood-pressure monitors, glucose meters, heart monitoring implants, Electroencephalography (EEG), Electrocardiogram (ECG), and Electromyography (EMG) wearable devices allow health providers to collect the patient health information locally and make a real-time decision based on the Patient Health Data (PHD). Hospitals have been adopting the IoT for many years and now they have healthcare IoT devices in patients’ rooms and their bodies. However, the medical agencies, hospitals, and companies do not consider the security risk of healthcare IoT devices connected to a Local Area Network (LAN) or Wide Area Network (WAN). The IoT devices can be easily hacked and may lead to several potentially life-threatening risks due to poor authentication and encryption practices. Existing machine learning algorithms and blockchain approach working in the cloud computing environment are unable to meet the Quality of Service (QoS) like reliability, authentication, identification, and security requirements of healthcare IoT devices. Most of the traditional machine learning algorithms and techniques for healthcare IoT lacks the real-world implementation for secure data transmission. Therefore, blockchain is introduced for secure and reliable transaction in healthcare IoT. Whereas Fog Computing (FC) is introduced to extend the services of the cloud at the edge of networks. Integration of FC with blockchain can overcome the issue of healthcare IoT device identification, authentication, and verification for scalable frequent data transmission in a decentralized environment. Hence, a novel solution for the abovementioned problem is proposed using FC and blockchain. It includes an FC-based three-tier architecture, an analytical model, a mathematical framework, and an Advanced Signature-Based Encryption (ASE) algorithm for healthcare IoT device identification, verification, and Patient Health Data (PHD) authentication. The aim is to extend secure data transmission for healthcare IoT and end-users availing the real-time services. The proposed model and algorithm will be able to provide services for transaction and transmission near the edge in a secure manner. By analyzing the generated results from the proposed novel ASE algorithm for throughput, packet error, reliability, and malicious node detection accuracy; it is observed that the ASE algorithm in the FC environment easily outperforms the cloud and the other existing state of the art techniques such as FogBus, Femto cloud, Blockchain Fog-based Architecture Network (BFAN), and BeeKeeper. The malicious node detection accuracy of the ASE algorithm in the FC environment is 91% and in the cloud is 83%. Whereas the reliability percentage of the ASE algorithm in FC is 95% and in the cloud is 87%. The proposed approach is tested on simulators iFogSim (Net-Beans) and SimBlock.",health
10.1016/j.amsu.2021.102489,Journal,Annals of Medicine and Surgery,scopus,2021-09-01,sciencedirect,Covid-19 imaging: A narrative review,https://api.elsevier.com/content/abstract/scopus_id/85112793878,"Background
                  The 2019 novel coronavirus disease (COVID-19) imaging data is dispersed in numerous publications. A cohesive literature review is to be assembled.
               
                  Objective
                  To summarize the existing literature on Covid-19 pneumonia imaging including precautionary measures for radiology departments, Chest CT's role in diagnosis and management, imaging findings of Covid-19 patients including children and pregnant women, artificial intelligence applications and practical recommendations.
               
                  Methods
                  A systematic literature search of PubMed/med line electronic databases.
               
                  Results
                  The radiology department's staff is on the front line of the novel coronavirus outbreak. Strict adherence to precautionary measures is the main defense against infection's spread. Although nucleic acid testing is Covid-19's pneumonia diagnosis gold standard; kits shortage and low sensitivity led to the implementation of the highly sensitive chest computed tomography amidst initial diagnostic tools. Initial Covid-19 CT features comprise bilateral, peripheral or posterior, multilobar ground-glass opacities, predominantly in the lower lobes. Consolidations superimposed on ground-glass opacifications are found in few cases, preponderantly in the elderly. In later disease stages, GGO transformation into multifocal consolidations, thickened interlobular and intralobular lines, crazy paving, traction bronchiectasis, pleural thickening, and subpleural bands are reported. Standardized CT reporting is recommended to guide radiologists. While lung ultrasound, pulmonary MRI, and PET CT are not Covid-19 pneumonia's first-line investigative diagnostic modalities, their characteristic findings and clinical value are outlined. Artificial intelligence's role in strengthening available imaging tools is discussed.
               
                  Conclusion
                  This review offers an exhaustive analysis of the current literature on imaging role and findings in COVID-19 pneumonia.",health
10.1016/j.compbiomed.2021.104711,Journal,Computers in Biology and Medicine,scopus,2021-09-01,sciencedirect,REUR: A unified deep framework for signet ring cell detection in low-resolution pathological images,https://api.elsevier.com/content/abstract/scopus_id/85112030760,"Detecting signet ring cells (SRCs) in pathological images is essential for carcinoma diagnosis. However, it is time consuming for pathologists to detect SRCs manually from pathological images, and the accuracy of detecting them is also relatively low because of their small sizes. Recently, the exploration of deep learning methods in pathology analysis has been widely investigated by researchers. Nevertheless, the automatic detection of SRCs from real pathological images faces two problems. One is that labeled pathological images are insufficient and usually incomplete. The other is that the training data and the real clinical data have a large difference in resolution. Hence, adopting the transfer learning method affects the performance of deep learning methods. To address these two problems, we present a unified framework named REUR [RetinaNet combining USRNet (unfolding super-resolution network) with the RGHMC (revised gradient harmonizing mechanism classification) loss] that can accurately detect SRCs in low-resolution (LR) pathological images. First, the framework with the super-resolution (SR) module can address the difference in resolution between the training data and the real clinical data. Second, the framework with the label correction module can obtain the revised ground-truth labels from noisy examples, which are embedded into the gradient harmonizing mechanism to acquire the RGHMC loss. The results of the numerical experiments showed that the framework can perform better than other one-stage detectors based on the RetinaNet architecture in the high-resolution (HR) noisy dataset. It achieved a kappa value of 0.74 and an accuracy of 0.89 in the test with 27 randomly selected whole slide images (WSIs), and, thus, it can assist pathologists in better analyzing WSIs. The framework provides an essential method in computer-aided diagnosis for medical applications.",health
10.1016/j.cmpb.2021.106281,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-09-01,sciencedirect,xECGNet: Fine-tuning attention map within convolutional neural network to improve detection and explainability of concurrent cardiac arrhythmias,https://api.elsevier.com/content/abstract/scopus_id/85111343607,"Background and objectiveDetecting abnormal patterns within an electrocardiogram (ECG) is crucial for diagnosing cardiovascular diseases. We start from two unresolved problems in applying deep-learning-based ECG classification models to clinical practice: first, although multiple cardiac arrhythmia (CA) types may co-occur in real life, the majority of previous detection methods have focused on one-to-one relationships between ECG and CA type, and second, it has been difficult to explain how neural-network-based CA classifiers make decisions. We hypothesize that fine-tuning attention maps with regard to all possible combinations of ground-truth (GT) labels will improve both the detection and interpretability of co-occurring CAs.
                  
                     Methods To test our hypothesis, we propose an end-to-end convolutional neural network (CNN), xECGNet, that fine-tunes the attention map to resemble the averaged response maps of GT labels. Fine-tuning is achieved by adding to the objective function a regularization loss between the attention map and the reference (averaged) map. Performance is assessed by F1 score and subset accuracy.
                  
                     Results The main experiment demonstrates that fine-tuning alone significantly improves a model’s multilabel subset accuracy from 75.8% to 84.5% when compared with the baseline model. Also, xECGNet shows the highest F1 score of 0.812 and yields a more explainable map that encompasses multiple CA types, when compared to other baseline methods.
                  
                     Conclusions xECGNet has implications in that it tackles the two obstacles for the clinical application of CNN-based CA detection models with a simple solution of adding one additional term to the objective function.",health
10.1016/j.compmedimag.2021.101957,Journal,Computerized Medical Imaging and Graphics,scopus,2021-09-01,sciencedirect,MSDS-UNet: A multi-scale deeply supervised 3D U-Net for automatic segmentation of lung tumor in CT,https://api.elsevier.com/content/abstract/scopus_id/85111220658,"Lung cancer is one of the most common and deadly malignant cancers. Accurate lung tumor segmentation from CT is therefore very important for correct diagnosis and treatment planning. The automated lung tumor segmentation is challenging due to the high variance in appearance and shape of the targeting tumors. To overcome the challenge, we present an effective 3D U-Net equipped with ResNet architecture and a two-pathway deep supervision mechanism to increase the network's capacity for learning richer representations of lung tumors from global and local perspectives.
                  Extensive experiments on two real medical datasets: the lung CT dataset from Liaoning Cancer Hospital in China with 220 cases and the public dataset of TCIA with 422 cases. Our experiments demonstrate that our model achieves an average dice score (0.675), sensitivity (0.731) and F1-score (0.682) on the dataset from Liaoning Cancer Hospital, and an average dice score (0.691), sensitivity (0.746) and F1-score (0.724) on the TCIA dataset, respectively. The results demonstrate that the proposed 3D MSDS-UNet outperforms the state-of-the-art segmentation models for segmenting all scales of tumors, especially for small tumors. Moreover, we evaluated our proposed MSDS-UNet on another challenging volumetric medical image segmentation task: COVID-19 lung infection segmentation, which shows consistent improvement in the segmentation performance.",health
10.1016/j.engappai.2021.104384,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-09-01,sciencedirect,A study on the use of Edge TPUs for eye fundus image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85111215307,"Medical image segmentation can be implemented using Deep Learning methods with fast and efficient segmentation networks. Single-board computers (SBCs) are difficult to use to train deep networks due to their memory and processing limitations. Specific hardware such as Google’s Edge TPU makes them suitable for real time predictions using complex pre-trained networks. In this work, we study the performance of two SBCs, with and without hardware acceleration for fundus image segmentation, though the conclusions of this study can be applied to the segmentation by deep neural networks of other types of medical images. To test the benefits of hardware acceleration, we use networks and datasets from a previous published work and generalize them by testing with a dataset with ultrasound thyroid images. We measure prediction times in both SBCs and compare them with a cloud based TPU system. The results show the feasibility of Machine Learning accelerated SBCs for optic disc and cup segmentation obtaining times below 25 ms per image using Edge TPUs.",health
10.1016/j.bspc.2021.103010,Journal,Biomedical Signal Processing and Control,scopus,2021-09-01,sciencedirect,Self-supervised ECG pre-training,https://api.elsevier.com/content/abstract/scopus_id/85111194150,"Background:
                  Real-world medical data, such as electrocardiogram (ECG), often show a long-tail distribution and severe category imbalance, and severely imbalanced data generate bias in deep learning models. In this work, we investigate how to alleviate the problems of label imbalance and inadequate labelling faced by deep learning models when applied to ECG data.
               
                  Methods:
                  We constructed a short-duration twelve-lead ECG dataset, containing more than 300,000 samples, for morphological recognition based on the actual distribution to evaluate and compare the recognition ability of humans and computers regarding ECG morphology. Two unique ECG data augmentation methods were designed and were combined with a variety of current mainstream self-supervised learning methods, and ultimately, the pre-trained weights were transferred to an 8-class multi-label ECG classification task for evaluation.
               
                  Results:
                  The experiments showed that self-supervised pre-training relying on negative sample pairs could achieve significantly better ECG representation than baseline, which was significantly effective for alleviating the imbalance in ECG data and reducing the labels of supervised samples. This method effectively utilized a large number of normal ECG samples. Additionally, with the diagnosis of the expert team as ground truth, under the condition of accessing only a small number of labelled samples, these models even performed better than the human ECG doctors participating in the test.
               
                  Conclusion:
                  The combination of self-supervised learning and unique data augmentation methods in the recognition of ECG morphology can effectively alleviate the long-tail problem and severe data imbalance and can significantly reduce the need for labelled samples in the downstream task.",health
10.1016/j.compmedimag.2021.101956,Journal,Computerized Medical Imaging and Graphics,scopus,2021-09-01,sciencedirect,Automated three-dimensional vessel reconstruction based on deep segmentation and bi-plane angiographic projections,https://api.elsevier.com/content/abstract/scopus_id/85111016853,"Automated three-dimensional (3D) blood vessel reconstruction to improve vascular diagnosis and therapeutics is a challenging task in which the real-time implementation of automatic segmentation and specific vessel tracking for matching artery sequences is essential. Recently, a deep learning-based segmentation technique has been proposed; however, existing state-of-the-art deep architectures exhibit reduced performance when they are employed using real in-vivo imaging because of serious issues such as low contrast and noise contamination of the X-ray images. To overcome these limitations, we propose a novel methodology composed of the de-haze image enhancement technique as pre-processing and multi-level thresholding as post-processing to be applied to the lightweight multi-resolution U-shaped architecture. Specifically, (1) bi-plane two-dimensional (2D) vessel images were extracted simultaneously using the deep architecture, (2) skeletons of the vessels were computed via a morphology operation, (3) the corresponding skeleton structure between image sequences was matched using the shape-context technique, and (4) the 3D centerline was reconstructed using stereo geometry. The method was validated using both in-vivo and in-vitro models. The results show that the proposed technique could improve the segmentation quality, reduce computation time, and reconstruct the 3D skeleton automatically. The algorithm accurately reconstructed the phantom model and the real mouse vessel in 3D in 2 s. Our proposed technique has the potential to allow therapeutic micro-agent navigation in clinical practice, thereby providing the 3D position and orientation of the vessel.",health
10.1016/j.cmpb.2021.106252,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-09-01,sciencedirect,Gradual back-projection residual attention network for magnetic resonance image super-resolution,https://api.elsevier.com/content/abstract/scopus_id/85110174209,"Background and objective
                  Magnetic Resonance Image (MRI) analysis can provide anatomical examination of internal organs, which is helpful for diagnosis of the disease. Aiming at the problems of insufficient feature information mining in the process of MRI super-resolution (SR) reconstruction, the difficulty of determining the interdependence between the channels of the feature map, and the reconstruction error when reconstructing high-resolution (HR) images, we propose a SR method to solve these problems.
               
                  Methods
                  In this work, we propose a gradual back-projection residual attention network for MRI super-resolution (GRAN), which outperforms most of the state-of-the-art methods. Firstly, we use the gradual upsampling method to gradually scale the low-resolution (LR) image to a given magnification to alleviate the high-frequency information loss caused by the upsampling process. Secondly, we merge the idea of iterative back-projection at each stage of gradual upsampling, learn the mapping relationship between HR and LR feature maps and reduce the noise introduced during the upsampling process. Finally, we use the attention mechanism to dynamically allocate attention resources to the feature maps generated at different stages of the gradual back-projection network, so that the network model can learn the interdependence between each feature map.
               
                  Results
                  For the 2 × and 4 × enlargement, the proposed GRAN method shows the superiority over the state-of-the-art methods on the Set5, Set14, and Urban100 benchmark datasets, extensive benchmark experiment and analysis show that the superiority of the GRAN algorithm in terms of peak signal-to-noise ratio and structural similarity index indicators.
               
                  Conclusion
                  The MRI results reconstructed by gradual back-projection residual attention network on the public dataset IDI have good image sharpness, rich texture details and good visual experience. In addition, the reconstructed image is the closest to the real image, enabling the medical expert to see the biological tissue structure and its early pathological changes more clearly, providing assistance and support to the medical expert in the diagnosis and treatment of the disease.",health
10.1016/j.jstrokecerebrovasdis.2021.105962,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-09-01,sciencedirect,StrokeWatch: An Instrument for Objective Standardized Real-Time Measurement of Door-to-Needle Times in Acute Ischemic Stroke Treatment,https://api.elsevier.com/content/abstract/scopus_id/85109982805,"Objectives
                  Monitoring critical time intervals in acute ischemic stroke treatment delivers metrics for quality of performance – the door-to-needle time being well-established. To resolve the conflict of self-reporting bias a “StrokeWatch” was designed – an instrument for objective standardized real-time measurement of procedural times.
               
                  Materials and methods
                  An observational, monocentric analysis of patients receiving intravenous thrombolysis for acute ischemic stroke between January 2018 and September 2019 was performed based on an ongoing investigator-initiated, prospective, and blinded endpoint registry. Patient data and treatment intervals before and after introduction of ""StrokeWatch"" were compared.
               
                  Results
                  “StrokeWatch” was designed as a mobile board equipped with three digital stopwatches tracking door-to-needle, door-to-groin, and door-to-recanalization intervals as well as a form for standardized documentation. 118 patients before introduction of “StrokeWatch” (subgroup A) and 53 patients after introduction of “StrokeWatch” (subgroup B) were compared. There were no significant differences in baseline characteristics, procedural times, or clinical outcome. A non-significant increase in patients with door-to-needle intervals of 60 min or faster (93.2 vs 98.1%, p = 0.243) and good functional outcome (mRS d90 ≤ 2, 47.5 vs 58.5%, p = 0.218) as well as a significant increase in reports of delayed arrival of intra-hospital patient transport service (0.8 vs 13.2%, p = 0.001) were observed in subgroup B.
               
                  Conclusions
                  The implementation of StrokeWatch for objective standardized real-time measurement of door-to-needle times is feasible in a real-life setting without negative impact on procedural times or outcome. It helped to reassure a high-quality treatment standard and reveal factors associated with procedural delays.",health
10.1016/j.vetmic.2021.109162,Journal,Veterinary Microbiology,scopus,2021-09-01,sciencedirect,"Evaluation of colonization, variable lipoprotein-based serological response, and cellular immune response of Mycoplasma hyorhinis in experimentally infected swine",https://api.elsevier.com/content/abstract/scopus_id/85109199082,"Mycoplasma hyorhinis (Mhr) is a commensal of the upper respiratory tract that can be shed by nasal secretions and transmitted by direct contact in neonatal and nursery pigs. Lesions associated with Mhr infection include polyserositis and arthritis; however, systemic Mhr disease pathogenesis is not well characterized. This study aimed to investigate the immunopathogenesis and bacterial dissemination pattern of Mhr using single and multiple inoculation approaches in a caesarian-derived colostrum-deprived (CDCD) pig model. Animals in three treatment groups were inoculated once (Mhr 1; n = 12) or four (Mhr 2; n = 8) times with Mhr or sham-inoculated (NC group; n = 3) nasally and by tonsillar painting. Inoculum consisted of a triple cloned Mhr field isolate (4.5 × 107 CFU/mL) in Friis medium. Clinical signs were evaluated daily during the study. Serum and oral fluid antibody (IgA and IgG) response and cellular immune response were assessed using a recombinant chimeric VlpA-G-based indirect ELISA and by ELISpot, respectively. The presence of Mhr in oral fluids, nasal and oropharyngeal swabs were evaluated by qPCR. At 6 wpi, pigs were euthanized and evaluated for gross lesions consistent with Mhr and bacterial colonization in tonsils by qPCR. No clinical signs or gross lesions consistent with Mhr-associated disease were observed throughout the study. For Mhr 2 group, the presence of IgA and IgG in serum and oral fluids were detected at 2 and 4 weeks post-inoculation (wpi), respectively, while in Mhr 1, only IgA was detected in oral fluids at 6 wpi. The proportion of animals shedding Mhr in nasal secretions varied from 20 to 40 % in the Mhr 1 and 62.5–100% in the Mhr 2 group. However, the proportion of animals shedding Mhr in oropharyngeal swabs was consistent through the study (60 %) in Mhr 1 and fluctuated from 20 % to 87.5 % in Mhr 2 group. The lack of clinical signs and the presence of Mhr specific humoral response and bacterial colonization indicates that the multiple inoculation experimental model may mimic subclinical natural infection in the field. In addition, the humoral and transient cellular response did not result in bacterial clearance. Based on these results, animals would have to be exposed multiple times to mount a detectable immune response.",health
10.1016/j.phymed.2021.153635,Journal,Phytomedicine,scopus,2021-09-01,sciencedirect,Re-Du-Ning injection ameliorates LPS-induced lung injury through inhibiting neutrophil extracellular traps formation,https://api.elsevier.com/content/abstract/scopus_id/85108987470,"Background
                  Acute lung injury (ALI) and acute respiratory distress syndrome (ARDS) are life-threatening diseases and could occur in severe COVID-19 patients. Re-Du-Ning injection (RDN) is a tradition Chinese medicine preparation which has been clinically used for treatment of respiratory diseases including COVID-19.
               
                  Purpose
                  To elucidate the potential mechanisms of RDN for the treatment of ALI.
               
                  Methods
                  Female C57BL/6J mice were used to establish ALI model by intraperitoneal injection 10 mg/kg LPS, and RDN injection was intraperitoneally administered with the dose of 5 and 10 ml/kg. The cytokines were measured by ELISA and qPCR. The data related to NETs were analyzed by ELISA, immunofluorescence, Western blotting and network pharmacological approach.
               
                  Results
                  RDN robustly alleviated LPS-induced ALI. Meanwhile, RDN downregulated the expression of pro-inflammatory cytokines, such as IL-1β, IL-6 and TNF-α. Specifically, RDN treatment inhibited the formation of neutrophil extracellular traps (NETs) and remarkably suppressed the protein of PAD4. The active compound from RDN decreased the phosphorylation of ERK1/2.
               
                  Conclusion
                  These findings demonstrate that RDN ameliorates LPS-induced ALI through suppressing MAPK pathway to inhibit the formation of NETs.",health
10.1016/j.comcom.2021.06.027,Journal,Computer Communications,scopus,2021-09-01,sciencedirect,Optimization of fitness data monitoring system based on Internet of Things and cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85108970321,"In the service dimension, the construction of fitness science data supervision service mode is discussed. Based on the stakeholder theory, through the statistical analysis of the stakeholders of fitness science data supervision, three core stakeholders of the government, users and data service personnel are identified. Based on these three dimensions, we find out the core concepts of government policy model, user demand model and service model. At the same time, each dimension is deeply analyzed. Through the relationship analysis between these three dimensions, the user-oriented collaborative supervision service model of fitness scientific data is expected to guide the specific service practice of fitness scientific data supervision through the establishment of this model. In addition, an unsupervised learning method in machine learning, the isolation forest algorithm, is introduced to detect abnormal data; at the same time, using real fitness data sets, through comparative experiments with local anomaly factor algorithms, it is verified that the isolation forest algorithm has a good effect of anomaly detection; this article also uses redis cache to optimize the performance of the fitness data monitoring system, which solves the access pressure of the main database in a multi-user high-concurrency environment; Finally, the usability and stability of the system are verified by functional tests and stress tests.",health
10.1016/j.engappai.2021.104316,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-09-01,sciencedirect,Deep replacement: Reinforcement learning based constellation management and autonomous replacement,https://api.elsevier.com/content/abstract/scopus_id/85108677220,"The Deep Reinforcement Learning (DRL) algorithm, Proximal Policy Optimization (PPO2), is deployed on a custom spacecraft (S/C) build and loss model to determine if an Artificial Intelligence (AI) can learn to monitor satellite constellation health and determine an optimal replacement strategy. A custom environment is created to simulate how S/C are built, launched, generate revenue, and finally decay. The reinforcement learning agent successfully learned an optimal policy for two models: a Simplified Model where the financial cost of actions is ignored; and an Advanced Model where the financial cost of actions is a major element. In both models the AI monitors the constellations and takes multiple strategic and tactical actions to replace satellites to maintain constellation performance. The Simplified Model showed that the PPO2 algorithm was able to converge on an optimal solution after 
                        ∼
                     200,000 simulations. The Advanced Model was much more difficult for the AI to learn, and thus, the performance drops during the early episodes, but eventually converges to an optimal policy at 
                        ∼
                     25,000,000 simulations. With the Advanced Model, the AI is taking actions that are successfully providing strategies for constellation management and satellite replacements which include these actions’ financial implications. Thus, the methods in this paper provide initial research developments towards a real-world tool and an AI application that can aid various Aerospace businesses in managing Low Earth Orbit (LEO) constellations. This type of AI application may become imperative for deploying and maintaining small satellite mega-constellations.",health
10.1016/j.biopha.2021.111801,Journal,Biomedicine and Pharmacotherapy,scopus,2021-09-01,sciencedirect,Pterocarpus santalinus L. extract mitigates gamma radiation-inflicted derangements in BALB/c mice by Nrf2 upregulation,https://api.elsevier.com/content/abstract/scopus_id/85107990229,"Plant-based natural extracts contain several nutrients and bioactive compounds, such as phenolics and flavonoids, that possess various health-promoting activities. This study investigated the effects of polyphenols from Pterocarpus santalinus hydroalcoholic extract (PSHE) against gamma radiation-induced derangements via the upregulation of Nrf2. Ultra High Performance Liquid Chromatography Coupled to High Resolution Mass Spectrometry (UHPLC-HRMS/MS) analysis was performed to identify the possible radioprotectors. In vivo and in vitro studies, namely Real-Time-PCR (RT-PCR) analysis, Reactive Oxygen Species (ROS) scavenging activity, lipid peroxidation and GSH levels, DNA damage and cell death studies, anti-inflammatory (Sandwich ELISA), immunomodulatory studies (antibody staining), and model free radical scavenging assays, were performed. Vanillic acid, protocatechuic acid, para-hydroxybenzoic acid, chlorogenic acid, TNF-α inhibitor (Eudesmin), isoflavone (Daidzein 7-o-glucoside), astragalin (Kaempferol 3-o-glycoside), and other polyphenols were identified in PSHE using UHPLC-HRMS/MS analysis. Prophylactic administration of PSHE (−1 h) rendered more than 33% survival in mice exposed to 8 Gy whole-body-irradiation with increased mice survival and recovery of bone marrow and spleen cellularity. Real-time RT-PCR analysis showed that PSHE treatment (50 µg/mL) upregulated Nrf2, HO-1, and GPX-1 in mice splenocytes. At 50 µg/mL, PSHE reduced ROSscavenging activity, mitochondrial and spleen membrane lipid peroxidation levels, DNA damage, and cell death, and increased GSH levels. At 10 µg/mL, PSHE treatment diminished the content of IL-6 and TNF-α. At 50 µg/mL, PSHE suppressed lymphocyte proliferation. These findings indicate that polyphenols of PSHE possess marked antioxidant, anti-inflammatory, and immunomodulatory capacities, which play important roles in the prevention of radiation damage.",health
10.1016/j.adhoc.2021.102562,Journal,Ad Hoc Networks,scopus,2021-09-01,sciencedirect,Developing novel low complexity models using received in-phase and quadrature-phase samples for interference detection and classification in Wireless Sensor Network and GPS edge devices,https://api.elsevier.com/content/abstract/scopus_id/85107952090,"Despite Wireless Sensor Networks (WSNs) significantly developing over the past decade, these networks, like most wireless networks, remain susceptible to malicious interference and spectrum coexistence. Other vulnerabilities arise as WSN applications adopt open standards and typically resource and energy-constrained commercial-off-the-shelf equipment. Deployments include safety-critical applications such as the internet of things, medical, aerospace and space and deep-sea exploration. To manage safety and privacy requirements across such a diverse wireless landscape, security on wireless edge devices needs improvement while maintaining low complexity. This paper improves wireless edge device security by developing a novel intelligent interference diagnostic framework. Received in-phase (I) and quadrature-phase (Q) samples are exclusively utilized to detect modern, subtle and traditional crude jamming attacks. This I/Q sample utilization inherently enables decentralized decision-making, where the low-order features were extracted in a previous study focused on classifying typical 2.4–2.5 GHz wireless signals. The associated optimal intelligent models are leveraged as the foundation for this paper’s work. Initially, Matlab Monte Carlo simulations investigate the ideal case, which incorporates no hardware limitations, identifies the required data type of signal interactions and motivates a hardware investigation. Software-defined radios (SDRs) collect the required live over-the-air I/Q data and transmit matched signal (ZigBee) and continuous-wave interference in developed ZigBee wireless testbeds. Low complexity supervised machine learning models are developed based exclusively on the low-order features and achieve an average accuracy among the developed models above 98%. The designed methodology involves examining ZigBee over-the-air data for artificial jamming and SDR jamming of ZigBee signals transmitted from SDR and commercial (XBee) sources. This approach expands to a legitimate node classification technique and an overall algorithm for wireless edge device interference diagnostic tools. The investigation includes developing Support Vector Machine, XGBoost and Deep Neural Network (DNN) models, where XGBoost is optimal. Adapting the optimized models to global positioning system signals establishes the transferability of the designed methodology. Implementing the designed approaches on a Raspberry Pi embedded device examines a relatively resource-constrained deployment. The primary contribution is the real experimentally validated interference diagnostic framework that enables independent device operation, as no channel assumptions, network-level information or spectral images are required. Developed models exclusively use I/Q data low-order features and achieve high accuracy and generalization to unseen data.",health
10.1016/j.ipm.2021.102648,Journal,Information Processing and Management,scopus,2021-09-01,sciencedirect,Enhanced Deep Discrete Hashing with semantic-visual similarity for image retrieval,https://api.elsevier.com/content/abstract/scopus_id/85107146153,"Hashing has been shown to be successful in a number of Approximate Nearest Neighbor (ANN) domains, ranging from medicine, computer vision to information retrieval. However, current deep hashing methods either ignore both rich information of labels and visual linkages of image pairs, or leverage relaxation-based algorithms to address discrete problems, resulting in a large information loss. To address the aforementioned problems, in this paper, we propose an 
                        E
                     nhanced 
                        D
                     eep 
                        D
                     iscrete 
                        H
                     ashing (EDDH) method to leverage both label embedding and semantic-visual similarity to learn the compact hash codes. In EDDH, the discriminative capability of hash codes is enhanced by a distribution-based continuous semantic-visual similarity matrix, where not only the margin between the positive pairs and negative pairs is expanded, but also the visual linkages between image pairs is considered. Specifically, the semantic-visual continuous similarity matrix is constructed by analyzing the asymmetric generalized Gaussian distribution of the visual linkages between pairs with label consideration. Besides, in order to achieve an efficient hash learning framework, EDDH employs an asymmetric real-valued learning structure to learn the compact hash codes. In addition, we develop a fast discrete optimization algorithm, which can directly generate discrete binary codes in single step, and introduce an intermediate term before iterations to avoid the problems caused by directly the use of large semantic-visual similarity matrix, which results in a significant reduction in the computational overhead. Finally, we conducted extensive experiments on three datasets to show that EDDH has a significantly enhanced performance compared to the compared state-of-the-art baselines.",health
10.1016/j.scs.2021.103050,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Optimization of AI-driven communication systems for green hospitals in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85107113682,"The green hospital is an important part for constructing Sustainable Cities. In this paper, system optimization algorithms based on artificial intelligence technologies are proposed by studying the communication system of the green hospital in the smart sustainable city, and the overall architecture design and detailed functional module design were carried out. The functions in the system can be divided into basic information management function, patient monitoring function, and remote self-test, etc. The medical equipment management system is characterized by the combination of Internet of Things technology, so that equipment managers can control the operating status of the equipment at any time, and can remotely upgrade and control the equipment through the system, and medical staff can view the measurement data of the equipment at the system interface and grasp the real-time information of treating patients to improve work efficiency. The accuracy of the improved particle swarm optimization (PSO) algorithm was compared with that of a single BP neural network algorithm. According to the requirement analysis of the health monitoring software and the overall design scheme of the system, each functional module of the health monitoring software is designed and the specific implementation of each functional module is carried out.",health
10.1016/j.scs.2021.103009,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Applying machine learning in intelligent sewage treatment: A case study of chemical plant in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85106305327,"Nowadays, sewage treatment in sustainable cities attracts more researchers both from academic and industrial communities. Especially, since industrial sewage is normally highly toxic, which could cause serious pollution in a city and lead to health problems of residents, it is critical to monitor and predictably maintain sewage treatment facilities in cities. This paper presents an intelligent sewage treatment system based on machine learning and Internet of Things sensors to assist to manage the sewage treatment in a fine chemical plant. The implemented system has operated for twenty months, acquired multi-dimension data such as temperatures in different treatment processes, operation parameters of devices, and real-time Chemical Oxygen Demand (COD). Since the change trend of outflow COD is highly related to operation status, this paper innovatively uses different types of temperature and water inflow data as model inputs and applies three algorithms to make prediction, which are Support Vector Regression (SVR), Long Short-Term Memory (LSTM) neural network, and Gated Recurrent Unit (GRU) neural network. The experimental results show that GRU model performs better (MAPE = 10.18%, RMSE = 35.67, MAE = 31.16) than LSTM and SVR. This study can be extended to various sewage treatment scenarios in sustainable cities.",health
10.1016/j.eswa.2021.114951,Journal,Expert Systems with Applications,scopus,2021-09-01,sciencedirect,Providing music service in Ambient Intelligence: experiments with gym users,https://api.elsevier.com/content/abstract/scopus_id/85104365062,"Ambient Intelligence (AmI) is an interdisciplinary research area of ICT which has evolved since the 90s, taking great advantage from the advent of the Internet of Things (IoT). AmI creates, by using Artificial Intelligence (AI), an intelligent ecosystem in which computers, sensors, lighting, music, personal devices, and distributed services, work together to improve the user experience through the support of natural and intuitive user interfaces. Nowadays, AmI is used in various contexts, e.g., for building smart homes and smart cities, providing healthcare, and creating an adequate atmosphere in retail and public environments.
                  In this paper, we propose a novel AmI system for gym environments, named Gym Intelligence, able to provide adequate music atmosphere, according to the users’ physical effort during the training. The music is taken from Spotify and is classified according to some music features, as provided by Spotify itself. The system is based on a multi-agent computational intelligence model built on two main components: 
                        
                           (
                           i
                           )
                        
                      machine learning methods that forecast appropriate values for the Spotify music features, and 
                        
                           (
                           ii
                           )
                        
                      a multi-objective dynamic genetic algorithm that selects a specific Spotify music track, according to such values. Gym Intelligence is built by sensing the ambient with a minimal, low-cost, and non-intrusive set of sensors, and it has been designed considering the outcome of a preliminary analysis in real gyms, involving real users. We have considered well-known regression methods and we have validated them using a collected data 
                        
                           (
                           i
                           )
                        
                      about the users’ physical effort, through the sensors, and 
                        
                           (
                           ii
                           )
                        
                      about the users’ music preferences, through an Android app that the users have used during the training. Among the regression methods considered, the one that provided the best results is the Random Forest, which predicted Spotify music features with a mean absolute error of 0.02 and a root mean squared error of 0.05. We have implemented Gym Intelligence and deployed it in five real gyms. We have evaluated it conducting several experiments. The experiments show how, with the help of Gym Intelligence, the users’ satisfaction about the provided background music, rose from 3.05 to 4.91 (on a scale from 1 to 5, where 5 is the maximum score).",health
10.1016/j.ijepes.2021.107035,Journal,International Journal of Electrical Power and Energy Systems,scopus,2021-09-01,sciencedirect,Lightweight transfer nets and adversarial data augmentation for photovoltaic series arc fault detection with limited fault data,https://api.elsevier.com/content/abstract/scopus_id/85103955734,"Incidents of DC series arc faults in Photovoltaic (PV) systems are becoming more common, posing significant threat to properties and human safety. Machine Learning (ML) based methods, developed recently, have demonstrated better performance in many fault diagnosis tasks. However, an unresolved challenge affecting their performance is the problem caused by difference between the source domain data used during the development and the target domain data encountered in operation in the field. Furthermore, the fault data in the target-domain are usually rare or not available for model training. Another constraint is that complex models are difficult to operate in real-time. This paper proposes a cross-domain DC series arc fault detection framework based on Lightweight Transfer Convolutional Neural Networks with Adversarial Data Augmentation (LTCNN-ADA) using limited target-domain fault data. Four datasets are prepared using different power sources and inverters in different operating conditions. The proposed framework is validated through comprehensive studies and experiments with different amount of fault data.",health
10.1016/j.imr.2020.100708,Journal,Integrative Medicine Research,scopus,2021-09-01,sciencedirect,Effects of estrogen inhibition formula herbal mixture for danazol-induced precocious puberty in female rats: an experimental study with network pharmacology,https://api.elsevier.com/content/abstract/scopus_id/85102854786,"Background
                  This study aimed at determining the effect of the herbal mixture estrogen inhibition formula (EIF) and its possible mechanisms by precocious puberty animal models and network pharmacology-based analysis.
               
                  Methods
                  Precocious puberty animal models were established by a single injection of 300 μg danazol, then female rats were administered EIF, vaginal openings were monitored, uterus and pituitary indices were determined. The levels of ALP, E2, LH, and FSH were measured using ELISA kits. Real-time PCR was performed to evaluate the mRNA expression of GnRH, UNC5C, and netrin-1 in hypothalamic tissues. We applied network pharmacological analysis to predict potential targets and pathways of EIF.
               
                  Results
                  EIF delayed danazol-induced early vaginal opening. In the onset model, EIF reduced the increased levels of serum ALP, E2, LH, and FSH; as well as mRNA expressions of GnRH, Netrin-1, and UNC5C. Moreover, long-term administration of EIF not only diminished all impaired factors but also had no effect on the normal development of the animals. The gene set enrichment analysis showed that the targets of EIF are mainly associated with the GnRH signaling and ovarian steroidogenesis pathways.
               
                  Conclusion
                  EIF could be used in preclinical research for the treatment of precocious puberty by the inhibition of HPGA pre-maturation.",health
10.1016/j.jes.2021.01.029,Journal,Journal of Environmental Sciences (China),scopus,2021-09-01,sciencedirect,Comparison of approaches to quantify SARS-CoV-2 in wastewater using RT-qPCR: Results and implications from a collaborative inter-laboratory study in Canada,https://api.elsevier.com/content/abstract/scopus_id/85101937522,"Detection of SARS-CoV-2 RNA in wastewater is a promising tool for informing public health decisions during the COVID-19 pandemic. However, approaches for its analysis by use of reverse transcription quantitative polymerase chain reaction (RT-qPCR) are still far from standardized globally. To characterize inter- and intra-laboratory variability among results when using various methods deployed across Canada, aliquots from a real wastewater sample were spiked with surrogates of SARS-CoV-2 (gamma-radiation inactivated SARS-CoV-2 and human coronavirus strain 229E [HCoV-229E]) at low and high levels then provided “blind” to eight laboratories. Concentration estimates reported by individual laboratories were consistently within a 1.0-log10 range for aliquots of the same spiked condition. All laboratories distinguished between low- and high-spikes for both surrogates. As expected, greater variability was observed in the results amongst laboratories than within individual laboratories, but SARS-CoV-2 RNA concentration estimates for each spiked condition remained mostly within 1.0-log10 ranges. The no-spike wastewater aliquots provided yielded non-detects or trace levels (<20 gene copies/mL) of SARS-CoV-2 RNA. Detections appear linked to methods that included or focused on the solids fraction of the wastewater matrix and might represent in-situ SARS-CoV-2 to the wastewater sample. HCoV-229E RNA was not detected in the no-spike aliquots. Overall, all methods yielded comparable results at the conditions tested. Partitioning behavior of SARS-CoV-2 and spiked surrogates in wastewater should be considered to evaluate method effectiveness. A consistent method and laboratory to explore wastewater SARS-CoV-2 temporal trends for a given system, with appropriate quality control protocols and documented in adequate detail should succeed.",health
10.1016/j.asej.2021.01.014,Journal,Ain Shams Engineering Journal,scopus,2021-09-01,sciencedirect,Optimized support vector machines for unveiling mortality incidence in Tilapia fish,https://api.elsevier.com/content/abstract/scopus_id/85101559447,"In this paper, a new classification approach based on swarm-optimization is introduced to investigate the various effects of the ammonia concentration on the protein level and bioactivity that directly affect the Egyptian Nile’s fish health and mortality rate (i.e. Tilapia fish “O. Niloticus”). This approach enhances the Support Vector (SVM) Machines to classify the fish based on the protein level by Moth-Flame Optimization (MFO) algorithm. The experiment was divided into sub-phases: lab experiments and computational experiments. The primary purposes of the proposed approach, guiding decision-makers to review the pathophysiological status of the fish. The proposed MFO-SVM approach utilizes physical and chemical measurements to finally show revolutionary advances against the classic SVM and other well-known optimizers and classifiers. By achieving 99.983% of classification accuracy, the proposed approach outperforms other machine learning approaches on the same dataset. We believe that such an approach could be useful for many other real-world challenging tasks.",health
10.1016/j.vetpar.2020.109160,Journal,Veterinary Parasitology,scopus,2021-09-01,sciencedirect,Characterization of a Trichinella spiralis cathepsin X and its promotion for the larval invasion of mouse intestinal epithelial cells,https://api.elsevier.com/content/abstract/scopus_id/85085912345,"The aim of this study was to ascertain the characteristics of a Trichinella spiralis cathepsin X (TsCX) and its role on larval invasion of intestinal epithelial cells (IECs). The full-length of TsCX cDNA sequence was cloned and expressed in Escherichia coli BL21. The results of RT-PCR, IFA and Western blot revealed that TsCX was expressed at T. spiralis muscle larvae (ML), intestinal infective larvae, adult worm and newborn larvae, and it was located in whole worm section. The results of Far western and confocal microscopy demonstrated that there was a specific binding of rTsCX and IEC, and the binding site was located within the IEC cytoplasm. rTsCX promoted T. spiralis larval invasion of mouse IECs while anti-rTsCX antibody inhibited larval invasion into the IECs. Silencing TsCX by specific siRNA reduced the TsCX expression and larval invasive capacity. These results indicated that TsCX specifically binds to IECs and promotes larval invasion of intestinal epithelia, and it might be a potential target of vaccines against enteral stages of T. spiralis.",health
10.1016/j.neucom.2021.03.109,Journal,Neurocomputing,scopus,2021-08-18,sciencedirect,Real-time detection of bursts in neuronal cultures using a neuromorphic auditory sensor and spiking neural networks,https://api.elsevier.com/content/abstract/scopus_id/85104794271,"The correct identification of burst events is crucial in many scenarios, ranging from basic neuroscience to biomedical applications. However, none of the burst detection methods that can be found in the literature have been widely adopted for this task. As an alternative to conventional techniques, a novel neuromorphic approach for real-time burst detection is proposed and tested on acquisitions from in vitro cultures. The system consists of a Neuromorphic Auditory Sensor, which converts the input signal obtained from electrophysiological recordings into spikes and decomposes them into different frequency bands. The output of the sensor is sent to a trained Spiking Neural Network implemented on a SpiNNaker board that discerns between bursting and non-bursting activity. This data-driven approach was compared with different conventional spike-based and raw-based burst detection methods, addressing some of their drawbacks, such as being able to detect both high and low frequency events and working in an online manner. Similar results in terms of number of detected events, mean burst duration and correlation as current state-of-the-art approaches were obtained with the proposed system, also benefiting from its lower power consumption and computational latency. Therefore, our neuromorphic-based burst detection paves the road to future implementations for real-time neuroprosthetic applications.",health
10.1016/j.neuroimage.2021.118206,Journal,NeuroImage,scopus,2021-08-15,sciencedirect,"Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes from clinical MRI exams with scans of different orientation, resolution and contrast",https://api.elsevier.com/content/abstract/scopus_id/85106551066,"Most existing algorithms for automatic 3D morphometry of human brain MRI scans are designed for data with near-isotropic voxels at approximately 1 mm resolution, and frequently have contrast constraints as well-typically requiring T1-weighted images (e.g., MP-RAGE scans). This limitation prevents the analysis of millions of MRI scans acquired with large inter-slice spacing in clinical settings every year. In turn, the inability to quantitatively analyze these scans hinders the adoption of quantitative neuro imaging in healthcare, and also precludes research studies that could attain huge sample sizes and hence greatly improve our understanding of the human brain. Recent advances in convolutional neural networks (CNNs) are producing outstanding results in super-resolution and contrast synthesis of MRI. However, these approaches are very sensitive to the specific combination of contrast, resolution and orientation of the input images, and thus do not generalize to diverse clinical acquisition protocols – even within sites. In this article, we present SynthSR, a method to train a CNN that receives one or more scans with spaced slices, acquired with different contrast, resolution and orientation, and produces an isotropic scan of canonical contrast (typically a 1 mm MP-RAGE). The presented method does not require any preprocessing, beyond rigid coregistration of the input scans. Crucially, SynthSR trains on synthetic input images generated from 3D segmentations, and can thus be used to train CNNs for any combination of contrasts, resolutions and orientations without high-resolution real images of the input contrasts. We test the images generated with SynthSR in an array of common downstream analyses, and show that they can be reliably used for subcortical segmentation and volumetry, image registration (e.g., for tensor-based morphometry), and, if some image quality requirements are met, even cortical thickness morphometry. The source code is publicly available at https://github.com/BBillot/SynthSR.",health
10.1016/j.eswa.2021.114791,Journal,Expert Systems with Applications,scopus,2021-08-15,sciencedirect,Towards graph-based class-imbalance learning for hospital readmission,https://api.elsevier.com/content/abstract/scopus_id/85103637496,"Predicting hospital readmission with effective machine learning techniques has attracted a great attention in recent years. The fundamental challenge of this task stems from characteristics of the data extracted from electronic health records (EHR), which are imbalanced class distributions. This challenge further leads to the failure of most existing models that only provide a partial understanding for the learning problem and result in a biased and inaccurate prediction. To address this challenge, we propose a new graph-based class-imbalance learning method by fully making use of the data from different classes. First, we conduct graph construction for learning the pattern discrimination from between-class and within-class data samples. Then we design an optimization framework to incorporate the constructed graphs to obtain a class-imbalance aware graph embedding and further alleviate performance degeneration. Finally, we design a neural network model as the classifier to conduct imbalanced classification, i.e., hospital readmission prediction. Comprehensive experiments on six real-world readmission datasets show that the proposed method outperforms state-of-the-art approaches in readmission prediction task.",health
10.1016/j.eswa.2021.114848,Journal,Expert Systems with Applications,scopus,2021-08-15,sciencedirect,Domain adaptation based self-correction model for COVID-19 infection segmentation in CT images,https://api.elsevier.com/content/abstract/scopus_id/85103118631,"The capability of generalization to unseen domains is crucial for deep learning models when considering real-world scenarios. However, current available medical image datasets, such as those for COVID-19 CT images, have large variations of infections and domain shift problems. To address this issue, we propose a prior knowledge driven domain adaptation and a dual-domain enhanced self-correction learning scheme. Based on the novel learning scheme, a domain adaptation based self-correction model (DASC-Net) is proposed for COVID-19 infection segmentation on CT images. DASC-Net consists of a novel attention and feature domain enhanced domain adaptation model (AFD-DA) to solve the domain shifts and a self-correction learning process to refine segmentation results. The innovations in AFD-DA include an image-level activation feature extractor with attention to lung abnormalities and a multi-level discrimination module for hierarchical feature domain alignment. The proposed self-correction learning process adaptively aggregates the learned model and corresponding pseudo labels for the propagation of aligned source and target domain information to alleviate the overfitting to noises caused by pseudo labels. Extensive experiments over three publicly available COVID-19 CT datasets demonstrate that DASC-Net consistently outperforms state-of-the-art segmentation, domain shift, and coronavirus infection segmentation methods. Ablation analysis further shows the effectiveness of the major components in our model. The DASC-Net enriches the theory of domain adaptation and self-correction learning in medical imaging and can be generalized to multi-site COVID-19 infection segmentation on CT images for clinical deployment.",health
10.1016/j.medj.2021.06.006,Journal,Med,scopus,2021-08-13,sciencedirect,Real-time analysis of a mass vaccination effort confirms the safety of FDA-authorized mRNA COVID-19 vaccines,https://api.elsevier.com/content/abstract/scopus_id/85110410124,"Background
                  As the coronavirus disease 2019 (COVID-19) vaccination campaign unfolds, it is important to continuously assess the real-world safety of Food and Drug Administration (FDA)-authorized vaccines. Curation of large-scale electronic health records (EHRs) enables near-real-time safety evaluations that were not previously possible.
               
                  Methods
                  In this retrospective study, we deployed deep neural networks over a large EHR system to automatically curate the adverse effects mentioned by physicians in over 1.2 million clinical notes between December 1, 2020 and April 20, 2021. We compared notes from 68,266 individuals who received at least one dose of BNT162b2 (n = 51,795) or mRNA-1273 (n = 16,471) to notes from 68,266 unvaccinated individuals who were matched by demographic, geographic, and clinical features.
               
                  Findings
                  Individuals vaccinated with BNT162b2 or mRNA-1273 had a higher rate of return to the clinic, but not the emergency department, after both doses compared to unvaccinated controls. The most frequently documented adverse effects within 7 days of each vaccine dose included myalgia, headache, and fatigue, but the rates of EHR documentation for each side effect were remarkably low compared to those derived from active solicitation during clinical trials. Severe events, including anaphylaxis, facial paralysis, and cerebral venous sinus thrombosis, were rare and occurred at similar frequencies in vaccinated and unvaccinated individuals.
               
                  Conclusions
                  This analysis of vaccine-related adverse effects from over 1.2 million EHR notes of more than 130,000 individuals reaffirms the safety and tolerability of the FDA-authorized mRNA COVID-19 vaccines in practice.
               
                  Funding
                  This study was funded by nference.",health
10.1016/j.neucom.2021.03.006,Journal,Neurocomputing,scopus,2021-08-11,sciencedirect,Large-scale gastric cancer screening and localization using multi-task deep neural network,https://api.elsevier.com/content/abstract/scopus_id/85104306993,"Gastric cancer is one of the most common cancers, which ranks third among the leading causes of cancer death. Biopsy of gastric mucosa is a standard procedure in gastric cancer screening test. However, manual pathological inspection is labor-intensive and time-consuming. Besides, it is challenging for an automated algorithm to locate the small lesion regions in the gigapixel whole-slide image and make the decision correctly. To tackle these issues, we collected large-scale whole-slide image dataset with detailed lesion region annotation and designed a whole-slide image analyzing framework consisting of 3 networks which could not only determine the screening result but also present the suspicious areas to the pathologist for reference. Experiments demonstrated that our proposed framework achieves sensitivity of 
                        
                           97.05
                           %
                        
                      and specificity of 
                        
                           92.72
                           %
                        
                      in screening task and Dice coefficient of 
                        
                           0.8331
                        
                      in segmentation task. Furthermore, we tested our best model in real-world scenario on 
                        
                           10
                           ,
                           315
                        
                      whole-slide images collected from 4 medical centers.",health
10.1016/j.jconrel.2021.06.039,Journal,Journal of Controlled Release,scopus,2021-08-10,sciencedirect,GANDA: A deep generative adversarial network conditionally generates intratumoral nanoparticles distribution pixels-to-pixels,https://api.elsevier.com/content/abstract/scopus_id/85113277795,"Intratumoral nanoparticles (NPs) distribution is critical for the success of nanomedicine in imaging and treatment, but computational models to describe the NPs distribution remain unavailable due to the complex tumor-nano interactions. Here, we develop a Generative Adversarial Network for Distribution Analysis (GANDA) to describe and conditionally generates the intratumoral quantum dots (QDs) distribution after i.v. injection. This deep generative model is trained automatically by 27,775 patches of tumor vessels and cell nuclei decomposed from whole-slide images of 4 T1 breast cancer sections. The GANDA model can conditionally generate images of intratumoral QDs distribution under the constraint of given tumor vessels and cell nuclei channels with the same spatial resolution (pixels-to-pixels), minimal loss (mean squared error, MSE = 1.871) and excellent reliability (intraclass correlation, ICC = 0.94). Quantitative analysis of QDs extravasation distance (ICC = 0.95) and subarea distribution (ICC = 0.99) is allowed on the generated images without knowing the real QDs distribution. We believe this deep generative model may provide opportunities to investigate how influencing factors affect NPs distribution in individual tumors and guide nanomedicine optimization for molecular imaging and personalized treatment.",health
10.1016/S2589-7500(21)00086-8,Journal,The Lancet Digital Health,scopus,2021-08-01,sciencedirect,Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study,https://api.elsevier.com/content/abstract/scopus_id/85111153013,"Background
                  Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted.
               
                  Methods
                  In this national real-world evidence study, we trained a DLS, the Comprehensive AI Retinal Expert (CARE) system, to identify the 14 most common retinal abnormalities using 207 228 colour fundus photographs derived from 16 clinical settings with different disease distributions. CARE was internally validated using 21 867 photographs and externally tested using 18 136 photographs prospectively collected from 35 real-world settings across China where CARE might be adopted, including eight tertiary hospitals, six community hospitals, and 21 physical examination centres. The performance of CARE was further compared with that of 16 ophthalmologists and tested using datasets with non-Chinese ethnicities and previously unused camera types. This study was registered with ClinicalTrials.gov, NCT04213430, and is currently closed.
               
                  Findings
                  The area under the receiver operating characteristic curve (AUC) in the internal validation set was 0·955 (SD 0·046). AUC values in the external test set were 0·965 (0·035) in tertiary hospitals, 0·983 (0·031) in community hospitals, and 0·953 (0·042) in physical examination centres. The performance of CARE was similar to that of ophthalmologists. Large variations in sensitivity were observed among the ophthalmologists in different regions and with varying experience. The system retained strong identification performance when tested using the non-Chinese dataset (AUC 0·960, 95% CI 0·957–0·964 in referable diabetic retinopathy).
               
                  Interpretation
                  Our DLS (CARE) showed satisfactory performance for screening multiple retinal abnormalities in real-world settings using prospectively collected fundus photographs, and so could allow the system to be implemented and adopted for clinical care.
               
                  Funding
                  This study was funded by the National Key R&D Programme of China, the Science and Technology Planning Projects of Guangdong Province, the National Natural Science Foundation of China, the Natural Science Foundation of Guangdong Province, and the Fundamental Research Funds for the Central Universities.
               
                  Translation
                  For the Chinese translation of the abstract see Supplementary Materials section.",health
10.1016/j.jbi.2021.103840,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,Treatment initiation prediction by EHR mapped PPD tensor based convolutional neural networks boosting algorithm,https://api.elsevier.com/content/abstract/scopus_id/85109424589,"Electronic health records contain patient’s information that can be used for health analytics tasks such as disease detection, disease progression prediction, patient profiling, etc. Traditional machine learning or deep learning methods treat EHR entities as individual features, and no relationships between them are taken into consideration. We propose to evaluate the relationships between EHR features and map them into Procedures, Prescriptions, and Diagnoses (PPD) tensor data, which can be formatted as images. The mapped images are then fed into deep convolutional networks for local pattern and feature learning. We add this relationship-learning part as a boosting module on a commonly used classical machine learning model. Experiments were performed on a Chronic Lymphocytic Leukemia dataset for treatment initiation prediction. Experimental results show that the proposed approach has better real world modeling performance than the baseline models in terms of prediction precision.",health
10.1016/j.jbi.2021.103848,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,Face mask detection using deep learning: An approach to reduce risk of Coronavirus spread,https://api.elsevier.com/content/abstract/scopus_id/85109043381,"Effective strategies to restrain COVID-19 pandemic need high attention to mitigate negatively impacted communal health and global economy, with the brim-full horizon yet to unfold. In the absence of effective antiviral and limited medical resources, many measures are recommended by WHO to control the infection rate and avoid exhausting the limited medical resources. Wearing a mask is among the non-pharmaceutical intervention measures that can be used to cut the primary source of SARS-CoV2 droplets expelled by an infected individual. Regardless of discourse on medical resources and diversities in masks, all countries are mandating coverings over the nose and mouth in public. To contribute towards communal health, this paper aims to devise a highly accurate and real-time technique that can efficiently detect non-mask faces in public and thus, enforcing to wear mask. The proposed technique is ensemble of one-stage and two-stage detectors to achieve low inference time and high accuracy. We start with ResNet50 as a baseline and applied the concept of transfer learning to fuse high-level semantic information in multiple feature maps. In addition, we also propose a bounding box transformation to improve localization performance during mask detection. The experiment is conducted with three popular baseline models viz. ResNet50, AlexNet and MobileNet. We explored the possibility of these models to plug-in with the proposed model so that highly accurate results can be achieved in less inference time. It is observed that the proposed technique achieves high accuracy (98.2%) when implemented with ResNet50. Besides, the proposed model generates 11.07% and 6.44% higher precision and recall in mask detection when compared to the recent public baseline model published as RetinaFaceMask detector. The outstanding performance of the proposed model is highly suitable for video surveillance devices.",health
10.1016/j.media.2021.102145,Journal,Medical Image Analysis,scopus,2021-08-01,sciencedirect,APPLAUSE: Automatic Prediction of PLAcental health via U-net Segmentation and statistical Evaluation,https://api.elsevier.com/content/abstract/scopus_id/85109028622,"Purpose:Artificial-intelligence population-based automated quantification of placental maturation and health from a rapid functional Magnetic Resonance scan. The placenta plays a crucial role for any successful human pregnancy. Deviations from the normal dynamic maturation throughout gestation are closely linked to major pregnancy complications. Antenatal assessment in-vivo using T2* relaxometry has shown great promise to inform management and possible interventions but clinical translation is hampered by time consuming manual segmentation and analysis techniques based on comparison against normative curves over gestation.
                  
                     Methods:This study proposes a fully automatic pipeline to predict the biological age and health of the placenta based on a free-breathing rapid (sub-30 second) T2* scan in two steps: Automatic segmentation using a U-Net and a Gaussian process regression model to characterize placental maturation and health. These are trained and evaluated on 108 3T MRI placental data sets, the evaluation included 20 high-risk pregnancies diagnosed with pre-eclampsia and/or fetal growth restriction. An independent cohort imaged at 1.5 T is used to assess the generalization of the training and evaluation pipeline.
                  
                     Results: Across low- and high-risk groups, automatic segmentation performs worse than inter-rater performance (mean Dice coefficients of 0.58 and 0.68, respectively) but is sufficient for estimating placental mean T2* (0.986 Pearson Correlation Coefficient). The placental health prediction achieves an excellent ability to differentiate cases of placental insufficiency between 27 and 33 weeks. High abnormality scores correlate with low birth weight, premature birth and histopathological findings. Retrospective application on a different cohort imaged at 1.5 T illustrates the ability for direct clinical translation.
                  
                     Conclusion:The presented automatic pipeline facilitates a fast, robust and reliable prediction of placental maturation. It yields human-interpretable and verifiable intermediate results and quantifies uncertainties on the cohort-level and for individual predictions. The proposed machine-learning pipeline runs in close to real-time and, deployed in clinical settings, has the potential to become a cornerstone of diagnosis and intervention of placental insufficiency. APPLAUSE generalizes to an independent cohort imaged at 1.5 T, demonstrating robustness to different operational and clinical environments.",health
10.1016/j.compbiomed.2021.104589,Journal,Computers in Biology and Medicine,scopus,2021-08-01,sciencedirect,Machine learning-based analysis of operator pupillary response to assess cognitive workload in clinical ultrasound imaging,https://api.elsevier.com/content/abstract/scopus_id/85108805307,"Introduction
                  Pupillometry, the measurement of eye pupil diameter, is a well-established and objective modality correlated with cognitive workload. In this paper, we analyse the pupillary response of ultrasound imaging operators to assess their cognitive workload, captured while they undertake routine fetal ultrasound examinations. Our experiments and analysis are performed on real-world datasets obtained using remote eye-tracking under natural clinical environmental conditions.
               
                  Methods
                  Our analysis pipeline involves careful temporal sequence (time-series) extraction by retrospectively matching the pupil diameter data with tasks captured in the corresponding ultrasound scan video in a multi-modal data acquisition setup. This is followed by the pupil diameter pre-processing and the calculation of pupillary response sequences. Exploratory statistical analysis of the operator pupillary responses and comparisons of the distributions between ultrasonographic tasks (fetal heart versus fetal brain) and operator expertise (newly-qualified versus experienced operators) are performed. Machine learning is explored to automatically classify the temporal sequences into the corresponding ultrasonographic tasks and operator experience using temporal, spectral, and time-frequency features with classical (shallow) models, and convolutional neural networks as deep learning models.
               
                  Results
                  Preliminary statistical analysis of the extracted pupillary response shows a significant variation for different ultrasonographic tasks and operator expertise, suggesting different extents of cognitive workload in each case, as measured by pupillometry. The best-performing machine learning models achieve receiver operating characteristic (ROC) area under curve (AUC) values of 0.98 and 0.80, for ultrasonographic task classification and operator experience classification, respectively.
               
                  Conclusion
                  We conclude that we can successfully assess cognitive workload from pupil diameter changes measured while ultrasound operators perform routine scans. The machine learning allows the discrimination of the undertaken ultrasonographic tasks and scanning expertise using the pupillary response sequences as an index of the operators’ cognitive workload. A high cognitive workload can reduce operator efficiency and constrain their decision-making, hence, the ability to objectively assess cognitive workload is a first step towards understanding these effects on operator performance in biomedical applications such as medical imaging.",health
10.1016/j.pmcj.2021.101437,Journal,Pervasive and Mobile Computing,scopus,2021-08-01,sciencedirect,Porting deep neural networks on the edge via dynamic K-means compression: A case study of plant disease detection,https://api.elsevier.com/content/abstract/scopus_id/85108633572,"Cyber Physical Systems (CPS) totally revolutionized the way we interact with the world providing useful services that can support the human being in many aspects of his life. Artificial Intelligence (AI) is another important player for bringing intelligence to CPS and allows the realization of Intelligent Cyber Physical Systems where smart applications can run. However, the constrained hardware of these devices in terms of memory and computing power makes challenging the deployment and execution of powerful algorithms (e.g., deep neural networks). To address this problem, modern solutions involve the use of compression techniques to reduce the memory footprint of deep learning models while saving the accuracy performance. The proposed work focuses on plant disease detection which represents one of the biggest challenges in smart agriculture; in such a context, the possibility to perform a timely diagnosis on crops suspected to be infected can avoid the spread of diseases, thus saving a lot of time and money during the plantation works. In this paper, we realized an intelligent CPS on top of which we implemented an AI application, called Deep Leaf that exploits Convolutional Neural Networks to detect the main biotic stresses affecting crops. To meet the hardware requirements of the Edge device running our application, we propose a novel dynamic compression algorithm based on K-Means for the reduction of models footprint. Experimental results show that our detector is able to correctly classify the plant health condition with an accuracy of 95% and demonstrate the effectiveness of the proposed compression algorithm which is able to maintain the same accuracy of the original 32 bit float model, with an overall memory size reduction of about 85.2%.",health
10.1016/j.prevetmed.2021.105399,Journal,Preventive Veterinary Medicine,scopus,2021-08-01,sciencedirect,Computerized assisted evaluation system for canine cardiomegaly via key points detection with deep learning,https://api.elsevier.com/content/abstract/scopus_id/85108068606,"Cardiomegaly is the main imaging finding for canine heart diseases. There are many advances in the field of medical diagnosing based on imaging with deep learning for human being. However there are also increasing realization of the potential of using deep learning in veterinary medicine. We reported a clinically applicable assisted platform for diagnosing the canine cardiomegaly with deep learning. VHS (vertebral heart score) is a measuring method used for the heart size of a dog. The concrete value of VHS is calculated with the relative position of 16 key points detected by the system, and this result is then combined with VHS reference range of all dog breeds to assist in the evaluation of the canine cardiomegaly. We adopted HRNet (high resolution network) to detect 16 key points (12 and four key points located on vertebra and heart respectively) in 2274 lateral X-ray images (training and validation datasets) of dogs, the model was then used to detect the key points in external testing dataset (396 images), the AP (average performance) for key point detection reach 86.4 %. Then we applied an additional post processing procedure to correct the output of HRNets so that the AP reaches 90.9 %. This result signifies that this system can effectively assist the evaluation of canine cardiomegaly in a real clinical scenario.",health
10.1016/j.compbiomed.2021.104547,Journal,Computers in Biology and Medicine,scopus,2021-08-01,sciencedirect,Predicting cell behaviour parameters from glioblastoma on a chip images. A deep learning approach,https://api.elsevier.com/content/abstract/scopus_id/85107956667,"The broad possibilities offered by microfluidic devices in relation to massive data monitoring and acquisition open the door to the use of deep learning technologies in a very promising field: cell culture monitoring. In this work, we develop a methodology for parameter identification in cell culture from fluorescence images using Convolutional Neural Networks (CNN). We apply this methodology to the in vitro study of glioblastoma (GBM), the most common, aggressive and lethal primary brain tumour. In particular, the aim is to predict the three parameters defining the go or grow GBM behaviour, which is determinant for the tumour prognosis and response to treatment. The data used to train the network are obtained from a mathematical model, previously validated with in vitro experimental results. The resulting CNN provides remarkably accurate predictions (Pearson's ρ > 0.99 for all the parameters). Besides, it proves to be sound, to filter noise and to generalise. After training and validation with synthetic data, we predict the parameters corresponding to a real image of a microfluidic experiment. The obtained results show good performance of the CNN. The proposed technique may set the first steps towards patient-specific tools, able to predict in real-time the tumour evolution for each particular patient, thanks to a combined in vitro-in silico approach.",health
10.1016/j.jocn.2021.05.015,Journal,Journal of Clinical Neuroscience,scopus,2021-08-01,sciencedirect,Potential and limitations of radiomics in neuro-oncology,https://api.elsevier.com/content/abstract/scopus_id/85107849829,"Radiomics seeks to apply classical methods of image processing to obtain quantitative parameters from imaging. Derived features are subsequently fed into algorithmic models to aid clinical decision making. The application of radiomics and machine learning techniques to clinical medicine remains in its infancy. The great potential of radiomics lies in its objective, granular approach to investigating clinical imaging. In neuro-oncology, advanced machine learning techniques, particularly deep learning, are at the forefront of new discoveries in the field. However, despite the great promise of machine learning aided radiomic approaches, the current use remains confined to scholarly research, without real-world deployment in neuro-oncology. The paucity of data, inconsistencies in preprocessing, radiomic feature instability, and the rarity of the events of interest are critical barriers to clinical translation. In this article, we will outline the major steps in the process of radiomics, as well as review advances and challenges in the field as they pertain to neuro-oncology.",health
10.1016/j.cmpb.2021.106212,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-08-01,sciencedirect,Deep learning for tracing esophageal motility function over time,https://api.elsevier.com/content/abstract/scopus_id/85107745430,"Background and Objective: Esophageal high-resolution manometry (HRM) is widely performed to evaluate the representation of manometric features in patients for diagnosing normal esophageal motility and motility disorders. Clinicians commonly assess esophageal motility function using a scheme termed the Chicago classification, which is difficult, time-consuming and inefficient with large amounts of data. Methods: Deep learning is a promising approach for diagnosing disorders and has various attractive advantages. In this study, we effectively trace esophageal motility function with HRM by using a deep learning computational model, namely, EMD-DL, which leverages three-dimensional convolution (Conv3D) and bidirectional convolutional long-short-term-memory (BiConvLSTM) models. More specifically, to fully exploit wet swallowing information, we establish an efficient swallowing representation method by localizing manometric features and swallowing box regressions from HRM. Then, EMD-DL learns how to identify major motility disorders, minor motility disorders and normal motility. To the best of our knowledge, this is the first attempt to use Conv3D and BiConvLSTM to predict esophageal motility function over esophageal HRM. Results: Test experiments on HRM datasets demonstrated that the overall accuracy of the proposed EMD-DL model is 91.32% with 90.5% sensitivity and 95.87% specificity. By leveraging information across swallowing motor cycles, our model can rapidly recognize esophageal motility function better than a gastroenterologist and lays the foundation for accurately diagnosing esophageal motility disorders in real time. Conclusions: This approach opens new avenues for detecting and identifying esophageal motility function, thereby facilitating more efficient computer-aided diagnosis in clinical practice.",health
10.1016/j.gsd.2021.100612,Journal,Groundwater for Sustainable Development,scopus,2021-08-01,sciencedirect,"Assessing drinking water quality based on physical, chemical and microbial parameters in the Red Sea State, Sudan using a combination of water quality index and artificial neural network model",https://api.elsevier.com/content/abstract/scopus_id/85107352300,"This study aimed to assess the quality of water resources, and its suitability for the drinking uses in Red Sea State, Sudan. Particularly, with regard to international standards from the World Health Organization (WHO/2017), and the national standards from Sudanese Standard and Meteorology Organization for drinking water (SDS-044/2007). Twenty locations site were investigated to represent this important area, where its analysed for compliance with the national and international standards, furthermore, the suitability for drinking purpose was assessed by using water quality index (WQI) method. Artificial Neural Network (ANN) was applied to predict the QWI by using the algorithm of feed forward back propagation artificial neural networks (BP ANN) for optimization. Physio-chemical assessments indicated that, water resources did not conform to the safe limits, especially heavy metals likes cadmium, which has the highest concentrations-hazard in almost all samples. High lead levels were observed at nineteen sites, while a high concentrations of nickel, and Total dissolved solids were observed at seven locations. The microbial assessment indicated most of locations did not conform to the safe limits, a high bacteria –hazard for Total coliform and Escherichia coli were observed in fourteen, and seven locations, respectively. Computed WQI values ranged from 35.61 to 337.52. ANN model showed much high prediction accuracy of WQI modeling with R2 values greater than 0.95 during training, testing and validation. WQI spatial distribution shown that, Red Sea State has unsuitable water quality in most of study sites (70%). The effects of heavy pollutants dominated on the water quality, and spread in these regions. This study conducted the first full-scale survey of the drinking water sources (ground and surface) in the Red Sea State of Sudan. Based on these results, we recommended that, an urgent measures such as a chemical treatments to treat the pollution, with/or filters installation should be implemented as soon as possible to manage and protect the water resources.",health
10.1016/j.measurement.2021.109565,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-08-01,sciencedirect,Intelligent fault diagnosis of planetary gearbox based on adaptive normalized CNN under complex variable working conditions and data imbalance,https://api.elsevier.com/content/abstract/scopus_id/85107298743,"In real industrial application, the operating conditions of the planetary gearbox are always variable speed and variable load according to production. Meanwhile, the scarcity of fault data and different working conditions lead to serious data imbalance and distribution differences, which make a great challenge for planetary gearbox fault detection and diagnosis. To address these issues, a novel adaptive normalized convolutional neural network (ANCNN) is developed to accurately and automatically diagnose the different fault locations and severities of planetary gearbox considering the scenarios of complex variable working conditions and data imbalance. First, Teager calculated order (TCO) spectrum is applied to avoid the influences of large speed fluctuations and variable loads, which is an efficient pretreatment approach for the proposed ANCNN. Then, the batch normalization algorithm is adopted to eliminate the feature distribution differences caused by variable operating modes and data imbalance. Finally, in order to automatically adapt to different planetary gearbox diagnosis circumstances, the particle swarm optimization (PSO) strategy is used for optimizing and flexibly deciding the key hyperparameters of the designed model, thereby improving the overall performance of the model. The effectiveness of the presented method is confirmed through experiments on two different planetary gearbox datasets, which are from a generic planetary gearbox for industrial applications and a drivetrain dynamic simulator test rig. In addition, comparison with other mainstream intelligent diagnosis techniques validates the superiority of the presented method. The experimental results demonstrate that the presented method can achieve diagnostic accuracies of better than 99.8%, and also shows excellent stability for the unbalanced data classification.",health
10.1016/j.cmpb.2021.106127,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-08-01,sciencedirect,Synthetic microbleeds generation for classifier training without ground truth,https://api.elsevier.com/content/abstract/scopus_id/85106973314,"Background and Objective
                  Cerebral microbleeds (CMB) are important biomarkers of cerebrovascular diseases and cognitive dysfunctions. Susceptibility weighted imaging (SWI) is a common MRI sequence where CMB appear as small hypointense blobs. The prevalence of CMB in the population and in each scan is low, resulting in tedious and time-consuming visual assessment. Automated detection methods would be of value but are challenged by the CMB low prevalence, the presence of mimics such as blood vessels, and the difficulty to obtain sufficient ground truth for training and testing. In this paper, synthetic CMB (sCMB) generation using an analytical model is proposed for training and testing machine learning methods. The main aim is creating perfect synthetic ground truth as similar as reals, in high number, with a high diversity of shape, volume, intensity, and location to improve training of supervised methods.
               
                  Method
                  sCMB were modelled with a random Gaussian shape and added to healthy brain locations. We compared training on our synthetic data to standard augmentation techniques. We performed a validation experiment using sCMB and report result for whole brain detection using a 10-fold cross validation design with an ensemble of 10 neural networks.
               
                  Results
                  Performance was close to state of the art (~9 false positives per scan), when random forest was trained on synthetic only and tested on real lesion. Other experiments showed that top detection performance could be achieved when training on synthetic CMB only. Our dataset is made available, including a version with 37,000 synthetic lesions, that could be used for benchmarking and training.
               
                  Conclusion
                  Our proposed synthetic microbleeds model is a powerful data augmentation approach for CMB classification with and should be considered for training automated lesion detection system from MRI SWI.",health
10.1016/j.cmpb.2021.106168,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-08-01,sciencedirect,Semi-AI and Full-AI digitizer: The ways to digitalize visual field big data,https://api.elsevier.com/content/abstract/scopus_id/85106865896,"Background and objective
                  Glaucoma is one of the major diseases that cause blindness, which is incurable and irreversible, and it is essential to detect glaucoma vision deficits in treatment and check the progression of vision disorders in advance. In order to minimize the risk of glaucoma, it is necessary not only to diagnose and observe glaucoma but also to predict prognosis via indicators from Visual Field (VF) tests. However, information from the VF test cannot be directly used in clinical studies because most medical institutions store VF test sheets in Portable Document Format (PDF) or image files in different standards.
               
                  Methods
                  We developed AI-based real-time VF big data digitizing systems that digitalize VF test images in real-time in two ways; Semi-AI and Full-AI digitizer. The Semi-AI digitizer detects the VF text area with actual coordinates derived from mouse handler system. Full-AI digitizer detects the VF text area with Faster Region Based Convolutional Neural Networks (RCNN). After detecting the text area, both systems extract texts with Recurrent Neural Network based Optical Character Recognition. Semi-AI and Full-AI digitizer post-processes the extracted text results with in-system algorithm and out-of-system algorithm, respectively.
               
                  Results
                  Both systems used 325,310 VF test sheets from a tertiary hospital and extracted a total of 5,530,270 texts. From the 100 randomly selected VF sheets, 3,400 texts were used for the validation. Semi-AI and Full-AI digitizer showed 0.993 and 0.983 of accuracy, respectively.
               
                  Conclusion
                  This study demonstrates the effectiveness of AI applications in detecting text areas and the different implementation methodologies of the post-processing process. In detecting text area, Semi-AI may be better than Full-AI digitizer in terms of system speed and human labor labeling if the number of types to be classified is small. However, Full-AI digitizer is recommended because it allows detecting text area regardless of resolution and size of the VF sheets, as the types of real-world VF test sheets cannot be predicted, and the types become more unpredictable when extended to multi-hospital studies. For Post-preprocessing, Semi-AI methodology is recommended because Semi-AI produced higher results with less effort and considered the convenience of researchers by implementing them as in-system.",health
10.1016/j.jviromet.2021.114183,Journal,Journal of Virological Methods,scopus,2021-08-01,sciencedirect,Development of an immunochromatographic kit to detect severe acute respiratory syndrome coronavirus 2,https://api.elsevier.com/content/abstract/scopus_id/85106322644,"Background
                  The novel severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) is responsible for the worldwide coronavirus disease-19 (COVID-19) pandemic, starting in late 2019. The standard diagnostic methods to detect SARS-CoV-2 are PCR-based genetic assays. Antigen-antibody-based immunochromatographic assays are alternative methods of detecting this virus. Rapid diagnosis kits to detect SARS-CoV-2 are urgently needed.
               
                  Study design
                  Three monoclonal antibodies against SARS-CoV-2 nucleocapsid (N) protein were used to develop an antigen-antibody-based immunochromatographic kit to detect SARS-CoV-2. These assays were evaluated using　 nasopharyngeal swab specimens collected from patients suspected of having COVID-19.
               
                  Results
                  These assays detected recombinant SARS-CoV-2 N protein at concentrations >0.2 ng/mL within 10 min after protein loading, but did not detect the N proteins of Middle East respiratory syndrome coronavirus (MERS-CoV), human coronaviruses OC43 (HCoV-OC43) and 299E (HCoV-229E) and other pathogens causing respiratory infections. Nasopharyngeal swab specimens obtained 1～3, 4～9, and ≥ 10 days after symptom onset from COVID-19 patients diagnosed by RT-PCR showed positivity rates of 100 %, >80 %, and <30 %, respectively.
               
                  Conclusions
                  Kits using this immunochromatographic assay may be a rapid and useful tool for point-of-care diagnosis of COVID-19 when samples are obtained from patients 1～9 days after symptom onset.",health
10.1016/j.renene.2021.04.040,Journal,Renewable Energy,scopus,2021-08-01,sciencedirect,Damage identification of wind turbine blades with deep convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85105896900,"Online early detection of surface damages on blades is critical for the safety of wind turbines, which could avoid catastrophic failures, minimize downtime, and enhance the reliability of the system. Monitoring the health status of blades is attracting more and more attention including on-site cameras and mobile cameras by drones and crawling robots. To deploy fast and efficient damage detection methods from image data, this work presents a hierarchical identification framework for wind turbine blades, which consists of a Haar-AdaBoost step for region proposal and a convolutional neural network (CNN) classifier for damage detection and fault diagnosis. Case studies are carried out on real data set collected from an eastern China wind farm. Results show that (i) the proposed framework can detect and identify the blade damages and outperforms other schemes include SVM and VGG16 models, (ii) sensitive analysis is conducted to validate the robustness of proposed method under limited data conditions, (iii) the proposed scheme is faster than one-step CNN method that directly classifying raw data.",health
10.1016/j.compstruc.2021.106568,Journal,Computers and Structures,scopus,2021-08-01,sciencedirect,A hybrid computational intelligence approach for structural damage detection using marine predator algorithm and feedforward neural networks,https://api.elsevier.com/content/abstract/scopus_id/85105544720,"Finite element (FE) based structural health monitoring (SHM) algorithms seek to update structural damage indices through solving an optimisation problem in which the difference between the response of the real structure and a corresponding FE model to some excitation force is minimised. These techniques, therefore, exploit advanced optimisation algorithms to alleviate errors stemming from the lack of information or the use of highly noisy measured responses. This study proposes an effective approach for damage detection by using a recently developed novel swarm intelligence algorithm, i.e. the marine predator algorithm (MPA). In the proposed approach, optimal foraging strategy and marine memory are employed to improve the learning ability of feedforward neural networks. After training, the hybrid feedforward neural networks and marine predator algorithm, MPAFNN, produces the best combination of connection weights and biases. These weights and biases then are re-input to the networks for prediction. Firstly, the classification capability of the proposed algorithm is investigated in comparison with some well-known optimization algorithms such as particle swarm optimization (PSO), gravitational search algorithm (GSA), hybrid particle swarm optimization-gravitational search algorithm (PSOGSA), and grey wolf optimizer (GWO) via four classification benchmark problems. The superior and stable performance of MPAFNN proves its effectiveness. Then, the proposed method is applied for damage identification of three numerical models, i.e. a simply supported beam, a two-span continuous beam, and a laboratory free-free beam by using modal flexibility indices. The obtained results reveal the feasibility of the proposed approach in damage identification not only for different structures with single damage and multiple damage, but also considering noise effect.",health
10.1016/j.annemergmed.2021.02.029,Journal,Annals of Emergency Medicine,scopus,2021-08-01,sciencedirect,Development and Validation of Machine Learning Models to Predict Admission From Emergency Department to Inpatient and Intensive Care Units,https://api.elsevier.com/content/abstract/scopus_id/85105468712,"Study objective
                  This study aimed to develop and validate 2 machine learning models that use historical and current-visit patient data from electronic health records to predict the probability of patient admission to either an inpatient unit or ICU at each hour (up to 24 hours) of an emergency department (ED) encounter. The secondary goal was to provide a framework for the operational implementation of these machine learning models.
               
                  Methods
                  Data were curated from 468,167 adult patient encounters in 3 EDs (1 academic and 2 community-based EDs) of a large academic health system from August 1, 2015, to October 31, 2018. The models were validated using encounter data from January 1, 2019, to December 31, 2019. An operational user dashboard was developed, and the models were run on real-time encounter data.
               
                  Results
                  For the intermediate admission model, the area under the receiver operating characteristic curve was 0.873 and the area under the precision-recall curve was 0.636. For the ICU admission model, the area under the receiver operating characteristic curve was 0.951 and the area under the precision-recall curve was 0.461. The models had similar performance in both the academic- and community-based settings as well as across the 2019 and real-time encounter data.
               
                  Conclusion
                  Machine learning models were developed to accurately make predictions regarding the probability of inpatient or ICU admission throughout the entire duration of a patient’s encounter in ED and not just at the time of triage. These models remained accurate for a patient cohort beyond the time period of the initial training data and were integrated to run on live electronic health record data, with similar performance.",health
10.1016/j.scs.2021.102945,Journal,Sustainable Cities and Society,scopus,2021-08-01,sciencedirect,Effective task scheduling algorithm with deep learning for Internet of Health Things (IoHT) in sustainable smart cities,https://api.elsevier.com/content/abstract/scopus_id/85105291613,"In the recent years, important key factor for urban planning is to analyze the sustainability and its functionality towards smart cities. Presently, many researchers employ the conservative machine learning based analysis but those are not appropriate for IoT based health data analysis because of their physical feature extraction and low accuracy. In this paper, we propose remote health monitoring and data analysis by integrating IoT and deep learning concepts. We proposed novel IoT based FoG assisted cloud network architecture that accumulates real-time health care data from patients via several medical IoT sensor networks, these data are analyzed using a deep learning algorithm deployed at Fog based Healthcare Platform. Furthermore, the proposed methodology is applied to the sustainable smart cities to evaluate the process for real-time. The proposed framework not only analyses the healthcare data but also provides immediate relief measures to the patient facing critical conditions and needs immediate consultancy of doctor. Performance is measure in terms of accuracy, precision and sensitivity of the proposed DHNN with task scheduling algorithm and it is obtained 97.6%, 97.9%, and 94.9%. While accuracy, precision and sensitivity for deep CNN is 96.5%, 97.5% and 94% and for Deep auto-encoder is 92%, 91%, and 82.5%.",health
10.1016/j.dss.2021.113539,Journal,Decision Support Systems,scopus,2021-08-01,sciencedirect,Predicting employee absenteeism for cost effective interventions,https://api.elsevier.com/content/abstract/scopus_id/85105018797,"This paper describes a decision support system designed for a Belgian Human Resource (HR) and Well-Being Service Provider. Their goal is to improve health and well-being in the workplace, and to this end, the task is to identify groups of employees at risk of sickness absence who can then be targeted with interventions aiming to reduce or prevent absences. To facilitate deployment, we apply a range of existing machine-learning methods to obtain predictions at monthly intervals using real HR and payroll data that contains no health-related predictors. We model employee absence as a binary classification problem with loss asymmetry and conceptualise a misclassification cost matrix of employee sickness absence. Model performance is evaluated using cost-based metrics, which have intuitive interpretation. We also demonstrate how this problem can be approached when costs are unknown. The proposed flexible evaluation procedure is not restricted to a specific model or domain and can be applied to address other HR analytics questions when deployed. Our approach of considering a wider range of methods and cost-based performance evaluation is novel in the domain of absenteeism prediction.",health
10.1016/j.irbm.2020.07.002,Journal,IRBM,scopus,2021-08-01,sciencedirect,A Computationally Efficient Correlational Neural Network for Automated Prediction of Chronic Kidney Disease,https://api.elsevier.com/content/abstract/scopus_id/85087974451,"Objectives
                  In this paper, we propose a computationally efficient Correlational Neural Network (CorrNN) learning model and an automated diagnosis system for detecting Chronic Kidney Disease (CKD). A Support Vector Machine (SVM) classifier is integrated with the CorrNN model for improving the prediction accuracy.
               
                  Material and methods
                  The proposed hybrid model is trained and tested with a novel sensing module. We have monitored the concentration of urea in the saliva sample to detect the disease. Experiments are carried out to test the model with real-time samples and to compare its performance with conventional Convolutional Neural Network (CNN) and other traditional data classification methods.
               
                  Results
                  The proposed method outperforms the conventional methods in terms of computational speed and prediction accuracy. The CorrNN-SVM combined network achieved a prediction accuracy of 98.67%. The experimental evaluations show a reduction in overall computation time of about 9.85% compared to the conventional CNN algorithm.
               
                  Conclusion
                  The use of the SVM classifier has improved the capability of the network to make predictions more accurately. The proposed framework substantially advances the current methodology, and it provides more precise results compared to other data classification methods.",health
10.1016/j.bbrc.2020.10.077,Journal,Biochemical and Biophysical Research Communications,scopus,2021-07-30,sciencedirect,"Life, death, and self: Fundamental questions of primitive cognition viewed through the lens of body plasticity and synthetic organisms",https://api.elsevier.com/content/abstract/scopus_id/85095615733,"Central to the study of cognition is being able to specify the Subject that is making decisions and owning memories and preferences. However, all real cognitive agents are made of parts (such as brains made of cells). The integration of many active subunits into a coherent Self appearing at a larger scale of organization is one of the fundamental questions of evolutionary cognitive science. Typical biological model systems, whether basal or advanced, have a static anatomical structure which obscures important aspects of the mind-body relationship. Recent advances in bioengineering now make it possible to assemble, disassemble, and recombine biological structures at the cell, organ, and whole organism levels. Regenerative biology and controlled chimerism reveal that studies of cognition in intact, “standard”, evolved animal bodies are just a narrow slice of a much bigger and as-yet largely unexplored reality: the incredible plasticity of dynamic morphogenesis of biological forms that house and support diverse types of cognition. The ability to produce living organisms in novel configurations makes clear that traditional concepts, such as body, organism, genetic lineage, death, and memory are not as well-defined as commonly thought, and need considerable revision to account for the possible spectrum of living entities. Here, I review fascinating examples of experimental biology illustrating that the boundaries demarcating somatic and cognitive Selves are fluid, providing an opportunity to sharpen inquiries about how evolution exploits physical forces for multi-scale cognition. Developmental (pre-neural) bioelectricity contributes a novel perspective on how the dynamic control of growth and form of the body evolved into sophisticated cognitive capabilities. Most importantly, the development of functional biobots – synthetic living machines with behavioral capacity – provides a roadmap for greatly expanding our understanding of the origin and capacities of cognition in all of its possible material implementations, especially those that emerge de novo, with no lengthy evolutionary history of matching behavioral programs to bodyplan. Viewing fundamental questions through the lens of new, constructed living forms will have diverse impacts, not only in basic evolutionary biology and cognitive science, but also in regenerative medicine of the brain and in artificial intelligence.",health
10.1016/j.enbuild.2021.110967,Journal,Energy and Buildings,scopus,2021-07-15,sciencedirect,"A non-intrusive approach for fault detection and diagnosis of water distribution systems based on image sensors, audio sensors and an inspection robot",https://api.elsevier.com/content/abstract/scopus_id/85104453372,"Fault diagnosis is important to maintain the normal operation of air-conditioning systems, reduce the energy consumption in buildings, and increase the service life of air-conditioning system equipment. We present a novel approach for fault detection and diagnosis system that relies on image and audio sensors and relevant algorithms.
                  This paper proposes a fault diagnosis algorithm based on a robot that can automatically capture audio and image signals from microphone arrays and cameras during inspection in a chiller room. It includes audio- and image-based fault diagnosis algorithms. The validity of the algorithm combined with sensors is verified using data from actual equipment in a chiller room.
                  The audio-based algorithm, which can monitor the abnormal sound of pumps to detect faults, utilizes Fourier transform, a finite impulse response digital filter, and an autoregressive integrated moving average model. We analyze the frequency domain of the pump signal and set the appropriate threshold to monitor abnormal signals based on the fitted model. Meanwhile, the image-based algorithms are divided into three sections to achieve three functions: 1) an AlexNet convolutional neural network is modified to classify the images of the chiller room equipment obtained by the visible light camera; 2) image morphology methods and trigonometric functions are used to read the dials’ indicators acquired by the visible light camera; and 3) optical character recognition is used to obtain the highest temperature value in the infrared image of the pump captured by the infrared camera, which helps maintenance staff verify the operation of the pump and detect faults as soon as possible.
                  These diagnostic algorithms are non-intrusive, low cost, and easy to deploy. Combined with real-time data collection from the sensors on the robot, the algorithms can effectively improve the intelligence of the equipment room and allocate human resources more reasonably.",health
10.1016/j.neucom.2020.08.091,Journal,Neurocomputing,scopus,2021-07-15,sciencedirect,Enhancing random forest classification with NLP in DAMEH: A system for DAta Management in eHealth Domain,https://api.elsevier.com/content/abstract/scopus_id/85101877123,"The use of pervasive IoT devices in Smart Cities, have increased the Volume of data produced in many and many field. Interesting and very useful applications grow up in number in E-health domain, where smart devices are used in order to manage huge amount of data, in highly distributed environments, in order to provide smart services able to collect data to fill medical records of patients. The problem here is to gather data, to produce records and to analyze medical records depending on their contents. Since data gathering involve very different devices (not only wearable medical sensors, but also environmental smart devices, like weather, pollution and other sensors) it is very difficult to classify data depending their contents, in order to enable better management of patients. Data from smart devices couple with medical records written in natural language: we describe here an architecture that is able to determine best features for classification, depending on existent medical records. The architecture is based on pre-filtering phase based on Natural Language Processing, that is able to enhance Machine learning classification based on Random Forests. We carried on experiments on about 5000 medical records from real (anonymized) case studies from various health-care organizations in Italy. We show accuracy of the presented approach in terms of Accuracy-Rejection curves.",health
10.1016/j.knosys.2021.107052,Journal,Knowledge-Based Systems,scopus,2021-07-08,sciencedirect,In-hospital resource utilization prediction from electronic medical records with deep learning,https://api.elsevier.com/content/abstract/scopus_id/85104581569,"Effective healthcare resource allocation is critical for intelligent medical systems, and accurate in-hospital resource utilization prediction from medical records is a prerequisite. Existing methods for this task usually rely on manual feature engineering which needs massive domain knowledge, and do not exploit the textual information in electronic medical records, e.g., diagnosis and operation texts. In this paper, we propose a deep in-hospital resource utilization prediction approach to jointly estimate the in-hospital costs and length of stays from patients’ admission records via multi-task learning. Our approach can exploit the heterogeneous information in records, such as patient features, diagnosis/operation texts, and the diagnosis/operation IDs, via a multi-view learning framework, where Transformers are used to learn the representations of words, diagnoses and operations. In addition, we design a diagnosis–operation attention network to capture the relations between diagnoses and operations. Besides, since different words, diagnoses and operations have different importance for cost estimation, we incorporate a hierarchical attention network to select important words, diagnoses and operations for learning informative record representations. Extensive experiments on a real-world medical dataset validate the effectiveness of our approach.",health
10.1016/j.ebiom.2021.103465,Journal,EBioMedicine,scopus,2021-07-01,sciencedirect,A mass spectrometry-based targeted assay for detection of SARS-CoV-2 antigen from clinical specimens,https://api.elsevier.com/content/abstract/scopus_id/85109005451,"Background
                  The COVID-19 pandemic caused by severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) has overwhelmed health systems worldwide and highlighted limitations of diagnostic testing. Several types of diagnostic tests including RT-PCR-based assays and antigen detection by lateral flow assays, each with their own strengths and weaknesses, have been developed and deployed in a short time.
               
                  Methods
                  Here, we describe an immunoaffinity purification approach followed a by high resolution mass spectrometry-based targeted qualitative assay capable of detecting SARS-CoV-2 viral antigen from nasopharyngeal swab samples. Based on our discovery experiments using purified virus, recombinant viral protein and nasopharyngeal swab samples from COVID-19 positive patients, nucleocapsid protein was selected as a target antigen. We then developed an automated antibody capture-based workflow coupled to targeted high-field asymmetric waveform ion mobility spectrometry (FAIMS) - parallel reaction monitoring (PRM) assay on an Orbitrap Exploris 480 mass spectrometer. An ensemble machine learning-based model for determining COVID-19 positive samples was developed using fragment ion intensities from the PRM data.
               
                  Findings
                  The optimized targeted assay, which was used to analyze 88 positive and 88 negative nasopharyngeal swab samples for validation, resulted in 98% (95% CI = 0.922–0.997) (86/88) sensitivity and 100% (95% CI = 0.958–1.000) (88/88) specificity using RT-PCR-based molecular testing as the reference method.
               
                  Interpretation
                  Our results demonstrate that direct detection of infectious agents from clinical samples by tandem mass spectrometry-based assays have potential to be deployed as diagnostic assays in clinical laboratories, which has hitherto been limited to analysis of pure microbial cultures.
               
                  Funding
                  This study was supported by DBT/Wellcome Trust India Alliance Margdarshi Fellowship grant IA/M/15/1/502023 awarded to AP and the generosity of Eric and Wendy Schmidt.",health
10.1016/j.jstrokecerebrovasdis.2021.105826,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-07-01,sciencedirect,Automatic Acute Stroke Symptom Detection and Emergency Medical Systems Alerting by Mobile Health Technologies: A Review,https://api.elsevier.com/content/abstract/scopus_id/85107711467,"Objectives
                  To survey recent advances in acute stroke symptom automatic detection and Emergency Medical Systems (EMS) alerting by mobile health technologies.
               
                  Materials and methods
                  Narrative review
               
                  Results
                  Delayed activation of EMS for stroke symptoms by patients and witnesses deprives patients of rapid access to brain-saving therapies and occurs due to public unawareness of stroke features, cognitive and motor deficits produced by the stroke itself, and sleep onset. A promising emerging approach to overcoming the inherent biologic constraints of patient capacity to self-detect and respond to stroke symptoms is continuous monitoring by mobile health technologies with wireless sensors and artificial intelligence recognition systems. This review surveys 11 sensing technologies - accelerometers, gyroscopes, magnetometers, pressure sensors, touch screen and keyboard input detectors, artificial vision, and artificial hearing; and 10 consumer device form factors in which they are increasingly implemented: smartphones, smart speakers, smart watches and fitness bands, smart speakers/voice assistants, home health robots, smart clothing, smart beds, closed circuit television, smart rings, and desktop/laptop/tablet computers.
               
                  Conclusions
                  The increase in computing power, wearable sensors, and mobile connectivity have ushered in an array of mobile health technologies that can transform stroke detection and EMS activation. By continuously monitoring a diverse range of biometric parameters, commercially available devices provide the technologic capability to detect cardinal language, motor, gait, and sensory signs of stroke onset. Intensified translational research to convert the promise of these technologies to validated, accurate real-world deployments are an important next priority for stroke investigation.",health
10.1016/j.cmpb.2021.106130,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-07-01,sciencedirect,"Chest x-ray automated triage: A semiologic approach designed for clinical implementation, exploiting different types of labels through a combination of four Deep Learning architectures",https://api.elsevier.com/content/abstract/scopus_id/85107617149,"Background and objectives
                  The multiple chest x-ray datasets released in the last years have ground-truth labels intended for different computer vision tasks, suggesting that performance in automated chest x-ray interpretation might improve by using a method that can exploit diverse types of annotations. This work presents a Deep Learning method based on the late fusion of different convolutional architectures, that allows training with heterogeneous data with a simple implementation, and evaluates its performance on independent test data. We focused on obtaining a clinically useful tool that could be successfully integrated into a hospital workflow.
               
                  Materials and methods
                  Based on expert opinion, we selected four target chest x-ray findings, namely lung opacities, fractures, pneumothorax and pleural effusion. For each finding we defined the most suitable type of ground-truth label, and built four training datasets combining images from public chest x-ray datasets and our institutional archive. We trained four different Deep Learning architectures and combined their outputs with a late fusion strategy, obtaining a unified tool. The performance was measured on two test datasets: an external openly-available dataset, and a retrospective institutional dataset, to estimate performance on the local population.
               
                  Results
                  The external and local test sets had 4376 and 1064 images, respectively, for which the model showed an area under the Receiver Operating Characteristics curve of 0.75 (95%CI: 0.74–0.76) and 0.87 (95%CI: 0.86–0.89) in the detection of abnormal chest x-rays. For the local population, a sensitivity of 86% (95%CI: 84–90), and a specificity of 88% (95%CI: 86–90) were obtained, with no significant differences between demographic subgroups. We present examples of heatmaps to show the accomplished level of interpretability, examining true and false positives.
               
                  Conclusion
                  This study presents a new approach for exploiting heterogeneous labels from different chest x-ray datasets, by choosing Deep Learning architectures according to the radiological characteristics of each pathological finding. We estimated the tool's performance on the local population, obtaining results comparable to state-of-the-art metrics. We believe this approach is closer to the actual reading process of chest x-rays by professionals, and therefore more likely to be successful in a real clinical setting.",health
10.1016/j.smhl.2021.100205,Journal,Smart Health,scopus,2021-07-01,sciencedirect,Wearable motion sensor-based chewing side detection,https://api.elsevier.com/content/abstract/scopus_id/85107281216,"Chewing side preference means a tendency to use one side to chew food more frequently than the other. Medical studies show that chewing side preference can result in lateral facial asymmetry, teeth abrasion, temporomandibular disorders, malocclusion, and stomach illness. To continuously detect chewing side preference and quantify its severity in daily life, several wearable sensor-based methods have been proposed in recent years. However, these methods are either intrusive or not fine-grained enough. In this paper, we propose a wearable motion sensor-based chewing side detection method. We observe that chewing activity generates mastication muscle bulge and skull vibration, which can be sensed by motion sensors worn on the mastication muscles. In addition, the muscle bulge and skull vibration of the chewing side are different from those of the non-chewing side. These observations motivate us to deploy motion sensors on the left and right temporalis muscles to detect chewing sides. We propose a heuristic-rules based method to exclude non-chewing data and segment each chew accurately. The relative difference series of the left and right sensors are then calculated to characterize the difference of muscle bulge and skull vibration between the chewing side and the non-chewing side. A two-class classifier is trained using long short-term memory (LSTM), an artificial recurrent neural network, to model the data samples and classify chewing sides. A real-world evaluation dataset of eight food types is collected from eight human subjects. The average detection accuracy reaches 84.8%. The highest detection accuracy for a single subject is up to 97.4%.",health
10.1016/j.artmed.2021.102083,Journal,Artificial Intelligence in Medicine,scopus,2021-07-01,sciencedirect,Multi-domain clinical natural language processing with MedCAT: The Medical Concept Annotation Toolkit,https://api.elsevier.com/content/abstract/scopus_id/85106551455,"Electronic health records (EHR) contain large volumes of unstructured text, requiring the application of information extraction (IE) technologies to enable clinical analysis. We present the open source Medical Concept Annotation Toolkit (MedCAT) that provides: (a) a novel self-supervised machine learning algorithm for extracting concepts using any concept vocabulary including UMLS/SNOMED-CT; (b) a feature-rich annotation interface for customizing and training IE models; and (c) integrations to the broader CogStack ecosystem for vendor-agnostic health system deployment. We show improved performance in extracting UMLS concepts from open datasets (F1:0.448–0.738 vs 0.429–0.650). Further real-world validation demonstrates SNOMED-CT extraction at 3 large London hospitals with self-supervised training over 
                        ∼
                     8.8B words from 
                        ∼
                     17M clinical records and further fine-tuning with 
                        ∼
                     6K clinician annotated examples. We show strong transferability (F1 > 0.94) between hospitals, datasets and concept types indicating cross-domain EHR-agnostic utility for accelerated clinical and research use cases.",health
10.1016/j.artmed.2021.102082,Journal,Artificial Intelligence in Medicine,scopus,2021-07-01,sciencedirect,NIA-Network: Towards improving lung CT infection detection for COVID-19 diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85106430602,"During pandemics (e.g., COVID-19) physicians have to focus on diagnosing and treating patients, which often results in that only a limited amount of labeled CT images is available. Although recent semi-supervised learning algorithms may alleviate the problem of annotation scarcity, limited real-world CT images still cause those algorithms producing inaccurate detection results, especially in real-world COVID-19 cases. Existing models often cannot detect the small infected regions in COVID-19 CT images, such a challenge implicitly causes that many patients with minor symptoms are misdiagnosed and develop more severe symptoms, causing a higher mortality. In this paper, we propose a new method to address this challenge. Not only can we detect severe cases, but also detect minor symptoms using real-world COVID-19 CT images in which the source domain only includes limited labeled CT images but the target domain has a lot of unlabeled CT images. Specifically, we adopt Network-in-Network and Instance Normalization to build a new module (we term it NI module) and extract discriminative representations from CT images from both source and target domains. A domain classifier is utilized to implement infected region adaptation from source domain to target domain in an Adversarial Learning manner, and learns domain-invariant region proposal network (RPN) in the Faster R-CNN model. We call our model NIA-Network (Network-in-Network, Instance Normalization and Adversarial Learning), and conduct extensive experiments on two COVID-19 datasets to validate our approach. The experimental results show that our model can effectively detect infected regions with different sizes and achieve the highest diagnostic accuracy compared with existing SOTA methods.",health
10.1016/j.compbiomed.2021.104489,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,The UTrack framework for segmenting and measuring dermatological ulcers through telemedicine,https://api.elsevier.com/content/abstract/scopus_id/85106284316,"Chronic dermatological ulcers cause great discomfort to patients, and while monitoring the size of wounds over time provides significant clues about the healing evolution and the clinical condition of patients, the lack of practical applications in existing studies impairs users’ access to appropriate treatment and diagnosis methods. We propose the UTrack framework to help with the acquisition of photos, the segmentation and measurement of wounds, the storage of photos and symptoms, and the visualization of the evolution of ulcer healing. UTrack-App is a mobile app for the framework, which processes images taken by standard mobile device cameras without specialized equipment and stores all data locally. The user manually delineates the regions of the wound and the measurement object, and the tool uses the proposed UTrack-Seg segmentation method to segment them. UTrack-App also allows users to manually input a unit of measurement (centimeter or inch) in the image to improve the wound area estimation. Experiments show that UTrack-Seg outperforms its state-of-the-art competitors in ulcer segmentation tasks, improving F-Measure by up to 82.5% when compared to superpixel-based approaches and up to 19% when compared to Deep Learning ones. The method is unsupervised, and it semi-automatically segments real-world images with 0.9 of F-Measure, on average. The automatic measurement outperformed the manual process in three out of five different rulers. UTrack-App takes at most 30 s to perform all evaluation steps over high-resolution images, thus being well-suited to analyze ulcers using standard mobile devices.",health
10.1016/j.jaip.2021.03.039,Journal,Journal of Allergy and Clinical Immunology: In Practice,scopus,2021-07-01,sciencedirect,Predicting Severe Asthma Exacerbations in Children: Blueprint for Today and Tomorrow,https://api.elsevier.com/content/abstract/scopus_id/85106217297,"Severe asthma exacerbations are the primary cause of morbidity and mortality in children with asthma. Accurate prediction of children at risk for severe exacerbations, defined as those requiring systemic corticosteroids, emergency department visit, and/or hospitalization, would considerably reduce health care utilization and improve symptoms and quality of life. Substantial progress has been made in identifying high-risk exacerbation-prone children. Known risk factors for exacerbations include demographic characteristics (ie, low income, minority race/ethnicity), poor asthma control, environmental exposures (ie, aeroallergen exposure/sensitization, concomitant viral infection), inflammatory biomarkers, genetic polymorphisms, and markers from other “omic” technologies. The strongest risk factor for a future severe exacerbation remains having had one in the previous year. Combining risk factors into composite scores and use of advanced predictive analytic techniques such as machine learning are recent methods used to achieve stronger prediction of severe exacerbations. However, these methods are limited in prediction efficiency and are currently unable to predict children at risk for impending (within days) severe exacerbations. Thus, we provide a commentary on strategies that have potential to allow for accurate and reliable prediction of children at risk for impending exacerbations. These approaches include implementation of passive, real-time monitoring of impending exacerbation predictors, use of population health strategies, prediction of severe exacerbation responders versus nonresponders to conventional exacerbation management, and considerations for preschool-age children who can be especially high risk. Rigorous prediction and prevention of severe asthma exacerbations is needed to advance asthma management and improve the associated morbidity and mortality.",health
10.1016/j.livsci.2021.104528,Journal,Livestock Science,scopus,2021-07-01,sciencedirect,Uterine health and fertility of timed AI postpartum Nelore beef cows raised in the Amazon biome,https://api.elsevier.com/content/abstract/scopus_id/85105602223,"This study evaluated the effect of uterine health on the fertility of postpartum beef cows. Multiparous lactating Nelore cows (Bos indicus; n = 155) were subjected to a timed artificial insemination (TAI) protocol. Cows were included in a progesterone-estradiol based TAI protocol. On Day 0, before the beginning of the protocol, cows were subjected to evaluation of purulent vaginal discharge (PVD) and collection of uterine tissue using the cytobrush technique. Slides for polymorphonuclear (PMN) cells counting were prepared before the same cytobrush was used for RNA extraction and analysis of IL-1β, IL-6, IL-8, TNFα, GAPDH, and βactin gene transcription. Cows were separated into 4 categories according to the proportion of PMN and PVD: 1) Healthy (HE; n = 87), cows with ≤ 4.75% PMN and PVD of 0; 2) Positive Purulent Vaginal Discharge (PVD+; n = 24), cows with ≤ 4.75% PMN and PVD ≥ 1; 3) Subclinical Endometritis (SCE; n = 29), cows with > 4.75% PMN and PVD of 0, and; 4) Subclinical Endometritis + PVD+ (SCEP; n = 15), cows with > 4.75% PMN and PVD ≥ 1. Cows in the HE group had a greater (P < 0.05) pregnancy per AI (P/IA) than cows in SCE and SCEP groups. However, P/AI in cows from the PVD+ group was not different in comparison to HE and SCE groups (P > 0.05). Cows from the SCE and SCEP groups had a higher (P < 0.001) proportion of PMN cells in the uterus than HE and PVD+ groups. Relative transcription of IL-6 and TNFα did not change among groups (P > 0.05). In contrast, transcription of IL-8 was greater (P = 0.02) in SCEP than HE and SCE groups. The relative transcription IL-1β was greater (P < 0.05) in SCEP than in PVD+, but the cows in the HE and SCE groups were not different from the other groups (P = 0.08). Our results demonstrate that postpartum beef cows, raised in the Amazon biome, with a higher proportion of PMN cells have lower fertility. Moreover, ~ 40% of the postpartum cows included in TAI programs early postpartum had suboptimal uterine conditions (subclinical endometritis, purulent vaginal discharge, or both).",health
10.1016/j.compbiomed.2021.104450,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,A comprehensive review and analysis of supervised-learning and soft computing techniques for stress diagnosis in humans,https://api.elsevier.com/content/abstract/scopus_id/85105598718,"Stress is the most prevailing and global psychological condition that inevitably disrupts the mood and behavior of individuals. Chronic stress may gravely affect the physical, mental, and social behavior of victims and consequently induce myriad critical human disorders. Herein, a review has been presented where supervised learning (SL) and soft computing (SC) techniques used in stress diagnosis have been meticulously investigated to highlight the contributions, strengths, and challenges faced in the implementation of these methods in stress diagnostic models. A three-tier review strategy comprising of manuscript selection, data synthesis, and data analysis was adopted. The issues in SL strategies and the potential possibility of using hybrid techniques in stress diagnosis have been intensively investigated. The strengths and weaknesses of different SL (Bayesian classifier, random forest, support vector machine, and nearest neighbours) and SC (fuzzy logic, nature-inspired, and deep learning) techniques have been presented to obtain clear insights into these optimization strategies. The effects of social, behavioral, and biological stresses have been highlighted. The psychological, biological, and behavioral responses to stress have also been briefly elucidated. The findings of the study confirmed that different types of data/signals (related to skin temperature, electro-dermal activity, blood circulation, heart rate, facial expressions, etc.) have been used in stress diagnosis. Moreover, there is a potential scope for using distinct nature-inspired computing techniques (Genetic Algorithm, Particle Swarm Optimization, Ant Colony Optimization, Whale Optimization Algorithm, Butterfly Optimization, Harris Hawks Optimizer, and Crow Search Algorithm) and deep learning techniques (Deep-Belief Network, Convolutional-Neural Network, and Recurrent-Neural Network) on multimodal data compiled using behavioral testing, electroencephalogram signals, finger temperature, respiration rate, pupil diameter, galvanic-skin-response, and blood pressure. Likewise, there is a wider scope to investigate the use of SL and SC techniques in stress diagnosis using distinct dimensions such as sentiment analysis, speech recognition, handwriting recognition, and facial expressions. Finally, a hybrid model based on distinct computational methods influenced by both SL and SC techniques, adaption, parameter tuning, and the use of chaos, levy, and Gaussian distribution may address exploration and exploitation issues. However, factors such as real-time data collection, bias, integrity, multi-dimensional data, and data privacy make it challenging to design precise and innovative stress diagnostic systems based on artificial intelligence.",health
10.1016/j.apenergy.2021.116977,Journal,Applied Energy,scopus,2021-07-01,sciencedirect,Cloud-based health-conscious energy management of hybrid battery systems in electric vehicles with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85104708241,"In order to fulfill the energy and power demand of battery electric vehicles, a hybrid battery system with a high-energy and a high-power battery pack can be implemented as the energy source. This paper explores a cloud-based multi-objective energy management strategy for the hybrid architecture with a deep deterministic policy gradient, which increases the electrical and thermal safety, and meanwhile minimizes the system’s energy loss and aging cost. In order to simulate the electro-thermal dynamics and aging behaviors of the batteries, models are built for both high-energy and high-power cells based on the characterization and aging tests. A cloud-based training approach is proposed for energy management with real-world vehicle data collected from various road conditions. Results show the improvement of electrical and thermal safety, as well as the reduction of energy loss and aging cost of the whole system with the proposed strategy based on the collected real-world driving data. Furthermore, processor-in-the-loop tests verify that the proposed strategy can achieve a much higher convergence rate and a better performance in terms of the minimization of both energy loss and aging cost compared with state-of-the-art learning-based strategies.",health
10.1016/j.bios.2021.113211,Journal,Biosensors and Bioelectronics,scopus,2021-07-01,sciencedirect,Pre-coated interface proximity extension reaction assay enables trace protein detection with single-digit accuracy,https://api.elsevier.com/content/abstract/scopus_id/85104054203,"Advances in trace protein detection contribute to the early diagnosis of diseases and exploration of stem cell development. The pre-coated interface proximity extension reaction (PIPER) assay enables target protein detection at trace levels and was developed based on protein biomarker recognition using sets of three specific antibodies and the extension of antibody-bound nucleic acid chains in proximity, accompanied by amplification and reading of protein signals via real-time quantitative polymerase chain reaction (qPCR). Noise generated in binding reactions and enzymatic steps was decreased by transferring the liquid-liquid reactions onto a liquid-solid interface in glutaraldehyde-treated tubes pre-coated with antibodies. Nucleic acid sequences of oligo-antibody-based probes were designed for extension and qPCR without pre-amplification when binding to a target molecule. As a proof of concept, the PIPER assay was used to profile slight variations in crucial biomarkers, high-sensitivity C-reactive protein, and cardiac troponin I. The detection sensitivity of the assay for the biomarkers was 0.05 pg/mL (1.25 fM) in 10% human serum. In phosphate-buffered saline, the PIPER assay detected fewer than 10 protein molecules per μL. The simple, widely applicable PIPER assay can detect trace protein biomarkers with single-digit accuracy, making it appropriate for the development of clinical hypersensitive protein detection and single-cell protein detection technology.",health
10.1016/j.cognition.2021.104713,Journal,Cognition,scopus,2021-07-01,sciencedirect,Disentangling prevalence induced biases in medical image decision-making,https://api.elsevier.com/content/abstract/scopus_id/85103613588,"Many important real-world decision tasks involve the detection of rarely occurring targets (e.g., weapons in luggage, potentially cancerous abnormalities in radiographs). Over the past decade, it has been repeatedly demonstrated that extreme prevalence (both high and low) leads to an increase in errors. While this “prevalence effect” is well established, the cognitive and/or perceptual mechanisms responsible for it are not. One reason for this is that the most common tool for analyzing prevalence effects, Signal Detection Theory, cannot distinguish between different biases that might be present. Through an application to pathology image-based decision-making, we illustrate that an evidence accumulation modeling framework can be used to disentangle different types of biases. Importantly, our results show that prevalence influences both response expectancy and stimulus evaluation biases, with novices (students, N = 96) showing a more pronounced response expectancy bias and experts (medical laboratory professionals, N = 19) showing a more pronounced stimulus evaluation bias.",health
10.1016/j.patcog.2021.107896,Journal,Pattern Recognition,scopus,2021-07-01,sciencedirect,Time series cluster kernels to exploit informative missingness and incomplete label information,https://api.elsevier.com/content/abstract/scopus_id/85101792853,"The time series cluster kernel (TCK) provides a powerful tool for analysing multivariate time series subject to missing data. TCK is designed using an ensemble learning approach in which Bayesian mixture models form the base models. Because of the Bayesian approach, TCK can naturally deal with missing values without resorting to imputation and the ensemble strategy ensures robustness to hyperparameters, making it particularly well suited for unsupervised learning.
                  However, TCK assumes missing at random and that the underlying missingness mechanism is ignorable, i.e. uninformative, an assumption that does not hold in many real-world applications, such as e.g. medicine. To overcome this limitation, we present a kernel capable of exploiting the potentially rich information in the missing values and patterns, as well as the information from the observed data. In our approach, we create a representation of the missing pattern, which is incorporated into mixed mode mixture models in such a way that the information provided by the missing patterns is effectively exploited. Moreover, we also propose a semi-supervised kernel, capable of taking advantage of incomplete label information to learn more accurate similarities.
                  Experiments on benchmark data, as well as a real-world case study of patients described by longitudinal electronic health record data who potentially suffer from hospital-acquired infections, demonstrate the effectiveness of the proposed methods.",health
10.1016/j.jsurg.2020.11.003,Journal,Journal of Surgical Education,scopus,2021-07-01,sciencedirect,A Comprehensive Multicomponent Neurosurgical Course with use of Virtual Reality: Modernizing the Medical Classroom,https://api.elsevier.com/content/abstract/scopus_id/85097129537,"OBJECTIVE
                  Surgical education has constantly evolved and has been recently severely impacted by the COVID-19 pandemic. While virtual reality (VR) has been utilized for resident training and neuroanatomy education, application of VR has been limited for neurosurgical education in medical school. This is the first report of a comprehensive, multicomponent teaching model with VR as a primary component to neurosurgical and neuroanatomy education for pre-clerkship medical students.
               
                  DESIGN
                  Twelve second-year medical students were included in this prospective survey study that was conducted to evaluate a year-long neurosurgery elective course with an interactive VR platform as a primary teaching tool for neuroanatomy and neurosurgical procedures. The course had 4 components: (1) didactic/lecture-based learning, (2) problem-based learning, (3) hands-on skills lab, and (4) VR-based learning through Surgical Theater's Precision VR visualization platform. Outcome measures were based on confidence levels measured on pre- and post-course competency confidence surveys in students’ ability to identify neuroanatomical structures, interpret neuroradiological imaging, and analyze neurosurgical cases, and student feedback on their experience with VR on a postcourse survey.
               
                  SETTING
                  The survey study was conducted in the neurosurgery library and conference room at University Hospitals Cleveland Medical Center in Cleveland, Ohio, USA.
               
                  PARTICIPANTS
                  All 12 second-year medical students who enrolled in the neurosurgery zero-credit hour course completed the course.
               
                  RESULTS
                  At course conclusion, 100% of students reported significantly higher competency confidence levels on all topics, and 100% agreed utilizing VR helped them gain a deeper understanding of neuroanatomy/neurosurgery. 92% agreed that using VR helped them better retain the anatomical/functional details of the brain/spine, and 69% better understand neurosurgical skills taught, respectively. 100% of students found the course to be a valuable learning experience and VR a useful learning tool.
               
                  CONCLUSION
                  A comprehensive multi-component neurosurgery elective course using VR as a primary teaching tool may improve neurosurgical education in medical school.",health
10.1016/j.semcancer.2020.06.002,Journal,Seminars in Cancer Biology,scopus,2021-07-01,sciencedirect,Artificial intelligence for breast cancer detection in mammography and digital breast tomosynthesis: State of the art,https://api.elsevier.com/content/abstract/scopus_id/85086474184,"Screening for breast cancer with mammography has been introduced in various countries over the last 30 years, initially using analog screen-film-based systems and, over the last 20 years, transitioning to the use of fully digital systems. With the introduction of digitization, the computer interpretation of images has been a subject of intense interest, resulting in the introduction of computer-aided detection (CADe) and diagnosis (CADx) algorithms in the early 2000′s. Although they were introduced with high expectations, the potential improvement in the clinical realm failed to materialize, mostly due to the high number of false positive marks per analyzed image.
                  In the last five years, the artificial intelligence (AI) revolution in computing, driven mostly by deep learning and convolutional neural networks, has also pervaded the field of automated breast cancer detection in digital mammography and digital breast tomosynthesis. Research in this area first involved comparison of its capabilities to that of conventional CADe/CADx methods, which quickly demonstrated the potential of this new technology. In the last couple of years, more mature and some commercial products have been developed, and studies of their performance compared to that of experienced breast radiologists are showing that these algorithms are on par with human-performance levels in retrospective data sets. Although additional studies, especially prospective evaluations performed in the real screening environment, are needed, it is becoming clear that AI will have an important role in the future breast cancer screening realm. Exactly how this new player will shape this field remains to be determined, but recent studies are already evaluating different options for implementation of this technology.
                  The aim of this review is to provide an overview of the basic concepts and developments in the field AI for breast cancer detection in digital mammography and digital breast tomosynthesis. The pitfalls of conventional methods, and how these are, for the most part, avoided by this new technology, will be discussed. Importantly, studies that have evaluated the current capabilities of AI and proposals for how these capabilities should be leveraged in the clinical realm will be reviewed, while the questions that need to be answered before this vision becomes a reality are posed.",health
10.1016/j.comnet.2021.108057,Journal,Computer Networks,scopus,2021-06-19,sciencedirect,A deep reinforcement learning-based multi-optimality routing scheme for dynamic IoT networks,https://api.elsevier.com/content/abstract/scopus_id/85104075448,"With the development of Internet of Things (IoT) and 5G technologies, more and more applications, such as autonomous vehicles and tele-medicine, become more sensitive to network latency and accuracy, which require routing schemes to be more flexible and efficient. In order to meet such urgent need, learning-based routing strategies are emerging as strong candidate solutions, with the advantages of high flexibility and accuracy. These strategies can be divided into two categories, centralized and distributed, enjoying the advantages of high precision and high efficiency, respectively. However, routing becomes more complex in dynamic IoT network, where the link connections and access states are time-varying, hence these learning-based routing mechanisms are required to have the capability to adapt to network changes in real time. In this paper, we designed and implemented both centralized and distributed Reinforcement Learning-based Routing schemes combined with Multi-optimality routing criteria (RLR-M). By conducting a series of experiments, we performed a comprehensive analysis of the results and arrived at the conclusion that the centralized is better suited to cope with dynamic networks due to its faster reconvergence (2.2 
                        ×
                      over distributed), while the distributed is better positioned to handle with large-scale networks through its high scalability (1.6 
                        ×
                      over centralized). Moreover, the multi-optimality routing scheme is implemented through model fusion, which is more flexible than traditional strategies and as such is better placed to meet the needs of IoT.",health
10.1016/j.ymssp.2020.107510,Journal,Mechanical Systems and Signal Processing,scopus,2021-06-16,sciencedirect,Metric-based meta-learning model for few-shot fault diagnosis under multiple limited data conditions,https://api.elsevier.com/content/abstract/scopus_id/85100211264,"The real-world large industry has gradually become a data-rich environment with the development of information and sensor technology, making the technology of data-driven fault diagnosis acquire a thriving development and application. The success of these advanced methods depends on the assumption that enough labeled samples for each fault type are available. However, in some practical situations, it is extremely difficult to collect enough data, e.g., when the sudden catastrophic failure happens, only a few samples can be acquired before the system shuts down. This phenomenon leads to the few-shot fault diagnosis aiming at distinguishing the failure attribution accurately under very limited data conditions. In this paper, we propose a new approach, called Feature Space Metric-based Meta-learning Model (FSM3), to overcome the challenge of the few-shot fault diagnosis under multiple limited data conditions. Our method is a mixture of general supervised learning and episodic metric meta-learning, which will exploit both the attribute information from individual samples and the similarity information from sample groups. The experiment results demonstrate that our method outperforms a series of baseline methods on the 1-shot and 5-shot learning tasks of bearing and gearbox fault diagnosis across various limited data conditions. The time complexity and implementation difficulty have been analyzed to show that our method has relatively high feasibility. The feature embedding is visualized by t-SNE to investigate the effectiveness of our proposed model.",health
10.1016/j.energy.2021.120152,Journal,Energy,scopus,2021-06-15,sciencedirect,Fuzzy logic and Elman neural network tuned energy management strategies for a power-split HEVs,https://api.elsevier.com/content/abstract/scopus_id/85102149995,"This paper focuses on optimal energy sharing between the two sources i.e., the internal combustion engine and the battery-powered electric motor in a hybrid electric vehicle (HEV). It is necessary that these sources operate in their efficient operating region while fulfilling the energy demanded by the vehicle to obtain the maximum fuel economy. As both of these sources have different operating characteristic and vehicle running conditions, the situation requires a smart controller to address this problem appropriately. In this work, fuzzy logic and Elman neural network-based adaptive energy management strategies (EMS) in an HEV are designed and implemented. The input parameters to these EMS are torque demand, battery state of charge, and regenerative braking. The proposed strategy aims to maximise the fuel economy while maintaining the battery health. A power-split HEV along with EMS is designed, modelled and simulated in MATLAB/Simulink first and then the whole system is validated in real-time using controller hardware in the loop testing platform (CHIL). The FPGA based MicroLabBox CHIL has been employed to test the system behaviour in real-time. The proposed EMS have been compared with conventional strategies and the comparison reveals that the Elman neural network-based method results in higher fuel economy, faster response, and minimal mismatch between desired and attained vehicle speeds.",health
10.1016/j.cej.2021.128812,Journal,Chemical Engineering Journal,scopus,2021-06-15,sciencedirect,Sorption enhancement of nickel(II) from wastewater by ZIF-8 modified with poly (sodium 4-styrenesulfonate): Mechanism and kinetic study,https://api.elsevier.com/content/abstract/scopus_id/85101005982,"Effective removal of toxic metal Ni(II) from wastewater is essential to water safety and human health. Although zeolitic imidazolate framework-8 (ZIF-8) has demonstrated outstanding selective removal of Ni(II) in high-salinity wastewater, the practical applications of ZIF-8 are mainly limited by low active sites utilization, slow adsorption kinetics and poor reusability. In this study, we prepared a novel negatively charged poly (sodium 4-styrenesulfonate) (PSS)-modified ZIF-8 adsorbent, ZIF-8@PSS (12 h), which increased the adsorption rate of Ni(II) (kinetic constant k = 0.0299 g mg−1 min−1) by nearly 10 times and the adsorption capacity (329.58 mg/g) by 1.6 times compared to pristine ZIF-8 (k = 0.0021 g mg−1 min−1). ZIF-8@PSS (12 h) (0.5 g/L) could quickly decrease Ni(II) (C0 = 1.0 mg/L) to 0.1 mg/L (discharged standard) in 25 min, while 600 min for ZIF-8. Batch experiments and characterization analyses revealed PSS can improve particle dispersion, increase active sites utilization, and strengthen Ni(II) diffusion kinetics, thereby enhancing the adsorption of Ni(II). Among them, the increase in active sites utilization of ZIF-8 contributes 83.3% to capacity improvement, while the –SO3
                     − on PSS is 16.7%. Furthermore, the enhancements of adsorption kinetics and capacity were also applicable to other heavy metals (e.g., Cu2+, Pb2+, Cr3+, Cd2+). Column experiments using real nickel plating effluent shown that 1 g ZIF-8@PSS (12 h) could produce ~3675 mL of clean water before breakthrough (Ni2+ < 0.1 mg/L). Moreover, a specific nickel chelator, dimethylglyoxime was used to regenerate the exhausted adsorbent and showed an insignificant capacity loss after four cycles. This study indicates the potential of ZIF-8@PSS (12 h) to remove Ni(II) from nickel plating effluent.",health
10.1016/j.jhazmat.2021.125230,Journal,Journal of Hazardous Materials,scopus,2021-06-15,sciencedirect,"Long-term exposure to 2-amino-3-methylimidazo[4,5-f]quinoline can trigger a potential risk of Parkinson's disease",https://api.elsevier.com/content/abstract/scopus_id/85100414788,"Humans are exposed to heterocyclic amines (HCAs) from a wide range of sources, such as protein-rich thermally processed foods, cigarette smoke, contaminated river water, the atmosphere, soil, and forest fire ash. Although the carcinogenic and mutagenic hazards of HCAs have been widely studied, the potential neurotoxicity of these compounds still needs to be further elucidated. Here, we studied the neurotoxicity of the HCA 2-amino-3-methylimidazole[4,5-f]quinoline (IQ) in vivo by utilizing a zebrafish model. After 35 days of exposure at 8, 80, and 800 ng/mL, zebrafish exploratory behavior and locomotor activity were significantly inhibited, and light/dark preference behaviors were also disturbed. Moreover, the expression of Parkinson's disease (PD)-related genes and proteins, dopamine-related genes, neuroplasticity-related genes, antioxidant enzyme genes and inflammatory cytokine genes in the zebrafish brain was significantly affected. The numbers of NeuN neurons in the midbrain were decreased in exposed zebrafish, while the numbers of apoptotic cells were increased. In summary, our research suggests that IQ is neurotoxic and significantly associated with PD and that long-term exposure to IQ may contribute to PD risk. This risk may be related to IQ-mediated effects on mitochondrial homeostasis and induction of oxidative stress and inflammation.",health
10.1016/j.neucom.2021.01.099,Journal,Neurocomputing,scopus,2021-06-07,sciencedirect,Meta-learning for few-shot bearing fault diagnosis under complex working conditions,https://api.elsevier.com/content/abstract/scopus_id/85102132168,"Deep learning-based bearing fault diagnosis has been systematically studied in recent years. However, the success of most of these methods relies heavily on massive labeled data, which is not always available in real production environments. Training a robust bearing fault diagnosis model with limited data and working well under complex working conditions remains a challenge. In this paper, a novel meta-learning fault diagnosis method (MLFD) based on model-agnostic meta-learning is proposed to address this issue. The raw signals of different working conditions are first converted to time–frequency images and then randomly sampled to form tasks for MLFD according to the protocol of meta-learning. The MLFD model acquires prior knowledge by optimizing initialization parameters based on multiple fault classification tasks of known working conditions during the meta-training process, and achieves fast and accurate few-shot bearing fault diagnosis under unseen working conditions by leveraging the learned knowledge. To comprehensively evaluate the performance of our method, a series of experiments were conducted to simulate different industrial scenarios based on the Case Western Reserve University Bearing Fault Benchmark, and the results demonstrate the superiority of MLFD in solving the few-shot fault classification problem under complex working conditions.",health
10.1016/j.neucom.2020.01.124,Journal,Neurocomputing,scopus,2021-06-07,sciencedirect,"Predicting energy cost of public buildings by artificial neural networks, CART, and random forest",https://api.elsevier.com/content/abstract/scopus_id/85101355528,"The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities.",health
10.1016/j.ijfoodmicro.2021.109192,Journal,International Journal of Food Microbiology,scopus,2021-06-02,sciencedirect,Prevalence of Brucella spp. in raw milk and artisanal cheese tested via real-time qPCR and culture assay,https://api.elsevier.com/content/abstract/scopus_id/85103935464,"Brucellosis is one of the most prevalent zoonotic diseases with worldwide distribution. Although the incidence of brucellosis varies widely in different regions, it is a major concern for public health around the world. This study aimed to determine the prevalence and quantity of Brucella spp. in sheep and goat raw milk, as well as artisanal cheeses produced in the North-west of Iran. To evaluate the intrinsic parameters that may affect the survival of Brucella spp., some of the cheese properties (e.g., pH, salt, moisture, and storage time before selling) were also assessed. A total of 572 samples consisting in 214 sheep raw milk, 92 goat raw milk, and 266 local artisanal cheese samples were collected. The artisanal cheeses were manufactured from a mixture of raw sheep and goat milk. According to the results, using quantitative real-time PCR (qPCR), 17.29%, 15.22%, and 22.93% of the sheep raw milk, goat raw milk, and artisanal cheese samples were found positive for Brucella spp., respectively. In comparison with culture assay, qPCR was 3.5 to 5 times (p < 0.05) more sensitive in the detection of Brucella spp. The results also revealed that the mean values of Brucella spp. load in sheep and goat raw milk and artisanal cheeses were 1.22, 1.55, and 1.43 log cell/ml or g, respectively. A positive correlation was found between Brucella load and successful detection of Brucella spp. by culture assay. Data also suggested a correlation (p < 0.01) between the load of Brucella spp. estimated by qPCR and pH value, salt content, and storage period of the cheese samples. However, Brucella spp. load did not correlate significantly with the moisture content. Based on the results, in any of the cheese samples with a pH value less than 4.5 and a storage period more than five months, no contamination with Brucella spp. was detected.",health
10.1016/S2589-7500(21)00005-4,Journal,The Lancet Digital Health,scopus,2021-06-01,sciencedirect,Health information technology and digital innovation for national learning health and care systems,https://api.elsevier.com/content/abstract/scopus_id/85106359380,"Health information technology can support the development of national learning health and care systems, which can be defined as health and care systems that continuously use data-enabled infrastructure to support policy and planning, public health, and personalisation of care. The COVID-19 pandemic has offered an opportunity to assess how well equipped the UK is to leverage health information technology and apply the principles of a national learning health and care system in response to a major public health shock. With the experience acquired during the pandemic, each country within the UK should now re-evaluate their digital health and care strategies. After leaving the EU, UK countries now need to decide to what extent they wish to engage with European efforts to promote interoperability between electronic health records. Major priorities for strengthening health information technology in the UK include achieving the optimal balance between top-down and bottom-up implementation, improving usability and interoperability, developing capacity for handling, processing, and analysing data, addressing privacy and security concerns, and encouraging digital inclusivity. Current and future opportunities include integrating electronic health records across health and care providers, investing in health data science research, generating real-world data, developing artificial intelligence and robotics, and facilitating public–private partnerships. Many ethical challenges and unintended consequences of implementation of health information technology exist. To address these, there is a need to develop regulatory frameworks for the development, management, and procurement of artificial intelligence and health information technology systems, create public–private partnerships, and ethically and safely apply artificial intelligence in the National Health Service.",health
10.1016/j.compmedimag.2021.101929,Journal,Computerized Medical Imaging and Graphics,scopus,2021-06-01,sciencedirect,Lesion synthesis to improve intracranial hemorrhage detection and classification for CT images,https://api.elsevier.com/content/abstract/scopus_id/85105757648,"Computer-aided diagnosis (CAD) for intracranial hemorrhage (ICH) is needed due to its high mortality rate and time sensitivity. Training a stable and robust deep learning-based model usually requires enough training examples, which may be impractical in many real-world scenarios. Lesion synthesis offers a possible solution to solve this problem, especially for the issue of the lack of micro bleedings. In this paper, we propose a novel strategy to generate artificial lesions on non-lesion CT images so as to produce additional labeled training examples. Artificial masks in any location, size, or shape can be generated through Artificial Mask Generator (AMG) and then be converted into hemorrhage lesions through Lesion Synthesis Network (LSN). Images with and without artificial lesions are combined for training an ICH detection with a novel Residual Score. We evaluate our method by the auxiliary diagnosis task of ICH. Our experiments demonstrate that the proposed approach can improve the AUC value from 84% to 91% in the ICH detection task and from 89% to 96% in the classification task. Moreover, by adding artificial lesions of small size, the sensitivity of micro bleeding is remarkably improved from 49% to 70%. Besides, the proposed method overcomes the other three synthetic approaches by a large margin.",health
10.1016/j.jtumed.2021.02.011,Journal,Journal of Taibah University Medical Sciences,scopus,2021-06-01,sciencedirect,"Perceptions of medical students in Pakistan, KSA, and the US regarding the significance of case-based learning",https://api.elsevier.com/content/abstract/scopus_id/85104975189,"Objective
                  This study aims to determine the perceptions of medical students in Pakistan, KSA, and the US regarding the significance of case-based learning (CBL).
               
                  Methods
                  For this cross-sectional study, data were collected by administering an online questionnaire to students in medical schools across Pakistan, KSA, and the US.
               
                  Results
                  A total of 344 medical students participated in this study, the great majority of whom agree that CBL paves the way for developing a sound understanding of the core subject, provides insight into real-life experiences, helps them transform from fact memorisers into problem solvers, and keeps them engaged during sessions, which motivates them to attend more of these. A comparison of respondents from Pakistan and KSA shows that CBL promotes deep learning and fostered their critical thinking; however, there was a difference in perception in some categories, including CBL as a tool used for grasping key concepts (p = 0.004), providing insight into real-life experiences (p = 0.001), offering a platform for self-directed learning (p = 0.000), nurturing collaborative abilities (p = 0.004), and maintaining students’ engagement (p = 0.002).
               
                  Conclusion
                  Our study shows that the selected cohort of medical students perceive CBL as an effective learning tool, as the majority feel overwhelmingly positive towards it. This study thus proposes the introduction of clinical exposure for medical students early in MBBS programmes, which will help promote collaborative skills and self-directed learning among them.",health
10.1016/j.compag.2021.106156,Journal,Computers and Electronics in Agriculture,scopus,2021-06-01,sciencedirect,A system for automatic rice disease detection from rice paddy images serviced via a Chatbot,https://api.elsevier.com/content/abstract/scopus_id/85104652334,"A LINE Bot System to diagnose rice diseases from actual paddy field images was developed and presented in this paper. It was easy-to-use and automatic system designed to help rice farmers improve the rice yield and quality. The targeted images were taken from the actual paddy environment without special sample preparation. We used a deep learning neural networks technique to detect rice diseases from the images. We developed an object detection model training and refinement process to improve the performance of our previous research on rice leave diseases detection. The process was based on analyzing the model’s predictive results and could be repeatedly used to improve the quality of the database in the next training of the model. The deployment model for our LINE Bot system was created from the selected best performance technique in our previous paper, YOLOv3, trained by refined training data set. The performance of the deployment model was measured on 5 target classes and found that the Average True Positive Point improved from 91.1% in the previous paper to 95.6% in this study. Therefore, we used this deployment model for Rice Disease LINE Bot system. Our system worked automatically real-time to suggest primary diagnosis results to the users in the LINE group, which included rice farmers and rice disease specialists. They could communicate freely via chat. In the real LINE Bot deployment, the model’s performance was measured by our own defined measurement Average True Positive Point and was found to be an average of 78.86%. The system was fast and took only 2–3 s for detection process in our system server.",health
10.1016/j.psep.2021.04.001,Journal,Process Safety and Environmental Protection,scopus,2021-06-01,sciencedirect,Multi-intelligent connected vehicle longitudinal collision avoidance control and exhaust emission evaluation based on parallel theory,https://api.elsevier.com/content/abstract/scopus_id/85104623018,"With the increasing of vehicle volume and driving speed, traffic accidents and environmental safety have become social concerns. Vehicle traffic accidents, especially multi-vehicle chain accidents, cause damage to property and human lives. Meanwhile, traffic pollution will lead to continuous harm to living environment and health. This is a coupled human-vehicle-environment interaction system, which is difficult to model with traditional mathematical methods. Parallel theory is an effective method to solve such complex problems based on advanced artificial intelligence and computer technology. In this paper, a parallel system is built to analyze and control multi-intelligent connected vehicle based on parallel theory. The parallel system is also used to analyze and assess the exhaust emission of multi-intelligent connected vehicle. The parallel system is carried out with three steps: 1) modeling and representation of multi-intelligent connected vehicle system using artificial societies; 2) analysis and evaluation by computational experiments; 3) control, management and exhaust emission evaluation through parallel execution of real and artificial systems and big data. The parallel control methods, models and conclusions obtained from this paper can be used to enhance the experience of safety in multi-vehicle control under vehicle to everything environment and make the safety intervention measures more efficient.",health
10.1016/j.cmpb.2021.106071,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-06-01,sciencedirect,Computer-aided diagnosis system for the classification of multi-class kidney abnormalities in the noisy ultrasound images,https://api.elsevier.com/content/abstract/scopus_id/85104342062,"Background and Objective: The primary causes of kidney failure are chronic and polycystic kidney diseases. Cyst, stone, and tumor development lead to chronic kidney diseases that commonly impair kidney functions. The kidney diseases are asymptomatic and do not show any significant symptoms at its initial stage. Therefore, diagnosing the kidney diseases at their earlier stage is required to prevent the loss of kidney function and kidney failure.
                  
                     Methods: This paper proposes a computer-aided diagnosis (CAD) system for detecting multi-class kidney abnormalities from ultrasound images. The presented CAD system uses a pre-trained ResNet-101 model for extracting the features and support vector machine (SVM) classifier for the classification purpose. Ultrasound images usually gets affected by speckle noise that degrades the image quality and performance of the CAD system. Hence, it is necessary to remove speckle noise from the ultrasound images. Therefore, a CAD based system is proposed with the despeckling module using a deep residual learning network (RLN) to reduce speckle noise. Pre-processing of ultrasound images using deep RLN helps to drastically improve the classification performance of the CAD system. The proposed CAD system achieved better prediction results when compared to the existing state-of-the-art methods.
                  
                     Results: To validate the proposed CAD system performance, the experiments have been carried out in the noisy kidney ultrasound images. The designed system framework achieved the maximum classification accuracy when compared to the existing approaches. The SVM classifier is selected for the CAD system based on performance comparison with various classifiers like K-nearest neighbour, tree, discriminant, Naive Bayes, and linear.
                  
                     Conclusions: The proposed CAD system outperforms in classifying the noisy kidney ultrasound images precisely as compared to the existing state-of-the-art methods. Further, the CAD system is evaluated in terms of selectivity and sensitivity scores. The presented CAD system with the pre-processing module would serve as a real-time supporting tool for diagnosing multi-class kidney abnormalities from the ultrasound images.",health
10.1016/j.ijpe.2021.108114,Journal,International Journal of Production Economics,scopus,2021-06-01,sciencedirect,Machine learning-based predictive maintenance: A cost-oriented model for implementation,https://api.elsevier.com/content/abstract/scopus_id/85104317955,"Predictive Maintenance (PdM) is a condition-based maintenance strategy (CBM) that carries out maintenance action when needed, avoiding unnecessary preventive actions or failures. Machine learning (ML), in the form of advanced monitoring and diagnosis technologies, has become increasingly attractive. Implementing ML-based PdM is a difficult and expensive process, especially for those companies which often lack the necessary skills and financial and labour resources. Thus, a cost-oriented analysis is required to define when ML-based PdM is the most suitable maintenance strategy. The implementation of this strategy involves investment costs in IT technologies, in addition to costs incurred from traditional maintenance activities depending of the performance of the ML model classifier; however, no previous research consider both costs in the economic evaluation of PdM.This paper aims to provide a mathematical model where investment costs are included and the ML performance is evaluated in terms of the probability to correctly intercept faults. A error matrix is used to quantify costs due to maintenance actions. Moreover, the mathematical model provides a cost-based quantitative method, based on the Receiver Operating Characteristics (ROC) curve. This optimizes the decision threshold of the ML model classifier, which allows the maintenance costs to be minimized in comparison to traditional decision threshold optimisation methods. Based on the mathematical model, a useful Decision Support System (DSS) that guides PdM implementation is introduced. Finally, the DSS is applied to a real case study to illustrate its applicability.",health
10.1016/j.scp.2021.100415,Journal,Sustainable Chemistry and Pharmacy,scopus,2021-06-01,sciencedirect,Green chemistry and coronavirus,https://api.elsevier.com/content/abstract/scopus_id/85104072773,"The novel coronavirus pandemic has rapidly spread around the world since December 2019. Various techniques have been applied in identification of SARS-CoV-2 or COVID-19 infection including computed tomography imaging, whole genome sequencing, and molecular methods such as reverse transcription polymerase chain reaction (RT-PCR). This review article discusses the diagnostic methods currently being deployed for the SARS-CoV-2 identification including optical biosensors and point-of-care diagnostics that are on the horizon. These innovative technologies may provide a more accurate, sensitive and rapid diagnosis of SARS-CoV-2 to manage the present novel coronavirus outbreak, and could be beneficial in preventing any future epidemics. Furthermore, the use of green synthesized nanomaterials in the optical biosensor devices could leads to sustainable and environmentally-friendly approaches for addressing this crisis.",health
10.1016/S2214-109X(21)00059-0,Journal,The Lancet Global Health,scopus,2021-06-01,sciencedirect,The injustice of unfit clinical practice guidelines in low-resource realities,https://api.elsevier.com/content/abstract/scopus_id/85103953372,"To end the international crisis of preventable deaths in low-income and middle-income countries, evidence-informed and cost-efficient health care is urgently needed, and contextualised clinical practice guidelines are pivotal. However, as exposed by indirect consequences of poorly adapted COVID-19 guidelines, fundamental gaps continue to be reported between international recommendations and realistic best practice. To address this long-standing injustice of leaving health providers without useful guidance, we draw on examples from maternal health and the COVID-19 pandemic. We propose a framework for how global guideline developers can more effectively stratify recommendations for low-resource settings and account for predictable contextual barriers of implementation (eg, human resources) as well as gains and losses (eg, cost-efficiency). Such development of more realistic clinical practice guidelines at the global level will pave the way for simpler and achievable adaptation at local levels. We also urge the development and adaptation of high-quality clinical practice guidelines at national and subnational levels in low-income and middle-income countries through co-creation with end-users, and we encourage global sharing of these experiences.",health
10.1016/j.jviromet.2021.114128,Journal,Journal of Virological Methods,scopus,2021-06-01,sciencedirect,Quantitative detection of human adenovirus from river water by monolithic adsorption filtration and quantitative PCR,https://api.elsevier.com/content/abstract/scopus_id/85102586694,"Water contaminated with fecally derived viruses, also known as enteric viruses, represents a particularly high risk for human health. However, they have not been included in water quality regulations yet. The detection of these viruses is often more expensive and time-consuming compared to the analysis of conventional fecal indicator organisms. In addition, most methods are not sensitive enough to detect small viral loads that may already cause serious health issues if present in water. In this study, we established a workflow for the successful and direct enrichment of human adenovirus (HAdV) from artificially contaminated river water based on monolithic adsorption filtration (MAF) and quantitative polymerase reaction (qPCR). With a clear focus on efficiency, we used targeted synthetic DNA fragments as standard for the quantification of HAdV by qPCR, leading to accurate and robust results with a qPCR efficiency of 95 %, a broad working range over 6 orders of magnitude and an LOD of 1 GU/μL. We carried out a cascade of spiking experiments, enhancing the complexity of the spiking matrix with each step to progressively evaluate MAF for the direct concentration of HAdV. We found that negatively charged MAF using monoliths with hydroxyl groups (MAF−OH) showed a better reproducibility and a significantly faster turnaround time than skimmed milk flocculation (SMF) when concentrating HAdV35 from artificially contaminated, acidified mineral water. We then validated positively charged MAF using monoliths with diethyl aminoethyl groups (MAF-DEAE) for the direct concentration of HAdV5 without pre-conditioning of water samples using tap water as spiking matrix with a less defined and controlled water chemistry. Finally, we evaluated MAF-DEAE for the direct concentration of HAdV5 from surface water using river water as representative matrix with an undefined water chemistry. We found, that MAF-DEAE achieved reproducible recoveries of HAdV5, independently of the spiked concentration level or sample volume. Furthermore, we showed, that MAF-DEAE drastically reduced the limit of detection (LOD) of HAdV5 by a factor of 115 from 6.0 ∙ 103 GU/mL before to 5.2 ∙ 101 GU/mL after MAF-DEAE. We identified that recoveries increased for smaller processing volumes with a peak at 0.5 L of 84.0 % and showed that recovery efficiency depends on sample volume and matrix type. The here presented workflow based on MAF-DEAE and qPCR offers an easy-to-implement and highly efficient alternative to existing approaches and allows for a fast detection of HAdV in water.",health
10.1016/j.rser.2021.110889,Journal,Renewable and Sustainable Energy Reviews,scopus,2021-06-01,sciencedirect,"Artificial intelligence and internet of things to improve efficacy of diagnosis and remote sensing of solar photovoltaic systems: Challenges, recommendations and future directions",https://api.elsevier.com/content/abstract/scopus_id/85101928488,"Currently, a huge number of photovoltaic plants have been installed worldwide and these plants should be carefully protected and supervised continually in order to be safe and reliable during their working lifetime. Photovoltaic plants are subject to different types of faults and failures, while available fault detection equipment are mainly used to protect and isolate the photovoltaic plants from some faults (such as arc fault, line-to-line, line-to-ground and ground faults). Although a good number of international standards (IEC, NEC, and UL) exists, undetectable faults continue to create serious problems in photovoltaic plants. Thus, designing smart equipment, including artificial intelligence and internet of things for remote sensing and fault detection and diagnosis of photovoltaic plants, will considerably solve the shortcomings of existing methods and commercialized equipment. This paper presents an overview of artificial intelligence and internet of things applications in photovoltaic plants. This research presents also the most advanced algorithms such as machine and deep learning, in terms of cost implementation, complexity, accuracy, software suitability, and feasibility of real-time applications. The embedding of artificial intelligence and internet of things techniques for fault detection and diagnosis into simple hardware, such as low-cost chips, may be economical and technically feasible for photovoltaic plants located in remote areas, with costly and challenging accessibility for maintenance. Challenging issues, recommendations, and trends of these techniques will also be presented in this paper.",health
10.1016/j.vph.2021.106838,Journal,Vascular Pharmacology,scopus,2021-06-01,sciencedirect,Interleukin-10 does not contribute to the anti-contractile nature of PVAT in health,https://api.elsevier.com/content/abstract/scopus_id/85100685883,"Perivascular adipose tissue (PVAT) is protective and reduces contraction of blood vessels in health. PVAT is composed of adipocytes, multiple types of immune cells and stromal cells. Interleukin (IL)-10, an anti-inflammatory cytokine usually produced by T cells, B cells and macrophages, was identified as one of the highly expressed (mRNA) cytokines in the mesenteric PVAT of healthy rats. One report suggested that exogenous IL-10 causes relaxation of mouse mesenteric arteries, also suggesting that IL-10 maybe a potential anti-contractile factor. Hence, we hypothesized that PVAT-derived IL-10 causes vasorelaxation and/or reduces vasoconstriction, thus contributing to the anti-contractile nature of PVAT in health. Mesenteric arteries from rats and mice expressed the receptor for IL-10 (in tunica intima and media) as determined by immunohistochemistry. Mesenteric resistance arteries for rats and superior mesenteric artery for mice were used for isometric contractility studies. Increasing concentrations [0.4–100 ng/mL] of recombinant rat/mouse (rr/mr) IL-10 or vehicle was directly added to half-maximally constricted (phenylephrine, PE) vessels (without PVAT, with endothelium). IL-10 did not cause a direct vasorelaxation. Further, the ability of rrIL-10 to cause a rightward or downward shift of a vasoconstriction-response curve was tested in the rat. The vessels were incubated with rrIL-10 [100 ng/mL or 10 ng/mL] or vehicle for 1.5 h in the tissue bath followed by a cumulative PE [10−8–10−4 M] or U46619 [10−10–10−5 M] response curve. The maximal contractions and EC50 values were similar in IL-10 incubated vessels vs vehicle. Thus, acute exposure of exogenous IL-10 did not reduce local vasoconstriction. To further test if endogenous IL-10 from PVAT was anti-contractile, superior mesenteric arteries from IL-10 WT and KO mice, with and without PVAT, were subjected to increasing concentrations of PE. The anti-contractile nature of PVAT was preserved with both short-term and prolonged depletion (using younger and older mice, respectively) of endogenous IL-10 in males and females. Contrary to our hypothesis, PVAT-derived IL-10 neither caused vasorelaxation nor reduced local vasoconstriction directly/indirectly. Therefore, IL-10 does not contribute to the anti-contractile nature of PVAT in healthy rodents.",health
10.1016/j.eswa.2021.114568,Journal,Expert Systems with Applications,scopus,2021-06-01,sciencedirect,An expert system for EMI data classification based on complex Bispectrum representation and deep learning methods,https://api.elsevier.com/content/abstract/scopus_id/85100040048,"This paper presents expert system framework based on Machine Learning (ML) for High-Voltage (HV) asset condition monitoring. The work investigates the classification of insulation faults in HV environment, based on real-world time series signals labelled by condition monitoring experts. Extending on our previous work, the proposed approach exploits the Bispectrum analysis and deep learning for feature extraction and classification. The calculated Bispectrum on time series signals can be deployed as the complex-valued Bispectrum, which contains phase information, or as its real-valued magnitude. This can be approached as an image classification problem which can be implemented in various deep networks including Convolutional Neural Network (CNN), Residual Neural Network (ResNet) and their complex-valued version. The employed deep networks performance is compared in terms of their classification accuracy. High classification performance is obtained which produces comparable performance with expert diagnosis. Thus, it can be interpreted as transfer of expert system to an intelligent system.",health
10.1016/j.micpro.2021.104007,Journal,Microprocessors and Microsystems,scopus,2021-06-01,sciencedirect,Intelligent diagnosis of Alzheimer's disease based on internet of things monitoring system and deep learning classification method,https://api.elsevier.com/content/abstract/scopus_id/85099497398,"Alzheimer's disease is a syndrome with a decreased ability to a different classification. Alzheimer's disease (AD), memory, and learning affect the classification domain as cognitive-motor or executive function, which is the most common dementia. Death and expensive detection is high treatment and between the result of the count rate of patient care. Early detection of AD is considered very important to improve patients' quality of life and their families. The purpose of this article is to reduce the cost of accelerating related to the diagnosis. The o allow complete access is possible to introduce a new non-invasive early diagnosis method. The new AD screening tests' interaction is based on introducing new technology in the business system, and an immersive and advanced human-computer has been introduced to the Internet system. Four experiments, based on the large-scale screening, damage to the mechanism of classification domain, shows that can be used in the network design of the thing system. In the proposed test, mainly common goal, focusing on evaluating the recent related memory loss in the conversation and events, human and between the virtual world and the real machine; abnormal the ability to recognize, express, and understand diagnostic differences in language problems terms. IOT (IOT) has integrated hundreds of millions of smart devices that can communicate with a minimum of human intervention. It should be strengthened to secure methods to ensure the ecosystem of useful IOT. Machine Learning (ML) is proceeding significantly over the past few years; in some critical applications, machine intelligence is actually of the machine to the laboratory curiosity conversion. The ability to monitor the IOT devices and intelligence will provide an essential solution for new or zero-day attacks. Components and apparatus of the ML Hano IOT are, based on whether learning the IOT in the environment is an effective way to explore the ""normal,"" ""abnormal"" behavior data.",health
10.1016/j.bpg.2020.101722,Journal,Best Practice and Research: Clinical Gastroenterology,scopus,2021-06-01,sciencedirect,Striving for quality improvement: can artificial intelligence help?,https://api.elsevier.com/content/abstract/scopus_id/85099293210,"Artificial intelligence (AI) is of keen interest for global health development as potential support for current human shortcomings. Gastrointestinal (GI) endoscopy is an excellent substrate for AI, since it holds the genuine potential to improve quality in GI endoscopy and overall patient care by improving detection and diagnosis guiding the endoscopists in performing endoscopy to the highest quality standards. The possibility of large data acquisitioning to refine algorithms makes implementation of AI into daily practice a potential reality. With the start of a new era adopting deep learning, large amounts of data can easily be processed, resulting in better diagnostic performances. In the upper gastrointestinal tract, research currently focusses on the detection and characterization of neoplasia, including Barrett’s, squamous cell and gastric carcinoma, with an increasing amount of AI studies demonstrating the potential and benefit of AI–augmented endoscopy. Deep learning applied to small bowel video capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. In the colon, multiple prospective trials including five randomized trials, showed a consistent improvement in polyp and adenoma detection rates, one of the main quality indicators in endoscopy. There are however potential additional roles for AI to assist in quality improvement of endoscopic procedures, training and therapeutic decision making. Further large-scale, multicenter validation trials are required before AI–augmented diagnostic gastrointestinal endoscopy can be integrated into our routine clinical practice.",health
10.1016/j.bpg.2020.101721,Journal,Best Practice and Research: Clinical Gastroenterology,scopus,2021-06-01,sciencedirect,Colorectal polyp characterization with endocytoscopy: Ready for widespread implementation with artificial intelligence?,https://api.elsevier.com/content/abstract/scopus_id/85098512500,"Endocytoscopy provides an in-vivo visualization of nuclei and micro-vessels at the cellular level in real-time, facilitating so-called “optical biopsy” or “virtual histology” of colorectal polyps/neoplasms. This functionality is enabled by 520-fold magnification power with endocytoscopy and recent breakthroughs in artificial intelligence (AI) allowing a great advance in endocytoscopic imaging; interpretation of images is now fully supported by AI tool which outputs predictions of polyp histopathology during colonoscopy. The advantage of the use of AI during optical biopsy can be appreciated especially by non-expert endoscopists who to increase performance.
                  This paper provides an overview of the latest evidence on colorectal polyp characterization with endocytoscopy combined with AI and identify the barriers to its widespread implementation.",health
10.1016/j.tox.2021.152770,Journal,Toxicology,scopus,2021-05-30,sciencedirect,Exposure to PM2.5 aggravates Parkinson's disease via inhibition of autophagy and mitophagy pathway,https://api.elsevier.com/content/abstract/scopus_id/85103978922,"Extensive health studies had declared that exposure to particulate matter (PM) was closely associated with neurodegenerative diseases, i.e. Parkinson’s disease (PD). Our aim was to clarify the potential molecular mechanism by which PM2.5 aggravated PD symptoms using in vitro and in vivo PD models. In this study, PC12 cells treated with rotenone (1 μM) and/or PM2.5 (50 μg/mL) for 4 days was used as the in vitro model. C57BL/6 J mice expored to PM2.5 (inhalation, 2.5 mg/kg) and rotenone (intraperitoneal injection, 30 mg/kg) for 28 days was used as the in vivo model. Rapamycin was used to promote the level of autophagy. The results showed that after exposure to PM2.5, the apoptosis of rotenone-treated PC12 cells were increased by increasing the ROS levels and decreasing the levels of mitochondrial membrane potential. In rotenone-treated PC12 cells, exposure to PM2.5 could decrease the expression levels of LC3II and Atg5, and increase the expression level of mTOR, suggesting that PM2.5 exposure inhibited autophagy. Furthermore, the mitophagy related genes, including PINK1 and Parkin, were decreased. At the same time, inhalation of PM2.5 could relieve the behavioral abnormalities of PD mouse induced by rotenone. The levels of inflammatory factors (TNF-α, IL-1β, and IL-6) were significantly increased. Inhalation of PM2.5 could induce the oxidative stress and apoptosis in the substantia nigra of PD mouse, as well as the key markers of autophagy and mitophagy were also changed, which was consistent with the cell model. Besides, rapamycin would relieve the damaging effect of PM2.5 by triggering autophagy and mitophagy in rotenone-induced PD models. These results indicated that exposure to PM2.5 aggravated the behavioral abnormalities of PD symptoms through increasing oxidative stress, decreasing autophagy and mitophagy, and inducing mitochondria-mediated neuronal apoptosis. These findings not only revealed the effects and mechanism of PM2.5 exposure on PD, but also provided fundamental data that can be exploited to develop environmental safety policies.",health
10.1016/j.knosys.2021.106925,Journal,Knowledge-Based Systems,scopus,2021-05-23,sciencedirect,A novel deep metric learning model for imbalanced fault diagnosis and toward open-set classification,https://api.elsevier.com/content/abstract/scopus_id/85102352594,"Intelligent fault diagnosis based on deep neural networks and big data has been an attractive field and shows great prospects for applications. However, applications in practice face following problems. (1) Unexpected and unseen faults of machinery in real environment may be encountered. (2) Large collections of healthy condition samples and few fault condition samples result in the imbalanced distribution of machinery health conditions. This paper proposes a novel deep metric learning model, where machinery condition is classified by retrieving similarities. The trained deep metric learning model can learn and recognize new faults quickly and easily to address the first problem. As core of deep metric learning, a novel loss function called normalized softmax loss with adaptive angle margin (NSL-AAM) is developed for second problem. NSL-AAM can supervise neural networks learning imbalanced data without altering the original data distribution. Experiments for balanced and imbalanced fault diagnosis are conducted to verify the ability of the proposed model for fault diagnosis. The results demonstrate that the proposed model can not only extract more distinctive features automatically, but also balance the representation of both the majority and minority classes. Furthermore, the results of experiments for diagnosing new faults are reported, which proves the capability of the trained model for open-set classification.",health
10.1016/j.jep.2021.113943,Journal,Journal of Ethnopharmacology,scopus,2021-05-23,sciencedirect,"Xuesaitong exerts long-term neuroprotection for stroke recovery by inhibiting the ROCKII pathway, in vitro and in vivo",https://api.elsevier.com/content/abstract/scopus_id/85101738050,"Ethnopharmacological relevance
                  Xuesaitong (XST) is a traditional Chinese medicine injection with neuroprotective properties and has been extensively used to treat stroke for many years. The main component of XST is Panax notoginseng saponins (PNS), which is the main extract of the Chinese herbal medicine Panax notoginseng.
               
                  Aim of the study
                  In this study, we investigated whether XST provided long-term neuroprotection by inhibiting neurite outgrowth inhibitor-A (Nogo-A) and the ROCKII pathway in experimental rats after middle cerebral artery occlusion (MCAO) and in SH-SY5Y cells exposed to oxygen-glucose deprivation/reperfusion (OGD/R).
               
                  Materials and methods
                  Rats with permanent MCAO were administered XST, Y27632, XST plus Y27632, and nimodipine for 14 and 28 days. Successful MCAO onset was confirmed by 2,3,5-triphenyl tetrazolium chloride (TTC) staining. Neurological deficit score (NDS) was used to assess neurological impairment. Hematoxylin-eosin (HE) staining and immunohistochemical (IHC) analysis of synaptophysin (SYN) and postsynaptic density protein-95 (PSD-95) were performed to evaluate cerebral ischemic injury and the neuroprotective capability of XST. Nogo-A levels and the ROCKII pathway were detected by IHC analysis, western blotting, and quantitative real-time polymerase chain reaction (qRT-PCR) to explore the protective mechanism of XST. OGD/R model was established in SH-SY5Y cells. Cell counting kit 8 (CCK8) was applied to detect the optimum OGD time and XST concentration. The expression levels Nogo-A and ROCKII pathway were determined using western blotting.
               
                  Results
                  Our results showed that XST reduced neurological dysfunction and pathological damage, promoted weight gain and synaptic regeneration, reduced Nogo-A mRNA and protein levels, and inhibited the ROCKII pathway in MCAO rats. CCK8 assay displayed that the optimal OGD time and optimal XST concentration were 7 h and 20 μg/mL respectively in SH-SY5Y cells. XST could evidently inhibit OGD/R-induced Nogo-A protein expression and ROCKII pathway activation in SH-SY5Y cells.
               
                  Conclusions
                  The present study suggested that XST exerted long-term neuroprotective effects that assisted in stroke recovery, possibly through inhibition of the ROCKII pathway.",health
10.1016/j.jclepro.2021.126493,Journal,Journal of Cleaner Production,scopus,2021-05-15,sciencedirect,High-resolution prediction of the spatial distribution of PM<inf>2.5</inf> concentrations in China using a long short-term memory model,https://api.elsevier.com/content/abstract/scopus_id/85102349520,"The concentration of fine particulate matter (PM2.5) has a significant impact on the environment and human health. However, strong spatial heterogeneity and spatiotemporal dependence increases the difficulty of prediction. Moreover, due to the lag of the update of auxiliary variables at national scale in the prediction application, it is still difficult to achieve the timely nationwide PM2.5 prediction at present. To better model and predict real time concentrations and spatial distributions of PM2.5, this study developed a workflow of future PM2.5 concentrations prediction based on long short-term memory (LSTM) model. Using ground-based station PM2.5 data in 2014–2018, the 1 km Multi-Angle Implementation of Atmospheric Correction (MAIAC) aerosol optical depth (AOD) product and other auxiliary data to predict PM2.5 concentrations in the next year and generate a high-resolution national PM2.5 concentration spatial distribution map. The LSTM model outperformed random forest (RF) and Cubist approaches for prediction PM2.5 because of its recurrent neural network structure that can capture time dependence and nonlinear relationships among PM2.5 concentrations and other independent variables, and exhibited a stable accuracy with an R2 of 0.83, by applying the annual time series, with an improvement of 0.04–0.09, compared to daily and monthly data. The results indicated that PM2.5 pollution had gradually decreased in 2019 after application of pollution controls, with annual mean PM2.5 concentrations of 27.33 ± 15.56 μg m−3, although there were still some areas with severe pollution, including the North China Plain, parts of the Loess Plateau, and the Taklimakan Desert. The LSTM model makes it possible to predict fine-scale PM2.5 spatial distributions nationwide in the future and may thus be useful for sustainable management and control of air pollution at a national scale.",health
10.1016/j.engstruct.2021.112084,Journal,Engineering Structures,scopus,2021-05-15,sciencedirect,Human-machine collaboration framework for structural health monitoring and resiliency,https://api.elsevier.com/content/abstract/scopus_id/85102047246,"Post-earthquake damage assessment can be significantly expedited when machine learning (ML) algorithms supported by sensing technologies are used. ML has some limitations when it comes to seismic damage assessment. ML tools require data from each class while training but in the case of seismic structural health monitoring, vibration data are usually available from the undamaged structures. In this paper, a framework called the human-machine collaboration (H-MC) is proposed. The H-MC framework combines the ML tools and human (domain) expertise for damage assessment of real instrumented buildings with only data from undamaged cases. It uses novelty detection as the ML tool and structure-specific analytical model to enable rapid damage detection. Subsequently, the framework is applied to detect damage in real instrumented buildings. The results showed that the H-MC algorithm correctly detected the damaged cases. It also labeled all the undamaged events accurately eliminating false positive detection. Furthermore, it is revealed that the resiliency of a building can be improved when the H-MC method is implemented over traditional field inspection. The proposed framework can be a viable tool for rapid post-earthquake damage assessment which is essential for improving community resiliency.",health
10.1016/j.jhazmat.2020.124811,Journal,Journal of Hazardous Materials,scopus,2021-05-15,sciencedirect,Two birds with one stone: The detection of nerve agents and AChE activity with an ICT-ESIPT-based fluorescence sensor,https://api.elsevier.com/content/abstract/scopus_id/85099161652,"Nerve agents are among the world’s deadliest poisons, and the target enzyme is acetylcholinesterase (AChE). To better diagnosis nerve agent poisonings, a reliable diagnostic method for both nerve agents and AChE is desirable. Herein, we synthesized a series of fluorescent sensors for both real nerve agents and acetylcholinesterase activity detection. Among these sensors, HBQ-AE exhibited a fast response rate (within 10 s for nerve agent and 8 min for AChE), good sensitivity (the limit of detection is 6 nM and 0.2 U/mL) and a high off/on contrast. To the best of our knowledge, HBQ-AE is the first fluorescence sensor for nerve agents and AChE activity detection. The fluorescent change of HBQ-AE from nonfluorescence to blue fluorescence (nerve agent) or orange fluorescence (AChE) by excitation at 365 nm can be easily observed with the naked eye. HBQ-AE was successfully applied to image nerve agents and AChE activity in living cells. Moreover, HBQ-AE is the vital member to construct a test paper that can be employed to detect and diagnose chemical warfare agents.",health
10.1016/j.eswa.2020.114538,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Parallel versus cascaded logistic regression trained single-hidden feedforward neural network for medical data,https://api.elsevier.com/content/abstract/scopus_id/85098990261,"Objective
                  An important step towards a better healthcare system is fast and accurate diagnosis. In the last decade, the application of intelligent systems in healthcare has led to impressive results. The goal of this paper is to extend the LogSLFN (single-hidden layer feedforward neural network trained using logistic regression) algorithm, which has been deployed successfully in the past for the case of a two-class decision problem, to the case of multiple classes. We have considered and statistically analyzed two approaches: a parallel LogSLFN, and a cascaded LogSLFN.
               
                  Materials and methods
                  According to the universal approximation theorem, a single-hidden layer feedforward neural network has the ability to approximate arbitrarily closely continuous functions of several real variables under certain reasonable assumptions. Essentially, a single hidden layer containing a finite fixed number of neurons is sufficient to provide an arbitrarily well approximation to a given training set of inputs and a desired target output represented by a continuous function. Parallel LogSLFN and cascaded LogSLFN are two novel approaches that can be applied to multiple-class decision problems. Both methods are extensions of the LogSLFN, which uses logistic regression to compute the weights between the input and hidden layer of a single-hidden layer feedforward network. No error correction is needed, the weights between the hidden and the output layer being computed using the Moore-Penrose pseudoinverse matrix. The proposed models have been tested on two medical datasets regarding cancer diagnosis and liver fibrosis staging. Experimental results and the subsequent statistical analysis have proved the robustness of the proposed models with other machine learning techniques reported in literature.
               
                  Main findings
                  The experimental results showed that the Parallel approach surpasses the Cascaded one. Still, both models are competitive to the other state-of-the-art techniques.
               
                  Conclusions
                  The LogSFLN algorithm can be successfully extended to multiple-class decision problems. By embedding knowledge extracted from the data into the architecture, we obtained a raise by 20% in accuracy when applied on the liver fibrosis dataset.",health
10.1016/j.eswa.2020.114533,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Dynamic learning framework for epileptic seizure prediction using sparsity based EEG Reconstruction with Optimized CNN classifier,https://api.elsevier.com/content/abstract/scopus_id/85098953605,"The World Health Organization (WHO) recently stated that epilepsy affects nearly 65 million people of the world population. Early forecast of the oncoming seizures is of paramount importance in saving the life of epileptic patients. This paper demonstrates a phase transition-based seizure prediction approach from multi-channel scalp electroencephalogram (EEG) recordings. The primary focus of this work is to discriminate the seizure and seizure-free EEG signals by learning the dynamics of preictal, interictal and ictal period. We propose an adaptive optimization approach using non-linear conjugate gradient technique in conjunction with Sparsity based EEG Reconstruction (SER) and three-dimensional Optimized Convolutional Neural Network (3D OCNN) classifier, based on Fletcher Reeves (FR) algorithm. Sparsity based artifact removal approach along with a 3D OCNN classifier, classifies the various states of seizures. FR algorithm is deployed with the deep neural network architecture to accelerate the convergence rate and to reduce the complexity of the proposed non-linear model. The Principle Component Analysis (PCA) algorithm replacing the Singular Value Decomposition (SVD) in the K-SVD algorithm, further reduces the time and complexity of the pre-processing stage. We further propose a Phase Transition based Kullback-Leibler divergence (PTB-KL) predictor for obtaining the Optimal Seizure Prediction Horizon (OSPH). The proposed model is evaluated using three diverse databases such as CHB-MIT, NINC and SRM respectively. Empirical results on the three EEG databases of 300 recordings outperforms the state-of-art approaches with an accuracy score of 0.98, sensitivity score of 0.99 and False Prediction Rate (FPR) of 0.07 FP/h. Statistical assessment of the proposed predictor gains an OSPH of about 1.1 h prior to the seizure onset. Experimental results prove that the phase transition-based seizure prediction approach is a promising one for accurate real-time prediction of epilepsy using scalp EEG data.",health
10.1016/j.jbi.2021.103787,Journal,Journal of Biomedical Informatics,scopus,2021-05-01,sciencedirect,Can technological advancements help to alleviate COVID-19 pandemic? a review,https://api.elsevier.com/content/abstract/scopus_id/85104674391,"The COVID-19 pandemic is continuing, and the innovative and efficient contributions of the emerging modern technologies to the pandemic responses are too early and cannot be completely quantified at this moment. Digital technologies are not a final solution but are the tools that facilitate a quick and effective pandemic response. In accordance, mobile applications, robots and drones, social media platforms (such as search engines, Twitter, and Facebook), television, and associated technologies deployed in tackling the COVID-19 (SARS-CoV-2) outbreak are discussed adequately, emphasizing the current-state-of-art. A collective discussion on reported literature, press releases, and organizational claims are reviewed. This review addresses and highlights how these effective modern technological solutions can aid in healthcare (involving contact tracing, real-time isolation monitoring/screening, disinfection, quarantine enforcement, syndromic surveillance, and mental health), communication (involving remote assistance, information sharing, and communication support), logistics, tourism, and hospitality. The study discusses the benefits of these digital technologies in curtailing the pandemic and ‘how’ the different sectors adapted to these in a shorter period. Social media and television’s role in ensuring global connectivity and serving as a common platform to share authentic information among the general public were summarized. The World Health Organization and Governments’ role globally in-line with the prevention of propagation of false news, spreading awareness, and diminishing the severity of the COVID-19 was discussed. Furthermore, this collective review is helpful to investigators, health departments, Government organizations, and policymakers alike to facilitate a quick and effective pandemic response.",health
10.1016/j.jsps.2021.03.002,Journal,Saudi Pharmaceutical Journal,scopus,2021-05-01,sciencedirect,"Commiphora myrrha (Nees) Engl. resin extracts induce phase-I cytochrome P450 2C8, 2C9, 2C19, and 3A4 isoenzyme expressions in human hepatocellular carcinoma (HepG2) cells",https://api.elsevier.com/content/abstract/scopus_id/85104367846,"Commiphora myrrha (Nees) Engl. (C. myrrha) resin is the most Middle Eastern herbal medicine used against numerous diseases. After being decocted or macerated, this resin is widely consumed among Saudi Arabian patients who are already under prescribed medication. Despite its popularity, no studies have been reported on potential modulation effects of these resin extracts on drug metabolism. Therefore, we studied C. myrrha resin extracts on the expression of cytochrome P450 (CYP) drug-metabolizing isoenzyme in human hepatocellular carcinoma cell line HepG2. The C. myrrha extracts were prepared by sonication and boiling, resembling the most popular traditional preparations of maceration and decoction, respectively. Both boiled and sonicated aqueous extracts were fingerprinted using high-performance liquid chromatography equipped with ultra-violet detector (HPLC-UVD). The viability of HepG2 cells treated with these aqueous extracts was determined using CellTiter-Glo® assay in order to select the efficient and non-toxic resin extract concentrations for phase-I metabolic CYP isoenzyme expression analysis. The isoenzyme gene and protein expression levels of CYP 2C8, 2C9, 2C19, and 3A4 were assessed using reverse transcription-quantitative polymerase chain reaction and Western blot technologies. The HPLC-UVD fingerprinting revealed different chromatograms for C. myrrha boiled and sonicated aqueous extracts. Both aqueous extracts were toxic to HepG2 cells when tested at concentrations exceeding 150 µg/ml of the dry crude extract. The CYP 2C8, 2C9, and 2C19 mRNA expression levels increased up to 4.0-fold in HepG2 cells treated with either boiled or sonicated C. myrrha aqueous extracts tested between 1 and 30 µg/ml, as compared with the untreated cells. However, CYP3A4 mRNA expression level exceeded the 2.0-fold cutoff when the cells were exposed to 30 µg/ml of C. myrrha extracts. The up-regulation of CYP mRNA expression levels induced by both boiled and sonicated C. myrrha aqueous extracts was confirmed at the CYP protein expression levels. In conclusion, both sonicated and boiled C. myrrha aqueous extracts modulate CYP 2C8, 2C9, 2C19, and 3A4 gene expression at clinically-relevant concentrations regardless of preparation methods. Further in vitro and in vivo experiments are required for CYP isoenzyme activity assessment and the establishment of herb-drug interaction profile for these traditional medicinal resin extracts.",health
10.1016/j.cjca.2020.12.009,Journal,Canadian Journal of Cardiology,scopus,2021-05-01,sciencedirect,Digital Health Approaches for the Assessment and Optimisation of Hypertension Care Provision,https://api.elsevier.com/content/abstract/scopus_id/85104335482,"Although many aspects of our lives have been transformed by digital innovation, widespread adoption of digital health advancements within the health care sector in general, and for hypertension care specifically, has been limited. However, it is likely that, over the next decade, material increases in the uptake of digital health innovations for hypertension care delivery will be seen. In this narrative review, we summarise those innovations thought to have the greatest chance for impact in the next decade. These include provision of virtual care combined with home blood pressure (BP) telemonitoring, use of digital registries and protocolised care, leveraging continuous BP measurement to collect vast amounts of individual and population-based BP data, and adoption of digital therapeutics to provide low-cost scalable interventions for patients with or at risk for hypertension. Of these, home BP telemonitoring is likely the most ready for implementation, but it needs to be done in a way that enables efficient guideline-concordant care in a cost-effective manner. In addition, efforts must be focused on implementing digital health solutions in a manner that addresses the major challenges to digital adoption. This entails ensuring that innovations are accessible, usable, secure, validated, evidence based, cost-effective, and integrated into the electronic systems that are already used by patients or providers. Increasing the use of broader digital innovations such as artificial/augmented intelligence, data analytics, and interactive voice response is also critically important. The digital revolution holds substantial promise, but success will depend on the ability of collaborative stakeholders to adopt and implement innovative, usable solutions.",health
10.1016/j.evopsy.2021.03.006,Journal,Evolution Psychiatrique,scopus,2021-05-01,sciencedirect,"From Digital Identity to Connected Personality, From Augmented Diagnostician to Virtual Caregiver: What Are the Challenges for the Psychology and the Psychiatry of the Future?",https://api.elsevier.com/content/abstract/scopus_id/85104125089,"Objectifs
                  Qui sommes-nous devenus, citoyens, patients, praticiens ? En quoi les moyens de communications et l’informatisation de notre société modifient-ils, intègrent-ils nos identités ? L’intelligence artificielle comprendrait-elle bientôt plus justement l’être humain dont elle s’émanciperait ?
               
                  Matériel et méthodes
                  Cheminons à partir de la lexicologie pour tenter de saisir, via le point de vue de la philosophie, l’identité contemporaine vers la notion d’« identité numérique » dont les incidents psychologiques normaux ou pathologiques entraînent ce que nous définissons « la personnalité numérique ». Puis, posant les bases d’une psychologie de l’identité contemporaine, nous envisageons comment « la psychologie » et « la psychiatrie » actuelles considèrent « la personnalité » du patient et, en retour, comment elles se définissent du point du vue du « praticien en ligne » ou du « chercheur connecté ».
               
                  Résultats
                  En échange de son utilisation « gratuite », l’action de l’internaute sur le Web 2.0 produit du contenu et alimente des bases de données, déclaratives ou non. En perte d’intimité au fur et à mesure que « ses » données ne lui appartiennent plus, l’identité du citoyen se décompose en fonctions des supports digitaux : site de rencontre amical, plateforme de liens amoureux, blog concernant un loisir ou un voyage, etc. Par le même mouvement, l’identité numérique se compose en autre-soi possédant une part d’intelligence artificielle pourvoyeuse de capacité d’existence propre. Plutôt que deux entités parallèlement différentiables, réelle ou augmentée, naît une identité hybride « réalistiquo-virtuelle ». Quelles conséquences normales ou pathologiques chez l’être humain ? Les tendances sociétales post-modernes issues du digital ou y trouvant expression peuvent entraîner, chez un individu donné, une exacerbation des traits de personnalité préalablement existants, voire des symptômes. Parallèlement, il arrive que les moyens de communication moderne deviennent une aide pour expérimenter le monde, majorer l’estime de soi, rêver favorablement ses phantasmes, se confier plus facilement à des « inconnu(e)s », etc. Mais dans tous les cas, chez le sujet souffrant, ou ne souffrant pas, préalablement à sa surexposition, de maladie neuropsychiatrique ou de trouble psychopathologique, il s’avère aujourd’hui scientifiquement documenté que la confrontation numérique accrue induit des atteintes neuropsychiques massives (affaiblissement de la mémoire de travail, des capacités d’attention et de concentration, des aptitudes à construire des opérations cognitives élaborées, etc.). Sur le plan psychopathologique, plutôt que la terminologie de « trouble de l’identité » ou une notion de « co-identités », le terme d’« identité trouble » nous paraît le mieux rendre compte de cette mutation du « moi » où la frontière entre réalité et virtualités s’amenuise : la dissociation prévaut. L’homme post-moderne et ses objets connectés ne font plus qu’un, mais cet « uniforme » apparaît constitué d’un patchwork de confettis identificatoires plus ou moins accolés, sans réelle harmonisation d’ensemble. La personnalité commune se marque d’hyperexpressivité et d’hyperémotivité, au détriment de la possibilité de contrôle des affects et du développement des capacités d’introspection. Contre le risque du vide, tend à se développer une contra-phobie par l’ordiphone, par l’objet lui-même, par la possibilité de contacter en permanence ses proches si nécessaire, et en retour rester toujours « disponible », ce qui alimente une forme d’égocentrisme addictogène. Résulte de ses évolutions, globalement dans la société, un affaiblissement des capacités langagières, et ainsi de réflexion, y compris pour l’espace clinique et scientifique.
               
                  Discussion
                  Pour les domaines de la psychologie et de la psychiatrie, s’associent actuellement deux évolutions : une velléité d’« objectivité-scientificité » et une numérisation de la relation patient–soignant. Du côté de la « science », la médecine objective « factuelle » s’intéresse de plus en plus à la pathologie aux dépens du sujet en souffrance, confondant signe et symptôme, glissant jusqu’à un niveau moléculaire, très en-deçà du patient, vers une psychiatrie ou une psychologie « post-clinique ». Qu’on veuille la promouvoir ou l’anéantir, du côté du clinicien ou du chercheur, la « subjectivité » est devenue un signifiant à la mode pour le domaine de la santé psychique. Ce retour actuel du « subjectif » prospère sur une sorte de peur de la subjectivité depuis la fin de la seconde guerre mondiale qui avait entraîné la nosographie américaine vers les « objectifs » des DSM (Manuel Diagnostique et Statistique des Troubles Psychiques publié par l’American Psychiatric Association depuis 1952). Mais plutôt qu’une connaissance validable, et/ou invariable concernant tel ou tel trouble psychique, le changement, la relativité des entités nosographiques d’une version à l’autre du manuel traduit, en miroir, la subjectivité d’une époque, ce que nous appelons « subjectivité sociétale ». Autant qu’elle témoigne de notre temps, la révolution bio-numérique s’imposera probablement dans une future édition de la nosographie : la validité diagnostique devrait se majorer par la définition précise de marqueurs biologiques et/ou neuroradiologiques, si ceux-ci participent à construire une théorie étiopathogénique des phénomènes psychiques observés. Cette orientation reste toutefois balbutiante : outre l’infime nombre de biomarqueurs identifiés, et surtout utilisables en pratique quotidienne, leurs liens de causalité ou de conséquentialité avec les symptômes ou le processus morbide restent le plus souvent incertains autant qu’ils sont fort divers et interreliés. Le chercheur en neurosciences vise à mesurer et analyser une multitude de données, intégrant en particulier les mimiques et les émotions authentifiables par caméra thermique, les mouvements des segments des corps et dynamiques des regards enregistrables par des capteurs, la standardisation des voix et des discours pour analyse par logiciel informatique de la prosodie, des signifiants employés, de la syntaxe… le tout s’intégrant dans un phénotypage digital de la souffrance. Pourra-t-on bientôt parler, en remplacement du psychologue ou du psychiatre, de « diagnosticien augmenté » ?
               
                  Conclusion
                  Apparaît-il actuellement hasardeux de faire confiance à un thérapeute entièrement virtuel… expérience déjà lancée il y a plus de 50 ans ! L’être humain est un « être de sens », or, selon le modèle de la clinique traumatique, le surgissement du tout-numérique peut entraîner un « effondrement du sens » générateur d’une tendance à la dissociation de la personnalité. Accordant le rétablissement des liens entre émotions, affects, comportements et cognitions, le langage parlé atténue puis fait disparaître la dissociation. Guidée par le praticien, cette parole thérapeutique est parfois qualifiée de « maïeutique », du nom de la science de l’accouchement : elle construit synchroniquement à son essence la pensée, et une prise de conscience de celle-ci, plutôt qu’elle n’en rendrait compte secondairement. Il s’agit d’une réinterprétation causale d’un sens compris ou plutôt « attribué » singulièrement par le sujet, après-coup, le passé revisité dans l’instant noue une synthèse, le hasard est transformé en destin. Le sujet qui parle réélabore son histoire vers une reconstruction sémantique, une densification de ses réseaux de signification. Reconquérant son être par la création d’un discours, de méandres véridiques comme fictionnels, la narration, voire la poétisation, offre l’illusion ponctuelle d’une meilleure cohérence, toujours relative, illusoire La parole thérapeutique et le discours sur celle-ci restent en devenir, inachevés, incertains autant que vivants, caractérisant une « post-psychothérapie », c’est-à-dire une psychothérapie et non pas une technique rééducative qui se trouverait figée dans des objectifs connus à l’avance. Les notions de faits et de réalité sont ici secondaires, non pas au sens de l’objectif, ni même du subjectif, mais du second degré, puis d’autres degrés successifs ou imbriqués portant l’effort intellectuel. Vers l’apaisement, si nous voulions amener la réflexion à son paroxysme, nous pourrions avancer qu’il suffirait de donner « n’importe quel sens », d’en choisir un quel qu’il soit, du côté du patient ou du praticien, sans qu’il ne soit nécessairement le même, témoignage d’une construction intersubjective formellement invalide.
               
                  Objectives
                  Who have we become, as citizens, patients, practitioners? How do the means of communication and the computerization of our society, its digitization, modify and integrate our identities? Can we assume that artificial intelligence will soon have a more accurate understanding of the human being from whom it will have emancipated itself?
               
                  Materials and methods
                  We move from lexicology to try to grasp, from the point of view of philosophy, a contemporary identity that is moving towards the notion of a “digital identity” whose normal or pathological psychological incidents lead to what we define as “the digital personality.” Then, laying the foundations for a contemporary psychology of identity, we consider how current “psychology” and “psychiatry” view the patient's “personality” and, in turn, how they define themselves from the point of view of “the patient,” or, inversely, from the point of view of the “online practitioner” or “connected researcher.”
               
                  Results
                  In exchange for its “free” use, the Internet user's action on Web 2.0 produces content and feeds databases, whether this is declared or not. Users’ privacy is lost, as “their” data no longer belongs to them; and citizens’ identity is broken down into digital media functions: a site for meeting friends, a dating platform, a blog about hobbies or travel, etc. At the same time, digital identity is made up of an other-self, including a part of artificial intelligence that provides capacity for its own existence. Rather than two parallel, differentiable entities, real or augmented, a “realistic-virtual” hybrid identity is born. What are the normal or pathological consequences for humans? Postmodern societal trends emerging from or finding expression in the digital can lead to an exacerbation of previously existing personality traits, or even symptoms, in a given individual. At the same time, it happens that the modern means of communication become an aid to experience the world, to increase self-esteem, to dream favorably about one's fantasies, to confide more easily in “strangers,” etc. But in all cases, in the subject suffering, or not suffering, prior to his overexposure, from a neuropsychiatric disease or a psychopathological disorder, it now turns out to be scientifically documented that the increased numerical confrontation induces massive neuropsychic damage (weakening working memory, attention and concentration skills, skills in constructing sophisticated cognitive operations, etc.). On the psychopathological level, rather than the terminology of “identity disorder” or a notion of “co-identities,” the term “identity elusive"" seems to us to best account for this mutation of the “me” where the border between reality and virtualities is shrinking: dissociation prevails. The postmodern human and its connected objects become one, but this “uniformity” appears to be made up of a patchwork of identifying confetti more or less joined together, without a real overall harmonization. The common personality is marked by hyperexpressiveness and hyperemotivity, to the detriment of the possibility of controlling affects and the development of introspective capacities. Against the risk of a vacuum, a contra-phobia tends to develop through the smartphone, by the object itself, by the possibility of constantly contacting relatives if necessary, and in return always remaining “available,” which fuels a form of addicting self-centeredness. The result of these developments, for society in general, is a weakening of language skills, and thus of reflection, including in the clinical and scientific space.
               
                  Discussion
                  For the areas of psychology and psychiatry, two developments are currently associated: a desire for “objectivity-scientificity” and a digitization of the patient–caregiver relationship. On the side of “science,” objective “factual” medicine is increasingly interested in pathology at the expense of the suffering subject, confusing sign and symptom, sliding down to a molecular level, far below the patient, towards psychiatry or postclinical psychology. Whether we want to promote it or destroy it, on the side of the clinician or the researcher, “subjectivity” has become a fashionable signifier in the field of mental health. This current return of the “subjective” thrives on a kind of fear of subjectivity present since the end of World War II, which had led American nosography towards the “objectives” of the DSM (Diagnostic and Statistical Manual of Mental Disorders, published by the American Psychiatric Association since 1952). But rather than a verifiable and/or invariable knowledge concerning a particular psychic disorder, the changes and the relativity of nosographic entities from one version of the manual to another provides us with a mirror image of the subjectivity of an era, which we propose to call “societal subjectivity.” As much as it is a product of our time, the bio-digital revolution will probably impose itself in a future edition of nosography: the diagnostic validity should be increased by the precise definition of biological and/or neuroradiological markers, if these participate in building an etiopathogenic theory of observed psychic phenomena. This orientation remains in its infancy, however: in addition to the tiny number of identified biomarkers, and above all, those that are usable in daily practice, their causal or consequential links with symptoms or with the morbid process remain most often uncertain, inasmuch as they are diverse and interrelated. The neuroscience researcher aims to measure and analyze a multitude of data, integrating, in particular, mimicry and emotions authenticated by thermal camera; movements of body segments and gaze dynamics recorded by sensors; the standardization of voices and speeches for computer software analysis of prosody, used signifiers, syntax… all of which is integrated into a digital phenotyping of suffering. Will we soon be able to speak, replacing the psychologist or the psychiatrist, of an “augmented diagnostician?”.
               
                  Conclusion
                  Does it currently appear risky to trust an entirely virtual therapist… an experiment already launched more than 50 years ago! The human being is a “being of meaning,” yet, according to the model of trauma, the emergence of the all-digital can lead to a “collapse of meaning,” generating a tendency to personality dissociation. Granting the reestablishment of the links between emotions, affects, behaviors, and cognitions, spoken language attenuates dissociation, then makes it disappear. Guided by the practitioner, this therapeutic word is sometimes qualified as “maieutics,” from the name of the science of childbirth: it builds thought synchronously to its essence, and an awareness of it, rather than nondisclosure, would account for it secondarily. It is a causal reinterpretation of a meaning understood or rather “attributed” singularly by the subject, after the fact: the past revisited in the present moment creates a synthesis, and chance is transformed into fate. The speaking subject re-elaborates her/his story towards a semantic reconstruction, a densification of her/his networks of signification. Reclaiming one's being by the creation of a discourse, of veridical as well as fictional meanders, narration, even poetization, offers the punctual illusion of a better coherence, always relative, illusory… Therapeutic speech and discourse about such speech–these are still being made, unfinished, uncertain, and alive. These are the characteristics of what we could a “post-psychotherapy,” that is, a psychotherapy and not a re-educational technique whose objectives would be fixed and known in advance. The notions of facts and reality are secondary here, not in the sense of the objective, nor even of the subjective, but of the second degree, then of other successive or overlapping degrees that require intellectual effort. Moving towards appeasement, if we wanted to bring the reflection to its paroxysm, we could advance that it would be enough to give “any meaning,” whatever it may be. This would apply both to the patient and to the practitioner, without each party's meaning necessarily being the same: a testimony to a formally invalid intersubjective construction.",health
10.1016/j.mimet.2021.106186,Journal,Journal of Microbiological Methods,scopus,2021-05-01,sciencedirect,"Large-scale comparison of E. coli levels determined by culture and a qPCR method (EPA Draft Method C) in Michigan towards the implementation of rapid, multi-site beach testing",https://api.elsevier.com/content/abstract/scopus_id/85103706448,"Fecal pollution remains a challenge for water quality managers at Great Lakes and inland recreational beaches. The fecal indicator of choice at these beaches is typically Escherichia coli (E. coli), determined by culture-based methods that require over 18 h to obtain results. Researchers at the United States Environmental Protection Agency (EPA) have developed a rapid E. coli qPCR methodology (EPA Draft Method C) that can provide same-day results for improving public health protection with demonstrated sensitivity, specificity, and data acceptance criteria. However, limited information is currently available to compare the occurrence of E. coli determined by cultivation and by EPA Draft Method C (Method C). This study provides a large-scale data collection effort to compare the occurrence of E. coli determined by these alternative methods at more than 100 Michigan recreational beach and other sites using the complete set of quantitative data pairings and selected subsets of the data and sites meeting various eligibility requirements. Simple linear regression analyses of composite (pooled) data indicated a correlation between results of the E. coli monitoring approaches for each of the multi-site datasets as evidenced by Pearson R-squared values ranging from 0.452 to 0.641. Theoretical Method C threshold values, expressed as mean log10 target gene copies per reaction, that corresponded to an established E. coli culture method water quality standard of 300 MPN or CFU /100 mL varied only from 1.817 to 1.908 for the different datasets using this model. Different modeling and derivation approaches that incorporated within and between-site variability in the estimates also gave Method C threshold values in this range but only when relatively well-correlated datasets were used to minimize the error. A hypothetical exercise to evaluate the frequency of water impairments based on theoretical qPCR thresholds corresponding to the E. coli water quality standard for culture methods suggested that the methods may provide the same beach notification outcomes over 90% of the time with Method C results differing from culture method results that indicated acceptable and unacceptable water quality at overall rates of 1.9% and 6.6%, respectively. Results from this study provide useful information about the relationships between E. coli determined by culture and qPCR methods across many diverse freshwater sites and should facilitate efforts to implement qPCR-based E. coli detection for rapid recreational water quality monitoring on a large scale in the State of Michigan.",health
10.1016/j.cmpb.2021.106035,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-05-01,sciencedirect,Convolutional neural network based automatic screening tool for cardiovascular diseases using different intervals of ECG signals,https://api.elsevier.com/content/abstract/scopus_id/85102972408,"Background and Objective: Automatic screening tools can be applied to detect cardiovascular diseases (CVDs), which are the leading cause of death worldwide. As an effective and non-invasive method, electrocardiogram (ECG) based approaches are widely used to identify CVDs. Hence, this paper proposes a deep convolutional neural network (CNN) to classify five CVDs using standard 12-lead ECG signals.
                  
                     Methods: The Physiobank (PTB) ECG database is used in this study. Firstly, ECG signals are segmented into different intervals (one-second, two-seconds and three-seconds), without any wave detection, and three datasets are obtained. Secondly, as an alternative to any complex preprocessing, durations of raw ECG signals have been considered as input with simple min-max normalization. Lastly, a ten-fold cross-validation method is employed for one-second ECG signals and also tested on other two datasets (two-seconds and three-seconds).
                  
                     Results: Comparing to the competing approaches, the proposed CNN acquires the highest performance, having an accuracy, sensitivity, and specificity of 99.59%, 99.04%, and 99.87%, respectively, with one-second ECG signals. The overall accuracy, sensitivity, and specificity obtained are 99.80%, 99.48%, and 99.93%, respectively, using two-seconds of signals with pre-trained proposed models. The accuracy, sensitivity, and specificity of segmented ECG tested by three-seconds signals are 99.84%, 99.52%, and 99.95%, respectively.
                  
                     Conclusion: The results of this study indicate that the proposed system accomplishes high performance and keeps the characterizations in brief with flexibility at the same time, which means that it has the potential for implementation in a practical, real-time medical environment.",health
10.1016/j.cmpb.2021.106034,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-05-01,sciencedirect,Effective epileptic seizure detection by using level-crossing EEG sampling sub-bands statistical features selection and machine learning for mobile healthcare,https://api.elsevier.com/content/abstract/scopus_id/85102625993,"Mobile healthcare is an emerging approach which can be realized by using cloud-connected biomedical implants. In this context, a level-crossing sampling and adaptive-rate processing based innovative method is suggested for an effective and automated epileptic seizures diagnosis. The suggested solution can achieve a significant real-time compression in computational complexity and transmission activity reduction. The proposed method acquires the electroencephalogram (EEG) signal by using the level-crossing analog-to-digital converter (LCADC) and selects its active segments by using the activity selection algorithm (ASA). This effectively pilots the post adaptive-rate modules such as denoising, wavelet based sub-bands decomposition, and dimension reduction. The University of Bonn and Hauz Khas epilepsy-detection databases are used to evaluate the proposed approach. Experiments show that the proposed system achieves a 4.1-fold and 3.7-fold decline, respectively, for University of Bonn and Hauz Khas datasets, in the number of samples obtained as opposed to traditional counterparts. This results in a reduction of the computational complexity of the proposed adaptive-rate processing approach by more than 14-fold. It promises a noticeable reduction in transmitter power, the use of bandwidth, and cloud-based classifier computational load. The overall accuracy of the method is also quantified in terms of the epilepsy classification performance. The proposed system achieves100% classification accuracy for most of the studied cases.",health
10.1016/j.bspc.2021.102538,Journal,Biomedical Signal Processing and Control,scopus,2021-05-01,sciencedirect,A novel multiscale convolutional neural network based age-related macular degeneration detection using OCT images,https://api.elsevier.com/content/abstract/scopus_id/85102353470,"Age-related macular degeneration (AMD) is an ocular disorder that affects the elderly. The prevalence of AMD is growing due to the aging population in society; hence early diagnosis is necessary to prevent vision loss in the elderly. Arranging a detailed eye screening system for detecting AMD is a very challenging process. This paper proposes a novel multiscale convolutional neural network (CNN) architecture for accurate diagnosis of AMD. The architecture proposed is a multiscale CNN with seven convolutional layers for classifying AMD or normal images. The multiscale convolution layer enables a large number of local structures to be generated with various filter sizes. In this proposed network, the sigmoid function is used as the classifier. The proposed CNN network is trained on the Mendeley dataset and tested on four datasets, namely Mendeley, OCTID, Duke, SD-OCT Noor dataset and achieved an accuracy of 99.73%, 98.08%, 96.66%, and 97.95% respectively. Comparison with alternative methods yielded results that exhibit the efficiency of the proposed algorithm in AMD detection. Even if the proposed model is trained only on the Mendeley dataset, it achieved good detection accuracy when tested with other datasets. This indicates the proposed model's ability to classify AMD/Normal images from other datasets. Comparison with other approaches produced results that exhibit the efficiency of the proposed algorithm in detecting AMD. The proposed architecture can be applied in rapid screening of the eye for the early detection of AMD. Due to less complexity and fewer learnable parameters, the proposed CNN can be implemented in real-time.",health
10.1016/j.compeleceng.2021.107036,Journal,Computers and Electrical Engineering,scopus,2021-05-01,sciencedirect,Screening of Glaucoma disease from retinal vessel images using semantic segmentation,https://api.elsevier.com/content/abstract/scopus_id/85101383196,"A timely diagnosis of Glaucoma has crucial importance in preventing blindness. As this disease exists in the immediate vicinity of the optical disk (OD), its precise localization and segmentation are critical in its accurate diagnosis. OD consists of two parts, namely: neuroretinal and optic cup (OC). In the proposed work, the problem of OD and OC segmentation is modeled as a semantic pixel-wise labeling problem, thus bridging the gap between medical image segmentation and semantic segmentation. The proposed method eliminates the need for pre- and post-processing steps. The proposed method is evaluated for the segmentation of OD and OC on Drishti and Rim-one datasets. The offered low computational and resource requirements along with the observed state-of-the-art accuracy of the proposed method support its implementation in the real-time automatic screening of the Glaucoma disease.",health
10.1016/j.jisa.2021.102748,Journal,Journal of Information Security and Applications,scopus,2021-05-01,sciencedirect,Agent architecture of an intelligent medical system based on federated learning and blockchain technology,https://api.elsevier.com/content/abstract/scopus_id/85100236256,"Multi-agent systems enable the division of complicated tasks into individual objects that can cooperate. Such architecture can be useful in building solutions in the Internet of Medical Things (IoMT). In this paper, we propose an architecture of such a system that ensures the security of private data, as well as allows the addition and/or modification of the used classification methods. The main advantages of the proposed system are based on the implementation of blockchain technology elements and threaded federated learning. The individual elements are located on the agents who exchange information. Additionally, we propose building an agent with a consortium mechanism for classification results from many machine learning solutions. This proposal offers a new model of agents that can be implemented as a system for processing medical data in real-time. Our proposition was described and tested to present advantages over other, existing state-of-the-art methods. We show, that this proposition can improve the Internet of Medical Thing solutions by presenting a new idea of a multi-agent system that can separate different tasks like security, or classification and as a result minimize operation time and increase accuracy.",health
10.1016/j.future.2020.11.007,Journal,Future Generation Computer Systems,scopus,2021-05-01,sciencedirect,Learning hierarchical face representation to enhance HCI among medical robots,https://api.elsevier.com/content/abstract/scopus_id/85100215322,"In this paper, we propose a hierarchical framework for face recognition by learning deep representation. In order to exploit key patches for face recognition, we separate the entire image into several patches including eyes, nose, and mouth. A binary facegrid is generated to indicate the accurate position of the key patches in face image. The patches are fed into the hierarchical framework to learn the deep representation of the image. We leverage the PCA and SVM method for face recognition. Our face representation can enhance many medical robot applications. Comprehensive experiments have demonstrated that our proposed method can effectively recognize real human faces from fake samples.",health
10.1016/j.image.2021.116198,Journal,Signal Processing: Image Communication,scopus,2021-05-01,sciencedirect,Predicting ASD diagnosis in children with synthetic and image-based eye gaze data,https://api.elsevier.com/content/abstract/scopus_id/85099252040,"As early intervention is highly effective for young children with autism spectrum disorder (ASD), it is imperative to make accurate diagnosis as early as possible. ASD has often been associated with atypical visual attention and eye gaze data can be collected at a very early age. An automatic screening tool based on eye gaze data that could identify ASD risk offers the opportunity for intervention before the full set of symptoms is present. In this paper, we propose two machine learning methods, synthetic saccade approach and image based approach, to automatically classify ASD given children’s eye gaze data collected from free-viewing tasks of natural images. The first approach uses a generative model of synthetic saccade patterns to represent the baseline scan-path from a typical non-ASD individual and combines it with the real scan-path as well as other auxiliary data as inputs to a deep learning classifier. The second approach adopts a more holistic image-based approach by feeding the input image and a sequence of fixation maps into a convolutional or recurrent neural network. Using a publicly-accessible collection of children’s gaze data, our experiments indicate that the ASD prediction accuracy reaches 67.23% accuracy on the validation dataset and 62.13% accuracy on the test dataset.",health
10.1016/j.eswa.2020.114379,Journal,Expert Systems with Applications,scopus,2021-05-01,sciencedirect,DGTL-Net: A Deep Generative Transfer Learning Network for Fault Diagnostics on New Hard Disks,https://api.elsevier.com/content/abstract/scopus_id/85098696865,"Intelligent fault diagnosis of hard disks becomes significantly important to guarantee reliability of current cloud-based industrial systems. Most intelligent diagnostic methods are commonly based on assumptions that data from different disks are subject to the same distribution and there are sufficient faulty samples for training the models. However, in reality, there are types of hard disks from different manufacturers and their SMART encoding varies widely across manufacturers. It results in distribution discrepancy among disks and influences the generalization of machine learning methods. Moreover, hard disks usually work in healthy state that faulty events rarely happen on most of them, or especially never occur on new ones. Thus, this paper proposes a deep generative transfer learning network (DGTL-Net) for intelligent fault diagnostics on new hard disks. The DGTL-Net combines the deep generative network that generates fake faulty samples and the deep transfer network that solves the problem of distribution discrepancy between hard disks. An iterative end-end training strategy is also proposed for DGTL-Net to get the most optimal parameters of generative and transfer network simultaneously. Experiments have been conducted to prove that our method achieves better performance.",health
10.1016/j.preteyeres.2020.100900,Journal,Progress in Retinal and Eye Research,scopus,2021-05-01,sciencedirect,"Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective",https://api.elsevier.com/content/abstract/scopus_id/85093916279,"The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a “new normal”, the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.",health
10.1016/j.bbr.2021.113156,Journal,Behavioural Brain Research,scopus,2021-04-23,sciencedirect,Maternal antibiotic administration during a critical developmental window has enduring neurobehavioural effects in offspring mice,https://api.elsevier.com/content/abstract/scopus_id/85101391612,"Rates of perinatal maternal antibiotic use have increased in recent years linked to prophylactic antibiotic use following Caesarean section delivery. This antibiotic use is necessary and beneficial in the short-term; however, long-term consequences on brain and behaviour have not been studied in detail. Here, we endeavoured to determine whether maternal administration of antibiotics during a critical window of development in early life has lasting effects on brain and behaviour in offspring mice. To this end we studied two different antibiotic preparations (single administration of Phenoxymethylpenicillin at 31 mg/kg/day; and a cocktail consisting of, ampicillin 1 mg/mL; vancomycin 0.5 mg/mL; metronidazole 1 mg/mL; ciprofloxacin 0.2 mg/mL and imipenem 0.25 mg/mL). It was observed that early life exposure to maternal antibiotics led to persistent alterations in anxiety, sociability and cognitive behaviours. These effects in general were greater in animals treated with the broad-spectrum antibiotic cocktail compared to a single antibiotic with the exception of deficits in social recognition which were more robustly observed in Penicillin V exposed animals. Given the prevalence of maternal antibiotic use, our findings have potentially significant translational relevance, particularly considering the implications on infant health during this critical period and into later life.",health
10.1016/j.jclepro.2021.125814,Journal,Journal of Cleaner Production,scopus,2021-04-20,sciencedirect,Online accurate state of health estimation for battery systems on real-world electric vehicles with variable driving conditions considered,https://api.elsevier.com/content/abstract/scopus_id/85101808443,"The environmental sustainability stimulates the development of electric vehicles with great energy-saving and emission reduction effects. State of health of the battery system in an electric vehicle is crucial to the safety of vehicle operation, charging station, and the environment. The existing techniques implemented in well-controlled experimental environments fail to learn unpredictable drivers’ driving behaviors and complex road/weather conditions during actual vehicular operation. This paper investigates a novel deep-learning-enabled method to perform accurate state of health estimation for battery systems on real-world electric vehicles. Eight potential evaluation schemes depending on the stable charging stages are recapped and discussed. By fitting the correlation between battery degeneration factors and various vehicle operation parameters such as ambient temperature and mileage, an approximate battery degeneration model oriented for the real application scenarios is obtained. The variable-length-input long short-term memory network is used to learn the variable battery degeneration factors acquired from different driving stages of a yearlong dataset. The test results show that the proposed method has a better performance than other estimation methods. More significantly, based on the acquisition advantages of big-data platforms, it can be used to full-state and full-climate vehicle applications unrestricted by complex actual environments.",health
10.1016/j.eswa.2020.114237,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,Monitoring linear profiles using Artificial Neural Networks with run rules,https://api.elsevier.com/content/abstract/scopus_id/85098181038,"In some applications, a relation between a response variable and one or more explanatory variables (referred as a “profile”) characterizes the quality of a process. Profile monitoring is commonly performed through statistical methods, while machine learning schemes have not received much attention in this regard. In this paper, a control chart based on Artificial Neural Networks (ANN) is proposed to monitor linear profiles in phase II. In the proposed control chart, some novel run rules as the major contribution of this paper are also used to enhance the efficiency of the control chart and for faster detection of shifts. Simulation results revealed a good performance of the proposed control chart based on average run length (ARL) criterion. Further, a systematic ANN-based diagnostic procedure was proposed to identify which parameter has changed in the process. Finally, the implementation of the proposed scheme was illustrated through a real calibration example from the field of chemical engineering.",health
10.1016/j.eswa.2020.114218,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,Breast calcification detection based on multichannel radiofrequency signals via a unified deep learning framework,https://api.elsevier.com/content/abstract/scopus_id/85096864735,"Breast calcifications in radiographic images suggest a high likelihood of breast lesion malignancy. However, it is difficult to detect calcifications in traditional B-mode ultrasound images due to resolution limits and speckle noise. In this paper, we propose a unified deep learning framework for automatic calcification detection based on multichannel ultrasound radio frequency (RF) signals. First, beamforming is used during preprocessing to merge and blend multichannel signals into one-channel RF signals. Each scan line is converted into a spectrogram by the short-time Fourier transform (STFT) to utilize the frequency domain characteristics. Then, an improved fully convolutional neural network called the RF signal Spectrogram-Calcification-Detection-Net (SCD-Net) is proposed to detect calcifications from spectrograms. This method employs a deep learning architecture based on YOLOv3 and combines features via convolutional long short-term memory (ConvLSTM). Next, a Kalman filter for tracking calcifications between consecutive spectrograms based on SCD-Net detection results is applied since the spatial coherence of calcifications in neighboring frames can be taken into account. Finally, the detected calcification is mapped from the time domain of spectrograms to B-mode images for clinical diagnosis. Experiments were conducted on a database of 337 experienced doctor-marked breast tumors with calcifications. Compared to the state-of-the-art methods for detecting calcifications, the proposed method achieved an average precision (AP) of 88.25%, an accuracy of 84% and an F1 score of 91%. The experimental results demonstrate that the unified framework has great performance for tumor calcification detection. The system can be effectively applied in a portable ultrasound instrument to accurately help radiologists and provide guidance for breast tumor diagnosis. This implies that the proposed approach can be implemented in real practice for analyzing breast RF signals, which have many useful medical applications in clinical breast tumor diagnosis.",health
10.1016/j.jep.2020.113768,Journal,Journal of Ethnopharmacology,scopus,2021-04-06,sciencedirect,Astragalus membranaceus and Salvia miltiorrhiza ameliorates cyclosporin A-induced chronic nephrotoxicity through the “gut-kidney axis”,https://api.elsevier.com/content/abstract/scopus_id/85098796907,"Ethnopharmacological relevance
                  The combination of Astragalus membranaceus and Salvia miltiorrhiza (AS) is an effective prescription that is widely used to treat chronic kidney disease (CKD) clinically in traditional Chinese medicine. Our previous studies have shown that AS can alleviate early CKD through the “gut-kidney axis”, but the regulatory role of AS in the “gut-kidney axis” in the middle and late stages of CKD caused by cyclosporin A-induced chronic nephrotoxicity (CICN) has remained unclear.
               
                  Aim of the study
                  To explore the protective effect of AS by regulating the intestinal flora to further control the miRNA-mRNA interaction profiles in CICN.
               
                  Materials and methods
                  Thirty-two mice were divided into four groups: Normal (N) (olive oil), Model (M) (CsA, 30 mg kg−1 d−1), AS (CsA + AS, 30 + 8.4 g kg−1 d−1) and FMT-AS (CsA + Faeces of AS group, 30 mg + 10 mL kg−1 d−1). The mice were treated for 6 weeks. Changes in renal function related metabolites were detected, pathological changes in the colon and kidney were observed, and 16S rDNA sequencing was performed on mouse faeces. In addition, miRNA and mRNA sequencing were performed on the kidney to construct differential expression (DE) profiles of the other 3 groups compared with group M. The target mRNAs among the DE miRNAs were then predicted, and an integrated analysis was performed with the DE mRNAs to annotate gene function by KEGG. DE miRNAs and DE mRNAs related to CICN in the overlapping top 20 KEGG pathways were screened and verified.
               
                  Results
                  Eight metabolites that could worsen renal function were increased in group M, accompanied by thickening of the glomerular basement membrane, vacuolar degeneration of renal tubules, and proliferation of collagen fibres, while AS and FMT-AS intervention amended these changes to varying degrees. Simultaneously, intestinal permeability increased, the abundance and diversity of the flora decreased, and the ratio of Firmicum to Bacteroides (F/B) increased in group M. The AS and FMT-AS treatments reversed the flora disorder and increased probiotics producing butyric acid and lactic acid, especially Akkermansia and Lactobacillus, which might regulate the 12 overlapping top 20 KEGG pathways, such as Butanoate metabolism, Tryptophan metabolism and several RF-related pathways, leading to the remission of renal metabolism. Finally, 15 DE miRNAs and 45 DE mRNAs were screened as the therapeutic targets, and the results coincided with the sequencing results.
               
                  Conclusion
                  AS could alleviate renal fibrosis and metabolism caused by CICN through the “gut-kidney axis”. Probiotics such as Akkermansia and Lactobacillus were the primary driving factors, and the miRNA-mRNA interaction profiles, especially Butanoate metabolism and Tryptophan metabolism, may be an important subsequent response and regulatory mechanism.",health
10.1016/j.jep.2020.113669,Journal,Journal of Ethnopharmacology,scopus,2021-04-06,sciencedirect,Tiao Geng decoction inhibits tributyltin chloride-induced GT1-7 neuronal apoptosis through ASK1/MKK7/JNK signaling pathway,https://api.elsevier.com/content/abstract/scopus_id/85098773002,"Ethnopharmacological relevance
                  Tiao Geng (TG) decoction is a Chinese herbal medicine extract that has been utilized for the treatment of menopausal symptoms for a history of over 30 years. In our previous study, we suggest that TG decoction possibly exerts an anti-apoptotic effect on hypothalamic neurons of ovariectomized rats via the ASK1/MKK7/JNK pathway. Tributyltin chloride (TBTC) causes oxidative damage and induces apoptosis of primary hypothalamic neurons in rats.
               
                  Aim of the study
                  The present work aimed to explore the inhibition of TG decoction on TBTC-induced GT1-7 cell apoptosis and its possible molecular mechanism.
               
                  Materials and methods
                  The GT1-7 cell line was exposed to TG decoction at diverse doses (31.25, 62.5, 125 μg/mL) for 24 h and later with TBTC (1 mg/L) for 1 h, with 17β-E2 (100 nM) treatment being the positive control. Then, CCK8 assay was conducted to evaluate cell viability, while flow cytometric analysis was conducted to examine the apoptosis level. Related pathways and differentially expressed proteins were identified by tandem mass tag (TMT)-based quantitative phosphoproteomics. qRT-PCR was carried out to examine mRNA levels of Bax and B-cell lymphoma-2 (Bcl-2). Western blotting was performed to detect the levels of Bax, Bcl-2, c-Jun, c-Jun N-terminal kinase (JNK), Caspase-3 (Casp3), Mitogen-activated protein kinase kinase 7 (MKK7), and apoptosis signal-regulating kinase 1 (ASK1) .
                  Finally, cells were pretreated with SP600125, an inhibitor of JNK, later the expression of JNK and Casp3 was measured.
               
                  Results
                  Application of TG decoction mitigated the GT1-7 cell apoptosis and injury caused by TBTC; besides, it inhibited the activation of the ASK1/MKK7/JNK pathway. Moreover, Bcl-2/Bax ratio became higher, and the MKK7, ASK1, Casp3 and c-Jun levels were inhibited. Besides, TG decoction combined with SP600125 (the JNK inhibitor) more significantly inhibited GT1-7 cell apoptosis caused by TBTC.
               
                  Conclusion
                  As discovered from the experiment in this study, TG decoction has a neuroprotective effect, which is achieved through inhibiting the ASK1/MKK7/JNK signal transduction pathway to reduce GT1-7 cell apoptosis.",health
10.1016/j.smhl.2021.100191,Journal,Smart Health,scopus,2021-04-01,sciencedirect,Inferring food types through sensing and characterizing mastication dynamics,https://api.elsevier.com/content/abstract/scopus_id/85107633513,"Unhealthy dietary structure leads to the prevalence of some chronic diseases, such as obesity, diabetes, and heart disease. Automatic food type recognition helps nutritionists and medical professionals understand patients’ nutritional contents, provide accurate and personalized treatments, and evaluate therapeutic effects. Existing wearable sensor-based methods take advantage of microphone, electromyography (EMG), and piezoelectric sensors embedded in the wearable devices. However, these sensors are either easily impacted by ambient acoustic noise or intrusive and uncomfortable to wear. We observe that each type of food has its own intrinsic properties, such as hardness, elasticity, fracturability, adhesiveness, and size. Different food properties result in different mastication dynamics. In this paper, we present the first effort in using wearable motion sensors to sense mastication dynamics and infer food types accordingly. We specifically define six mastication dynamics parameters to represent these food properties. They are chewing speed, the number of chews, chewing time, chewing force, chewing cycle duration and skull vibration. We embed motion sensors in a headband and deploy the sensors on the temporalis muscles to sense mastication dynamics accurately and less intrusively. In addition, we extract 65 hand-crafted features from each chewing sequence to explicitly characterize the mastication dynamics using motion sensor data. A real-world evaluation dataset of 11 food categories (20 types of food in total) is collected from 15 human subjects. The average recognition accuracy of these 15 human subjects is 82.3%. The accuracy of a single human subject is up to 93.3%.",health
10.1016/j.jmsy.2021.02.012,Journal,Journal of Manufacturing Systems,scopus,2021-04-01,sciencedirect,Robust diagnosis with high protection to gas turbine failures identification based on a fuzzy neuro inference monitoring approach,https://api.elsevier.com/content/abstract/scopus_id/85101807612,"Modern industry requires the development of new monitoring and diagnostic procedures, which enable the detection, localization, and isolation of faults. For sustainable solutions in terms of operational safety and availability, while bringing out zero accidents, zero downtime, and zero faults, for a trend acting on environmental issues. Towards this development, this work proposes solutions for the monitoring of gas turbines and their real-time implementation, in order to approximate and predict the degradation of the components of this system, by an approach of faults detection and isolation, based on an adaptive neural-fuzzy inference system. This will develop a reliable approach to maintain and monitor gas turbines, in case of failure or accident to prevent in real-time and makes it possible to achieve high power with efficiency and small footprint with High performance by operating this rotating machine. However, the application of the Adaptive Neuro-Fuzzy Inference System Observer-Based Approach, makes it possible to increase the life of the examined turbine and keep better reliability for their monitoring system and satisfy the techno-economic and environmental performance impacts. For the purpose of controlling failures and the occurrence of turbine system malfunctions, and avoiding their consequences on the safety and productivity of the installation.",health
10.1016/j.cmpb.2021.106019,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-04-01,sciencedirect,Mass Image Synthesis in Mammogram with Contextual Information Based on GANs,https://api.elsevier.com/content/abstract/scopus_id/85101397555,"Background and Objective: In medical imaging, the scarcity of labeled lesion data has hindered the application of many deep learning algorithms. To overcome this problem, the simulation of diverse lesions in medical images is proposed. However, synthesizing labeled mass images in mammograms is still challenging due to the lack of consistent patterns in shape, margin, and contextual information. Therefore, we aim to generate various labeled medical images based on contextual information in mammograms.
                  
                     Methods:In this paper, we propose a novel approach based on GANs to generate various mass images and then perform contextual infilling by inserting the synthetic lesions into healthy screening mammograms. Through incorporating features of both realistic mass images and corresponding masks into the adversarial learning scheme, the generator can not only learn the distribution of the real mass images but also capture the matching shape, margin and context information.
                  
                     Results:To demonstrate the effectiveness of our proposed method, we conduct experiments on publicly available mammogram database of DDSM and a private database provided by Nanfang Hospital in China. Qualitative and quantitative evaluations validate the effectiveness of our approach. Additionally, through the data augmentation by image generation of the proposed method, an improvement of 5.03% in detection rate can be achieved over the same model trained on original real lesion images.
                  
                     Conclusions:The results show that the data augmentation based on our method increases the diversity of dataset. Our method can be viewed as one of the first steps toward generating labeled breast mass images for precise detection and can be extended in other medical imaging domains to solve similar problems.",health
10.1016/j.jchemneu.2021.101924,Journal,Journal of Chemical Neuroanatomy,scopus,2021-04-01,sciencedirect,Therapeutics effects of [Pyr1] apelin-13 on rat contusion model of spinal cord injury: An experimental study,https://api.elsevier.com/content/abstract/scopus_id/85101359279,"Spinal cord injury (SCI) can cause various symptoms, including pain, complete or incomplete loss of autonomic, sensory, motor and functions inferior to the site of the damage. Despite wondrous advances in medicine, treating spinal cord injuries remains a thorny issue yet. Recently, the control of inflammatory processes after damage to the nervous system has been noticed as a promising therapeutic target. The goal of the present experiment was to identify the effects of apelin-13 on the histological outcome, inflammatory factors, and functional recovery in the animal contusion model of SCI were analyzed. 40 Female Wistar rats were randomly but equally assigned in laminectomy, contusion, PBS (1 mL PBS, i.p), control group which received apelin-13 (control + apelin, 100 μg/kg, i.p), and apelin-13 treatment groups. In the treatment group, apelin-13 (100 μg/kg) was injected intraperitoneally 30 min after injury. The weight-dropping contusion model was used for inducing SCI. The Basso, Beattie, and Bresnahan scale (BBB), narrow beam test (NBT), rotarod test, and the open-field test was applied to evaluate locomotor and behavioral activity. Real-time polymerase chain reaction (PCR) and ELISA technique was accomplished eight weeks after inducing SCI to measure the level of fibroblast growth factor FGF-1, FGFR1 and the inflammatory factors including interleukin (IL)-1β, tumor necrosis factor-α (TNF-α), IL-6, and IL-10. Furthermore, histological change was estimated by H&E staining. Our results showed that apelin-13 treatment after SCI led to a significant increase in functional recovery and behavioral tests. Stereological estimation illustrated that apelin-13 could reduce significantly central cavity volume and number of glial cells, and also increase significantly spinal cord volume and number of neural cells. PCR and ELISA evaluation shows a significant increase in IL-10 level and decrease in levels of FGF-1, FGF-R1, and pro-inflammatory cytokines (PIC). This study suggested that apelin-13 has neuroprotective effects by regulating the inflammatory process after SCI.",health
10.1016/j.cmpb.2021.105971,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-04-01,sciencedirect,Dynamically learned PSO based neighborhood influenced fuzzy c-means for pre-treatment and post-treatment organ segmentation from CT images,https://api.elsevier.com/content/abstract/scopus_id/85101288768,"Background and Objective
                  The accurate segmentation of pre-treatment and post-treatment organs is always perceived as a challenging task in medical image analysis field. Especially, in those situations where the amount of data set is limited, the researchers are compelled to design unsupervised model for segmentation. In this paper, we propose a novel dynamically learned particle swarm optimization based neighborhood influenced fuzzy c-means (DLPSO-NIFCM) clustering (unsupervised learning model) for solving pre-treatment and post-treatment organs segmentation problems. The proposed segmentation technique has been successfully applied to segment the liver parts from the Computed Tomography (CT) images of abdomen and also the lung parenchyma from the lungs CT images.
               
                  Methodology
                  In the proposed method, we formulate a primary convex objective function by considering the membership value of a pixel as well as the membership of its other neighboring pixels. Then we apply a new algebraic transformation on the primary objective function to design a new and more suitable objective function without losing convexity of the primary objective function. This new objective function is compatible for hybridization with any heuristic search technique in true sense. In this work, we propose a dynamically learned PSO to obtain the initial cluster centroids from the final objective function. Finally, we use a graph-based isolation mechanism for refining the segmentation results.
               
                  Results and Conclusion
                  This hybrid method, along with the restructured single variable objective function of the distance, leads to accurate clustering results with relatively lesser converging time as compared to the state-of-the-art methods. The segmentation results, obtained through several experiments with real CT images, are encouraging. The numerical values of different performance metrics obtained over the same data set confirm that the proposed algorithm performs better with respect to the state-of-the-art methods. Hence, we may consider the proposed method as a promising tool for clustering and CT image segmentation in a Computer Aided Diagnostic (CAD) system.",health
10.1016/j.jnca.2021.102995,Journal,Journal of Network and Computer Applications,scopus,2021-04-01,sciencedirect,Dew computing-inspired health-meteorological factor analysis for early prediction of bronchial asthma,https://api.elsevier.com/content/abstract/scopus_id/85100605135,"Bronchial asthma is one of the most common chronic diseases of childhood and considered as a major health problem globally. The irregularity in meteorological factors has become a primary cause of health severity for the individuals suffering from asthma. In the presented research, a dew-cloud assisted cyber-physical system (CPS) is proposed to analyze the correlation between the meteorological and health parameters of the individuals. The work is primarily focused on determining the health adversity caused by the irregular scale of meteorological factors in real-time. IoT-assisted smart sensors are utilized to capture ubiquitous information from indoor environment that make a vital impact on the health of the individual directly or indirectly. The data is analyzed over the cyber-space to quantify the probable irregular health events by utilizing the data classification efficiency of Weighted-Naïve Bayes modeling technique. Moreover, the relationship between meteorological and health parameters is estimated by utilizing the Adaptive Neuro-Fuzzy Inference System (ANFIS) and calculate a unifying factor over the temporal scale. To validate the monitoring performance, the proposed model is implemented in the four schools of Jalandhar, India. The experimental evaluation of the proposed model acknowledges the performance efficiency through several statistical approaches. Furthermore, the comparative analysis is evaluated with state-of-the-art decision-making algorithms that demonstrate the effectiveness of the proposed solution for the targeted application.",health
10.1016/j.bspc.2021.102428,Journal,Biomedical Signal Processing and Control,scopus,2021-04-01,sciencedirect,Unlabeled skin lesion classification by self-supervised topology clustering network,https://api.elsevier.com/content/abstract/scopus_id/85100441216,"As one of the most widespread cancer, skin cancer can be initially diagnosed by visual observation, following up with a series clinical check by dermoscopic analysis, histopathological assessment, and a biopsy. The initial visual observation provides the possibility of using artificial intelligence, which is confronted with various challenges on account of the discrepancy between different skin images. Though some deep learning methods have achieved improvements on this task, they needs a large mount of skin images annotated by well-trained professional doctors, which is very expensive to label so much data in reality. Furthermore, they maybe deteriorated into a new category with an unseen disease symptom, and existing skin lesion classification methods can not solve this problem. Here, this paper proposes a Self-supervised Topology Clustering Network (STCN) by a transformation-invariant network with self-supervised maximum modularity clustering algorithm following topology analysis principle. This approach can automatically classify unlabeled medical images without prior class number, and we implement sufficient validating experiments to certify that our STCN model can effectively solve the unlabeled medical image classification task.",health
10.1016/j.jpowsour.2021.229561,Journal,Journal of Power Sources,scopus,2021-04-01,sciencedirect,Data-driven fault diagnosis method for the safe and stable operation of solid oxide fuel cells system,https://api.elsevier.com/content/abstract/scopus_id/85100426597,"Solid oxide fuel cell system is complex with multiple variables strongly coupled. Once a fault occurs, if it cannot be found in time, the initial minor fault may slowly evolve and spread to subsequent components. Therefore, fault diagnosis is a promising approach to guarantee the stability of the system. In this paper, the impact of air leakage and fuel starvation is investigated. To diagnose the two types of faults, a novel data-driven online fault diagnosis method based on principal component analysis and support vector machine is developed. Data comes from the entire stage of the solid oxide fuel cell system experiment. The results show that the proposed method can effectively identify the air leakage and fuel starvation fault in real time. Through comparison with traditional machine learning methods, this method shows higher accuracy and better generalization performance. Moreover, it combines prior knowledge and statistical characteristics to extract effective features, thereby reducing the calculation burden. Furthermore, with proper modifications, the proposed method can be extended to other types of solid oxide fuel cell system faults, which is significant in enhancing the reliability of the system.",health
10.1016/j.aca.2021.338254,Journal,Analytica Chimica Acta,scopus,2021-04-01,sciencedirect,Detection of Plasmodium falciparum malaria in 1 h using a simplified enzyme-linked immunosorbent assay,https://api.elsevier.com/content/abstract/scopus_id/85100400846,"Malaria is a parasitic disease caused by protists of the genus Plasmodium, which are transmitted to humans through the bite of infected female Anopheles mosquitoes. Analytical methodologies and efficient drugs exist for the early detection and treatment of malaria, and yet this disease continues infecting millions of people and claiming several hundred thousand lives each year. One of the reasons behind this failure to control the disease is that the standard method for malaria diagnosis, microscopy, is time-consuming and requires trained personnel. Alternatively, rapid diagnostic tests, which have become common for point-of-care testing thanks to their simplicity of use, tend to be insufficiently sensitive and reliable, and PCR, which is sensitive, is too complex and expensive for massive population screening.
                  In this work, we report a sensitive simplified ELISA for the quantitation of Plasmodium falciparum lactate dehydrogenase (Pf-LDH), which is capable of detecting malaria in 45–60 min. Assay development was founded in the selection of high-performance antibodies, implementation of a poly-horseradish peroxidase (polyHRP) signal amplifier, and optimization of whole-blood sample pre-treatment. The simplified ELISA achieved limits of detection (LOD) and quantification (LOQ) of 0.11 ng mL−1 and 0.37 ng mL−1, respectively, in lysed whole blood, and an LOD comparable to that of PCR in Plasmodium in vitro cultures (0.67 and 1.33 parasites μL−1 for ELISA and PCR, respectively). Accordingly, the developed immunoassay represents a simple and effective diagnostic tool for P. falciparum malaria, with a time-to-result of <60 min and sensitivity similar to the reference PCR, but easier to implement in low-resource settings.",health
10.1016/j.autcon.2021.103603,Journal,Automation in Construction,scopus,2021-04-01,sciencedirect,A field parameters-based method for real-time wear estimation of disc cutter on TBM cutterhead,https://api.elsevier.com/content/abstract/scopus_id/85100241917,"In hard rock TBM tunneling, the loss caused by disc cutter wear accounts for a large proportion of time and cost for the entire project. However, existing disc cutter wear prediction models mainly focus on predicting cutter consumption before construction and cannot predict the wear of each disc cutter. Moreover, the accurate rock parameters required in these models are challenging to obtain. Hence, these models are not capable of determining which cutter on cutterhead should be replaced during construction. To solve the problems mentioned above, this paper presents a novel field parameters-based method for estimating the wear of each disc cutter in real-time. The proposed method is implemented through the following steps. To begin with, a new health index is constructed and defined as the ratio of the rolling distance of a cutter in a small excavated section to its maximum rolling distance. Then, specific field parameters related to the new health index are analyzed and selected. Thereafter, the mapping model between the new health index and the specific field parameters is established based on a one-dimensional convolutional neural network. Finally, on the basis of the established model, the estimated health indices corresponding to all excavated sections of a disc cutter are accumulated to obtain its health status. The field data obtained from Mumbai metro tunnel was utilized to verify the effectiveness of the proposed method, which demonstrates that the proposed method can estimate the wear of each disc cutter in real-time with average accuracy as high as 87.8% on the test set. Therefore, the proposed method is capable of significantly reducing the time and cost of cutter inspection, replacement, and repair for TBM, thereby improve tunneling efficiency and reduce construction cost.",health
10.1016/j.patrec.2021.01.010,Journal,Pattern Recognition Letters,scopus,2021-04-01,sciencedirect,Deep learning for real-time semantic segmentation: Application in ultrasound imaging,https://api.elsevier.com/content/abstract/scopus_id/85100000089,"A real-time architecture of medical image semantic segmentation called Fully Convolution dense Dilated Network, is proposed to improve the segmentation efficiency while ensuring high accuracy. Considering low resolution and contrast, interferences of shadows, as well as differences in nodules’ position and size, accurate ultrasound images’ segmentation cannot be obtained easily. Therefore, a novel layer that integrates the advantages of dense connectivity, dilated convolutions and factorized filters, is proposed in an attempt to remain efficient while retaining remarkable accuracy. Dense connectivity combines low-level fine segmentation with high-level coarse segmentation to extract more features from ultrasound images. Dilated convolution can expand the receptive field of the filter, and the problem of differences in nodules’ size and position can be solved with different sizes of filters. This study also introduces factorized filters into the network to further optimize the efficiency of the model. In addition, aiming at the class imbalance problem in medical image semantic segmentation, a loss function optimization method is proposed which further improves the accuracy of the network. A thorough set of experiments based on thyroid dataset show that the proposed model achieves state-of-the-art performance in terms of robustness and efficiency.",health
10.1016/j.media.2020.101942,Journal,Medical Image Analysis,scopus,2021-04-01,sciencedirect,Automated interpretation of congenital heart disease from multi-view echocardiograms,https://api.elsevier.com/content/abstract/scopus_id/85098981556,"Congenital heart disease (CHD) is the most common birth defect and the leading cause of neonate death in China. Clinical diagnosis can be based on the selected 2D key-frames from five views. Limited by the availability of multi-view data, most methods have to rely on the insufficient single view analysis. This study proposes to automatically analyze the multi-view echocardiograms with a practical end-to-end framework. We collect the five-view echocardiograms video records of 1308 subjects (including normal controls, ventricular septal defect (VSD) patients and atrial septal defect (ASD) patients) with both disease labels and standard-view key-frame labels. Depthwise separable convolution-based multi-channel networks are adopted to largely reduce the network parameters. We also approach the imbalanced class problem by augmenting the positive training samples. Our 2D key-frame model can diagnose CHD or negative samples with an accuracy of 95.4%, and in negative, VSD or ASD classification with an accuracy of 92.3%. To further alleviate the work of key-frame selection in real-world implementation, we propose an adaptive soft attention scheme to directly explore the raw video data. Four kinds of neural aggregation methods are systematically investigated to fuse the information of an arbitrary number of frames in a video. Moreover, with a view detection module, the system can work without the view records. Our video-based model can diagnose with an accuracy of 93.9% (binary classification), and 92.1% (3-class classification) in a collected 2D video testing set, which does not need key-frame selection and view annotation in testing. The detailed ablation study and the interpretability analysis are provided.
                  The presented model has high diagnostic rates for VSD and ASD that can be potentially applied to the clinical practice in the future. The short-term automated machine learning process can partially replace and promote the long-term professional training of primary doctors, improving the primary diagnosis rate of CHD in China, and laying the foundation for early diagnosis and timely treatment of children with CHD.",health
10.1016/j.cpc.2020.107779,Journal,Computer Physics Communications,scopus,2021-04-01,sciencedirect,Mammography and breast tomosynthesis simulator for virtual clinical trials,https://api.elsevier.com/content/abstract/scopus_id/85098176202,"Computer modeling and simulations are increasingly being used to predict the clinical performance of x-ray imaging devices in silico, and to generate synthetic patient images for training and testing of machine learning algorithms. We present a detailed description of the computational models implemented in the open source GPU-accelerated Monte Carlo x-ray imaging simulation code MC-GPU. This code, originally developed to simulate radiography and computed tomography, has been extended to replicate a commercial full-field digital mammography and digital breast tomosynthesis (DBT) device. The code was recently used to image 3000 virtual breast models with the aim of reproducing in silico a clinical trial used in support of the regulatory approval of DBT as a replacement of mammography for breast cancer screening. The updated code implements a more realistic x-ray source model (extended 3D focal spot, tomosynthesis acquisition trajectory, tube motion blurring) and an improved detector model (direct-conversion Selenium detector with depth-of-interaction effects, fluorescence tracking, electronic noise and anti-scatter grid). The software uses a high resolution voxelized geometry model to represent the breast anatomy. To reduce the GPU memory requirements, the code stores the voxels in memory within a binary tree structure. The binary tree is an efficient compression mechanism because many voxels with the same composition are combined in common tree branches while preserving random access to the phantom composition at any location. A delta scattering ray-tracing algorithm which does not require computing ray-voxel interfaces is used to minimize memory access. Multiple software verification and validation steps intended to establish the credibility of the implemented computational models are reported. The software verification was done using a digital quality control phantom and an ideal pinhole camera. The validation was performed reproducing standard bench testing experiments used in clinical practice and comparing with experimental measurements. A sensitivity study intended to assess the robustness of the simulated results to variations in some of the input parameters was performed using an in silico clinical trial pipeline with simulated lesions and mathematical observers. We show that MC-GPU is able to simulate x-ray projections that incorporate many of the sources of variability found in clinical images, and that the simulated results are robust to some uncertainty in the input parameters. Limitations of the implemented computational models are discussed.
               
                  Program summary
                  
                     Program title: MCGPU_VICTRE
                  
                     CPC Library link to program files: 
                     https://doi.org/10.17632/k5x2bsf27m.1
                  
                  
                     Licensing provisions: CC0 1.0
                  
                     Programming language: C (with NVIDIA CUDA extensions)
                  
                     Nature of problem: The health risks associated with ionizing radiation impose a limit to the amount of clinical testing that can be done with x-ray imaging devices. In addition, radiation dose cannot be directly measured inside the body. For these reasons, a computational replica of an x-ray imaging device that simulates radiographic images of synthetic anatomical phantoms is of great value for device evaluation. The simulated radiographs and dosimetric estimates can be used for system design and optimization, task-based evaluation of image quality, machine learning software training, and in silico imaging trials.
                  
                     Solution method: Computational models of a mammography x-ray source and detector have been implemented. X-ray transport through matter is simulated using Monte Carlo methods customized for parallel execution in multiple Graphics Processing Units. The input patient anatomy is represented by voxels, which are efficiently stored in the video memory using a new binary tree structure compression mechanism.",health
10.1016/j.chb.2020.106661,Journal,Computers in Human Behavior,scopus,2021-04-01,sciencedirect,"Mobile applications aiming to facilitate immigrants’ societal integration and overall level of integration, health and mental health. Does artificial intelligence enhance outcomes?",https://api.elsevier.com/content/abstract/scopus_id/85098090687,"Using panel data on immigrant populations from European, Asian and African countries the study estimates positive associations between the number of mobile applications in use aiming to facilitate immigrants' societal integration (m-Integration) and increased level of integration (Ethnosizer), good overall health (EQ-VAS) and mental health (CESD-20). It is estimated that the patterns are gender sensitive. In addition, it is found that m-Integration applications in relation to translation and voice assistants, public services, and medical services provide the highest returns on immigrants' level of integration, health/mental health status. For instance, translation and voice assistant applications are associated with a 4% increase in integration and a 0.8% increase in good overall health. Moreover, m-Integration applications aided by artificial intelligence (AI) are associated with increased health/mental health and integration levels among immigrants. We indicate that AI by providing customized search results, peer reviewed e-learning, professional coaching on pronunciation, real-time translations, and virtual communication for finding possible explanations for health conditions might bring better quality services facilitating immigrants' needs. This is the first known study to introduce the term ‘m-Integration’, quantify associations between applications, health/mental health and integration for immigrants, and assess AI's role in enhancing the aforementioned outcomes.",health
10.1016/j.ymssp.2020.107398,Journal,Mechanical Systems and Signal Processing,scopus,2021-04-01,sciencedirect,1D convolutional neural networks and applications: A survey,https://api.elsevier.com/content/abstract/scopus_id/85095978325,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.",health
10.1016/j.jep.2020.113654,Journal,Journal of Ethnopharmacology,scopus,2021-03-25,sciencedirect,Antidiabetic effect of a flavonoid-rich extract from Sophora alopecuroides L. in HFD- and STZ- induced diabetic mice through PKC/GLUT4 pathway and regulating PPARα and PPARγ expression,https://api.elsevier.com/content/abstract/scopus_id/85097798210,"Headings ethnopharmacological relevance
                  
                     Sophora alopecuroides L. is a traditional ethnopharmacological plant, which is widely used in traditional Chinese medicine and Mongolian and Uighur medicine to ameliorate “thirst disease”.
               
                  Aim of the study
                  This study aimed to investigate the antidiabetic activities and mechanisms of a flavonoid-rich extract from Sophora alopecuroides L. (SA-FRE) both in vivo and vitro.
               
                  Materials and methods
                  The main six chemical constituents of SA-FRE were elucidated based on an off-line semi-preparative liquid chromatography nuclear magnetic resonance (LC-NMR) protocol. Myc-GLUT4-mOrange-L6 cell models and mouse model with diabetes induced by high-fat diet combined with STZ injection were respectively adopted to investigate the antidiabetic effects of SA-FRE both in vitro and vivo.
                  
               
                  Results
                  
                     In vivo, 4-week treatment of SA-FRE ameliorated hyperglycemia, dyslipidemia, and insulin resistance in diabetic mice. Mechanically, SA-FRE regulated PPARα and PPARγ expression in white adipose tissue (WAT) and liver, thereby ameliorating dyslipidemia. Moreover, SA-FRE increased the phosphorylation of PKC and further stimulated the GLUT4 expression in WAT and skeletal muscle, thus increasing the glucose utilization in vivo. In vitro, 50 μg/mL SA-FRE increased GLUT4 translocation to about 1.91-fold and glucose uptake to 1.82-fold in L6-myotubes. SA-FRE treatment increased the GLUT4 expression at both gene and protein levels. Furthermore, only Gö6983, a PKC inhibitor, reversed the SA-FRE-induced GLUT4 translocation and expression at the gene and protein levels.
               
                  Conclusions
                  Generally, SA-FRE ameliorated hyperglycemia, dyslipidemia, and insulin resistance partly through activating PKC/GLUT4 pathway and regulating PPARα and PPARγ expression.",health
10.1016/j.jep.2020.113563,Journal,Journal of Ethnopharmacology,scopus,2021-03-25,sciencedirect,Comprehensive evaluation of the combined extracts of Epimedii Folium and Ligustri Lucidi Fructus for PMOP in ovariectomized rats based on MLP-ANN methods,https://api.elsevier.com/content/abstract/scopus_id/85096192504,"Ethnopharmacological relevance
                  Kidney deficiency is the main pathogenesis of osteoporosis based on the theory of “kidney governing bones” in traditional Chinese medicine (TCM). Osteoporosis is a systemic disease; kidney deficiency influences the growth, aging and reproduction of human body, reflecting in endocrine, nerve, immunity, metabolism and other functions. Multi-target drugs composed of natural non-toxic products from kidney-reinforcing herbs, are being investigated for the treatment of osteoporosis. Therefore, it is necessary and imperative to develop an objective and comprehensive method to evaluate and compare the effects of herbs with listed drugs.
               
                  Aim of the study
                  This study was designed to evaluate and compare the therapeutic effects and the underlying molecular mechanism of the combined extracts of Epimedii Folium and Ligustri Lucidi Fructus (EL) with Raloxifene hydrochloride (RH) in ovariectomy (OVX)-induced postmenopausal osteoporosis (PMOP) rats based on the multi-layer perception (MLP)-artificial neural network (ANN) model.
               
                  Materials and methods
                  Female SD rats were subjected to either sham surgery (n = 8) or bilateral OVX (n = 48). One week after recovering from surgery, the OVX-induced rats were randomly divided into three groups: OVX model group (n = 32, every 8 rats were killed at the end of the 5th, 9th, 11th or 13th week after OVX), EL group (treated with EL 0.35 g/kg, n = 8), and RH group (treated with RH 6.25 mg/kg, n = 8). The rats in the treatment groups were administrated once a day for 12 weeks, then sacrificed. We observed bone mass and quality, bone remodeling, the function of estrogen and TGF-β1/Smads pathway in all rats.
               
                  Results
                  Both EL and RH could increase bone mineral density, enhance bone strength, relieve bone micro-structure degeneration, re-balance bone remodeling, regulate estrogen dysfunction, and up-regulate TGF-β1 expression. The evaluation of the MLP-ANN model showed that EL and RH had markedly anti-PMOP effects, and there was no significant difference in the comprehensive evaluation of anti-osteoporosis between the two drugs. However, RH had better effects on bone mass and quality and TGF-β1/Smads pathway than EL; EL had better effects on estrogen function than RH.
               
                  Conclusion
                  Combined extracts of Epimedii Folium and Ligustri Lucidi Fructus (EL) exhibited bone-protective effects on PMOP. The MLP-ANN method evaluated the efficacy of drugs more comprehensively, which provided a new direction for the evaluation and comparison of drugs.",health
10.1016/j.aca.2021.338250,Journal,Analytica Chimica Acta,scopus,2021-03-22,sciencedirect,A fluorescence biosensor for therapeutic drug monitoring of vancomycin using in vivo microdialysis,https://api.elsevier.com/content/abstract/scopus_id/85099992366,"Clinical vancomycin (Van) treatment is administered over a prolonged period to achieve a sustained therapeutic effect. Accurate, rapid, and continuous Van detection is an unmet medical monitoring need that can provide data-based guidance for doctors to adjust the dosage and treatment plan in real-world settings. In this study, we created a Van-specific, fluorescent biosensor that was combined with a microdialysis sampling technique to develop a rapid, simple, accurate, and sensitive detection method, which was validated for Van in vivo. A Van-specific probe was created by separately conjugating each of the two peptide chains of a dimeric derivative of the Van binding peptide L-Lys-D-Ala-D-Ala to a fluorescent dansyl chloride group. Subject-specific pharmacokinetics of Van was recorded in normal rabbits and rabbits with adenine-induced chronic renal failure (CRF), which indicated the feasibility of therapeutic drug monitoring in vivo. The area under the concentration–time curve (AUC0–last) was 10,715 min μg mL−1 (95% CI = 8,892 to 12,538) in the normal rabbits, and 14,822 and 19,025 min μg mL−1 in two selected CRF rabbits. Furthermore, using pharmacokinetic dosing of Van in a rabbit study, we designed the dosage and drug administration interval to achieve a sustained therapeutic effect. The normal rabbits received three Van doses, 20, 5, and 5 mg kg−1, administered at 0, 500, and 900 min, respectively. The CRF rabbits received two Van doses, 20 and 5 mg kg−1, administered at 0 and 600 min, respectively. Thus, we established an effective method for the continuous monitoring of Van. This method facilitates the detection of Van in clinical treatment and provides the scientific basis for an effective approach to monitor blood drug levels during the clinical treatment of various diseases.",health
10.1016/j.comcom.2021.01.036,Journal,Computer Communications,scopus,2021-03-15,sciencedirect,The anomaly detection mechanism using deep learning in a limited amount of data for fog networking,https://api.elsevier.com/content/abstract/scopus_id/85100629475,"The treatment of brain ischemia is the use of tissue plasminogen activator. But after treatment there may be a risk of Brain hemorrhage. Under the pressure of rescue time, medical personnel and their families must make decisions. There is currently no benchmark that can provide what can happen after treatment. This is because there are too many uncertainties. This study proposes that an adaptive deep autoencoder model is used to learn the features of a particular data and analyze the results that the data belongs to. For data preprocessing, the study also proposes methods such as K-means and connecting and labeling non-background areas to de-noise the image and preserve the desired areas to the maximum extent. In addition, we use Variational AutoEncoder Wasserstein Generative Adversarial Network with Gradient Penalty (VAE WGAN-GP) to generate 3D medical images to solve the problem of too few training data. We study key techniques such as pre-processing of real data and image generation with limited real data, so that the model can be trained smoothly. From our experiments, we found that the autoencoder model analyzes real data that is bleeding and non-bleeding and achieves 76% accuracy.",health
10.1016/j.eswa.2020.114070,Journal,Expert Systems with Applications,scopus,2021-03-15,sciencedirect,AnomalP: An approach for detecting anomalous protein conformations using deep autoencoders,https://api.elsevier.com/content/abstract/scopus_id/85092096474,"Proteomics is nowadays one of the most important and relevant fields from computational biology, raising a lot of challenging and provocative questions. Gaining an understanding of protein dynamic and function as well as obtaining additional insights into the protein folding process is still of great interest in bioinformatics and medicine. This paper introduces a new approach 
                        
                           A
                           n
                           o
                           m
                           a
                           l
                           P
                        
                      for detecting anomalous protein conformational transitions using deep autoencoders for encoding information about the structural similarity between proteins belonging to the same superfamily. Experiments are conducted on real protein data and the obtained results emphasize the potential of autoencoders to learn biological relevant patterns, such as proteins’ structural characteristics and that they are useful for detecting conformations or proteins which are likely to be anomalous with respect to a superfamily. The study performed in this paper is aimed to provide better insights of proteins structural similarity, with the broader goal of learning to predict proteins conformational transitions.",health
10.1016/j.iot.2020.100347,Journal,Internet of Things (Netherlands),scopus,2021-03-01,sciencedirect,RL-PMAgg: Robust aggregation for PM2.5 using deep RL-based trust management system,https://api.elsevier.com/content/abstract/scopus_id/85114812625,"Air pollution has become a major environmental issue in large cities. Air pollutants, especially fine particulate matter (PM2.5) has raised various concerns on human health. As a result, several low-cost PM2.5 monitoring systems have been deployed worldwide. However, an accurate air pollution monitoring system profoundly relies on data quality. In this paper, we propose RL-PMAgg for robustly computing PM2.5 pollution rates in existence of faulty sensors. Our method consists of three modules. The outlier detector gives quality assessments to the measurements. We use an RL-based trust management system to create a profile for each sensor and track its behavior in the long run. Then, an aggregated PM2.5 rate is computed by using a set of honest sensors along with their trust levels and measurements. We evaluate RL-PMAgg on both simulated and real-world datasets. We compare the proposed method with relevant works. Experimental results show that RL-PMAgg resists the majority of attacks as compared with other works.",health
10.1016/S0038-0814(21)00053-0,Journal,Soins,scopus,2021-03-01,sciencedirect,Advocating a new health order,https://api.elsevier.com/content/abstract/scopus_id/85103118451,"Le système de santé français reste à ce jour encore trop médico-centré
                  Une véritable révolution doit s'opérer afin de le faire évoluer, nécessitant de revoir nos schémas de pensée habituels et d'intégrer les évolutions technologiques telles que l'intelligence artificielle
                  D'autres acteurs peuvent y contribuer, comme les infirmiers en pratique avancée, grâce à une formation solide et une volonté politique forte.
               
                  The French health system remains overly medico-centric. A real revolution is needed to help it evolve, requiring an overhaul of our usual ways of thinking and the integration of new technologies such as artificial intelligence. Other players can contribute, such as advanced practice nurses, thanks to their solid training and strong political will.",health
10.1016/j.jcv.2021.104757,Journal,Journal of Clinical Virology,scopus,2021-03-01,sciencedirect,"Evaluation of a measles virus multiplex, triple-target real-time RT-PCR in three specimen matrices at a U.S. academic medical center",https://api.elsevier.com/content/abstract/scopus_id/85101360201,"Background
                  Measles virus (MeV) is an important cause of acute febrile illness and pediatric mortality globally, with recent U.S. outbreaks associated with under-vaccination. MeV is highly contagious and timely diagnosis is critical to limit spread. RNA detection is the most sensitive method for acute measles diagnosis; however, MeV nucleic acid amplification assays are not widely available.
               
                  Methods
                  We performed a diagnostic accuracy study of a triple-target, real-time RT-PCR (rRT-PCR) assay for simultaneous detection of MeV N, H, and L genes.
               
                  Results
                  The MeV triple-target rRT-PCR was tested against serial dilutions (7.0−2.0 log10 copies/mL) of five MeV isolates representing circulating genotypes, and detected 98.7% (74/75) of nasopharyngeal (NP) swab dilutions, 100% (75/75) of plasma dilutions, and 85.3% (64/75) of urine dilutions. MeV RNA detection in urine was markedly improved with the addition of a nucleic acid stabilizing agent. A 95% lower limit of detection (LLOD) of < 3.0 log10 copies/mL was established in each specimen matrix. No cross-reactivity with relevant viruses or interfering substances were identified in specificity studies. The MeV triple-target rRT-PCR detected all three gene targets in a clinical NP swab from an individual with confirmed measles infection. Furthermore, pooled testing from 798 influenza A/B/RSV-negative pediatric NP swabs identified two specimens positive for MeV RNA, confirmed by N gene sequencing to represent shedding of the vaccine-type measles virus.
               
                  Conclusions
                  The MeV triple-target rRT-PCR assay showed high analytic sensitivity across circulating MeV genotypes in three clinically-relevant matrices. Implementation of this assay in the clinical laboratory may facilitate timely diagnosis of acute measles infection and implementation of appropriate infection control interventions.",health
10.1016/j.berh.2021.101662,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2021-03-01,sciencedirect,Managing patients using telerheumatology: Lessons from a pandemic,https://api.elsevier.com/content/abstract/scopus_id/85100105533,"The coronavirus disease 2019 (COVID-19) pandemic has presented unique challenges to rheumatology provision. Measures to control the pandemic have limited face-to-face contact with rheumatology healthcare professionals. One innovation has been the widespread adoption of telerheumatology to assist in the care of patients with rheumatic and musculoskeletal diseases, building on an existing evidence base in rheumatology. Widespread adoption has only occurred following the COVID-19 pandemic. We discuss the evidence supporting telerheumatology adoption prior to the pandemic, and outline several innovative approaches used to assist in the care of rheumatology patients that have been introduced. Alongside the advantages of these interventions, we discuss the limitations and regulatory challenges. Advances must be balanced, considering wider issues of equity of access, implementation, adoption, and sustainability of telerheumatology post-pandemic. We propose it is not ‘if’, but ‘how’ rheumatologists embrace newer telerheumatology technology, outlining practice points and future research agenda.",health
10.1016/j.vetmic.2021.108999,Journal,Veterinary Microbiology,scopus,2021-03-01,sciencedirect,A longitudinal observational study in two cats naturally-infected with hepadnavirus,https://api.elsevier.com/content/abstract/scopus_id/85100053978,"Hepatitis B virus (HBV) is a major cause of liver disease in humans including chronic hepatitis and hepatocellular carcinoma. Domestic cat hepadnavirus (DCH), a novel HBV-like hepadnavirus, was identified in domestic cats in 2018. From 6.5 %–10.8 % of pet cats are viremic for DCH and altered serological markers suggestive of liver damage have been identified in 50 % of DCH-infected cats. DCH DNA has been detected in association with characteristic lesions of chronic hepatitis and with hepatocellular carcinoma in cats, suggesting a possible association. In this study longitudinal molecular screening of cats infected with DCH was performed to determine if DCH can cause chronic infections in cats. Upon re-testing of sera from five DCH-positive animals, 2–10 months after the initial diagnosis, three cats tested negative for DCH on two consecutive occasions using quantitative PCR. Two other cats remained DCH-positive, including an 8-month-old female cat re-tested four months after the initial positive result, and a 9-year-old male cat, which tested positive for DCH on six occasions over an 11-month period. The latter had a history of chronic hepatopathy with jaundice, lethargy and elevated serum alanine transaminase levels (ALT). During the period of observation, DCH titers ranged between 1.64 × 105 and 2.09 × 106 DNA copies/mL and ALT was persistently elevated, suggesting chronic infection. DCH DNA was not detected in oral, conjunctival, preputial and rectal swabs from the two animals collected at several time points. Long-term (chronic) infection would be consistent with the relatively high number of viremic cats identified in epidemiological investigations, with the possible association of DCH with chronic hepatic pathologies and with what described with HBV in human patients.",health
10.1016/j.compbiomed.2020.104189,Journal,Computers in Biology and Medicine,scopus,2021-03-01,sciencedirect,A novel algorithm for minute ventilation estimation in remote health monitoring with magnetometer plethysmography,https://api.elsevier.com/content/abstract/scopus_id/85099685697,"Purpose
                  The purpose of this study was to evaluate the accuracy of minute ventilation (
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                     ) estimation using a novel method based on a non-linear algorithm coupled with cycle-based features. The experiment protocol was well adapted for remote health monitoring applications by exploiting data streams from respiratory magnetometer plethysmography (RMP) during different physical activity (PA) types. Methods Thirteen subjects with an age distribution of 
                        
                           24.1
                           ±
                           3.4
                        
                      years performed thirteen PA ranging from sedentary to moderate intensity (walking at 4 and 6 km/h, running at 9 and 12 km/h, biking at 90 W and 110 W). In total, 3359 temporal segments of 10s were acquired using the Nomics RMP device while the iWorx spirometer was used for reference 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      measurements. An artificial neural network (ANN) model based on respiration features was used to estimate 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      and compared to the multiple linear regression (MLR) model. We also compared the subject-specific approach with the subject-independent approach. Results The ANN model using subject-specific approach achieved better accuracy for the 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      estimation. The bias was between 
                        
                           0.20
                           ±
                           0.87
                        
                      and 
                        
                           0.78
                           ±
                           3
                        
                      l/min with the ANN model as compared to 
                        
                           0.73
                           ±
                           3.19
                        
                      and 
                        
                           4.17
                           ±
                           2.61
                        
                      l/min with the MLR model. Conclusion Our results demonstrated the pertinence of processing data streams from wearable RMP device to estimate the 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      with sufficient accuracy for various PA types. Due to its low-complexity and real-time algorithm design, the current approach can be easily integrated into most remote health monitoring applications coupled with wearable sensors.",health
10.1016/j.micpro.2020.103737,Journal,Microprocessors and Microsystems,scopus,2021-03-01,sciencedirect,HPAC-sbox- a novel implementation of predictive learning classifier and adaptive chaotic s-box for counterfeiting sidechannel attacks in an IOT networks,https://api.elsevier.com/content/abstract/scopus_id/85099437035,"Today, embedded systems are augmented with the Internet of things and more with the artificial intelligence to make world even connected with aliens. With an IoT networks are getting its insight since it deals with large number of data information, security has considered to be more important and needs to be a diagnosis for every minute. To enhance the security in the network, a mathematically secure algorithms were formulated and runs on the cryptographic embedded chips to counterfeit the risks which are caused by the different attacks such as side channel attacks (SCA) on the networks. Even though many cryptographic encryption algorithms such as AES, DES, RC4 algorithms were gaining its importance, fixed encryption keys, non-intelligent detection of attacks, cognitive countermeasures are some of the real-time challenges in an existing system of encryption. Following the limitations of existing systems, this research article focuses on design of new AES with HPAC-SBOX (Hybrid Prediction and Adaptive Chaos) which integrates powerful predictive learning algorithms and adaptive chaotic logistic S-Box. The following contributions of this research articles are: a) Preparation of Data Sets from the Power consumption traces captured from Multi Core Embedded boards while running the Advanced Encryption Systems(AES) on it b) Implementation of High Speed and High Accurate Prediction learning machines for the prediction of side-channel attacks c) Design of Adaptive Chaotic S-Box using 3-Dlogistic Hyperbolic maps for attacked bits. To evaluate the proposed architecture, experimentation in carried out in an IoT networks and various performance parameters were calculated and analyzed. The results show that the proposed architecture outperforms the other existing algorithms in terms of prediction and performance.",health
10.1016/j.cortex.2020.12.010,Journal,Cortex,scopus,2021-03-01,sciencedirect,Brain-based concealed memory detection is driven mainly by orientation to salient items,https://api.elsevier.com/content/abstract/scopus_id/85099278957,"In the pursuit of new methods for concealed memory detection, event-related potential components (ERP) have been placed at the forefront of research. No method, however, is scientifically complete without a theory and the present study therefore aimed to unravel the cognitive processes underlying these ERPs (i.e., orienting and arousal inhibition). This was accomplished by using a Concealed Information Test (CIT) in which participants were once motivated to conceal and once motivated to reveal their identity. The results showed a similarly strong P3 CIT effect in the two motivational conditions, which was enhanced for high salience compared to low salience identity items. Similar results were observed when using a multivariate machine-learning algorithm – suggesting that brain-based concealed memory detection is driven mainly by orientation to salient stimuli, rather than by arousal inhibition. In addition, the algorithm, trained and tested on the ERPs of different identity items, achieved detection rates exceeding those achieved by the P3. This implies that CIT researchers and practitioners could potentially rely on the entire ERP waveform instead of a-priori selecting separate components. Together these results enrich current understanding of the mechanisms underlying neurophysiological responding to concealed information and pave the way for novel and powerful algorithms which could be used in real-life forensic investigations.",health
10.1016/j.smhl.2020.100165,Journal,Smart Health,scopus,2021-03-01,sciencedirect,Robustness to noise for speech emotion classification using CNNs and attention mechanisms,https://api.elsevier.com/content/abstract/scopus_id/85098782745,"Speech Emotion Recognition (SER) is an important task since emotion is a primary dimension in human communication and health. It has a wide variety of practical applications such as assessing the mood of callers to an emergency call center and as a diagnostic tool for therapists. Since most of the SER models in the literature are trained with clean noiseless data and non noise-robust input features, they are not very useful in real world conditions where noise is almost always present. Although there are methods to reduce these adverse effects of noise, a systematic analysis of these methods in the context of SER is lacking. In this paper several different methods to mitigate adverse effects of noise on CNN (Convolutional Neural Network) based SER are developed and analyzed. The SER models trained on the Berlin Database of Emotional Speech were tested with clean data and data mixed with 10 different noise types at different noise levels with signal to noise ratios of 10,15,20,25,30 and 35. We show that the noise robustness of SER models can be improved by combining the magnitude spectrogram with the modified group delay spectrogram, by including synthetic noise in the training data, and by using an attention mechanism. When trained with noisy data, the models trained with the combined input saw a 10% increase in average accuracy than the models using individual inputs and not trained with noise. Adding the attention mechanism to the previous model further improved the accuracy by 5%. Finally, by training and evaluating on the RAVDESS dataset, we demonstrated that the noise robust methods developed can be generalized into other datasets and emotions. We achieved an average accuracy of 81% on RAVDESS dataset under noisy conditions.",health
10.1016/j.ygcen.2020.113704,Journal,General and Comparative Endocrinology,scopus,2021-03-01,sciencedirect,Gamma-aminobutyric acid regulates glucose homeostasis and enhances the hepatopancreas health of juvenile Chinese mitten crab (Eriocheir sinensis) under fasting stress,https://api.elsevier.com/content/abstract/scopus_id/85098710797,"The ability of immune defense and resistance to physiological stress is crucial to animal health and survival. This study investigated the regulation of γ-aminobutyric acid (GABA) on metabolic homeostasis and its enhancement of hepatopancreas health in juvenile Chinese mitten crab (Eriocheir sinensis) under food deprivation. Juvenile crabs of 400 individuals were divided into four treatment groups: a control group without injection, and injections with a phosphate-buffered saline solution, 100 μmol GABA/mL and 1000 μmol GABA/mL, respectively. Hypoglycemia was induced by fasting, whereas the GABA treatment regulated hemolymph glucose homeostasis. The quantitative real-time PCR (qRT-PCR) results showed that the GABA treatment significantly up-regulated the mRNA expression levels of crustacean hyperglycemic hormone (CHH) and pyruvate kinase (PK). In contrast, the expression of E. sinensis insulin-like peptide (EsILP) was significantly down-regulated in the cranial ganglia, thoracic ganglia and hepatopancreas. Moreover, acid phosphatase (ACP), alkaline phosphatase (AKP), aspartate aminotransferase (AST) and alanine aminotransferase (ALT) activities were significantly increased in the hepatopancreas by the GABA treatment. Furthermore, the hemocyanin content in serum was significantly increased with the GABA injection, and the glutathione (GSH) content, total superoxide dismutase (T-SOD) activity and catalase (CAT) activity in the hepatopancreas showed a similar increasing trend with the dose elevation of GABA. Therefore, these results indicate that GABA can effectively maintain the hemolymph glucose homeostasis by regulating the levels of glucose metabolism-related hormones and key enzymes to promote the degradation and utilization of hepatopancreas glycogen. Meanwhile, GABA can improve the hepatopancreas function and immune status of juvenile E. sinensis under fasting stress. The treatment with GABA may provide a clue to guide health management in crab farming.",health
10.1016/j.cie.2020.107056,Journal,Computers and Industrial Engineering,scopus,2021-03-01,sciencedirect,Reinforcement learning-driven maintenance strategy: A novel solution for long-term aircraft maintenance decision optimization,https://api.elsevier.com/content/abstract/scopus_id/85098538813,"A novel Reinforcement Learning (RL) driven maintenance strategy is proposed in this paper for solving the problem of aircraft long-term maintenance decision optimization. Specifically, it is targeted to process the information of aircraft future mission requirement, repair cost, spare components storage and aircraft Prognostics and Health Management (PHM) output, and provide real-time End-to-End sequential maintenance action decisions based on the coordination between short and long-term operation performance. The proposed RL-driven strategy is designed in the RL framework with Extreme Learning Machine based Q-learning algorithm, and an integrated aircraft maintenance simulation model is developed for training/testing RL-driven strategy. We test the proposed RL-driven strategy in several simulated dynamic aircraft maintenance scenarios together with 3 other commonly used maintenance strategies. The obtained results demonstrate that RL-driven strategy has prior performance in adjusting its decision principle for handling the variations of mission reward, repair/spare component storage cost and PHM ability in different maintenance scenarios. Some practical application suggestions and future perspectives of RL-driven strategy are discussed based on the obtained experiment results.",health
10.1016/j.cbpc.2020.108951,Journal,Comparative Biochemistry and Physiology Part - C: Toxicology and Pharmacology,scopus,2021-03-01,sciencedirect,Genipin induces developmental toxicity through oxidative stress and apoptosis in zebrafish,https://api.elsevier.com/content/abstract/scopus_id/85098178184,"Genipin, an iridoid substance, is mainly derived from Gardenia jasminoides Ellis of the traditional Chinese medicine and is widely used in raw materials for the food additive gardenia blue and biological materials. The developmental toxicity of genipin has not been investigated, and its underlying mechanism is unclear. Therefore, in this study we attempt to investigate the potential developmental toxicity of genipin in zebrafish embryos/larvae. The results showed zebrafish embryos treated with 50 μg/ml dose of genipin display inhibited hatching rates and body length. The pericardial edema was observed. It was also found that genipin could induce cardio-toxicity, hepatotoxicity and nephrotoxicity in zebrafish larvae. After genipin treatment, the suppression of antioxidant capacity and increase of oxidative stress were showed for the triggered generation of ROS and MDA, and decreased activity of SOD. Compared with the 0.5% DMSO group, a number of apoptotic cells in zebrafish were increased after genipin exposure. By measuring marker gene expression with the using of qRT-PCR, we proposed that developmental toxicity after genipin treatment might be associated with oxidative stress and apoptosis increase. Our research offers a better understanding for developmental toxicity of genipin.",health
10.1016/j.bspc.2020.102386,Journal,Biomedical Signal Processing and Control,scopus,2021-03-01,sciencedirect,Detection of melatonin-onset in real settings via wearable sensors and artificial intelligence. A pilot study,https://api.elsevier.com/content/abstract/scopus_id/85098168222,"Circadian rhythms modulate physiological and behavioral processes of approximately 24-h periodicity. Alterations in the circadian timing system may lead to cardiovascular, metabolic or neurological diseases, cancers and sleep disorders, as well as to disruption of quality of life. Circadian rhythms can be tracked via laboratory tests measuring hormones in salivary, urinary or blood samples, which are collected in controlled environments. These tests are unsuitable for continuous monitoring in real-life, being expensive and time consuming, producing discrete information (i.e., few values per day) and requiring controlled environmental conditions (e.g., exposure to light can alter the samples). Thus, there is a need to develop non-invasive methods and tools to track circadian rhythms in real-life conditions.
                  In this study, 10 healthy participants wore commercial medical-rated (i.e., CE-marked) wearable sensors, which continuously measured ECG, skin body temperature and physical activity for two consecutive days. Up to 10 salivary samples per day were taken and sent to a laboratory for measuring melatonin, which was used as proxy for circadian rhythm tracking.
                  The results presented in this paper demonstrated that Heart Rate Variability (HRV) measures, physical activity and skin temperature changed significantly after the onset of melatonin. The deep-learning model presented in this study detected the onset of melatonin with 71 % accuracy, 67 % sensitivity, 75 % specificity and 77 % area under the curve (AUC).
                  The current study concluded that deep learning could be used to track melatonin-onset in real-life, using physiological and behavioral measures monitored via wearable and easy-to-use sensors.",health
10.1016/j.bios.2020.112903,Journal,Biosensors and Bioelectronics,scopus,2021-03-01,sciencedirect,Induced bioresistance via BNP detection for machine learning-based risk assessment,https://api.elsevier.com/content/abstract/scopus_id/85098146521,"Machine Learning (ML) is a powerful tool for big data analysis that shows substantial potential in the field of healthcare. Individual patient data can be inundative, but its value can be extracted by ML's predictive power and ability to find trends. A great area of interest is early diagnosis and disease management strategies for cardiovascular disease (CVD), the leading cause of death in the world. Treatment is often inhibited by analysis delays, but rapid testing and determination can help improve frequency for real time monitoring. In this research, an ML algorithm was developed in conjunction with a flexible BNP sensor to create a quick diagnostic tool. The sensor was fabricated as an ion-selective field effect transistor (ISFET) in order to be able to quickly gather large amounts of electrical data from a sample. Artifical samples were tested to characterize the sensors using linear sweep voltammetry, and the resulting data was utilized as the initial training set for the ML algorithm, an implementation of quadratic discriminant analysis (QDA) written in MATLAB. Human blood serum samples from 30 University of Pittsburgh Medical Center (UPMC) patients were tested to evaluate the effective sorting power of the algorithm, yielding 95% power in addition to ultra fast data collection and determination.",health
10.1016/j.conbuildmat.2020.121706,Journal,Construction and Building Materials,scopus,2021-03-01,sciencedirect,Acoustic emission source location using Lamb wave propagation simulation and artificial neural network for I-shaped steel girder,https://api.elsevier.com/content/abstract/scopus_id/85097473335,"Acoustic emission (AE) is often used for structural health monitoring (SHM) in the wide field of engineering structures and one of its most beneficial attributes is the ability to localize the damage/crack based on the AE events. The vast majority of ongoing work on AE monitoring focues on geometrically simple structures or a confined area, but the AE source location strategies are rather complicated for real engineering structures. In this paper, an effective method for source localization in realistic structures is presented based on the application of artificial neural networks (ANN), using finite element (FE) simulation results of Lamb waves as the modelling basis. Pencil lead break experiments and related FE simulations on a steel-concrete composite girder are conducted to evaluate the performance of the method. The identification of different wave modes is carried by comparing alternative onset time detection methods. Numerical results are found to be matching closely with the experimental results. To get a reliable ANN model, the validated FE model is used to create a comprehensive database with five different sensor arrangements. It is found that the proposed method is superior to the classical Time of Arrival (TOA) method with the same input data. The results indicate that using trained neural networks based on numerical data is a viable option for AE source location in the case of the I-shaped girder, increasing the likelihood of design and optimization of the AE technique in monitoring realistic structures.",health
10.1016/j.rvsc.2020.11.017,Journal,Research in Veterinary Science,scopus,2021-03-01,sciencedirect,Efficacy of a Salmonella enterica serovar Abortusovis (S. Abortusovis) inactivated vaccine in experimentally infected gestating ewes,https://api.elsevier.com/content/abstract/scopus_id/85096997250,"Salmonella enterica serovar Abortusovis (S. Abortusovis) infection is one of the most important causes of infectious late-term abortion as well as birth of weak lambs in sheep in many countries throughout the world. Implementation of protocols based on the application of effective vaccines is one of the most effective approaches for controlling this disease, but variable efficacy has been reported, possibly related to factors associated with the host, the vaccine, the parameters used for determining efficacy and the challenge protocols. In this context, a new commercial inactivated vaccine (INMEVA; Laboratorios Hipra S.A., Spain) was evaluated in 20 control and 17 vaccinated gestating ewes, subcutaneously challenged at 90 days of gestation with 5 × 106 colony-forming units (cfu) of a wild strain of S. Abortusovis. Incidence of reproductive failures, bacterial vaginal excretion (by real time PCR), and lamb survival were evaluated as indicators of the vaccine's level of protection. Moreover, humoral response (by ELISA test in serum samples) was studied. Vaccination was showed to be safe under the study conditions. Vaccine efficacy was demonstrated in two different ways: i) it significantly decreased the percentage of abortions [29.4% (5/17) in the vaccinated group compared to the control group (65%; 13/20)] and ii) there was a significant reduction of the overall vaginal excretion in the sampling period (3.05 log cfu/mL ± 0.84 in the vaccinated group vs. 5.68 ± 0.67 in the control group).
                  Given these results, the vaccine evaluated can be considered as an effective alternative for controlling S. Abortusovis infection in ovine flocks.",health
10.1016/j.jep.2020.113538,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,Developmental toxicity of Clerodendrum cyrtophyllum turcz ethanol extract in zebrafish embryo,https://api.elsevier.com/content/abstract/scopus_id/85096104462,"Ethnopharmacological relevance
                  
                     Clerodendrum cyrtophyllum Turcz has been used in traditional medicine for the treatment of various diseases. In spite of its therapeutic applications, research on its toxicity and teratogenicity is still limited.
               
                  Aim of the study
                  The study aimed to investigate the developmental toxicity of the ethanol extract of C. cyrtophyllum (EE) in zebrafish embryo model.
               
                  Material and methods
                  Major compounds from crude ethanol extract of Clerodendron cyrtophyllum Turcz leaves were determined using HPLC-DAD-Orbitrap-MS analysis
                        .
                      The developmental toxicity of EE were investigated using zebrafish embryo model. Zebrafish embryos at 6 h post-fertilization (hpf) were treated with EE at different concentrations. Egg coagulation, mortality, hatching, yolk sac edema, pericardial edema and teratogenicity were recorded each day for during a 5-day exposure. At time point 120 hpf, body length, pericardial area, heartbeat and yolk sac area were assessed. In order to elucidate molecular mechanisms for the developmental toxicity of EE, we further evaluated the effects of the EE on the expression of genes involved on signaling pathways affecting fish embryo’s development such as heart development (gata5, myl7, myh6, has2, hand2, nkx 2.5), oxidative stress (cat, sod1, gpx4, gstp2), wnt pathway (β-catenin, wnt3a, wnt5, wnt8a, wnt11), or cell apoptosis (p53, bax, bcl2, casp3, casp8, casp9, apaf-1, gadd45bb) using qRT-PCR analysis.
               
                  Results
                  Our results demonstrated that three major components including acteoside, cirsilineol and cirsilineol-4'-O-β-D-glucopyranoside were identified from EE. EE exposure during 6–96 h post-fertilization (hpf) at doses ranging from 80 to 200 μg/mL increased embryo mortality and reduced hatching rate. EE exposure at 20 and 40 μg/mL until 72–120 hpf induced a series of malformations, including yolk sac edema, pericardial edema, spine deformation, shorter body length. Based on two prediction models using a teratogenic index (TI), a 25% lethality concentration (LD25) and the no observed-adverse-effect level (NOAEL), EE is considered as teratogenic for zebrafish embryos with TI (LC50/EC50) and LD25/NOAEC values at 96 hpf reaching 3.87 and 15.73 respectively. The mRNA expression levels of p53, casp8, bax/bcl2, gstp2, nkx2.5, wnt3a, wnt11, gadd45bb and gata5 were significantly upregulated by EE exposure at 20 and 40 μg/mL while the expression of wnt5, hand2 and bcl2 were downregulated.
               
                  Conclusions
                  These results provide evidence for toxicity effects of EE to embryo stages and provide an insight into the potential toxicity mechanisms on embryonic development.",health
10.1016/j.future.2020.10.030,Journal,Future Generation Computer Systems,scopus,2021-03-01,sciencedirect,HealthXAI: Collaborative and explainable AI for supporting early diagnosis of cognitive decline,https://api.elsevier.com/content/abstract/scopus_id/85095701881,"Our aging society claims for innovative tools to early detect symptoms of cognitive decline. Several research efforts are being made to exploit sensorized smart-homes and artificial intelligence (AI) methods to detect a decline of the cognitive functions of the elderly in order to promptly alert practitioners. Even though those tools may provide accurate predictions, they currently provide limited support to clinicians in making a diagnosis. Indeed, most AI systems do not provide any explanation of the reason why a given prediction was computed. Other systems are based on a set of rules that are easy to interpret by a human. However, those rule-based systems can cope with a limited number of abnormal situations, and are not flexible enough to adapt to different users and contextual situations. In this paper, we tackle this challenging problem by proposing a flexible AI system to recognize early symptoms of cognitive decline in smart-homes, which is able to explain the reason of predictions at a fine-grained level. Our method relies on well known clinical indicators that consider subtle and overt behavioral anomalies, as well as spatial disorientation and wandering behaviors. In order to adapt to different individuals and situations, anomalies are recognized using a collaborative approach. We experimented our approach with a large set of real world subjects, including people with MCI and people with dementia. We also implemented a dashboard to allow clinicians to inspect anomalies together with the explanations of predictions. Results show that our system’s predictions are significantly correlated to the person’s actual diagnosis. Moreover, a preliminary user study with clinicians suggests that the explanation capabilities of our system are useful to improve the task performance and to increase trust. To the best of our knowledge, this is the first work that explores data-driven explainable AI for supporting the diagnosis of cognitive decline.",health
10.1016/j.jep.2020.113516,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,The anti-inflammatory potential of Cinnamomum camphora (L.) J.Presl essential oil in vitro and in vivo,https://api.elsevier.com/content/abstract/scopus_id/85094843041,"Ethnopharmacological relevance
                  Borneol was widely used in traditional Chinese medicine formulas due to its pharmacological activities, e.g. sedative, anti-inflammatory, and anti-ischemic properties. Cinnamomum camphora (L.) J.Presl essential oil (BEO) is a by-product of natural crystalline borneol (NCB) production obtained by steam distillation of Cinnamomum camphora (L.) J.Presl leaves, and borneol was the main component of BEO. This study aims to investigate the anti-inflammatory effect of BEO and its corresponding mechanisms through in vitro and in vivo studies.
               
                  Materials and methods
                  Human erythrocyte membrane stability assay and the acute inflammation murine model (xylene-induced ear edema) were chosen to evaluate the anti-inflammatory effect of BEO. Expression of inflammatory mediators, including interleukin (IL)-1β, IL-6, and tumor necrosis factor α (TNF-α) was determined by real-time quantitative polymerase chain reaction (RT-PCR) and enzyme-linked immunosorbent assays (ELISA). The functional compounds in the BEO were identified by using gas chromatography-mass spectrometry (GC-MS). The steady-state transdermal diffusion rates of BEO and BEO nano-emulsion with were also determined in this study. Cytotoxicity of BEO was analyzed by cell counting kit-8 (CCK-8) assay.
               
                  Results
                  The BEO showed a high human erythrocyte membrane stabilization by inhibiting heat-induced hemolysis (IC50 = 5.29 mg/mL) and hypotonic solution-induced hemolysis (IC50 = 0.26 mg/mL) in vitro. The BEO was topically applied to mice auricles, both single and repeated administration significantly reduced xylene-induced auricle swelling (p < 0.0001). Expression of inflammatory mediators, including interleukin (IL)-1β, IL-6, and tumor necrosis factor α (TNF-α) in serum and tissue was significantly downregulated (p < 0.05), so as to the mRNA expression of IL-1β (p＜0.05) and TNF-α (p < 0.001). A total of 43 components were identified and quantified by GC-MS. The most abundant was borneol [178.3 mg/mL, 20.9% (m/v)], followed by β-caryophyllene (116.3 mg/mL), camphor (115.2 mg/mL), and limonene (89.4 mg/mL). For determining the skin permeability of BEO, the steady-state transdermal diffusion rates of BEO and BEO nano-emulsion were determined to be 6.7 and 8.9 mg/cm2·h, respectively.
               
                  Conclusion
                  It is suspected that the anti-inflammatory effects in vivo and in vitro were derived from the above-mentioned components in the BEO. These findings will facilitate the development of BEO as a new and natural therapeutic agent for inflammatory skin conditions.",health
10.1016/j.apacoust.2020.107738,Journal,Applied Acoustics,scopus,2021-03-01,sciencedirect,Comprehensive fault diagnostics of wind turbine gearbox through adaptive condition monitoring scheme,https://api.elsevier.com/content/abstract/scopus_id/85094834657,"The current work reports a multi-level classification to envisage the location, type/category and severity level of local defects at different stages of speed in a wind turbine gearbox with minimal human intervention. Experiments are conducted by subjecting a three-stage gearbox to fluctuating speeds with multiple sensors recording the real-time information generated. Wavelet coefficients are employed to extract the statistical features from the raw signatures decomposed through wavelet transform. A decision tree algorithm is used to identify features of significance and an integrated multi-variable feature data set is devised based on feature-level data fusion. The intended multi-level classification on the integrated feature data set is accomplished with the help of machine-learning algorithms. The results reveal that the adaptive neuro-fuzzy inference system (ANFIS) performs the intended four-level classification on the wind turbine gearbox with a classification accuracy of 92%. Thus, the integration of multi-sensor information in conjunction with ANFIS as a classification algorithm, owing to its efficiency in predicting every possible detail about the health/condition of the different gearbox components, demonstrates its potential to be used as an adaptive condition monitoring as it.",health
10.1016/j.eswa.2020.113920,Journal,Expert Systems with Applications,scopus,2021-03-01,sciencedirect,BIDI: A classification algorithm with instance difficulty invariance,https://api.elsevier.com/content/abstract/scopus_id/85090363699,"In artificial intelligence, an expert/intelligent systems can emulate the decision-making ability of human experts. A good classification algorithm can provide significant assistance to expert/intelligent systems in solving a variety of practical problems. In classification, the “hard” instances may be outliers or noisy instances that are difficult to learn, which may confuse the classifier and induce the overfitting problem in the case of placing much emphasis on them. In fact, the difficulty of instances is crucial for improving the generalization and credibility of classification. Unfortunately, nearly all the existing classifiers ignore this important information. In this paper, the classification difficulty of each instance is introduced from a statistical perspective, which is an inherent characteristic of the instance itself. Then, a new classification algorithm named “boosting with instance difficulty invariance (BIDI)” is proposed by incorporating the classification difficulty of instances. The BIDI conforms to the human cognition that easy instances are misclassified with a lower probability than difficult ones, and performs better with respect to generalization. The key insight of BIDI can provide relevant guidance for researchers to improve the generalization and credibility of classifiers in the expert systems of decision support systems. Experimental results demonstrate the effectiveness of BIDI in real-world data sets, indicating that it has great potential for solving many classification tasks of expert systems such as disease diagnosis and credit card fraud detection. Although the classification difficulty has strong statistical significance, its implementation remains computationally expensive. A fast method demonstrating rationality and feasibility is also proposed to approximate instances’ classification difficulty.",health
10.1016/j.neucom.2020.10.039,Journal,Neurocomputing,scopus,2021-02-28,sciencedirect,A new method for intelligent fault diagnosis of machines based on unsupervised domain adaptation,https://api.elsevier.com/content/abstract/scopus_id/85097714683,"Data driven fault diagnosis has attracted a lot of attention in recent years owing to its intelligent and accurate detection of fault categories. However, it is a challenge for its applications in real world. The abundant labeled data is extremely necessary for data driven fault diagnosis to train a favorable model. Even though enough labeled data is prepared for training a model, we still cannot ensure the data used for training and testing draw from identical distribution. In other words, the labeled source domain has different distribution compared with the unlabeled target domain. In this paper, we introduce the domain adaptation strategy into deep neural networks to propose a deep domain adaptation architecture, which realizes to learn knowledge from the labeled source domain to facilitate the target classification. In the proposed model, the conditional and marginal distribution are adapted together in multiple layers of neural network, which uses MMD to measure the distribution discrepancy. Besides, the relative importance between marginal and conditional distributions is explored, and an adaptively weighted strategy is further introduced to learn the relative importance of the two distributions. To evaluate the proposed method, we conduct the simulations on different workloads, sensor deployment locations, and even different platforms. The results show the superiority of the proposed model to other intelligent fault diagnosis methods, meanwhile verify the necessity of marginal and conditional distribution adaptation and adaptive weighted strategy.",health
10.1016/j.knosys.2020.106679,Journal,Knowledge-Based Systems,scopus,2021-02-15,sciencedirect,Federated learning for machinery fault diagnosis with dynamic validation and self-supervision,https://api.elsevier.com/content/abstract/scopus_id/85098734354,"Intelligent data-driven machinery fault diagnosis methods have been successfully and popularly developed in the past years. While promising diagnostic performance has been achieved, the existing methods generally require large amounts of high-quality supervised data for training, which are mostly difficult and expensive to collect in real industries. Therefore, it is motivated that the distributed data of multiple clients can be integrated and exploited to build a powerful data-driven model. However, that basically requires data sharing among different users, and is not preferred in most industrial cases due to potential conflict of interests. In order to address the data island problem, a federated learning method for machinery fault diagnosis is proposed in this paper. Model training is locally implemented within each participated client, and a self-supervised learning scheme is proposed to enhance the learning performance. The server aggregates the locally updated models in each training round under the dynamic validation scheme, and a global fault diagnosis model can be established. Only the models are mutually communicated rather than the data, which ensures data privacy among different clients. The experiments on two datasets suggest the proposed method offers a promising approach on confidential decentralized learning.",health
10.1016/j.bios.2020.112830,Journal,Biosensors and Bioelectronics,scopus,2021-02-15,sciencedirect,Diagnosis of COVID-19 for controlling the pandemic: A review of the state-of-the-art,https://api.elsevier.com/content/abstract/scopus_id/85098139782,"To date, health organizations and countries around the world are struggling to completely control the spread of the coronavirus disease 2019 (COVID-19). Scientists and researchers are developing tests for the rapid detection of individuals who may carry the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), while striving to find a suitable vaccine to immunize healthy individuals. As there are clinically reported cases of asymptomatic carriers of SARS-CoV-2, fast and accurate diagnosis plays an important role in the control and further prevention of this disease. Herein, we present recent technologies and techniques that have been implemented for the diagnosis of COVID-19. We summarize the methods created by different research institutes as well as the commercial devices and kits developed by companies for the detection of SARS-CoV-2. The description of the existing methods is followed by highlighting their advantages and challenges. Finally, we propose some promising techniques that could potentially be applied to the detection of SARS-CoV-2, and tracing the asymptomatic carriers of COVID-19 rapidly and accurately in the early stages of infection, based on reviewing the research studies on the detection of similar infectious viruses, especially severe acute respiratory syndrome (SARS) coronavirus, and Middle East respiratory syndrome (MERS) coronavirus.",health
10.1016/j.patter.2020.100195,Journal,Patterns,scopus,2021-02-12,sciencedirect,Topic classification of electric vehicle consumer experiences with transformer-based deep learning,https://api.elsevier.com/content/abstract/scopus_id/85100638713,"The transportation sector is a major contributor to greenhouse gas (GHG) emissions and is a driver of adverse health effects globally. Increasingly, government policies have promoted the adoption of electric vehicles (EVs) as a solution to mitigate GHG emissions. However, government analysts have failed to fully utilize consumer data in decisions related to charging infrastructure. This is because a large share of EV data is unstructured text, which presents challenges for data discovery. In this article, we deploy advances in transformer-based deep learning to discover topics of attention in a nationally representative sample of user reviews. We report classification accuracies greater than 91% (F1 scores of 0.83), outperforming previously leading algorithms in this domain. We describe applications of these deep learning models for public policy analysis and large-scale implementation. This capability can boost intelligence for the EV charging market, which is expected to grow to US$27.6 billion by 2027.",health
10.1016/j.ins.2020.09.049,Journal,Information Sciences,scopus,2021-02-04,sciencedirect,Ground truthing from multi-rater labeling with three-way decision and possibility theory,https://api.elsevier.com/content/abstract/scopus_id/85092211973,"In recent years, Machine Learning (ML) has attracted wide interest as aid for decision makers in complex domains, such as medicine. Although domain experts are typically aware of the intrinsic uncertainty around it, the issue of Ground Truth (GT) quality has scarcely been addressed in the ML literature. GT quality is regularly assumed to be adequate, regardless of the number and skills of raters involved in data annotation. These factors can, however, potentially have a severe negative impact on the reliability of ML models. In this article we study the influence of GT quality, in terms of number of raters, their expertise, and their agreement level, on the performance of ML models. We introduce the concept of reduction: computational procedures by which to produce single-target GT from multi-rater settings. We propose three reductions, based on three-way decision, possibility theory, and probability theory. We provide characterizations of these reductions from the perspective of learning theory and propose two ML algorithms. We report the result of experiments, on both real-world medical and synthetic datasets, showing that GT quality strongly impacts on the performance of ML models, and that the proposed algorithms can better handle this form of uncertainty compared with state-of-the-art approaches.",health
10.1016/j.antiviral.2020.104998,Journal,Antiviral Research,scopus,2021-02-01,sciencedirect,Infectious bronchitis virus: Identification of Gallus gallus APN high-affinity ligands with antiviral effects,https://api.elsevier.com/content/abstract/scopus_id/85098587922,"Infectious bronchitis virus (IBV) is a coronavirus, causes infectious bronchitis (IB) with high morbidity and mortality, and gives rise to huge economic losses for the poultry industry. Aminopeptidase N (APN) may be one of the IBV functional receptors. In this study, Gallus gallus APN (gAPN) protein was screened by phage-displayed 12-mer peptide library. Two high-affinity peptides H (HDYLYYTFTGNP) and T (TKFSPPSFWYLH) to gAPN protein were selected for in depth characterization of their anti-IBV effects. In vitro, indirect ELISA showed that these two high-affinity ligands could bind IBV S1 antibodies. Quantitative real-time PCR (qRT-PCR) assay, virus yield reduction assay and indirect immunofluorescence assay results revealed 3.125–50 μg/ml of peptide H and 6.25–50 μg/ml of peptide T reduced IBV proliferation in chicken embryo kidney cells (CEKs). In vivo, high-affinity phage-vaccinated chickens were able to induce specific IBV S1 antibodies and IBV neutralizing antibodies. QRT-PCR results confirmed that high-affinity phages reduced virus proliferation in chicken tracheas, lungs and kidneys, and alleviated IBV-induced lesions. By multiple sequence alignment, motif ‘YxYY’ and ‘FxPPxxWxLH’ of high-affinity peptides were identified in IBV S1-NTD, while another motif ‘YxFxGN’ located in S2. These results indicated that high affinity peptides of gAPN could present an alternative approach to IB prevention or treatment.",health
10.1016/j.psep.2020.12.011,Journal,Process Safety and Environmental Protection,scopus,2021-02-01,sciencedirect,Enhanced spectrum convolutional neural architecture: An intelligent leak detection method for gas pipeline,https://api.elsevier.com/content/abstract/scopus_id/85098537048,"In this work, a novel convolutional neural architecture (SE-CNN), which combines spectrum enhancement (SE) and convolutional neural network (CNN), is proposed to detect the leak of gas pipeline. The SE has the effect of enhancing the leak signals and reducing background noise. CNN can automatically extract leak features and realize leak diagnosis. The experimental results show that the SE-CNN can achieve an average accuracy of 94.3
                        %
                      for 6 categories and only requires 1.04s of detection time. In this experiment, the diameters of the main pipeline and the branch pipeline are 125mm and 25mm. Due to its excellent accuracy and efficiency, the proposed enhanced spectrum convolutional neural architecture paves the way for real-time leak detection in industrial environments, which can ensure the process safety of gas pipeline transportation. Under strong background noise, the average accuracy of the SE-CNN can reach 94.3
                        %
                     , which is 33
                        %
                     , 3.7
                        %
                      higher than that of SVM and CNN. In particular, the SE can be regarded as a data compression method, which can significantly reduce the original data size. The training time of the SE-CNN is 539s, reducing 90.6
                        %
                      compared with CNN.",health
10.1016/j.antiviral.2020.105000,Journal,Antiviral Research,scopus,2021-02-01,sciencedirect,Suppression effect of plant-derived berberine on cyprinid herpesvirus 2 proliferation and its pharmacokinetics in Crucian carp (Carassius auratus gibelio),https://api.elsevier.com/content/abstract/scopus_id/85098469519,"Cyprinid herpesvirus 2 (CyHV-2), which infects silver crucian carp including goldfish (Carassius auratus auratus) and Crucian carp (Carassius auratus gibelio) with high mortality, is an emerging viral pathogen worldwide. Previous studies showed that berberine (BBR), a bioactive plant-derived alkaloid, demonstrated potential antiviral actions against many different viruses. Here, we assessed the effect of berberine hydrochloride (BBH) on the replication of CyHV-2 in vitro and in vivo. Cytotoxicity assay indicated that 5–25 μg/mL BBH was non-toxic to the RyuF-2 cells. In viral inhibition assays, real time PCR was employed to titrate the genomic copy number of progeny virus, real time RT-PCR was applied to monitor the transcriptional levels of viral genes, and Western blot analysis was performed to detect the synthetic levels of viral proteins. The results demonstrated that BBH systematically impedes the viral gene transcription and suppressed the replication of CyHV-2 in RyuF-2 cells. In animal challenge test, BBH was confirmed to protect Crucian carps from CyHV-2 infection in a dose-dependent manner, which was supported by suppressed viral replication levels, reduced viral pathogenesis and higher survival rates. Furthermore, pharmacokinetics data of BBH in Crucian carp revealed its rapid absorption (Tmax of 1.5 h), suitable plasma half-life (t1/2z/h of 7–12 h depending on oral dosage), and dose-dependent drug exposure properties following oral administration (revealed by AUC0-t values). These findings shed light on repurposing BBH to treat CyHV-2 infections in silver crucian carp.",health
10.1016/j.patrec.2020.11.016,Journal,Pattern Recognition Letters,scopus,2021-02-01,sciencedirect,Auditory perception vs. face based systems for human age estimation in unsupervised environments: from countermeasure to multimodality,https://api.elsevier.com/content/abstract/scopus_id/85098156122,"Face-based age estimation systems are commonly considered in biometric applications as well as in other fields such as forensics or healthcare. For security purposes, features extracted from the face can be used to verify or estimate the age of individuals in order to control their access to physical or logical resources. The main problem in using facial biometrics is its sensitivity, to acquisition (e.g. illumination, pose, occlusion, image quality, etc.), to face expression, and especially to potential attacks in unsupervised environments. In this work, we propose a robust modality using both random auditory stimulation and Deep-learning based age estimation, though individual perception (RaS-DeeP): (1) as a countermeasure to prevent attacks on face-based age estimation systems, but also (2) : as a complementary modality in a multimodal biometric system (i.e. face-sound perception) in order to improve the performances of face-based age estimation system. Used as countermeasure, we show that RaS-DeeP provides promising results with an EER value of 4.2%. On the other hand, when considering the multimodal system face-auditory perception, we show that, the performance of face age estimation system is enhanced with an EER of 3.3%. To evaluate the performance of multimodal system in real-time, 71 subjects from different age ranges achieving five repetitions, participated in our experiment.",health
10.1016/j.wneu.2020.10.171,Journal,World Neurosurgery,scopus,2021-02-01,sciencedirect,Attitudes of the Surgical Team Toward Artificial Intelligence in Neurosurgery: International 2-Stage Cross-Sectional Survey,https://api.elsevier.com/content/abstract/scopus_id/85097780896,"Background
                  Artificial intelligence (AI) has the potential to disrupt how we diagnose and treat patients. Previous work by our group has demonstrated that the majority of patients and their relatives feel comfortable with the application of AI to augment surgical care. The aim of this study was to similarly evaluate the attitudes of surgeons and the wider surgical team toward the role of AI in neurosurgery.
               
                  Methods
                  In a 2-stage cross sectional survey, an initial open-question qualitative survey was created to determine the perspective of the surgical team on AI in neurosurgery including surgeons, anesthetists, nurses, and operating room practitioners. Thematic analysis was performed to develop a second-stage quantitative survey that was distributed via social media. We assessed the extent to which they agreed and were comfortable with real-world AI implementation using a 5-point Likert scale.
               
                  Results
                  In the first-stage survey, 33 participants responded. Six main themes were identified: imaging interpretation and preoperative diagnosis, coordination of the surgical team, operative planning, real-time alert of hazards and complications, autonomous surgery, and postoperative management and follow-up. In the second stage, 100 participants responded. Responders somewhat agreed or strongly agreed about AI being used for imaging interpretation (62%), operative planning (82%), coordination of the surgical team (70%), real-time alert of hazards and complications (85%), and autonomous surgery (66%). The role of AI within postoperative management and follow-up was less agreeable (49%).
               
                  Conclusions
                  This survey highlights that the majority of surgeons and the wider surgical team both agree and are comfortable with the application of AI within neurosurgery.",health
10.1016/j.compbiomed.2020.104150,Journal,Computers in Biology and Medicine,scopus,2021-02-01,sciencedirect,Multimodal spatio-temporal deep learning approach for neonatal postoperative pain assessment,https://api.elsevier.com/content/abstract/scopus_id/85097719224,"The current practice for assessing neonatal postoperative pain relies on bedside caregivers. This practice is subjective, inconsistent, slow, and discontinuous. To develop a reliable medical interpretation, several automated approaches have been proposed to enhance the current practice. These approaches are unimodal and focus mainly on assessing neonatal procedural (acute) pain. As pain is a multimodal emotion that is often expressed through multiple modalities, the multimodal assessment of pain is necessary especially in case of postoperative (acute prolonged) pain. Additionally, spatio-temporal analysis is more stable over time and has been proven to be highly effective at minimizing misclassification errors. In this paper, we present a novel multimodal spatio-temporal approach that integrates visual and vocal signals and uses them for assessing neonatal postoperative pain. We conduct comprehensive experiments to investigate the effectiveness of the proposed approach. We compare the performance of the multimodal and unimodal postoperative pain assessment, and measure the impact of temporal information integration. The experimental results, on a real-world dataset, show that the proposed multimodal spatio-temporal approach achieves the highest AUC (0.87) and accuracy (79%), which are on average 6.67% and 6.33% higher than unimodal approaches. The results also show that the integration of temporal information markedly improves the performance as compared to the non-temporal approach as it captures changes in the pain dynamic. These results demonstrate that the proposed approach can be used as a viable alternative to manual assessment, which would tread a path toward fully automated pain monitoring in clinical settings, point-of-care testing, and homes.",health
10.1016/j.apenergy.2020.116049,Journal,Applied Energy,scopus,2021-02-01,sciencedirect,Adaptive prognostics in a controlled energy conversion process based on long- and short-term predictors,https://api.elsevier.com/content/abstract/scopus_id/85097470918,"The pulp and paper industry is a fundamental sector of the economy of many countries. However, this sector requires real collaboration and initiatives from stakeholders to reduce its significant consumption of energy and emission of greenhouse gases. Heat exchangers are examples of equipment in pulp mills that are subjected to undesirable and complex phenomena such as evolution of fouling over time, which leads to inefficiency in terms of energy consumption and unplanned shutdowns, resulting in ineffective maintenance strategies and production costs. Therefore, there is a clear need to develop an accurate predictive maintenance tool that helps mill operators avoid such situations. It is necessary for that tool to effectively track the fouling evolution level and, based on it, deploy a reliable prognostics approach to estimate more accurately the time-to-clean of this equipment. This study presents a new hybrid prognostics approach for fouling prediction in heat exchangers. The proposed approach relies on the fusion of information of different prediction horizons to estimate the time-to-clean. Employing long short-term memory, it allows adaptation of long-term predictions by accurate short-term predictions using multiple non-linear auto-regressive exogenous models. This fusion not only captures the changes in degradation trend over time, but also ensures a good accuracy of prognostics results in both the short- and long-term horizons for planning maintenance actions. The effectiveness of the proposed approach was successfully proven on real industrial data collected from a pulp mill heat exchanger located in Canada.",health
10.1016/j.apenergy.2020.116297,Journal,Applied Energy,scopus,2021-02-01,sciencedirect,An Echo State Network for fuel cell lifetime prediction under a dynamic micro-cogeneration load profile,https://api.elsevier.com/content/abstract/scopus_id/85097452614,"Improving Proton Exchange Membrane Fuel Cell durability is a key that paves the way to its large scale industrial deployment. During the last five years, the prognostics discipline emerged as an interesting field for Proton Exchange Membrane Fuel Cell state of health prediction and lifetime estimation. The information provided by the prognostic module is crucial for optimizing the control strategy to extend the fuel cell lifetime. In this paper, an approach based on Echo State Network for fuel cell prognostics under a variable load is developed. The novelty of this paper is to perform prognostics under a variable load profile without prior knowledge of this latter. Two solutions are developed in this work. The first one consists of evaluating the remaining useful lifetime under a repeated load cycle. The second one is based on using Markov chains to generate estimations of the future load profile, allowing thus to overcome the need of real future load profile prior knowledge. Both proposed solutions give accurate prediction results of proton exchange membrane fuel cell remaining useful lifetime, with low uncertainties.",health
10.1016/j.bios.2020.112789,Journal,Biosensors and Bioelectronics,scopus,2021-02-01,sciencedirect,Multifunctional nanoplatform for dual-mode sensitive detection of pathogenic bacteria and the real-time bacteria inactivation,https://api.elsevier.com/content/abstract/scopus_id/85096478857,"Bacterial infection is a growing public health concern and causes a huge medical and financial burden. It is of significance to efficiently construct multifunctional platforms for bacterial point-of-care testing (POCT) and elimination. Herein, near-infrared (NIR) light-responded vancomycin-doped prussian blue nanoparticles (PB-VANNPs) with high efficient photothermal conversion was synthesized for binding, dual-mode portable detection, and elimination of bacteria. The PB-VANNPs can bind to the surface of Gram-positive bacteria such as Staphylococcus aureus (S. aureus), forming complex of PB-VANNPs/S. aureus. After being centrifugated, the suspension solution of PB-VANNPs can stimulate perfluorohexane (PFH) to rapidly release oxygen (O2) under NIR irradiation. Thus, the bacteria can be sensitively detected with portable pressure meter as signal reader, reporting a limit of detection (LOD) of 1.0 CFU mL-1. On the other side, the sediment of PB-VANNPs/S. aureus can be detected via thermal camera, reporting a LOD of 1.0 CFU mL-1. Interestingly, the bacteria can be effectively inactivated with the local temperature elevation during temperature-based detection. The antibacterial efficiency reaches as high as 99.8%. The developed multifunctional nanoplatform not only provides a straightforward “mix-then-test” way for portable detection of bacteria with high sensitivity, also realizes high efficiency elimination of bacteria simultaneously. The developed strategy was further applied for promoting wound healing of bacteria-infected mice.",health
10.1016/j.anucene.2020.107934,Journal,Annals of Nuclear Energy,scopus,2021-02-01,sciencedirect,Advanced fault diagnosis method for nuclear power plant based on convolutional gated recurrent network and enhanced particle swarm optimization,https://api.elsevier.com/content/abstract/scopus_id/85094324307,"A predictive approach to fault diagnosis in complex systems such as the Nuclear power plant (NPP) is becoming popular because of the efficiency and accuracy it presents. However, there is still a huge gap between the proposed fault diagnosis techniques and engineering applications. To further optimize the fault diagnosis route and encourage real-time application, this paper presents a highly accurate and adaptable fault diagnosis technique based on the convolutional gated recurrent unit (CGRU) and enhanced particle swarm optimization (EPSO). Stacking convolutional kernel and GRU results in a model that speedily extract the local characteristics and learn the time-series information. The EPSO is utilized to adaptively search for optimal hyper-parameters for the CGRU. Finally, the accuracy is evaluated on a dataset obtained from experiments, and comparative analysis of the proposed model with existing architectures and models are presented. Relevant research results that show the usefulness of the proposed model are also presented, which highlights the enhanced intelligence and information level achieved in the NPP fault diagnosis.",health
10.1016/j.micpro.2020.103301,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,IoT enabled cancer prediction system to enhance the authentication and security using cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85094168107,"In recent days, Internet of Things, Cloud Computing, Deep learning, Machine learning and Artificial Intelligence are considered to be an emerging technologies to solve variety of real world problems. These techniques are importantly applied in various fields such as healthcare systems, transportation systems, agriculture and smart cities to produce fruitful results for number of issues in today's environment. This research work focuses on one such application in the field of IoT together with cloud computing. More number of sensors that are deployed in human body is used to collect patient related data such as deviation in body temperature and others which leads to variation in blood cells that turned to be cancerous cells. Main intention of this work is design a cancer prediction system using Internet of Things upon extracting the details of blood results to test whether it is normal or abnormal. In addition to this, encryption is done on the blood results of cancer affected patient and store it in cloud for quick reference through Internet for the doctor or healthcare nurse to handle the patient data secretly. This research work concentrates on enhancing the health care computations and processing. It provides a framework to enhance the performance of the existing health care industry across the globe. As the entire medical data has to be saved in cloud, the traditional medical treatment limitations can be overcome. Encryption and decryption is done using AES algorithm in order to provide authentication and security in handling cancer patients. The main focus is to handle healthcare data effectively for the patient when they are away from the home town since the needed cancer treatment details are stored in cloud. The task completion time is greatly reduce from 400 to 160  by using VMs. CloudSim gives an adaptable simulation structure that empowers displaying and reproduced results.",health
10.1016/j.future.2020.08.038,Journal,Future Generation Computer Systems,scopus,2021-02-01,sciencedirect,An automatic multi-view disease detection system via Collective Deep Region-based Feature Representation,https://api.elsevier.com/content/abstract/scopus_id/85090344347,"With today’s growing requirements in disease diagnosis, we are constantly looking for better solutions. To meet the current demands, a disease detection system being highly effective as well as efficient is required. Existing and popular medical biometrics methods mainly focus on the local features extracted from raw medical image data, rather than study them globally. Meanwhile, prior knowledge is pre-defined in these methods so that procedures are inconsistent and require more manual operations. To address these, we present an automatic multi-view disease detection system, which contains a series of automatic procedures. The system first takes a tuple of images containing the face, tongue, and sublingual vein as the multi-view input, before directly outputting the predicted class label. To perform multi-view disease diagnosis, we propose a collective deep region-based feature representation. In summary, there are three real innovations in this paper: (1) Automated end-to-end medical biometrics system, (2) Deep region-based feature representation, (3) Multi-view multi-disease medical biometrics diagnosis. Extensive experiments were conducted on four diseases and one healthy control group using binary classification, showing both the effectiveness and efficiency of the proposed system. The average accuracy achieved was 95.8%, 96.49%, 96%, and 96.8% for breast tumor, heart disease, fatty liver, and lung tumor versus healthy control group taking 0.0031s, 0.003s, 0.0046s, and 0.0033s to process each sample respectively.",health
10.1016/j.future.2020.08.046,Journal,Future Generation Computer Systems,scopus,2021-02-01,sciencedirect,A drone-based networked system and methods for combating coronavirus disease (COVID-19) pandemic,https://api.elsevier.com/content/abstract/scopus_id/85090189689,"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus. It is similar to influenza viruses and raises concerns through alarming levels of spread and severity resulting in an ongoing pandemic worldwide. Within eight months (by August 2020), it infected 24.0 million persons worldwide and over 824 thousand have died. Drones or Unmanned Aerial Vehicles (UAVs) are very helpful in handling the COVID-19 pandemic. This work investigates the drone-based systems, COVID-19 pandemic situations, and proposes an architecture for handling pandemic situations in different scenarios using real-time and simulation-based scenarios. The proposed architecture uses wearable sensors to record the observations in Body Area Networks (BANs) in a push–pull data fetching mechanism. The proposed architecture is found to be useful in remote and highly congested pandemic areas where either the wireless or Internet connectivity is a major issue or chances of COVID-19 spreading are high. It collects and stores the substantial amount of data in a stipulated period and helps to take appropriate action as and when required. In real-time drone-based healthcare system implementation for COVID-19 operations, it is observed that a large area can be covered for sanitization, thermal image collection, and patient identification within a short period (2 KMs within 10 min approx.) through aerial route. In the simulation, the same statistics are observed with an addition of collision-resistant strategies working successfully for indoor and outdoor healthcare operations. Further, open challenges are identified and promising research directions are highlighted.",health
10.1016/j.rcim.2020.102029,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-02-01,sciencedirect,Towards manufacturing robotics accuracy degradation assessment: A vision-based data-driven implementation,https://api.elsevier.com/content/abstract/scopus_id/85088120602,"In this manuscript we report on a vision-based data-driven methodology for industrial robot health assessment. We provide an experimental evidence of the usefulness of our methodology on a system comprised of a 6-axis industrial robot, two monocular cameras and five binary squared fiducial markers. The fiducial marker system permits to accurately track the deviation of the end-effector along a fixed non-trivial trajectory. Moreover, we monitor the trajectory deflection using three gradually increasing weights attached to the end-effector. When the robot is loaded with the maximum allowed payload, a deviation of 0.77mm is identified in the Z-coordinate of the end-effector. Tracing trajectory information, we train five supervised learning regression models. Such models are afterwards used to predict the deviation of the end-effector, using the pose estimation provided by the visual tracking system. As a result of this study, we show that this procedure is a stable, robust, rigorous and reliable tool for robot trajectory deviation estimation and it even allows to identify the mechanical element producing non-kinematic errors.",health
10.1016/j.ejso.2020.04.010,Journal,European Journal of Surgical Oncology,scopus,2021-02-01,sciencedirect,Peroperative personalised decision support and analytics for colon cancer surgery- Short report,https://api.elsevier.com/content/abstract/scopus_id/85083856433,"Advanced instrumentation whether robotic or non-robotic- hasn't itself made for better surgery as all critical measures of operative success depend still on intraoperative surgeon judgement and decision-making. Computer assisted surgery, or digital surgery, refers to the combination of technology with real-time data during an operation and is often assumed to need new hardware platforms to become a reality. However, methods to support personalised surgical endeavour exist now and can be deployed today within standard laparoscopic paradigms. Here we describe in detail the rationale for the deployment of such assistance for surgical step-advancement in our current practice evolution from traditional proximal colon cancer resection to complete mesocolic excision focussing on personalised 3d anatomical display, intraoperative, quantificative fluorescence assessment of intracorporeal anastomoses and postoperative digital feedback to enable reflection and identify areas of technical improvement.",health
10.1016/j.jtbi.2020.110497,Journal,Journal of Theoretical Biology,scopus,2021-01-21,sciencedirect,An ensemble mixed effects model of sleep loss and performance,https://api.elsevier.com/content/abstract/scopus_id/85092697951,"Sleep loss causes decrements in cognitive performance, which increases risks to those in safety-sensitive fields, including medicine and aviation. Mathematical models can be formulated to predict performance decrement in response to sleep loss, with the goal of identifying when an individual may be at highest risk for an accident. This work produces an Ensemble Mixed Effects Model that combines a traditional Linear Mixed Effects (LME) model with a semi-parametric, nonlinear model called Mixed Effects Random Forest (MERF). Using this model, we predict performance on the Psychomotor Vigilance Task (PVT), a test of sustained attention, using biologically motivated features extracted from a dataset containing demographic, sleep, and cognitive test data from 44 healthy participants studied during inpatient sleep loss laboratory experiments.
                  Our Ensemble Mixed Effects Model accurately predicts an individual’s trend in PVT performance, and fits the data better than prior published models. The ensemble successfully combines MERF’s high rate of peak identification with LME’s conservative predictions. We investigate two questions relevant to this model’s potential use in operational settings: the tradeoff between additional model features versus ease of collecting these features in real-world settings, and how recent a cognitive task must have been administered to produce strong predictions.
                  This work addresses limitations of previous approaches by developing a predictive model that accounts for interindividual differences and utilizes a nonlinear, semi-parametric method called MERF. We methodologically address the modeling decisions required for this prediction problem, including the choice of cross-validation method. This work is novel in its use of data from a highly-controlled inpatient study protocol that uncouples the influence of the sleep-wake cycle from the endogenous circadian rhythm on the cognitive task being modeled. This uncoupling provides a clearer picture of the model’s real-world predictive ability for situations in which people work at different circadian times (e.g., night- or shift-work).",health
10.1016/j.ecoenv.2020.111609,Journal,Ecotoxicology and Environmental Safety,scopus,2021-01-15,sciencedirect,LncRNA loc105377478 promotes NPs-Nd<inf>2</inf>O<inf>3</inf>-induced inflammation in human bronchial epithelial cells through the ADIPOR1/NF-κB axis,https://api.elsevier.com/content/abstract/scopus_id/85095937114,"With the wide application of neodymium oxide nanoparticles (NPs-Nd2O3) in various fields, their health hazards have aroused public concern in recent years. However, data regarding the cytotoxicity of NPs-Nd2O3 is limited. In this study, we investigated the function and mechanism of long-chain non-coding RNAs (lncRNAs) in NPs-Nd2O3-induced airway inflammation. Treatment with NPs-Nd2O3 induced an inflammatory response in human bronchial epithelial cells (16HBE) by upregulating the expression of interleukin-6 (IL-6) and interleukin-8 (IL-8). The levels of LDH and intracellular ROS in the cells treated by various doses of NPs-Nd2O3 also increased significantly. After treatment with 10 μg/ml NPs-Nd2O3, RNA microarray and real-time quantitative polymerase chain reaction (qRT-PCR) showed a significant upregulation of lncRNA loc105377478. Functional experiments suggested lncRNA loc105377478 enhanced the expression of IL-6, IL-8 and ROS in NPs-Nd2O3-treated 16HBE cells, and it was further demonstrated that lncRNA loc105377478 promoted the activation of NF-κB by negatively regulating ADIPOR1 expression. Moreover, the expression of IL-6 and IL-8 in NPs-Nd2O3-treated 16HBE cells was regulated by lncRNA loc105377478, which was mediated by the NF-κB signaling pathway. In conclusion, lncRNA loc105377478 promotes NF-κB activation by negatively regulating ADIPOR1 expression, thereby upregulating the expression of IL-6 and IL-8 in 16HBE cells treated with NPs-Nd2O3.",health
10.1016/j.jep.2020.113363,Journal,Journal of Ethnopharmacology,scopus,2021-01-10,sciencedirect,Effect of weimaining on apoptosis and Caspase-3 expression in a breast cancer mouse model,https://api.elsevier.com/content/abstract/scopus_id/85091231598,"Ethnopharmacological relevance
                  Weimaining (WMN) is a condensed Tannin compound extracted from Fagopyrum cymosum (Trevir.) Meisn., which comes from the roots of buckwheat, a type of Chinese herbal medicine, was first recorded in “Bencao Shiyi”. WMN has inhibitory effects on multiple cancer types and is widely used in clinical practice; however, the mechanism underlying the anti-tumor effect of WMN is still unclear.
               
                  Aim of the study
                  To investigate the effect of WMN on the cellular activity and apoptosis of mouse breast cancer 4T1-luc2 cells, and caspase-3 and cleaved-caspase-3 expression.
               
                  Materials and methods
                  Luciferase-labeled mouse breast cancer 4T1-luc2 cells were inoculated into the mouse breast pad to establish a luciferase-labeled mouse breast cancer cell model. BALB/C-nu mice were randomly divided into model, WMN, and low-molecular-weight heparin (LMWH) groups (n = 10). Another 10 mice served as the normal control group (no cancer cell injection). The WMN group was administered WMN 250 mg/kg per day for 14 days, the LMWH group was given LMWH (1500 U/kg) daily for 14 days by intraperitoneal injection, and the model and normal control groups were given an equal dose of 0.9% NaCl. The number and distribution of transplanted tumors in 4T1-luc2 breast cancer cells were observed in nude mice by an in vivo imaging system at the time of inoculation after successful modeling, and on days 7 and 14 after drug administration. Tumor cell apoptosis was detected by the terminal deoxynucleotidyl transferase dUTP nick end labeling (TUNEL) method; caspase-3 mRNA expression was detected by RT-PCR and Western blotting was applied to detect the levels of caspase-3 and cleaved-caspase-3 protein expression.
               
                  Results
                  The apoptosis index (AI) of the WMN group was detected by the TUNEL method, and the AI increased with the increase of treatment time. Compared with the model group, the mRNA expression of caspase-3 and the protein levels of caspase-3 and cleaved-caspase-3 were notably elevated in the WMN group. After in vivo bioluminescent imaging, the total photon number of the WMN group was found to be lower than that of the LWMH group on day 14 after administration. Additionally, the AI and expression levels of caspase-3 mRNA, caspase-3, and cleaved-caspase-3 protein of the WMN group were higher than those of the LWMH group.
               
                  Conclusion
                  WMN can effectively suppress the growth of 4T1-luc2 breast cancer xenografts in mice, and promote the apoptosis of breast cancer cells by upregulating the expression of caspase-3.",health
10.1016/j.jep.2020.113075,Journal,Journal of Ethnopharmacology,scopus,2021-01-10,sciencedirect,Commiphora myrrha stimulates insulin secretion from mouse and human islets of Langerhans,https://api.elsevier.com/content/abstract/scopus_id/85089844285,"Ethnopharmacological relevance
                  Traditionally plant-based remedies such as Commiphora myrrha (CM) have been used as an ayurvedic medicine to treat diabetes mellitus in some region of Arabia and Africa. Previous reports have shown that CM reduced blood glucose levels and increased insulin concentrations in animal models of diabetes in vivo. However, the exact mechanisms by which CM improved glycemic control in these animals are not fully understood. We hypothesized that CM may have a direct insulinotropic activity on β-cells to increase insulin secretion.
               
                  Aim of the study
                  The direct effects of CM were investigated using MIN6 β-cells and isolated mouse and human islets in static and perifusion insulin secretion experiments. Isolated mouse and human islets were used to investigate the rate and pattern of CM-induced insulin secretion.
               
                  Materials and methods
                  The effect of CM on insulin secretion was assessed by static and perifusion experiments using MIN6 cells, a mouse-derived β-cell line, and primary mouse and human islets. The effects of CM on cell viability and membrane integrity of MIN6 cells and mouse islets were assessed using an ATP viability assay and a trypan blue exclusion test. The mRNA expression profiles of preproinsulin and Pdx1, a major β-cell transcription factor, were determined by quantitative RT-PCR following chronic exposure to CM.
               
                  Results
                  Exposing MIN6 cells to a CM resin solution (0.5–10 mg/ml) caused a concentration-dependent increase in insulin secretion in a static setting. Similarly, incubating mouse islets to CM (0.1–10 mg/ml) resulted in stimulation of insulin secretion in a concentration-dependent manner. CM concentrations at ≤ 2 mg/ml were not associated with reduction in cell viability nor with reduction in cell membrane integrity. However, higher concentrations of CM were accompanied with marked uptake of trypan blue dye and cell death. In a perifusion setting, CM (2 mg/ml) caused rapid and reversible increases in insulin secretion from both mouse and human islets at both sub-stimulatory and stimulatory glucose levels. The stimulatory effect of CM on insulin secretion did not change the total insulin content of β-cells nor the mRNA expression of preproinsulin and Pdx1.
               
                  Conclusions
                  These data indicate that aqueous CM resin solution has a direct stimulatory effect on β-cells without compromising plasma membrane integrity. CM stimulates insulin secretion from MIN6 cells, a mouse-derived β-cell line, and isolated primary mouse and human islets in vitro at both sub-stimulatory and stimulatory glucose concentrations. The mechanism by which CM may induce insulin secretion is most likely due to a stimulation of insulin granules release rather than insulin synthesis.",health
10.1016/j.neucom.2020.08.064,Journal,Neurocomputing,scopus,2021-01-08,sciencedirect,Learning from class-imbalance and heterogeneous data for 30-day hospital readmission,https://api.elsevier.com/content/abstract/scopus_id/85092076089,"Predicting 30-day hospital readmission is a core research task in the development of personalized healthcare. However, the imbalanced class distribution and the heterogeneity of electronic health records are the major challenges to establish an effective machine learning model for this task. To overcome these issues, we propose a new 30-day readmission prediction algorithm to improve the performance. First, we solve the problem of class-imbalance readmission prediction by learning sample weights based on hypothesis margin loss. At the same time, we consider the character of data heterogeneity, and learn the weights of heterogeneous data sources to improve the generalization ability. Based on this, we construct an optimization framework, which involves two variables, i.e., sample weights and source weights. By iterative optimization, we obtain the prediction result for readmission. Finally, we conduct experiments on three real-world readmission datasets to verify the effectiveness of the proposed method. The experimental results show that the proposed algorithm has the advantages to deal with the task of 30-day hospital readmission prediction.",health
10.1016/j.ijpharm.2020.120028,Journal,International Journal of Pharmaceutics,scopus,2021-01-05,sciencedirect,Optimization and evaluation of propolis liposomes as a promising therapeutic approach for COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85095979631,"The present work aimed to develop an optimized liposomal formulation for enhancing the anti-viral activity of propolis against COVID-19. Docking studies were performed for certain components of Egyptian Propolis using Avigan, Hydroxychloroquine and Remdesivir as standard antivirals against both COVID-19 3CL-protease and S1 spike protein. Response surface methodology and modified injection method were implemented to maximize the entrapment efficiency and release of the liposomal formulation. The optimized formulation parameters were as follow: LMC of 60 mM, CH% of 20% and DL of 5 mg/ml. At those values the E.E% and released % were 70.112% and 81.801%, respectively with nanosized particles (117 ± 11 nm). Docking studies revealed that Rutin and Caffeic acid phenethyl ester showed the highest affinity to both targets. Results showed a significant inhibitory effect of the optimized liposomal formula of Propolis against COVID-3CL protease (IC50 = 1.183 ± 0.06) compared with the Egyptian propolis extract (IC50 = 2.452 ± 0.11), P < 0.001. Interestingly, the inhibition of viral replication of COVID-19 determined by RT_PCR has been significantly enhanced via encapsulation of propolis extract within the liposomal formulation (P < 0.0001) and was comparable to the viral inhibitory effect of the potent antiviral (remdesivir). These findings identified the potential of propolis liposomes as a promising treatment approach against COVID-19.",health
10.1016/j.procs.2021.09.145,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,"Architecture and organization of a Platform for diagnostics, therapy and post-covid complications using AI and mobile monitoring",https://api.elsevier.com/content/abstract/scopus_id/85116935586,"Infectious diseases accompanied mankind throughout its existence. However, in the 20th century, with the implementation od mass vaccination, this problem was partially forgotten. It reappeared at the end of the 2019 with the COVID-19 pandemic. The diseases are associated with high mortality, the main causes of which are: respiratory failure, acute respiratory distress syndrome, thrombotic complications, etc. As many centuries ago, the key to fighting a pandemic is to diagnose patients with infections as quickly as possible, isolate them, and implement treatment procedures. In this paper we propose a Platform supporting medics in the fight against epidemic. Unlike alternative systems, the proposed IT Platform will ultimately cover all areas of fighting against COVID-19, from the diagnosis of infection, through treatment, to rehabilitation of post-disease complications. Like most clinical information systems, the Platform is based on Artificial Intelligence, in particular Federated Learning. Also, unlike known solutions, it uses all available historical data of the patient’s health and information from real-time mobile diagnostics, using cellular communication and Internet of Things solutions. Such solutions could be helpful in fighting against any future mass infections.",health
10.1016/j.nicl.2021.102849,Journal,NeuroImage: Clinical,scopus,2021-01-01,sciencedirect,Minimum detectable spinal cord atrophy with automatic segmentation: Investigations using an open-access dataset of healthy participants,https://api.elsevier.com/content/abstract/scopus_id/85116485665,"Spinal cord atrophy is a well-known biomarker in multiple sclerosis (MS) and other diseases. It is measured by segmenting the spinal cord on an MRI image and computing the average cross-sectional area (CSA) over a few slices. Introduced about 25 years ago, this procedure is highly sensitive to the quality of the segmentation and is prone to rater-bias. Recently, fully-automated spinal cord segmentation methods, which remove the rater-bias and enable the automated analysis of large populations, have been introduced. A lingering question related to these automated methods is: How reliable are they at detecting atrophy? In this study, we evaluated the precision and accuracy of automated atrophy measurements by simulating scan-rescan experiments.
                  Spinal cord MRI data from the open-access spine-generic project were used. The dataset aggregates 42 sites worldwide and consists of 260 healthy subjects and includes T1w and T2w contrasts. To simulate atrophy, each volume was globally rescaled at various scaling factors. Moreover, to simulate patient repositioning, random rigid transformations were applied. Using the DeepSeg algorithm from the Spinal Cord Toolbox, the spinal cord was segmented and vertebral levels were identified. Then, the average CSA between C3-C5 vertebral levels was computed for each Monte Carlo sample, allowing us to derive measures of atrophy, intra/inter-subject variability, and sample-size calculations.
                  The minimum sample size required to detect an atrophy of 2% between unpaired study arms, commonly seen in MS studies, was 467 +/− 13.9 using T1w and 467 +/− 3.2 using T2w images. The minimum sample size to detect a longitudinal atrophy (between paired study arms) of 0.8% was 60 +/− 25.1 using T1w and 10 +/− 1.2 using T2w images. At the intra-subject level, the estimated CSA, observed in this study, showed good precision compared to other studies with COVs (across Monte Carlo transformations) of 0.8% for T1w and 0.6% for T2w images.
                  While these sample sizes seem small, we would like to stress that these results correspond to a “best case” scenario, in that the dataset used here was of particularly good quality and the model for simulating atrophy does not encompass all the variability met in real-life datasets. The simulated atrophy and scan-rescan variability may over-simplify the biological reality. The proposed framework is open-source and available at https://csa-atrophy.readthedocs.io/.",health
10.1016/j.csbj.2021.08.048,Journal,Computational and Structural Biotechnology Journal,scopus,2021-01-01,sciencedirect,Automated metabolic assignment: Semi-supervised learning in metabolic analysis employing two dimensional Nuclear Magnetic Resonance (NMR),https://api.elsevier.com/content/abstract/scopus_id/85115236580,"Metabolomics is an expanding field of medical diagnostics since many diseases cause metabolic reprogramming alteration. Additionally, the metabolic point of view offers an insight into the molecular mechanisms of diseases. Due to the complexity of metabolic assignment dependent on the 1D NMR spectral analysis, 2D NMR techniques are preferred because of spectral resolution issues. Thus, in this work, we introduce an automated metabolite identification and assignment from 1H-1H TOCSY (total correlation spectroscopy) using real breast cancer tissue. The new approach is based on customized and extended semi-supervised classifiers: KNFST, SVM, third (PC3) and fourth (PC4) degree polynomial. In our approach, metabolic assignment is based only on the vertical and horizontal frequencies of the metabolites in the 1H–1H TOCSY. KNFST and SVM show high performance (high accuracy and low mislabeling rate) in relatively low size of initially labeled training data. PC3 and PC4 classifiers showed lower accuracy and high mislabeling rates, and both classifiers fail to provide an acceptable accuracy at extremely low size (≤9% of the entire dataset) of initial training data. Additionally, semi-supervised classifiers were implemented to obtain a fully automatic procedure for signal assignment and deconvolution of TOCSY, which is a big step forward in NMR metabolic profiling. A set of 27 metabolites were deduced from the TOCSY, and their assignments agreed with the metabolites deduced from a 1D NMR spectrum of the same sample analyzed by conventional human-based methodology.",health
10.1016/j.procs.2021.07.059,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,PlantifyAI: A Novel Convolutional Neural Network Based Mobile Application for Efficient Crop Disease Detection and Treatment,https://api.elsevier.com/content/abstract/scopus_id/85115224350,"Crop diseases are a major threat to human food security. Around the world, more than 80% of agricultural production is generated by farmers, and over 50% of their yield is lost due to pests and pathogens, leading to mass disruption in food supply and a large number of hungry people. Identifying a disease correctly is a crucial first step for efficient treatment but remains difficult in many parts of the world due to limited access to agricultural experts and professional infrastructure. The purpose of this research was to create a free, easy-to-use, and widely accessible mobile application that efficiently and accurately, diagnoses 26 diseases of 14 crop species. Furthermore, this application provides treatment steps, common symptoms, and access to recommended curing products for each disease. The real-time crop disease diagnosis is based on a convolutional neural network (CNN) that was trained, validated, and tested on a dataset of 87,860 leaf images split into 38 classes. To design an optimal CNN, 16 different CNNs were designed and tested. MobileNetV2 using the Canny Edge Detection filter was chosen as it had the highest classification accuracy of 95.7% and an F1 score of 96.1. Multi-level testing and data analysis was conducted for this application, it has been verified to be functional in the real world through field testing at local garden centers. This application is a novel and accessible tool for crop disease management and can be deployed as a free service to farmers for ecologically sustainable production, overall increasing food security.",health
10.1016/j.matpr.2021.03.109,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Real-time applications and novel manufacturing strategies of incremental forming: An industrial perspective,https://api.elsevier.com/content/abstract/scopus_id/85114180763,"Incremental Sheet-Metal Forming (ISMF) is a flexible and evolving metal forming technology for rapid free-form prototyping and small-batch metal components manufacturing. The end product has evolved by means of localized deformation in addition bi-axial stretching during that deforming tool squeezed on blank with predefined process variables. Owing to a unique process advantages and low manufacturing cost, its market requirement continuous enlargement and the process gradually transforms from prototyping to real-time manufacturing perspective. Over the preceding decades, ISMF technology has been adequately established in research and development, although it is less explored in the real-time industrial environment. The main intention of this exploration is to bring-forth insight into potential applications such as aviation, automotive, bio-medical, research and concept development through implementation of ISMF. Further, component evaluation performed to establish a convenient and feasible solution from deep-drawing and hydro-forming. For customized part forming, conventional forming process seems to be insufficient. Due to industrial transformation, dependent on cost-effectiveness, even prototyping and low-volume manufactured components relying on superior quality. Although, understanding the effect and influence of process variable, which needs the data analysis with implementing the optimization models and Artificial neural-network (ANN) model. These types of analysis majorly focus on monitoring and predict target values at each cycle and also reconfigure to optimistic or organize the iterative method for describing the appropriate process guidelines. Further, recent advances in ISMF process variants are explored, while looking at the benefits of ISMF for real-time part production. ISMF continues to mature into technology for production applications, while exploring the potential field to transform the way sheet components are fabricated in the new-era of digital manufacturing. This study will, in turn, enhance the capabilities of ISMF technology, which has grown significantly over the preceding decades, allowing technology adopters to innovate new design principle and achieve greater production flexibility.",health
10.1016/j.matpr.2021.03.658,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Predictive analytics as a service for vehicle health monitoring using edge computing and AK-NN algorithm,https://api.elsevier.com/content/abstract/scopus_id/85114146905,"Smart logistics is a part of Industry 4.0. With the increased development of the technology in the vehicle industry, the machine learning algorithms are applied on sensor data in order to detect the failure of the components of the vehicle. Several systems for vehicle health monitoring are presented in the literature for delivery of services in real-time. The sensor values obtained from the cloud are processed with machine learning algorithms, but have problem with delay in execution and data center failure. Edge computing is introduced in recent years so that intensive operations are performed at the edge of the device than at the cloud. This paper presents edge computing based fault prediction system that will predict vehicle health using internal and external sensors in real-time. Risk details are displayed through a mobile application in the form of notifications as well as a dashboard at the terminal. Such a system reduces latency between sending and processing vehicle data. The proposed system uses ensemble of ANN and k-NN classifiers named as AK-NN so as to improve prediction performance. In the first step, ANN is trained and validated on the Chevrolet car OBD dataset. Error reported from this best trained network is used by k-NN for statistical analysis of the error distributions. Three different experiments based on ANN, k-NN and AK-NN are made and evaluated using NRMSE, COD, cross entropy loss, accuracy and ROC measures. 85% accuracy for k-NN model when k = 3, 78% accuracy using ANN and 98.7% for ensemble method are achieved. Comparative study using key performance indicators such as Mean time between failure (MTBF) and Mean time to Repair (MTTR) is also made on 84 vehicles for prediction alert over mobile phone using analytical dashboard and proved to reach availability objective.",health
10.1016/j.imu.2021.100690,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,Performance analysis of cost-sensitive learning methods with application to imbalanced medical data,https://api.elsevier.com/content/abstract/scopus_id/85111923392,"Many real-world machine learning applications require building models using highly imbalanced datasets. Usually, in medical datasets, the healthy patients or samples are dominant, making them the majority class, while the sick patients are few, making them the minority class. Researchers have proposed numerous machine learning methods to predict medical diagnosis. Still, the class imbalance problem makes it difficult for classifiers to adequately learn and distinguish between the minority and majority classes. Cost-sensitive learning and resampling techniques are used to deal with the class imbalance problem. This research focuses on developing robust cost-sensitive classifiers by modifying the objective functions of some well-known algorithms, such as logistic regression, decision tree, extreme gradient boosting, and random forest, which are then used to efficiently predict medical diagnosis. Meanwhile, as opposed to resampling techniques, our approach does not alter the original data distribution. Firstly, we implement the standard versions of these algorithms to provide a baseline for performance comparison. Secondly, we develop their corresponding cost-sensitive algorithms. For the proposed approaches, it is not necessary to change the distribution of the original data as the modified algorithms consider the imbalanced class distribution during training, thereby resulting in more reliable performance than when the data is resampled. Four popular medical datasets, including the Pima Indians Diabetes, Haberman Breast Cancer, Cervical Cancer Risk Factors, and Chronic Kidney Disease datasets, are used in the experiments to validate the performance of the proposed approach. The experimental results show that the cost-sensitive methods yield superior performance compared to the standard algorithms.",health
10.1016/j.aej.2021.06.024,Journal,Alexandria Engineering Journal,scopus,2021-01-01,sciencedirect,"Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath",https://api.elsevier.com/content/abstract/scopus_id/85109458695,"The problem of respiratory sound classification has received good attention from the clinical scientists and medical researcher’s community in the last year to the diagnosis of COVID-19 disease. The Artificial Intelligence (AI) based models deployed into the real-world to identify the COVID-19 disease from human-generated sounds such as voice/speech, dry cough, and breath. The CNN (Convolutional Neural Network) is used to solve many real-world problems with Artificial Intelligence (AI) based machines. We have proposed and implemented a multi-channeled Deep Convolutional Neural Network (DCNN) for automatic diagnosis of COVID-19 disease from human respiratory sounds like a voice, dry cough, and breath, and it will give better accuracy and performance than previous models. We have applied multi-feature channels such as the data De-noising Auto Encoder (DAE) technique, GFCC (Gamma-tone Frequency Cepstral Coefficients), and IMFCC (Improved Multi-frequency Cepstral Coefficients) methods on augmented data to extract the deep features for the input of the CNN. The proposed approach improves system performance to the diagnosis of COVID-19 disease and provides better results on the COVID-19 respiratory sound dataset.",health
10.1016/j.inpa.2021.06.001,Journal,Information Processing in Agriculture,scopus,2021-01-01,sciencedirect,ResTS: Residual Deep interpretable architecture for plant disease detection,https://api.elsevier.com/content/abstract/scopus_id/85108257140,"Recently many methods have been induced for plant disease detection by the influence of Deep Neural Networks in Computer Vision. However, the dearth of transparency in these types of research makes their acquisition in the real-world scenario less approving. We propose an architecture named ResTS (Residual Teacher/Student) that can be used as visualization and a classification technique for diagnosis of the plant disease. ResTS is a tertiary adaptation of formerly suggested Teacher/Student architecture. ResTS is grounded on a Convolutional Neural Network (CNN) structure that comprises two classifiers (ResTeacher and ResStudent) and a decoder. This architecture trains both the classifiers in a reciprocal mode and the conveyed representation between ResTeacher and ResStudent is used as a proxy to envision the dominant areas in the image for categorization. The experiments have shown that the proposed structure ResTS (F1 score: 0.991) has surpassed the Teacher/Student architecture (F1 score: 0.972) and can yield finer visualizations of symptoms of the disease. Novel ResTS architecture incorporates the residual connections in all the constituents and it executes batch normalization after each convolution operation which is dissimilar to the formerly proposed Teacher/Student architecture for plant disease diagnosis. Residual connections in ResTS help in preserving the gradients and circumvent the problem of vanishing or exploding gradients. In addition, batch normalization after each convolution operation aids in swift convergence and increased reliability. All test results are attained on the PlantVillage dataset comprising 54 306 images of 14 crop species.",health
10.1016/j.egyr.2021.05.046,Journal,Energy Reports,scopus,2021-01-01,sciencedirect,Cascaded feature enhancement network model for real-time video monitoring of power system,https://api.elsevier.com/content/abstract/scopus_id/85108078296,"The application of real-time monitoring has been widely used to detect the safety and stability of the electric power system. Traditional monitoring relies heavily on human judgment and is impossible to detect status in real-time. Recently, with the development of deep learning, the object detection algorithm based on the deep convolutional neural network becomes a great option for realizing real-time monitoring applications of the power system. However, in power system scenarios, failed or unreal-time detection of abnormal conditions may cause a hazardous accident. To apply and optimize the object detection algorithm, issues such as multi-scale objects, class imbalance, and difficulty in balance speed and accuracy need to be addressed to improve the detection performance. Thus, we present a cascaded feature enhancement network model that combining attention mechanism, feature fusion scheme, and Cascaded Refinement Scheme. Attention mechanism and feature fusion scheme can help extract more effective feature information of multi-scale objects. Cascaded Refinement Scheme can effectively solve the problem of class imbalance. The whole model can well balanced in detect speed and accuracy. Experiments are performed on two benchmarks: PSA_Datasets and PASCAL VOC. Our method gets an absolute gain of 1.6% (300
                        ×
                     300 input), 2.6% (512
                        ×
                     512 input) in terms of mAP result of PSA_Datasets and 1% (300
                        ×
                     300 input), 1.6% (512
                        ×
                     512 input) in PASCAL VOC Dataset, compared to the best results of other SOTA detectors.",health
10.1016/j.procir.2021.05.031,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Artificial intelligence enhanced interaction in digital twin shop-floor,https://api.elsevier.com/content/abstract/scopus_id/85107885361,"As an enabling technology for smart manufacturing, digital twin has been widely applied in manufacturing shop-floor. A great deal of research focuses on the key issues in implementing digital twin shop-floor (DTS), including scheduling, production planning, fault diagnosis and prognostics. However, DTS puts forward higher requirements in terms of real-time interaction. Artificial intelligence (AI), as an effective approach to improve the intelligence of the physical shop-floor, provides a new method to meet the above requirements. In this paper, a framework of AI-enhanced DTS in interaction is proposed. AI-enhanced DTS improves the real-time interaction through predictive control. The implementation mechanism of AI-enhanced interaction in DTS is also presented in detail. Enabling technologies for interaction in DTS are introduced at last.",health
10.1016/j.nicl.2021.102707,Journal,NeuroImage: Clinical,scopus,2021-01-01,sciencedirect,icobrain ms 5.1: Combining unsupervised and supervised approaches for improving the detection of multiple sclerosis lesions,https://api.elsevier.com/content/abstract/scopus_id/85107640291,"Multiple sclerosis (MS) is a chronic autoimmune, inflammatory neurological disease of the central nervous system. Its diagnosis nowadays commonly includes performing an MRI scan, as it is the most sensitive imaging test for MS. MS plaques are commonly identified from fluid-attenuated inversion recovery (FLAIR) images as hyperintense regions that are highly varying in terms of their shapes, sizes and locations, and are routinely classified in accordance to the McDonald criteria. Recent years have seen an increase in works that aimed at development of various semi-automatic and automatic methods for detection, segmentation and classification of MS plaques. In this paper, we present an automatic combined method, based on two pipelines: a traditional unsupervised machine learning technique and a deep-learning attention-gate 3D U-net network. The deep-learning network is specifically trained to address the weaker points of the traditional approach, namely difficulties in segmenting infratentorial and juxtacortical plaques in real-world clinical MRIs. It was trained and validated on a multi-center multi-scanner dataset that contains 159 cases, each with T1 weighted (T1w) and FLAIR images, as well as manual delineations of the MS plaques, segmented and validated by a panel of raters. The detection rate was quantified using lesion-wise Dice score. A simple label fusion is implemented to combine the output segmentations of the two pipelines. This combined method improves the detection of infratentorial and juxtacortical lesions by 14% and 31% respectively, in comparison to the unsupervised machine learning pipeline that was used as a performance assessment baseline.",health
10.1016/j.matpr.2021.02.348,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Predictive analytics of bridge safety for intelligent transportation system using ensemble model,https://api.elsevier.com/content/abstract/scopus_id/85107404137,"Bridges are the main links for many transportation systems. Many of the bridges built are subjected to deterioration but are still in use. Factors like heavy weights imposed by vehicles, pressure of water and depreciation effect the lifetime of the bridges. This may lead to various disasters endangering the lives of people. Hence continuous monitoring of bridges using real time bridge data is required to predict bridge safety and alert user passing by the bridge. Existing bridge safety monitoring systems are either Sensor based or uses specialized equipment to monitor safety using frequencies of vibration. Such systems are expensive and have low performance. Traditional prediction algorithms from data mining and regression modeling can help in correlation between input parameters and bridge condition using historical data. They have difficulty either in scaling of data or may not adapt to dynamic changes in input data. Mobile app based system that uses ensemble of both Artificial Neural Network (ANN) and Gaussian Process Regression (GPR) is proposed in this paper to predict bridge safety. This paper signifies on the structural health monitoring of the bridge and the potential advantage of integrating Artificial Intelligence based predictive analytics into IoT sensors to assess the bridge safety. Three different experiments based on ANN, GPR and ensemble of ANN,GPR are made. In the first step, ANN is trained and validated on two datasets with different scenario (Indian and U.S.A). Error reported from this best trained network is used by GPR for statistical analysis of the error distributions. This combined system based mobile app is evaluated using NRMSE, COD and cross entropy loss measures. Test results proved that, the third hyper-parameter values of ensemble model yielded a good result with less error rate than ANN and GPR predictive models.",health
10.1016/j.matpr.2020.11.261,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Analysis and control of the motor vibration using arduino and machine learning model,https://api.elsevier.com/content/abstract/scopus_id/85107352700,"The motor vibrations provide information for diagnosing and predicting errors through signal processing. Motor vibrations provide information for diagnosing and predicting errors through data signal. In this article, we introduce an IoT-based detecting scheme for recording the vibration of an induction motor. A three different sensor such as vibration, Micro-Electro-Mechanical Systems (MEMS) and temperature sensor is used to gather the data from the motor vibration. We conducted an experiment by analysing the motor vibration by using Arduino, when the motor vibration is going to abnormal at that time Arduino send the signal to relay by cutting the supply to the motor. However, the motor running on proper condition with proper temperature, the controller is continuously monitoring and forward the data to storage system. The results can presentation on the mobile phone. The experiments were performed in the steady-state condition and the measured vibration signals were analysed using the Discrete Fourier Transform (DFT). Depend on the outcomes of the proposed model, which greatly monitor and early diagnosis the motor vibration, and performance was analysed by using the Machine Learning model of Decision Tree (DT). The controller can forward the vibration data the cloud with a maximum delay of about 0.9 sec. the stored data is retrieved by using the train the DT model to analysis the performance classification accuracy. This article introduces a new method for implementing real-time vibration measurement and analysis tools based on MATLAB.",health
10.1016/j.procs.2021.03.025,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Lightweight photoplethysmography quality assessment for real-time IoT-based health monitoring using unsupervised anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/85106733954,"Real-time remote health monitoring is dramatically growing, revolutionizing healthcare delivery and outcome in everyday settings. Such remote services enable monitoring individuals anywhere and anytime, allowing diseases early detection and prevention. Photoplethysmography (PPG) is a non-invasive and convenient technique that enables tracking vital signs such as heart rate, heart rate variability, respiration rate, and blood oxygen saturation. PPG is broadly used in various clinical and commercial wearable devices, as it is easy-to-implement and low-cost. However, the technique is highly susceptible to motion artifacts and environmental noises, which distort the collected signals. Therefore, the signal quality needs to be investigated, and unreliable signals should be discarded. In the literature, rule-based and machine learning-based PPG quality assessment methods have been investigated in several studies. However, the rule-based methods are mostly inaccurate in remote health monitoring, where users engage in different physical activities. The supervised machine learning-based methods –including deep learning–are also infeasible for real-time monitoring applications since they are slow and are dependent on a massive pool of annotated data to train the model. In this paper, we introduce a PPG quality assessment method, enabled by an elliptical envelope, which requires low computational resources. The method clusters the PPG signals into two groups as “reliable” and “unreliable.” We also investigate various features extracted from the PPG signals. Five features with the highest scoring values are selected to be fed to the elliptical envelope model. Moreover, we assess the performance of the proposed method in terms of accuracy and execution time, using data collected in free-living conditions via an Internet-of-Things-based health monitoring system enabled by smart wristbands. The method is evaluated in comparison to a state-of-the-art PPG quality assessment method. We also provide the model implemented in Python for the community to be used in their solutions.",health
10.1016/j.procs.2021.03.070,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Using deep learning model for adapting and managing covid-19 pandemic crisis,https://api.elsevier.com/content/abstract/scopus_id/85106702825,"The purpose of current paper is to create a smart and effective tool for telemedicine to early detect and diagnose COVID-19 disease and therefore help to manage Pandemic Crisis (MCPC) in Sultanate of Oman, as a tool for future pandemic containment. In this paper, we used tools to create robust models in real-time to support Telemedicine, it is Machine Learning (ML), Deep Learning (DL), Convolutional Neural Networks using Tensorflow (CNN-TF), and CNN Deployment. These models will assist telemedicine, 1) developing Automated Medical Immediate Diagnosis service (AMID). 2) Analysis of Chest X-rays image (CXRs). 3) Simplifying Classification of confirmed cases according to its severity. 4) Overcoming the lack of experience, by improving the performance of medical diagnostics and providing recommendations to the medical staff. The results show that the best Regression among the five Regression models is Random Forest Regression. while the best classification among the eight classification models and Recurrent Neural Network using Tensorflow (RNNTF) is Random Forest classification, and the best Clustering model among two Clustering models is K-Means++. Furthermore, CNN-TF model was able to discriminate between those with positive cases Covid-19 and those with negative cases.",health
10.1016/j.isatra.2021.05.019,Journal,ISA Transactions,scopus,2021-01-01,sciencedirect,An evolving neuro-fuzzy classifier for fault diagnosis of gear systems,https://api.elsevier.com/content/abstract/scopus_id/85106378114,"Gear systems (or gearboxes) are widely used in rotating machinery. Reliable gear fault diagnostic techniques and systems are critically needed to provide early warning of a possible defect so as to prevent machinery operation degradation and to reduce costs related to predictive maintenance. In this work, a new evolving neuro-fuzzy (eNF) classifier is proposed for real-time gear system fault diagnostics. In evolving process, the constraints related to gear health states are used to guide the partition of the output space, to prevent possible misleading clusters. A new training algorithm based on the normalized Adadelta function is suggested to improve eNF training convergence and accuracy. The effectiveness of the proposed eNF classifier is tested by simulation and experiment tests.",health
10.1016/j.imu.2021.100591,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,The diagnostic accuracy of Artificial Intelligence-Assisted CT imaging in COVID-19 disease: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85105522693,"Artificial intelligence (AI) systems have become critical in support of decision-making. This systematic review summarizes all the data currently available on the AI-assisted CT-Scan prediction accuracy for COVID-19. The ISI Web of Science, Cochrane Library, PubMed, Scopus, CINAHL, Science Direct, PROSPERO, and EMBASE were systematically searched. We used the revised Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool to assess all included studies' quality and potential bias. A hierarchical receiver-operating characteristic summary (HSROC) curve and a summary receiver operating characteristic (SROC) curve have been implemented. The area under the curve (AUC) was computed to determine the diagnostic accuracy. Finally, 36 studies (a total of 39,246 image data) were selected for inclusion into the final meta-analysis. The pooled sensitivity for AI was 0.90 (95% CI, 0.90–0.91), specificity was 0.91 (95% CI, 0.90–0.92) and the AUC was 0.96 (95% CI, 0.91–0.98). For deep learning (DL) method, the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.88 (95% CI, 0.87–0.88) and the AUC was 0.96 (95% CI, 0.93–0.97). In case of machine learning (ML), the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.95 (95% CI, 0.94–0.95) and the AUC was 0.97 (95% CI, 0.96–0.99). AI in COVID-19 patients is useful in identifying symptoms of lung involvement. More prospective real-time trials are required to confirm AI's role for high and quick COVID-19 diagnosis due to the possible selection bias and retrospective existence of currently available studies.",health
10.1016/j.procs.2021.02.012,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,The impact of the soft errors in convolutional neural network on GPUS: Alexnet as case study,https://api.elsevier.com/content/abstract/scopus_id/85105461752,"Convolutional Neural Networks (CNNs) have been increasingly deployed in many applications, including safety critical system such as healthcare and autonomous vehicles. Meanwhile, the vulnerability of CNN model to soft errors (e.g., caused by radiation induced) rapidly increases, thus reliability is crucial especially in real-time system. There are many traditional techniques for improve the reliability of the system, e.g., Triple Modular Redundancy, but these techniques incur high overheads, which makes them hard to deploy. In this paper, we experimentally evaluate the vulnerable parts of Alexnet mode (e.g., fault injector). Results show that FADD and LD are the top vulnerable instructions against soft errors for Alexnet model, both instructions generate at least 84% of injected faults as SDC errors. Thus, these the only parts of the Alexnet model that need to be hardened instead of using fully duplication solutions.",health
10.1016/j.procs.2021.03.075,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Input doubling method based on SVR with RBF kernel in clinical practice: Focus on small data,https://api.elsevier.com/content/abstract/scopus_id/85104314419,"In recent years, machine-learning-based approaches have become of considerable interest to the efficient processing of short or limited data samples. Its so-called small data approach. This is due to the significant growth of new intellectual analysis tasks in various industries, which are characterized by limited historical data. These include Materials Science, Economics, Medicine, and so on. An effective processing of short datasets is especially acute in medicine. Insufficient number of vectors, significant gaps in the data collected during the supervision of patient’s treatment or rehabilitation, reduces the effectiveness or prevents effective intellectual analysis based on them. This paper presents a new approach to processing short medical data samples. The basis of the developed method is SVR with RBF kernel. The algorithmic implementation of the method in both operation modes is described. Experimental modeling on a real short data set (Trabecular bone data) is conducted. It contained only 35 observations. A comparison of the method with a number of existing machine learning methods is conducted. It is experimental established the highest accuracy of the method among those considered. The developed method has potential opportunities for wide application in various fields of medicine.",health
10.1016/j.imu.2021.100566,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,COVID-19 prediction using LSTM algorithm: GCC case study,https://api.elsevier.com/content/abstract/scopus_id/85104093246,"Coronavirus-19 (COVID-19) is the black swan of 2020. Still, the human response to restrain the virus is also creating massive ripples through different systems, such as health, economy, education, and tourism. This paper focuses on research and applying Artificial Intelligence (AI) algorithms to predict COVID-19 propagation using the available time-series data and study the effect of the quality of life, the number of tests performed, and the awareness of citizens on the virus in the Gulf Cooperation Council (GCC) countries at the Gulf area. So we focused on cases in the Kingdom of Saudi Arabia (KSA), United Arab of Emirates (UAE), Kuwait, Bahrain, Oman, and Qatar. For this aim, we accessed the time-series real-datasets collected from Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). The timeline of our data is from January 22, 2020 to January 25, 2021. We have implemented the proposed model based on Long Short-Term Memory (LSTM) with ten hidden units (neurons) to predict COVID-19 confirmed and death cases. From the experimental results, we confirmed that KSA and Qatar would take the most extended period to recover from the COVID-19 virus, and the situation will be controllable in the second half of March 2021 in UAE, Kuwait, Oman, and Bahrain. Also, we calculated the root mean square error (RMSE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and death cases are 320.79 and 1.84, respectively, and both are related to Bahrain. While the worst values are 1768.35 and 21.78, respectively, and both are related to KSA. On the other hand, we also calculated the mean absolute relative errors (MARE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and deaths cases are 37.76 and 0.30, and these are related to Kuwait and Qatar respectively. While the worst values are 71.45 and 1.33, respectively, and both are related to KSA.",health
10.1016/j.imu.2021.100564,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,"Machine learning approaches in COVID-19 diagnosis, mortality, and severity risk prediction: A review",https://api.elsevier.com/content/abstract/scopus_id/85104050206,"The existence of widespread COVID-19 infections has prompted worldwide efforts to control and manage the virus, and hopefully curb it completely. One important line of research is the use of machine learning (ML) to understand and fight COVID-19. This is currently an active research field. Although there are already many surveys in the literature, there is a need to keep up with the rapidly growing number of publications on COVID-19-related applications of ML. This paper presents a review of recent reports on ML algorithms used in relation to COVID-19. We focus on the potential of ML for two main applications: diagnosis of COVID-19 and prediction of mortality risk and severity, using readily available clinical and laboratory data. Aspects related to algorithm types, training data sets, and feature selection are discussed. As we cover work published between January 2020 and January 2021, a few key points have come to light. The bulk of the machine learning algorithms used in these two applications are supervised learning algorithms. The established models are yet to be used in real-world implementations, and much of the associated research is experimental. The diagnostic and prognostic features discovered by ML models are consistent with results presented in the medical literature. A limitation of the existing applications is the use of imbalanced data sets that are prone to selection bias.",health
10.1016/j.tige.2020.09.001,Journal,Techniques and Innovations in Gastrointestinal Endoscopy,scopus,2021-01-01,sciencedirect,Training for Advanced Endoscopic Imaging in Gastrointestinal Diseases,https://api.elsevier.com/content/abstract/scopus_id/85100680745,"Advanced endoscopic imaging is an emerging field in endoscopy practice, especially in optical diagnosis. Current technologies like virtual chromoendoscopy and small-field technologies allow visualization of subtle changes in mucosal and vascular patterns that are predictive of histology. The limiting factor in broadly utilizing these techniques is training and the need for reliable detection of these subtleties. This review provides the current evidence and limitations of training in advanced endoscopic imaging, and future directions of learning. A literature search was performed on PubMed and Medline through March 2020 with relevant keywords as advanced endoscopic imaging, training, and learning. References of relevant articles were screened for additional literature. Several didactic and web-based education programs are developed for training in virtual chromoendoscopy, autofluorescence imaging, confocal laser endomicroscopy, and volumetric laser endomicroscopy. Studies and post-hoc analysis on learning curves showed relatively steep learning curves after training, and web-based education seems to be as valuable as in-person didactic training for most techniques. However, consistent performance on expert level after training has not yet been demonstrated. Most advanced endoscopic imaging techniques are learned within a reasonable timeframe. Future efforts to enhance training and implementation of these techniques should focus on developing standardized and broadly incorporated training programs. The future role of artificial intelligence-assistance in advanced endoscopy and training has to be elucidated.",health
10.1016/j.neucom.2020.01.127,Journal,Neurocomputing,scopus,2021-01-01,sciencedirect,A deep neural network ensemble of multimodal signals for classifying excavator operations,https://api.elsevier.com/content/abstract/scopus_id/85100594980,"The prognostics and health management (PHM) aims to provide a comprehensive solution for equipment health care. Classifying the operation mode of excavator, one of the tasks in the PHM, is important to evaluate the remaining useful lifetime. Several studies have been conducted to classify the operations with either video or sensor data, but they have several limitations to use only one type of data. A model trained with sensor data cannot classify the similar operations such as “digging” and “ditch digging”, whereas a model with video data is vulnerable to surrounding condition like weather. In this paper, to overcome these shortcomings, we propose a deep neural network ensemble called FusionNet that classifies the operations of excavator. Two models are trained with sensor data and video frames respectively, where the feature extractors are transferred to the FusionNet. The proposed network ensemble performs a flexible and well-optimized classification by automatically calculating weights according to the extracted feature vectors and combining them. To verify the proposed model, several experiments are conducted with the real-world data. The proposed model achieves the accuracy of 99.17% which outperforms the conventional methods. We also confirm that the proposed model can address the shortcomings of using only one type of data and maximize the benefits through the automatic weighting of extracted features.",health
10.1016/j.aei.2021.101246,Journal,Advanced Engineering Informatics,scopus,2021-01-01,sciencedirect,"A systematic literature review on intelligent automation: Aligning concepts from theory, practice, and future perspectives",https://api.elsevier.com/content/abstract/scopus_id/85099458674,"With the recent developments in robotic process automation (RPA) and artificial intelligence (AI), academics and industrial practitioners are now pursuing robust and adaptive decision making (DM) in real-life engineering applications and automated business workflows and processes to accommodate context awareness, adaptation to environment and customisation. The emerging research via RPA, AI and soft computing offers sophisticated decision analysis methods, data-driven DM and scenario analysis with regard to the consideration of decision choices and provides benefits in numerous engineering applications. The emerging intelligent automation (IA) – the combination of RPA, AI and soft computing – can further transcend traditional DM to achieve unprecedented levels of operational efficiency, decision quality and system reliability. RPA allows an intelligent agent to eliminate operational errors and mimic manual routine decisions, including rule-based, well-structured and repetitive decisions involving enormous data, in a digital system, while AI has the cognitive capabilities to emulate the actions of human behaviour and process unstructured data via machine learning, natural language processing and image processing. Insights from IA drive new opportunities in providing automated DM processes, fault diagnosis, knowledge elicitation and solutions under complex decision environments with the presence of context-aware data, uncertainty and customer preferences. This sophisticated review attempts to deliver the relevant research directions and applications from the selected literature to the readers and address the key contributions of the selected literature, IA’s benefits, implementation considerations, challenges and potential IA applications to foster the relevant research development in the domain.",health
10.1016/j.tej.2020.106885,Journal,Electricity Journal,scopus,2021-01-01,sciencedirect,Machine learning methods for power line outage identification,https://api.elsevier.com/content/abstract/scopus_id/85098190289,"As Phasor Measurement Units (PMUs) become widely deployed, power systems can take advantage of the large amount of data provided by PMUs and leverage the advances in big data analytics to improve real-time monitoring and diagnosis. In this paper, we develop practical analytics that are not tightly coupled with the power flow analysis and state estimation, as these tasks require detailed and accurate information about the power system. We focus on power line outage identification, and use a machine learning framework to locate line outages. The same framework is used for the prediction of both single line and multiple line outages. We investigate a range of machine learning algorithms and feature extraction methods. The algorithms are designed to capture the essential dynamic characteristics of the power system when the topology change occurs abruptly. The proposed methods use only voltage phasor angles obtained by continuously monitoring the buses. We tested the proposed methods on their prediction performance under different levels of noise and missingness. It is shown that the proposed methods have better tolerance for noisy data and incomplete data when compared to the previous work that involves solving power flow equations or state estimation equations.",health
10.1016/j.cct.2020.106219,Journal,Contemporary Clinical Trials,scopus,2021-01-01,sciencedirect,Using digital technologies in clinical trials: Current and future applications,https://api.elsevier.com/content/abstract/scopus_id/85097798472,"In 2015, we provided an overview of the use of digital technologies in clinical trials, both as a methodological tool and as a mechanism to deliver interventions. At that time, there was limited guidance and limited use of digital technologies in clinical research. However, since then smartphones have become ubiquitous and digital health technologies have exploded. This paper provides an update to our earlier publication and an overview of how technology has been used in the past five years in clinical trials, providing examples with varying levels of technological integration and across different health conditions. Digital technology integration ranges from the incorporation of artificial intelligence in diagnostic devices to the use of real-world data (e.g., electronic health records) for study recruitment. Clinical trials can now be conducted entirely virtually, eliminating the need for in-person interaction. Much of the published research demonstrates how digital approaches can improve the design and implementation of clinical trials. While challenges remain, progress over the last five years is encouraging, and barriers can be overcome with careful planning.",health
10.1016/j.psychres.2020.113585,Journal,Psychiatry Research,scopus,2021-01-01,sciencedirect,"Digital Gaming Interventions in Psychiatry: Evidence, Applications and Challenges",https://api.elsevier.com/content/abstract/scopus_id/85097734134,"Human evolution has regularly intersected with technology. Digitalization of various services has brought a paradigm shift in consumerism. Treading this path, mental health practice has gradually moved to Digital Mental Health Interventions (DMHI), to improve service access and delivery. Applied games are one such innovation that has gained recent popularity in psychiatry. Based on the principles of gamification, they target psychosocial and cognitive domains, according to the deficits in various psychiatric disorders. They have been used to deliver cognitive behaviour therapy, cognitive training and rehabilitation, behavioural modification, social motivation, attention enhancement, and biofeedback. Research shows their utility in ADHD, autistic spectrum disorders, eating disorders, post-traumatic stress, impulse control disorders, depression, schizophrenia, dementia, and even healthy aging. Virtual reality and artificial intelligence have been used in conjunction with gaming interventions to improvise their scope. Even though these interventions hold promise in engagement, ease of use, reduction of stigma, and bridging the mental-health gap, there are pragmatic challenges, especially in developing countries. These include network quality, infrastructure, feasibility, socio-cultural adaptability, and potential for abuse. Keeping this in the background, this review summarizes the scope, promise, and evidence of digital gaming in psychiatric practice, and highlights the potential caveats in their implementation.",health
10.1016/j.imbio.2020.152028,Journal,Immunobiology,scopus,2021-01-01,sciencedirect,Study on the additive protective effect of PGLYRP3 and Bifidobacterium adolescentis Reuter 1963 on severity of DSS-induced colitis in Pglyrp3 knockout (Pglyrp3 −/−) and wild-type (WT) mice,https://api.elsevier.com/content/abstract/scopus_id/85096671566,"Background and Aims
                  Pglyrp3 is a bactericidal innate immunity protein known to sustain the habitual gut microbiome and protect against experimental colitis. Intestinal inflammation and metaflammation are commonly associated with a marked reduction of commensal bifidobacteria. Whether Pglyrp3 and bifidobacteria interact synergistically or additively to alleviate metaflammation is unknown. We investigated the extent to which Pglyrp3 and bifidobacteria regulate metaflammation and gut bacterial dysbiosis in DSS-induced mouse models of intestinal inflammation.
               
                  Material & Methods
                  8–10 weeks old male mice were used. In both WT and Pglyrp3 −/− experiments, the mice were randomly divided into three groups of 16 mice per group: (1) a control group receiving sterile tap water, (2) an experimental group receiving sterile tap water supplemented with only 5% DSS, and (3) an experimental group receiving sterile tap water supplemented with 5% DSS and 1 × 109 CFU/ml of Bifidobacterium adolescentis (B.a.) for 7 days. Wild-type (WT) littermates of the respective gene (i.e. Pglyrp3) were used as controls throughout the study. Clinical signs of general health and inflammation were monitored daily. Faecal pellet samples were analysed by qRT-PCR for microbial composition. Histology of relevant organs was carried out on day 8. Metabolic parameters and liver inflammation were determined in serum samples.
               
                  Results
                  Intestinal inflammation in mice of group 2 were significantly increased compared to those of control group 1. There was a significant difference in mean scores for inflammation severity between DSS-treated WT and DSS-treated Pglyrp3 −/− mice. Buildup of key serum metabolic markers (cholesterol, triglyceride and glucose) was set off by colonic inflammation. qRT-PCR quantification showed that DSS significantly decreased the Clostridium coccoides and Bifidobacterium cell counts while increasing those of Bacteroides group in both WT and Pglyrp3 −/− mice. These manifestations of DSS-induced dysbiosis were significantly attenuated by feeding B.a. Both the local and systemic ill-being of the mice alleviated when they received B.a.
                  
               
                  Discussion
                  This study shows that Pglyrp3 facilitates recognition of bifidobacterial cell wall-derived peptidoglycan, thus leading additively to a reduction of metaflammation through an increase in the number of bifidobacteria, which were able to mitigate intestinal immunopathology in the context of Pglyrp3 blockade.",health
10.1016/j.media.2020.101883,Journal,Medical Image Analysis,scopus,2021-01-01,sciencedirect,Rigid and non-rigid motion artifact reduction in X-ray CT using attention module,https://api.elsevier.com/content/abstract/scopus_id/85095417175,"Motion artifacts are a major factor that can degrade the diagnostic performance of computed tomography (CT) images. In particular, the motion artifacts become considerably more severe when an imaging system requires a long scan time such as in dental CT or cone-beam CT (CBCT) applications, where patients generate rigid and non-rigid motions. To address this problem, we proposed a new real-time technique for motion artifacts reduction that utilizes a deep residual network with an attention module. Our attention module was designed to increase the model capacity by amplifying or attenuating the residual features according to their importance. We trained and evaluated the network by creating four benchmark datasets with rigid motions or with both rigid and non-rigid motions under a step-and-shoot fan-beam CT (FBCT) or a CBCT. Each dataset provided a set of motion-corrupted CT images and their ground-truth CT image pairs.
                  The strong modeling power of the proposed network model allowed us to successfully handle motion artifacts from the two CT systems under various motion scenarios in real-time. As a result, the proposed model demonstrated clear performance benefits. In addition, we compared our model with Wasserstein generative adversarial network (WGAN)-based models and a deep residual network (DRN)-based model, which are one of the most powerful techniques for CT denoising and natural RGB image deblurring, respectively. Based on the extensive analysis and comparisons using four benchmark datasets, we confirmed that our model outperformed the aforementioned competitors. Our benchmark datasets and implementation code are available at https://github.com/youngjun-ko/ct_mar_attention.",health
10.1016/j.media.2020.101852,Journal,Medical Image Analysis,scopus,2021-01-01,sciencedirect,Discriminative and generative models for anatomical shape analysis on point clouds with deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85093915610,"We introduce deep neural networks for the analysis of anatomical shapes that learn a low-dimensional shape representation from the given task, instead of relying on hand-engineered representations. Our framework is modular and consists of several computing blocks that perform fundamental shape processing tasks. The networks operate on unordered point clouds and provide invariance to similarity transformations, avoiding the need to identify point correspondences between shapes. Based on the framework, we assemble a discriminative model for disease classification and age regression, as well as a generative model for the accruate reconstruction of shapes.
                  In particular, we propose a conditional generative model, where the condition vector provides a mechanism to control the generative process. For instance, it enables to assess shape variations specific to a particular diagnosis, when passing it as side information.
                  Next to working on single shapes, we introduce an extension for the joint analysis of multiple anatomical structures, where the simultaneous modeling of multiple structures can lead to a more compact encoding and a better understanding of disorders.
                  We demonstrate the advantages of our framework in comprehensive experiments on real and synthetic data. The key insights are that (i) learning a shape representation specific to the given task yields higher performance than alternative shape descriptors, (ii) multi-structure analysis is both more efficient and more accurate than single-structure analysis, and (iii) point clouds generated by our model capture morphological differences associated to Alzheimer’s disease, to the point that they can be used to train a discriminative model for disease classification. Our framework naturally scales to the analysis of large datasets, giving it the potential to learn characteristic variations in large populations.",health
10.1016/j.cmpb.2020.105779,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-01-01,sciencedirect,A modular and scalable computational framework for interactive immersion into imaging data with a holographic augmented reality interface,https://api.elsevier.com/content/abstract/scopus_id/85092219783,"Background and objective
                  Modern imaging scanners produce an ever-growing body of 3D/4D multimodal data requiring image analytics and visualization of fused images, segmentations, and information. For the latter, augmented reality (AR) with head-mounted displays (HMDs) has shown potential. This work describes a framework (FI3D) for interactive immersion with data, integration of image processing and analytics, and rendering and fusion with an AR interface.
               
                  Methods
                  The FI3D was designed and endowed with modules to communicate with peripherals, including imaging scanners and HMDs, and to provide computational power for data acquisition and processing. The core of FI3D is deployed to a dedicated computational unit that performs the computationally demanding processes in real-time, and the HMD is used as a display output peripheral and an input peripheral through gestures and voice commands. FI3D offers user-made processing and analysis dedicated modules. Users can customize and optimize these for a particular workflow while incorporating current or future libraries.
               
                  Results
                  The FI3D framework was used to develop a workflow for processing, rendering, and visualization of CINE MRI cardiac sets. In this version, the data were loaded from a remote database, and the endocardium and epicardium of the left ventricle (LV) were segmented using a machine learning model and transmitted to a HoloLens HMD to be visualized in 4D. Performance results show that the system is capable of maintaining an image stream of one image per second with a resolution of 512 × 512. Also, it can modify visual properties of the holograms at 1 update per 16 milliseconds (62.5 Hz) while providing enough resources for the segmentation and surface reconstruction tasks without hindering the HMD.
               
                  Conclusions
                  We provide a system design and framework to be used as a foundation for medical applications that benefit from AR visualization, removing several technical challenges from the developmental pipeline.",health
10.1016/j.envres.2020.110141,Journal,Environmental Research,scopus,2021-01-01,sciencedirect,Assessing personal exposure using Agent Based Modelling informed by sensors technology,https://api.elsevier.com/content/abstract/scopus_id/85092078286,"Technology innovations create possibilities to capture exposure-related data at a great depth and breadth. Considering, though, the substantial hurdles involved in collecting individual data for whole populations, this study introduces a first approach of simulating human movement and interaction behaviour, using Agent Based Modelling (ABM).
                  A city scale ABM was developed for urban Thessaloniki, Greece that feeds into population-based exposure assessment without imposing prior bias, basing its estimations onto emerging properties of the behaviour of the computerised autonomous decision makers (agents) that compose the city-system. Population statistics, road and buildings networks data were transformed into human, road and building agents, respectively. Survey outputs with time-use patterns were associated with human agent rules, aiming to model representative to real-world behaviours. Moreover, time-geography of exposure data, derived from a local sensors campaign, was used to inform and enhance the model. As a prevalence of an agent-specific decision-making, virtual individuals of different sociodemographic backgrounds express different spatiotemporal behaviours and their trajectories are coupled with spatially resolved pollution levels.
                  Personal exposure was evaluated by assigning PM concentrations to human agents based on coordinates, type of location and intensity of encountered activities. Study results indicated that PM2.5 inhalation adjusted exposure between housemates can differ by 56.5% whereas exposure between two neighbours can vary by as much as 87%, due to the prevalence of different behaviours.
                  This study provides details of a new methodology that permits the cost-effective construction of refined time-activity diaries and daily exposure profiles, taking into account different microenvironments and sociodemographic characteristics. The proposed method leads to a refined exposure assessment model, addressing effectively vulnerable subgroups of population. It can be used for evaluating the probable impacts of different public health policies prior to implementation reducing, therefore, the time and expense required to identify efficient measures.",health
10.1016/j.bspc.2020.102178,Journal,Biomedical Signal Processing and Control,scopus,2021-01-01,sciencedirect,Towards effective classification of brain hemorrhagic and ischemic stroke using CNN,https://api.elsevier.com/content/abstract/scopus_id/85089894411,"Brain stroke is one of the most leading causes of worldwide death and requires proper medical treatment. Therefore, in this paper, our aim is to classify brain computed tomography (CT) scan images into hemorrhagic stroke, ischemic stroke and normal. Our newly proposed convolutional neural network (CNN) model utilizes image fusion and CNN approaches. Initially, some preprocessing operations have been employed by using multi-focus image fusion in order to improve the quality of CT images. Further, preprocessed images are fed into the newly proposed 13 layers CNN architecture for stroke classification. The robustness of our CNN method has been checked by conducting two experiments on two different datasets. In the first experiment, CT image dataset is partitioned into 20% testing and 80% training sets, while in the second experiment, 10 fold cross-validation of the image dataset has been performed. The classification accuracy obtained by our method on dataset 1 in the first experiment is 98.33% and in the second experiment, it is 98.77%, while in dataset 2 accuracy obtained in experiment 1 and 2 is 92.22% and 93.33% respectively. All the experiments have been conducted on the real CT image dataset which we have been collected from Himalayan Institute of Medical Sciences (HIMS), Dehradun, India. The results obtained by the proposed method have also been compared with AlexNet and ResNet50 where results show improvement over these CNN architectures.",health
10.1016/j.ymssp.2020.107061,Journal,Mechanical Systems and Signal Processing,scopus,2021-01-01,sciencedirect,Recovering compressed images for automatic crack segmentation using generative models,https://api.elsevier.com/content/abstract/scopus_id/85086994715,"In a structural health monitoring (SHM) system that uses digital cameras to monitor cracks of structural surfaces, techniques for reliable and effective data compression are essential to ensure a stable and energy-efficient crack images transmission in wireless devices, e.g., drones and robots with high definition cameras installed. Compressive sensing (CS) is a signal processing technique that allows accurate recovery of a signal from a sampling rate much smaller than the limitation of the Nyquist sampling theorem. Different from the popular approach of simultaneously training encoder and decoder using neural network models, the CS theory ensures a high probability of accurate signal reconstruction based on random measurements that is shorter than the length of the original signal under a sparsity constraint. Such method is particularly useful when measurements are expensive, such as wireless sensing of civil structures, because its hardware implementation allows down sampling of signals during the sensing process. Hence, CS methods can achieve significant energy saving for the sensing devices. However, the strong assumption of the signals being highly sparse in an invertible space is relatively hard to guarantee for many real images, such as image of cracks. In this paper, we present a new approach of CS that replaces the sparsity regularization with a generative model that is able to effectively capture a low dimension representation of targeted images. We develop a recovery framework for automatic crack segmentation of compressed crack images based on this new CS method. We demonstrate the remarkable performance of our method that takes advantage of the strong capability of generative models to capture the necessary features required in the crack segmentation task even the backgrounds of the generated images are not well reconstructed. The superior performance of our recovery framework is illustrated by comparisons to three existing CS algorithms. Furthermore, we show that our framework is potentially extensible to other common problems in automatic crack segmentation, such as defect recovery from motion blurring and occlusion.",health
10.1016/j.jaim.2018.02.139,Journal,Journal of Ayurveda and Integrative Medicine,scopus,2021-01-01,sciencedirect,Scientific validation of anti-arthritic effect of Kashayams – A polyherbal formulation in collagen induced arthritic rats,https://api.elsevier.com/content/abstract/scopus_id/85059941091,"Background
                  Toll-like receptor-4 (TLR-4) mediates activation of nuclear factor kappa-light-chain-enhancer of activated B cells (NF-κB) resulting in induction of proinflammatory genes such as that encoding tumor necrosis factor-α (TNF-α) and interleukin-1β (IL-1β) which played a significant role in cartilage destruction of rheumatoid arthritis (RA). Low risk and better efficacy made herbal drugs more reliable than nonsteroid anti-inflammatory drugs (NSAIDS) in RA treatment. Gugguluthiktam Kashayam (GuK), Punarnavadi Kashayam (PuK) and Balaguluchiadi Kashayam (BgK) are ayurvedic polyherbal formulations prescribed in classical ayurvedic texts Sahasrayogam and Ashtangahridayam as medicines for the treatment of RA.
               
                  Objective
                  The objective of the present study was to elucidate the molecular mechanism of anti-arthritic effect of these Kashayams on TLR-4 signal transduction pathway in collagen induced arthritic rats.
               
                  Material and methods
                  The wistar rats grouped into group I - Normal, group II- Collagen induced arthritis (CIA), group III- CIA + BgK, group IV– CIA + PuK, group V- CIA + GuK, group VI - CIA + Indomethacin (3 mg/kg b.wt.). Treatment with Kashayam (2 ml/kg b.wt) started after 14 days of primary immunization with type II collagen and continued for a period of 45 days.
               
                  Results
                  Arthritis index, C-reactive protein (CRP), rheumatoid factor (RF) and myeloperoxidase (MPO) in serum and protein level of TLR-4, myeloid differentiation factor 88 (MYD88), NF-κB, TNF-α, IL-1β, inducible nitric oxide synthase (iNOS), cyclooxygenase-2 COX-2) and prostaglandin E-2 (PGE-2) in cartilage were significantly elevated in CIA rats. Further, treatment with Kashayams downregulated all these inflammatory mediators hitherto TLR-4-NF-kB signal transduction pathway except IL-10, an anti-inflammatory cytokine which showed a reverse effect.
               
                  Conclusion
                  This molecular mechanism of the investigation confirmed the clinical efficacy of Kashayams in preventing the progression of RA and gave an intuition of the scientific validation of Kashayams, an Ayurvedic classical medicine.",health
10.1016/j.scitotenv.2020.142368,Journal,Science of the Total Environment,scopus,2020-12-20,sciencedirect,A novel dynamic multi-criteria ensemble selection mechanism applied to drinking water quality anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/85091235644,"The provision of clean and safe drinking water is a crucial task for water supply companies from all over the world. To this end, automatic anomaly detection plays a critical role in drinking water quality monitoring. Recent anomaly detection studies use techniques that focus on a single global objective. Yet, companies need solutions that better balance the trade-off between false positives (FPs), which lead to financial losses to water companies, and false negatives (FNs), which severely impact public health and damage the environment. This work proposes a novel dynamic multi-criteria ensemble selection mechanism to cope with both problems simultaneously: the non-dominated local class-specific accuracy (NLCA). Moreover, experiments rely on recent time series related classification metrics to assess the predictive performance. Results on data from a real-world water distribution system show that NLCA outperforms other ensemble learning and dynamic ensemble selection techniques by more than 15% in terms of time series related F
                     1 scores. As a conclusion, NLCA enables the development of stronger anomaly detection systems for drinking water quality monitoring. The proposed technique also offers a new perspective on dynamic ensemble selection, which can be applied to different classification tasks to balance conflicting criteria.",health
10.1016/j.jclepro.2020.123365,Journal,Journal of Cleaner Production,scopus,2020-12-20,sciencedirect,An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,https://api.elsevier.com/content/abstract/scopus_id/85089891280,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers’ maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions.",health
10.1016/j.jpowsour.2020.229069,Journal,Journal of Power Sources,scopus,2020-12-15,sciencedirect,Cloud computing-based real-time global optimization of battery aging and energy consumption for plug-in hybrid electric vehicles,https://api.elsevier.com/content/abstract/scopus_id/85095795552,"This paper addresses two conflicts in the energy management strategy (EMS) for plug-in hybrid electric vehicles (PHEVs). One is the conflict between fuel economy optimization and battery state of health preservation, and the other is the conflict between global optimality and real-time capability. Inspired by the hierarchy structure of a computer, a two-layer internet-distributed EMS (ID-EMS) is developed using cloud computing and the internet of vehicles. The top layer in the cloud, which possesses powerful calculating capability, focuses on global optimality by utilizing machine learning technology and stochastic dynamic programming. The bottom layer on board, with limited computing power, employs a fuzzy controller to respond to real-time conditions while trying not to deviate too far from the global solution. Thus, a real-time global optimal EMS can be achieved. The ID-EMS is implemented on an internet-distributed vehicle-in-the-loop simulation platform whose in-loop vehicle makes it possible to test the ID-EMS in an on-road driving experiment. The ID-EMS outperforms a rule-based EMS in terms of overall cost by 6.8%, but it is surpassed by an acausal EMS with dynamic programming by 7%. These results suggest directions for the future development of EMS for PHEVs using cloud computing.",health
10.1016/j.eswa.2020.113715,Journal,Expert Systems with Applications,scopus,2020-12-15,sciencedirect,Graph classification algorithm based on graph structure embedding,https://api.elsevier.com/content/abstract/scopus_id/85088375744,"With the application of data mining in many fields such as information science, bioinformatics, and network intrusion detection, more and more data are showing new features such as strong structuration and complex relationships between data. As a complex data structure, a graph can be used to describe the relationship between things. Traditional graph classification methods based on graph feature vector construction need to select a feature vector construction criterion in advance, such as graph-based theoretical indicators or graph-based topology occurrences, and then extract features from each graph in the graph set according to the designated criterion. However, the construction method of the graph feature vector is easy to lose the graph structural information and requires strong professional knowledge. Inspired by the Word2Vec and Doc2Vec models in the Natural Language Processing (NLP), this paper first constructs a “word list” of graph data consisting of subgraphs. Then a neural network for training graph embedding is designed with the graph itself as its input, and the “word” in the graph and the attribute features of the graph are used as its output, so that the neural network automatically learns the graph embedding corresponding to each graph. The graph embedding not only reflects the features of the graph itself but also includes the relative relationship among graphs. Finally, on the basis of the well-trained graph embedding, the common classifier can be used to classify graphs. Based on real-world bioinformatics and social data sets, the experiments demonstrate that the proposed graph classification algorithm has advantages over the existing graph classification algorithms based on feature vector construction.",health
10.1016/j.patter.2020.100145,Journal,Patterns,scopus,2020-12-11,sciencedirect,A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread,https://api.elsevier.com/content/abstract/scopus_id/85097386310,"We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform.",health
10.1016/j.patter.2020.100137,Journal,Patterns,scopus,2020-12-11,sciencedirect,Parallel Factor Analysis Enables Quantification and Identification of Highly Convolved Data-Independent-Acquired Protein Spectra,https://api.elsevier.com/content/abstract/scopus_id/85096522758,"High-throughput data-independent acquisition (DIA) is the method of choice for quantitative proteomics, combining the best practices of targeted and shotgun approaches. The resultant DIA spectra are, however, highly convolved and with no direct precursor-fragment correspondence, complicating biological sample analysis. Here, we present CANDIA (canonical decomposition of data-independent-acquired spectra), a GPU-powered unsupervised multiway factor analysis framework that deconvolves multispectral scans to individual analyte spectra, chromatographic profiles, and sample abundances, using parallel factor analysis. The deconvolved spectra can be annotated with traditional database search engines or used as high-quality input for de novo sequencing methods. We demonstrate that spectral libraries generated with CANDIA substantially reduce the false discovery rate underlying the validation of spectral quantification. CANDIA covers up to 33 times more total ion current than library-based approaches, which typically use less than 5% of total recorded ions, thus allowing quantification and identification of signals from unexplored DIA spectra.",health
10.1016/j.jtbi.2020.110380,Journal,Journal of Theoretical Biology,scopus,2020-12-07,sciencedirect,Anticipating future learning affects current control decisions: A comparison between passive and active adaptive management in an epidemiological setting,https://api.elsevier.com/content/abstract/scopus_id/85089137762,"Infectious disease epidemics present a difficult task for policymakers, requiring the implementation of control strategies under significant time constraints and uncertainty. Mathematical models can be used to predict the outcome of control interventions, providing useful information to policymakers in the event of such an epidemic. However, these models suffer in the early stages of an outbreak from a lack of accurate, relevant information regarding the dynamics and spread of the disease and the efficacy of control. As such, recommendations provided by these models are often incorporated in an ad hoc fashion, as and when more reliable information becomes available. In this work, we show that such trial-and-error-type approaches to management, which do not formally take into account the resolution of uncertainty and how control actions affect this, can lead to sub-optimal management outcomes. We compare three approaches to managing a theoretical epidemic: a non-adaptive management (AM) approach that does not use real-time outbreak information to adapt control, a passive AM approach that incorporates real-time information if and when it becomes available, and an active AM approach that explicitly incorporates the future resolution of uncertainty through gathering real-time information into its initial recommendations. The structured framework of active AM encourages the specification of quantifiable objectives, models of system behaviour and possible control and monitoring actions, followed by an iterative learning and control phase that is able to employ complex control optimisations and resolve system uncertainty. The result is a management framework that is able to provide dynamic, long-term projections to help policymakers meet the objectives of management. We investigate in detail the effect of different methods of incorporating up-to-date outbreak information. We find that, even in a highly simplified system, the method of incorporating new data can lead to different results that may influence initial policy decisions, with an active AM approach to management providing better information that can lead to more desirable outcomes from an epidemic.",health
10.1016/j.neucom.2020.07.045,Journal,Neurocomputing,scopus,2020-12-05,sciencedirect,Knowledge-shot learning: An interpretable deep model for classifying imbalanced electrocardiography data,https://api.elsevier.com/content/abstract/scopus_id/85089337744,"Classification of Electrocardiogram (ECG) data has been an important research topic in the machine learning area for many years. Recently, deep learning methods have been used in classifying ECG data and have achieved superior results than traditional methods. However, in real-world applications, two challenges existing deep learning methods cannot handle well – imbalanced data and model interpretability. In this paper, we propose an ECG classification method named Knowledge-Shot Learning (KSL) that can handle with the above two challenges. KSL constructs a novel neural network architecture that can be effectively trained on imbalanced ECG data. Besides, KSL can also extract interpretable feature vectors and give support cases as result explanations. Moreover, KSL can even classify unseen diseases if provided with the necessary medical knowledge. Experiments on real-world ECG data show that KSL improves 10.00% of 
                        
                           
                              
                                 F
                              
                              
                                 1
                              
                           
                        
                     -score on imbalanced classes, and 43.75% of 
                        
                           
                              
                                 F
                              
                              
                                 1
                              
                           
                        
                     -score on unseen classes, compared with the second-best baseline. KSL also provides interpretable results that are consistent with medical domain knowledge.",health
10.1016/j.prevetmed.2020.105199,Journal,Preventive Veterinary Medicine,scopus,2020-12-01,sciencedirect,Estimation of the sensitivity and specificity of four serum ELISA and one fecal PCR for diagnosis of paratuberculosis in adult dairy cattle in New Zealand using Bayesian latent class analysis,https://api.elsevier.com/content/abstract/scopus_id/85097155218,"In New Zealand, a new diagnostic approach for the control of paratuberculosis in mixed aged milking cows has been developed using a combination of ELISA and quantitative fecal PCR (f-qPCR). Our analysis was designed to evaluate performance of these individual tests in infected or infectious mixed aged cows across the prevalence of infection typically encountered on NZ dairy farms and calculate test accuracy when used as a screening test of serological ELISAs for four separate antigens read in parallel followed by a confirmatory quantitative f-qPCR test.
                  Data from a cross-sectional study of 20 moderate prevalence herds was combined with existing data from 2 low and 20 high prevalence herds forming a dataset of 3845 paired serum and fecal samples. Incidence of clinical Johne’s disease (JD) was used to classify herds into three prevalence categories. High (≥ 3% annual clinical JD for the last three years), moderate (<3 – 1%) and low (<1% incidence for at least the last five years). Positive tests were declared if> 50 ELISA units and f-qPCR at two cut-points (≥1 × 104 genomes/mL or >1 × 103 genomes/mL).
                  Fixed Bayesian latent class models at both f-qPCR cut-points, accounted for conditional independence and paired conditional dependence. Mixed models at both f-qPCR cut-points, using a different mechanism to account for conditional dependencies between tests were also implemented. Models (24 in number) were constructed using OpenBUGS. The aim was to identify Mycobacterium avium subsp. paratuberculosis (MAP) infected cows that met at least one of two criteria: shedding sufficient MAP in feces to be detected by f-qPCR or mounting a detectable MAP antibody response.
                  The best fit to the data was obtained by modelling pairwise dependencies between tests in a fixed model or by accounting for dependencies in a mixed model at a fecal cut-off of ≥1 × 104 genomes/mL. Test performance differed with prevalence, but models were robust to prior assumptions. For the fixed model, at a prevalence of 0.29 (95 % probability interval (PI) = 0.25−0.33), as a screening plus confirmatory f-qPCR, post-test probability for disease in a positive animal was 0.84 (95 %PI = 0.80−0.88) and 0.16 (95 %PI = 0.15−0.18) for disease in a test negative animal. In low prevalence herds (0.01(95 %PI = 0.00−0.04)) the equivalent figures were 0.84 (95 %PI = 0.08−0.92) and 0.00 (95 %PI = 0.00−0.02).
                  These results suggest this is a useful tool to control JD on dairy farms, particularly in herds with higher levels of infection, where the sampling and testing cost per animal is defrayed across more detected animals.",health
10.1016/j.fsi.2020.10.023,Journal,Fish and Shellfish Immunology,scopus,2020-12-01,sciencedirect,Cutaneous mucosal immune-parameters and intestinal immune-relevant genes expression in streptococcal-infected rainbow trout (Oncorhynchus mykiss): A comparative study with the administration of florfenicol and olive leaf extract,https://api.elsevier.com/content/abstract/scopus_id/85095737003,"This study evaluated changes in cutaneous mucosal immunity (total protein (TP) and immunoglobulin (TIg), lysozyme, protease, esterase, and alkaline phosphatase (ALP)) and some immune-related genes expression (tumor necrosis factor-α (TNF-α), interleukin-1β (IL-1β), interleukin-8, hepcidin-like antimicrobial peptides (HAMP), and immunoglobulin M (IgM)) in the intestine of rainbow trout (Oncorhynchus mykiss) orally-administrated florfenicol (FFC) and/or olive leaf extract (OLE), experimentally infected with Streptococcus iniae. The juvenile fish (55 ± 7.6 g) were divided into different groups according to the use of added OLE (80 g kg−1 food), the presence/absence of FFC (15 mg kg−1 body weight for 10 consecutive days), and the streptococcal infectivity (2.87 × 107 CFU mL−1 as 30% of LD50-96h). The extract's chemical composition was analyzed using the high-performance liquid chromatography (HPLC) system. The skin mucus and intestine of fish were sampled after a 10-day therapeutic period for all groups, and their noted indices were measured. Our results signified that the oleuropein, quercetin, and trans-ferulic acid were the most obvious active components of OLE which were found by HPLC analysis. The combined use of OLE and FFC could lowered some skin mucus immunological indices (e.g., TP, TIg, and ALP), and the gene expression of inflammatory cytokines (e.g., TNF-α and IL-1β) of rainbow trout. Moreover, lysozyme and protease activities respectively were invigorated by the FFC and OLE treatment. Also, the use of OLE as a potential medicine induced the gene expression of HAMP. As the prevention approach, it would be recommended to find the best dose of OLE alone or in combination with the drug through therapeutics period before the farm involved in the streptococcal infection.",health
10.1016/j.neuropsychologia.2020.107667,Journal,Neuropsychologia,scopus,2020-12-01,sciencedirect,Functional connectivity in a triple-network saliency model is associated with real-life self-control,https://api.elsevier.com/content/abstract/scopus_id/85095735482,"Despite its significance for health and education, the neurocognitive mechanism of real-life self-control remains unclear. While recent studies focused on task-related brain activation patterns as predictors of self-control, the contribution and relevance of functional connectivity between large-scale brain networks mediating higher-order cognition is largely unknown. Using a saliency-based triple-network model of cognitive control, we tested the hypothesis that cross-network interactions among the salience network (SN), the central executive network (CEN), and the default mode network (DMN) are associated with real-life self-control. To this end, a large community sample (N = 294) underwent ecological momentary assessment of daily self-control as well as task-free fMRI to examine intrinsic inter-network organization and determine a SN-centered network interaction index (NII). Logistic multilevel regression analysis showed that higher NII scores were associated with increased real-life self-control. This suggests that the assumed role of the SN in initiating switching between the DMN and CEN is an important part of self-control.",health
10.1016/j.jngse.2020.103671,Journal,Journal of Natural Gas Science and Engineering,scopus,2020-12-01,sciencedirect,System-level prognosis and health monitoring modeling framework and software implementation for gas pipeline system integrity management,https://api.elsevier.com/content/abstract/scopus_id/85094628312,"Over the past few decades, recurrent pipeline failures have caused a major impact on human lives and property damage. Studies have shown the lack of a comprehensive, integrated, and accessible set of risk-informed integrity management models and tools for pipeline operators are the main reason behind those damages. To address this gap, this paper presents a system-level Prognosis and Health Monitoring (PHM) modeling framework for gas pipeline system integrity management to prevent or reduce the likelihood of failures. PHM modeling is a comprehensive approach that takes into consideration all possible failure modes of the pipeline under study. It leverages the advancement of sensor technology to stream field data in real-time to perform a dynamic system-level failure analysis based on Hybrid Causal Logic (HCL) and Dynamic Bayesian Networks (DBNs) predictive models to provide cost-effective and optimal mitigation actions such as sensor placement and maintenance schedule optimizations. The developed models are implemented into a software platform where the pipeline operators can observe the real-time and projected health state of the pipeline and the set of suggested actions to enhance the structural integrity of the pipeline system. The platform includes three main modules: Real-Time Monitoring, System-Level Reliability, and Optimal Mitigation Actions. From a safety perspective, the proposed comprehensive and dynamic pipeline health assessment framework either prevents the pipeline failures or reduces their likelihood by supporting pipeline operators in optimal decision-making and planning activities. To verify the performance of the proposed framework and its software implementation, it is applied to a case study of a corroded gas transmission pipeline and the results are discussed.",health
10.1016/j.cct.2020.106191,Journal,Contemporary Clinical Trials,scopus,2020-12-01,sciencedirect,Identification of undiagnosed atrial fibrillation patients using a machine learning risk prediction algorithm and diagnostic testing (PULsE-AI): Study protocol for a randomised controlled trial,https://api.elsevier.com/content/abstract/scopus_id/85093084431,"Atrial fibrillation (AF) is associated with an increased risk of stroke, enhanced stroke severity, and other comorbidities. However, AF is often asymptomatic, and frequently remains undiagnosed until complications occur. Current screening approaches for AF lack either cost-effectiveness or diagnostic sensitivity; thus, there is interest in tools that could be used for population screening. An AF risk prediction algorithm, developed using machine learning from a UK dataset of 2,994,837 patients, was found to be more effective than existing models at identifying patients at risk of AF. Therefore, the aim of the trial is to assess the effectiveness of this risk prediction algorithm combined with diagnostic testing for the identification of AF in a real-world primary care setting. Eligible participants (aged ≥30 years and without an existing AF diagnosis) registered at participating UK general practices will be randomised into intervention and control arms. Intervention arm participants identified at highest risk of developing AF (algorithm risk score ≥ 7.4%) will be invited for a 12‑lead electrocardiogram (ECG) followed by two-weeks of home-based ECG monitoring with a KardiaMobile device. Control arm participants will be used for comparison and will be managed routinely. The primary outcome is the number of AF diagnoses in the intervention arm compared with the control arm during the research window. If the trial is successful, there is potential for the risk prediction algorithm to be implemented throughout primary care for narrowing the population considered at highest risk for AF who could benefit from more intensive screening for AF.
                  Trial Registration: NCT04045639",health
10.1016/j.est.2020.101957,Journal,Journal of Energy Storage,scopus,2020-12-01,sciencedirect,Quantitative diagnosis of internal short circuit for cylindrical li-ion batteries based on multiclass relevance vector machine,https://api.elsevier.com/content/abstract/scopus_id/85092536635,"Battery internal short circuit (ISC) state should always be supervised. To facilitate the use of battery thermal behaviors, this work develops a lumped thermal evolution model (TEM) based on the equivalent circuit model (ECM). Then, multiple dispersedly-configured TEM/ECM sub-models are synthesized using the extreme learning machine to approximate the distribution nature of real batteries. To acquire ISC dataset, three kinds of active-destruction experiments are carried out on the battery. Thereafter, from thermal and electrical residuals, four ISC features are extracted whereby the multiclass relevance vector machine is utilized to discriminate ISC state. Specially, according to the posterior probability outputs, ISC degree can also be quantified. Experimental results on cylindrical li-ion batteries verify the reliability of the model structure and suggest the proposed diagnosis scheme can recognize ISC faults effectively with a grade misjudgment rate of 14.59% and a state misjudgment rate as low as 3.13%.",health
10.1016/j.jviromet.2020.113991,Journal,Journal of Virological Methods,scopus,2020-12-01,sciencedirect,A combined approach of MALDI-TOF mass spectrometry and multivariate analysis as a potential tool for the detection of SARS-CoV-2 virus in nasopharyngeal swabs,https://api.elsevier.com/content/abstract/scopus_id/85092484384,"Coronavirus disease 2019, known as COVID-19, is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The early, sensitive and specific detection of SARS-CoV-2 virus is widely recognized as the critical point in responding to the ongoing outbreak. Currently, the diagnosis is based on molecular real time RT-PCR techniques, although their implementation is being threatened due to the extraordinary demand for supplies worldwide. That is why the development of alternative and / or complementary tests becomes so relevant. Here, we exploit the potential of mass spectrometry technology combined with machine learning algorithms, for the detection of COVID-19 positive and negative protein profiles directly from nasopharyngeal swabs samples. According to the preliminary results obtained, accuracy = 67.66 %, sensitivity = 61.76 %, specificity = 71.72 %, and although these parameters still need to be improved to be used as a screening technique, mass spectrometry-based methods coupled with multivariate analysis showed that it is an interesting tool that deserves to be explored as a complementary diagnostic approach due to the low cost and fast performance. However, further steps, such as the analysis of a large number of samples, should be taken in consideration to determine the applicability of the method developed.",health
10.1016/j.asoc.2020.106754,Journal,Applied Soft Computing Journal,scopus,2020-12-01,sciencedirect,Sentiment Analysis of COVID-19 tweets by Deep Learning Classifiers—A study to show how popularity is affecting accuracy in social media,https://api.elsevier.com/content/abstract/scopus_id/85092457474,"COVID-19 originally known as Corona VIrus Disease of 2019, has been declared as a pandemic by World Health Organization (WHO) on 11th March 2020. Unprecedented pressures have mounted on each country to make compelling requisites for controlling the population by assessing the cases and properly utilizing available resources. The rapid number of exponential cases globally has become the apprehension of panic, fear and anxiety among people. The mental and physical health of the global population is found to be directly proportional to this pandemic disease. The current situation has reported more than twenty four million people being tested positive worldwide as of 27th August, 2020. Therefore, it is the need of the hour to implement different measures to safeguard the countries by demystifying the pertinent facts and information. This paper aims to bring out the fact that tweets containing all handles related to COVID-19 and WHO have been unsuccessful in guiding people around this pandemic outbreak appositely. This study analyzes two types of tweets gathered during the pandemic times. In one case, around twenty three thousand most re-tweeted tweets within the time span from 1st Jan 2019 to 23rd March 2020 have been analyzed and observation says that the maximum number of the tweets portrays neutral or negative sentiments. On the other hand, a dataset containing 226,668 tweets collected within the time span between December 2019 and May 2020 have been analyzed which contrastingly show that there were a maximum number of positive and neutral tweets tweeted by netizens. The research demonstrates that though people have tweeted mostly positive regarding COVID-19, yet netizens were busy engrossed in re-tweeting the negative tweets and that no useful words could be found in WordCloud or computations using word frequency in tweets. The claims have been validated through a proposed model using deep learning classifiers with admissible accuracy up to 81%. Apart from these the authors have proposed the implementation of a Gaussian membership function based fuzzy rule base to correctly identify sentiments from tweets. The accuracy for the said model yields up to a permissible rate of 79%.",health
10.1016/j.anaerobe.2020.102282,Journal,Anaerobe,scopus,2020-12-01,sciencedirect,Characterization of medical relevant anaerobic microorganisms by isothermal microcalorimetry,https://api.elsevier.com/content/abstract/scopus_id/85092451485,"Detection of anaerobe bacteria by culture methods requires appropriate media, special growth conditions, additional detection techniques and it typically takes several days. Therefore, anaerobes are often missed in patient specimens under routine culture conditions. Microcalorimetry may provide a simple and accurate real-time method for faster and better detection of anaerobes. An isothermal calorimeter which detect minimal changes of temperature over time was used for the calorimetric experiments. In order to find optimal growth conditions, seven reference or clinical strains of medical relevant anaerobe bacteria were tested under different circumstances. First, the strains were tested with different growth media. After determining the optimal medium for each strain, the gas phase was modified by adding 3 mL or 4 mL medium, to evaluate growth under conditions with less oxygen. Cooked Meat Medium was best supporting growth of the tested strains, including Cutibacterium acnes, Fusobacterium nucleatum, Finegoldia magna, Parvimonas micra, Bacteroides fragilis and Actinomyces odontolyticus, followed by thioglycolate. The best medium to detect Clostridioides difficile was H-Medium. All tested strains showed better growth in 4 mL medium than in 3 mL. The detection time ranged between 10 and 72 h. Our results demonstrated that the sensitivity and the detection time of anaerobe bacteria can be improved by isothermal calorimetry with optimization of growth conditions. Therefore, calorimetric detection, a practical, quick and easy-to-do method, has the potential to replace current microbiological methods.",health
10.1016/j.asoc.2020.106732,Journal,Applied Soft Computing Journal,scopus,2020-12-01,sciencedirect,Capsule Neural Networks for structural damage localization and quantification using transmissibility data,https://api.elsevier.com/content/abstract/scopus_id/85092175198,"One of the current challenges in structural health monitoring (SHM) is to take the most advantage of large amounts of data to deliver accurate damage measurements and predictions. Deep Learning methods tackle these problems by finding complex relations hidden in the data available. Amongst these, Capsule Neural Networks (CapsNets) have recently been developed, achieving promising results in benchmark Deep Learning problems. In this paper, Capsule Networks are expanded to locate and to quantify structural damage. The proposed approach is evaluated in two case studies: a system with springs and masses that simulate a structure, and a beam with different damage scenarios. For both case studies, training and validation sets are created using Finite Element (FE) models and calibrated with experimental data, which is also used for testing. The main contributions of this study are: A novel CapsNets-based method for dual classification–regression task in SHM, analysis of both routing algorithms (dynamic routing and Expectation–Maximization routing) in the context of SHM, and analysis of generalization between FE models and real-life experiments. The results show that the proposed Capsule Networks with dynamic routing achieve better results than Convolutional Neural Networks (CNN), especially when it comes to false positive values.",health
10.1016/j.exppara.2020.108014,Journal,Experimental Parasitology,scopus,2020-12-01,sciencedirect,Analytical sensitivity of loopamp and quantitative real-time PCR on dried blood spots and their potential role in monitoring human African trypanosomiasis elimination,https://api.elsevier.com/content/abstract/scopus_id/85092023989,"The objective set by WHO to reach elimination of human African trypanosomiasis (HAT) as a public health problem by 2020 is being achieved. The next target is the interruption of gambiense-HAT transmission in humans by 2030. To monitor progress towards this target, in areas where specialized local HAT control capacities will disappear, is a major challenge. Test specimens should be easily collectable and safely transportable such as dried blood spots (DBS). Monitoring tests performed in regional reference centres should be reliable, cheap and allow analysis of large numbers of specimens in a high-throughput format. The aim of this study was to assess the analytical sensitivity of Loopamp, M18S quantitative real-time PCR (M18S qPCR) and TgsGP qPCR as molecular diagnostic tests for the presence of Trypanosoma brucei gambiense in DBS. The sensitivity of the Loopamp test, with a detection limit of 100 trypanosomes/mL, was in the range of parasitaemias commonly observed in HAT patients, while detection limits for M18S and TgsGP qPCR were respectively 1000 and 10,000 trypanosomes/mL. None of the tests was entirely suitable for high-throughput use and further development and implementation of sensitive high-throughput molecular tools for monitoring HAT elimination are needed.",health
10.1016/j.arr.2020.101174,Journal,Ageing Research Reviews,scopus,2020-12-01,sciencedirect,"A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",https://api.elsevier.com/content/abstract/scopus_id/85091870837,"One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",health
10.1016/j.est.2020.101836,Journal,Journal of Energy Storage,scopus,2020-12-01,sciencedirect,Intelligent state of health estimation for lithium-ion battery pack based on big data analysis,https://api.elsevier.com/content/abstract/scopus_id/85090922628,"State of health (SOH) of in-vehicle lithium-ion batteries not only directly determines the acceleration performance and driving range of electric vehicles (EVs), but also reflects the residual value of the batteries. Especially, with the development of data acquisition and analysis technologies, using big data to realize on-line evaluation of battery SOH shows vital significance. In this paper, we propose an intelligent SOH estimation framework based on the real-world data of EVs collected by the big data platform. Defined by the more accessible detection, the health features are extracted from historical operating data. Then, the deep learning process is implemented in feedforward neural network driven by the degradation index. The estimation method is validated by the one-year monitoring dataset from 700 vehicles with different driving mode. The result shows that the proposed framework can effectively estimate SOH with the maximum relative error of 4.5% and describe the aging trend of battery pack based on big data platform.",health
10.1016/j.biotri.2020.100146,Journal,Biotribology,scopus,2020-12-01,sciencedirect,Effects of Mucin on the dexterity and tactile sensitivity of medical glove users,https://api.elsevier.com/content/abstract/scopus_id/85090742355,"The evaluation of medical glove performance has mostly focused on analysing how good a barrier the glove materials are, as well as their durability. Very few studies aim to determine how these gloves affect the performance of the user. This could lead to a lowered ability to carry out tasks, leading to poor healthcare due to diminished sensitivity and dexterity. Furthermore, none of these studies incorporate contaminants to replicate the real-world environments in which medical gloves are used. The work carried out here aims to look at the effects of the bodily fluid mucin on medical glove user's performance. This was assessed via the use of the Purdue Pegboard and Crawford Small Parts Dexterity Test in conjunction with a tactile bump sensitivity test. These tests were carried each in five conditions; bare hand, donned natural rubber latex (NRL) and donned acrylonitrile butadiene rubber (XNBR) gloves – both with and without a 10 mg/ml concentration of porcine gastric mucin applied. The results show that donning gloves decreased dexterity and sensitivity compared to the bare hand. However, mucin was shown to increase dexterity and sensitivity in XNBR, but not with NRL. This is expected to be due to the different ways in which the materials interact with the mucin, affecting the ability to develop a muco-adhesive film and changing the frictional properties of the glove materials.",health
10.1016/j.cmpb.2020.105724,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-12-01,sciencedirect,White learning methodology: A case study of cancer-related disease factors analysis in real-time PACS environment,https://api.elsevier.com/content/abstract/scopus_id/85090232609,"Background and Objective
                  Bayesian network is a probabilistic model of which the prediction accuracy may not be one of the highest in the machine learning family. Deep learning (DL) on the other hand possess of higher predictive power than many other models. How reliable the result is, how it is deduced, how interpretable the prediction by DL mean to users, remain obscure. DL functions like a black box. As a result, many medical practitioners are reductant to use deep learning as the only tool for critical machine learning application, such as aiding tool for cancer diagnosis.
               
                  Methods
                  In this paper, a framework of white learning is being proposed which takes advantages of both black box learning and white box learning. Usually, black box learning will give a high standard of accuracy and white box learning will provide an explainable direct acyclic graph. According to our design, there are 3 stages of White Learning, loosely coupled WL, semi coupled WL and tightly coupled WL based on degree of fusion of the white box learning and black box learning. In our design, a case of loosely coupled WL is tested on breast cancer dataset. This approach uses deep learning and an incremental version of Naïve Bayes network. White learning is largely defied as a systemic fusion of machine learning models which result in an explainable Bayes network which could find out the hidden relations between features and class and deep learning which would give a higher accuracy of prediction than other algorithms. We designed a series of experiments for this loosely coupled WL model.
               
                  Results
                  The simulation results show that using WL compared to standard black-box deep learning, the levels of accuracy and kappa statistics could be enhanced up to 50%. The performance of WL seems more stable too in extreme conditions such as noise and high dimensional data. The relations by Bayesian network of WL are more concise and stronger in affinity too.
               
                  Conclusion
                  The experiments results deliver positive signals that WL is possible to output both high classification accuracy and explainable relations graph between features and class.",health
10.1016/j.renene.2020.06.154,Journal,Renewable Energy,scopus,2020-12-01,sciencedirect,Spatio-temporal fusion neural network for multi-class fault diagnosis of wind turbines based on SCADA data,https://api.elsevier.com/content/abstract/scopus_id/85089269994,"Numerous sensors have been deployed in different locations in components of wind turbines to continuously monitor the health status of the turbine system and accordingly, generate a large volume of operation data by the supervisory control and data acquisition (SCADA) system. Naturally, these sensory data are multivariate time series with high spatio-temporal correlations. It is still challenging to effectively model such correlations and then enable an accurate fault diagnosis. To this end, we proposed a new spatio-temporal fusion neural network (STFNN) for wind turbine fault diagnosis. Specifically, a multi-kernel fusion convolution neural network (MKFCNN) with multiple convolution kernels of different sizes is first designed to extract multi-scale spatial correlations among different variables. Then, we adopt the long short-term memory (LSTM) to further learn the temporal dependence of the learned spatial features. The proposed STFNN model provides an end-to-end fault diagnosis way, which can directly learn spatio-temporal dependency from the raw SCADA data and give the fault diagnosis result. The effectiveness and superiority of the proposed method are evaluated on a generic wind turbine benchmark simulation dataset and a SCADA dataset from a real wind farm. Both experimental results have indicated that the proposed method outperformed several compared methods.",health
10.1016/j.ins.2020.06.072,Journal,Information Sciences,scopus,2020-12-01,sciencedirect,Self-learning based medical image representation for rigid real-time and multimodal slice-to-volume registration,https://api.elsevier.com/content/abstract/scopus_id/85088921051,"Recently, the convolutional neural network (CNN) based real-time slice-to-volume registration methods show great potential in related clinical applications. Generally, these methods are mostly employed in monomodal scenarios because they essentially rely on image intensities. To extend this strategy in more general computer-aided surgery scenarios, we present a self-learning based multimodal image representation model for real-time and multimodal slice-to-volume registration. Different from usual approaches, which utilize structural descriptors or translate the image from one modality to another, the proposed method exploits the highly similar information embedded in multimodal images through the two-channel self-learning strategy based on the CNN. In this way, a universal image representation network for any modality can be achieved. Specifically, different multimodal image pairs can be simultaneously fed into two shared-weight channels in the training phase. The self-learning strategy is concretely implemented by making the paired outputs similar and retaining the edge information of the originals. Subsequently, the image representation of any modality can be realized through one channel. Experiments on different datasets have been conducted to evaluate the proposed method, demonstrating its significant advantage in providing multimodal representation for real-time and multimodal slice-to-volume registration; moreover, it is observed to be superior to the state-of-the-art representation methods.",health
10.1016/j.eswa.2020.113710,Journal,Expert Systems with Applications,scopus,2020-12-01,sciencedirect,A study on adaptation lightweight architecture based deep learning models for bearing fault diagnosis under varying working conditions,https://api.elsevier.com/content/abstract/scopus_id/85088656809,"Deep learning models have been widely studied in fault diagnosis recently. A mainstream application is to recognize patterns in spectrograms of faults. However, some common drawbacks still remain as following: a) Preprocess to improve the quality of spectrograms is rarely explored; b) Computing cost of a conventional CNN far exceeds the requirements of fast analysis in industry; c) Adequate labeled data cannot be acquired to train a comprehensive diagnosis model for varying working conditions. In this paper, an Adaptive Logarithm Normalization (ALN) is proposed to realize preprocess considering data distribution, it attempts to improve the quality of spectrograms via eliminating truncation phenomenon and enriching details simultaneously; Meanwhile, simplified lightweight models are built on the basis of present lightweight building blocks to reduce parameters, while maintaining high performances; Furthermore, an adaptation architecture is proposed by integrating Deep Adaptation Network (DAN) idea with simplified lightweight models, aiming at enhancing the generalization capability of models. Experiments have been carried out to implement the proposed methods with two different datasets. The overall success not only proves the methods feasible, but also indicates a possible diagnosis prospect for real industrial scenarios.",health
10.1016/j.jpdc.2020.07.003,Journal,Journal of Parallel and Distributed Computing,scopus,2020-12-01,sciencedirect,Knowledge-driven machine learning based framework for early-stage disease risk prediction in edge environment,https://api.elsevier.com/content/abstract/scopus_id/85088654909,"Early-stage disease risk prediction can be beneficial to improve the health of the mass and can reduce the economic burden of late treatment. Machine learning has played a pivotal role in predictive systems, which requires achieving a specific degree of accuracy for healthcare systems. Most recently researchers have found the necessity of bridging between epidemiology and machine learning classifications toward health risk prediction. This work proposes an epidemiology knowledge-driven unique model that follows the principle of association rule-based ontology to select features and classification techniques. The goal of this approach is to generalize a framework for future robust systems to predict the likelihood of diseases, which can be executed in the edge computing environment. The framework introduces epidemiological library and structured attribute set along with the library of precaution to derive the disease risk-prediction process. To investigate the adoption of the epidemiology knowledge-driven model, we considered a real dataset of early-stage likelihood prediction of diabetes and carried out a set of experiments for highlighting the significance of several epidemiological factors. The classification aspect of the framework is further compared with widely accepted approaches for machine learning based healthcare, which shows the novelty of the proposed model.",health
10.1016/j.eswa.2020.113707,Journal,Expert Systems with Applications,scopus,2020-12-01,sciencedirect,Classifying Papanicolaou cervical smears through a cell merger approach by deep learning technique,https://api.elsevier.com/content/abstract/scopus_id/85088641238,"Early detection of cancer is important to improve survival and reduce associated morbility. Nowadays, there is no automatic classification process with enough accuracy to be recommended to its use in population cervical cancer screening. In most automatic medical image classifications, these images are clean in background and without overlap between elements, which means that these images do not reflect reality and the model cannot be applied to directly obtained images from medical samples. The objectives of this study are to design and implement a Cell Merger Approach to improve the efficiency and realism of the PAP-smears classification model, by allowing overlapping and folding of different cells, to design and implement a Convolutional Neural Network for PAP-smears image classification, and to optimize and integrate the cell fusion approach with the neural network building a feasible, reliable and highly accurate system for cervical smears classification. The carried out experiments have validated both the CNN and the proposed Cell Merger Approach with very interesting results. The most outstanding results show that the Convolutional Neural Network models together with the Cell Merger Approach have a classification accuracy of 88.8% with a standard deviation of 1%, obtaining a sensitivity and specificity of 0.92 and 0.83 respectively. This classification level depicts a robust and accurate model that is comparable to an expert pathologist competencies.",health
10.1016/j.cmpb.2020.105616,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-12-01,sciencedirect,CLIN-IK-LINKS: A platform for the design and execution of clinical data transformation and reasoning workflows,https://api.elsevier.com/content/abstract/scopus_id/85087430673,"Background and Objective
                  Effective sharing and reuse of Electronic Health Records (EHR) requires technological solutions which deal with different representations and different models of data. This includes information models, domain models and, ideally, inference models, which enable clinical decision support based on a knowledge base and facts. Our goal is to develop a framework to support EHR interoperability based on transformation and reasoning services intended for clinical data and knowledge.
               
                  Methods
                  Our framework is based on workflows whose primary components are reusable mappings. Key features are an integrated representation, storage, and exploitation of different types of mappings for clinical data transformation purposes, as well as the support for the discovery of new workflows. The current framework supports mappings which take advantage of the best features of EHR standards and ontologies. Our proposal is based on our previous results and experience working with both technological infrastructures.
               
                  Results
                  We have implemented CLIN-IK-LINKS, a web-based platform that enables users to create, modify and delete mappings as well as to define and execute workflows. The platform has been applied in two use cases: semantic publishing of clinical laboratory test results; and implementation of two colorectal cancer screening protocols. Real data have been used in both use cases.
               
                  Conclusions
                  The CLIN-IK-LINKS platform allows the composition and execution of clinical data transformation workflows to convert EHR data into EHR and/or semantic web standards. Having proved its usefulness to implement clinical data transformation applications of interest, CLIN-IK-LINKS can be regarded as a valuable contribution to improve the semantic interoperability of EHR systems.",health
10.1016/j.jns.2020.117081,Journal,Journal of the Neurological Sciences,scopus,2020-11-15,sciencedirect,New technologies and Amyotrophic Lateral Sclerosis – Which step forward rushed by the COVID-19 pandemic?,https://api.elsevier.com/content/abstract/scopus_id/85090005531,"Amyotrophic Lateral Sclerosis (ALS) is a fast-progressive neurodegenerative disease leading to progressive physical immobility with usually normal or mild cognitive and/or behavioural involvement. Many patients are relatively young, instructed, sensitive to new technologies, and professionally active when developing the first symptoms. Older patients usually require more time, encouragement, reinforcement and a closer support but, nevertheless, selecting user-friendly devices, provided earlier in the course of the disease, and engaging motivated carers may overcome many technological barriers. ALS may be considered a model for neurodegenerative diseases to further develop and test new technologies. From multidisciplinary teleconsults to telemonitoring of the respiratory function, telemedicine has the potentiality to embrace other fields, including nutrition, physical mobility, and the interaction with the environment. Brain-computer interfaces and eye tracking expanded the field of augmentative and alternative communication in ALS but their potentialities go beyond communication, to cognition and robotics. Virtual reality and different forms of artificial intelligence present further interesting possibilities that deserve to be investigated. COVID-19 pandemic is an unprecedented opportunity to speed up the development and implementation of new technologies in clinical practice, improving the daily living of both ALS patients and carers.
                  The present work reviews the current technologies for ALS patients already in place or being under evaluation with published publications, prompted by the COVID-19 pandemic.",health
10.1016/j.jep.2020.113208,Journal,Journal of Ethnopharmacology,scopus,2020-11-15,sciencedirect,Salvia miltiorrhiza bunge exerts anti-oxidative effects through inhibiting KLF10 expression in vascular smooth muscle cells exposed to high glucose,https://api.elsevier.com/content/abstract/scopus_id/85088872308,"Ethnopharmacological relevance
                  Traditional Chinese medicinal herb Salvia miltiorrhiza Bunge(Danshen) and its components have been widely used to treat cardiovascular diseases for hundreds of years in China, including hypertension, diabetes, atherosclerosis, and chronic heart failure. Salvia miltiorrhiza injection (SMI), an aqueous extracts of Salvia miltiorrhiza Bunge, is one of most widely used traditional Chinese medicine injections. SMI is widely used in the treatment of diabetic vascular complications, However, the mechanisms remain to be defined.
               
                  Aim of the study
                  To investigate protective mechanism of Salvia miltiorrhiza Bunge against ROS generation in VSMCs of diabetic mice and patients.
               
                  Materials and methods
                  
                     Salvia miltiorrhiza injection (hereinafter referred to as SMI, 1.5 g mL−1), which was approved by the State Food and Drug Administration (approval number: Z32020161), was obtained from Shenlong Pharmaceutical Co., Ltd. (batch number: 11040314). SMI or vehicle were intraperitoneally administrated to the HFD-fed db/db mice, artery was harvested after 24weeks later. qRT-PCR and Western blot analysis were used to detect the expression of KLF6, KLF5, KLF4, KLF10, KLF12, and HO-1. DCFH-DA staining detected intracellular ROS production. Loss- and gain-of-function experiments of KLF10 were used to investigate the effect of KLF10 on the expression of HO-1. Dual-luciferase reporter assay evaluated the effect of KLF10 on the activity of the HO-1 promoter.
               
                  Results
                  KLF10 expression and ROS generation are significantly increased in the arteries of HFD-fed db/db mice, VSMCs of diabetic patients, as well as in high glucose-treated VSMCs. KLF10 overexpression suppresses, while its knockdown facilitates the expression of heme oxygenase (HO-1) mRNA and protein. Further, Salvia miltiorrhiza injection (SMI) abrogates KLF10 upregulation and reduces ROS generation induced by high glucose in VSMCs. Mechanistically, KLF10 negatively regulates the HO-1 gene transcription via directly binding to its promoter. Accordingly, SMI treatment of VSMCs reduces ROS generation through inhibiting KLF10 expression and thus relieving KLF10 repression of the expression of HO-1 gene, subsequently contributing to upregulation of HO-1.
               
                  Conclusion
                  
                     SMI exerts anti-oxidative effects on VSMCs exposed to high glucose through inhibiting KLF10 expression and thus upregulating HO-1.",health
10.1016/j.jbi.2020.103590,Journal,Journal of Biomedical Informatics,scopus,2020-11-01,sciencedirect,A virtual reality methodology for cardiopulmonary resuscitation training with and without a physical mannequin,https://api.elsevier.com/content/abstract/scopus_id/85092735575,"Background
                  Cardiopulmonary resuscitation (CPR) is an emergency procedure that can increase survival after a cardiac arrest. Performing CPR effectively requires both procedural knowledge and manual skills. Traditional CPR training methodology includes lessons led by instructors and supervised practice on mannequins, thus requiring considerable resources.
               
                  Objective
                  This paper proposes a new methodology for low-cost CPR training based on virtual reality (VR) with and without the addition of a physical mannequin. Moreover, it describes an experimental evaluation of the methodology that assessed gain in manual skills during training, transfer of procedural knowledge and manual skills in a final assessment, and changes in self-efficacy with three measurements over time (pre-training, post-training, and post-assessment).
               
                  Methods
                  We implemented a VR application that supports the proposed methodology, and can thus be used with or without a mannequin. The experimental evaluation involved 30 participants who tried CPR in VR twice, performing two repetitions of 30 chest compressions per trial. Half participants tried the VR application with the mannequin and half without it. Final assessment required all participants to perform CPR on the mannequin without the assistance of VR. To assess self-efficacy, participants filled in a questionnaire at the three times of measurement.
               
                  Results
                  Mixed-design ANOVAs showed effects of repetition, effects of group, or interaction between the two variables on manual skills assessed during training. In the final assessment, participants in both groups correctly remembered most of the steps of the procedure. ANOVAs revealed differences between the two groups only in pressure-related skills (better with mannequin) and in the number of wrong steps added to the procedure (better without mannequin). Mixed-design ANOVA showed a self-efficacy increase in both groups after training, which was maintained after final assessment.
               
                  Conclusions
                  The proposed VR methodology for CPR training has a positive effect on procedural knowledge, manual skills, and self-efficacy, with as well as without the physical mannequin. Trials on a mannequin are required to understand the correct pressure for chest compression. This supports the adoption of the proposed VR methodology to reduce instructor and mannequin time required to teach CPR to trainees.",health
10.1016/S2215-0366(20)30285-6,Journal,The Lancet Psychiatry,scopus,2020-11-01,sciencedirect,Brain-based mediation of non-conscious reduction of phobic avoidance in young women during functional MRI: a randomised controlled experiment,https://api.elsevier.com/content/abstract/scopus_id/85092479184,"Background
                  Exposure therapy is the treatment of choice for anxiety disorders but requires people to confront feared situations and can be distressing. We tested the hypothesis that exposure without conscious awareness would reduce fear in participants with specific phobia by harnessing the neural circuitry supporting the automatic extinction of fear.
               
                  Methods
                  In this single-centre, randomised controlled experiment, we recruited women aged 18–29 years from an ethnically diverse, community-based population in northeastern USA, between Sept 1, 2013, and Aug 1, 2016. Eligible participants classified as having phobia met the DSM-5 criteria for specific phobia but not for any other disorder, had scores in the top 10% of respondents to the Fear of Spiders Questionnaire, and exhibited impairing avoidance of a live tarantula. Eligible controls met no criteria for any disorder, were in the bottom 30% of questionnaire respondents, and displayed no avoidance of the tarantula. The randomisation schedule was generated with the open source Research Randomizer Tool. A research assistant randomly assigned participants to the active intervention of very brief exposure (VBE)—the repeated presentation of masked phobic stimuli (ie, spiders)—or the control intervention which used masked flowers (VBF). VBE and VBF were given code numbers to prevent staff from knowing which intervention they were administering. During a 10 min functional MRI (fMRI) task, each participant was exposed to 16 blocks of ten masked target stimuli (spiders or flowers), alternating with 16 blocks of ten masked neutral stimuli. A few minutes after fMRI, participants with spider phobia approached the tarantula again so we could measure changes in phobic behaviour. The primary outcome was real-time changes in brain activity measured by fMRI. All analyses were done by intention to treat.
               
                  Results
                  We recruited 82 women, of whom 42 had spider phobia and 40 were controls. VBE generated stronger neural activity in participants with spider phobia than in controls, particularly in regions supporting emotion, emotion regulation, and attention systems, such as the inferior frontal cortex (Cohen's d 0·95, 95% CI 0·93–0·98, Bayesian posterior probability 99·5%) and the caudate nucleus (1·16, 1·14–1·18, 100·0%). In participants with phobia, VBE also generated stronger activity in these regions than did VBF (eg, dorsal anterior cingulate cortex Cohen's d 0·80, 95% CI 0·78–0·80, Bayesian posterior probability 98·5%; caudate nucleus 1·0, 0·98–1·02, 99·5%). VBE reduced avoidance of the live tarantula in participants with phobia. Regions supporting fear extinction (including ventral medial prefrontal cortex) and emotional salience processing mediated this effect. No adverse events occurred.
               
                  Interpretation
                  VBE reduced fear non-consciously in participants with spider phobia by recruiting brain regions supporting automatic fear extinction, emotion regulation, and top-down attentional processing. Future studies should explore the use of VBE in other fear-based disorders.
               
                  Funding
                  National Institutes of Mental Health and Brain & Behavior Research Foundation.",health
10.1016/j.compbiomed.2020.104038,Journal,Computers in Biology and Medicine,scopus,2020-11-01,sciencedirect,Generating wall shear stress for coronary artery in real-time using neural networks: Feasibility and initial results based on idealized models,https://api.elsevier.com/content/abstract/scopus_id/85092058026,"Computational fluid dynamics (CFD) and medical imaging can be integrated to derive some important hemodynamic parameters such as wall shear stress (WSS). However, CFD suffers from a relatively long computational time that usually varies from dozens of minutes to hours. Machine learning is a popular tool that has been applied to many fields, and it can predict outcomes fast and even instantaneously in most applications. This study aims to use machine learning as an alternative to CFD for generating hemodynamic parameters in real-time diagnosis during medical examinations. To perform the feasibility study, we used CFD to model the blood flow in 2000 idealized coronary arteries, and the calculated WSS values in these models were used as the dataset for training and testing. The preparation of the dataset was automated by scripts programmed in Python, and OpenFOAM was used as the CFD solver. We have explored multivariate linear regression, multi-layer perceptron, and convolutional neural network architectures to generate WSS values from coronary artery geometry directly without CFD. These architectures were implemented in TensorFlow 2.0. Our results showed that these algorithms were able to generate results in less than 1 s, proving its capability in real-time applications, in terms of computational time. Based on the accuracy, convolutional neural network outperformed the other architectures with a normalized mean absolute error of 2.5%. Although this study is based on idealized models, to the best of our knowledge, it is the first attempt to predict WSS in a stenosed coronary artery using machine learning approaches.",health
10.1016/j.engappai.2020.103968,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-11-01,sciencedirect,Group reduced kernel extreme learning machine for fault diagnosis of aircraft engine,https://api.elsevier.com/content/abstract/scopus_id/85091667321,"The original kernel extreme learning machine (KELM) employs all training samples to construct hidden layer, thus avoiding the performance fluctuations caused by the ELM randomly assigning weights. However, excessive nodes will inevitably lead to structural redundancy, which hinders its application in systems with high real-time performance requirements but limited onboard storage and computing capacity. Considering the well interpretability of sparse learning, this study introduces the group sparse structure for KELM to resolve its limitation of structural redundancy. Specifically, the proposed novel method introduces a special norm to reformulate the dual optimization problem of KELM to realize group sparse structure in output weights. As a result, nodes with large weights can be selected as the significant nodes, while nodes with small weights will be regarded as the redundant nodes and neglected directly. In addition, we have also devised an alternating iterative optimization algorithm and deduced the complete proof of convergence to solve the non-smoothness optimization problem in proposed method. Then, the validity and feasibility of the proposed method are verified by extensive experiments on benchmark datasets. More importantly, tests of fault diagnosis for an aircraft engine show that the proposed approach can maintain the competitive recognition performance with much faster testing speed.",health
10.1016/j.fsi.2020.09.012,Journal,Fish and Shellfish Immunology,scopus,2020-11-01,sciencedirect,"Fish IKKα from Japanese eel (Anguilla japonica) can activate NF-κB, AP1, and type I IFN signaling pathways",https://api.elsevier.com/content/abstract/scopus_id/85091219497,"Inhibitor of nuclear factor kappa-B kinase subunit alpha (IKKα) plays a pivotal role in the activation of nuclear factor kappa-B (NF-κB) pathway in response to pathogens infections in mammals, but the information about IKKα in the regulation of immune responses is still limited in teleost fishes. In the present study, the full-length cDNA of an IKKα homologue, AjIKKα, was cloned by 5′ and 3′ SMART RACE from Japanese eel, and its characteristics of expression in response to various PAMPs and A. hydrophila infection were investigated both in vivo and in vitro using quantitative real-time polymerase chain reaction (qRT-PCR). In addition, the subcellular localization of AjIKKα GFP fusion protein and the induction of AjIKKα in the activation of NF-κB, type I IFN and AP1 performed using Dual-Glo luciferase assay system were also detected. Sequence comparison analysis revealed that AjIKKα has typical conserved domains, including an N-terminal kinase domain, an ubiquitin-like domain, a scaffold dimerization domain, and a C-terminal NEMO-binding domain. The predicted three-dimensional structure of AjIKKα is similar to that of human IKKα. Quantitative real-time polymerase chain reaction (qRT-PCR) analysis revealed a broad expression for AjIKKα in a wide range of tissues, with the highest expression in the liver, followed by the intestine, gills, and spleen, and with a lower expression in the muscle and heart. The AjIKKα expressions in the liver and kidney were significantly induced following injection with the viral mimic poly I:C and Aeromonas hydrophila infection, whereas the bacterial mimic LPS down-regulated the expression of AjIKKα in the spleen. In vitro, the AjIKKα transcripts of Japanese eel liver cells were significantly enhanced by the treatment of LPS, poly I:C, CpG-DNA, and PGN or the stimulation of different concentration of Aeromonas hydrophila (1 × 106 cfu/mL, 1 × 107 cfu/mL, and 1 × 108 cfu/mL). Luciferase assays demonstrated that AjIKKα expression could significantly induce NF-κB, AP-1 and type I IFN promoter activation in a dose-dependent manner. Additionally, subcellular localization studies showed that AjIKKα was evenly distributed in the cytoplasm in the natural state, but AjIKKα was found to aggregate into spots in the cytoplasm after the stimulation of LPS and poly I:C. These results collectively indicated that AjIKKα plays an important role in innate immunity of host against antibacterial and antiviral infection likely via the activation of NF-κB, AP1and type I IFN signaling pathway.",health
10.1016/j.cie.2020.106816,Journal,Computers and Industrial Engineering,scopus,2020-11-01,sciencedirect,Ergonomic risk assessment based on computer vision and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85090876246,"We develop a novel method that performs accurate ergonomic risk assessment, automatically computing Rapid Upper Limb Assessment (RULA) scores from snapshots or digital video using computer vision and machine learning techniques. Our method overcomes the limitations in recent developments based on computer vision or in wearable measurement sensors, being able to perform unsupervised assessment handling multiple workers simultaneously, even under sub-optimal viewing conditions (e.g., poor illumination, occlusions, and unstable camera views). The processing workflow uses open-source neural networks to detect the workers’ skeletons, after which their body-joint positions and angles are inferred, with which RULA scores are computed. The method was tested with computer-generated, controlled real-world image datasets, and with freely available videos taken in outdoor working scenarios. The computed RULA scores were in close agreement with the assessments of seven specialists in the field, achieving a Cohen’s 
                        κ
                      over 0.6 in most real-world experiments.",health
10.1016/j.nedt.2020.104592,Journal,Nurse Education Today,scopus,2020-11-01,sciencedirect,Communication skills training using virtual reality: A descriptive qualitative study,https://api.elsevier.com/content/abstract/scopus_id/85090743102,"Background
                  Modern medical pedagogical strategies are shifting toward the use of virtual patient simulations.
               
                  Objective
                  This study aims to examine students' users' attitudes and experiences and clinical facilitators' perspectives on student performances in the clinical setting post-virtual patient training.
               
                  Design
                  A descriptive qualitative study design was used.
               
                  Setting
                  Nursing faculty at a local university in Singapore.
               
                  Participants
                  24 nursing undergraduates and six clinical facilitators.
               
                  Methods
                  This study is a follow-up of an experimental study on the Virtual Counseling Application Using Artificial Intelligence (VCAAI). The study took place from the academic year 2017/2018 ended in November 2019. Focus group discussions and individual interviews were conducted. All interviews and focus group discussions were audiotaped, transcribed verbatim, and analyzed using thematic analysis.
               
                  Results
                  Two overarching themes (students' virtual patient user experience and clinical facilitators' evaluations of students' clinical communication skills) comprising six themes were generated. Themes under students' user experience included: 1) attitudes toward virtual patient training, 2) virtual patient's role in student development, and 3) enhanced features and implementation suggestions. Themes under clinical facilitators' evaluations included: 1) insights on students' communication skills and 2) approaches to improve communication skills. An overlapping theme titled ‘value of technology in teaching communication’ comprised of mutual feedback from both students and clinical facilitators. Early implementation, continued accessibility, enhancing realism and technological improvements to the VCAAI were listed as key areas for program improvement, while increased situational sensitivity and language training are recommended to further enhance students' communication skills.
               
                  Conclusion
                  The mixed attitudes toward virtual patient interactions and recognitions of the benefits of virtual patient simulations suggest the potential effectiveness of the use of virtual patients in teaching effective nursing communication skills. However, the lack of authenticity and other limitations need to be addressed before official implementations of such trainings with virtual patients to undergraduate nursing curricula.",health
10.1016/j.mpdhp.2020.08.004,Journal,Diagnostic Histopathology,scopus,2020-11-01,sciencedirect,Artificial intelligence in pathology: an overview,https://api.elsevier.com/content/abstract/scopus_id/85090478810,"Artificial intelligence (AI) is at the forefront of modern technology and emerging uses within the healthcare sector are now being realised. Pathology will be a key area where the impact of AI will be felt. With more and more laboratories making the transition to digital pathology this will provide the key infrastructure in which to deploy these tools and their use will start to become a reality in diagnostic practice. The potential of AI in pathology is to create image analysis tools which could either be used for diagnostic support or to derive novel insights into disease biology, in addition to those achievable with a human observer. Some examples providing diagnostic support currently exist for a limited, but expanding number of applications, such as tumour detection, automated tumour grading, immunohistochemistry scoring, and predicting mutation status. There are a number of challenges to consider, not least the validation and regulatory framework for these tools. In this article, we set out an overview of AI in histopathology, discuss its potential workflow applications, and give key examples of the potential for AI in clinical practice. Considerations for the implementation of AI in practice are also explored.",health
10.1016/j.lfs.2020.118305,Journal,Life Sciences,scopus,2020-11-01,sciencedirect,LncRNA PVT1 regulates ferroptosis through miR-214-mediated TFR1 and p53,https://api.elsevier.com/content/abstract/scopus_id/85089997914,"Aim
                  The study aims to investigate the roles of LncRNA and miRNA in ferroptosis in brain ischemia/reperfusion (I/R) in vivo and in vitro.
               
                  Materials and methods
                  qPCR assay was used to analyze lncRNA PVT1 and miR-214 expressions in acute ischemic stroke (AIS) patients. Then, we established brain I/R mice models and OGD/R PC12 cell models to analyze the mechanism of ferroptosis. I/R mice were treated by lncRNA PVT silencing or miR-214 overexpressing lentivirus via lateral ventricles. Infarct size was analyzed by TTC staining, accompanied by the detection of ferroptosis indicators through Perls'Prussian blue staining, iron kit, MDA kit, glutathione kit, GPx activities kit and Western blotting (WB). Dual luciferase reporter assay was used to assess whether miR-214 bound to PVT1, TP53 or TFR1. Co-IP analyzed the interplay of p53 with SLC7A11.
               
                  Key findings
                  We found that the levels of PVT1 were upregulated and miR-214 levels were downregulated in plasma of AIS patients. NIHSS score was positively correlated with PVT1 levels but was negatively with miR-214 levels. PVT1 silencing or miR-214 overexpression significantly reduced infarct size and suppressed ferroptosis in vivo. miR-214 overexpression markedly decreased PVT1 levels. Specifically, miR-214 could bind to 3'untranslated region (3’UTR) of PVT1, TP53 or TFR1. PVT1 overexpression or miR-214 silencing markedly abolished the effects of Ferrostatin-1 on ferroptosis indicators except for TFR1 expression. Besides, miR-214 silencing counteracted the effects of PVT1 knockdown on the ferroptosis-related proteins.
               
                  Conclusion
                  PVT1 regulated ferroptosis through miR-214-mediated TFR1 and TP53 expression. There was a positive feedback loop of lncRNA PVT1/miR-214/p53 possibly.",health
10.1016/j.fsi.2020.07.013,Journal,Fish and Shellfish Immunology,scopus,2020-11-01,sciencedirect,VLRs expression were significantly affected by complement C3 knockdown morphants in Lampetra morii,https://api.elsevier.com/content/abstract/scopus_id/85089418226,"The complement component 3 of the lamprey, a jawless vertebrate, functions as an opsonin during the phagocytosis of rabbit red cells. Furthermore, lamprey C3 may be activated and cleaved into C3b, which is attached to the surface of target cells in the cytolytic process. However, the mechanism mediating the biological function of C3 in the lamprey is unknown. To our knowledge, this study is the first to show that variable lymphocyte receptors (VLRs) expression were significantly affected by complement C3 knockdown morphants in Lampetra morii. We identified the C3 gene in the lamprey genome based on its orthologs, conserved synteny, functional domains, phylogenetic tree, and conserved motifs. Additionally, we determined the optimal infection concentration of Aeromonas hydrophila to perform immune stimulation experiments in the lamprey larvae. The quantitative real-time polymerase chain reaction and immunofluorescence analyses revealed that the expression of Lampetra morii C3 (lmC3) was significantly upregulated in the larvae infected with 107 CFU/mL of A. hydrophila. The lmC3 morphants (lmC3 MO) of lamprey larvae were generated by morpholino-mediated knockdown. The lmC3 MO larvae were highly susceptible to A. hydrophila infection, which indicated that lmC3 is critical in lamprey immune response. The expression of a selected panel of orthologous genes was comparatively analyzed in the infected wild type, infected lmC3 MO, infected control MO, uninfected wild type and uninfected lmC3 MO one-month-old ammocoete larvae. The knockdown of lmC3 strongly affected the expression of VLRA+/VLRB+/VLRC+-associated genes, which was also confirmed by immunohistochemical analysis. Thus, VLR expression were significantly affected by complement C3 knockdown morphants in Lampetra morii.",health
10.1016/j.fsi.2020.06.061,Journal,Fish and Shellfish Immunology,scopus,2020-11-01,sciencedirect,"Bacillus subtilis H2 modulates immune response, fat metabolism and bacterial flora in the gut of grass carp (Ctenopharyngodon idellus)",https://api.elsevier.com/content/abstract/scopus_id/85088932023,"Functional ingredients such as Bacillus subtilis are used in aquaculture to improve fish condition, modulate microbiota and promote a healthy intestinal system. However, the underlying mechanisms of grass carp treated with B. subtilis are not fully characterized. This study investigated the gut microbes of grass carp after treated with B. subtilis H2 (106 CFU/mL) and Aeromonas hydrophila (106 CFU/mL). The intestinal flora was found that the dominant bacterial phyla identified in all samples were Proteobacteria, Actinobacteria, Fusobacteria, Bacteroidetes and Acidobacteria. Compared with the control group, the relative abundance of Proteobacteria and Bacteroidetes in B. subtilis group were significantly increased. In addition, the relative abundances of Aeromonas and Shewanella in A. hydrophila group were more than the control group. For the intestinal transcriptomic profiling of the grass carp treated with B. subtilis H2, 824 different expressed genes (DEGs) between the B. subtilis H2 treated and non-treated groups were detected, including 365 up-regulated and 459 down-regulated genes. Six DEGs were randomly selected for further validation by quantitative real-time RT-PCR (qRT-PCR) and the results were consistent with the RNA-seq data. Additionally, eight immunomodulatory genes (IL-4, IL-11, IFN-α, CSF, FOSB, MAPK12b, IGHV3-11 and IGHV3-21) were significantly up-regulated after treated with B. subtilis H2. Furthermore, almost all the lipid metabolism-associated genes were significantly up-regulated after treated with B. subtilis H2 according to the lipid metabolism pathways. Eleven lipid metabolism-associated genes were selected by qRT-PCR, which showed that the expressions of almost all the selected genes were increased, especially Apob-48, ABCG8 and DGAT. Taken together, our results support that B. subtilis could modulate the immune response, fat metabolism and bacterial assembly in the gut of grass carp.",health
10.1016/j.ipm.2020.102347,Journal,Information Processing and Management,scopus,2020-11-01,sciencedirect,I see it in your eyes: Training the shallowest-possible CNN to recognise emotions and pain from muted web-assisted in-the-wild video-chats in real-time,https://api.elsevier.com/content/abstract/scopus_id/85087970812,"A robust value- and time-continuous emotion recognition has enormous potential benefits within healthcare. For example, within mental health, a real-time patient monitoring system capable of accurately inferring a patient’s emotional state could help doctors make an appropriate diagnosis and treatment plan. Such interventions could be vital in terms of ensuring a higher quality of life for the patient involved. To make such tools a reality, the associated machine learning systems need to be fast, robust and generalisable. In this regard, we present herein, a novel emotion recognition system consisting of the shallowest realisable Convolutional Neural Network (CNN) architecture. We draw insights from visualisations of the trained filter weights and the facial action unit (FAU) activations, i. e. the inputs to the model, of the participants featured in the in-the-wild, spontaneous video-chat sessions of the SEWA corpus. Further, we demonstrate the generalisablity of this approach on the German, Hungarian, and Chinese cultures available in this corpus. The obtained cross-cultural performance is a testimony to the universality of FAUs in expression and understanding of the human affective behaviours. These learnings were moderately consistent with the human perception of emotional expression. The practicality of the proposed approach is also demonstrated in another key healthcare applications; pain intensity prediction. Key results from these experiments highlight the transparency of the shallow CNN structure. As FAU can be extracted in near real-time, and because the models we developed are exceptionally shallow, this study paves the way for a robust, cross-cultural, end-to-end, in-the-wild, explainable real-time affect and pain prediction, that is value- and time-continuous.",health
10.1016/j.ipm.2020.102340,Journal,Information Processing and Management,scopus,2020-11-01,sciencedirect,A topic modeling framework for spatio-temporal information management,https://api.elsevier.com/content/abstract/scopus_id/85087504158,"Real-time processing and learning of conflicting data, especially messages coming from different ideas, locations, and time, in a dynamic environment such as Twitter is a challenging task that recently gained lots of attention. This paper introduces a framework for managing, processing, analyzing, detecting, and tracking topics in streaming data. We propose a model selector procedure with a hybrid indicator to tackle the challenge of online topic detection. In this framework, we built an automatic data processing pipeline with two levels of cleaning. Regular and deep cleaning are applied using multiple sources of meta knowledge to enhance data quality. Deep learning and transfer learning techniques are used to classify health-related tweets, with high accuracy and improved F1-Score. In this system, we used visualization to have a better understanding of trending topics. To demonstrate the validity of this framework, we implemented and applied it to health-related twitter data from users originating in the USA over nine months. The results of this implementation show that this framework was able to detect and track the topics at a level comparable to manual annotation. To better explain the emerging and changing topics in various locations over time the result is graphically displayed on top of the United States map.",health
10.1016/j.cmpb.2020.105508,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-11-01,sciencedirect,A size-invariant convolutional network with dense connectivity applied to retinal vessel segmentation measured by a unique index,https://api.elsevier.com/content/abstract/scopus_id/85086575110,"Background and objectives: Retinal vessel segmentation (RVS) helps in diagnosing diseases such as hypertension, cardiovascular diseases, and others. Convolutional neural networks are widely used in RVS tasks. However, how to comprehensively evaluate the segmentation results and how to improve the networks’ learning ability are two great challenges.
                  
                     Methods: In this paper, we proposed an ingenious index: fusion score (FS), which provides an overall measure for those binary images. The FS converts multiple metrics into a single target, and therefore facilitates the optimal threshold’s selection and models’ comparison. In addition, We simultaneously combined size-invariant feature maps and dense connectivity together to improve the traditional CNN’s learning ability. Therefore, a size-invariant convolutional network with dense connectivity is designed for RVS. The size-invariant skill helps the deep layers create feature maps with high resolution. The dense connectivity technique is utilized to integrate those hierarchical features and reuse characteristic maps to enhance the network’s learning ability. Finally, an optimized threshold is used on the output image to obtain a binary image.
                  
                     Results: The results of experiments conducted on two shared retinal image databases, DRIVE and STARE, demonstrate that our approach outperforms other techniques when evaluated in terms of F1-score, Matthews correlation coefficient (MCC), G-mean and FS. In addition, the cross training reveals that our method has stronger robustness with respect to training sets. Segmenting a 565 × 584 image only takes 39 ms with a single GPU (graphics processing unit).
                  
                     Conclusions: Compared with those traditional metrics, the FS is a better indicator to measure the results of RVS tasks. The experimental results revealed that the proposed method is more suitable for real-world applications.",health
10.1016/j.measurement.2020.107847,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Under the background of healthy China: Regulating the analysis of hybrid machine learning in sports activities to control chronic diseases,https://api.elsevier.com/content/abstract/scopus_id/85086573801,"One of the most important concerns in human life is concentrating on health. Major threats to human life are chronic diseases such as cancer and diabetes. China government mainly focusing on understanding the progression and spreading of chronic diseases over the population for allocating medical resources and designing a strategy in healthcare. Various conventional methods have been used for fetching chronic disease indicators in large scale based on the population health. But they are costly, not time effective and less accuracy in prediction. But this paper used Hybrid Predicting Model designed by incorporating the main features of the Gaussian Mixture Method and Collaborating Topic Modelling to increase the prediction accuracy. The proposed HPM method experimented on human mobility pattern dataset collected from the various metropolitan area of China. From the dataset, HPM predicts the rate of chronic disease presence and relative activity. GMM obtain the health condition whereas CTM obtains the data sparsity. The proposed hybrid prediction method is implemented in MATLAB software and experimented. Form the obtained results and comparing with the other existing methods, it is identified that the HPM outperforms in terms of prediction accuracy. HPM is evaluated using real-time check-in and chronic disease dataset in China cities. The proposed HPM method obtained 0.09% of the value which is high than the other baseline methods. From the obtained MSE and value, it is well clear the proposed HPM outperforms than the baseline methods.",health
10.1016/j.measurement.2020.108052,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Deep learning-based prognostic approach for lithium-ion batteries with adaptive time-series prediction and on-line validation,https://api.elsevier.com/content/abstract/scopus_id/85086367941,"Prognostics for lithium-ion batteries is very critical in many industrial applications, and accurate prediction of battery state of health (SOH) is of great importance for health management. This paper proposes a novel deep learning-based prognostic method for lithium-ion batteries with on-line validation. An effective variant of recurrent neural network, i.e. long short-term memory structure, is used with variable input dimension, that facilitates network training with additional labeled samples. Adaptive time-series predictions are carried out for prognostics. An on-line validation method is further proposed for parameter optimization in real time based on the available system information, which allows for continuous model improvement. Experiments on a popular lithium-ion battery dataset are implemented to validate the effectiveness and superiority of the proposed method. The experimental results show the prognostic performances are promising both for the multi-steps-ahead predictions and long-horizon SOH estimations.",health
10.1016/j.jclepro.2020.121941,Journal,Journal of Cleaner Production,scopus,2020-10-20,sciencedirect,Artificial intelligence-enabled context-aware air quality prediction for smart cities,https://api.elsevier.com/content/abstract/scopus_id/85088373071,"Metropolitan areas around the world are experiencing a surge in air pollution levels due to different anthropogenic causes, making accurate air quality prediction a critical task for public health. Although many prediction systems have been researched and modelled, many of them have neglected the different effects that air pollution has on each individual citizen. Hence, we present a novel context prediction model that includes context-aware computing concepts to merge an accurate air pollution prediction algorithm (using Long Short-Term Memory Deep Neural Network) with information from both surrounding pollution sources (e.g., bushfire incidents, traffic volumes) and user’s health profile. This model is then integrated into a tool called My Air Quality Index (MyAQI), which is further implemented and evaluated in a real-life use case set up in Melbourne Urban Area (Victoria, Australia). Results obtained with MyAQI show both that (i) high precision levels are reached (90–96%) when forecasting air quality situations in four air quality monitoring stations, and (ii) the proposed model is highly adaptable to users’ individual health condition effects under the same airborne pollutant levels.",health
10.1016/j.virusres.2020.198140,Journal,Virus Research,scopus,2020-10-15,sciencedirect,Potentiality to natural immunization inducement against VHS in olive flounder by live VHSV immersion vaccination at temperature controlled culture condition,https://api.elsevier.com/content/abstract/scopus_id/85089812520,"Viral hemorrhagic septicemia virus (VHSV) is the etiological agent of viral hemorrhagic septicemia (VHS), one of the most severe viral diseases affecting cultured olive flounder (Paralichthys olivaceus) in Far East Asia. VHS occurs during the winter or spring season when the water temperature is low (9–15 °C). In our previous study found that VHSV infection had controlled by using water temperature (above 17 °C). By using water temperature, we demonstrated optimal live VHSV immersion vaccine treatment concentration, also live VHSV immersion vaccine treatment method. We confirmed that the effective VHSV immersion treatment was 105.5 TCID50/mL at 17 °C. It was no need pretreatment before live VHSV immersion vaccination. The VHSV titer of vaccinated fish organs was under the estimated limit (<1.8 log TCID50/mL) within 3 days in 105.5 TCID50/mL live VHSV immersion at 17 °C. High survival rates were observed in live VHSV immersion with 105.5 and 107.5 TCID50/mL at 17 °C and then infected VHSV at 10 °C. VHSV specific antibody was not detected from in the surviving flounder under VHSV infection after immersion treatment with live VHSV. In addition, the potentiality of natural immunization against VHS in olive flounder was suggested by live VHSV immersion vaccine at temperature controlled fish culture condition.",health
10.1016/j.patter.2020.100108,Journal,Patterns,scopus,2020-10-09,sciencedirect,Using Machine Learning to Identify Adverse Drug Effects Posing Increased Risk to Women,https://api.elsevier.com/content/abstract/scopus_id/85102228908,"Adverse drug reactions are the fourth leading cause of death in the US. Although women take longer to metabolize medications and experience twice the risk of developing adverse reactions compared with men, these sex differences are not comprehensively understood. Real-world clinical data provide an opportunity to estimate safety effects in otherwise understudied populations, i.e., women. These data, however, are subject to confounding biases and correlated covariates. We present AwareDX, a pharmacovigilance algorithm that leverages advances in machine learning to predict sex risks. Our algorithm mitigates these biases and quantifies the differential risk of a drug causing an adverse event in either men or women. AwareDX demonstrates high precision during validation against clinical literature and pharmacogenetic mechanisms. We present a resource of 20,817 adverse drug effects posing sex-specific risks. AwareDX, and this resource, present an opportunity to minimize adverse events by tailoring drug prescription and dosage to sex.",health
10.1016/j.heliyon.2020.e05243,Journal,Heliyon,scopus,2020-10-01,sciencedirect,"Fast, easy, cheap, robust and safe method of analysis of Sudan dyes in chilli pepper powder",https://api.elsevier.com/content/abstract/scopus_id/85092504210,"Illicit use of Sudan dyes, a group of harmful and carcinogenic azo dyes, in the food industry has taken a surge in various parts of the world, especially in Africa. Their use in food as additives pose a dire health risk to consumers and have been banned by various food regulatory bodies worldwide. To help increase surveillance, various methods have been proposed for their analysis in literature. This study also sought to experiment and propose an alternative method for quick, easy, cheap, robust and ecologically safe analysis of Sudan dyes in chilli pepper powder and similar matrices. The optimized method used a 6.0 mL mixture of acetone:acetonitrile (1:5 v/v) solvent in a modified QuEChERs method for extraction of Sudan dyes I-IV. The simultaneous analysis of the dyes were achieved on Shimadzu prominence UFLC 20AD coupled with SPD 20AX UV detector operated at dual wavelength of 500 and 480 nm. A total of twenty four (24) chilli pepper powder samples from eight different vendors on the Ghana market were analysed using the optimized method. Quantitation of analytes were done using the external standard calibration method with determination coefficient, R2 > 0.9999. The limit of detection (LOD) and limit of quantitation (LOQ) of the method were 0.02–0.04 mg/kg and 0.05–0.13 mg/kg respectively. A good recovery range between 85.3 – 121.2% were obtained for a spike level of 1.0 mg/kg in real samples. ANOVA analysis at 95% CL showed statistically no significant difference (p > 0.05) in the recoveries between samples and also between the individual compounds. The method experimented and proposed in this study is fast, easy, cheap, robust and ecologically safe, presenting an alternative method for routine analysis for increased rate of surveillance against the illicit use of Sudan dyes as food additives.",health
10.1016/j.compbiomed.2020.104004,Journal,Computers in Biology and Medicine,scopus,2020-10-01,sciencedirect,Scalable and energy efficient seizure detection based on direct use of compressively-sensed EEG data on an ultra low power multi-core architecture,https://api.elsevier.com/content/abstract/scopus_id/85091921119,"Extracting information from dense multi-channel neural sensors for accurate diagnosis of brain disorders necessitates computationally expensive and advanced signal processing approaches to analyze the massive volume of recorded data. Compressive Sensing (CS) is an efficient method for reducing the computational complexity and power consumption in the resource-constrained multi-site neural systems. However, reconstructing the signal from compressed measurements is computationally intensive, making it unsuitable for real-time applications such as seizure detection. In this paper, a seizure detection algorithm is proposed to overcome these limitations by circumventing the reconstruction phase and directly processing the compressively sampled EEG signals. The Lomb-Scargle Periodogram (LSP) is used to extract the spectral energy features of the compressed data. Performance of the seizure detector using non-linear support vector machine (SVM) classifier, tested on 24 patients of the CHB-MIT data-set for compression ratios (CR) of 1–64x, is 96–93%, 92-87%, 0.95–0.91, and <1 s for sensitivity, accuracy, the area under the curve, and latency, respectively. A power-efficient classification method based on the utilization of dual linear SVM classifiers is proposed. The proposed classification method based on the dual linear SVM classification achieved better classification performance compared to commonly used classifiers, such as K-nearest neighbor, random forest, artificial neural network, and linear SVM, while consuming low power in comparison to non-linear SVM kernels. The hardware-optimized implementation of this algorithm is proposed on a low-power multi-core SoC for near-sensor data analytics: Mr. Wolf. Optimized implementation of this algorithm on Mr. Wolf platform leads to detecting a seizure with an energy budget of 18.4 μJ and 3.9 μJ for a compression ratio of 24x using non-linear SVM classifier and the dual linear SVM based classification method, respectively.",health
10.1016/j.micpro.2020.103227,Journal,Microprocessors and Microsystems,scopus,2020-10-01,sciencedirect,Fog Computing-inspired Smart Home Framework for Predictive Veterinary Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85089574391,"Domestic Pet Care has been an important domain in the healthcare industry. In the presented study, a comprehensive framework of the Smart VetCare system for the health monitoring of domestic pets has been presented. The work is focused on the remote surveillance of domestic animals’ health conditions inside the home environment using IoMT Technology. Specifically, pet health is analyzed for vulnerability in the ambient home environment and ubiquitous activities over a fog computing platform of FogBus. Furthermore, a temporal data granule is formulated and the Probability of Health Vulnerability (PoHV) is defined for determining the health severity of the animal. Additionally, the Temporal Sensitivity Measure (TSM) is defined for real-time pet healthcare analysis, which is visualized using the Self Organized Mapping (SOM) Technique. For validation purposes, the framework is deployed in the smart home environment using 12 IoMT WiSense Nodes and Health Sensor belt for monitoring a domestic dog of American Bully breed over the dynamic resource management platform of FogBus and iFogSim simulator. Based on the comparison with numerous state-of-the-art techniques, the proposed framework can register a better precision value (94.78%), accuracy value (95.38%), sensitivity value (93.71%), and f-measure value (94.41%).",health
10.1016/j.ohx.2020.e00131,Journal,HardwareX,scopus,2020-10-01,sciencedirect,Partially RepRapable automated open source bag valve mask-based ventilator,https://api.elsevier.com/content/abstract/scopus_id/85089470505,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided.",health
10.1016/j.ijrefrig.2020.06.020,Journal,International Journal of Refrigeration,scopus,2020-10-01,sciencedirect,Machine learning enhanced inverse modeling method for variable speed air conditioning systems,https://api.elsevier.com/content/abstract/scopus_id/85089143501,"Various faults may occur in the air conditioning systems due to improper installation and poor maintenance. Various fault detection and diagnosis methods have been developed, which need lots of data to evaluate the protocols. However, experimental data is usually not sufficient. The FDD protocols especially machine learning based can easily overfit the limited experiment data. It may be not satisfied for the real applications because of wider range of operation. The machine learning enhanced inverse modeling method is presented to generate the simulation data under various conditions of different scenarios. The clustering algorithm is used to classify the training data reasonably balancing the weights of different conditions. The particle swarm optimization (PSO) is developed to obtain the global optimal estimation of model parameters under wider operation conditions. The experimental data of both variable and constant speed systems are used to validate clustering-PSO enhanced algorithm, which shows acceptable capability and accuracy of prediction.",health
10.1016/j.exppara.2020.107958,Journal,Experimental Parasitology,scopus,2020-10-01,sciencedirect,A tick cell line as a powerful tool to screen the antimicrobial susceptibility of the tick-borne pathogen Anaplasma marginale,https://api.elsevier.com/content/abstract/scopus_id/85089108991,"Anaplasma marginale is the causative agent of the severe bovine anaplasmosis. The tick Rhipicephalus microplus is one of the main vectors of A. marginale in tropical and subtropical regions of the world. After the tick bite, the bacterium invades and proliferates within the bovine erythrocytes leading to anemia, impairment of milk production and weight loss. In addition, infection can cause abortion and high mortality in areas of enzootic instability. Immunization with live and inactivated vaccines are employed to control acute bovine anaplasmosis. However, they do not prevent persistent infection. Consequently, infected animals, even if immunized, are still reservoirs of the bacterium and contribute to its dissemination. Antimicrobials are largely employed for the prophylaxis of bovine anaplasmosis. However, they are often used in sublethal doses which may select pre-existing resistant bacteria and induce genetic or phenotypic variations. Therefore, we propose a new standardized in vitro assay to evaluate the susceptibility of A. marginale strains to different antimicrobials. This tool will help health professionals to choose the more adequate treatment for each herd which will prevent the selection and spread of resistant strains. For that, we initially evaluated the antimicrobial susceptibility of two field isolates of A. marginale (Jaboticabal and Palmeira) infecting bovines. The least susceptible strain (Jaboticabal) was used for the standardization of an antimicrobial assay using a culture of Ixodes scapularis-derived tick cell line, ISE6. Results showed that enrofloxacin (ENRO) at 0.25, 1 or 4 μg/mL and oxytetracycline (OTC) at 4 or 16 μg/mL are the most efficient treatments, followed by OTC at 1 μg/mL and imidocarb dipropionate (IMD) at 1 or 4 μg/mL. In addition, this proposed tool has technical advantages compared to the previously established bovine erythrocyte culture. Thereby, it may be used to guide cattle farmers to the correct use of antimicrobials. The choice of the most suitable antimicrobial is essential to eliminate persistent infections, prevent the spread of resistant strains and help controlling of bovine anaplasmosis.",health
10.1016/j.berh.2020.101559,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2020-10-01,sciencedirect,Innovations to improve access to musculoskeletal care,https://api.elsevier.com/content/abstract/scopus_id/85088788188,"Innovation is a form of realising a new way of doing something, often ignoring traditional wisdom, in order to meet new challenges. Globally, particularly in emerging economies, the high burden of musculoskeletal conditions and their contribution to multimorbidity continue to rise, as does the gap for services to deliver essential care. There is a growing need to find solutions to this challenge and deliver person-centred and integrated care, wherein empowering patients with the capacity for self-management is critical. Whilst there is an abundance of information available online to support consumer education, the number of sources for credible medical information is diluted by uninformed anecdotal social media solutions. Even with the provision of high-quality information, behavioural change does not necessarily follow, and more robust educational approaches are required.
                  In this chapter, we examine innovation, its management and the strategic directions required to improve musculoskeletal healthcare at macro (policy), meso (service delivery) and micro (clinical practice) levels. We discuss the critical role of consumer agency (patients and their families/carers) in driving innovation and the need to leverage this through empowerment by education.
                  We provide a snapshot of real-world examples of innovative practices including capacity building in consumer and interprofessional musculoskeletal education and practice; recommendations to transform the access and delivery of integrated, person-centred care; and initiatives in musculoskeletal care and implementation of models of care, enabled by digital health solutions including telehealth, remote monitoring, artificial intelligence, blockchain technology and big data. We provide emerging evidence for how innovation can support systems' strengthening and build capacity to support improved access to ‘right’ musculoskeletal care, and explore some of the ways to best manage innovations.
                  We conclude with recommended systematic steps to establish required leadership, collaboration, research, networking, dissemination, implementation and evaluation of future innovations in musculoskeletal health and care.",health
10.1016/j.media.2020.101793,Journal,Medical Image Analysis,scopus,2020-10-01,sciencedirect,Cascaded one-shot deformable convolutional neural networks: Developing a deep learning model for respiratory motion estimation in ultrasound sequences,https://api.elsevier.com/content/abstract/scopus_id/85088385162,"Improving the quality of image-guided radiation therapy requires the tracking of respiratory motion in ultrasound sequences. However, the low signal-to-noise ratio and the artifacts in ultrasound images make it difficult to track targets accurately and robustly. In this study, we propose a novel deep learning model, called a Cascaded One-shot Deformable Convolutional Neural Network (COSD-CNN), to track landmarks in real time in long ultrasound sequences. Specifically, we design a cascaded Siamese network structure to improve the tracking performance of CNN-based methods. We propose a one-shot deformable convolution module to enhance the robustness of the COSD-CNN to appearance variation in a meta-learning manner. Moreover, we design a simple and efficient unsupervised strategy to facilitate the network's training with a limited number of medical images, in which many corner points are selected from raw ultrasound images to learn network features with high generalizability. The proposed COSD-CNN has been extensively evaluated on the public Challenge on Liver UltraSound Tracking (CLUST) 2D dataset and on our own ultrasound image dataset from the First Affiliated Hospital of Sun Yat-sen University (FSYSU). Experiment results show that the proposed model can track a target through an ultrasound sequence with high accuracy and robustness. Our method achieves new state-of-the-art performance on the CLUST 2D benchmark set, indicating its strong potential for application in clinical practice.",health
10.1016/j.asoc.2020.106515,Journal,Applied Soft Computing Journal,scopus,2020-10-01,sciencedirect,Fault diagnosis of rolling bearing of wind turbines based on the Variational Mode Decomposition and Deep Convolutional Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85087937848,"Machine learning techniques have been successfully applied in intelligent fault diagnosis of rolling bearings in recent years. However, in the real world industrial application, the dissimilarity of data due to changes in the working conditions and data acquisition environment often cause a poor performance of the existing fault diagnosis methods. Consequently, to address these inadequacies, this paper developed a novel method by integrating the Convolutional Neural Networks (CNNs) with the Variational Mode Decomposition (VMD) algorithms. Named as “Variational Mode Decomposition with Deep Convolutional Neural Networks (VMD-DCNNs)”, the method, in an end-to-end way, directly processes raw vibration signals without artificial experiences and manual intervention to realize the fault diagnosis of rolling bearings. In addition, the CNN technique is used to extract features from each Intrinsic Mode Function (IMF) in order to address the deficiency in extracting features from a single source and to achieve an effective and efficient fault diagnosis of rolling bearings under different environments and states. The value of parameter K of the VMD-DCNNs model is optimized by considering time complexity and generalization ability of the model. Lastly, bearing experiments are conducted to verify the superiority of the VMD-DCNNs in diagnosing fault under different conditions. The visualizations of the signals in the convolutional layer explain the reasonability in selecting the value of parameter K and they also indicate that the translational invariances in a raw IMF component have been learned by the VMD-DCNNs model.",health
10.1016/j.revmed.2020.04.012,Journal,Revue de Medecine Interne,scopus,2020-10-01,sciencedirect,Evaluation of the use of a simulation software in the learning of cardiopulmonary auscultation in undergraduate medical students,https://api.elsevier.com/content/abstract/scopus_id/85087753992,"Introduction
                  Medsounds™ software allows to create an auscultation learning platform, by providing real pre-recorded cardiopulmonary sounds on virtual chests. The study aimed at comparing the skills in cardiopulmonary auscultation between students who benefited from this platform and students who did not have access to it.
               
                  Methods
                  A controlled trial was conducted with 2nd year medical students randomised into three groups. Groups A, B and C received 10 h of cardiopulmonary clinical training. In addition, group B benefited from an online access to the educative platform, and group C had a demonstration of the platform during their clinical training, then an online access. The main outcome was a 3-point multiple-choice questionnaire based on 2 original case vignettes about the description of cardiopulmonary sounds. The secondary outcome was the faculty exam on high-fidelity cardiopulmonary simulator.
               
                  Results
                  Groups A and B included 127 students, and group C 117. Students in group C had a significantly higher score than those in group A (1.72/3 versus 1.48/3; p = 0.02), without difference between the groups B and C. Students who actually had a demonstration of the platform and used it at home had a higher score than those who did not use it (1.87 versus 1.51; p = 0.01). Students who had a demonstration of the platform before using it performed a better pulmonary examination on high-fidelity simulators.
               
                  Conclusion
                  The supervised use of an online auscultation simulation software in addition to the traditional clinical training seems to improve the auscultation performances of undergraduated medical students.",health
10.1016/j.micpath.2020.104376,Journal,Microbial Pathogenesis,scopus,2020-10-01,sciencedirect,Pathogenicity of Aeromonas hydrophila causing mass mortalities of Procambarus clarkia and its induced host immune response,https://api.elsevier.com/content/abstract/scopus_id/85087717503,"Outbreaks of mass mortalities among cultured Procambarus clarkia occurred in a commercial hatchery during the spring of 2019 in Jiangsu province of China. Here, we exploit the pathogenicity and immune response of Aeromonas hydrophila (GPC1-2), which was isolated from diseased P. clarkia. Crayfish challenged showed similar pathological signs to the naturally diseased P. clarkia, lethal dose 50% (LD50) of the strain GPC1-2 to P. clarkia was 3.8 × 106 CFU/mL. Detection of virulence-associated genes by PCR indicated that the strain GPC1-2 carried hlyA, aerA, alt, ast, act, aha, ahp, ahpA, and ahpB. Histopathological analysis of hepatopancreas revealed that the hepatic tubule lumen and the gap between the hepatic tubules became larger, and the brush border disappeared in the P. clarkia infected by GPC1-2. Quantitive real-time PCR (qRT-PCR) was undertaken to measure mRNA expression levels for six immune-related genes in P. clarkia after A. hydrophila infection. The expression level of proPO, NOS, ALF1, TLR2, PX, and AST were detected in hemolymph, hepatopancreas, gill and intestine tissues, and clear transcriptional activation of these genes were observed in the infected individuals. These results revealed pathogenicity of A. hydrophila and its activation of host immune response, which will provide a scientific reference for the breeding and disease prevention in P. clarkia culture.",health
10.1016/j.cmpb.2020.105635,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,Data preprocessing for heart disease classification: A systematic literature review.,https://api.elsevier.com/content/abstract/scopus_id/85087500300,"Context
                  Early detection of heart disease is an important challenge since 17.3 million people yearly lose their lives due to heart diseases. Besides, any error in diagnosis of cardiac disease can be dangerous and risks an individual's life. Accurate diagnosis is therefore critical in cardiology. Data Mining (DM) classification techniques have been used to diagnosis heart diseases but still limited by some challenges of data quality such as inconsistencies, noise, missing data, outliers, high dimensionality and imbalanced data. Data preprocessing (DP) techniques were therefore used to prepare data with the goal of improving the performance of heart disease DM based prediction systems.
               
                  Objective
                  The purpose of this study is to review and summarize the current evidence on the use of preprocessing techniques in heart disease classification as regards: (1) the DP tasks and techniques most frequently used, (2) the impact of DP tasks and techniques on the performance of classification in cardiology, (3) the overall performance of classifiers when using DP techniques, and (4) comparisons of different combinations classifier-preprocessing in terms of accuracy rate.
               
                  Method
                  A systematic literature review is carried out, by identifying and analyzing empirical studies on the application of data preprocessing in heart disease classification published in the period between January 2000 and June 2019. A total of 49 studies were therefore selected and analyzed according to the aforementioned criteria.
               
                  Results
                  The review results show that data reduction is the most used preprocessing task in cardiology, followed by data cleaning. In general, preprocessing either maintained or improved the performance of heart disease classifiers. Some combinations such as (ANN + PCA), (ANN + CHI) and (SVM + PCA) are promising terms of accuracy. However the deployment of these models in real-world diagnosis decision support systems is subject to several risks and limitations due to the lack of interpretation.",health
10.1016/j.cmpb.2020.105643,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,High accurate lightweight deep learning method for gesture recognition based on surface electromyography,https://api.elsevier.com/content/abstract/scopus_id/85087496227,"Background and objectives
                  Surface Electromyography (sEMG) is used mostly for neuromuscular diagnosis, assistive technology, physical rehabilitation, and human-computer interactions. Achieving a precise and lightweight method along with low latency for gesture recognition is still a real-life challenge, especially for rehabilitation and assistive robots. This work aims to introduce a highly accurate and lightweight deep learning method for gesture recognition.
               
                  Methods
                  High-density sEMG, unlike sparse sEMG, does not require accurate electrode placement and provides more physiological information. Then we apply high-density sEMG, which, according to previous studies, leads to sEMG images. In this study, we introduce the Sensor-Wise method, which has a higher capability to extract features compared to the sEMG image method due to its high compatibility with the nature of sEMG signals and the structure of convolutional networks.
               
                  Results
                  The proposed method, because of its optimal structure with only two hidden layers and its high compatibility, has shown no sign of overfitting and was able to reach an accuracy of almost 100% (99.99%) when it was evaluated by CapgMyo DB-a database through 96 electrodes. Using this method, even with 16 electrodes, we were able to reach an accuracy of 99.8%, which was higher than the accuracies reported in the previous studies. Additionally, the method was evaluated by the CSL-HDEMG database, where the accuracy reached 99.55%. Previous studies either introduced expensive computational methods with overfitting or reported lower accuracies compared to this study.
               
                  Conclusions
                  The Sensor- Wise method has high compatibility with the nature of sEMG signals and the structure of convolutional networks. The high accuracy and lightweight structure of this method with only two hidden layers make it a proper option for hardware implementation.",health
10.1016/j.media.2020.101766,Journal,Medical Image Analysis,scopus,2020-10-01,sciencedirect,Uncertainty-aware multi-view co-training for semi-supervised medical image segmentation and domain adaptation,https://api.elsevier.com/content/abstract/scopus_id/85087275458,"Although having achieved great success in medical image segmentation, deep learning-based approaches usually require large amounts of well-annotated data, which can be extremely expensive in the field of medical image analysis. Unlabeled data, on the other hand, is much easier to acquire. Semi-supervised learning and unsupervised domain adaptation both take the advantage of unlabeled data, and they are closely related to each other. In this paper, we propose uncertainty-aware multi-view co-training (UMCT), a unified framework that addresses these two tasks for volumetric medical image segmentation. Our framework is capable of efficiently utilizing unlabeled data for better performance. We firstly rotate and permute the 3D volumes into multiple views and train a 3D deep network on each view. We then apply co-training by enforcing multi-view consistency on unlabeled data, where an uncertainty estimation of each view is utilized to achieve accurate labeling. Experiments on the NIH pancreas segmentation dataset and a multi-organ segmentation dataset show state-of-the-art performance of the proposed framework on semi-supervised medical image segmentation. Under unsupervised domain adaptation settings, we validate the effectiveness of this work by adapting our multi-organ segmentation model to two pathological organs from the Medical Segmentation Decathlon Datasets. Additionally, we show that our UMCT-DA model can even effectively handle the challenging situation where labeled source data is inaccessible, demonstrating strong potentials for real-world applications.",health
10.1016/j.media.2020.101757,Journal,Medical Image Analysis,scopus,2020-10-01,sciencedirect,Yottixel – An Image Search Engine for Large Archives of Histopathology Whole Slide Images,https://api.elsevier.com/content/abstract/scopus_id/85087273852,"With the emergence of digital pathology, searching for similar images in large archives has gained considerable attention. Image retrieval can provide pathologists with unprecedented access to the evidence embodied in already diagnosed and treated cases from the past. This paper proposes a search engine specialized for digital pathology, called Yottixel, a portmanteau for “one yotta pixel,” alluding to the big-data nature of histopathology images. The most impressive characteristic of Yottixel is its ability to represent whole slide images (WSIs) in a compact manner. Yottixel can perform millions of searches in real-time with a high search accuracy and low storage profile. Yottixel uses an intelligent indexing algorithm capable of representing WSIs with a mosaic of patches which are then converted into barcodes, called “Bunch of Barcodes” (BoB), the most prominent performance enabler of Yottixel. The performance of the prototype platform is qualitatively tested using 300 WSIs from the University of Pittsburgh Medical Center (UPMC) and 2,020 WSIs from The Cancer Genome Atlas Program (TCGA) provided by the National Cancer Institute. Both datasets amount to more than 4,000,000 patches of 1000 × 1000 pixels. We report three sets of experiments that show that Yottixel can accurately retrieve organs and malignancies, and its semantic ordering shows good agreement with the subjective evaluation of human observers.",health
10.1016/j.chaos.2020.110059,Journal,"Chaos, Solitons and Fractals",scopus,2020-10-01,sciencedirect,Applications of machine learning and artificial intelligence for Covid-19 (SARS-CoV-2) pandemic: A review,https://api.elsevier.com/content/abstract/scopus_id/85086902632,"Background and objective
                  During the recent global urgency, scientists, clinicians, and healthcare experts around the globe keep on searching for a new technology to support in tackling the Covid-19 pandemic. The evidence of Machine Learning (ML) and Artificial Intelligence (AI) application on the previous epidemic encourage researchers by giving a new angle to fight against the novel Coronavirus outbreak. This paper aims to comprehensively review the role of AI and ML as one significant method in the arena of screening, predicting, forecasting, contact tracing, and drug development for SARS-CoV-2 and its related epidemic.
               
                  Method
                  A selective assessment of information on the research article was executed on the databases related to the application of ML and AI technology on Covid-19. Rapid and critical analysis of the three crucial parameters, i.e., abstract, methodology, and the conclusion was done to relate to the model's possibilities for tackling the SARS-CoV-2 epidemic.
               
                  Result
                  This paper addresses on recent studies that apply ML and AI technology towards augmenting the researchers on multiple angles. It also addresses a few errors and challenges while using such algorithms in real-world problems. The paper also discusses suggestions conveying researchers on model design, medical experts, and policymakers in the current situation while tackling the Covid-19 pandemic and ahead.
               
                  Conclusion
                  The ongoing development in AI and ML has significantly improved treatment, medication, screening, prediction, forecasting, contact tracing, and drug/vaccine development process for the Covid-19 pandemic and reduce the human intervention in medical practice. However, most of the models are not deployed enough to show their real-world operation, but they are still up to the mark to tackle the SARS-CoV-2 epidemic.",health
10.1016/j.cmi.2020.02.006,Journal,Clinical Microbiology and Infection,scopus,2020-10-01,sciencedirect,Machine learning in the clinical microbiology laboratory: has the time come for routine practice?,https://api.elsevier.com/content/abstract/scopus_id/85081582683,"Background
                  Machine learning (ML) allows the analysis of complex and large data sets and has the potential to improve health care. The clinical microbiology laboratory, at the interface of clinical practice and diagnostics, is of special interest for the development of ML systems.
               
                  Aims
                  This narrative review aims to explore the current use of ML In clinical microbiology.
               
                  Sources
                  References for this review were identified through searches of MEDLINE/PubMed, EMBASE, Google Scholar, biorXiv, arXiV, ACM Digital Library and IEEE Xplore Digital Library up to November 2019.
               
                  Content
                  We found 97 ML systems aiming to assist clinical microbiologists. Overall, 82 ML systems (85%) targeted bacterial infections, 11 (11%) parasitic infections, nine (9%) viral infections and three (3%) fungal infections. Forty ML systems (41%) focused on microorganism detection, identification and quantification, 36 (37%) evaluated antimicrobial susceptibility, and 21 (22%) targeted the diagnosis, disease classification and prediction of clinical outcomes. The ML systems used very diverse data sources: 21 (22%) used genomic data of microorganisms, 19 (20%) microbiota data obtained by metagenomic sequencing, 19 (20%) analysed microscopic images, 17 (18%) spectroscopy data, eight (8%) targeted gene sequencing, six (6%) volatile organic compounds, four (4%) photographs of bacterial colonies, four (4%) transcriptome data, three (3%) protein structure, and three (3%) clinical data. Most systems used data from high-income countries (n = 71, 73%) but a significant number used data from low- and middle-income countries (n = 36, 37%). Performance measures were reported for the 97 ML systems, but no article described their use in clinical practice or reported impact on processes or clinical outcomes.
               
                  Implications
                  In clinical microbiology, ML has been used with various data sources and diverse practical applications. The evaluation and implementation processes represent the main gap in existing ML systems, requiring a focus on their interpretability and potential integration into real-world settings.",health
10.1016/j.jaim.2018.02.140,Journal,Journal of Ayurveda and Integrative Medicine,scopus,2020-10-01,sciencedirect,Effect of seeds of Entada phaseoloides on chronic restrain stress in mice,https://api.elsevier.com/content/abstract/scopus_id/85059584549,"Background
                  
                     Entada phaseoloides is a well-known medicinal plant traditionally used in Ayurvedic medicine for centuries.
               
                  Objective
                  To evaluate the anti-stress activity of seeds of E. phaseoloides in endoplasmic reticulum stress during chronic restrain stress in mice, based on our preliminary screening.
               
                  Materials and Methods
                  Mice (n = 6/group) were restrained daily for 6 h in 50 ml polystyrene tubes for 28 days. Methanolic extract of E. phaseoloides (MEEP) (100 and 200 mg/kg, p.o.) and standard drug, imipramine (10 mg/kg i.p.) were administered daily 45 min prior to restrain from day 22–28. Then, forced swim test (FST) was performed to assess despair behavior. Lipid peroxidation (LPO) and antioxidant enzymes Reduced glutathione (GSH), Superoxide dismutase (SOD) were measured in the hippocampus of mice. 78 kDa Glucose-regulated Protein, 94 kDa Glucose-regulated Protein, C/EBP homologous protein, Caspase-12 expression were quantified by Real Time PCR.
               
                  Results
                  MEEP significantly reduced the immobility time in FST (P < 0.001). Significant reduction of LPO (P < 0.05) level and restored antioxidant enzymes viz. GSH (P < 0.001) and SOD towards vehicle control group were observed. Down-regulation of genes GRP 78, GRP 94 (P < 0.001), CHOP and Caspase-12 (P < 0.001) as compared to the chronic restrain stress group was evident, which were upregulated following treatment. Isolation of the active components of the seeds revealed the presence of Oleic acid (1), Entadamide A (2), Entadamide A-beta-d-glucopyranoside (3) and 1-O-protocatechuoyl-β-d-glucose.
               
                  Conclusion
                  MEEP altered endoplasmic reticulum stress in chronic restrain stressed mice; however, as an antidepressant it showed a weaker response.",health
10.1016/j.knosys.2020.106178,Journal,Knowledge-Based Systems,scopus,2020-09-27,sciencedirect,Deep learning-based unsupervised representation clustering methodology for automatic nuclear reactor operating transient identification,https://api.elsevier.com/content/abstract/scopus_id/85087409980,"Transient identification of condition monitoring data in nuclear reactor is important for system health assessment. Conventionally, the operating transients are correlated with the pre-designed ones by human operators during operations. However, due to necessary conservatism and significant differences between the operating and pre-designed transients, it has been less effective to manually identify transients, that usually contribute to different system degradation modes. This paper proposes a deep learning-based unsupervised representation clustering method for automatic transient pattern recognition based on the on-site condition monitoring data. Sample entropy is used as indicator for transient extraction, and a pre-training stage is implemented using an auto-encoder architecture for learning high-level features. An iterative representation clustering algorithm is further proposed to enhance the clustering effects, where a novel distance metric learning strategy is integrated. Experiments on a real-world nuclear reactor condition monitoring dataset validate the effectiveness and superiority of the proposed method, which provides a promising tool for transient identification in the real industrial scenarios. This study offers a new perspective in exploring unlabeled data with deep learning, and the end-to-end implementation scheme facilitates applications in the real nuclear industry.",health
10.1016/j.neucom.2020.04.075,Journal,Neurocomputing,scopus,2020-09-24,sciencedirect,Cost sensitive active learning using bidirectional gated recurrent neural networks for imbalanced fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85085615458,"Most existing fault diagnosis methods may fail in the following three scenarios: (1) serial correlations exist in the process data; (2) fault data are much less than normal data; and (3) it is impractical to obtain enough labeled data. In this paper, a novel form of the bidirectional gated recurrent unit (BGRU) is developed to underpin effective and efficient fault diagnosis using cost sensitive active learning. Specifically, BGRU is devised to consider the dynamic behavior of a complex process. In the training phase of BGRU, the idea of weighting each training example is proposed to reduce the effect of class imbalance. Besides, in order to explore the unlabeled data, cost sensitive active learning is utilized to select the candidate instances. The effectiveness of the proposed method is evaluated on the Tennessee Eastman (TE) dataset and a real plasma etching process dataset. The experiment results show that the proposed cost senstive active learning bidirectional gated recurrent unit (CSALBGRU) method achieves better performance in both binary fault diagnosis and multi-class fault diagnosis.",health
10.1016/j.yexcr.2020.112139,Journal,Experimental Cell Research,scopus,2020-09-15,sciencedirect,A novel 3D printed bioactive scaffolds with enhanced osteogenic inspired by ancient Chinese medicine HYSA for bone repair,https://api.elsevier.com/content/abstract/scopus_id/85086671764,"Some traditional Chinese medicine (TCM) has been applied in bone repair, however, hydroxy-safflower yellow A (HYSA), one composition of safflower of the typical invigorating the circulation of TCM, has little been studied in orthopedics field for osteogenesis and angiogenesis clinically. Herein, we hypothetically speculated that the synthetic bioactive glasses (BG, 1393) scaffolds carried HYSA by a 3D print technique could enhance osteogenic repair properties. Notably, scaffolds coating chitosan/sodium alginate endowed with excellent drug control release ability, and significantly improved the BG mechanical strength. HYSA was loaded into BG scaffolds by coating chitosan/sodium alginate film, and the osteogenesis and angiogenesis of the HYSA/scaffolds were evaluated in vitro and in vivo. In vitro the cell culture results exhibited that the high dose of HYSA (0.5 mg/ml) loaded scaffolds can promote the proliferation of bone marrow stromal cells (rBMSCs) and migration, tubule formation of human umbilical vein endothelial cells (HUVECs). The active alkaline phosphatase (ALP) of rBMSCs can also be improved by the high dose of HYSA/scaffolds. Results of qRT-PCR and Western blot indicated that the high dose of HYSA/scaffolds can up-regulate ALP, OCN, OPN and RUNX-2 expression and relative protein secretion of the HIF-1α and BMP-2. In the animal experiment, the high dose of HYSA/scaffolds has a significantly better capacity to promote new bone formation than the undoped scaffolds at 8 weeks post-surgery. Thus, our results claimed that the novel HYSA/scaffolds hold the substantial potential to be further developed as effective and safe bone tissue engineering biomaterials for bone regeneration by combining enhanced osteogenesis and angiogenesis.",health
10.1016/j.patter.2020.100083,Journal,Patterns,scopus,2020-09-11,sciencedirect,"The Veterans Affairs Precision Oncology Data Repository, a Clinical, Genomic, and Imaging Research Database",https://api.elsevier.com/content/abstract/scopus_id/85102968026,"The Veterans Affairs Precision Oncology Data Repository (VA-PODR) is a large, nationwide repository of de-identified data on patients diagnosed with cancer at the Department of Veterans Affairs (VA). Data include longitudinal clinical data from the VA's nationwide electronic health record system and the VA Central Cancer Registry, targeted tumor sequencing data, and medical imaging data including computed tomography (CT) scans and pathology slides. A subset of the repository is available at the Genomic Data Commons (GDC) and The Cancer Imaging Archive (TCIA), and the full repository is available through the Veterans Precision Oncology Data Commons (VPODC). By releasing this de-identified dataset, we aim to advance Veterans' health care through enabling translational research on the Veteran population by a wide variety of researchers.",health
10.1016/j.cjche.2020.06.015,Journal,Chinese Journal of Chemical Engineering,scopus,2020-09-01,sciencedirect,Deep learning technique for process fault detection and diagnosis in the presence of incomplete data,https://api.elsevier.com/content/abstract/scopus_id/85089986909,"In modern industrial processes, timely detection and diagnosis of process abnormalities are critical for monitoring process operations. Various fault detection and diagnosis (FDD) methods have been proposed and implemented, the performance of which, however, could be drastically influenced by the common presence of incomplete or missing data in real industrial scenarios. This paper presents a new FDD approach based on an incomplete data imputation technique for process fault recognition. It employs the modified stacked autoencoder, a deep learning structure, in the phase of incomplete data treatment, and classifies data representations rather than the imputed complete data in the phase of fault identification. A benchmark process, the Tennessee Eastman process, is employed to illustrate the effectiveness and applicability of the proposed method.",health
10.1016/j.compbiomed.2020.103940,Journal,Computers in Biology and Medicine,scopus,2020-09-01,sciencedirect,Computer-Aided Diagnosis system for diagnosis of pulmonary emphysema using bio-inspired algorithms,https://api.elsevier.com/content/abstract/scopus_id/85089819166,"Pulmonary emphysema is a condition characterized by the destruction and permanent enlargement of the alveoli of the lungs. The destruction of gas-exchanging alveoli causes shortness of breath followed by a chronic cough and sputum production. A Computer-Aided Diagnosis (CAD) framework for diagnosing pulmonary emphysema from chest Computed Tomography (CT) slices has been designed and implemented in this study. The process of implementing the CAD framework includes segmenting the lung tissues and extracting the regions of interest (ROIs) using the Spatial Intuitionistic Fuzzy C-Means clustering algorithm. The ROIs that were considered in this work were emphysematous lesions — namely, centrilobular, paraseptal, and bullae that were labelled by an expert radiologist. The shape, texture, and run-length features were extracted from each ROI. A wrapper approach that employed four bio-inspired algorithms — namely, Moth–Flame Optimization (MFO), Firefly Optimization (FFO), Artificial Bee Colony Optimization, and Ant Colony Optimization — with the accuracy of the support vector machine classifier as the fitness function was used to select the optimal feature subset. The selected features of each bio-inspired algorithm were trained independently using the Extreme Learning Machine classifier based on the tenfold cross-validation technique. The framework was tested on real-time and public emphysema datasets to perform binary classification of lung CT slices of patients with and without the presence of emphysema. The framework that used MFO and FFO for feature selection produced superior results regarding accuracy, precision, recall, and specificity for the real-time dataset and the public dataset, respectively, when compared to the other bio-inspired algorithms.",health
10.1016/j.bspc.2020.102149,Journal,Biomedical Signal Processing and Control,scopus,2020-09-01,sciencedirect,An IoT-based framework for early identification and monitoring of COVID-19 cases,https://api.elsevier.com/content/abstract/scopus_id/85089552227,"The world has been facing the challenge of COVID-19 since the end of 2019. It is expected that the world will need to battle the COVID-19 pandemic with precautious measures, until an effective vaccine is developed. This paper proposes a real-time COVID-19 detection and monitoring system. The proposed system would employ an Internet of Things (IoTs) framework to collect real-time symptom data from users to early identify suspected coronaviruses cases, to monitor the treatment response of those who have already recovered from the virus, and to understand the nature of the virus by collecting and analyzing relevant data. The framework consists of five main components: Symptom Data Collection and Uploading (using wearable sensors), Quarantine/Isolation Center, Data Analysis Center (that uses machine learning algorithms), Health Physicians, and Cloud Infrastructure. To quickly identify potential coronaviruses cases from this real-time symptom data, this work proposes eight machine learning algorithms, namely Support Vector Machine (SVM), Neural Network, Naïve Bayes, K-Nearest Neighbor (K-NN), Decision Table, Decision Stump, OneR, and ZeroR. An experiment was conducted to test these eight algorithms on a real COVID-19 symptom dataset, after selecting the relevant symptoms. The results show that five of these eight algorithms achieved an accuracy of more than 90 %. Based on these results we believe that real-time symptom data would allow these five algorithms to provide effective and accurate identification of potential cases of COVID-19, and the framework would then document the treatment response for each patient who has contracted the virus.",health
10.1016/j.measurement.2020.107861,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-09-01,sciencedirect,Internet of things sensor assisted security and quality analysis for health care data sets using artificial intelligent based heuristic health management system,https://api.elsevier.com/content/abstract/scopus_id/85089438452,"The developments in the medical systems, especially in health care management systems, play a vital role in patients. The effective management of health records leads to an increase in the importance of the healthcare management system all over the world. A real-time health monitoring system is a key zone for the Internet of Things (IoT) sensor technology in human services using Big Data Analytics. The major challenge that has to do with the health care data sets is security and privacy. In this paper, an artificial intelligence-based heuristic health management system has been designed and developed. This system is exceptionally close to improve the security and privacy of the live datasets of patients and the association of medicinal services over its different viewpoints. These services include the capacity for specialists, experts, attendants, and staff to settle on better decisions faster. Moreover, security and quality of data by configuration should be a part of any IoT use case, task or arrangement. Utilizing IoT assisted artificial intelligent based heuristic health management system intends to improve and minimize the security risk on health care data sets with assisted IoT sensors. The experimental results show promising outcomes in terms of various performance factors. The system attains precision as 99.75%, error rate as 0.0646 and predicted positive condition rate as 98.46%, Informedness as 98.6% and accuracy as 99.66%. The system is implemented using the MATLAB program.",health
10.1016/j.jbi.2020.103527,Journal,Journal of Biomedical Informatics,scopus,2020-09-01,sciencedirect,A Machine Learning method for relabeling arbitrary DICOM structure sets to TG-263 defined labels,https://api.elsevier.com/content/abstract/scopus_id/85089199737,"Purpose:
                  To present a Machine Learning pipeline for automatically relabeling anatomical structure sets in the Digital Imaging and Communications in Medicine (DICOM) format to a standard nomenclature that will enable data abstraction for research and quality improvement.
               
                  Methods:
                  DICOM structure sets from approximately 1200 lung and prostate cancer patients across 40 treatment centers were used to build predictive models to automate the relabeling of clinically specified structure labels to standardized labels as defined by the American Association of Physics in Medicine’s (AAPM) Task Group 263 (TG-263). Volumetric bitmaps were created based on the delineated volumes and were combined with associated bony anatomy data to build feature vectors. Feature reduction was performed with singular value decomposition and the resulting vectors were used for predicting the label of each structure using five different classifier algorithms on the Apache Spark platform with 5-fold cross-validation. Undersampling methods were used to deal with underlying class imbalance that hindered the performance of classifiers. Experiments were performed on both a curated version of the data, which included only annotated structures, and the non-curated data that included all structures from the original treatment plans.
               
                  Results:
                  Random Forest provided the highest accuracies with F1 scores of 98.77 for lung and 95.06 for prostate on the curated data sets. Scores were lower with 95.67 for lung and 90.22 for prostate on the non-curated data sets, highlighting some of the challenges of classifying real clinical data. Including bony anatomy data and pooling information from all structures for the same patient both increased accuracies. In some cases, undersampling with k-Means clustering for class balancing improved classifier accuracy but in all experiments it significantly reduced run time compared to random undersampling.
               
                  Conclusion:
                  This work shows that structure sets can be relabeled using our approach with accuracies over 95% for many structure types when presented with curated data. Although accuracies dropped when using the full non-curated data sets, some structure types were still correctly labeled over 90% of the time. With similar results obtained on an external test data set, we can infer that the proposed models are likely to work on other clinical data sets.",health
10.1016/j.jocn.2020.04.125,Journal,Journal of Clinical Neuroscience,scopus,2020-09-01,sciencedirect,Tele-robotics and artificial-intelligence in stroke care,https://api.elsevier.com/content/abstract/scopus_id/85088965193,"In the last forty years, the field of medicine has experienced dramatic shifts in technology-enhanced surgical procedures – from its initial use in 1985 for neurosurgical biopsies to current implementation of systems such as magnetic-guided catheters for endovascular procedures. Systems such as the Niobe Magnetic Navigation system and CorPath GRX have allowed for utilization of a fully integrated surgical robotic systems for perioperative manipulation, as well as tele-controlled manipulation systems for telemedicine. These robotic systems hold tremendous potential for future implementation in cerebrovascular procedures, but lack of relevant clinical experience and uncharted ethical and legal territory for real-life tele-robotics have stalled their adoption for neurovascular surgery, and might present significant challenges for future development and widespread implementation. Yet, the promise that these technologies hold for dramatically improving the quality and accessibility of cerebrovascular procedures such as thrombectomy for acute stroke, drives the research and development of surgical robotics. These technologies, coupled with artificial intelligence (AI) capabilities such as machine learning, deep-learning, and outcome-based analyses and modifications, have the capability to uncover new dimensions within the realm of cerebrovascular surgery.",health
10.1016/j.bspc.2020.102106,Journal,Biomedical Signal Processing and Control,scopus,2020-09-01,sciencedirect,FPGA-based real-time epileptic seizure classification using Artificial Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85088878293,"Epilepsy is a neurological disorder characterised by unusual brain activity widely known as seizure affecting 4-7% of the world's population. The diagnosis of this disorder is currently based on analysis of the electroencephalography (EEG) signals in the time-frequency domain. The analysis is performed applying various algorithms that yield high performance, however the challenge of effective real-time epilepsy diagnosis persists.
                  To address this, we have developed a Field Programmable Gate Array (FPGA) based solution for the classification of generalized and focal epileptic seizure types using a feed-forward multi-layer neural network architecture (MLP ANN).
                  The neural network algorithm is trained, validated and tested on 822 captured signals from Temple University Hospital Seizure Detection Corpus (TUH EEG Corpus) database. Inputs into the system were five main features obtained from EEG signals by time-frequency analysis followed by Continuous Wavelet Transform (CWT) and subsequent statistical analysis. Out of the total number of samples, 583 (70 %) of them were utilised during the system development in MATLAB and TensorFlow and 239 (30 %) samples were further used for subsequent testing of the model performance on the FPGA. Subsequently, the adequate parameters of the ANN model were determined by using k-Fold Cross-Validation. Finally, the best performing ANN model in terms of average validation data accuracy achieved during cross-validation was implemented on the FPGA for real-time seizure classification. The digital ANN solution was coded in Very High-Speed Integrated Circuit Hardware Description Language (VHDL) and tested on the FPGA using 30 % reaming data.
                  The results of this research demonstrate that epilepsy diagnosis with quite high accuracy (95.14 %) can be achieved with (5-12-3) MLP ANN implemented on FPGA. Also, the results show the steps towards appropriate implementation of ANN on the FPGA. These results can be utilised as the basis for the design of an application-specific integrated circuit (ASIC) allowing large serial production.",health
10.1016/j.compag.2020.105632,Journal,Computers and Electronics in Agriculture,scopus,2020-09-01,sciencedirect,Comfort and health evaluation of live mutton sheep during the transportation based on wearable multi-sensor system,https://api.elsevier.com/content/abstract/scopus_id/85087855037,"The uncertainty of transport environment threatens the comfort and health of live mutton sheep and even affects the quality of meat after slaughter. Using modern information technology to solve the deficiencies of live animal centralized transport is of great significance for the stable development of animal husbandry. In this paper, the wearable multi-sensor system was specially designed, and the system test experiment and transport monitoring experiment were carried out. According to the continuous and real-time data of environmental and physiological parameters obtained from the transport monitoring experiment, the optimization extraction, data collection analysis, correlation analysis and simulation analysis of the internal environment in the carriage were carried out, and the prediction model between environmental and physiological parameters based on generalized regression neural network (GRNN) and the prediction model of comfort and health evaluation based on back propagation neural network (BPNN) were established. The results show that: (1) The wearable multi-sensor system had high accuracy and stability of data collection, and the power consumption and communication performance can meet the monitoring requirements. (2) The observation values of internal environmental parameters increased gradually with the accumulation of transport time, and finally reached the state of dynamic balance. The heart rate fluctuated greatly and was higher than the normal range. The blood oxygen saturation showed a gradual decrease trend, but the overall was in the normal range. The body temperature gradually increased, and was affected by discomfort. (3) The correlation analysis showed that there was a significant correlation between environmental and physiological parameters. (4) The area with larger value of environmental parameters was close to the middle and front of the carriage, which was mainly caused by the high density and poor air circulation. (5) The prediction model between environmental and physiological parameters based on GRNN and the prediction model of comfort and health evaluation based on BPNN had high prediction accuracy, and the combination of the two models can map the impact of environmental factors on the change of vital signs to the relationship between comfort and health. Therefore, in the case of unknown vital signs information, only obtaining environmental information can also predict the health levels, which can provide decision-making basis for relevant practitioners.",health
10.1016/j.cie.2020.106566,Journal,Computers and Industrial Engineering,scopus,2020-09-01,sciencedirect,Prediction of pellet quality through machine learning techniques and near-infrared spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85087818203,"In recent years, pellet has received increasing attention among other biofuels due to its low storage costs and high combustion efficiency. The traceability of pellet quality along the entire supply chain is a critical issue, since fraudulent behaviours, such as the replacement with lower quality pellet, may both cause an economic damage and harm consumers’ health. Traditionally, pellet quality is evaluated through laboratory analysis, which is costly and time-consuming. To overcome these limitations, in this work we define a methodology for quick and low-cost evaluation of pellet quality, which may be used along the entire supply chain. The proposed technique is based on the classification of pellet spectra through machine learning techniques. Spectra are obtained by means of a near-infrared (NIR) spectrophotometer, which is a relatively cheap instrument of small dimensions (even portable) that is suitable for on-site analysis at any phase of the supply chain. We propose two different approaches, namely an automatic classification of pellet, which does not require laboratory analysis, and a semi-automatic approach, that increases the overall accuracy but requires laboratory analysis for uncertainly classified samples. We validate the methodology by performing several experiments on real-world data, by training different machine learning algorithms and evaluating the impact of several transformations introduced to reduce the scattering effect, which is a well-known issue related to NIR data.",health
10.1016/j.pmcj.2020.101175,Journal,Pervasive and Mobile Computing,scopus,2020-09-01,sciencedirect,IoT-enabled Low Power Environment Monitoring System for prediction of PM2.5,https://api.elsevier.com/content/abstract/scopus_id/85086801095,"Air pollution is a major concern worldwide due to its significant impacts on the global environment and human health. The conventional instruments used by the air quality monitoring stations are costly, bulkier, time-consuming, and power-hungry. Furthermore, due to limited data availability and non-scalability, these stations cannot provide high spatial and temporal resolution in real-time. Although energy-efficient, wireless sensor network with the high spatio-temporal resolution is one of the potential solutions, real-time remote monitoring of all significant air quality parameters with low power consumption is challenging. To address this challenge, we propose internet of things-enabled low power environment monitoring system for real-time monitoring of ten significant air quality parameters. Moreover, the proposed system enables remote monitoring and storage of data for future analysis. Unlike earlier research work, further expansion of the proposed system is easily possible, as the proposed Wireless Sensor Node (WSN) can interface a higher number of sensors with the same number of interfacing pins. We did an in-depth analysis through calibration, experiments, and deployment which confirms the power efficiency, flexibility, reliability and accuracy of the proposed system. Results illustrate the low power consumption of 25.67mW, data transmission reliability of 97.4%, and battery life of approximately 31 months for a sampling time of 60 min. The study of the correlation between Particulate Matter 2.5 (PM2.5) and other pollutants is performed using Central Pollution Control Board data of 41 months. The initial study related to correlation is performed for the future work of developing a prediction model of PM2.5 using highly correlated pollutants. The future approach for developing a prediction model in the form of analytical equations with the help of artificial neural network is demonstrated. This approach can be implemented using the proposed WSN or low-cost processing tool for evaluating PM2.5 from precursor gases. Therefore, this approach can be one of the promising approaches in the future for monitoring PM2.5 without power-hungry gas sensors and bulkier analyzers.",health
10.1016/j.ijmedinf.2020.104225,Journal,International Journal of Medical Informatics,scopus,2020-09-01,sciencedirect,Clinical questionnaire filling based on question answering framework,https://api.elsevier.com/content/abstract/scopus_id/85086743489,"Background
                  Electronic Health Records (EHR) are the foundation of much medical research. However, analyzing the text data of EHRs directly is an challenging task. Therefore, physicians often use questionnaires to first convert text data to structured data. Filling in these questionnaires requires a considerable amount of time and medical knowledge. It is a significant task to develop an algorithm to make computers fill out these questionnaires automatically.
               
                  Objective
                  This research aims to build a deep learning model that can automatically complete questionnaires with given medical text.
               
                  Methods
                  This task is a part of Information Extraction (IE), but it differs from the existing tasks of medical IE. Because of the questions in questionnaires are closed-end type, which refers to making a selection among given options, we could treat this task as a classification problem. However, conventional classification algorithms are resource-consuming when filling out one entire questionnaire with one model. They also could not use the question information to guide the questionnaire filling task. To handle these issues, we propose a neural network model based on question answering (QA) framework in this paper. With this framework, our neural network can fill out one complete questionnaire using only one model.
               
                  Results
                  We perform experiments on three real-world Chinese medical datasets and related clinical questionnaires. Our model respectively achieves F1 scores of 0.9273, 0.8834, and 0.9846. The results outperform several baseline models.
               
                  Conclusion
                  The strong performance of our QA model will allow us to build a system which can help physicians to fill out questionnaires and convert text data to structured data. This system can reduce the workload of physicians.",health
10.1016/j.iot.2020.100185,Journal,Internet of Things (Netherlands),scopus,2020-09-01,sciencedirect,Highly-efficient fog-based deep learning AAL fall detection system,https://api.elsevier.com/content/abstract/scopus_id/85086362688,"Falls is one of most concerning accidents in aged population due to its high frequency and serious repercussion; thus, quick assistance is critical to avoid serious health consequences. There are several Ambient Assisted Living (AAL) solutions that rely on the technologies of the Internet of Things (IoT), Cloud Computing and Machine Learning (ML). Recently, Deep Learning (DL) have been included for its high potential to improve accuracy on fall detection. Also, the use of fog devices for the ML inference (detecting falls) spares cloud drawback of high network latency, non-appropriate for delay-sensitive applications such as fall detectors. Though, current fall detection systems lack DL inference on the fog, and there is no evidence of it in real environments, nor documentation regarding the complex challenge of the deployment. Since DL requires considerable resources and fog nodes are resource-limited, a very efficient deployment and resource usage is critical. We present an innovative highly-efficient intelligent system based on a fog-cloud computing architecture to timely detect falls using DL technics deployed on resource-constrained devices (fog nodes). We employ a wearable tri-axial accelerometer to collect patient monitoring data. In the fog, we propose a smart-IoT-Gateway architecture to support the remote deployment and management of DL models. We deploy two DL models (LSTM/GRU) employing virtualization to optimize resources and evaluate their performance and inference time. The results prove the effectiveness of our fall system, that provides a more timely and accurate response than traditional fall detector systems, higher efficiency, 98.75% accuracy, lower delay, and service improvement.",health
10.1016/j.ijmedinf.2020.104176,Journal,International Journal of Medical Informatics,scopus,2020-09-01,sciencedirect,The development an artificial intelligence algorithm for early sepsis diagnosis in the intensive care unit,https://api.elsevier.com/content/abstract/scopus_id/85085579350,"Background
                  Severe sepsis and septic shock are still the leading causes of death in Intensive Care Units (ICUs), and timely diagnosis is crucial for treatment outcomes. The progression of electronic medical records (EMR) offers the possibility of storing a large quantity of clinical data that can facilitate the development of artificial intelligence (AI) in medicine. However, several difficulties, such as poor structure and heterogenicity of the raw EMR data, are encountered when introducing AI with ICU data. Labor-intensive work, including manual data entry, personal medical records sorting, and laboratory results interpretation may hinder the progress of AI. In this article, we introduce the developing of an AI algorithm designed for sepsis diagnosis using pre-selected features; and compare the performance of the AI algorithm with SOFA score based diagnostic method.
               
                  Materials and methods
                  This is a prospective open-label cohort study. A specialized EMR, named TED_ICU, was implemented for continuous data recording. One hundred six clinical features relevant to sepsis diagnosis were selected prospectively. A labeling work to allocate SEPSIS or NON_SEPSIS status for each ICU patient was performed by the in-charge intensivist according to SEPSIS-3 criteria, along with the automatic recording of selected features every day by TED_ICU. Afterward, we use de-identified data to develop the AI algorithm. Several machine learning methods were evaluated using 5-fold cross-validation, and XGBoost, a decision-tree based algorithm was adopted for our AI algorithm development due to best performance.
               
                  Results
                  The study was conducted between August 2018 and December 2018 for the first stage of analysis. We collected 1588 instances, including 444 SEPSIS and 1144 NON-SEPSIS, from 434 patients. The 434 patients included 259 (59.6%) male patients and 175 female patients. The mean age was 67.6-year-old, and the mean APACHE II score was 13.8. The SEPSIS cohort had a higher SOFA score and increased use of organ support treatment. The AI algorithm was developed with a shuffle method using 80% of the instances for training and 20% for testing. The established AI algorithm achieved the following: accuracy = 82% ± 1%; sensitivity = 65% ± 5%; specificity = 88% ± 2%; precision = 67% ± 3%; and F1 = 0.66 ± 0.02. The area under the receiver operating characteristic curve (AUROC) was approximately 0.89. The SOFA score was used on the same 1588 instances for sepsis diagnosis, and the result was inferior to our AI algorithm (AUROC = 0.596).
               
                  Conclusion
                  Using real-time data, collected by EMR, from the ICU daily practice, our AI algorithm established with pre-selected features and XGBoost can provide a timely diagnosis of sepsis with an accuracy greater than 80%. AI algorithm also outperforms the SOFA score in sepsis diagnosis and exhibits practicality as clinicians can deploy appropriate treatment earlier. The early and precise response of this AI algorithm will result in cost reduction, outcome improvement, and benefit for healthcare systems, medical staff, and patients as well.",health
10.1016/j.microc.2020.105038,Journal,Microchemical Journal,scopus,2020-09-01,sciencedirect,A smartphone-based rapid quantitative detection platform for lateral flow strip of human chorionic gonadotropin with optimized image algorithm,https://api.elsevier.com/content/abstract/scopus_id/85085341749,"Colloidal gold immunochromatographic test strip has been widely used as a rapid, simple and low-cost correct detection technology. However, its detection is often qualitative or semi-quantitative, which limits its clinical application to some extent. Herein, a portable test strip quantitative detection device based on smartphone to detect human chorionic gonadotropin (HCG) is developed. In experiment, a colloidal gold HCG detection strip based on antigen antibody immune response is constructed, and the quantitative results of three different image processing methods on the same strip detection are compared, including the threshold processing algorithm based on location information, the RGB color component extraction algorithm and the grayscale projection value processing algorithm, the results show that the last algorithm can realize the best recognition of the region of interest of strip. The mobile phone application software (App) based on this design shows that the detection limit of constructed colloidal gold HCG strip is 3 ng/mL with a linear range of 6–300 ng/mL. The detection result of real urine sample is consistent with the spiked concentration (R2 = 0.988), indicating that the concentration of HCG can be accurately measured in urine with this method, presenting the potential for instant diagnosis.",health
10.1016/j.ins.2020.05.001,Journal,Information Sciences,scopus,2020-09-01,sciencedirect,Least squares projection twin support vector clustering (LSPTSVC),https://api.elsevier.com/content/abstract/scopus_id/85084794021,"Clustering is a prominent unsupervised learning technique. In the literature, many plane based clustering algorithms are proposed, such as the twin support vector clustering (TWSVC) algorithm. In this work, we propose an alternative algorithm based on projection axes termed as least squares projection twin support vector clustering (LSPTSVC). The proposed LSPTSVC finds projection axis for every cluster in a manner that minimizes the within class scatter, and keeps the clusters of other classes far away. To solve the optimization problem, the concave-convex procedure (CCCP) is utilized in the proposed method. Moreover, the solution of proposed LSPTSVC involves a set of linear equations leading to very less training time. To verify the performance of the proposed algorithm, several experiments are performed on synthetic and real world benchmark datasets. Experimental results and statistical analysis show that the proposed LSPTSVC performs better than existing algorithms w.r.t. clustering accuracy as well as training time. Moreover, a comparison of the proposed method with existing algorithms is presented on biometric and biomedical applications. Better generalization performance is achieved by proposed LSPTSVC on clustering of facial images, and Alzheimer’s disease data.",health
10.1016/j.mechmachtheory.2020.103932,Journal,Mechanism and Machine Theory,scopus,2020-09-01,sciencedirect,Intelligent ball screw fault diagnosis using a deep domain adaptation methodology,https://api.elsevier.com/content/abstract/scopus_id/85084176694,"Intelligent data-driven fault diagnosis methods have been successfully developed in the recent years. However, as one of the most important machines in the industries, the ball screw health monitoring problem has received less attention, due to the complex operating patterns and sophisticated mechanical structures. In practice, the working conditions of the ball screws usually change, that further makes the fault diagnosis problem more challenging since the data distributions are not the same. In order to address this issue, a deep learning-based domain adaptation method is proposed for the cross-domain ball screw fault diagnosis problem. The deep convolutional neural network is adopted for feature extraction and health condition classification. The maximum mean discrepancy metric is proposed to measure and optimize the data distributions of different operating conditions. A data segmentation method which is specially designed for the ball screw is further integrated. The experiments on the real ball screw condition monitoring data are carried out for validation. The results indicate the proposed approach is promising for the cross-domain diagnostic tasks of the ball screw in the real industries.",health
10.1016/j.appet.2020.104698,Journal,Appetite,scopus,2020-09-01,sciencedirect,Momentary changes in heart rate variability can detect risk for emotional eating episodes,https://api.elsevier.com/content/abstract/scopus_id/85083899611,"Emotion dysregulation is a known risk factor for a variety of maladaptive eating behaviors, including emotional eating (Crockett, Myhre, & Rokke, 2015; Lavender et al., 2015). New passive sensing technologies offer the prospect of detecting emotion dysregulation in real-time through measurement of heart rate variability (HRV), a transdiagnostic bio-signal of emotion regulation, which may in turn signal risk of engaging in a maladaptive eating behavior. In the current study, our primary aim was to test the hypothesis that momentary changes in HRV can be used to detect risk of experiencing an emotional eating episode in an ecologically valid setting using a wrist worn sensor with acceptable classification accuracy. Participants were 21 adults with clinically significant emotional eating behaviors. Participants wore the Empatica E4 wrist-sensor and tracked all emotional eating episodes using ecological momentary assessment for four weeks. Time and frequency domain features of HRV were extracted in the 30-min period preceding emotional eating episodes and control cases (defined as the 30 min prior to an EMA survey that did not contain an emotional eating episode). Support vector machine (SVM) learning models were implemented using time domain and frequency domain features. SVM models using frequency domain features achieved the highest classification accuracy (77.99%), sensitivity (78.75%), and specificity (75.00%), consistent with standards deemed acceptable for the prediction of event-level health behavior. SVM models using time domain features still performed above chance, though were less accurate at classifying episodes (accuracy 63.48%, sensitivity 62.68%, and specificity 70.00%) and did not meet acceptable classification accuracy. Wearable sensors that assess HRV show promise as a tool for capturing risk of engaging in emotional eating episodes.",health
10.1016/j.future.2019.11.001,Journal,Future Generation Computer Systems,scopus,2020-09-01,sciencedirect,Wireless high-frequency NLOS monitoring system for heart disease combined with hospital and home,https://api.elsevier.com/content/abstract/scopus_id/85075418039,"Heart disease is one of the serious public health problems in the world at present. According to the research, the mortality and disability rates of cardiovascular diseases are the highest in the world. In this paper, we introduce wireless radio-frequency technique for health monitoring and use non-line-of-sight (NLOS) biological device to perceive physiological signal of patients. Therefore, we put forward a NLOS monitoring system for heart disease. Firstly, It is used to collect the physiological data of heart disease patients in real time. It is portable and non-line-of-sight, which provides really contact-less and interference-free monitoring environment for patients. Besides, edge computing is introduced to the heart disease monitoring system to support the short-delay and high-reliability response to urgent disease condition. Specifically, we deploy based on deep learning disease prediction model at edge nodes. Meanwhile, combining hospital and home healthcare, we propose rescue strategies for heart attack. To verify the feasibility of wireless NLOS monitoring system for heart disease combined hospital and home, we conduct case analysis for the key technologies and methods in the monitoring system, and built an experimental platform to test the proposed system.",health
10.1016/j.inpa.2019.10.004,Journal,Information Processing in Agriculture,scopus,2020-09-01,sciencedirect,Automatic recognition of ingestive-related behaviors of dairy cows based on triaxial acceleration,https://api.elsevier.com/content/abstract/scopus_id/85075381879,"Ingestive-related behaviors including feeding and ruminating are important indexes to measure the health and welfare of dairy cows. The purpose of this study is to develop a method based on triaxial acceleration to automatically recognize feeding and ruminating of dairy cows. During the experiment, five diary cows raised in a barn were used as experimental subjects. A triaxial acceleration sensor was used as the device to collect jaw-movement data of dairy cows, and the behaviors of dairy cows were classified into three categories: feeding, ruminating and other behavior. The features of time-domain and frequency-domain were extracted from the raw acceleration data. Three machine learning algorithms including k-nearest neighbor, support vector machine and probabilistic neural network were used for the classification and the results based on four different data segment lengths were compared. The results show that the three algorithms can be used for recognition of feeding and ruminating with high accuracy. Under the condition that the sampling frequency of the sensor is 5 Hz, the combination of data segment length of 256 and k-nearest neighbor algorithm is the best scheme for recognition of feeding and ruminating in this study. The precision and recall of recognition for feeding were 92.8% and 95.6% respectively, and those of recognition for ruminating were 93.7% and 94.3% respectively. The specificity and AUC of recognition for feeding were 96.1% and 0.959 respectively, and those of recognition for ruminating were 97.5% and 0.959 respectively. This will provide an effective method for real-time monitoring of ingestive-related behaviors of dairy cows and lay a foundation for prediction of dairy cows’ health status and welfare to further achieve the purpose of disease prediction and adjusting feeding and management methods.",health
10.1016/j.neucom.2020.04.123,Journal,Neurocomputing,scopus,2020-08-25,sciencedirect,Automated diagnosis of multi-plane breast ultrasonography images using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85085094427,"Breast ultrasonography is currently considered the first-line examination in the diagnosis of breast lesions or other abnormalities. Many automated breast cancer diagnosis methods have been developed for ultrasonography images; however, most previous automated methods used only a single breast ultrasonography image. This is inconsistent with the real-world situation, as breast cancer is heterogeneous, and it can lead to high false negative rates. Generally, sonographers diagnose a lesion by reviewing multiple planes. In this paper, we formulate the diagnosis of breast cancer on ultrasonography images as a Multiple Instance Learning (MIL) problem, diagnosing a breast nodule by jointly analyzing the nodule on multiple planes. An attention-augmented deep neural network is then developed to solve this problem. To the best of our knowledge, this is the first implementation of a MIL framework on such data. A large breast ultrasonography image dataset was constructed to train and evaluate the model; this contained 10,464 images from 3700 lesions labeled as benign or malignant, which originated from 2568 patients. The high classification accuracy achieved demonstrates the effectiveness of the proposed architecture for the diagnosis of breast cancer. The MIL based method obtained superior performance to single instance methods in this breast cancer diagnosis task. Notably, the proposed attention-augmented network allowed us to find key instances, which can be provided the region of interest (ROI) in the final diagnosis given to a doctor. Furthermore, we empirically demonstrate that our approach achieves better performance than other state-of-the-art MIL methods.",health
10.1016/j.neucom.2020.05.014,Journal,Neurocomputing,scopus,2020-08-25,sciencedirect,Domain generalization in rotating machinery fault diagnostics using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85084766952,"The past years have witnessed the successful development of intelligent machinery fault diagnostic methods. Besides the basic data-driven fault diagnosis tasks where the training and testing data are collected from the same distribution, the more practical cross-domain problems have also attracted much attention considering variations of machine operating conditions. In the literature, most existing studies generally assume the availability of testing data during model training, thus facilitating explicit domain adaptations. However, this assumption poses obstacles in the application on real-time cross-domain fault diagnosis, where the testing data can not be obtained in advance. This paper proposes a deep learning-based domain generalization method for machinery fault diagnosis. A domain augmentation method is adopted to expand the available dataset. Domain adversarial training is implemented, and generalized features can be learned from different domains, which hold in new working scenarios without assuming the availability of testing data. Distance metric learning is also used to further enhance model robustness in fault classifications. Through experiments on two rotating machinery datasets, the effectiveness of the proposed method is validated, which is promising in on-line cross-domain fault diagnosis tasks.",health
10.1016/j.chemolab.2020.104070,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2020-08-15,sciencedirect,Clustering algorithm for mixed datasets using density peaks and Self-Organizing Generative Adversarial Networks,https://api.elsevier.com/content/abstract/scopus_id/85086449942,"This paper presents a new Density-Peaks and Self-Organizing Generative Adversarial Networks (DP-SO-GAN) for clustering mixed datasets. Many clustering methods depend on the assumption that datasets contain either categorical or numerical attributes. Nevertheless, in real-time, most of the applications include mixed categorical and numerical attributes. In medicine, the clustering of cardiovascular disease is an essential task. The clustering of such data attributes is a vital and challenging issue. First, we transform mixed data attributes such as categorical attributes using a one-hot encoding technique and numerical attributes using normalization techniques. The converted characteristics are input to a Self-Organizing Generative Adversarial Networks (SO-GAN) to learn the feature map. Second, we train two kernel networks, such as the generator and discriminator, and each one holds a trivial amount of convolution kernels. Last, we propose an enhanced density peaks clustering algorithm and computing similarity measure between the data objects in the feature representation. The clustering accuracy for the cardiovascular disease dataset results in 88.32% with a standard deviation of 0.1 and is relatively higher than that of other existing algorithms. The training time for hand-written digits datasets over 300 epochs is 3148.26 ​s. Experiment results obtained on a set of five datasets demonstrate the merits of the proposed method, especially in terms of the stability and efficiency of network training. The computational complexity of the proposed method in terms of floating-point operations is reduced by around 18% as compared with the classical generative adversarial networks.",health
10.1016/j.patter.2020.100074,Journal,Patterns,scopus,2020-08-14,sciencedirect,Machine-Learning Approaches in COVID-19 Survival Analysis and Discharge-Time Likelihood Prediction Using Clinical Data,https://api.elsevier.com/content/abstract/scopus_id/85092796371,"As a highly contagious respiratory disease, COVID-19 has yielded high mortality rates since its emergence in December 2019. As the number of COVID-19 cases soars in epicenters, health officials are warning about the possibility of the designated treatment centers being overwhelmed by coronavirus patients. In this study, several computational techniques are implemented to analyze the survival characteristics of 1,182 patients. The computational results agree with the outcome reported in early clinical reports released for a group of patients from China that confirmed a higher mortality rate in men compared with women and in older age groups. The discharge-time prediction of COVID-19 patients was also evaluated using different machine-learning and statistical analysis methods. The results indicate that the Gradient Boosting survival model outperforms other models for patient survival prediction in this study. This research study is aimed to help health officials make more educated decisions during the outbreak.",health
10.1016/S2352-3018(20)30190-9,Journal,The Lancet HIV,scopus,2020-08-01,sciencedirect,Modern diagnostic technologies for HIV,https://api.elsevier.com/content/abstract/scopus_id/85088944280,"Novel diagnostic technologies, including nanotechnology, microfluidics, -omics science, next-generation sequencing, genomics big data, and machine learning, could contribute to meeting the UNAIDS 95-95-95 targets to end the HIV epidemic by 2030. Novel technologies include multiplexed technologies (including biomarker-based point-of-care tests and molecular platform technologies), biomarker-based combination antibody and antigen technologies, dried-blood-spot testing, and self-testing. Although biomarker-based rapid tests, in particular antibody-based tests, have dominated HIV diagnostics since the development of the first HIV test in the mid-1980s, targets such as nucleic acids and genes are now used in nanomedicine, biosensors, microfluidics, and -omics to enable early diagnosis of HIV. These novel technologies show promise as they are associated with ease of use, high diagnostic accuracy, rapid detection, and the ability to detect HIV-specific markers. Additional clinical and implementation research is needed to generate evidence for use of novel technologies and a public health approach will be required to address clinical and operational challenges to optimise their global deployment.",health
10.1016/j.jbi.2020.103481,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Adversarial active learning for the identification of medical concepts and annotation inconsistency,https://api.elsevier.com/content/abstract/scopus_id/85088920666,"Objective
                  Named entity recognition (NER) is a principal task in the biomedical field and deep learning-based algorithms have been widely applied to biomedical NER. However, all of these methods that are applied to biomedical corpora use only annotated samples to maximize their performances. Thus, (1) large numbers of unannotated samples are relinquished and their values are overlooked. (2) Compared with other types of active learning (AL) algorithms, generative adversarial learning (GAN)-based AL methods have developed slowly. Furthermore, current diversity-based AL methods only compute similarities between a pair of sentences and cannot evaluate distribution similarities between groups of sentences. Annotation inconsistency is one of the significant challenges in the biomedical annotation field. Most existing methods for addressing this challenge are statistics-based or rule-based methods. (3) They require sufficient expert knowledge and complex designs. To address challenges (1), (2), and (3) simultaneously, we propose innovative algorithms.
               
                  Methods
                  GAN is introduced in this paper, and we propose the GAN-bidirectional long short-term memory-conditional random field (GAN-BiLSTM-CRF) and the GAN-bidirectional encoder representations from transformers-conditional random field (GAN-BERT-CRF) models, which can be considered an NER model, an AL model, and a model identifying error labels. BiLSTM-CRF or BERT-CRF is defined as the generator and a convolutional neural network (CNN)-based network is considered the discriminator. (1) The generator employs unannotated samples in addition to annotated samples to maximize NER performance. (2) The outputs of the CRF layer and the discriminator are used to select unlabeled samples for the AL task. (3) The discriminator discriminates the distribution of error labels from that of correct labels, identify error labels, and address the annotation inconsistency challenge.
               
                  Results
                  The corpus from the 2010 i2b2/VA NLP challenge and the Chinese CCKS-2017 Task 2 dataset are adopted for experiments. Compared to the baseline BiLSTM-CRF and BERT-CRF, the GAN-BiLSTM-CRF and GAN-BERT-CRF models achieved significant improvements on the precision, recall, and F1 scores in terms of NER performance. Learning curves in AL experiments show the comparative results of the proposed models. Furthermore, the trained discriminator can identify samples with incorrect medical labels in both simulation and real-word experimental environments.
               
                  Conclusion
                  The idea of introducing GAN contributes significant results in terms of NER, active learning, and the ability to identify incorrect annotated samples. The benefits of GAN will be further studied.",health
10.1016/j.jbi.2020.103502,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,RAHM: Relation augmented hierarchical multi-task learning framework for reasonable medication stocking,https://api.elsevier.com/content/abstract/scopus_id/85088044216,"As an important task in digital preventive healthcare management, especially in the secondary prevention stage, active medication stocking refers to the process of preparing necessary medications in advance according to the predicted disease progression of patients. However, predicting preventive or even life-saving medicine for each patient is a non-trivial task. Existing models usually overlook the implicit hierarchical relation between patient’s predicted diseases and medications, and mainly focus on single tasks (medication recommendation or disease prediction). To tackle this limitation, we propose a relation augmented hierarchical multi-task learning framework, named RAHM. which is capable of learning multi-level relation-aware patient representation for reasonable medication stocking. Specifically, the framework first leverages the underlying structural relations of Electronic Health Record (EHR) data to learn the low-level patient visit representation. Then, it uses a regular LSTM to encode the historical temporal disease information for disease-level patient representation learning. Further, a relation-aware LSTM (R-LSTM) is proposed to handle the relations between diseases and medication in longitudinal patient records, which can better integrate the historical information into the medication-level patient representation. In the learning process, two pseudo residual structures are introduced to mitigate the error propagation and preserve the valuable relation information of EHRs. To validate our method, extensive experiments have been conducted based on the real-world clinical dataset. The results demonstrate a consistent superiority of our framework over several baselines in suggesting reasonable stock medication.",health
10.1016/j.jbi.2020.103494,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Evolving dynamic self-adaptation policies of mHealth systems for long-term monitoring,https://api.elsevier.com/content/abstract/scopus_id/85087487414,"Tele-rehabilitation can complement traditional rehabilitation therapies by providing valuable information that can help in the evaluation, monitoring, and treatment of patients. Many patient tele-monitoring systems that integrate wearable technology are emerging as an effective tool for the long-term surveillance of rehabilitation progression, enabling continuous sampling of patient real-time movement in a non-invasive way, without affecting the normal daily activity of the outpatient, who, therefore, will not need to make frequent clinic visits. One of the main challenges of tele-rehabilitation systems is to pay special attention to the diversity of dysfunctions in patients by offering devices with customized behaviours adaptable to the physical conditions of each patient at the different stages of the rehabilitation therapy. Long-term monitoring systems need an adaptation policy to autonomously reconfigure their behaviour according to vital signs read during the physical activity of the patient, the remaining battery level, or the required accuracy of collected data. However, it would alsobe desirable to adjust such adaptation policies over time, according to the patient’s evolution. This work presents a wearable patient-monitoring system for tele-rehabilitation that is able to dynamically self-configure its internal behaviour to the current context of the outpatient according to a set of adaptation policies that optimize battery consumption, taking into account other QoS parameters at the same time. Our system is also able to self-adapt its internal adaptation policies as a patient’s condition improves, while maintaining the system’s efficiency. We illustrate our proposal with a real mHealth case study. The results of the experiments show that the system updates the adaptation policies, taking into account specific indicators of the disease. The validation results show that the evolution of the self-adaptation policies correlates with the progression of different patients.",health
10.1016/j.jbi.2020.103483,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Agents and robots for collaborating and supporting physicians in healthcare scenarios,https://api.elsevier.com/content/abstract/scopus_id/85087202709,"Monitoring patients through robotics telehealth systems is an interesting scenario where patients’ conditions, and their environment, are dynamic and unknown variables. We propose to improve telehealth systems’ features to include the ability to serve patients with their needs, operating as human caregivers. The objective is to support the independent living of patients at home without losing the opportunity to monitor their health status. Application scenarios are several, and they spread from simple clinical assisting scenarios to an emergency one. For instance, in the case of a nursing home, the system would support in continuously monitoring the elderly patients. In contrast, in the case of an epidemic diffusion, such as COVID-19 pandemic, the system may help in all the early triage phases, significantly reducing the risk of contagion. However, the system has to let medical assistants perform actions remotely such as changing therapies or interacting with patients that need support. The paper proposes and describes a multi-agent architecture for intelligent medical care. We propose to use the beliefs-desires-intentions agent architecture, part of it is devised to be deployed in a robot. The result is an intelligent system that may allow robots the ability to select the most useful plan for unhandled situations and to communicate the choice to the physician for his validation and permission.",health
10.1016/j.jiph.2020.06.006,Journal,Journal of Infection and Public Health,scopus,2020-08-01,sciencedirect,Artificial intelligence-based tools to control healthcare associated infections: A systematic review of the literature,https://api.elsevier.com/content/abstract/scopus_id/85086591816,"Background
                  Healthcare-associated infections (HAIs) are the most frequent adverse events in healthcare and a global public health concern. Surveillance is the foundation for effective HAIs prevention and control. Manual surveillance is labor intensive, costly and lacks standardization. Artificial Intelligence (AI) and machine learning (ML) might support the development of HAI surveillance algorithms aimed at understanding HAIs risk factors, improve patient risk stratification, identification of transmission pathways, timely or real-time detection. Scant evidence is available on AI and ML implementation in the field of HAIs and no clear patterns emerges on its impact.
               
                  Methods
                  We conducted a systematic review following the PRISMA guidelines to systematically retrieve, quantitatively pool and critically appraise the available evidence on the development, implementation, performance and impact of ML-based HAIs detection models.
               
                  Results
                  Of 3445 identified citations, 27 studies were included in the review, the majority published in the US (n
                     =15, 55.6%) and on surgical site infections (SSI, n
                     =8, 29.6%). Only 1 randomized controlled trial was included. Within included studies, 17 (63%) ML approaches were classified as predictive and 10 (37%) as retrospective. Most of the studies compared ML algorithms’ performance with non-ML logistic regression statistical algorithms, 18.5% compared different ML models’ performance, 11.1% assessed ML algorithms’ performance in comparison with clinical diagnosis scores, 11.1% with standard or automated surveillance models. Overall, there is moderate evidence that ML-based models perform equal or better as compared to non-ML approaches and that they reach relatively high-performance standards. However, heterogeneity amongst the studies is very high and did not dissipate significantly in subgroup analyses, by type of infection or type of outcome.
               
                  Discussion
                  Available evidence mainly focuses on the development and testing of HAIs detection and prediction models, while their adoption and impact for research, healthcare quality improvement, or national surveillance purposes is still far from being explored.",health
10.1016/j.jcv.2020.104474,Journal,Journal of Clinical Virology,scopus,2020-08-01,sciencedirect,Validation and verification of the Abbott RealTime SARS-CoV-2 assay analytical and clinical performance,https://api.elsevier.com/content/abstract/scopus_id/85085767646,"Background
                  High-throughput assays for the SARS-CoV-2 virus are critical to increasing test capacity and slowing the spread of COVID-19. Abbott Molecular developed and received emergency use authorization (EUA) to deploy the new RealTime SARS-CoV-2 assay, run on the automated m2000sp/rt system.
               
                  Objective
                  To evaluate analytical and clinical performance of the RealTime SARS-CoV-2 assay compared to the SARS-CoV-2 CDC-based laboratory developed test (LDT) in clinical use by the University of Washington Clinical Virology Laboratory (UW Virology).
               
                  Methods
                  RealTime SARS-CoV-2 assay limit of detection (LOD) was evaluated by testing two dilution panels of 60 replicates each. Cross-reactivity was evaluated by testing 24 clinical samples positive for various non‒SARS-CoV-2 respiratory viruses. Clinical performance was evaluated using 30 positive and 30 negative SARS-CoV-2 clinical samples previously tested using the UW Virology SARS-CoV-2 LDT.
               
                  Results
                  Exceeding the 100 copies/mL LOD reported in the RealTime SARS-CoV-2 assay EUA product insert, 19 of 20 replicates were detected at 50 copies/mL and 16 of 20 replicates were detected at 25 copies/mL. All clinical samples positive for 24 non‒SARS-CoV-2 respiratory viruses were SARS-CoV-2 negative on the RealTime SARS-CoV-2 assay. The assay had high sensitivity (93%) and specificity (100%) for detecting SARS-CoV-2 in clinical samples. Two positive samples that tested negative with the RealTime SARS-CoV-2 assay had cycle numbers of 35.94 or greater and required dilution prior to testing. One of these samples was also inconclusive on the SARS-CoV-2 LDT.
               
                  Conclusion
                  The RealTime SARS-CoV-2 assay is acceptable for clinical use. With the high-throughput, fully automated m2000 system, this assay will accelerate the pace of SARS-CoV-2 testing.",health
10.1016/j.jri.2020.103148,Journal,Journal of Reproductive Immunology,scopus,2020-08-01,sciencedirect,Proteomics and transcriptomics study reveals the utility of ISGs as novel molecules for early pregnancy diagnosis in dairy cows,https://api.elsevier.com/content/abstract/scopus_id/85084793155,"An early and precise diagnosis of pregnancy in cows is critical to short the calving interval and to improve their reproductive efficiency. Neutrophils are the first blood cells to sensitize the embryo in the uterus and participate in maternal recognition of pregnancy after getting induced by interferon tau (IFNτ). To study the protein abundance ratio, blood samples were collected on 0th, 10th, 18th and 36th day post-artificial insemination (AI) from crossbred Karan Fries cows. Neutrophils were isolated through density gradient centrifugation and studied for protein abundance by high-performance liquid chromatography coupled with mass spectrometry (LC–MS). Protein abundance ratios for Myxovirus resistance (MX1 and MX2) were found to be higher (P < 0.05) on day 10 and day 18 post-AI, whereas Oligoadenylate synthetase-1 (OAS1) and Interferon stimulated gene-15 ubiquitin-like modifier (ISG15) proteins were more abundant on day 18 post-AI. The relative mRNA expressions of these molecules were also studied by qPCR. The gene expression of ISG15, MX1, MX2 and OAS1 was found to be higher (P < 0.05) on day 10th, 18th and 36th post-AI compared to day 0. The study indicates that ISGs on blood neutrophils are essential for the establishment of pregnancy and may be targeted as potential biomarkers for pregnancy diagnosis in cows.",health
10.1016/j.cmpb.2020.105458,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-08-01,sciencedirect,Prediction model of the response to neoadjuvant chemotherapy in breast cancers by a Naive Bayes algorithm,https://api.elsevier.com/content/abstract/scopus_id/85083086614,"Background and Objective:
                  Chemotherapy is useful to many breast cancer patients, however, it is not therapeutic for some patients. Pathologic complete response (pCR) is an indicator to good response in Neoadjuvant chemotherapy (NAC). In this study, we aimed to develop a way to predict pCR before NAC.
               
                  Methods:
                  We retrospectively collected 287 stage II-III breast cancer cases either to a training set (N = 197) or to a test set (N = 90). Fourteen candidate genes were selected from four public microarray data sets. A prediction model was built, by using these fourteen candidate genes and three reference genes expression which were tested by TaqMan probe-based quantitative polymerase chain reaction, after selecting a better algorithm.
               
                  Results:
                  The Naive Bayes algorithm had a relatively higher predictive value, compared with random forest, support vector machine (SVM), and k-nearest neighbor (knn) algorithms (P < 0.05). This 17-gene prediction model showed a high positive correlation with pCR (odds ratio, 8.914, 95% confidence interval, 4.430–17.934, P < 0.001). By using this model, the enrolled patients were classified into sensitive (SE) and insensitive (INS) groups. The pCR rates between the SE and INS groups were highly different (42.3% vs.7.6%, P < 0.001). The sensitivity and specificity of this prediction model were 84.5% and 62.0%.
               
                  Conclusions:
                  Instead of whole transcriptome-based technologies, panel gene expression with tens of essential genes implemented in a machine learning model has predictive potential for chemosensitivity in breast cancers.",health
10.1016/j.chemosphere.2020.126653,Journal,Chemosphere,scopus,2020-08-01,sciencedirect,Effects of novel brominated flame retardants and metabolites on cytotoxicity in human umbilical vein endothelial cells,https://api.elsevier.com/content/abstract/scopus_id/85083060199,"Novel brominated flame retardants (NBFRs) have been widely used and frequently detected in various environmental matrices. In this study, 2-ethylhexyl-2,3,4,5-tetrabromobenzoate (TBB), bis-(2-ethylhexyl) tetrabromophthalate (TBPH) and their metabolites (namely 2,3,4,5-tetra-bromo benzoic acid (TBBA) and mono(2-ethylhexyl) tetrabromophthalate (TBMEHP)) were exposed to human umbilical vein endothelial cells (HUVECs). Metabolites can induce stronger cytotoxicity than parent compounds with EC50 at 47.3 (TBBA), 8.6 μg/ml (TBMEHP) vs > 200 μg/mL for parent compounds. Gene expression of platelet endothelial cell adhesion molecule-1, the gene associated with blood platelet kinetics, was significantly induced under TBBA and TBMEHP exposure. The in vivo test was consistent with gene expression result that the number of platelets in mouse blood was significantly increased after gavaged with 0.8 μg/mL TBBA and TBMEHP. In addition, TBB or TBPH were exposed to mice via gavage, and higher concentrations of TBBA (4 h, 60.8 ± 12.9 ng/mL, 8 h, 69.4 ± 2.24 ng/mL) in mouse blood were found than those of TBMEHP (4 h, 17.2 ± 4.01 ng/mL, 8 h, 12.8 ± 3.20 ng/mL), indicating that TBB was more readily in vivo metabolized than TBPH. The in vivo metabolism of TBB and TBPH and the stronger toxicity of their metabolites underscore the potential risk through NBFR exposure and the importance of understanding NBFR metabolism process.",health
10.1016/j.measurement.2020.107811,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-08-01,sciencedirect,Structural damage identification based on unsupervised feature-extraction via Variational Auto-encoder,https://api.elsevier.com/content/abstract/scopus_id/85083024572,"Structural health monitoring (SHM) is a practical tool for assessing the safety and system performance of existing structures. And structural damage identification has become the core of a SHM system. However, how to extract damage-sensitive features from structural response has become a challenging problem. Thus deep learning methods have attracted increasing attention for its ability to effectively extract high-level abstract features form raw data. This paper presents a damage detection method based on Variational Auto-encoder (VAE), one of the most important generative models in unsupervised deep learning. In this paper, VAE is used to process responses of the structure, which reduces the high-dimensional data to low-dimensional feature space, and then restores the original data from the low-dimensional representations. This structure forces the VAE to learn the essential features hidden behind the complex data. Taking advantage of this characteristic, we apply the VAE to damage identification task of a bridge under moving vehicle. The results of both numerical simulation and experiment are proved that the proposed method can accurately identify the structural damage/s. This method directly analyzes the measured responses of the structure without the structural element model and baseline data. It is a baseline-free data driven method, which is suitable for real engineering application in SHM.",health
10.1016/j.ijbiomac.2019.11.172,Journal,International Journal of Biological Macromolecules,scopus,2020-08-01,sciencedirect,Activation of RAW264.7 macrophages by an acidic polysaccharide derived from Citrus grandis ‘Tomentosa’,https://api.elsevier.com/content/abstract/scopus_id/85075859481,"Citrus grandis ‘Tomentosa’ which is a special Citrus cultivar, has been employed as cough suppressant and expectorant in traditional Chinese medicine for thousands of years. The aim of this study is to investigate the immunomodulatory role of an acidic polysaccharide (designated as CGTP-AP) purified from C. grandis ‘Tomentosa’. CGTP-AP showed effective immune activation in RAW264.7 macrophages at the concentration of 1–100 μg/mL. CGTP-AP could promote the release of NO in dose- and time-dependent manners. Enzyme-Linked Immunosorbent Assay (ELISA) and RT-PCR analysis demonstrated that CGTP-AP could stimulate the secretion of TNF-α and IL-6 in a dosage-dependent way. Western blot analysis and RT-PCR analysis indicated that CGTP-AP treatment could induce the iNOS and COX-2 expression in RAW264.7 macrophages. By conducting the inhibitors experiments, the activation of NF-κB and MAPK signaling pathways by CGTP-AP treatment was confirmed. Therefore, the present results declared that CGTP-AP could be a promising candidate as a potent immunomodulator for the application in future pharmaceutical development.",health
10.1016/j.conbuildmat.2020.118860,Journal,Construction and Building Materials,scopus,2020-07-30,sciencedirect,Structural health evaluation of the prestressed concrete using advanced acoustic emission (AE) parameters,https://api.elsevier.com/content/abstract/scopus_id/85082870823,"Acoustic emission (AE) is a promising technology for structural health monitoring to reduce costs and improve performance but hard to interpret. This paper puts forward an advanced deep neural network (DNN) method to dig information between AE parameters and performance of the structures since raw data obtained by the AE structural monitoring system is nearly useless without reinterpretation. Firstly, this study carried out a series of AE monitoring to catch crack signals of the prestressed concrete samples of cycle loads under three-point bending tests. The AE parameters analyzed include 
                        
                           
                              A
                              
                                 mean
                              
                           
                        
                     , 
                        
                           RA
                        
                     , 
                        
                           LE
                        
                     , 
                        
                           LQ
                        
                     , 
                        
                           
                              A
                              max
                           
                        
                     , 
                        
                           EA
                        
                     , 
                        
                           
                              V
                              e
                           
                        
                     , and 
                        
                           AK
                        
                     . The combination of them gives a comprehensive structural performance evaluation by the DNN model. The results show a good correlation between AE parameters with the crack activities of different loads. 
                        
                           
                              A
                              
                                 mean
                              
                           
                        
                     , 
                        
                           RA
                        
                     , 
                        
                           LE
                        
                      are the critical parameters in detecting whether the structure meets the design strength requirement. The combination of all these parameters gives an overall assessment of the structures. Finally, the method applies to the monitoring of two real-world bridges and gets comprehensive evaluations for all the monitoring points. This paper not only addresses a systematic experiment and a comprehensive parameter analysis method to realize data interpretation, but also practical applications in real-world bridges.",health
10.1016/j.foodchem.2020.126505,Journal,Food Chemistry,scopus,2020-07-30,sciencedirect,Preparation of monoclonal antibody against penicillic acid (PA) and its application in the immunological detection,https://api.elsevier.com/content/abstract/scopus_id/85081115992,"The high content of Penicillic acid (PA) in the feed pose threat to human health and cause serious losses to economic wealth through the enrichment effect of the food chain. The reliable and rapidly detection of PA is of significant importance to ensure food safety. In this study, indirect competitive enzyme-linked immunosorbent assay (ic-ELISA) and immunochromatographic test strips (ICTS) were established for PA determination based on anti-PA mAb secreted by 4H9 cell line. The linear range of ic-ELISA detection was 0.12–1.95 μg/mL, and the limit of detection (LOD) was 0.03 μg/mL. Then, conventional gold nanospheres (AuNS) with the average diameter of 20 nm were synthetized and AuNS-based strip was developed for rapidly detection of PA. The visual LOD (vLOD) of the AuNS-based strip was 3.9 μg/mL and the assay time of visual evaluation was less than 10 min without any instrument. To enhance the signal sensitivity of the ICTS, the larger size (about 85 nm) of gold nanoflowers (AuNFs) was prepared in our work, and was used as higher signal reporter to establish the AuNF-based strip for PA determination. Fortunately, the vLOD of AuNF-based strip was 0.97 μg/mL, which was approximately 4-fold lower than that of traditional AuNS-based strip. In summary, the rapid and sensitive immunoassays established in this study could be applied to detect and analyze the contamination of PA toxin in real food samples.",health
10.1016/j.scitotenv.2020.138533,Journal,Science of the Total Environment,scopus,2020-07-15,sciencedirect,Combined use of principal component analysis and artificial neural network approach to improve estimates of PM<inf>2.5</inf> personal exposure: A case study on older adults,https://api.elsevier.com/content/abstract/scopus_id/85083345897,"Accurate exposure estimate of the air pollutant PM2.5 is required to evaluate its health impacts in epidemiological studies, due to its adverse effects on human's respiratory and cardiovascular systems. However, traditional personal sampling is time and cost consuming. Thus, modeling techniques are needed to accurately predict the personal exposure level to PM2.5. In this study, a total of 117 older adults over 60 were recruited in Tianjin, a heavily polluted city in northern China, for indoor, outdoor and personal PM2.5 sampling. Eighteen variables which may increase the exposure level of older adults were recorded for artificial neural network (ANN) simulation. Four modeling techniques, including time-integrated activity modeling, Monte Carlo simulation, ANN modeling, and combined use of principal component analysis (PCA) and ANN model, were used to evaluate their ability for predicting real exposure values of PM2.5. The results of traditional time-weighted activity modeling showed the lowest correlation with measured values with R2 of 0.57 and 0.42 in winter and summer, respectively. For Monte Carlo simulation, high correlation was obtained (R2 of 0.93 and 0.92 in winter and summer, respectively) between percentiles of the predicted and the real exposure values. Compared with the simple ANN models, the combined use of PCA and ANN produced the most accurate results with R2 of 0.99 and RMSE lower than 15. Since the information of the input variables for the PCA-ANN model can be obtained from the questionnaire and fixed air quality monitoring sites, this technique shows a great potential in predicting personal exposure level to the air pollutant because no additional concentration measurement is needed.",health
10.1016/j.measurement.2020.107785,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-07-15,sciencedirect,Unsupervised deep hashing by joint optimization for pulmonary nodule image retrieval,https://api.elsevier.com/content/abstract/scopus_id/85083034639,"In recent years, hash-based image retrieval has attracted great attention due to the rapid growth of medical images. In the paper, an end-to-end unsupervised deep hashing is proposed, where feature extraction and binary optimization are carried out by joint optimization. Our method consists of five components: a shared deep convolution neural network for learning image representations, a deconvolution module for reconstructing the original images, a classification module for leveraging semantic supervision by pseudo labels, a binary code learning module for encoding images features into binary codes, and a joint loss function for deep hash function learning. In addition, the real-valued features balanced in different dimensions by a rotation matrix are quantized directly into discrete binary codes in an alternating optimization approach to minimize the quantization loss. Experiments have been performed on the pulmonary nodule images dataset and the results demonstrate the proposed method can yield better retrieval performance by comparing with the state-of-the-art unsupervised hashing methods.",health
10.1016/j.measurement.2020.107768,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-07-15,sciencedirect,"Intelligent fault diagnosis of rotating machinery via wavelet transform, generative adversarial nets and convolutional neural network",https://api.elsevier.com/content/abstract/scopus_id/85082880587,"The fault detection of rotating machinery systems especially its typical components such as bearings and gears is of special importance for maintaining machine systems working normally and safely. However, due to the change of working conditions, the disturbance of environment noise, the weakness of early features and various unseen compound failure modes, it is quite hard to achieve high-accuracy intelligent failure monitoring task of rotating machinery using existing intelligent fault diagnosis approaches in real industrial applications. In the paper, a novel and high-accuracy fault detection approach named WT-GAN-CNN for rotating machinery is presented based on Wavelet Transform (WT), Generative Adversarial Nets (GANs) and convolutional neural network (CNN). The proposed WT-GAN-CNN approach includes three parts. To begin with, WT is employed for extracting time-frequency image features from one-dimension raw time domain signals. Secondly, GANs are used to generate more training image samples. Finally, the built CNN model is used to accomplish the fault detection of rotating machinery by the original training time-frequency images and the generated fake training time-frequency images. Two experiment studies are implemented to assess the effectiveness of our proposed approach and the results demonstrate it is higher in testing accuracy than other intelligent failure detection approaches in the literatures even in the interference of strong environment noise or when working conditions are changed. Furthermore, its result in the stability of testing accuracy is also quite excellent.",health
10.1016/j.knosys.2020.105978,Journal,Knowledge-Based Systems,scopus,2020-07-08,sciencedirect,MTMA: Multi-task multi-attribute learning for the prediction of adverse drug–drug interaction,https://api.elsevier.com/content/abstract/scopus_id/85084192352,"Adverse drug–drug interaction (ADDI) is an important issue in drug developments and clinical applications, which causes a significant burden in the healthcare system and leads to serious morbidity and mortality in patients. Many methods are proposed for ADDI prediction due to the accumulation of healthcare data in a massive scale. However, these methods are insufficient in exploring the potential adverse mechanisms among drugs and incapable of revealing the leading factors of ADDIs. In this paper, we propose a Multi-Task Multi-Attribute (MTMA) learning model for ADDI prediction. In MTMA, two drug attributes, molecular structure and side effect, are adopted to model the adverse interactions among drugs and two interpretable tensors, adverse molecular structure–molecular structure interaction tensor and adverse side effect-side effect interaction tensor, are designed to uncover the adverse mechanisms among drugs. Meanwhile, we impose 
                        
                           
                              l
                           
                           
                              2
                              ,
                              1
                           
                        
                     -norm on the predicted attribute matrices to explore the leading molecular substructures and side effects for each specific ADDI. The optimization problem of MTMA is solved by an alternating algorithm based on the methods of low-rank tensor decomposition and stochastic gradient descent. Experiments on the real-world dataset demonstrate the considerable performance of MTMA when compared with nine baseline methods and its three variants.",health
10.1016/j.knosys.2020.105971,Journal,Knowledge-Based Systems,scopus,2020-07-08,sciencedirect,Intelligent fault diagnosis of rolling bearings based on normalized CNN considering data imbalance and variable working conditions,https://api.elsevier.com/content/abstract/scopus_id/85084170861,"Intelligent fault detection and diagnosis, as an important approach, play a crucial role in ensuring the stable, reliable and safe operation of rolling bearings, which is one of the most important components in the rotating machinery. In real industries, it is common to face that the issues of severe data imbalance and distribution difference since the number of fault data is small and the equipments frequently change the working conditions according to the production. To accurately and automatically identify the conditions of rolling bearings, a normalized convolutional neural network is proposed for the diagnosis of different fault severities and orientations considering data imbalance and variable working conditions. First, the batch normalization is adopted as a novel application to eliminate feature distribution difference, which is the prerequisite for ensuring generalization ability under different working conditions. Then, a special model structure is established and the overall performances of the proposed model are optimized by iterative update, which combines the exponential moving average technology. Finally, the proposed model is applied to the fault diagnosis under different data imbalance cases and working conditions. The effectiveness of the proposed method is verified based on two popular experiment dataset, and the diagnosis performance is widely evaluated in different scenarios. Comparisons with other commonly used methods and related works on the same dataset demonstrate the superiority of the proposed method. The results show that the proposed method has excellent diagnosis accuracy and admirable robustness, and also has sufficient stability on the data imbalance.",health
10.1016/j.artmed.2020.101920,Journal,Artificial Intelligence in Medicine,scopus,2020-07-01,sciencedirect,Automated detection of dynamical change in EEG signals based on a new rhythm measure,https://api.elsevier.com/content/abstract/scopus_id/85087898088,"Automated detection of dynamical change in EEG signals has been a long-standing problem in a wide range of clinic applications. It is essential to extract an effective and accurate EEG rhythm indicator that can reflect the dynamical behavior of a given EEG signal. Time-frequency analysis is a promising method to achieve this end, but existing methods still have limitations in real implementation making this kind of methods still progressive until the present day. In this paper, along the line of ongoing research on time-frequency methods, we present a new method based on graph-based modeling. By virtue of this method, an effective and accurate EEG rhythm indicator can be extracted to characterize the dynamical EEG time series. Together with the extracted EEG rhythm indicator, an automatic analysis of continuous monitoring of EEG signal, is developed by means of a null hypothesis testing to inspect whether an EEG change occurs or not during a monitoring period. The proposed framework is applied to both simulated data and real signals respectively to validate its effectiveness. Experimental results, together with theoretical interpretation and discussions, suggest its promising potentials in practice.",health
10.1016/j.comcom.2020.05.042,Journal,Computer Communications,scopus,2020-07-01,sciencedirect,Fastest adaptive estimation algorithms for topological structure errors in smart grid networks,https://api.elsevier.com/content/abstract/scopus_id/85086375513,"Compared with traditional wired networks, wireless sensor networks(WSN) have the characteristics of low cost and rapid deployment, and also guarantee the same level of fault tolerance as wired networks. The WSN can also monitor the operating status of the power grid in real time, collect physical information such as related parameters, and provide more comprehensive and complete power grid operation data as a reference basis for smart grid operation and related management personnel, and complete the diagnosis, monitoring and power statistics of smart grid equipment The rapid construction of the data communication network has become a key technology to effectively solve the problems of difficult optimization management and high cost and economic benefits in the smart grid. This paper discusses the application of WSNs in smart grids from two aspects. Firstly, construct a WSN topology that complies with the smart grid architecture, and establish a real-time routing mechanism that meets the requirements of smart distribution network communication reliability; secondly, propose a fastest adaptive algorithm for the fault of the WSN topology in the smart grid . The proposed adaptive routing mechanism has certain advantages in node energy consumption, which reduces energy consumption by nearly 4% compared to the directional diffusion method and the LEACH algorithm. Therefore, the algorithm is more suitable for the adaptation of WSN topology, and the method can Improve the life cycle of sensor nodes and networks.",health
10.1016/j.ymeth.2020.05.011,Journal,Methods,scopus,2020-07-01,sciencedirect,Encoder-decoder CNN models for automatic tracking of tongue contours in real-time ultrasound data,https://api.elsevier.com/content/abstract/scopus_id/85085288808,"One application of medical ultrasound imaging is to visualize and characterize human tongue shape and motion in real-time to study healthy or impaired speech production. Due to the low-contrast characteristic and noisy nature of ultrasound images, it requires knowledge about the tongue structure and ultrasound data interpretation for users to recognize tongue locations and gestures easily. Moreover, quantitative analysis of tongue motion needs the tongue contour to be extracted, tracked and visualized instead of the whole tongue region. Manual tongue contour extraction is a cumbersome, subjective, and error-prone task. Furthermore, it is not a feasible solution for real-time applications where the tongue contour moves rapidly with nuance gestures. This paper presents two new deep neural networks (named BowNet models) that benefit from the ability of global prediction of encoding–decoding fully convolutional neural networks and the capability of full-resolution extraction of dilated convolutions. Both qualitatively and quantitatively studies over datasets from two ultrasound machines disclosed the outstanding performances of the proposed deep learning models in terms of performance speed and robustness. Experimental results also revealed a significant improvement in the accuracy of prediction maps due to the better exploration and exploitation ability of the proposed network models.",health
10.1016/j.jbi.2020.103423,Journal,Journal of Biomedical Informatics,scopus,2020-07-01,sciencedirect,A medical treatment based scoring model to detect abusive institutions,https://api.elsevier.com/content/abstract/scopus_id/85084593071,"Medical abuse refers to a type of abnormal medical practice which is not in compliance with qualitative or ethical standards, such as excessive prescription or overbilling of medical services. Detection of such medical abuses is crucial, especially for the patients and insurance providers, because they become subject to the extra payments incurred. As a result, insurance providers hire medical experts in order to review claims manually, yet through examination is almost impossible due to the volume of the claims filed. A typical approach is to select institutions on suspicion of abusive practices and to manually review all claims involving suspect institutions. In this light, several studies have developed models designed to extract institution-level variables. However, since these variables are at an institution-level, the model cannot account for different types of abuse practiced by individual institutions, hence degrading the accuracy of the prediction model. At the same time, these variables contain information too simple to construct an effective scoring model. In this study, we propose a model that scores the degree of abuse practiced by institutions at the treatment-level, which is the lowest level of data that can be obtained from a medical claim. Our model is the first to use such fine-grained information to construct a model for scoring the abuse by medical institutions. The proposed model consists of two stages: Training a deep neural network with embedding layers for categorical variables, and scoring the abuse degree for each treatment with the model. Then, we aggregate the resulting abuse score of each treatment and the claim amount associated with each treatment by an institution which we define as the abuse score of the institution. We test our model using real-world claim data submitted to the Health Insurance Review and Assessment (HIRA) in 2016. We also compare the performance of the proposed model against the scoring model HIRA has been using, which computes the abuse score of an institution by using institution-level variables as proposed in past literature. Experiment results show that the proposed model represents the degree of medical abuse better. In addition, the results suggest that the reviewers may examine through the claims by at most 6.1 times more efficiently than when using the scoring model with institution-level variables.",health
10.1016/j.biopha.2020.110213,Journal,Biomedicine and Pharmacotherapy,scopus,2020-07-01,sciencedirect,Shuxuening injection facilitates neurofunctional recovery via down-regulation of G-CSF-mediated granulocyte adhesion and diapedesis pathway in a subacute stroke mouse model,https://api.elsevier.com/content/abstract/scopus_id/85084436869,"Post-stroke neural damage is a serious health concern which does not yet have an effective treatment. We have shown previously that Shuxuening injection (SXNI), a Ginkgo biloba extract-based natural medicine, protects brain after an acute ischemic stroke, but its efficacy for post-stroke recovery is not known. This study was to investigate whether SXNI can improve the prognosis of stroke at a subacute phase. Mice with cerebral ischemia-reperfusion injury (CIRI) were established by middle cerebral artery occlusion (MCAO), and drugs or saline were injected by the tail vein every 12 h after reperfusion. The therapeutic effect of SXNI was evaluated by survival rate, modified neurologic severity scores (mNSS), open-field test, locomotive gait patterns, cerebral infarction volume, brain edema and histopathological changes. Subsequently, a combined method of RNA-seq and Ingenuity® Pathway Analysis (IPA) was performed to identify key targets and pathways of SXNI facilitating the prognosis of stroke in mouse brain. The results of the transcriptome analysis were verified by real time reverse transcription-polymerase chain reaction (RT-PCR), enzyme-linked immunosorbent assay (ELISA), western blot (WB) and immunohistochemistry (IHC). The experimental results showed that in the new subacute stroke model, SXNI markedly improves the survival rate, neurological and motor functions and histopathological changes, and significantly reduces cerebral infarction and edema volume. RNA-seq analysis of subacute stroke mice with or without SXNI (3 mL/kg) indicated 963 differentially expressed genes (DEGs) with a fold change ≥ 1.5 and a P-value ≤ 0.01. IPA analysis of DEGs showed that granulocyte adhesion and diapedesis ranked first in the pathway ranking, and the most critical gene regulated by SXNI was G-csf. Simultaneously, RT-PCR, ELISA, WB and IHC results demonstrated that SXNI not only obviously reduced the mRNA expression levels of key genes G-csf, Sele and Mac-1 in this pathway, but also significantly decreased the protein expression levels of G-CSF in serum and E-selectin and MAC-1 in brain tissues. In summary, our research suggested that SXNI can exert a remarkable neurofunctional therapeutic effect on stroke mice via down-regulating G-CSF to inhibit granulocyte adhesion and diapedesis. This study provides experimental evidence that SXNI may fulfill the need for stroke medicine targeting specifically at the recovery stage.",health
10.1016/j.arth.2020.04.048,Journal,Journal of Arthroplasty,scopus,2020-07-01,sciencedirect,Digital Orthopaedics: A Glimpse Into the Future in the Midst of a Pandemic,https://api.elsevier.com/content/abstract/scopus_id/85084400483,"Background
                  The response to COVID-19 catalyzed the adoption and integration of digital health tools into the health care delivery model for musculoskeletal patients. The change, suspension, or relaxation of Medicare and federal guidelines enabled the rapid implementation of these technologies. The expansion of payment models for virtual care facilitated its rapid adoption. The authors aim to provide several examples of digital health solutions utilized to manage orthopedic patients during the pandemic and discuss what features of these technologies are likely to continue to provide value to patients and clinicians following its resolution.
               
                  Conclusion
                  The widespread adoption of new technologies enabling providers to care for patients remotely has the potential to permanently change the expectations of all stakeholders about the way care is provided in orthopedics. The new era of Digital Orthopaedics will see a gradual and nondisruptive integration of technologies that support the patient’s journey through the successful management of their musculoskeletal disease.",health
10.1016/j.ijmedinf.2020.104143,Journal,International Journal of Medical Informatics,scopus,2020-07-01,sciencedirect,An Integrated Approach of Machine Learning and Systems Thinking for Waiting Time Prediction in an Emergency Department,https://api.elsevier.com/content/abstract/scopus_id/85083437884,"Objective
                  The objective of this study is to apply machine learning algorithms for real-time and personalized waiting time prediction in emergency departments. We also aim to introduce the concept of systems thinking to enhance the performance of the prediction models.
               
                  Methods
                  Four popular algorithms were applied: (i) stepwise multiple linear regression; (ii) artificial neural networks; (iii) support vector machines; and (iv) gradient boosting machines. A linear regression model served as a baseline model for comparison. We conducted computational experiments based on a dataset collected from an emergency department in Hong Kong. Model diagnostics were performed, and the results were cross-validated.
               
                  Results
                  All the four machine learning algorithms with the use of systems knowledge outperformed the baseline model. The stepwise multiple linear regression reduced the mean-square error by almost 15%. The other three algorithms had similar performances, reducing the mean-square error by approximately 20%. Reductions of 17 – 22% in mean-square error due to the utilization of systems knowledge were observed.
               
                  Discussion
                  The multi-dimensional stochasticity arising from the ED environment imposes a great challenge on waiting time prediction. The introduction of the concept of systems thinking led to significant enhancements of the models, suggesting that interdisciplinary efforts could potentially improve prediction performance.
               
                  Conclusion
                  Machine learning algorithms with the utilization of the systems knowledge could significantly improve the performance of waiting time prediction. Waiting time prediction for less urgent patients is more challenging.",health
10.1016/j.cmpb.2020.105483,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-07-01,sciencedirect,Patient clustering using dynamic partitioning on correlated and uncertain biomedical data,https://api.elsevier.com/content/abstract/scopus_id/85082794247,"Background and objectivesHealth professionals look for specific patterns by correlating multiple physiological data in the process of deciding treatments to remedy clinical abnormalities. Biomedical data exhibit some common patterns in the event of identical clinical illnesses. The primary interest of this work is automatic discovery of such patterns in vital sign data (e.g. heart rate, blood pressure) using unsupervised learning and utilising them to identify patients with similar clinical conditions.
                  
                     MethodsA patient clustering method is developed that efficiently isolates patients into multiple groups by discovering dynamic patterns in multi-dimensional vital sign data. A dynamic partitioning algorithm and a patient clustering approach is proposed by introducing a measure namely aggregated instance-wise uncertainty (AIU) computed from multi-dimensional physiological time-series data.
                  
                     ResultsThe developed model is evaluated qualitatively using principal component analysis and silhouette value; and quantitatively in terms of its ability of clustering patients associated with different clinical situations. Experiments are conducted using real-world biomedical data of patients having various clinical conditions. Thee observed accuracy was 82.85% and 91.17% on two experimental datasets comprised of 35 and 34 patients data respectively.The comparisons show that the proposed approached outperformed than other methods in state-of-the-art approach.
                  
                     ConclusionsThe experimental outcomes demonstrate the effectiveness of the proposed approach in discovering distinct patterns with predictive significance.",health
10.1016/j.cmpb.2020.105382,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-07-01,sciencedirect,Medical decision making for 5D cardiac model: Template matching technique and simulation of the fifth dimension,https://api.elsevier.com/content/abstract/scopus_id/85079560398,"The purpose of this paper is to develop a 5D cardiac model which is inspired from the 5D model for the lungs. This model depends on five variables: the anatomical structure of the 3D heart, temporal dimension and the function of blood flow as the fifth dimension. To test this hypothesis, we took the same mathematical modeling as a reference for the fifth dimension of pulmonary flow where 
                        
                           
                              
                                 r
                                 →
                              
                              ρ
                           
                           
                              (
                              t
                              )
                           
                           =
                           
                              
                                 r
                                 →
                              
                              v
                           
                           
                              (
                              t
                              )
                           
                           +
                           
                              
                                 r
                                 f
                              
                              →
                           
                           
                              (
                              t
                              )
                           
                        
                      where
                        
                           
                           
                              
                                 r
                                 →
                              
                              v
                           
                           
                              (
                              t
                              )
                           
                        
                      is the displacement vectors with approximate magnitudes by linear functions of the tidal volume and 
                        
                           
                              
                                 
                                 
                                    r
                                    f
                                 
                              
                              →
                           
                           
                              (
                              t
                              )
                           
                        
                      is the blood flow. The scans were acquired for 10 patients,in the 404 series for a total of 18,483 images studied in three cases: healthy patient, case of heart failure and aortic stenosis. Where 
                        
                           
                              
                                 r
                                 →
                              
                              v
                           
                           
                        
                     and 
                        
                           
                              r
                              →
                           
                           f
                        
                      are the unit vectors along the volume of ejection and the blood flow axes, indicating the direction of motion of the object due to heart volume ejection and blood flow variations, respectively. The quantities of α and β coefficients are determined from real-time patient image data. The alpha and beta coefficients are derived from the following dimension equations[mm / ml] [mm*ms / ml] . Since the cardiac system has two diastolic and systolic phases, we have calculated α1 and β1 for telediatolic volume and α2 and β2 for telesystolic volume throughout the cardiac cycle as a function of the location of the cuts chosen randomly.
                  Fifth-dimensional experiments are used to track, simulate the behavior of blood flow to detect preliminary indications for the identification of stenosis or valve leakage. The average discrepancy was tabulated as the global fraction of systolic ejection. The results shown in Fig. 3 detect a correspondence between the hunting chamber cut and the flow sequence through the orifice of aorta for this patient with suspicious of having an aortic stenosis disease and an ejection fraction about 71% with a maximum of velocity (Vmax) detected=250 (cm / ms) = 2.5 (m / 10–3 s). In this case this patient has a minor stenosis in the aorta. It should be referred that the normalization of this measures is classified such as : Minor stenosis: area 1.5 cm2, Vmax <3 m / moderate stenosis: area 1.0 - 1.5 cm2, Vmax 3 - 4 m / severe stenosis: area <1.0 cm2, Vmax> 4 m / s. For a patient who has an aortic stenosis the cloud of the points is accumulated comparing to the origin of the axis while the patient with a symptom of insufficiency the points are widened with a remarkable gap in the trajectory.
                  To solve the issue of the bad prediction, the inaccuracy of the clouds points of the model 5D, the lack of the exact measurements to estimate the degree of cardiac insufficiency (leakage or stenosis), a solution of 5D imagery was depicted. Our main contribution is to test the validity of the template-matching algorithm and the fifth dimension simulation to provide more clues to detect the aortic stenosis and cardiac insufficiency in the context of medical decision support.",health
10.1016/j.apacoust.2020.107242,Journal,Applied Acoustics,scopus,2020-07-01,sciencedirect,An improved method to detect coronary artery disease using phonocardiogram signals in noisy environment,https://api.elsevier.com/content/abstract/scopus_id/85079343118,"Identification of coronary artery disease (CAD) from phonocardiogram (PCG) signal is a low signal to noise ratio (SNR) problem. This study proposes a PCG based CAD detection system robust against the environmental noise that does not require additional reference signals for noise acquisition and PCG segmentation. Here, the experiments are conducted on 40 CAD and 40 normal subjects. PCG signals are recorded from a multichannel data acquisition system from four auscultation sites on the left anterior chest. While heart sounds are propagated to different auscultation sites with a certain delay, the ambient noise appearing at microphone array are not mutually time-lagged. Thus, we propose to use the imaginary part of cross power spectral density (ICPSD) to capture the spectrum of heart sounds as it is unresponsive to zero time-lagged signals. Subband based spectral features obtained from ICPSD are classified in a machine learning framework. The performance of the system is studied in the presence of babble, vehicle and white noise in which useful information were extracted from both systolic and diastolic phases of cardiac cycle. The proposed method achieves accuracy, sensitivity and specificity of 74.98%, 76.50% and 73.46%, respectively in absence of ambient noise for k-fold (
                        
                           k
                           =
                           5
                        
                     ) cross-validation. The accuracy for 0 dB SNR in presence of white, babble and vehicle noise were 
                        
                           71.13
                           %
                           ,
                           66.47
                           %
                        
                      and 
                        
                           69.60
                           %
                        
                     , respectively. The proposed method was found to be superior in CAD classification when compared with existing noise removal based approach. The present work shows the potential of developing a PCG-based multichannel CAD detection system as an affordable point of care device for real-life use, where a certain amount of ambient noise is expected.",health
10.1016/j.eswa.2020.113251,Journal,Expert Systems with Applications,scopus,2020-07-01,sciencedirect,Integrating complex event processing and machine learning: An intelligent architecture for detecting IoT security attacks,https://api.elsevier.com/content/abstract/scopus_id/85079340111,"The Internet of Things (IoT) is growing globally at a fast pace: people now find themselves surrounded by a variety of IoT devices such as smartphones and wearables in their everyday lives. Additionally, smart environments, such as smart healthcare systems, smart industries and smart cities, benefit from sensors and actuators interconnected through the IoT. However, the increase in IoT devices has brought with it the challenge of promptly detecting and combating the cybersecurity attacks and threats that target them, including malware, privacy breaches and denial of service attacks, among others. To tackle this challenge, this paper proposes an intelligent architecture that integrates Complex Event Processing (CEP) technology and the Machine Learning (ML) paradigm in order to detect different types of IoT security attacks in real time. In particular, such an architecture is capable of easily managing event patterns whose conditions depend on values obtained by ML algorithms. Additionally, a model-driven graphical tool for security attack pattern definition and automatic code generation is provided, hiding all the complexity derived from implementation details from domain experts. The proposed architecture has been applied in the case of a healthcare IoT network to validate its ability to detect attacks made by malicious devices. The results obtained demonstrate that this architecture satisfactorily fulfils its objectives.",health
10.1016/j.cmpb.2019.105191,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-07-01,sciencedirect,Self-attention based recurrent convolutional neural network for disease prediction using healthcare data,https://api.elsevier.com/content/abstract/scopus_id/85075528327,"Background and Objective: Nowadays computer-aided disease diagnosis from medical data through deep learning methods has become a wide area of research. Existing works of analyzing clinical text data in the medical domain, which substantiate useful information related to patients with disease in large quantity, benefits early-stage disease diagnosis. However, benefits of analysis not achieved well when the traditional rule-based and classical machine learning methods used; which are unable to handle the unstructured clinical text and only a single method is not able to handle all challenges related to the analysis of the unstructured text, Moreover, the contribution of all words in clinical text is not the same in the prediction of disease. Therefore, there is a need to develop a neural model which solve the above clinical application problems, is an interesting topic which needs to be explored. Methods:Thus considering the above problems, first, this paper present self-attention based recurrent convolutional neural network (RCNN) model using real-life clinical text data collected from a hospital in Wuhan, China. This model automatically learns high-level semantic features from clinical text by using bi-direction recurrent connection within convolution. Second, to deal with other clinical text challenges, we combine the ability of RCNN with the self-attention mechanism. Thus, self-attention gets the focus of the model on essential convolve features which have effective meaning in the clinical text by calculating the probability of each convolve feature through softmax. Results:The proposed model is evaluated on real-life hospital dataset and used measurement metrics as Accuracy and recall. Experiment results exhibit that the proposed model reaches up to accuracy 95.71%, which is better than many existing methods for cerebral infarction disease. Conclusions:This article presented the self-attention based RCNN model by combining the RCNN with self-attention mechanism for prediction of cerebral infarction disease. The obtained results show that the presented model better predict the cerebral infarction disease risk compared to many existing methods. The same model can also be used for the prediction of other disease risks.",health
10.1016/j.jep.2020.112706,Journal,Journal of Ethnopharmacology,scopus,2020-06-28,sciencedirect,The effects of hydro-ethanolic extract of Capparis spinosa (C. spinosa) on lipopolysaccharide (LPS)-induced inflammation and cognitive impairment: Evidence from in vivo and in vitro studies,https://api.elsevier.com/content/abstract/scopus_id/85083222506,"Ethnopharmacological relevance
                  
                     Capparis spinose (C. spinosa) belonging to Capparaeae, originates from dry areas in the west or central Asia and Mediterranean basin. For thousands of years, C. spinosa has been reported to be used as a therapeutic traditional medicine to relieve various ailments including rheumatism, pain and inflammatory diseases.
               
                  Aim of the study
                  There are several studies mentioning that systemic inflammation results in learning and memory impairments through the activation of microglia. The objective of this study was to investigate the effect of C. spinosa on both in vivo and in vitro models of neuroinflammation and cognitive impairment using lipopolysaccharide (LPS).
               
                  Materials and methods
                  In vivo: 40 male rats were used in the present study. Cognitive impairment was induced using LPS (1 mg/kg/d; i.p.) for 4 weeks. Treatment with C. spinosa (100 and 300 mg/kg/d; p.o.) was performed 1 h before LPS administration. At the end of the experiment, rats were undergone for behavioral and biochemical analysis. In vitro: Primary microglia isolated from mouse was used in the present study. The cells were pretreated with C. spinosa extract (10–300 μg/ml) and then stimulated with LPS (1 μg/ml). The expression levels of inflammatory and anti-inflammatory cytokines were elucidated using Real-Time PCR and ELISA methods.
               
                  Results
                  The escape latency in the Morris water maze test in the LPS group was significantly greater than the control group (p < 0.001), while, in extract-treated groups, it was less than the LPS group (p < 0.001). Additionally, we found that the levels of IL-1β, TNF-α, and iNOS/Arg-1 ratio was also significantly lower in extract-treated groups than the LPS group (p < 0.001). The results revealed that C. spinosa extract significantly reduced the levels of TNF-α, iNOS, COX-2, IL-1β, IL-6, NO and PGE2, and the ratios of iNOS/Arg-1 and NO/urea, following the LPS-induced inflammation in microglia (p < 0.001).
               
                  Conclusions
                  Our finding provides evidence that C. spinosa has a neuroprotective effect, and might be considered as an effective therapeutic agent for the treatment of neurodegenerative diseases that are accompanied by microglial activation, such as AD.",health
10.1016/j.neucom.2020.02.049,Journal,Neurocomputing,scopus,2020-06-14,sciencedirect,Sparse filtering based domain adaptation for mechanical fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85080057528,"Recently, machine learning has achieved considerable success in the field of mechanical fault diagnosis. Nevertheless, in many real-world applications, the original vibration data usually collected under different work conditions which lead to large distribution divergences. As a result, the performances of many machine learning methods may drop dramatically. To overcome this deficiency, domain adaptation is introduced by adapting the regression model or classifier trained in the source domain for use in the distinct but related target domain. Particularly, a novel sparse filtering based domain adaptation approach (SFDA) is proposed for the mechanical fault diagnosis. Comparing with the previous researches, two main contributions of SFDA are concluded as follows: (1) the domain adaptation is applied to the sparse filtering algorithm. (2) The ℓ1-norm and ℓ2-norm are employed to the maximum mean discrepancy (MMD). (3) SFDA is easy to be implemented, and high classification accuracy can be obtained. The bearing and gear dataset are utilized to testify the validity and reliability of SFDA.",health
10.1016/j.patter.2020.100042,Journal,Patterns,scopus,2020-06-12,sciencedirect,Deep Learning Identifies Digital Biomarkers for Self-Reported Parkinson's Disease,https://api.elsevier.com/content/abstract/scopus_id/85095745471,"Large-scale population screening and in-home monitoring for patients with Parkinson's disease (PD) has so far been mainly carried out by traditional healthcare methods and systems. Development of mobile health may provide an independent, future method to detect PD. Current PD detection algorithms will benefit from better generalizability with data collected in real-world situations. In this paper, we report the top-performing smartphone-based method in the recent DREAM Parkinson's Disease Digital Biomarker Challenge for digital diagnosis of PD. Utilizing real-world accelerometer records, this approach differentiated PD from control subjects with an area under the receiver-operating characteristic curve of 0.87 by 3D augmentation of accelerometer records, a significant improvement over other state-of-the-art methods. This study paves the way for future at-home screening of PD and other neurodegenerative conditions affecting movement.",health
10.1016/j.artmed.2020.101819,Journal,Artificial Intelligence in Medicine,scopus,2020-06-01,sciencedirect,Toward development of PreVoid alerting system for nocturnal enuresis patients: A fuzzy-based approach for determining the level of liquid encased in urinary bladder,https://api.elsevier.com/content/abstract/scopus_id/85085731220,"Preventive and accurate assessment of bladder voiding dysfunctions necessitates measuring the amount of liquid encapsulated within urinary bladder walls in a non-invasive and real-time manner. The real-time monitoring of urine levels helps patients with urological disorders such as Nocturnal Enuresis (NE) by preventing the occurrence of enuresis via a pre-void stage alerting system. Although some advances have been achieved toward developing a non-invasive approach for determining the amount of accumulated urine inside the bladder, there is still a lack of an easy-to-implement technique which is suitable to embed in a wearable pre-warning device. This study aims to develop a machine-learning empowered technique to quantify to what extent an individual's bladder is filled by observing the filling-voiding pattern of a patient over a training period. In this experiment, a pulse-echo sonar element is used to generate ultrasound pulses while the probe surface is positioned perpendicular to the bladder's position. From the reflected echoes, four features which show sufficient sensitiveness and therefore could be modulated noticeably by different levels of liquid encased in the bladder, are extracted. The extracted features are then fed into a novel intelligent decision support system– known as FECOC – which is based on hybridization of fuzzy inference systems (FIS) and error correcting output codes (ECOC). The proposed scheme tends to achieve better results when examined in real case studies.",health
10.1016/j.compmedimag.2020.101729,Journal,Computerized Medical Imaging and Graphics,scopus,2020-06-01,sciencedirect,Simplification of neural networks for skin lesion image segmentation using color channel pruning,https://api.elsevier.com/content/abstract/scopus_id/85084760154,"Automatic analysis of skin abnormality is an effective way for medical experts to facilitate diagnosis procedures and improve their capabilities. Efficient and accurate methods for analysis of the skin abnormalities such as convolutional neural networks (CNNs) are typically complex. Hence, the implementation of such complex structures in portable medical instruments is not feasible due to power and resource limitations. CNNs can extract features from the skin abnormality images automatically. To reduce the burden of the network for feature extraction, which can lead to the network simplicity, proper input color channels could be selected. In this paper, a pruning framework is proposed to simplify these complex structures through the selection of most informative color channels and simplification of the network. Moreover, hardware requirements of different network structures are identified to analyze the complexity of different networks. Experimental results are conducted for segmentation of images from two publicly available datasets of both dermoscopy and non-dermoscopy images. Simulation results show that using the proposed color channel selection method, simple and efficient neural network structures can be applied for segmentation of skin abnormalities.",health
10.1016/j.compbiomed.2020.103810,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,Proposing a convolutional neural network for stress assessment by means of derived heart rate from functional near infrared spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85084553687,"Background
                  Stress is known as one of the major factors threatening human health. A large number of studies have been performed in order to either assess or relieve stress by analyzing the brain and heart-related signals.
               
                  Method
                  In this study, a method based on the Convolutional Neural Network (CNN) approach is proposed to assess stress induced by the Montreal Imaging Stress Task. The proposed model is trained on the heart rate signal derived from functional Near-Infrared Spectroscopy (fNIRS), which is referred to as HRF. In this regard, fNIRS signals of 20 healthy volunteers were recorded using a configuration of 23 channels located on the prefrontal cortex. The proposed deep learning system consists of two main parts where in the first part, the one-dimensional convolutional neural network is employed to build informative activation maps, and then in the second part, a stack of deep fully connected layers is used to predict the stress existence probability. Thereafter, the employed CNN method is compared with the Dense Neural Network, Support Vector Machine, and Random Forest regarding various classification metrics.
               
                  Results
                  Results clearly showed the superiority of CNN over all other methods. Additionally, the trained HRF model significantly outperforms the model trained on the filtered fNIRS signals, where the HRF model could achieve 98.69 ± 0.45% accuracy, which is 10.09% greater than the accuracy obtained by the fNIRS model.
               
                  Conclusions
                  Employment of the proposed deep learning system trained on the HRF measurements leads to higher stress classification accuracy than the accuracy reported in the existing studies where the same experimental procedure has been done. Besides, the proposed method suggests better stability with lower variation in prediction. Furthermore, its low computational cost opens up the possibility to be applied in real-time monitoring of stress assessment.",health
10.1016/j.psj.2019.10.015,Journal,Poultry Science,scopus,2020-06-01,sciencedirect,Cleaning and disinfection of crates and trucks used for duck transport: field observations during the H5N8 avian influenza outbreaks in France in 2017,https://api.elsevier.com/content/abstract/scopus_id/85084461250,"Transport of infected birds is thought to play a key role in the spread of avian influenza (AI) on poultry farms during epizootic outbreaks. Ensuring efficient cleaning and disinfection (C&D) of equipment used for transport is needed to prevent the spread of AI. This study aimed to evaluate the efficacy against the AI virus of C&D protocols applied on trucks and crates used for the transport of ducks during the H5N8 AI outbreaks in France in 2017. In 3 abattoirs, 16 transport vehicles and their crates were sampled by swabbing to detect the influenza type A genome by real-time reverse-transcription polymerase chain reaction. Vehicles were tested before and after decontamination, which was carried out in accordance with the abattoirs' protocols. A total of 86 samples out of 299 collected before C&D were positive for AI (29%); 7 trucks out of 16 transported crates detected positive for AI. After C&D, the AI genome was detected in 56 samples out of 308 (18%). Ten trucks were loaded with a shipment of AI-positive crates. Eight vehicles were detected positive in the cabin, on the truck bed, and/or on the wheels. Despite reinforcement of C&D, the efficacy of decontamination was variable among slaughterhouses. The efficacy seemed to depend on the initial contamination load, C&D protocols, and how the protocol is implemented. Breaks in biosecurity measures led to frequent contamination of trucks after C&D. Observational studies during animal health crises are of interest to analyze practices in emergency conditions and to put forward measures aimed at increased preparedness.",health
10.1016/j.ijid.2020.03.025,Journal,International Journal of Infectious Diseases,scopus,2020-06-01,sciencedirect,"Comparison of Xpert MTB/RIF (G4) and Xpert Ultra, including trace readouts, for the diagnosis of pulmonary tuberculosis in a TB and HIV endemic setting",https://api.elsevier.com/content/abstract/scopus_id/85084032333,"Background
                  There are limited data about Xpert-Ultra performance in different settings, in HIV-infected persons, in those with a history of previous TB, and with trace readouts.
               
                  Methods
                  We evaluated the relative accuracy of Xpert-MTB/RIF and Xpert-Ultra in 272 selected but well-characterized archived sputum samples. Of these, 168 were culture-positive (64/168 smear-positive and 104/168 smear-negative), and 104 were culture-negative (102/104 from patients with previous TB and 2/104 from patients without a TB history). Assay-specific limit-of-detection (LOD) experiments were conducted using serial dilutions of Mycobacterium tuberculosis H37Rv.
               
                  Results
                  Overall sensitivity (95%CI) in smear-negative culture-positive samples for Xpert-MTB/RIF and Xpert-Ultra were 71.2% (62.5–79.9) and 77% (68.9–85.1), respectively (and in HIV-infected persons: 63.5% (50–76.1) and 73.1% (61.1–85.2), respectively). The LOD for Xpert-Ultra was lower (9 versus 184 CFU/ml). There were a total of 9/272 (3.3%) Xpert Ultra trace readouts (6/104 [5.8%]) in smear-negative culture-positive persons, and 3/102 (3%) in culture-negative non-TB persons with a history of previous TB).
               
                  Conclusions
                  Xpert-Ultra had a lower LOD compared to Xpert-MTB/RIF. A small proportion of samples (<5%) from culture-negative patients but with a history of previous TB had a likely false-positive trace readout. These data inform the management of patients with suspected TB in endemic settings.",health
10.1016/j.compbiomed.2020.103792,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,Automated detection of COVID-19 cases using deep neural networks with X-ray images,https://api.elsevier.com/content/abstract/scopus_id/85083900518,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (https://github.com/muhammedtalo/COVID-19)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.",health
10.1016/j.jbi.2020.103426,Journal,Journal of Biomedical Informatics,scopus,2020-06-01,sciencedirect,Harmonized representation learning on dynamic EHR graphs,https://api.elsevier.com/content/abstract/scopus_id/85083820653,"With the rise of deep learning, several recent studies on deep learning-based methods for electronic health records (EHR) successfully address real-world clinical challenges by utilizing effective representations of medical entities. However, existing EHR representation learning methods that focus on only diagnosis codes have limited clinical value, because such structured codes cannot concretely describe patients’ medical conditions, and furthermore, some of the codes assigned to patients contain errors and inconsistency; this is one of the well-known caveats in the EHR. To overcome this limitation, in this paper, we fuse more detailed and accurate information in the form of natural language provided by unstructured clinical data sources (i.e., clinical notes). We propose HORDE, a unified graph representation learning framework to embed heterogeneous medical entities into a harmonized space for further downstream analyses as well as robustness to inconsistency in structured codes. Our extensive experiments demonstrate that HORDE significantly improves the performances of conventional clinical tasks such as subsequent code prediction and patient severity classification compared to existing methods, and also show the promising results of a novel EHR analysis about the consistency of each diagnosis code assignment.",health
10.1016/j.atmosenv.2020.117451,Journal,Atmospheric Environment,scopus,2020-06-01,sciencedirect,Estimating ground-level PM<inf>2.5</inf> using micro-satellite images by a convolutional neural network and random forest approach,https://api.elsevier.com/content/abstract/scopus_id/85083652155,"PM2.5 poses a serious threat to public health, however its spatial concentrations are not well characterized due to the sparseness of regulatory air quality monitoring (AQM) stations. This motivates novel low-cost methods to estimate ground-level PM2.5 at a fine spatial resolution so that PM2.5 exposure in epidemiological research can be better quantified. Satellite-retrieved aerosol products are widely used to estimate the spatial distribution of ground-level PM2.5. However, these aerosol products can be subject to large uncertainties due to many approximations and assumptions made in multiple stages of their retrieval algorithms. Therefore, estimating ground-level PM2.5 directly from satellites (e.g. satellite images) by skipping the intermediate step of aerosol retrieval can potentially yield lower errors because it avoids retrieval error propagating into PM2.5 estimation and is desirable compared to current ground-level PM2.5 retrieval methods. Additionally, the spatial resolutions of estimated PM2.5 are usually constrained by those of the aerosol products and are currently largely at a comparatively coarse 1 km or greater resolution. Such coarse spatial resolutions are unable to support scientific studies that thrive on highly spatially-resolved PM2.5. These limitations have motivated us to devise a computer vision algorithm for estimating ground-level PM2.5 at a high spatiotemporal resolution by directly processing the global-coverage, daily, near real-time updated, 3 m/pixel resolution, three-band micro-satellite imagery of spatial coverages significantly smaller than 1 
                        ×
                      1 km (e.g., 200 
                        ×
                      200 m) available from Planet Labs. In this study, we employ a deep convolutional neural network (CNN) to process the imagery by extracting image features that characterize the day-to-day dynamic changes in the built environment and more importantly the image colors related to aerosol loading, and a random forest (RF) regressor to estimate PM2.5 based on the extracted image features along with meteorological conditions. We conducted the experiment on 35 AQM stations in Beijing over a period of ~3 years from 2017 to 2019. We trained our CNN-RF model on 10,400 available daily images of the AQM stations labeled with the corresponding ground-truth PM2.5 and evaluated the model performance on 2622 holdout images. Our model estimates ground-level PM2.5 accurately at a 200 m spatial resolution with a mean absolute error (MAE) as low as 10.1 μg m−3 (equivalent to 23.7% error) and Pearson and Spearman r scores up to 0.91 and 0.90, respectively. Our trained CNN from Beijing is then applied to Shanghai, a similar urban area. By quickly retraining only RF but not CNN on the new Shanghai imagery dataset, our model estimates Shanghai 10 AQM stations' PM2.5 accurately with a MAE and both Pearson and Spearman r scores of 7.7 μg m−3 (18.6% error) and 0.85, respectively. The finest 200 m spatial resolution of ground-level PM2.5 estimates from our model in this study is higher than the vast majority of existing state-of-the-art satellite-based PM2.5 retrieval methods. And our 200 m model's estimation performance is also at the high end of these state-of-the-art methods. Our results highlight the potential of augmenting existing spatial predictors of PM2.5 with high-resolution satellite imagery to enhance the spatial resolution of PM2.5 estimates for a wide range of applications, including pollutant emission hotspot determination, PM2.5 exposure assessment, and fusion of satellite remote sensing and low-cost air quality sensor network information.",health
10.1016/j.gie.2019.12.049,Journal,Gastrointestinal Endoscopy,scopus,2020-06-01,sciencedirect,Artificial intelligence using convolutional neural networks for real-time detection of early esophageal neoplasia in Barrett's esophagus (with video),https://api.elsevier.com/content/abstract/scopus_id/85082811592,"Background and Aims
                  The visual detection of early esophageal neoplasia (high-grade dysplasia and T1 cancer) in Barrett’s esophagus (BE) with white-light and virtual chromoendoscopy still remains challenging. The aim of this study was to assess whether a convolutional neural artificial intelligence network can aid in the recognition of early esophageal neoplasia in BE.
               
                  Methods
                  Nine hundred sixteen images from 65 patients of histology-proven early esophageal neoplasia in BE containing high-grade dysplasia or T1 cancer were collected. The area of neoplasia was masked using image annotation software. Nine hundred nineteen control images were collected of BE without high-grade dysplasia. A convolutional neural network (CNN) algorithm was pretrained on ImageNet and then fine-tuned with the goal of providing the correct binary classification of “dysplastic” or “nondysplastic.” We developed an object detection algorithm that drew localization boxes around regions classified as dysplasia.
               
                  Results
                  The CNN analyzed 458 test images (225 dysplasia and 233 nondysplasia) and correctly detected early neoplasia with sensitivity of 96.4%, specificity of 94.2%, and accuracy of 95.4%. With regard to the object detection algorithm for all images in the validation set, the system was able to achieve a mean average precision of .7533 at an intersection over union of .3
               
                  Conclusions
                  In this pilot study, our artificial intelligence model was able to detect early esophageal neoplasia in BE images with high accuracy. In addition, the object detection algorithm was able to draw a localization box around the areas of dysplasia with high precision and at a speed that allows for real-time implementation.",health
10.1016/j.micpath.2020.104092,Journal,Microbial Pathogenesis,scopus,2020-06-01,sciencedirect,Alteration of the gut microbiome and immune factors of grass carp infected with Aeromonas veronii and screening of an antagonistic bacterial strain (Streptomyces flavotricini),https://api.elsevier.com/content/abstract/scopus_id/85081984813,"Aeromonas veronii is a widely distributed novel pathogen that can affect humans and animals, it can cause sepsis in fish with high mortality and serious economic losses to aquaculture. In the study, the gut microbiome of the infected and uninfected grass carp with Aeromonas veronii were analyzed probiotics and pathogenic bacteria by the Miseq high-throughput sequencing, the results showed that the infected fish were significantly higher in Proteobacteria, Firmicutes, Fusobacteria, and the immune factors in liver and kidney were up-regulated by qRT-PCR. In order to effectively inhibit the pathogen, we screened an actinomycete strain and had good antibacterial effect on Aeromonas veronii. The new antagonistic bacteria was named as Streptomyces flavotricini X101, the whole genome sequencing revealed that the metabolic process was most active. After grass carp was inoculated with the minimum inhibitory concentration of 900 μg/mL of the strain's fermentation supernatant, then Aeromonas veronii was injected, we found that the pathological symptoms such as body surface, anus and abdominal congestion were alleviated by H&E staining. Cellular experiments showed that it wasn't toxic to liver cells of grass carp. Overall, this is the first study of changes in intestinal flora, phenotype, and immune factors in grass crap infected with Aeromonas veronii, it had important theoretical significance and application value for immunization and prevention.",health
10.1016/j.ins.2020.02.037,Journal,Information Sciences,scopus,2020-06-01,sciencedirect,A training-integrity privacy-preserving federated learning scheme with trusted execution environment,https://api.elsevier.com/content/abstract/scopus_id/85081023216,"Machine learning models trained on sensitive real-world data promise improvements to everything from medical screening to disease outbreak discovery. In many application domains, learning participants would benefit from pooling their private datasets, training precise machine learning models on the aggregate data, and sharing the profits of using these models. Considering privacy and security concerns often prevent participants from contributing sensitive data for training, researchers proposed several techniques to achieve data privacy in federated learning systems. However, such techniques are susceptible to causative attacks, whereby malicious participants can inject false training results with the aim of corrupting the well-learned model. To end this, in this paper, we propose a new privacy-preserving federated learning scheme that guarantees the integrity of deep learning processes. Based on the Trusted Execution Environment (TEE), we design a training-integrity protocol for this scheme, in which causative attacks can be detected. Thus, each participant is compelled to execute the privacy-preserving learning algorithm of the scheme correctly. We evaluate the performance of our scheme by prototype implementations. The experimental result shows that the scheme is training-integrity and practical.",health
10.1016/j.asoc.2020.106123,Journal,Applied Soft Computing Journal,scopus,2020-06-01,sciencedirect,Dynamic ensemble mechanisms to improve particulate matter forecasting,https://api.elsevier.com/content/abstract/scopus_id/85080929358,"Respirable solid particles and liquid droplets suspended in the air, known as particulate matter (PM), may have a significant impact on human health, urban infrastructure, and natural and agricultural systems. The adverse effects of PM have raised public concern, especially in heavily polluted areas in the world, making it imperative the development of strategies to keep the concentration levels of these pollutants below harmful thresholds. Traditional machine learning approaches have been used to forecast PM concentrations. However, complex chemical processes may be involved in the composition of PM in the atmosphere and influenced by many meteorological parameters. Thus, underlying data distributions of PM data, uninterruptedly collected, may evolve over time. This phenomenon, known as concept drift, implies an important challenge for traditional machine learning techniques since they do not have mechanisms to handle changes on data distribution at the running time, thus limiting their forecasting capabilities. The overall goal of this work is to evaluate whether the incorporation of mechanisms to deal with concept drift, together with online sequential learning approaches, can improve the accuracy of PM forecasting. To do so, new mechanisms that enable online dynamic ensembles to handle and retain knowledge from different concepts for more time were proposed and adapted to EOS and DOER algorithms, resulting in three approaches: EOS-rank, EOS-D and DOER-rank. These ensemble strategies, which were based on Online Sequential Extreme Learning Machines (OS-ELM), were compared with five algorithms from the literature. To evaluate their performance, real-world and artificial datasets, with known dynamic behaviors, and PM concentration datasets from different cities of the State of São Paulo, Brazil, were used in the experiments. The obtained results showed that the proposed approaches can handle dynamic environments with different rates of drift and that EOS-rank was capable of outperforming most approaches from the literature in scenarios with higher rates of drift. The results also indicate that PM data distributions slowly evolve over time and, consequently, the proposed mechanisms that keep information of past concepts and slowly adapt the ensemble tend to present better results when applied to forecast PM concentration.",health
10.1016/j.biopha.2019.109733,Journal,Biomedicine and Pharmacotherapy,scopus,2020-06-01,sciencedirect,Prevent action of magnoflorine with hyaluronic acid gel from cartilage degeneration in anterior cruciate ligament transection induced osteoarthritis,https://api.elsevier.com/content/abstract/scopus_id/85079860048,"According to the Chinese medicine, magnoflorine exerted significant anti-inflammatory effects and potentially promoted synthesis of proteoglycans in chondrocytes to reverse the progression of rheumatoid arthritis. However, the latent beneficial effect of magnoflorine for the treatment of traumatic osteoarthritis (OA) is still unknown. Therefore, we aim to demonstrate the efficacy of magnoflorine combined with HA-gel in attenuating cartilage degeneration in anterior cruciate ligament transection (ACLT) induced OA rat model. We found that the histological results showed the elevated cartilage matrix, chondrogenic signals and chondroprogenitor cells in HA-gel + magnoflorine treatment. HA-gel + magnoflorine treatment resulted in a decreased modified Mankin’s score, and a higher volume ratio of hyaline cartilage (HC)/calcified cartilage (CC) and HC/Sum (whole cartilage), compared to ACLT and HA-gel groups. Furthermore, both the volume ratios of HC/Sum and HC/CC were negatively correlated with modified Mankin’s scores. Finally, HA-gel + magnoflorine could significantly increase the BV/TV, Tb.Th, and decrease the Tb.Pf, Po(tot), Conn.Dn and Tb.Sp. In vitro, 50 μg/ml magnoflorine treatment could significantly increase the viability, S-phase, migration rate and chondrogenesis of chondroprogenitor cells. There were significant downregulations of MAPK/NF-κB signaling, and upregulations of chondrogenic signals in 50 μg/ml magnoflorine treatment. There were significant downregulations of proinflammatory cytokines and upregulation of IL-10 in HA-gel + magnoflorine treated group. Therefore, our study elucidated a protective effect of HA-gel + magnoflorine on attenuating cartilage degradation and maintaining SCB stabilization in ACLT induced OA.",health
10.1016/j.parint.2020.102063,Journal,Parasitology International,scopus,2020-06-01,sciencedirect,First report of multiple resistance to eprinomectin and benzimidazole in Haemonchus contortus on a dairy goat farm in France,https://api.elsevier.com/content/abstract/scopus_id/85078212316,"Pour-on eprinomectin was recently registered for lactating small ruminants. Given the high prevalence of benzimidazole resistance in gastrointestinal nematodes in dairy goats, many farmers use eprinomectin exclusively to treat their animals. On a French dairy goat farm, a veterinary practitioner noted a poor response to two types of eprinomectin treatment (pour-on application and injectable formulation). Therefore, we evaluated the efficacy of both formulations of eprinomectin, as well as moxidectin and fenbendazole, using the fecal egg count reduction test (FECRT) according to the World Association for the Advancement of Veterinary Parasitology (WAAVP) guidelines. Nematode species were identified at days 0 and post-treatment days 14 after bulk larval cultures, by morphology and real-time PCR. Plasma concentrations of eprinomectin were analyzed by high-performance liquid chromatography (HPLC) at post-treatment days 2 and 5 in the eprinomectin-treated groups. Egg count reductions were poor in animals treated with topical (−16.7%; 95% CI:[−237; 59]) or subcutaneous (21.5%; 95% CI:[−126; 73]) eprinomectin, and with fenbendazole (−5.8%; 95% CI:[−205; 63]). Haemonchus contortus was the main species identified by morphology and by real-time PCR before and after treatment. The plasma concentrations of eprinomectin were determined in all eprinomectin-treated animals and were above 2 ng/ml at post-treatment day 2, indicating that the lack of effect was not due to low exposure of the worms to the drug. Interestingly, moxidectin remained effective in all infected animals. This is the first report of multiple resistance to eprinomectin and benzimidazole in H. contortus on a French dairy goat farm with moxidectin as a relevant alternative.",health
10.1016/j.reth.2019.12.001,Journal,Regenerative Therapy,scopus,2020-06-01,sciencedirect,Thickness-wise growth technique for human articular chondrocytes to fabricate three-dimensional cartilage grafts,https://api.elsevier.com/content/abstract/scopus_id/85077922678,"Introduction
                  Cutting the cost of manufacturing is important for extending the use of tissue-engineered therapeutic products. The present study aimed to develop a simple method for fabrication of cartilaginous tissues for regenerative therapy, utilizing the phenomenon where human articular chondrocytes grow thickness-wise and spontaneously form three-dimensionally thick tissues.
               
                  Methods
                  Normal human articular chondrocytes (NHACs) were cultured with varying concentrations of transforming growth factor beta 1 (TGF-β1) and/or fibroblast growth factor-2 (FGF-2) to optimize the culture condition for thickness-wise growth of chondrocytes. Next, the tissues grown in the optimal condition were subjected to re-differentiation culture in attached and detached states to assess differentiation capacity by evaluating secreted factors, histological analysis, and a gene expression assay.
               
                  Results
                  NHACs grew thickness-wise efficiently in the presence of 1 ng/mL TGF-β1 and 10 ng/mL FGF-2. After two weeks of culture, NHACs grew with 11-fold higher thickness and 16-fold higher cell number compared to cells which were neither treated with TGF-β1 nor with FGF-2. These thickness-wise-grown chondrocytes could be re-differentiated by a differentiation medium according to the increase in melanoma inhibitory activity (MIA) and positive safranin-O staining. Interestingly, the cartilaginous gene expression was considerably different between the attached and detached conditions even in the same culture medium, indicating the necessity of detachment and shrinkage to achieve further differentiation.
               
                  Conclusions
                  Spontaneous thickness-wise growth might provide a simple tissue-engineering method for manufacturing cartilaginous 3D tissues.",health
10.1016/j.copbio.2019.12.021,Journal,Current Opinion in Biotechnology,scopus,2020-06-01,sciencedirect,Incorporating biological structure into machine learning models in biomedicine,https://api.elsevier.com/content/abstract/scopus_id/85077913249,"In biomedical applications of machine learning, relevant information often has a rich structure that is not easily encoded as real-valued predictors. Examples of such data include DNA or RNA sequences, gene sets or pathways, gene interaction or coexpression networks, ontologies, and phylogenetic trees. We highlight recent examples of machine learning models that use structure to constrain model architecture or incorporate structured data into model training. For machine learning in biomedicine, where sample size is limited and model interpretability is crucial, incorporating prior knowledge in the form of structured data can be particularly useful. The area of research would benefit from performant open source implementations and independent benchmarking efforts.",health
10.1016/j.cmpb.2019.105299,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-06-01,sciencedirect,Design and evaluation of a context-aware model based on psychophysiology,https://api.elsevier.com/content/abstract/scopus_id/85077675344,"Background and objective: Psychotherapy is one of the most common pathways to help individuals address any mental disorders. However, the traditional method of assessing mental health has a margin for improvement. The recent advances in digital technology (e.g., smartphones and wearables) and machine learning techniques can support psychotherapy through the addition of psychophysiology. This paper presents RevitalMe, a context-aware model for assisting a psychotherapeutic understanding of human behavior, providing psychophysiological insights from real-life. Methods: Five volunteers used RevitalMe’s prototype in natural environments for eight days each. Ecological Momentary Assessment was used to collect individuals’ stressful states, and to label real-life data. The Wilcoxon Signed-Rank Test was performed to verify a significant difference between the labeled states. Then, RevitalMe classified psychological states based on physiological measurements through machine learning, associating them with the behavior of the individual. After that, visual insights were generated through contexts processing and presented to psychotherapists as evidence of an individual’s daily behavior and psychological state. Twelve psychotherapists evaluated the clinical acceptability of RevitalMe, answering six quantitative statements and two qualitative questions. Furthermore, a t-Test was performed to investigate clinical acceptability given therapy field and clinical years. Results: The Wilcoxon Signed-Rank Test succeeds in proving that labeled states were statistically significant, and RevitalMe achieved an F1-Score of 75% in the binary classification of stressed states in natural environments. The evaluation showed clinical acceptability of 90%, composed by partial agreement of 62% and a total agreement of 28%. In this regard, the t-Test provided that the level of interest from cognitive-behavior therapists in psychophysiological insight was higher than that from psychodynamic therapists. Conclusions: The psychophysiological insights approximate cognitive-behavior psychotherapy to individual’s behavior and daily events, focusing on assistance in mental healthcare.",health
10.1016/j.jep.2020.112670,Journal,Journal of Ethnopharmacology,scopus,2020-05-23,sciencedirect,Effect of Anoectochilus roxburghii flavonoids extract on H<inf>2</inf>O<inf>2</inf> - Induced oxidative stress in LO2 cells and D-gal induced aging mice model,https://api.elsevier.com/content/abstract/scopus_id/85081986322,"Ethnopharmacological relevance
                  Anoectochilus roxburghii (A. roxburghii) is a popular folk medicine in many Asian countries, which has been used traditionally for treatment of some diseases such as diabetes, tumors, hyperlipemia, and hepatitis. The ethanol extract from A. roxburghii was recently shown to exert better ability to scavenge free radicals in vitro and possess antioxidant on natural aging mice in vivo.
               
                  Aim of the study
                  This study is to characterize the chemical composition, and investigate the protective effect of the A. roxburghii flavonoids extract (ARF) against hydrogen peroxide (H2O2)-induced oxidative stress in LO2 cells in vitro and D-galactose (D-gal)-induced aging mice model in vivo, and explore the underlying mechanisms.
               
                  Materials and methods
                  The chemical components of the flavonoids extract from 
                     A. roxburghii were detected by ultraperformance lipid chromatography coupled with quadrupole-time-of-flight mass spectrometry (UPLC-QTOF-MS/MS). H2O2 was used to establish an oxidative stress model in LO2 cells. Cytotoxic and protective effects of ARF on the LO2 cells were determined using 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT) method. Moreover, the levels of superoxide dismutase (SOD), glutathione peroxidase (GSH-PX), and malondialdehyde (MDA) in cell supernatants were measured by commercial reagent kits. Kun-Ming mice were induced to aging with D-gal (400 mg/kg, BW) by subcutaneous injection for 58 days. From the 28th day to the 58th day of D-gal treatment, ARF (122.5, 245 and 490 mg/kg, BW) and vitamin E (100 mg/kg, BW) were orally administrated to aging mice once a day for consecutive 30 days. After 25 days of the treatment with ARF, learning and memory were assessed using Morris Water Maze (MWM). At the end of the test period, the animals were euthanized by cervical dislocation, and the levels of SOD, GSH-PX, and MDA in serum, liver homogenates and brain homogenates were measured. The levels of monoamine oxidase (MAO) and acetylcholinesterase (AchE) were determined in brain homogenates. Skin and liver histopathological morphology were observed by H&E staining. Furthermore, antioxidant-related gene expression levels in the liver were carried out by quantitative real-time polymerase chain reaction (qRT-PCR).
               
                  Results
                  Nine flavonoids were identified in the extracts of A. roxburghii. In vitro assay, a high concentration of ARF (>612.5 μg/ml) reduced the survival rate and had toxic effects on LO2 cells. In addition, ARF (245 μg/ml, 490 μg/ml) and Vitamin C (200 μg/ml) markedly inhibited generations of MDA and increased activities of SOD, GSH-PX in H2O2-induced LO2 cells supernatants. In vivo assay, ARF (122.5 mg/kg, 245 mg/kg and 490 mg/kg) and Vitamin E (100 mg/kg) not only ameliorated learning and memory ability but also improved skin and liver pathological alterations. Strikingly, ARF significantly decreased MDA and MAO levels, markedly enhanced antioxidant enzyme (SOD and GSH-PX) activities. Further, compared to the D-gal group, ARF could obviously up-regulate glutathione peroxidase-1 (GPx-1) and glutathione peroxidase-4 (GPx-4) mRNA levels.
               
                  Conclusions
                  These findings suggested that ARF protects LO2 cells against H2O2-induced oxidative stress and exerts the potent anti-aging effects in D-gal aging mice model, which may be related to the inhibition of oxidative stress. Flavonoid compounds may contribute to the anti-oxidative capability and modulating aging.",health
10.1016/j.vaa.2019.12.008,Journal,Veterinary Anaesthesia and Analgesia,scopus,2020-05-01,sciencedirect,Ultrasound-guided continuous block of median and ulnar nerves in horses: development of the technique,https://api.elsevier.com/content/abstract/scopus_id/85082748293,"Objective
                  To develop a technique for ultrasound-guided continuous median and ulnar peripheral nerve block in horses.
               
                  Study design
                  Anatomical and prospective experimental study.
               
                  Animals
                  A total of 16 thoracic limbs from horse cadavers and 18 adult horses.
               
                  Method
                  This study was conducted in three phases. Phase 1: Dissection of median and ulnar nerves in the antebrachial region of two cadaver limbs to identify localizing landmarks. Description of sonoanatomy in 14 cadaver limbs using ultrasound-guided perineural infiltration of a combination of cellulose gel (5 mL), contrast medium (4 mL) and methylene blue (1 mL). Catheters were inserted between the perineural sheath and epineurium in six limbs, followed by computed tomography. Phase 2: Ultrasonographic images of the limbs of 18 healthy horses of different breeds were used to define an acoustic window and optimize the approach to nerves. Phase 3: Two case reports of horses with chronic pain of different etiologies. Catheters were inserted between the epineurium and paraneural sheath of the median and/or ulnar nerves guided by ultrasound, followed by continuous infusion of 0.4% ropivacaine.
               
                  Results
                  Information from phase 1 was used to direct needle insertion, solution dispersion and catheter implantation in phase 2, which resulted in 100% technique accuracy. In response to the peripheral nerve block, pain reduction was apparent in the two clinical cases by increased weight bearing in affected limbs and decreased requirement for systemic analgesic medications. No local reactions were observed.
               
                  Conclusions and clinical relevance
                  The ultrasound technique allowed real-time visualization of needle, catheter and drug dispersion and resulted in a high success rate for nerve blocks. The horses administered a median and ulnar nerve block exhibited no discomfort or signs of infection at the catheter insertion site. Further studies are warranted to validate the efficacy of this technique.",health
10.1016/j.mednuc.2020.02.006,Journal,Medecine Nucleaire,scopus,2020-05-01,sciencedirect,Joint SFMN/ANOCEF focus on 18F-FDOPA PET imaging in glioma: Current applications and perspectives,https://api.elsevier.com/content/abstract/scopus_id/85081912823,"18F-FDOPA PET has demonstrated its additional value during the clinical course of glioma, at initial diagnosis, for treatment planning or follow-up. The aim of the current review was to summarize current applications of 18F-FDOPA PET in gliomas and constitute, as a perspective, a first step in harmonizing clinical practices in French centers. In France, the indication for 18F-FDOPA PET is restricted to the assessment of primary brain tumor recurrence. According to the literature, this indication could be expanded to primary diagnosis and, to a lesser extent, treatment monitoring. There is a real need to harmonize standard procedures among French centers. The objective is to increase the availability of data for this rare entity of glioma and to develop multi-parametric PET analyses (static, dynamic and textural), also known as radiomics, by using artificial intelligence algorithms. For this purpose, kinetics analysis with dynamic PET acquisition should be implemented in routine practice because it has demonstrated its additional value for initial diagnosis in gliomas. Therefore, this review proposes a workflow based on acquisition and reconstruction parameters that can be implemented in each center to increase the amount of standardized 18F-FDOPA PET data in neuro-oncology imaging in France. This would help in creating a national database and developing national multi-center studies that can respond to the challenge of using multi-parametric PET in glioma.",health
10.1016/j.measurement.2020.107539,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-05-01,sciencedirect,A simple data augmentation algorithm and a self-adaptive convolutional architecture for few-shot fault diagnosis under different working conditions,https://api.elsevier.com/content/abstract/scopus_id/85079319367,"In the era of big data, various data-driven fault diagnosis algorithms, which are mainly based on traditional machine learning and deep learning, have been developed and successfully applied on several benchmark datasets. However, in the real world, there are two major obstacles that prevent existing data-driven algorithms from being applied in actual industrial diagnostics applications: a) few-shot learning with limited labelled data, and b) high requirement for model’s generalization ability to adapt different diagnosis circumstances. Two classic feature engineering methods of Order Tracking and Fast Fourier Transform give us inspirations to solve these problems. In this paper, we propose a data augmentation algorithm based on the core assumption of Order Tracking and present a self-adaptive convolutional neural network for fault diagnosis. The data augmentation algorithm utilizes resampling technique to simulate data under different rotating speeds and working loads, in which the Fast Fourier Transform is embedded alternately to calculate the frequency spectra of the expanded dataset. Based on the robust features in the spectra, the self-adaptive convolutional architecture is designed with much fewer Floating Points Operations (FLOPs) and trainable parameters than the deep counterparts, by which the extracted features are invariant for generalization and discriminative for classification. Experiments based on two bearing databases have been carried out and the results have verified the generalization ability and adaptability for few-shot learning of our proposed methods.",health
10.1016/j.biopha.2020.109908,Journal,Biomedicine and Pharmacotherapy,scopus,2020-05-01,sciencedirect,Epimedium polysaccharides attenuates hematotoxicity by reducing oxidative stress and enhancing immune function in mice model of benzene-induced bone marrow failure,https://api.elsevier.com/content/abstract/scopus_id/85078667696,"Chronic benzene (BZ) exposure is associated with multiple adverse health effects and leads to progressive bone marrow failure (BMF). BZ-induced BMF is an acquired aplastic anemia characterized by severe anemia, neutropenia and thrombocytopenia, which is likely caused by immunotoxicity and oxidative stress. Previous studies showed that Epimedium polysaccharides (EPS), a natural and major herbal compound derived from Epimedium, has immunomodulatory and antioxidant potential. The purpose of this study was to evaluate the potential efficacy of EPS against BZ-induced BMF. BMF mouse model was established by subcutaneous injection of 2 ml/kg BZ in CD1 mice. Mice received daily oral treatment with 100 mg/kg high-dose EPS and 20 mg/kg low-dose EPS for four weeks. Our data showed that EPS treatment alleviated BZ-associated weight loss and increased the number of whole blood cells in peripheral blood and nucleated cells in bone marrow. Furthermore, EPS treatment decreased apoptotic rate and reactive oxygen species production, S-phase arrest in bone marrow cells. Finally, EPS treatment improved T cell-mediated immune suppression by increasing CD3+, CD4 + T-cell counts, and CD4+/CD8+ ratio. and modulated hematopoietic cytokines including EPO, IL-11, and IL-2 in peripheral blood. Our study suggests that EPS is a potential therapeutic target to attenuate hematotoxicity induced by BZ.",health
10.1016/j.ymssp.2019.106609,Journal,Mechanical Systems and Signal Processing,scopus,2020-05-01,sciencedirect,A rotating machinery fault diagnosis method based on multi-scale dimensionless indicators and random forests,https://api.elsevier.com/content/abstract/scopus_id/85077448538,"Fault diagnosis methods based on dimensionless indicators have long been studied for rotating machinery. However, traditional dimensionless indicators frequently suffer a low accuracy of fault diagnosis for nonlinear and non-stationary dynamic signals of rotating machinery. In this paper, we propose an effective fault diagnosis method based on multi-scale dimensionless indicator (MSDI) and random forests. In the proposed method, the real-time vibration signals are first processed by the variational mode decomposition and then six types of MSDI are constructed based on the decomposed signals. Through utilizing the Fisher criterion, several top ranked MSDIs are selected as fault features. Based on the selected MSDIs, the random forests model is applied to determine fault types. To verify the superiority of the proposed method, several experiments on fault diagnosis are conducted on a centrifugal multi-level impeller blower. The results demonstrate that the proposed method can successfully identify different fault types and the average accuracy can reach 95.58%. In contrast with traditional dimensionless indicators based methods, the proposed method can improve the fault diagnosis accuracy by 7.25% and outperforms other techniques such as back propagation neural network, support vector machine and extreme learning machine. These results indicate that the MSDI can effectively solve the deficiency of the traditional dimensionless indicator, and has stronger distinguishing ability for the fault types.",health
10.1016/j.chemosphere.2019.125730,Journal,Chemosphere,scopus,2020-05-01,sciencedirect,Toxicity assessment of parabens in Caenorhabditis elegans,https://api.elsevier.com/content/abstract/scopus_id/85077400711,"Parabens, the alkyl esters of p-hydroxybenzoic acid such as methylparaben (MeP), ethylparaben (EtP), propylparaben (PrP), butylparaben (BuP) are used as a preservative in food, personal care products (PCPs), and pharmaceuticals, due to their antimicrobial properties. Parabens are continuously released into the environment, during washout of PCPs, disposal of industrial waste from the pharmaceutical and paper industries. Parabens have been detected in the indoor dust, wastewater stream, surface water of rivers, and the marine system. Recent eco-toxicological data and the environmental presence of parabens, has raised concerns regarding the safety and health of environment/humans. Thus, to further understand the toxicity of parabens, the present study was carried out in the soil nematode and well established biological model organism Caenorhabditis elegans. In the present study, LC50 of MeP, EtP, PrP and BuP for 72 h exposures from L1 larva to adult stage was found to be 278.1, 217.8, 169.2, and 131.88 μg/ml, respectively. Further exposure to 1/5th of LC50 of parabens yielded an internal concentration ranging from 1.67 to 2.83 μg/g dry weight of the organism. The toxicity of parabens on the survival, growth, behavior, and reproduction of the C. elegans was found in the order of BuP > PrP > EtP > MeP. Worms exposed to parabens show significant down-regulation of vitellogenin genes, high levels of reactive oxygen species and anti-oxidant transcripts, the latter being concordant with nuclear localization of DAF-16 and up-regulation of HSF-1 and SKN-1/Nrf. Hence, parabens caused endocrine disruption, oxidative stress and toxicity in C. elegans at environment relevant internal concentration of parabens.",health
10.1016/j.neucom.2019.11.010,Journal,Neurocomputing,scopus,2020-04-28,sciencedirect,Output based transfer learning with least squares support vector machine and its application in bladder cancer prognosis,https://api.elsevier.com/content/abstract/scopus_id/85078061159,"Two dilemmas frequently occur in many real-world clinical prognoses. First, the on-hand data cannot be put entirely into the existing prediction model, since the features from new data do not perfectly match those of the model. As a result, some unique features collected from the patients in the current domain of interest might be wasted. Second, the on-hand data is not sufficient enough to learn a new prediction model. To overcome these challenges, we propose an output-based transfer learning approach with least squares support vector machine (LS-SVM) to make the maximum use of the small dataset and guarantee an enhanced generalization capability. The proposed approach can learn a current domain of interest with limited samples effectively by leveraging the knowledge from the predicted outputs of the existing model in the source domain. Also, the extent of output knowledge transfer from the source domain to the current one can be automatically and rapidly determined using a proposed fast leave-one-out cross validation strategy. The proposed approach is applied to a real-world clinical dataset to predict 5-year overall and cancer-specific mortality of bladder cancer patients after radical cystectomy. The experimental results indicate that the proposed approach achieves better classification performances than the other comparative methods and has the potential to be implemented into the real-world context to deal with small data problems in cancer prediction and prognosis.",health
10.1016/j.aca.2020.02.004,Journal,Analytica Chimica Acta,scopus,2020-04-22,sciencedirect,DNA aptamer-based non-faradaic impedance biosensor for detecting E. coli,https://api.elsevier.com/content/abstract/scopus_id/85079432760,"Developing a real-time, portable, and inexpensive sensor for pathogenic bacteria is crucial since the conventional detection approaches such as enzyme-linked immunosorbent assay (ELISA) and polymerase chain reaction (PCR) assays are high cost, time-consuming, and require an expert operator. Here we present a portable, inexpensive, and convenient impedance-based biosensor using Interdigitated Electrode (IDE) arrays to detect Escherichia coli (E. coli) as a model to demonstrate the feasibility of an impedance-based biosensor. We manipulated the affinity of the IDE array towards E. coli (E. coli BL21 series) by functionalizing the IDEs’ surface with an E. coli outer membrane protein (OMP) Ag1 Aptamer. To determine the dominant factors affecting the sensitivity and the performance of the biosensor in detecting E. coli, we investigated the roles of the substrate material used in the fabrication of the IDE, the concentration of the aptamer, and the composition of the carboxy aliphatic thiol mixture used in the pre-treatment of the IDE surface. In the sensing experiments we used an E. coli concentration range of 25–1000 cfu mL−1 and confirmed the binding of the OMP Ag1 Aptamer to the outer membrane protein of the E. coli by Field Emission Scanning Electron Microscopy (FESEM), Optical Microscopy, and Atomic Force Microscopy (AFM). By tuning the surface chemistry, the IDEs’ substrate material, and the concentration of the OMP Ag1 Aptamer, our sensor could detect E. coli with the analytical sensitivity of approximately 1.8 Ohm/cfu and limit of detection of 9 cfu mL−1. We found that the molecular composition of the self-assembled monolayer (SAM) formed on the top of the IDEs before the attachment of the OMP Ag1 Aptamer significantly impacted the sensitivity of the sensor. Notably, with straightforward changes to the molecular recognition elements, this platform device can be used to detect a wide range of other microorganisms and chemicals relevant for environmental monitoring and public health.",health
10.1016/j.knosys.2020.105534,Journal,Knowledge-Based Systems,scopus,2020-04-22,sciencedirect,GEV-NN: A deep neural network architecture for class imbalance problem in binary classification,https://api.elsevier.com/content/abstract/scopus_id/85078052925,"Class imbalance is a common issue in many applications such as medical diagnosis, fraud detection, web advertising, etc. Although standard deep learning method has achieved remarkably high-performance on datasets with balanced classes, its ability to classify imbalanced dataset is still limited. This paper proposes a novel end-to-end deep neural network architecture and adopts Gumbel distribution as an activation function in neural networks for class imbalance problem in the application of binary classification. Our proposed architecture, named GEV-NN, consists of three components: the first component serves to score input variables to determine a set of suitable input, the second component is an auto-encoder that learns efficient explanatory features for the minority class, and in the last component, the combination of the scored input and extracted features are then used to make the final prediction. We jointly optimize these components in an end-to-end training. Extensive experiments using real-world imbalanced datasets showed that GEV-NN significantly outperforms the state-of-the-art baselines by around 2% at most. In addition, the GEV-NN gives a beneficial advantage to interpret variable importance. We find key risk factors for hypertension, which are consistent with other scientific researches, using the first component of GEV-NN.",health
10.1016/j.patter.2020.100006,Journal,Patterns,scopus,2020-04-10,sciencedirect,Intelligent Electromagnetic Sensing with Learnable Data Acquisition and Processing,https://api.elsevier.com/content/abstract/scopus_id/85089142867,"Electromagnetic (EM) sensing is a widespread contactless examination technique with applications in areas such as health care and the internet of things. Most conventional sensing systems lack intelligence, which not only results in expensive hardware and complicated computational algorithms but also poses important challenges for real-time in situ sensing. To address this shortcoming, we propose the concept of intelligent sensing by designing a programmable metasurface for data-driven learnable data acquisition and integrating it into a data-driven learnable data-processing pipeline. Thereby, a measurement strategy can be learned jointly with a matching data post-processing scheme, optimally tailored to the specific sensing hardware, task, and scene, allowing us to perform high-quality imaging and high-accuracy recognition with a remarkably reduced number of measurements. We report the first experimental demonstration of “learned sensing” applied to microwave imaging and gesture recognition. Our results pave the way for learned EM sensing with low latency and computational burden.",health
10.1016/j.tgie.2019.150631,Journal,Techniques and Innovations in Gastrointestinal Endoscopy,scopus,2020-04-01,sciencedirect,Artificial intelligence for colon polyp detection: Why should we embrace this?,https://api.elsevier.com/content/abstract/scopus_id/85104673399,"Optimal success of colonoscopy for prevention of colorectal cancer is currently measured by adenoma detection rate (ADR), which reflects a colonoscopists ability to identify colorectal and remove precancerous polyps. Among colonoscopists in the same health care system and shared patient population, ADR varies from 7% to 53%. For every 1% increase in ADR, risk of interval colorectal cancer is reduced by 3%-6%. Beyond attaining excellent exposure of entire mucosal surface during colonoscopy, ADR can be improved with a second observer. Computer-aided detection (“facial recognition” for polyps) has potential to improve ADR as a second observer. Several groups are working to bring this technology into the endoscopy unit. Success will require real-time implementation of an affordable system with very high accuracy and proven benefit to improve ADR and reduce miss rate of precancerous lesions. In just the past year, computer-aided detection systems that run live during colonoscopy have been shown to improve ADR using affordable off-the-shelf computers.",health
10.1016/j.pmcj.2020.101147,Journal,Pervasive and Mobile Computing,scopus,2020-04-01,sciencedirect,Unsupervised domain adaptation for activity recognition across heterogeneous datasets,https://api.elsevier.com/content/abstract/scopus_id/85083082262,"Sensor-based human activity recognition is to recognise human daily activities through a collection of ambient and wearable sensors. It is the key enabler for many healthcare applications, especially in ambient assisted living. The advance of sensing and communication technologies has driven the deployment of sensors in many residential and care home settings. However, the challenge still resides in the lack of sufficient, high-quality activity annotations on sensor data, which most of the existing activity recognition algorithms rely on. In this paper, we propose an Unsupervised Domain adaptation technique for Activity Recognition, called UDAR, which supports sharing and transferring activity models from one dataset to another heterogeneous dataset without the need of activity labels on the latter. This approach has combined knowledge- and data-driven techniques to achieve coarse- and fine-grained feature alignment. We have evaluated UDAR on five third-party, real-world datasets and have demonstrated high recognition accuracy and robustness against sensor noise, compared to the state-of-the-art domain adaptation techniques.",health
10.1016/j.jbi.2020.103395,Journal,Journal of Biomedical Informatics,scopus,2020-04-01,sciencedirect,Research on Chinese medical named entity recognition based on collaborative cooperation of multiple neural network models,https://api.elsevier.com/content/abstract/scopus_id/85081138953,"Medical named entity recognition (NER) in Chinese electronic medical records (CEMRs) has drawn much research attention, and plays a vital prerequisite role for extracting high-value medical information. In 2018, China Health Information Processing Conference (CHIP2018) organized a medical NER academic competition aiming to extract three types of malignant tumor entity from CEMRs. Since the three types of entity are highly domain-specific and interdependency, extraction of them cannot be achieved with a single neural network model. Based on comprehensive study of the three types of entity and the entity interdependencies, we propose a collaborative cooperation of multiple neural network models based approach, which consists of two BiLSTM-CRF models and a CNN model. In order to tackle the problem that target scene dataset is small and entity distributions are sparse, we introduce non-target scene datasets and propose sentence-level neural network model transfer learning. Based on 30,000 real-world CEMRs, we pre-train medical domain-specific Chinese character embeddings with word2vec, GloVe and ELMo, and apply them to our approach respectively to validate effects of pre-trained language models in Chinese medical NER. Also, as control experiments, we apply Gated Recurrent Unit to our approach. Finally, our approach achieves an overall F1-score of 87.60%, which is the state-of-the-art performance to the best of our knowledge. In addition, our approach has won the champion of the medical NER academic competition organized by 2019 China Conference on Knowledge Graph and Semantic Computing, which proves the outstanding generalization ability of our approach.",health
10.1016/j.jenvp.2020.101406,Journal,Journal of Environmental Psychology,scopus,2020-04-01,sciencedirect,Attention restoration during environmental exposure via alpha-theta oscillations and synchronization,https://api.elsevier.com/content/abstract/scopus_id/85080995062,"Evidence has revealed that exposure to a restorative environment can have health and cognitive benefits, but the mechanism remains unclear. This study was designed to explore the neural mechanism of environmental restorative experiences. We conducted an experiment by randomly exposing thirty-two participants to either 20 min of a restorative (wooded garden) or a nonrestorative (traffic island) environment. Participants’ real-time electroencephalogram (EEG) signals were monitored via a 14-channel mobile device during the exposure. They also completed a series of psychological assessments of affective and cognitive functioning, as well as the perceived restorativeness of the environment, before and after the exposure.
                  The results revealed stronger and more efficient alpha-theta synchronization (functional connectivity) during the restorative experience, as well as stronger alpha-theta oscillations in the occipital lobes. Regression analysis revealed that perceived coherence was associated with the efficiency of the alpha-theta synchronization network (alpha: coef. = 2.02, 95% CI [0.68, 3.36], p = 0.020, R2 = 23.97%; theta: coef. = 2.41, 95% CI [1.30, 3.52], p < 0.001, R2 = 39.54%); fatigue recovery was associated with alpha-theta oscillations in the occipital lobes (alpha: coef. = -0.58, 95% CI [-0.88, −0.28], p = 0.001, R2 = 33.62%; theta: coef. = -0.50, 95% CI [-0.73, −0.26], p < 0.001, R2 = 37.74%); and the degree of fatigue recovery further improved attention-related cognitive performance (coef. = 0.22, 95% CI [0.03, 0.41], p = 0.027; R2 = 15.28%). Based on the abovementioned evidence, we proposed that the perceived coherence of the restorative environment may induce fatigue recovery and, hence, attention restoration via alpha-theta oscillations and synchronization. The increased alpha-theta oscillations in the occipital lobes suppress visual processing, allowing the human brain to reorganize itself via alpha-theta synchronization.",health
10.1016/j.media.2020.101634,Journal,Medical Image Analysis,scopus,2020-04-01,sciencedirect,Dynamic coronary roadmapping via catheter tip tracking in X-ray fluoroscopy with deep learning based Bayesian filtering,https://api.elsevier.com/content/abstract/scopus_id/85078506635,"Percutaneous coronary intervention (PCI) is typically performed with image guidance using X-ray angiograms in which coronary arteries are opacified with X-ray opaque contrast agents. Interventional cardiologists typically navigate instruments using non-contrast-enhanced fluoroscopic images, since higher use of contrast agents increases the risk of kidney failure. When using fluoroscopic images, the interventional cardiologist needs to rely on a mental anatomical reconstruction. This paper reports on the development of a novel dynamic coronary roadmapping approach for improving visual feedback and reducing contrast use during PCI. The approach compensates cardiac and respiratory induced vessel motion by ECG alignment and catheter tip tracking in X-ray fluoroscopy, respectively. In particular, for accurate and robust tracking of the catheter tip, we proposed a new deep learning based Bayesian filtering method that integrates the detection outcome of a convolutional neural network and the motion estimation between frames using a particle filtering framework. The proposed roadmapping and tracking approaches were validated on clinical X-ray images, achieving accurate performance on both catheter tip tracking and dynamic coronary roadmapping experiments. In addition, our approach runs in real-time on a computer with a single GPU and has the potential to be integrated into the clinical workflow of PCI procedures, providing cardiologists with visual guidance during interventions without the need of extra use of contrast agent.",health
10.1016/j.cortex.2019.11.021,Journal,Cortex,scopus,2020-04-01,sciencedirect,Response patterns in the developing social brain are organized by social and emotion features and disrupted in children diagnosed with autism spectrum disorder,https://api.elsevier.com/content/abstract/scopus_id/85077919917,"Adults and children recruit a specific network of brain regions when engaged in “Theory of Mind” (ToM) reasoning. Recently, fMRI studies of adults have used multivariate analyses to provide a deeper characterization of responses in these regions. These analyses characterize representational distinctions within the social domain, rather than comparing responses across preferred (social) and non-preferred stimuli. Here, we conducted opportunistic multivariate analyses in two previously collected datasets (Experiment 1: n = 20 5–11 year old children and n = 37 adults; Experiment 2: n = 76 neurotypical and n = 29 5–12 year old children diagnosed with Autism Spectrum Disorder (ASD)) in order to characterize the structure of representations in the developing social brain, and in order to discover if this structure is disrupted in ASD. Children listened to stories that described characters' mental states (Mental), non-mentalistic social information (Social), and causal events in the environment (Physical), while undergoing fMRI. We measured the extent to which neural responses in ToM brain regions were organized according to two ToM-relevant models: 1) a condition model, which reflected the experimenter-generated condition labels, and 2) a data-driven emotion model, which organized stimuli according to their emotion content. We additionally constructed two control models based on linguistic and narrative features of the stories. In both experiments, the two ToM-relevant models outperformed the control models. The fit of the condition model increased with age in neurotypical children. Moreover, the fit of the condition model to neural response patterns was reduced in the RTPJ in children diagnosed with ASD. These results provide a first glimpse into the conceptual structure of information in ToM brain regions in childhood, and suggest that there are real, stable features that predict responses in these regions in children. Multivariate analyses are a promising approach for sensitively measuring conceptual and neural developmental change and individual differences in ToM.",health
10.1016/j.bspc.2019.101839,Journal,Biomedical Signal Processing and Control,scopus,2020-04-01,sciencedirect,A novel automated system of discriminating Microaneurysms in fundus images,https://api.elsevier.com/content/abstract/scopus_id/85077512201,"Diabetic retinopathy, a chronic disease in diabetic patients leads to Vision loss, by disabling microvascular complications, if not recognized and cured at the earlier stage. This article explores a novel and reliable method for automatic early detection of Microaneurysms (MA) in fundus images. Microaneurysms characterized by small red spots on the retina, the red lesions are symptoms of early stage of DR. Development of an automated screening system would assist an ophthalmologist in diagnosing DR at an early stage. Hence, in this paper, a novel feature extraction technique using a Local Neighborhood Differential Coherence Pattern (LNDCP) is proposed. In this method, texture characteristics needed for classification by Feed Forward Neural Network (FFNN) is captured efficiently. The performance of the algorithm is validated using experiments on Retinopathy Online Challenge (ROC) public dataset and a single real-time dataset, AGAR300. Efficiency of the algorithm is benchmarked with state-of-art approaches and a Free-response Receiver Operating Characteristic (FROC) score of 0.481 and 0.442 have been achieved for ROC and AGAR300 respectively.",health
10.1016/j.cmpb.2019.105088,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,An efficient architecture for medical high-resolution images transmission in mobile telemedicine systems,https://api.elsevier.com/content/abstract/scopus_id/85076233598,"Background and Objective
                  The medical high-resolution image is very important in image processing and computer vision applications, which plays a critical role in image-guided diagnosis, clinical trials, consultation, and case discussion. How to efficiently access medical high-resolution images in mobile telemedicine systems is becoming a big challenge. Therefore, this work proposes an efficient pyramid architecture for optimizing medical high-resolution images transmission and rendering.
               
                  Methods
                  The proposed architecture consists of three core schemes: (1) unbalance pyramid scheme based on geometric relationship, (2) indexing scheme based on hash table and lattice partitioning and (3) query scheme based on similar matching. Then, we design the responsive service components: generating service, indexing service, and query service. Finally, these services are combined into a prototype system that enables efficient transmission and rendering of medical high-resolution images.
               
                  Results
                  The result shows that the unbalance pyramid scheme can quickly generate the pyramid structure and the corresponding image files. The indexing scheme can create the index structure and the index file in real-time. The query scheme can not only match the best layer to which the image block belongs in real-time, but also can accurately capture the query image block.
               
                  Conclusions
                  The prototype system based on proposed architecture is fully compliant with the DICOM standard, which can be seamlessly integrated with other existing medical systems or mobile applications, and used in various scenarios such as diagnosis, research, and education.",health
10.1016/j.cmpb.2019.105254,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic digital ECG signal extraction and normal QRS recognition from real scene ECG images,https://api.elsevier.com/content/abstract/scopus_id/85076186466,"Background and objective
                  Electrocardiogram (ECG) is one of the most important tools for assessing cardiac function and detecting potential heart problems. However, most of the current ECG report records remain on the paper, which makes it difficult to preserve and analyze the data. Moreover, paper records could result in the loss significant data, which brings inconvenience to the subsequent clinical diagnosis or artificial intelligence-assisted heart health diagnosis. Taking digital pictures is an intuitive way of preserving these files and can be done simply using smartphones or any other devices with cameras. However, these real scene ECG images often have some image noise that hinders signal extraction. How to eliminate image noise and extract ECG binary image automatically from the noisy and low-quality real scene images of ECG reports is the first problem to be solved in this paper. Next, QRS recognition is implemented on the extracted binary images to determine key points of ECG signals. 1D digital ECG signal is also extracted for accessing the exact values of the extracted points. In light of these tasks, an automatic digital ECG signal extraction and normal QRS recognition from real scene ECG images is proposed in this paper.
               
                  Methods
                  The normal QRS recognition approach for real scene ECG images in this paper consists of two steps: ECG binary image extraction from ECG images using a new two-layer hierarchical method, and the subsequent QRS recognition based on a novel feature-fusing method. ECG binary image extraction is implemented using sub-channel filters followed by an adaptive filtering algorithm. According to the ratio between pixel and real value of ECG binary image, 1D digital ECG signal is obtained. The normal QRS recognition includes three main steps: establishment of candidate point sets, feature fusion extraction, and QRS recognition. Two datasets are introduced for evaluation including a real scene ECG images dataset and the public Non-Invasive Fetal Electrocardiogram Database (FECG).
               
                  Results
                  Through the experiment on real scene ECG image, the F1 score for Q, R, S detection is 0.841, 0.992, and 0.891, respectively. The evaluation on the public FECG dataset also proves the robustness of our algorithm, where F1 score for R is 0.992 (0.996 for thoracic lead) and 0.988 for thoracic S wave.
               
                  Conclusions
                  The proposed method in this article is a promising tool for automatically extracting digital ECG signals and detecting QRS complex in real scene ECG images with normal QRS.",health
10.1016/j.cma.2019.112732,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-04-01,sciencedirect,Surrogate modeling for fluid flows based on physics-constrained deep learning without simulation data,https://api.elsevier.com/content/abstract/scopus_id/85075943774,"Numerical simulations on fluid dynamics problems primarily rely on spatially or/and temporally discretization of the governing equation using polynomials into a finite-dimensional algebraic system. Due to the multi-scale nature of the physics and sensitivity from meshing a complicated geometry, such process can be computational prohibitive for most real-time applications (e.g., clinical diagnosis and surgery planning) and many-query analyses (e.g., optimization design and uncertainty quantification). Therefore, developing a cost-effective surrogate model is of great practical significance. Deep learning (DL) has shown new promises for surrogate modeling due to its capability of handling strong nonlinearity and high dimensionality. However, the off-the-shelf DL architectures, success of which heavily relies on the large amount of training data and interpolatory nature of the problem, fail to operate when the data becomes sparse. Unfortunately, data is often insufficient in most parametric fluid dynamics problems since each data point in the parameter space requires an expensive numerical simulation based on the first principle, e.g., Navier–Stokes equations. In this paper, we provide a physics-constrained DL approach for surrogate modeling of fluid flows without relying on any simulation data. Specifically, a structured deep neural network (DNN) architecture is devised to enforce the initial and boundary conditions, and the governing partial differential equations (i.e., Navier–Stokes equations) are incorporated into the loss of the DNN to drive the training. Numerical experiments are conducted on a number of internal flows relevant to hemodynamics applications, and the forward propagation of uncertainties in fluid properties and domain geometry is studied as well. The results show excellent agreement on the flow field and forward-propagated uncertainties between the DL surrogate approximations and the first-principle numerical simulations.",health
10.1016/j.cmpb.2019.105019,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic diagnosis of fungal keratitis using data augmentation and image fusion with deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85070552720,"Background and objectives
                  Fungal keratitis is caused by inflammation of the cornea that results from infection by fungal organisms. The lack of an early effective diagnosis often results in serious complications even blindness. Confocal microscopy is one of the most effective methods in the diagnosis of fungal keratitis, but the diagnosis depends on the subjective judgment of medical experts.
               
                  Methods
                  To address this problem, this paper proposes a novel convolutional neural network framework for the automatic diagnosis of fungal keratitis using data augmentation and image fusion. Firstly, a normal image is augmented by flipping to solve the problem of having a limited and imbalanced database. Secondly, a sub-area contrast stretching algorithm is proposed for image preprocessing to highlight the key structures in the images and to filter out irrelevant information. Thirdly, the histogram matching fusion algorithm is implemented, then the preprocessed image is fused with the original image to form a new algorithm framework and a new database. Finally, the traditional convolutional neural network is integrated into the novel algorithm framework to perform the experiments.
               
                  Results
                  Experiments show that the accuracy of traditional AlexNet and VGGNet is 99.35% and 99.14%, that of AlexNet and VGGNet based on MF fusion is 99.80% and 99.83%, and that of AlexNet and VGGNet based on histogram matching fusion (HMF) is 99.95% and 99.89%. The experimental results show that the AlexNet framework using data augmentation and image fusion achieves a perfect trade-off between the diagnostic performance and the computational complexity, with a diagnostic accuracy of 99.95%.
               
                  Conclusions
                  These experimental results demonstrate the novel convolutional neural network framework perfectly balances the diagnostic performance and computational complexity, and can improve the effect and real-time performance in the diagnosis of fungal keratitis.",health
10.1016/j.jbiomech.2019.109513,Journal,Journal of Biomechanics,scopus,2020-03-26,sciencedirect,Real-time feedback to reduce low-back load in lifting and lowering,https://api.elsevier.com/content/abstract/scopus_id/85075972424,"Low-back pain (LBP) is a common health problem. Literature indicates an exposure-response relation between work-related lifting and LBP. Therefore, this study investigated effects of three kinds of real-time feedback on low-back load, quantified as lumbar moments, during lifting. We recruited 97 healthy male and female participants without a recent history of LBP and without prior biomechanical knowledge on lifting. Participants were assigned to groups based on the time of enrollment, filling the four groups in the following order: moment feedback, trunk inclination angle feedback, lumbar flexion feedback, and a control group not receiving feedback. Feedback was given by a sound when a threshold level of the input variable was exceeded. Participants were unaware of the input variable for the feedback, but were instructed to try to avoid the audio feedback by changing their lifting strategy. The groups with feedback were able to reduce the audio feedback and thus changed the input variable towards a more desired level. Lumbar moments significantly decreased over trials in the inclination and moment feedback groups, remained similar in the lumbar flexion group and increased in the control group. Between group comparisons revealed that low-back load was significantly lower in the moment and inclination groups compared to the control group. Additionally, moments were lower in the inclination group than in the lumbar flexion group. Real-time feedback on moments or trunk inclination is a promising tool to reduce low-back load during lifting and lowering.",health
10.1016/j.watres.2019.115435,Journal,Water Research,scopus,2020-03-15,sciencedirect,"Microbial source tracking (MST) in Chattahoochee River National Recreation Area: Seasonal and precipitation trends in MST marker concentrations, and associations with E. coli levels, pathogenic marker presence, and land use",https://api.elsevier.com/content/abstract/scopus_id/85077660807,"Escherichia coli levels in recreational waters are often used to predict when fecal-associated pathogen levels are a human health risk. The reach of the Chattahoochee River that flows through the Chattahoochee River National Recreation Area (CRNRA), located in the Atlanta-metropolitan area, is a popular recreation area that frequently exceeds the U.S. Environmental Protection Agency beach action value (BAV) for E. coli. A BacteriALERT program has been implemented to provide real-time E. coli estimates in the reach and notify the public of potentially harmful levels of fecal-associated pathogens as indicated by surrogate models based on real-time turbidity measurements from continuous water quality monitoring stations. However, E. coli does not provide information about the sources of fecal contamination and its accuracy as a human health indicator is questionable when sources of contamination are non-human. The objectives of our study were to investigate, within the Park and surrounding watersheds, seasonal and precipitation-related patterns in microbial source tracking marker concentrations of possible sources (human, dog, and ruminant), assess correlations between source contamination levels and culturable E. coli levels, determine which sources best explained model-based E. coli estimates above the BAV and detection of esp2 (a marker for the esp gene associated with pathogenic strains of Enterococcus faecium and Enterococcus faecalis), and investigate associations between source contamination levels and land use features. Three BacteriALERT sites on the Chattahoochee River were sampled six times per season in the winter and summer from December 2015 through September 2017, and 11 additional stream sites (synoptic sites) from the CRNRA watershed were sampled once per season. Samples were screened with microbial source tracking (MST) quantitative PCR (qPCR) markers for humans (HF183 Taqman), dogs (DogBact), and ruminants (Rum2Bac), the esp2 qPCR marker, and culturable E. coli. At the BacteriALERT sites, HF183 Taqman concentrations were higher under wet conditions DogBact concentrations were greater in the winter and under wet conditions, and Rum2Bac concentrations were comparatively low throughout the study with no difference across seasons or precipitation conditions. Concentrations of HF183 Taqman, DogBact, and Rum2Bac were positively correlated with culturable E. coli concentrations; however, DogBact had the largest R2 value among the three markers, and the forward stepwise regression indicated it was the best predictor of culturable E. coli concentrations at the BacteriALERT sites. Recursive partitioning indicated that BAV exceedances of model-based E. coli estimates were best explained by DogBact concentrations ≥3 gene copies per mL (CN/mL). Detections of esp2 at BacteriALERT sites were best explained by DogBact concentrations ≥11 CN/mL, while detections of esp2 at synoptic sites were best explained by HF183 Taqman ≥29 CN/mL. At the synoptic sites, HF183 Taqman levels were associated with wastewater treatment plant density. However, this relationship was driven primarily by a single site, suggesting possible conveyance issues in that catchment. esp2 detections at synoptic sites were positively associated with development within a 2-km radius and negatively associated with development within the catchment, suggesting multiple sources of esp2 in the watershed. DogBact and Rum2Bac were not associated with the land use features included in our analyses. Implications for Park management include: 1) fecal contamination levels were highest during wet conditions and in the off season when fewer visitors are expected to be participating in water-based recreation, 2) dogs are likely contributors to fecal contamination in the CRNRA and may be sources of pathogenic bacteria indicating further investigation of the origins of this contamination may be warranted as would be research to understand the human health risks from exposure to dog fecal contamination, and 3) high levels of the human marker at one site in the CRNRA watershed suggests more extensive monitoring in that catchment may locate the origin of human fecal contamination detected during this study.",health
10.1016/j.saa.2019.117731,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2020-03-05,sciencedirect,A signal-on fluorescence based biosensing platform for highly sensitive detection of DNA methyltransferase enzyme activity and inhibition,https://api.elsevier.com/content/abstract/scopus_id/85075380206,"DNA methylation mediated by DNA methyltransferase (MTase) enzyme is internal cell mechanism which regulate the expression or suppression of crucial genes involve in cancer early diagnosis. Herein, highly sensitive fluorescence biosensing platform was developed for monitoring of DNA Dam MTase enzyme activity and inhibition based on fluorescence signal on mechanism. The specific Au NP functionalized oligonucleotide probe with overhang end as a template for the synthesis of fluorescent silver nanoclusters (Ag NCs) was designed to provide the FRET occurrence. Following, methylation and cleavage processes by Dam MTAse and DpnI enzymes respectively at specific probe recognition site could resulted to release of AgNCs synthesizer DNA fragment and returned the platform to fluorescence signal-on state through interrupting in FRET. Subsequently, amplified fluorescence emission signals of Ag NCs showed increasing linear relationship with amount of Dam MTase enzyme at the range of 0.1–20 U/mL and the detection limit was estimated at 0.05 U/mL. Superior selectivity of experiment was illustrated among other tested MTase and restriction enzymes due to the specific recognition of MTase toward its substrate. Furthermore, the inhibition effect of applied Dam MTase drug inhibitors screened and evaluated with satisfactory results which would be helpful for discovery of antimicrobial drugs. The real sample assay also showed the applicability of proposed method in human serum condition. This novel strategy presented an efficient and cost effective platform for sensitive monitoring of DNA MTase activity and inhibition which illustrated its great potential for further application in medical diagnosis and drug discovery.",health
10.1016/j.artmed.2020.101817,Journal,Artificial Intelligence in Medicine,scopus,2020-03-01,sciencedirect,Real-world data medical knowledge graph: construction and applications,https://api.elsevier.com/content/abstract/scopus_id/85079325883,"Objective
                  Medical knowledge graph (KG) is attracting attention from both academic and healthcare industry due to its power in intelligent healthcare applications. In this paper, we introduce a systematic approach to build medical KG from electronic medical records (EMRs) with evaluation by both technical experiments and end to end application examples.
               
                  Materials and Methods
                  The original data set contains 16,217,270 de-identified clinical visit data of 3,767,198 patients. The KG construction procedure includes 8 steps, which are data preparation, entity recognition, entity normalization, relation extraction, property calculation, graph cleaning, related-entity ranking, and graph embedding respectively. We propose a novel quadruplet structure to represent medical knowledge instead of the classical triplet in KG. A novel related-entity ranking function considering probability, specificity and reliability (PSR) is proposed. Besides, probabilistic translation on hyperplanes (PrTransH) algorithm is used to learn graph embedding for the generated KG.
               
                  Results
                  A medical KG with 9 entity types including disease, symptom, etc. was established, which contains 22,508 entities and 579,094 quadruplets. Compared with term frequency - inverse document frequency (TF/IDF) method, the normalized discounted cumulative gain (NDCG@10) increased from 0.799 to 0.906 with the proposed ranking function. The embedding representation for all entities and relations were learned, which are proven to be effective using disease clustering.
               
                  Conclusion
                  The established systematic procedure can efficiently construct a high-quality medical KG from large-scale EMRs. The proposed ranking function PSR achieves the best performance under all relations, and the disease clustering result validates the efficacy of the learned embedding vector as entity’s semantic representation. Moreover, the obtained KG finds many successful applications due to its statistics-based quadruplet.
                  where 
                        
                           N
                           
                              c
                              o
                           
                           
                              m
                              i
                              n
                           
                        
                      is a minimum co-occurrence number and R is the basic reliability value. The reliability value can measure how reliable is the relationship between Si
                      and Oij
                     . The reason for the definition is the higher value of N
                     co(Si, Oij
                     ), the relationship is more reliable. However, the reliability values of the two relationships should not have a big difference if both of their co-occurrence numbers are very big. In our study, we finally set 
                        
                           N
                           
                              c
                              o
                           
                           
                              m
                              i
                              n
                           
                        
                      = 10 and R = 1 after some experiments. For instance, if co-occurrence numbers of three relationships are 1, 100 and 10000, their reliability values are 1, 2.96 and 5 respectively.",health
10.1016/j.fsi.2020.01.049,Journal,Fish and Shellfish Immunology,scopus,2020-03-01,sciencedirect,Edwardsiella tarda induces enteritis in farmed seahorses (Hippocampus erectus): An experimental model and its evaluation,https://api.elsevier.com/content/abstract/scopus_id/85078315863,"Bacterial enteritis is an important deadly threat to farmed seahorses. However, its pathogenesis is obscure because of the paucity of reproducible experimental intestinal inflammation models. Herein, a strain of Edwardsiella tarda YT1 from farmed seahorse Hippocampus erectus was isolated and identified by morphological, phylogenetic, and biochemical analysis, and confirmed as a pathogen of enteritis for the first time by challenge experiment. Two E. tarda concentrations (1 × 105 and 1 × 107 colony forming units [cfu] ml−1) were confirmed suitable for an enteritis model by intraperitoneal injection. To develop and evaluate the experimental model, we challenged seahorses with E. tarda and found that (1) the infection inhibited body length increase, significantly decreased body weight (P < 0.05), and induced typical pathological features including anorexia, anal inflammation, and intestinal fluid retention; (2) 19 external (weight, height, anal inflammation, feeding status, and intestinal fluid retention), histological (goblet and inflammatory cell numbers and thickening of lamina propria and muscularis mucosae), and molecular (hepcidin, liver-expressed antimicrobial peptide, lysozyme, piscidin, interleukin [IL]-1β, IL-1β receptor, IL-2, IL-10, interferon1, tumor necrosis factor [TNF]-α, and toll-like receptor 5 [TLR5]) indicators were suitable for model evaluation, as they could sensitively respond and varied similarly throughout the experiment, indicating the high sensitivity of seahorses against pathogen invasion; (3) TLR5 may play an essential role in triggering host immune responses during E. tarda-induced chronic enteritis, and (4) the evaluating system could reflect the pattern and intensity of disease progression. Thus, we developed an experimental model and an evaluating system of bacterial enteritis in farmed seahorses, helping us to reveal the pathogenesis of bacterial enteritis, identify potential therapeutic drugs, and search suitable genetic markers for seahorse molecular breeding.",health
10.1016/j.iot.2019.100130,Journal,Internet of Things (Netherlands),scopus,2020-03-01,sciencedirect,An IoT based device-type invariant fall detection system,https://api.elsevier.com/content/abstract/scopus_id/85077314197,"As the world elderly population is increasing rapidly, the use of technology for the development of accurate and fast automatic fall detection systems has become a necessity. Most of the fall detection systems are developed for specific devices which reduces the versatility of the fall detection system. This paper proposes a centralized unobtrusive IoT based device-type invariant fall detection and rescue system for monitoring of a large population in real-time. Any type of devices such as Smartphones, Raspberry Pi, Arduino, NodeMcu, and Custom Embedded Systems can be used to monitor a large population in the proposed system. The devices are placed into the users’ left or right pant pocket. The accelerometer data from the devices are continuously sent to a multithreaded server which hosts a pre-trained machine learning model that analyzes the data to determine whether a fall has occurred or not. The server sends the classification results back to the corresponding devices. If a fall is detected, the server notifies the mediator of the user's location via an SMS. As a failsafe, the corresponding device alerts nearby individuals by sounding the buzzer and contacts emergency medical services and mediators via SMS for immediate medical assistance, thus saving the user's life. The proposed system achieved 99.7% accuracy, 96.3% sensitivity, and 99.6% specificity. Finally, the proposed system can be implemented on a variety of devices and used to reliably monitor a large population with low false alarm rate, without obstructing the users’ daily living, as no external connections are required.",health
10.1016/j.jmir.2019.11.001,Journal,Journal of Medical Imaging and Radiation Sciences,scopus,2020-03-01,sciencedirect,Machine Learning Methods for Computer-Aided Breast Cancer Diagnosis Using Histopathology: A Narrative Review,https://api.elsevier.com/content/abstract/scopus_id/85077158769,"Histopathology is a method used for breast cancer diagnosis. Machine learning (ML) methods have achieved success for supervised learning tasks in the medical domain. In this article, we investigate the impact of ML for the diagnosis of breast cancer using histopathology images of conventional photomicroscopy. Cancer diagnosis is the identification of images as cancer or noncancer, and this involves image preprocessing, feature extraction, classification, and performance analysis. In this article, different approaches to perform these necessary steps are reviewed. We find that most ML research for breast cancer diagnosis has been focused on deep learning. Based on inferences from the recent research activities, we discuss how ML methods can benefit conventional microscopy-based breast cancer diagnosis. Finally, we discuss the research gaps of ML approaches for the implementation in a real pathology environment and propose future research guidelines.",health
10.1016/j.micpro.2019.102960,Journal,Microprocessors and Microsystems,scopus,2020-03-01,sciencedirect,A novel hybrid optimized and adaptive reconfigurable framework for the implementation of hybrid bio-inspired classifiers for diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85077060597,"Due to recent advances in IoT (Internet of Things) technologies, availability of reliable data and emergence of machine learning, bio-inspired learning and artificial intelligence, has demonstrated its ability to solve the large complex problems which is not possible before. In particular, machine learning and bio-inspired learning algorithms provides the effective solutions in image processing techniques. However, the implementation of the above-mentioned algorithms in the general CPU requires the intensive usage of bandwidth, area and power which makes the CPU unhealthy of usage and implementation. To overcome this problem, ASIC (application specific integrated circuits), GPU (Graphics Processing Unit) &FPGA (Field Programmable gate arrays) have been employed to improve the performance of the hybrid machine learning (ML) classifiers and deep learning algorithms. FPGA has been recently employed for an effective implementation and to achieve the high performance of the learning algorithms. But integrating the complex learning algorithms in FPGA still remains to be real challenge among the researchers. The paper proposes new reconfigurable architectures for bio- inspired classifiers to diagnosis the medical casualties which can be suitable for the tele health care applications. This paper aim is as follows (i) Design and implementation of Parallel Fusion of FSM and Reconfigurable shared Distributed Arithmetic for Bio-Inspired Classifiers (ii) Development of Accelerator Environment to test the performance of proposed architecture (iii) Performance evaluation of proposed architecture in terms of accuracy of detection in compared with MATLAB simulation iv) Implementation of proposed architectures in different ARtix-7 architectures and determination of power, throughput and area . Moreover, the proposed architecture has been tested with the and compared with the other existing architectures.",health
10.1016/j.neunet.2019.12.001,Journal,Neural Networks,scopus,2020-03-01,sciencedirect,Minimum variance-embedded deep kernel regularized least squares method for one-class classification and its applications to biomedical data,https://api.elsevier.com/content/abstract/scopus_id/85076900773,"Deep kernel learning has been well explored for multi-class classification tasks; however, relatively less work is done for one-class classification (OCC). OCC needs samples from only one class to train the model. Most recently, kernel regularized least squares (KRL) method-based deep architecture is developed for the OCC task. This paper introduces a novel extension of this method by embedding minimum variance information within this architecture. This embedding improves the generalization capability of the classifier by reducing the intra-class variance. In contrast to traditional deep learning methods, this method can effectively work with small-size datasets. We conduct a comprehensive set of experiments on 18 benchmark datasets (13 biomedical and 5 other datasets) to demonstrate the performance of the proposed classifier. We compare the results with 16 state-of-the-art one-class classifiers. Further, we also test our method for 2 real-world biomedical datasets viz.; detection of Alzheimer’s disease from structural magnetic resonance imaging data and detection of breast cancer from histopathological images. Proposed method exhibits more than 5% 
                        
                           
                              F
                           
                           
                              1
                           
                        
                      score compared to existing state-of-the-art methods for various biomedical benchmark datasets. This makes it viable for application in biomedical fields where relatively less amount of data is available.",health
10.1016/j.nucmedbio.2019.12.006,Journal,Nuclear Medicine and Biology,scopus,2020-03-01,sciencedirect,Preclinical investigation of potential use of thymidine phosphorylase-targeting tracer for diagnosis of nonalcoholic steatohepatitis,https://api.elsevier.com/content/abstract/scopus_id/85076634500,"Introduction
                  Although liver biopsy is the gold standard for the diagnosis of nonalcoholic steatohepatitis (NASH), it has several problems including high invasiveness and sampling errors. Therefore, the development of alternative methods to overcome these disadvantages is strongly required. In this study, we evaluated the potential use of our tracer targeting thymidine phosphorylase (TYMP), 5-[123I]iodo-6-[(2-iminoimidazolidinyl)methyl]uracil ([123I]IIMU) for the diagnosis of NASH.
               
                  Methods
                  The mice used as the NASH model (hereafter, NASH mice) were prepared by feeding a methionine- and choline-deficient diet for 4 weeks. A control group was similarly given a control diet. The expression levels of the TYMP gene and protein in the liver were examined by real-time reverse-transcription polymerase chain reaction and western blot analyses. The localizations of [125I]IIMU and the TYMP protein in the liver were examined by autoradiography and immunohistochemical staining, respectively. Finally, the mice were injected with [123I]IIMU and single-photon emission tomography (SPECT) imaging was conducted.
               
                  Results
                  The hepatic expression levels of TYMP were significantly lower in the NASH mice than in the control mice at both mRNA and protein levels, suggesting that a decrease in TYMP level could be an indicator of NASH. [125I]IIMU was uniformly distributed in the liver of the control mice, whereas it showed a patchy distribution in that of the NASH mice. The localization of [125I]IIMU was visually consistent with that of the TYMP protein in the liver of the control and NASH mice. SPECT analysis indicated that the hepatic accumulation of [123I]IIMU in the NASH mice was significantly lower than that in the control mice [SUV (g/ml): 4.14 ± 0.87 (Control) vs 2.31 ± 0.29 (NASH)].
               
                  Conclusions
                  [123I]IIMU may provide a noninvasive means for imaging TYMP expression in the liver and may be applicable to the diagnosis of NASH.",health
10.1016/j.engappai.2019.103427,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-03-01,sciencedirect,Stochastic parallel extreme artificial hydrocarbon networks: An implementation for fast and robust supervised machine learning in high-dimensional data,https://api.elsevier.com/content/abstract/scopus_id/85076620125,"Artificial hydrocarbon networks (AHN) – a supervised learning method inspired on organic chemical structures and mechanisms – have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than 
                        
                           10
                           ,
                           000
                           x
                        
                      times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential.",health
10.1016/j.bspc.2019.101787,Journal,Biomedical Signal Processing and Control,scopus,2020-03-01,sciencedirect,An efficient error-minimized random vector functional link network for epileptic seizure classification using VMD,https://api.elsevier.com/content/abstract/scopus_id/85076002241,"In this paper, variational mode decomposition (VMD), Hilbert transform (HT), and proposed error-minimized random vector functional link network (EMRVFLN) are integrated to detect and classify epileptic seizure from electroencephalogram (EEG) signals. VMD is applied to decompose the EEG signal into Band-limited intrinsic mode functions (BLIMFs). The five efficacious instantaneous features are computed using HT to construct the feature vector. Proposed EMRVFLN classifier is used to classify the epileptic seizure. The performances of the proposed EMRVFLN are compared with recently developed classifiers such as least-square support vector machine (LSSVM) and extreme learning machine (ELM). The combination of VMD and HT with proposed EMRVFLN classifier outperforms other state-of-the-art methods with classification accuracy of 100% for two class classification problem and 99.74% for three class classification problem. The remarkable classification accuracy facilitates the digital implementation of the proposed EMRVFLN classifier which may aid to design an embedded system for real-time disease diagnosis.",health
10.1016/j.fsi.2019.11.047,Journal,Fish and Shellfish Immunology,scopus,2020-03-01,sciencedirect,Susceptibility and immune responses after challenge with Flavobacterium columnare and Pseudomonas fluorescens in conventional and specific pathogen-free rare minnow (Gobiocypris rarus),https://api.elsevier.com/content/abstract/scopus_id/85075871887,"The susceptibility of fish from different culture environments to bacterial infection is not well known. The susceptibility and pathological changes of conventional (CV) and specific pathogen-free (SPF) rare minnow (Gobiocypris rarus) infected with two gram-negative bacteria, Flavobacterium columnare and Pseudomonas fluorescens are investigated. Rare minnows were intraperitoneally challenged with two bacterial species to first determine semi-lethal doses (LD50), and then with the LD50 dose, determine innate immune response. Infected rare minnows developed characteristic red bellies and then died. LD50 doses of F. columnare and P. fluorescens were 4.586 × 108 cfu/mL and 2.319 × 1010 cfu/mL for CV rare minnow, and 2.575 × 108 cfu/mL and 1.935 × 1010 cfu/mL, respectively, for SPF rare minnow. The results of RT-PCR showed that the highest levels of toll-like receptor 3 (TLR3), interleukin-6 (IL-6), interferon-2 (IFN-2) and rare minnow Z-DNA binding protein kinase (GrPKZ) mRNA were noticed at 6–48 h post-infection (hpi). In addition, TLR3, IL-6 and IFN-2 in F. columnare challenged rare minnow were more highly expressed than those in P. fluorescens challenged rare minnow, whereas as opposed in the expression of GrPKZ mRNA. Stimulation of innate immune responses is closely related to bacterial virulence. SPF rare minnow might be more susceptible to these bacteria than CV rare minnow, possibly due to their clean environment and lack of resistance. We speculate that clean environment renders rare minnow more susceptible to bacterial infections.",health
10.1016/j.future.2019.10.043,Journal,Future Generation Computer Systems,scopus,2020-03-01,sciencedirect,HealthFog: An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments,https://api.elsevier.com/content/abstract/scopus_id/85074613864,"Cloud computing provides resources over the Internet and allows a plethora of applications to be deployed to provide services for different industries. The major bottleneck being faced currently in these cloud frameworks is their limited scalability and hence inability to cater to the requirements of centralized Internet of Things (IoT) based compute environments. The main reason for this is that latency-sensitive applications like health monitoring and surveillance systems now require computation over large amounts of data (Big Data) transferred to centralized database and from database to cloud data centers which leads to drop in performance of such systems. The new paradigms of fog and edge computing provide innovative solutions by bringing resources closer to the user and provide low latency and energy efficient solutions for data processing compared to cloud domains. Still, the current fog models have many limitations and focus from a limited perspective on either accuracy of results or reduced response time but not both. We proposed a novel framework called HealthFog for integrating ensemble deep learning in Edge computing devices and deployed it for a real-life application of automatic Heart Disease analysis. HealthFog delivers healthcare as a fog service using IoT devices and efficiently manages the data of heart patients, which comes as user requests. Fog-enabled cloud framework, FogBus is used to deploy and test the performance of the proposed model in terms of power consumption, network bandwidth, latency, jitter, accuracy and execution time. HealthFog is configurable to various operation modes which provide the best Quality of Service or prediction accuracy, as required, in diverse fog computation scenarios and for different user requirements.",health
10.1016/j.cmpb.2019.105132,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-03-01,sciencedirect,Virtual reality-based measurement of ocular deviation in strabismus,https://api.elsevier.com/content/abstract/scopus_id/85073938186,"Background and objective
                  Strabismus is an eye movement disorder in which shows the abnormal ocular deviation. Cover tests have mainly been used in the clinical diagnosis of strabismus for treatment. However, the whole process depends on the doctor's level of experience, which could be subjected to several factors. In this study, an automated technique for measurement of ocular deviation using a virtual reality (VR) device is developed.
               
                  Methods
                  A VR display system in which the screens that have the fixation target are changed alternately between on and off stages is used to simulate the normal strabismus diagnosis steps. Patients watch special-designed 3D scenes, and their eye motions are recorded by two infrared (IR) cameras. An image-processing-based pupil tracking technique is then applied to track their eye movement. After recording eye motion, two strategies for strabismus angle estimation are implemented: direct measurement and stepwise approximation. The direct measurement converts the eye movement to a strabismus angle after considering the eyeball diameter, while the stepwise approximation measures the ocular deviation through the feedback calibration process.
               
                  Results
                  Experiments are carried out with various strabismus patients. The results are compared to those of their doctors’ measurement, which shows good agreement.
               
                  Conclusions
                  The results clearly indicate that these techniques could identify ocular deviation with high accuracy and efficiency. The proposed system can be applied in small space and has high tolerance for the unexpected head movements compared with other camera-based system.",health
10.1016/j.neulet.2020.134775,Journal,Neuroscience Letters,scopus,2020-02-16,sciencedirect,The functional implications and modifiability of resting-state brain network complexity in older adults,https://api.elsevier.com/content/abstract/scopus_id/85078510212,"The dynamics of the resting-state activity in brain functional networks are complex, containing meaningful patterns over multiple temporal scales. Such physiologic complexity is often diminished in older adults. Here we aim to examine if the resting-state complexity within functional brain networks is sensitive to functional status in older adults and if repeated exposure to transcranial direct current stimulation (tDCS) would modulate such complexity. Twelve older adults with slow gait and mild-to-moderate executive dysfunction and 12 age- and sex-matched controls completed a baseline resting-state fMRI (rs-fMRI). Ten participants in the functionally-limited group then completed ten 20-minute sessions of real (n = 6) or sham (n = 4) tDCS targeting the left prefrontal cortex over a two-week period as well as a follow-up rs-fMRI. The resting-state complexity associated with seven functional networks was quantified by averaging the multiscale entropy (MSE) of the blood oxygen level-dependent (BOLD) time-series for all voxels within each network. Compared to controls, functionally-limited group exhibited lower complexity in the motor, ventral attention, limbic, executive and default mode networks (F > 6.3, p < 0.02). Within this group, those who received tDCS exhibited greater complexity within the ventral, executive and limbic networks (p < 0.04) post intervention as compared to baseline, while no significant changes in sham group was observed. This study provides preliminary evidence that older adults with functional limitations had diminished complexity of resting-state brain network activity and repeated exposure to tDCS may increase that resting-state complexity, warranting future studies to establish such complexity as a marker of brain health in older adults.",health
10.1016/j.comcom.2020.01.050,Journal,Computer Communications,scopus,2020-02-15,sciencedirect,Deep learning-based intelligent face recognition in IoT-cloud environment,https://api.elsevier.com/content/abstract/scopus_id/85078483384,"In recent years, the Internet-of-Things (IoT) technology is being used in many application areas such as healthcare, video surveillance, transportation etc. The massive adoption and growth of IoT in these areas are generating a massive amount of data. For example, IoT devices such as cameras are generating a huge amount of images when used in hospital surveillance scenarios. Here, face recognition is an important element that can be used for securing hospital facilities, emotion detection and sentiment analysis of patients, detecting patient fraud, and hospital traffic pattern analysis. Automatic and intelligent face recognition systems have high accuracy in a controlled environment; however, they have low accuracy in an uncontrolled environment. Also, the systems need to operate in real-time in many applications such as smart healthcare. This paper suggests a tree-based deep model for automatic face recognition in a cloud environment. The proposed deep model is computationally less expensive without compromising the accuracy. In the model, an input volume is split into several volumes, where a tree is constructed for each volume. A tree is defined by its branching factor and height. Each branch is represented by a residual function, which is constituted by a convolutional layer, a batch normalization, and a non-linear function. The proposed model is evaluated in various publicly available databases. A comparison of performance is also done with state-of-the-art deep models for face recognition. The results of the experiments demonstrate that the proposed model achieved accuracies of 98.65%, 99.19%, 95.84% on FEI, ORL, and LFW databases, respectively.",health
10.1016/j.jbi.2019.103354,Journal,Journal of Biomedical Informatics,scopus,2020-02-01,sciencedirect,"Task definition, annotated dataset, and supervised natural language processing models for symptom extraction from unstructured clinical notes",https://api.elsevier.com/content/abstract/scopus_id/85077000258,"Introduction
                  Machine learning (ML) and natural language processing have great potential to improve information extraction (IE) within electronic medical records (EMRs) for a wide variety of clinical search and summarization tools. Despite ML advancements, clinical adoption of real time IE tools for patient care remains low. Clinically motivated IE task definitions, publicly available annotated clinical datasets, and inclusion of subtasks such as coreference resolution and named entity normalization are critical for the development of useful clinical tools.
               
                  Materials and methods
                  We provide a task definition and comprehensive annotation requirements for a clinically motivated symptom extraction task. Four annotators labeled symptom mentions within 1108 discharge summaries from two public clinical note datasets for the tasks of named entity recognition, coreference resolution, and named entity normalization; these annotations will be released to the public. Baseline human performance was assessed and two ML models were evaluated on the symptom extraction task.
               
                  Results
                  16,922 symptom mentions were identified within the discharge summaries, with 11,944 symptom instances after coreference resolution and 1255 unique normalized answer forms. Human annotator performance averaged 92.2% F1. Recurrent network model performance was 85.6% F1 (recall 85.8%, precision 85.4%), and Transformer-based model performance was 86.3% F1 (recall 86.6%, precision 86.1%). Our models extracted vague symptoms, acronyms, typographical errors, and grouping statements. The models generalized effectively to a separate clinical note corpus and can run in real time.
               
                  Conclusion
                  To our knowledge, this dataset will be the largest and most comprehensive publicly released, annotated dataset for clinically motivated symptom extraction, as it includes annotations for named entity recognition, coreference, and normalization for more than 1000 clinical documents. Our neural network models extracted symptoms from unstructured clinical free text at near human performance in real time. In this paper, we present a clinically motivated task definition, dataset, and simple supervised natural language processing models to demonstrate the feasibility of building clinically applicable information extraction tools.",health
10.1016/j.measurement.2019.107377,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-02-01,sciencedirect,Machinery fault diagnosis with imbalanced data using deep generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85076676290,"Despite the recent advances of intelligent data-driven fault diagnosis methods on rotating machines, balanced training data for different machine health conditions are assumed in most studies. However, the signals in machine faulty states are usually difficult and expensive to collect, resulting in imbalanced training dataset in most cases. That significantly deteriorates the effectiveness of the existing data-driven approaches. This paper proposes a deep learning-based fault diagnosis method to address the imbalanced data problem by explicitly creating additional training data. Generative adversarial networks are firstly used to learn the mapping between the distributions of noise and real machinery temporal vibration data, and additional realistic fake samples can be generated to balance and further expand the available dataset afterwards. Through experiments on two rotating machinery datasets, it is validated that the data-driven methods can significantly benefit from the data augmentation, and the proposed method offers a promising tool on fault diagnosis with imbalanced training data.",health
10.1016/j.dsp.2019.102611,Journal,Digital Signal Processing: A Review Journal,scopus,2020-02-01,sciencedirect,Use of PALM for ℓ<inf>1</inf> sparse matrix factorization: Difficulty and rationalization of a two-step approach,https://api.elsevier.com/content/abstract/scopus_id/85076012110,"Blind Source Separation (BSS) is a key machine learning method, which has been successfully applied to analyze multichannel data in various domains ranging from medical imaging to astrophysics. Being an ill-posed matrix factorization problem, it is necessary to introduce extra regularizing priors on the sources. While using sparsity has led to improved factorization results, the quality of the separation process turns out to be dramatically dependent on the minimization strategy and the regularization parameters. In this scope, the Proximal Alternating Linearized Minimization (PALM) has recently attracted a lot of interest as a generic, fast and highly flexible algorithm. Using PALM for sparse BSS is theoretically well grounded, but getting good empirical results requires a fine tuning of the involved regularization parameters, which might be too computationally expensive with real-world large-scale data, therefore mandating automatic parameter choice strategies. In this article, we first investigate the empirical limitations of using the PALM algorithm to perform sparse BSS and we explain their origin. Based on this, we further study and justify an alternative two-step algorithmic framework combining PALM with a heuristic approach, namely the Generalized Morphological Component Analysis (GMCA). This method enables an automatic parameter choice for the PALM step. Numerical experiments with comparisons to standard algorithms are carried out on two realistic experiments in spectroscopy and astrophysics.",health
10.1016/j.simpat.2019.102023,Journal,Simulation Modelling Practice and Theory,scopus,2020-02-01,sciencedirect,A new machine learning method for identifying Alzheimer's disease,https://api.elsevier.com/content/abstract/scopus_id/85075505114,"Most of the studies on Alzheimer's disease (AD) have been carried out using medical images. However, the acquisition of medical images data is difficult. The identification based on the patient's speech data can effectively reduce the medical cost, and the speech data can be collected in a non-invasive manner so that the patient's data can be collected in real-time and accurately. This paper proposes a new method that uses the spectrogram features extracted from speech data to identify AD, which can help families to understand the disease development of patients in an earlier stage, so that they can take measures in advance to delay the disease development. We use the speech data collected from the elderly that express the speech features displayed in the speech and used the machine learning methods for identifying AD. During the simulation and experiment, we collect a new speech dataset, which includes Alzheimer's disease patients and healthy control subjects. Then, we compare with the speech data made available by the Dem@Care project. Among the tested models, LogisticgressionCV model exhibited the best performance. It is shown that this method using extracted spectrogram features from speech data to identify AD is feasible. The credibility of the new dataset and feasibility of the used methods in this paper are demonstrated.",health
10.1016/j.micpro.2019.102929,Journal,Microprocessors and Microsystems,scopus,2020-02-01,sciencedirect,A Fog-Cloud based cyber physical system for Ulcerative Colitis diagnosis and stage classification and management,https://api.elsevier.com/content/abstract/scopus_id/85075315081,"Ulcerative Colitis is a fairly common, chronic or long-term disease that causes inflammation of the large intestine. It can be debilitating and can sometimes lead to life threatening complications. Therefore, its diagnosis in nascent stages is important. Healthcare services based on Fog-Cloud assisted Cyber-Physical Systems are emerging as a proactive and efficacious solution to provide remote monitoring of individuals for early detection and consequent management of several diseases. This paper presents a novel IoT-Fog-Cloud assisted Cyber Physical System for diagnosis and stage classification of Ulcerative Colitis using Naïve Bayes classifier and Deep Neural Network respectively. A vital point of this paper is real-time alert generation from Fog Layer in case the user need emergency treatment if he/she is already diagnosed with UC. Finally, analysis results and compiled medical information of each user is stored on cloud. Implementation results of the proposed framework proves its efficiency in diagnosis and subsequent stage classification of Ulcerative Colitis with real-time classification mechanism at fog layer. Furthermore, alert generation improves the efficacy of the proposed system.",health
10.1016/j.engappai.2019.103336,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-02-01,sciencedirect,Fault location estimation for series-compensated double-circuit transmission line using EWT and weighted RVFLN,https://api.elsevier.com/content/abstract/scopus_id/85075028838,"In this paper, empirical Wavelet transform (EWT), Hilbert transform (HT) and weighted random vector functional link network (WRVFLN) are integrated for fault detection, classification, and location estimation in a series capacitor compensated double circuit transmission line (SCCDCTL). The full cycle current signals from the point of fault inception are decomposed using EWT to extract three band-limited modes (BLMs). The four efficacious instantaneous features namely energy, Shannon entropy, the standard deviation of the magnitude, and crest factor are computed from the Hilbert transformed array of the BLMs to construct the feature vector. A diagonal matrix W is computed from the zero sequence current of original six current signals as a weighting factor to categorize the ground fault accurately. Numerous faults are generated with a wide variation of the system conditions such as fault resistance, fault inception angle, fault distance, percentage compensation level, source impedance, line parameters, load angle, and inter-circuit fault in MATLAB/Simulink environments. An efficient WRVFLN computational intelligence technique is proposed to recognize and estimate the location of the faults by taking the extracted suitable feature vector with weight factor as an input. The performances of WRVFLN are compared with the recently developed advanced classifiers such as least-square support vector machine (LSSVM) and extreme learning machine (ELM) in the MATLAB interface. The lesser computational complexity, faster learning speed, superior classification accuracy, accurate fault location estimation, and short event detection time prove that the proposed EWTHT–WRVFLN method can be implemented in the real power system for online fault diagnosis. Finally, the developed system architecture is implemented on the reconfigurable digital field programmable gate array (FPGA) in ISE design suite 14.5 environments to verify the cogency of the proposed method in real-time. The feasibility of the proposed method is tested and validated by using the fast FPGA digital circuitry in a loop.",health
10.1016/j.breast.2019.10.001,Journal,Breast,scopus,2020-02-01,sciencedirect,"The ethical, legal and social implications of using artificial intelligence systems in breast cancer care",https://api.elsevier.com/content/abstract/scopus_id/85074099299,"Breast cancer care is a leading area for development of artificial intelligence (AI), with applications including screening and diagnosis, risk calculation, prognostication and clinical decision-support, management planning, and precision medicine. We review the ethical, legal and social implications of these developments. We consider the values encoded in algorithms, the need to evaluate outcomes, and issues of bias and transferability, data ownership, confidentiality and consent, and legal, moral and professional responsibility. We consider potential effects for patients, including on trust in healthcare, and provide some social science explanations for the apparent rush to implement AI solutions. We conclude by anticipating future directions for AI in breast cancer care. Stakeholders in healthcare AI should acknowledge that their enterprise is an ethical, legal and social challenge, not just a technical challenge. Taking these challenges seriously will require broad engagement, imposition of conditions on implementation, and pre-emptive systems of oversight to ensure that development does not run ahead of evaluation and deliberation. Once artificial intelligence becomes institutionalised, it may be difficult to reverse: a proactive role for government, regulators and professional groups will help ensure introduction in robust research contexts, and the development of a sound evidence base regarding real-world effectiveness. Detailed public discussion is required to consider what kind of AI is acceptable rather than simply accepting what is offered, thus optimising outcomes for health systems, professionals, society and those receiving care.",health
10.1016/j.measurement.2019.107155,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-02-01,sciencedirect,Transfer between multiple machine plants: A modified fast self-organizing feature map and two-order selective ensemble based fault diagnosis strategy,https://api.elsevier.com/content/abstract/scopus_id/85073936697,"The signal differences cause machine fault diagnosis (MFD) models developed in one plant to not be readily applicable to others. This paper presents a modified fast self-organizing feature map (FSOM) and two-order selective ensemble (SE) strategy to realize transfer learning (TL) between multiple plants, including three major processes: i) modified FSOM to map the original real-imaginary polar diagrams to a new feature space where the differences in the same fault category are reduced, ii) cross Minkowski distance matrix to calculate the similarity between channels, and to select the helpful channels in the source plant by an evaluation process, iii) two-order SE to fuse high-powered channels in the target plant to promote diagnosis. Experiments in two gearbox systems demonstrate the effectiveness of transferring from a simple/local to a complex/global device, thus being a useful tool to solve the practical problem that model in the laboratory and apply in the industrial field.",health
10.1016/j.micpro.2019.102906,Journal,Microprocessors and Microsystems,scopus,2020-02-01,sciencedirect,Area and power efficient pipelined hybrid merged adders for customized deep learning framework for FPGA implementation,https://api.elsevier.com/content/abstract/scopus_id/85073599282,"With the rapid growth of deep learning and neural network algorithms, various fields such as communication, Industrial automation, computer vision system and medical applications have seen the drastic improvements in recent years. However, deep learning and neural network models are increasing day by day, while model parameters are used for representing the models. Although the existing models use efficient GPU for accommodating these models, their implementation in the dedicated embedded devices needs more optimization which remains a real challenge for researchers. Thus paper, carries an investigation of deep learning frameworks, more particularly as review of adders implemented in the deep learning framework. A new pipelined hybrid merged adders (PHMAC) optimized for FPGA architecture which has more efficient in terms of area and power is presented. The proposed adders represent the integration of the principle of carry select and carry look ahead principle of adders in which LUT is re-used for the different inputs which consume less power and provide effective area utilization. The proposed adders were investigated on different FPGA architectures in which the power and area were analyzed. Comparison of the proposed adders with the other adders such as carry select adders (CSA), carry look ahead adder (CLA), Carry skip adders and Koggle Stone adders has been made and results have proved to be highly vital into a 50% reduction in the area, power and 45% when compared with above mentioned traditional adders.",health
10.1016/j.chemosphere.2019.124937,Journal,Chemosphere,scopus,2020-02-01,sciencedirect,Zebrafish behavioral phenomics employed for characterizing behavioral neurotoxicity caused by silica nanoparticles,https://api.elsevier.com/content/abstract/scopus_id/85072682384,"Nowadays, silica nanoparticles (SiNPs) as one of the most productive nano-powder, has been extensively applied in various filed. The potential harm of SiNPs has previously received severe attention. A bulk of researches have proven the adverse effect of SiNPs on the health of ecological organisms and human. However, neurotoxic impacts of SiNPs, still remain in the stage of exploration. The potential neurotoxic effects of SiNPs need to be further explored. And the toxic mechanism needs comprehensive clarification. Herein, the neurotoxicity of SiNPs of various concentrations (100, 300, 1000 μg/mL) on adult zebrafish was determined by behavioral phenotyping and confirmed by molecular biology techniques such as qPCR. Behavioral phenotype revealed observable effects of SiNPs on disturbing light/dark preference, dampening exploratory behavior, inhibiting memory capability. Furthermore, the relationship between neurotoxic symptom and the transcriptional alteration of autophagy- and parkinsonism-related genes was preliminarily assessed. Importantly, further investigations should be carried out to determine the effects of SiNPs to cause neurodegeneration in the brain as well as to decipher the specific neurotoxic mechanisms. In sum, this work comprehensively evaluated the neurotoxic effect of small-sized SiNPs on overall neurobehavioral profiles and indicated the potential for SiNPs to cause Parkinson’s disease, which will provide a solid reference for the research on the neurotoxicity of SiNPs.",health
10.1016/j.inffus.2019.06.005,Journal,Information Fusion,scopus,2020-02-01,sciencedirect,AI-Skin: Skin disease recognition based on self-learning and wide data collection through a closed-loop framework,https://api.elsevier.com/content/abstract/scopus_id/85068990864,"There are a lot of hidden dangers in the change of human skin conditions, such as the sunburn caused by long-time exposure to ultraviolet radiation, which not only has aesthetic impact causing psychological depression and lack of self-confidence, but also may even be life-threatening due to skin canceration. Current skin disease researches adopt the auto-classification system for improving the accuracy rate of skin disease classification. However, the excessive dependence on the image sample database is unable to provide individualized diagnosis service for different population groups. To overcome this problem, a medical AI framework based on data width evolution and self-learning is put forward in this paper to provide skin disease medical service meeting the requirement of real time, extendibility and individualization. First, the wide collection of data in the close-loop information flow of user and remote medical data center is discussed. Next, a data set filter algorithm based on information entropy is given, to lighten the load of edge node and meanwhile improve the learning ability of remote cloud analysis model. In addition, the framework provides an external algorithm load module, which can be compatible with the application requirements according to the model selected. Three kinds of deep learning model, i.e., LeNet-5, AlexNet and VGG16, are loaded and compared, which have verified the universality of the algorithm load module. The experiment platform for the proposed real-time, individualized and extensible skin disease recognition system is built. And the system’s computation and communication delay under the interaction scenario between tester and remote data center are analyzed. It is demonstrated that the system we put forward is reliable and effective.",health
10.1016/j.jep.2019.112221,Journal,Journal of Ethnopharmacology,scopus,2020-01-10,sciencedirect,Dezhou donkey (Equus asinus) milk a potential treatment strategy for type 2 diabetes,https://api.elsevier.com/content/abstract/scopus_id/85071945083,"Ethnopharmacological relevance
                  Donkey (Equus asinus) milk has become a medical and nutrient product since ancient times. In addition, donkey milk was regarded as a medicinal food and substitute product for infant formula in some ancient western countries. Chinese ancient medical books documented the medicinal value of donkey milk, using donkey milk to treat diabetes, cough and jaundice.
                  
               
                  Aim of the study
                  To investigate the donkey milk’s components and anti-diabetic effect of donkey milk in vitro and in vivo and to study the molecular mechanism of donkey milk was an anti-diabetic medication.
               
                  Materials and methods
                  In this study, the gastrointestinal digested donkey milk was simulated in vitro and its products of protein digestion were analyzed by SDS-PAGE. We then performed cell viability assay, insulin secretion assay, animal experiments and ELISA assays to study the anti-diabetic effect of donkey milk in vitro and in vivo. Donkey milk’s anti-diabetic molecular mechanism and specific targets were detected by using quantitative real time PCR.
               
                  Results
                  Lysozyme (LZ) and α-lactalbumin (α-La) exhibited significantly lower digestibility and higher retention than the other components of donkey milk. In vitro, 500 μg/mL of donkey milk could improve damaged β-cells viability significantly (P < 0.0001). In vivo, the blood glucose and HOMA-IR of diabetic rats treated with donkey milk were 14.23 ± 5.18 mM and 74.94 ± 23.62, respectively, whereas the diabetic group were 22.18 ± 2.23 mM and 112.16 ± 18.44, respectively (P < 0.01). The SOD value of donkey milk group was 265.87 ± 21.29 U/L, while the SOD value of diabetic group was 193.20 ± 52.07 U/L (P < 0.05). These results indicated that the blood glucose was reduced, the ability of the body to eliminate free radicals was enhanced, antioxidant levels in the body was increased, insulin resistance was improved in type 2 diabetic rats after donkey milk powder fed for 4 weeks. Furthermore, donkey milk could treat diabetes through down-regulating phosphoenolpyruvate carboxykinase 1 (Pck1) and glucose-6-phosphatase (G6PC).
               
                  Conclusions
                  Donkey milk has played an important role in the treatment of type 2 diabetes, and contributed to the development of the donkey milk products.",health
10.1016/j.ifacol.2020.12.2856,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,A deep learning unsupervised approach for fault diagnosis of household appliances,https://api.elsevier.com/content/abstract/scopus_id/85107800132,Fault detection and fault diagnosis are crucial subsystems to be integrated within the control architecture of modern industrial processes to ensure high quality standards. In this paper we present a two-stage unsupervised approach for fault detection and diagnosis in household appliances. In particular a suitable testing procedure has been implemented on a real industrial production line in order to extract the most meaningful features that allow to efficiently classify different types of fault by consecutively exploiting deep autoencoder neural network and k-means or hierarchical clustering techniques.,health
10.1016/j.matpr.2020.08.718,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Hybrid clustering algorithm for an efficient brain tumor segmentation,https://api.elsevier.com/content/abstract/scopus_id/85102451494,"This work describes the data mining methods, techniques and algorithms used for implementation. It is an emerging field of IT industry and research. There are many other fields such as Artificial Intelligence, Machine Learning, Deep Learning, Virtualization, Visualization, Parallel Computing and Image Processing. The human internal Brain can be seen or visualized by the Magnetic Resonance Imaging scan or Computerized Tomography scan. The MRI image is scanned and will be taken as input for processing. The MRI scan is more advantageous and more comfortable than CT scan for diagnosis. MRI scan provides detailed picture of organs. It does not affect the human health and body condition. It doesn't use any radiation. It is purely based on the magnetic field and radio waves. LIPC technique makes the training samples from the patients and arranges them into different group of classes used to construct different dictionaries. Image segmentation is a technique of dividing an image into different multiple portions, which is used to spot out objects and boundaries in images. There are many image segmentation techniques applicable for image processing. No acceptable method is available for solving all kinds of segmentation problem. Every method has merits and demerits. So, choosing good method is the challenging task. The hybrid clustering method is proposed in this work. The k-means algorithm and fuzzy c-means algorithm is proposed for brain tumor segmentation. The algorithm is implemented in synthetic and real time dataset. From the experimental results, this method provides better results in the form of accuracy.",health
10.1016/j.ifacol.2020.12.1208,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Toward safe dose delivery in plasma medicine using projected neural network-based fast approximate NMPC,https://api.elsevier.com/content/abstract/scopus_id/85099875999,"Atmospheric pressure plasma jets (APPJs) are increasingly used for biomedical applications. Reproducible and effective operation of APPJs hinges on controlling the nonlinear effects of plasma on a target substrate in the face of intrinsic variabilities of the plasma as well as exogenous disturbances. This paper presents a low-memory fast approximate nonlinear model predictive control (NMPC) strategy for an APPJ with prototypical applications in plasma medicine. The NMPC objective is to regulate the delivery of the cumulative thermal effects of plasma to a substrate, while adhering to constraints pertaining to a patient’s safety and comfort. Deep neural networks are used to approximate the implicit NMPC law with a cheap-to-evaluate explicit control law that has low memory requirements. Robust constraint satisfaction is guaranteed by projecting the output of the neural network onto a set that ensures the state stays within an appropriately defined invariant set. Closed-loop simulations and real-time control experiments indicate that the proposed approximate NMPC strategy is effective in handling nonlinear control costs at fast sampling times, while guaranteeing satisfaction of safety-critical system constraints. This work takes a crucial step toward fast NMPC of safety-critical plasma applications using resource-limited embedded control hardware.",health
10.1016/j.promfg.2020.10.164,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Deep multi-layer perceptron based prediction of energy efficiency and surface quality for milling in the era of sustainability and big data,https://api.elsevier.com/content/abstract/scopus_id/85099828504,"In advanced industries such as aerospace, medical and automotive, high precision machining is increasingly required for many parts made by difficult-to-cut alloys. Machine tool manufacturers respond to this demand by developing more advanced machine tools that have advanced sub-systems for attaining high-precision and wide flexibility, with the expense of energy efficiency. Unfortunately, worldwide primary energy resources continue to run out. Furthermore, GHG emissions mostly related to energy, remain to be a global issue with the ever-increasing economic expansion in many developed and developing economies.
                  In the meantime, increasing use of sensors and Internet of Things (IoT) technologies in shop-floors set off a data explosion, warranting the use of emerging Deep Learning techniques to cope with “Big Data” reality of manufacturing. Therefore, in this study a Deep Multi-Layer Perceptron (DMLP) based algorithm for predicting surface roughness and specific cutting energy - major measures of precision and energy efficiency-, has been developed for slot milling of AL7075. Design of Experiment is used to collect the required data and train DMLP based model. The finalized prediction algorithm estimated quality and energy efficiency with 91.5% and 90.7% accuracy rates in slot milling, verified by additional machining and data collection.",health
10.1016/j.micpro.2020.103344,Journal,Microprocessors and Microsystems,scopus,2020-01-01,sciencedirect,Medical information retrieval systems for e-Health care records using fuzzy based machine learning model,https://api.elsevier.com/content/abstract/scopus_id/85094859542,"As other sectors advance through the aid of cognitive computing, whereas the health care sector is still evolving, offering more advantages for all consumers. The growing complexities of healthcare are compounded by an aging population that contributes to underprivileged decision-making contributing to adverse impacts on the standard of treatment and raises the cost of treatment. Advances in this field, however, is hampered by numerous challenges that create a gap between the knowledge base and user queries, query inconsistencies, and user domain information set. In recent years, the rapid development with the use of machine learning and artificial intelligence for medical applications has already been shown, from diagnostic heart failure to 1-D cardiovascular beatings and automated finding using multi-dimensional clinical data. Consequently, smart decision support structures are required, which can enable clinicians to make more informed treatment decisions. An innovative solution is to harness increasing healthcare digitization that produces enormous volumes of clinical data contained in e-HCR and merge it with advanced ML software to improve clinical decision-making, thus extending the medication evidence base at the same time. Through this work, we are investigating new methodologies as well as digging at specific real-life technologies already being implemented in the medical sector and concentrating mainly on studying about accurate depictions of patients from e-HCR.",health
10.1016/j.procs.2020.07.028,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,A mobile clinical DSS based on augmented reality and deep learning for the home cares of patients afflicted by bedsores,https://api.elsevier.com/content/abstract/scopus_id/85094582861,"A bedsore, also known as pressure sore, pressure ulcer or decubitus ulcer, is the result of constant pressure on skin occurring in bedridden patients and paraplegics continuously sitting in chair. All patients who are immobile for a long time due to any cause are likely to get bedsores. Effective and efficient management of processes related to the treatment of bedsores is an important issue for healthcare organizations as it heavily affects the quality of life of patients and the costs for such organizations. Therefore organizations need and look for more and more to provide their field workforce with smart mobile tools able to support such processes. In such a context, this paper proposes a mobile app implementing a Clinical Decision Support System (CDSS) to help field operators to measure the bedsore, classify its status, trace its evolution along the timeline and making correct decisions about the course of actions to effectively treat it. The mobile app is mostly based on Augmented Reality supported by Deep Learning, thus it requires an adequate system architecture to be effectively deployed, adopted and used. From the conceptual viewpoint, the defined CDSS model lays on three important considerations: providing automatic support to classify the status of a bedsore does not do all the work but help operators to improve the quality of their decisions, augmented reality allows to build a situated environment for decision-making supporting the operators’ cognitive processes, operators should use only one tool to execute all their tasks in order to be more focused on the real problem which is to improve the quality of life of their patients.",health
10.1016/j.jsurg.2020.09.022,Journal,Journal of Surgical Education,scopus,2020-01-01,sciencedirect,"Video Commentary &amp; Machine Learning: Tell Me What You See, I Tell You Who You Are",https://api.elsevier.com/content/abstract/scopus_id/85092937825,"Background & Objective
                  Teaching and assessment of complex problem solving are a challenge for medical education. Integrating Machine Learning (ML) into medical education has the potential to revolutionize teaching and assessment of these problem-solving processes. In order to demonstrate possible applications of ML to education, we sought to apply ML in the context of a structured Video Commentary (VC) assessment, using ML to predict residents’ training level.
               
                  Setting
                  A secondary analysis of multi-institutional, IRB approved study. Participants had completed the VC assessment consisting of 13 short (20-40 seconds) operative video clips. They were scored in real-time using an extensive checklist by an experienced proctor in the assessment. A ML model was developed using TensorFlow and Keras. The individual scores of the 13 video clips from the VC assessment were used as the inputs for the ML model as well as for regression analysis.
               
                  Participants
                  A total of 81 surgical residents of all postgraduate years (PGY) 1-5 from 7 institutions constituted the study sample.
               
                  Results
                  Scores from individual VC clips were strongly positively correlated with PGY level (p = 0.001). Some video clips were identified to be strongly correlated with a higher total score on the assessment; others had significant influence when used to predict trainees’ PGY levels. Using a supervised machine learning model to predict trainees’ PGY resulted in a 40% improvement over traditional statistical analysis.
               
                  Conclusions
                  Performing better in a few select video clips was key to obtaining a higher total score but not necessarily foretelling of a higher PGY level. The use of the total score as a sole measure may fail to detect deeper relationships. Our ML model is a promising tool in gauging learners’ levels on an assessment as extensive as VC. The model managed to approximate residents’ PGY levels with a lower MAE than using traditional statistics. Further investigations with larger datasets are needed.",health
10.1016/j.promfg.2020.07.003,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Ss-infogan for class-imbalance classification of bearing faults,https://api.elsevier.com/content/abstract/scopus_id/85090497782,"As the core part of the Prognostic and Health Management (PHM) of major equipment such as high-speed trains and aero engines, bearing fault classification have been the research priorities in the field. Although convolutional neural network (CNN) has shown good results in this type of task, the real application with limited training data makes CNN have a big gap between the actual application and the expected effect. Therefore, bearing faults classification with class-imbalance is a very practical work. In this paper, semi-supervised information maximizing generative adversarial network (ss-InfoGAN), which uses adversarial structure to generate samples of the minority, is introduced to augment data to solve class imbalance problem. In addition, the latent codes, the inputs of generator, are decomposed into three parts with three additional networks, respectively, at the start of generator. Meanwhile, the 50% precision threshold is proposed during the training stage of discriminator to make a trade-off between computing resources and theoretical foundations and facilitate the network converge. Bearing fault experiments are conducted to investigate the effectiveness of the presented network. The result shows classification accuracy is improved by 40% by the ss-InfoGAN compared to the traditional CNN for the case of extremely class-imbalance condition.",health
10.1016/j.promfg.2020.05.149,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Deep learning-based cross-machine health identification method for vacuum pumps with domain adaptation,https://api.elsevier.com/content/abstract/scopus_id/85089146261,"Intelligent data-driven machinery health identification has been attracting increasing attention in the manufacturing industries, due to reduced maintenance cost and enhanced operation safety. Despite the successful development, the main limitation of most existing methods lies in the assumption that the training and testing data are collected from the same distribution, i.e. the same machine under identical condition. However, this assumption is difficult to be met in the real industries, since the diagnostic model is generally expected to be applied on new machines. In order to address this issue, a deep learning-based cross-machine health identification method is proposed for industrial vacuum pumps, which are of great importance in the manufacturing industry but have received far less research attention in the literature. Generalized diagnostic features can be learnt using the proposed domain adaptation technique with maximum mean discrepancy metric. The health identification model learnt from the training machines can be well applied on new machines. Experiments on a real-world vacuum pump dataset validate the proposed method, which is promising for industrial applications.",health
10.1016/j.promfg.2020.05.128,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Deep learning-based intelligent defect detection of cutting wheels with industrial images in manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85089137367,"The cutting wheel is an important tool in the television liquid crystal display (LCD) panel manufacturing process. The degradation of the cutting wheel significantly affects the LCD panel quality. Currently, there is few effective approaches that can detect the degradation of the cutting wheel at the working station for health monitoring purpose, due to the small size of the component and the complex manufacturing operation. That leads to high economic costs in the production lines in the real industries. In order to address this issue, this paper presents a deep convolutional neural network-based method for defect detection of the cutting wheels using the industrial images. An end-to-end health monitoring system is built based on machine vision, which directly takes the raw images as inputs, and outputs the detection results. That facilitates the industrial applications since little prior knowledge on image processing and fault detection is required. The experiments on a real-world cutting wheel degradation dataset are carried out for validation. High fault diagnosis testing accuracies are obtained, that indicates the proposed method offers an effective and promising approach for the cutting wheel health monitoring problem.",health
10.1016/j.procs.2020.03.004,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Activity Recognition in Smart Homes using UWB Radars,https://api.elsevier.com/content/abstract/scopus_id/85085563629,"In the last decade, smart homes have transitioned from a potential solution for aging-in-place to a real set of technologies being deployed in the real-world. This technological transfer has been mostly supported by simple, commercially available sensors such as passive infrared and electromagnetic contacts. On the other hand, many teams of research claim that the sensing capabilities are still too low to offer accurate, robust health-related monitoring and services. In this paper, we investigate the possibility of using Ultra-wideband (UWB) Doppler radars for the purpose of recognizing the ongoing ADLs in smart homes. Our team found out that with simple configuration and classical features engineering, a small set of UWB radars could reasonably be used to recognize ADLs in a realistic home environment. A dataset was built from 10 persons performing 15 different ADLs in a 40 square meters apartment with movement on the other side of the wall. Random Forest was able to attain 80% accuracy with an F1-Score of 79%, and a Kappa of 77%. Those results indicate the use of Doppler radars can be a good research avenue for smart homes.",health
10.1016/j.procs.2020.03.036,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Air Quality Forecasting using LSTM RNN and Wireless Sensor Networks,https://api.elsevier.com/content/abstract/scopus_id/85085553433,"In the past few decades, many urban areas around the world have suffered from severe air pollution and the health hazards that come with it, making gathering real-time air quality and air quality forecasting very important to take preventive and corrective measures. This paper proposes a scalable architecture to monitor and gather real-time air pollutant concentration data from various places and to use this data to forecast future air pollutant concentrations. Two sources are used to collect air quality data. The first being a wireless sensor network that gathers and sends pollutant concentrations to a server, with its sensor nodes deployed in various locations in Bengaluru city in South India. The second source is the real-time air quality data gathered and made available by the Government of India as a part of its Open Data initiative. Both sources provide average concentrations of various air pollutants on an hourly basis. Due to its proven track record of success with time-series data, a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) model was chosen to perform the task of air quality forecasting. This paper critically analyses the performance of the model in two regions that exhibit a significant difference in temporal variations in air quality. As these variations increase, the model suffers performance degradation necessitating adaptive modelling.",health
10.1016/j.procs.2020.03.236,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Deep Convolutional Neural Network based Detection System for Real-time Corn Plant Disease Recognition,https://api.elsevier.com/content/abstract/scopus_id/85084445610,"Corn is one of the most popular food grains in the India and crop loss due to diseases substantially affects the Indian economy and threatens the food availability. Recent access of smart devices can be utilized to provide automatic diagnosis of corn diseases and prevent severe crop losses. This paper presents a real time method based on deep convolutional neural network for corn leaf disease recognition. Deep neural network performance is improved by tuning the hyper-parameters and adjusting the pooling combinations on a system with GPU. Further, the number of parameters of the developed model is optimized to make it suitable for real time inference. The pre-trained deep CNN model was deployed onto raspberry pi 3 using Intel Movidius Neural Compute Stick consisting dedicated CNN hardware blocks. During the recognition of corn leaf diseases, the deep learning model achieves an accuracy of 88.46% demonstrating the feasibility of this method. The presented corn plant disease recognition model is capable of running on standalone smart devices like raspberry-pi or smart-phone and drones.",health
10.1016/j.imu.2020.100335,Journal,Informatics in Medicine Unlocked,scopus,2020-01-01,sciencedirect,Spark Architecture for deep learning-based dose optimization in medical imaging,https://api.elsevier.com/content/abstract/scopus_id/85084287220,"Background and objectives
                  Deep Learning (DL) and Machine Learning (ML) have brought several breakthroughs to biomedical image analysis by making available more consistent and robust tools for the identification, classification, reconstruction, denoising, quantification, and segmentation of patterns in biomedical images. Recently, some applications of DL and ML in Computed Tomography (CT) scans for low dose optimization were developed. Nowadays, DL algorithms are used in CT to perform replacement of missing data (processing technique) such as low dose to high dose, sparse view to full view, low resolution to high resolution, and limited angle to full angle. Thus, DL comes with a new vision to process biomedical data imagery from CT scan. It becomes important to develop architectures and/or methods based on DL algorithms for minimizing radiation during a CT scan exam thanks to reconstruction and processing techniques.
               
                  Methods
                  This paper describes DL for CT scan low dose optimization, shows examples described in the literature, briefly discusses new methods used in CT scan image processing, and offers conclusions. We based our study on the literature and proposed a pipeline for low dose CT scan image reconstruction. Our proposed pipeline relies on DL and the Spark Framework using MapReduce programming. We discuss our proposed pipeline with those proposed in the literature to conclude the efficiency and importance.
               
                  Results
                  An architecture for low dose optimization using CT imagery is suggested. We used the Spark Framework to design the architecture. The proposed architecture relies on DL, and permits us to develop efficient and appropriate methods to process dose optimization with CT scan imagery. The real implementation of our pipeline for image denoising shows that we can reduce the radiation dose, and use our proposed pipeline to improve the quality of the captured image.
               
                  Conclusion
                  The proposed architecture based on DL is complete and enables faster processing of biomedical CT imagery as compared with prior methods described in the literature.",health
10.1016/j.imu.2020.100324,Journal,Informatics in Medicine Unlocked,scopus,2020-01-01,sciencedirect,Sperm motility analysis system implemented on a hybrid architecture to produce an intelligent analyzer,https://api.elsevier.com/content/abstract/scopus_id/85082863547,"Much research and analysis in biomedicine involve image and video inspection using microscopes. Presently, scientists are dissatisfied with manual observations and assessments, when objective and enhanced data can be obtained by applying new technologies (such as image and video inspection) to biomedical fields, such as sperm analysis. Computer Assisted Sperm Analysis (CASA) systems, developed in the late 1980s, constitute third-generation methods of sperm analysis. This study aimed to develop a standalone medical image and video analysis system that is reconfigurable, flexible, reliable, deterministic, and robust. It proposed a new sperm motility analysis system running on a dual core Central Processing Unit (CPU) + field programmable gate arrays (FPGA) platform, under a real-time operating system (RTOS), which is a step ahead of the third-generation CASA systems.
                  The system hardware and related sperm detection and tracking algorithms were the novelty of this work. The image processing functions mainly run on FPGA, image acquisition, and calculations run on CPU, parallel with FPGA.
                  The result is a much faster, reliable, reconfigurable, and compact intelligent analyzer system.
                  Our prototype system was applied to sperm motility analysis; however, other image processing systems can be applied to this architecture. Additionally, the proposed tracking method for sperm track determination is simple, effective, and does not exert a load on the system.",health
10.1016/j.jmsy.2020.01.006,Journal,Journal of Manufacturing Systems,scopus,2020-01-01,sciencedirect,Real-time penetration state monitoring using convolutional neural network for laser welding of tailor rolled blanks,https://api.elsevier.com/content/abstract/scopus_id/85078696693,"In this paper, an innovative monitoring system capable of diagnosing the penetration state during the laser welding process is introduced, which consists of two main blocks: a coaxial visual monitoring platform and a penetration state diagnosis unit. The platform can capture coaxial images of the interaction zone during the laser welding through a partially transmitting mirror and a high-speed camera. An image dataset representing four welding states was created for training and validation. The unit mainly consists of an embedded power-efficient computing TX2 and image processing algorithms based on a convolution neural network (CNN). Experiment results show that the platform can stably capture state-of-the-art welding images. The CNN used for a diagnosis of the penetration state is optimized using an optimal network structure and hyperparameters, applying a super-Gaussian function to initialize the weights of the convolutional layer. Its latency on TX2 is less than 2 ms, satisfying the real-time requirement. During the real laser welding of tailor-rolled blanks, a penetration state diagnosis with an accuracy of 94.6 % can be achieved even if the illumination changes significantly. The similar accuracy between the validating set and a real laser welding demonstrates that the proposed monitoring system has strong robustness. The precision and recall ratios of the CNN are higher than those of other methods such as a histogram of oriented gradients and local binary pattern.",health
10.1016/j.compeleceng.2019.106529,Journal,Computers and Electrical Engineering,scopus,2020-01-01,sciencedirect,A bone age assessment system for real-world X-ray images based on convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85076052603,"It is of vast significance to assess the bone age of hand radiographs automatically in pediatric radiology and legal medicine. In the literature, many papers focus on improving the assessment accuracy but neglecting the existence of poor-quality X-ray images. However, in real medical scenarios, the existence of poor-quality X-ray images is unavoidable. To tackle this problem, we propose a bone age assessment system for real-world X-ray images. Specifically, we first establish a regression model ‘BoNet+’ based on densely connected convolutional networks. Then, to handle poor-quality X-ray images, we introduce three model architectures that are different in the way of improving image quality. Experiment results show that the proposed models can estimate the bone age of poor-quality images accurately. We also tentatively put forward that if the expressivity of CNN model is enough high, multiple tasks can be handled together just by a single model.",health
10.1016/j.artmed.2019.101767,Journal,Artificial Intelligence in Medicine,scopus,2020-01-01,sciencedirect,SemBioNLQA: A semantic biomedical question answering system for retrieving exact and ideal answers to natural language questions,https://api.elsevier.com/content/abstract/scopus_id/85076035703,"Background and objective
                  Question answering (QA), the identification of short accurate answers to users questions written in natural language expressions, is a longstanding issue widely studied over the last decades in the open-domain. However, it still remains a real challenge in the biomedical domain as the most of the existing systems support a limited amount of question and answer types as well as still require further efforts in order to improve their performance in terms of precision for the supported questions. Here, we present a semantic biomedical QA system named SemBioNLQA which has the ability to handle the kinds of yes/no, factoid, list, and summary natural language questions.
               
                  Methods
                  This paper describes the system architecture and an evaluation of the developed end-to-end biomedical QA system named SemBioNLQA, which consists of question classification, document retrieval, passage retrieval and answer extraction modules. It takes natural language questions as input, and outputs both short precise answers and summaries as results. The SemBioNLQA system, dealing with four types of questions, is based on (1) handcrafted lexico-syntactic patterns and a machine learning algorithm for question classification, (2) PubMed search engine and UMLS similarity for document retrieval, (3) the BM25 model, stemmed words and UMLS concepts for passage retrieval, and (4) UMLS metathesaurus, BioPortal synonyms, sentiment analysis and term frequency metric for answer extraction.
               
                  Results and conclusion
                  Compared with the current state-of-the-art biomedical QA systems, SemBioNLQA, a fully automated system, has the potential to deal with a large amount of question and answer types. SemBioNLQA retrieves quickly users’ information needs by returning exact answers (e.g., “yes”, “no”, a biomedical entity name, etc.) and ideal answers (i.e., paragraph-sized summaries of relevant information) for yes/no, factoid and list questions, whereas it provides only the ideal answers for summary questions. Moreover, experimental evaluations performed on biomedical questions and answers provided by the BioASQ challenge especially in 2015, 2016 and 2017 (as part of our participation), show that SemBioNLQA achieves good performances compared with the most current state-of-the-art systems and allows a practical and competitive alternative to help information seekers find exact and ideal answers to their biomedical questions. The SemBioNLQA source code is publicly available at https://github.com/sarrouti/sembionlqa.",health
10.1016/j.compeleceng.2019.106530,Journal,Computers and Electrical Engineering,scopus,2020-01-01,sciencedirect,Arm fracture detection in X-rays based on improved deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85075720723,"In this paper, a novel deep learning method is proposed and applied to fracture detection in arm bone X-rays. The main improvements include three aspects. First, a new backbone network is established based on feature pyramid architecture to gain more fractural information. Second, an image preprocessing procedure including opening operation and pixel value transformation is developed to enhance the contrast of original images. Third, the receptive field adjustment containing anchor scale reduction and tiny RoIs expansion is exploited to find more fractures. In the experiments, nearly 4000 arm fracture X-ray radiographs collected from MURA dataset are annotated by experienced radiologists. The experiment results show that the proposed deep learning method achieves the state-of-the-art AP in arm fracture detection and it has strong potential application in real clinical environments.",health
10.1016/j.ijmedinf.2019.104014,Journal,International Journal of Medical Informatics,scopus,2020-01-01,sciencedirect,Cost-effective survival prediction for patients with advanced prostate cancer using clinical trial and real-world hospital registry datasets,https://api.elsevier.com/content/abstract/scopus_id/85075365778,"Introduction
                  Predictive survival modeling offers systematic tools for clinical decision-making and individualized tailoring of treatment strategies to improve patient outcomes while reducing overall healthcare costs. In 2015, a number of machine learning and statistical models were benchmarked in the DREAM 9.5 Prostate Cancer Challenge, based on open clinical trial data for metastatic castration resistant prostate cancer (mCRPC). However, applying these models into clinical practice poses a practical challenge due to the inclusion of a large number of model variables, some of which are not routinely monitored or are expensive to measure.
               
                  Objectives
                  To develop cost-specified variable selection algorithms for constructing cost-effective prognostic models of overall survival that still preserve sufficient model performance for clinical decision making.
               
                  Methods
                  Penalized Cox regression models were used for the survival prediction. For the variable selection, we implemented two algorithms: (i) LASSO regularization approach; and (ii) a greedy cost-specified variable selection algorithm. The models were compared in three cohorts of mCRPC patients from randomized clinical trials (RCT), as well as in a real-world cohort (RWC) of advanced prostate cancer patients treated at the Turku University Hospital. Hospital laboratory expenses were utilized as a reference for computing the costs of introducing new variables into the models.
               
                  Results
                  Compared to measuring the full set of clinical variables, economic costs could be reduced by half without a significant loss of model performance. The greedy algorithm outperformed the LASSO-based variable selection with the lowest tested budgets. The overall top performance was higher with the LASSO algorithm.
               
                  Conclusion
                  The cost-specified variable selection offers significant budget optimization capability for the real-world survival prediction without compromising the predictive power of the model.",health
10.1016/j.ahj.2019.10.007,Journal,American Heart Journal,scopus,2020-01-01,sciencedirect,ECG AI-Guided Screening for Low Ejection Fraction (EAGLE): Rationale and design of a pragmatic cluster randomized trial,https://api.elsevier.com/content/abstract/scopus_id/85074666778,"Background
                  A deep learning algorithm to detect low ejection fraction (EF) using routine 12-lead electrocardiogram (ECG) has recently been developed and validated. The algorithm was incorporated into the electronic health record (EHR) to automatically screen for low EF, encouraging clinicians to obtain a confirmatory transthoracic echocardiogram (TTE) for previously undiagnosed patients, thereby facilitating early diagnosis and treatment.
               
                  Objectives
                  To prospectively evaluate a novel artificial intelligence (AI) screening tool for detecting low EF in primary care practices.
               
                  Design
                  The EAGLE trial is a pragmatic two-arm cluster randomized trial (NCT04000087) that will randomize >100 clinical teams (i.e., clusters) to either intervention (access to the new AI screening tool) or control (usual care) at 48 primary care practices across Minnesota and Wisconsin. The trial is expected to involve approximately 400 clinicians and 20,000 patients. The primary endpoint is newly discovered EF ≤50%. Eligible patients will include adults who undergo ECG for any reason and have not been previously diagnosed with low EF. Data will be pulled from the EHR, and no contact will be made with patients. A positive deviance qualitative study and a post-implementation survey will be conducted among select clinicians to identify facilitators and barriers to using the new screening report.
               
                  Summary
                  This trial will examine the effectiveness of the AI-enabled ECG for detection of asymptomatic low EF in routine primary care practices and will be among the first to prospectively evaluate the value of AI in real-world practice. Its findings will inform future implementation strategies for the translation of other AI-enabled algorithms.",health
10.1016/j.asoc.2019.105890,Journal,Applied Soft Computing Journal,scopus,2020-01-01,sciencedirect,A new convolutional neural network model for peripapillary atrophy area segmentation from retinal fundus images,https://api.elsevier.com/content/abstract/scopus_id/85074508955,"Peripapillary atrophy (PPA) is a clinical finding, which reflects the atrophy of retina layer and retinal pigment epithelium. The size of PPA area is a useful medical indicator, as it is highly associated with many diseases such as glaucoma and myopia. Therefore, separating the PPA area from retinal images, which is called PPA area segmentation, is very important. It is a challenging task, because PPA areas are irregular and non-uniform, and their contours are blurry and change gradually. To solve these issues, we transform the PPA area segmentation task into a task of segmenting another two areas with relatively regular and uniform shapes, and then propose a novel multi-task fully convolutional network (MFCN) model to jointly extract them from retinal images. Meanwhile, we take edge continuity of the target area into consideration. To evaluate the performance of the proposed model, we conduct experiments on images with PPA areas labelled by experts and achieve an average precision of 0.8928, outperforming the state-of-the-art models. To demonstrate the application of PPA segmentation in medical research, we apply PPA related features based on the segmented PPA area on differentiating glaucomatous and physiologic large cup cases. Experiment conducted on real datasets confirms the effectiveness of using these features for glaucoma diagnosis.",health
10.1016/j.actbio.2019.10.021,Journal,Acta Biomaterialia,scopus,2020-01-01,sciencedirect,Adaptive in vivo device for theranostics of inflammation: Real-time monitoring of interferon-γ and aspirin,https://api.elsevier.com/content/abstract/scopus_id/85074455944,"Cytokines mediate and control immune and inflammatory responses. Complex interactions exist among cytokines, inflammation, and the innate and adaptive immune responses in maintaining homeostasis, health, and well-being. On-demand, local delivery of anti-inflammatory drugs to target tissues provides an approach for more effective drug dosing while reducing the adverse effects of systemic drug delivery. This work demonstrates a proof-of-concept theranostic approach for inflammation based on analyte-kissing induced signaling, whereby a drug (in this report, aspirin) can be released upon the detection of a target level of a proinflammatory cytokine (i.e., interferon-γ (IFN-γ)) in real time. The structure-switching aptamer-based biosensor described here is capable of quantitatively and dynamically detecting IFN-γ both in vitro and in vivo with a sensitivity of 10 pg mL−1. Moreover, the released aspirin triggered by the immunoregulatory cytokine IFN-γ is able to inhibit inflammation in a rat model, and the release of aspirin can be quantitatively controlled. The data reported here provide a new and promising strategy for the in vivo detection of proinflammatory cytokines and the subsequent therapeutic delivery of anti-inflammatory molecules. This universal theranostic platform is expected to have great potential for patient-specific personalized medicine.
               
                  Statement of Significance
                  We developed an adaptive in vivo sensing device whereby a drug, aspirin, can be released upon the detection of a proinflammatory cytokine, interferon-γ (IFN-γ), in real time with a sensitivity of 10 pg mL−1. Moreover, the aspirin triggered by IFN-γ depressed inflammation in the rat model and was delivered indirectly through blood and cerebrospinal fluid or directly to the inflammation tissue or organ without adverse gastrointestinal effects observed in the liver and kidney. We envision that, for the first time, patients with chronic inflammatory disease can receive the right intervention and treatment at the right time. Additionally, this technology may empower patients to monitor their personalized health and disease management program, allowing real-time diagnostics, disease monitoring, and precise and effective treatments.",health
10.1016/bs.adcom.2019.09.005,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Impact of cloud security in digital twin,https://api.elsevier.com/content/abstract/scopus_id/85073737509,"Digital Twin is a way to virtually represent or model a physical object using the real time data. This innovation sets up a way to deal with industries and organizations to supervise their products, consequently bridging the gap between design and implementations. As the name suggests, “Digital Twin” infers that a reproduction of the product is made in order to have a nearby relationship with the live item. The procedure of computerized twin begins by gathering real time data, processed data, and operational data and performs distinctive investigation which helps in anticipating the future. This additionally enhances the customer experiences by giving a digital feel of their product. The objective behind all these is the job of gathering information and putting them in a place, i.e., the cloud which could store exorbitant data. The user experience gets enhanced by the intervention of digital twin technology which could help in the successful working of the products geographically distributed. The impact of Internet of Things and Cloud Computing lifts up the digital twin.
                  The information gathered from the sources can be arranged in terms of utilization and prospect to change on a timely basis. These data, as they are stored require proper coordination and a legitimate use.
                  Digital Twin innovation assumes incredible opportunities in the field of manufacturing, healthcare, smart cities, automobile and so on. The effect of having a digital twin for the product makes it simple for activities and recognize the blemishes, if any happened. This approach can help reduce the workload and furthermore can get trained on the virtual machine without the need of a specific training.
                  With the most prevailing technologies of today, like Artificial Intelligence, Machine Learning and Internet of Things more prominent approach to train and monitor products, taking care of its own execution, collaborating to different frameworks, performing self-repairs are made possible. Hence the future is getting unfolded with the emerging DIGITAL TWIN era. The massive data utilized in the field of digital twin is prone to severe security breaches. Thus digital twin technology should be handled with extreme care so as to protect the data. Hence, this chapter identifies the ways and means of collecting, organizing and storing the data in a secured cloud environment. The data is filtered according to the use and priority and pushed into the cloud. It is determined to implement an exclusive algorithm for a secured cloud which would greatly benefit the users and the providers to handle and process it effectively.",health
10.1016/j.engappai.2019.103255,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-01-01,sciencedirect,Therapy-driven Deep Glucose Forecasting,https://api.elsevier.com/content/abstract/scopus_id/85072863135,"The automatic regulation of blood glucose for Type 1 diabetes patients is the main goal of the artificial pancreas, a closed-loop system that exploits continue glucose monitoring data to define an optimal insulin therapy. One of the most successful approaches for developing the artificial pancreas is the model predictive control, which exhibits promising results on both virtual and real patients. The performance of such controller is highly dependent on the reliability of the glucose–insulin model used for prediction purpose, which is usually implemented with classic mathematical models. The main limitation of these models consists in the difficulties of modeling the physiological nonlinear dynamics typical of this system. The availability of big amount of in silico and in vivo data moved the attention to new data-driven methods which are able to easily overcome this problem. In this paper we propose Deep Glucose Forecasting, a deep learning approach for forecasting glucose levels, based on a novel, two-headed Long-Short Term Memory implementation. It takes in input the previous values obtained through continue glucose monitoring, the carbohydrate intake, the suggested insulin therapy and forecasts the interstitial glucose level of the patient. The proposed architecture has been trained on 100 virtual adult patients of the UVA/Padova simulator, and tested on both virtual and real patients. The proposed solution is able to generalize to new unseen data, outperforms classical population models and reaches performance comparable to classical personalized models when fine-tuning is exploited on real patients.",health
10.1016/j.cma.2019.112628,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-01-01,sciencedirect,Deep learning acceleration of Total Lagrangian Explicit Dynamics for soft tissue mechanics,https://api.elsevier.com/content/abstract/scopus_id/85072715847,"Simulating complex soft tissue deformations has been an intense research area in the fields of computer graphics or computational physiology for instance. A desired property is the ability to perform fast, if not real-time, simulations while being physically accurate. Numerical schemes have been explored to speed up finite element methods, like the Total Lagrangian Explicit Dynamics (TLED). However, real-time applications still come at the price of accuracy and fidelity. In this work, we explore the use of neural networks as function approximators to accelerate the time integration of TLED, while being generic enough to handle various geometries, motion and materials without having to retrain the neural network model. The method is evaluated on a set of experiment, showing promising accuracy at time steps up to 20 times larger than the “breaking” time step, as well as in a simple medical application. Such an approach could pave the way to very fast but accurate acceleration strategies for computational biomechanics.",health
10.1016/j.ins.2019.08.062,Journal,Information Sciences,scopus,2020-01-01,sciencedirect,Neighbourhood-based undersampling approach for handling imbalanced and overlapped data,https://api.elsevier.com/content/abstract/scopus_id/85071863517,"Class imbalanced datasets are common across different domains including health, security, banking and others. A typical supervised learning algorithm tends to be biased towards the majority class when dealing with imbalanced datasets. The learning task becomes more challenging when there is also an overlap of instances from different classes. In this paper, we propose an undersampling framework for handling class imbalance in binary datasets by removing potential overlapped data points. Our methods are designed to identify and eliminate majority class instances from the overlapping region. Accurate identification and elimination of these instances maximise the visibility of the minority class instances and at the same time minimises excessive elimination of data, which reduces information loss. Four methods based on neighbourhood searching with different criteria to identify potential overlapped instances are proposed in this paper. Extensive experiments using simulated and real-world datasets were carried out. Results show comparable performance with state-of-the-art methods across different common metrics with exceptional and statistically significant improvements in sensitivity.",health
10.1016/j.bspc.2019.101638,Journal,Biomedical Signal Processing and Control,scopus,2020-01-01,sciencedirect,EEG mobility artifact removal for ambulatory epileptic seizure prediction applications,https://api.elsevier.com/content/abstract/scopus_id/85070796123,"Mobile monitoring of electroencephalogram (EEG) signals is prone to different sources of artifacts. Most importantly, motion-related artifacts present a major challenge hindering the clean acquisition of EEG data as they spread all over the scalp and across all frequency bands. This leads to additional complexity in the development of neurologically-oriented mobile health solutions. Among the top five most common neurological disorders, epilepsy has increasingly relied on EEG for diagnosis. Separate methods have been used to classify EEG segments in the context of epilepsy while reducing the existing mobility artifacts. This work specifically devises an approach to remove motion-related artifacts in the context of epilepsy. The proposed approach first includes the recording of EEG signals using a wearable EEG headset. The recorded signals are then colored by some motion artifacts generated in a lab-controlled experiment. This stage is followed by temporal and spectral characterization of the signals and artifact removal using independent component analysis (ICA). The proposed approach is tested using real clinical EEG data and results showed an average increase in accuracy of ∼9% in seizure detection and ∼24% in prediction.",health
10.1016/j.eswa.2019.112843,Journal,Expert Systems with Applications,scopus,2020-01-01,sciencedirect,Intelligent image-based colourimetric tests using machine learning framework for lateral flow assays,https://api.elsevier.com/content/abstract/scopus_id/85070583607,"This paper aims to deliberately examine the scope of an intelligent colourimetric test that fulfils ASSURED criteria (Affordable, Sensitive, Specific, User-friendly, Rapid and robust, Equipment-free, and Deliverable) and demonstrate the claim as well. This paper presents an investigation into an intelligent image-based system to perform automatic paper-based colourimetric tests in real-time to provide a proof-of-concept for a dry-chemical based or microfluidic, stable and semi-quantitative assay using a larger dataset with diverse conditions. The universal pH indicator papers were utilised as a case study. Unlike the works done in the literature, this work performs multiclass colourimetric tests using histogram-based image processing and machine learning algorithm without any user intervention. The proposed image processing framework is based on colour channel separation, global thresholding, morphological operation and object detection. We have also deployed aserver-based convolutional neural network framework for image classification using inductive transfer learning on a mobile platform. The results obtained by both traditional machine learning and pre-trained model-based deep learning were critically analysed with the set evaluation criteria (ASSURED criteria). The features were optimised using univariate analysis and exploratory data analysis to improve the performance. The image processing algorithm showed >98% accuracy while the classification accuracy by Least Squares Support Vector Machine (LS-SVM) was 100%. On the other hand, the deep learning technique provided >86% accuracy, which could be further improved with a large amount of data. The k-fold cross-validated LS-SVM based final system, examined on different datasets, confirmed the robustness and reliability of the presented approach, which was further validated using statistical analysis. The understaffed and resource-limited healthcare system can benefit from such an easy-to-use technology to support remote aid workers, assist in elderly care and promote personalised healthcare by eliminating the subjectivity of interpretation.",health
10.1016/j.eswa.2019.112855,Journal,Expert Systems with Applications,scopus,2020-01-01,sciencedirect,Breast tumor segmentation and shape classification in mammograms using generative adversarial and convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85070060332,"Mammogram inspection in search of breast tumors is a tough assignment that radiologists must carry out frequently. Therefore, image analysis methods are needed for the detection and delineation of breast tumors, which portray crucial morphological information that will support reliable diagnosis. In this paper, we proposed a conditional Generative Adversarial Network (cGAN) devised to segment a breast tumor within a region of interest (ROI) in a mammogram. The generative network learns to recognize the tumor area and to create the binary mask that outlines it. In turn, the adversarial network learns to distinguish between real (ground truth) and synthetic segmentations, thus enforcing the generative network to create binary masks as realistic as possible. The cGAN works well even when the number of training samples are limited. As a consequence, the proposed method outperforms several state-of-the-art approaches. Our working hypothesis is corroborated by diverse segmentation experiments performed on INbreast and a private in-house dataset. The proposed segmentation model, working on an image crop containing the tumor as well as a significant surrounding area of healthy tissue (loose frame ROI), provides a high Dice coefficient and Intersection over Union (IoU) of 94% and 87%, respectively. In addition, a shape descriptor based on a Convolutional Neural Network (CNN) is proposed to classify the generated masks into four tumor shapes: irregular, lobular, oval and round. The proposed shape descriptor was trained on DDSM, since it provides shape ground truth (while the other two datasets does not), yielding an overall accuracy of 80%, which outperforms the current state-of-the-art.",health
10.1016/j.inffus.2019.06.019,Journal,Information Fusion,scopus,2020-01-01,sciencedirect,A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition,https://api.elsevier.com/content/abstract/scopus_id/85067959783,"With the rapid development of artificial intelligence and mobile Internet, the new requirements for human-computer interaction have been put forward. The personalized emotional interaction service is a new trend in the human-computer interaction field. As a basis of emotional interaction, emotion recognition has also introduced many new advances with the development of artificial intelligence. The current research on emotion recognition mostly focuses on single-modal recognition such as expression recognition, speech recognition, limb recognition, and physiological signal recognition. However, the lack of the single-modal emotional information and vulnerability to various external factors lead to lower accuracy of emotion recognition. Therefore, multimodal information fusion for data-driven emotion recognition has been attracting the attention of researchers in the affective computing filed. This paper reviews the development background and hot spots of the data-driven multimodal emotion information fusion. Considering the real-time mental health monitoring system, the current development of multimodal emotion data sets, the multimodal features extraction, including the EEG, speech, expression, text features, and multimodal fusion strategies and recognition methods are discussed and summarized in detail. The main objective of this work is to present a clear explanation of the scientific problems and future research directions in the multimodal information fusion for data-driven emotion recognition field.",health
10.1016/j.inffus.2019.06.024,Journal,Information Fusion,scopus,2020-01-01,sciencedirect,Multi-class Arrhythmia detection from 12-lead varied-length ECG using Attention-based Time-Incremental Convolutional Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85067829138,"Automatic arrhythmia detection from Electrocardiogram (ECG) plays an important role in early prevention and diagnosis of cardiovascular diseases. Convolutional neural network (CNN) is a simpler, more noise-immune solution than traditional methods in multi-class arrhythmia classification. However, suffering from lack of consideration for temporal feature of ECG signal, CNN couldn’t accept varied-length ECG signal and had limited performance in detecting paroxysmal arrhythmias. To address these issues, we proposed attention-based time-incremental convolutional neural network (ATI-CNN), a deep neural network model achieving both spatial and temporal fusion of information from ECG signals by integrating CNN, recurrent cells and attention module. Comparing to CNN model, this model features flexible input length, halved parameter amount as well as more than 90% computation reduction in real-time processing. The experiment result shows that, ATI-CNN reached an overall classification accuracy of 81.2%. In comparison with a classical 16-layer CNN named VGGNet, ATI-CNN achieved accuracy increases of 7.7% in average and up to 26.8% in detecting paroxysmal arrhythmias. Combining all these excellent features, ATI-CNN offered an exemplification for all kinds of varied-length signal processing problems.",health
10.1016/j.aca.2019.08.019,Journal,Analytica Chimica Acta,scopus,2019-12-04,sciencedirect,An exonuclease-assisted triple-amplified electrochemical aptasensor for mucin 1 detection based on strand displacement reaction and enzyme catalytic strategy,https://api.elsevier.com/content/abstract/scopus_id/85070664893,"The development of some sensitive methods for MUC1 is critical for preclinical diagnosis of tumors. In this experiment, we built a triple-amplified electrochemical aptasensor to achieve sensitive detection of MUC1, which was based on exonuclease III (Exo III)-assisted with strand displacement reaction and enzyme catalytic strategy. Firstly, with the help of Exo III, MUC1 and aptamer could be recycled during the cycle I, the single stranded DNA-1 (S-1) was produced during the process and was introduced to the hybride reaction on the electrode. Secondly, during the cycle II, strand displacement reaction was triggered on the electrode with the adding of hairpin DNA-2 (H-2). Thirdly, after the gold nanoparticles (AuNPs)-DNA-enzyme conjugates hybrided with the H-2 on the electrode, the AuNPs-DNA-enzyme conjugates could act as signal probe to produce electrochemical catalytic signal. We used the fabricated triple-amplified electrochemical aptasensor that could detect MUC1 from 0.1 pg mL−1 to 10 ng mL−1 with the detection limit of 0.04 pg mL−1 under the optimized experimental conditions. The constructed triple-amplified electrochemical aptasensor could be applied in real samples determination. Besides, the strategy can be applied to detect other proteins for health monitoring.",health
10.1016/j.fsi.2019.11.004,Journal,Fish and Shellfish Immunology,scopus,2019-12-01,sciencedirect,"Vibrio harveyi biofilm as immunostimulant candidate for high-health pacific white shrimp, Penaeus vannamei farming",https://api.elsevier.com/content/abstract/scopus_id/85075430139,"The study was to develop Vibrio harveyi biofilm-based novel microbial product and its oral delivery for high health Penaeus vannamei farming. Yield of bacterial biofilm was optimized on chitin substrate (size: <360, 360–850 and 850–1250 μm; concentration: 0.3, 0.6 and 0.9%) in tryptone soy broth (0.15%). The biofilm was characterized by crystal violet assay, SEM and LSCM imaging; protein profiling by SDS-PAGE and LC-ESI-MS/MS. The immune stimulatory effect of the biofilm in yard experiments was evaluated by relative quantification of immune genes using real-time PCR effect on overall improvement on health status under field trials. The highest biofilm yield (6.13 ± 0.2 × 107 cfu/ml) was obtained at 0.6% of <360 μm chitin substrate. The biofilm formation was stabilized by 96 h of incubation at 30 °C. Protein profiling confirmed expression of six additional proteins (SDS-PAGE) and 11 proteins were differentially expressed (LC-ESI-MS/MS) in biofilm cells over free cells of V. harveyi. Oral administration of the biofilm for 48 h confirmed to enhance expression of antimicrobial peptides, penaeidin, crustin and lysozyme in P. vannamei. Further Oral administration of biofilm for two weeks to P. vannamei (1.8 ± 0.13 g) improved the growth (2.66 ± 0.06 g) and survival (84.44 ± 1.82%) compared to control (2.15 ± 0.03 g; 70.94 ± 0.66%) Nursery trials showed a significant reduction in occurrence of anatomical deformities like antenna cut (12.67 ± 0.66%), rostrum cut (4.66 ± 0.87%), and tail rot (3.33 ± 0.88%), compared to animals fed with normal diet which was 24.33 ± 2.72; 14 ± 1.52 and 10.66 ± 1.45% respectively. In vitro and in vivo studies suggest inactivated biofilm cells of V. harveyi on chitin substrate express additional antigenic proteins and when administered orally through feed at regular intervals stimulates immune response and improve growth, survival and health status of shrimp.",health
10.1016/j.compeleceng.2019.106465,Journal,Computers and Electrical Engineering,scopus,2019-12-01,sciencedirect,A novel backstepping adaptive impedance control for an upper limb rehabilitation robot,https://api.elsevier.com/content/abstract/scopus_id/85072382915,"Stroke contributes to hemiplegia, which severely reduces people's ability to perform activities of daily living. Due to the insufficiency of medical resources, there is an urgent need for home-based rehabilitation robot. In this paper, we design a home-based upper limb rehabilitation robot, based on the principle that three axes intersect at one point. A three-dimensional force sensor is equipped at the end of the manipulator to measure the interaction forces between the affected upper limb and the robot during rehabilitation training. The virtual rehabilitation training environment is designed to improve the enthusiasm of patients. A backstepping adaptive fuzzy based impedance control method is proposed for the home-based upper limb rehabilitation robot to prevent secondary injury of the affected limb. The adaptive law is introduced, and the backstepping adaptive fuzzy based impedance controller is proved in details. Experiments results demonstrate the effectiveness of the proposed control method.",health
10.1016/j.jviromet.2019.113730,Journal,Journal of Virological Methods,scopus,2019-12-01,sciencedirect,A rapid RT-LAMP assay for the detection of all four lineages of Peste des Petits Ruminants Virus,https://api.elsevier.com/content/abstract/scopus_id/85072376536,"Peste des petits ruminants (PPR) is a viral disease of small ruminants that is caused by the PPR virus (PPRV) and is a significant burden on subsistence farmers across the developing world. Loop-mediated isothermal amplification (LAMP) provides cost-effective, rapid, specific and sensitive detection of nucleic acid and has been demonstrated to have field application for a range of viruses. We describe the development of a novel PPRV RT-LAMP assay utilising carefully-selected primers (targeting the N-gene) allowing for the detection of all known PPRV lineages in < 20 min. The assay was evaluated in comparison with a “gold standard” real-time RT-PCR assay using more than 200 samples, comprising samples from recent PPRV outbreaks, experimentally-infected goats, well-characterised cell culture isolates and samples collected from uninfected animals. The RT-LAMP assay demonstrated 100% diagnostic specificity and greater than 97% diagnostic sensitivity in comparison with the real-time RT-PCR assay. The limit of detection was between 0.3 and 0.8 log10 TCID50 ml−1 equating to a CT value of 31.52 to 33.48. In experimentally-infected animals, the RT-LAMP could detect PPRV as early as 4 days post infection (dpi) - before clinical signs were observed at 7 dpi. The RT-LAMP assay can support the global PPR eradication campaign.",health
10.1053/j.ajkd.2019.06.013,Journal,American Journal of Kidney Diseases,scopus,2019-12-01,sciencedirect,Continuous Renal Replacement Therapy Dosing in Critically Ill Patients: A Quality Improvement Initiative,https://api.elsevier.com/content/abstract/scopus_id/85072198500,"Rationale & Objective
                  Clinical practice guidelines recommend delivering a continuous renal replacement therapy (CRRT) dose of 20 to 25mL/kg/h. However, practice patterns nationwide are highly variable; this inconsistent prescribing may lead to errors in medication dosing and increase rates of electrolyte and acid-base abnormalities. We describe an initiative to standardize CRRT practice patterns and reduce dosing variability.
               
                  Study Design
                  Quality improvement study.
               
                  Setting & Participants
                  Adult patients treated with CRRT at the University of Colorado Hospital between January 2016 and October 2017.
               
                  Quality Improvement Activities
                  An assessment of the magnitude of the variability in CRRT dosing and the following specific interventions were implemented during the course of 1 year: (1) modification of the electronic medical record (EMR) to include calculated average 24-hour dose in real time, (2) modification of the CRRT procedure note to include comments on dosing, (3) modification of the CRRT order set to display calculations, and (4) yearly educational sessions for renal fellows outlining CRRT-specific dosing targets.
               
                  Outcomes
                  The primary outcome was weekly percentage of CRRT treatments with an average delivered daily dose of 20 to 25mL/kg/h. Process and balancing outcomes included CRRT flowsheet accuracy, documentation of rates of delivered dose, and nursing satisfaction.
               
                  Analytical Approach
                  Rates of weekly CRRT dosing in compliance with national guidelines were determined and used to create run charts showing compliance rates before and after the quality improvement interventions.
               
                  Results
                  Among 837 treatments before the intervention, 279 (33%) daily CRRT sessions achieved an average dose of 20 to 25mL/kg/h. Following implementation of interventions, 631 of 952 (66%) treatments achieved this goal. Week-to-week variation in dosing was significantly reduced.
               
                  Limitations
                  A single-center study generating data that may not be generalizable to institutions with different CRRT nursing models or different EMR systems.
               
                  Conclusions
                  Changes to the EMR and documentation templates and education of CRRT providers about dosing were associated with doubling of the rate of appropriate CRRT dosing and reduction in dosing variability.",health
10.1016/j.cmpb.2019.105053,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-12-01,sciencedirect,Saliency-driven system models for cell analysis with deep learning,https://api.elsevier.com/content/abstract/scopus_id/85072048959,"Background and objectives: Saliency refers to the visual perception quality that makes objects in a scene to stand out from others and attract attention. While computational saliency models can simulate the expert’s visual attention, there is little evidence about how these models perform when used to predict the cytopathologist’s eye fixations. Saliency models may be the key to instrumenting fast object detection on large Pap smear slides under real noisy conditions, artifacts, and cell occlusions. This paper describes how our computational schemes retrieve regions of interest (ROI) of clinical relevance using visual attention models. We also compare the performance of different computed saliency models as part of cell screening tasks, aiming to design a computer-aided diagnosis systems that supports cytopathologists.
                  
                     Method: We record eye fixation maps from cytopathologists at work, and compare with 13 different saliency prediction algorithms, including deep learning. We develop cell-specific convolutional neural networks (CNN) to investigate the impact of bottom-up and top-down factors on saliency prediction from real routine exams. By combining the eye tracking data from pathologists with computed saliency models, we assess algorithms reliability in identifying clinically relevant cells.
                  
                     Results:The proposed cell-specific CNN model outperforms all other saliency prediction methods, particularly regarding the number of false positives. Our algorithm also detects the most clinically relevant cells, which are among the three top salient regions, with accuracy above 98% for all diseases, except carcinoma (87%). Bottom-up methods performed satisfactorily, with saliency maps that enabled ROI detection above 75% for carcinoma and 86% for other pathologies.
                  
                     Conclusions:ROIs extraction using our saliency prediction methods enabled ranking the most relevant clinical areas within the image, a viable data reduction strategy to guide automatic analyses of Pap smear slides. Top-down factors for saliency prediction on cell images increases the accuracy of the estimated maps while bottom-up algorithms proved to be useful for predicting the cytopathologist’s eye fixations depending on parameters, such as the number of false positive and negative. Our contributions are: comparison among 13 state-of-the-art saliency models to cytopathologists’ visual attention and deliver a method that the associate the most conspicuous regions to clinically relevant cells.",health
10.1016/j.ymssp.2019.106266,Journal,Mechanical Systems and Signal Processing,scopus,2019-12-01,sciencedirect,Hierarchical fault classification for resource constrained systems,https://api.elsevier.com/content/abstract/scopus_id/85071331238,"Prognostics and health management (PHM) is the study of using health information to support decision making to improve maintenance and operations. There are many existing methods for PHM but most solely focus on predictive accuracy and ignore resource constraints. In a real-world application of a PHM system, resources consumed by the predictive algorithm at the core of the PHM system could be a limiting factor. In this study, we propose using a hierarchical classification scheme to break the conventional classification problem into many sub-problems arranged in a hierarchy. By splitting the diagnostic task into many sub-problems, the hierarchical classifier can be constructed to maximize accuracy while minimizing resource consumption. Reinforcement learning is proposed to select the classifiers for each sub-problem. The proposed methodology is applied to condition monitoring of a hydraulic actuator where power is a limiting resource. Numerical experiments demonstrate that the proposed hierarchical classification method can reduce resource consumption compared to a traditional flat classification approach.",health
10.1016/j.future.2019.07.020,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,Sensor-based activity recognition: One picture is worth a thousand words,https://api.elsevier.com/content/abstract/scopus_id/85069616209,"In several domains, including healthcare and home automation, it is important to unobtrusively monitor the activities of daily living (ADLs) carried out by people at home. A popular approach consists in the use of sensors attached to everyday objects to capture user interaction, and ADL models to recognize the current activity based on the temporal sequence of used objects. Often, ADL models are automatically extracted from labeled datasets of activities and sensor events, using supervised learning techniques. Unfortunately, acquiring such datasets in smart homes is expensive and violates users’ privacy. Hence, an alternative solution consists in manually defining ADL models based on common sense, exploiting logic languages such as description logics. However, manual specification of ADL ontologies is cumbersome, and rigid ontological definitions fail to capture the variability of activity execution. In this paper, we introduce a radically new approach enabled by the recent proliferation of tagged visual contents available on the Web. Indeed, thanks to the popularity of social network applications, people increasingly share pictures and videos taken during the execution of every kind of activity. Often, shared contents are tagged with metadata, manually specified by their owners, that concisely describe the depicted activity. Those metadata represent an implicit activity label of the picture or video. Moreover, today’s computer vision tools support accurate extraction of tags describing the situation and the objects that appear in the visual content. By reasoning with those tags and their corresponding activity labels, we can reconstruct accurate models of a comprehensive set of human activities executed in the most disparate situations. This approach overcomes the main shortcomings of existing techniques. Compared to supervised learning methods, it does not require the acquisition of training sets of sensor events and activities. Compared to knowledge-based methods, it does not involve any manual modeling effort, and it captures a comprehensive array of execution modalities. Through extensive experiments with large datasets of real-world ADLs, we show that this approach is practical and effective.",health
10.1016/j.isatra.2018.12.025,Journal,ISA Transactions,scopus,2019-12-01,sciencedirect,Deep residual learning-based fault diagnosis method for rotating machinery,https://api.elsevier.com/content/abstract/scopus_id/85059116434,"Effective fault diagnosis of rotating machinery has always been an important issue in real industries. In the recent years, data-driven fault diagnosis methods such as neural networks have been receiving increasing attention due to their great merits of high diagnosis accuracy and easy implementation. However, it is mostly difficult to fully train a deep neural network since gradients in optimization may vanish or explode during back-propagation, which results in deterioration and noticeable variance in model performance. In fault diagnosis researches, larger data sequence of machinery vibration signal containing sufficient information is usually preferred and consequently, deep models with large capacity are generally adopted. In order to improve network training, a residual learning algorithm is proposed in this paper. The proposed architecture significantly improves the information flow throughout the network, which is well suited for processing machinery vibration signal with variable sequential length. Little prior expertise on fault diagnosis and signal processing is required, that facilitates industrial applications of the proposed method. Experiments on a popular rolling bearing dataset are implemented to validate the proposed method. The results of this study suggest that the proposed intelligent fault diagnosis method for rotating machinery offers a new and promising approach.",health
10.1016/j.eswa.2019.05.033,Journal,Expert Systems with Applications,scopus,2019-11-15,sciencedirect,QRS detection method based on fully convolutional networks for capacitive electrocardiogram,https://api.elsevier.com/content/abstract/scopus_id/85066484457,"A capacitive electrocardiogram (cECG) signal is considered a promising alternative to a conventional contact electrocardiogram (ECG) signal because the cECG signal can serve the same purpose as the contact ECG signal but can be measured during daily life without causing a subject to feel uncomfortable. However, the cECG signal has a limitation in that detection of QRS complexes, which is a fundamental step to analyze heart condition, is not easy. That is because the cECG signal is sensitive to noise, especially motion noise. This paper proposes a method to detect QRS complexes in cECG signals degraded by motion noise. The proposed method is based on fully convolutional networks (FCNs) and mainly consists of three parts: the generation of ground-truth data, the FCN model, and postprocessing. A labeling process for generating the ground-truth data is proposed. Then, an FCN model that is suitable for cECG signals is proposed. The proposed FCN model uses filters of a large size to achieve a large receptive field, unlike the common FCN models used in image processing. The receptive field is sufficiently large to involve information about adjacent QRS complexes, such as the time interval between the QRS complexes and its variability. By considering the information, the proposed FCN model can reliably classify QRS complexes even in cECG signals degraded by motion noise. Additionally, postprocessing, which consists of an accumulation step and a non-maximum suppression step, is proposed to complement the proposed FCN model. In experiments with real data, the proposed method showed an average sensitivity of 96.94%, positive predictive value of 99.13%, and F1 score of 98.02%. These results demonstrate that the proposed method overcomes the limitation of a cECG signal and helps the cECG signal be widely utilized for medical or healthcare applications.",health
10.1016/j.comnet.2019.106870,Journal,Computer Networks,scopus,2019-11-09,sciencedirect,Game-based adaptive anomaly detection in wireless body area networks,https://api.elsevier.com/content/abstract/scopus_id/85070500273,"Wireless Body Area Network (WBAN) is a quite suitable communication tool for medical IoT devices that are deployed to collect physiological parameters and forecast real-time events in order to facilitate the diagnostic decision-making for the medical staff. However, sensor readings may be inaccurate due to resource-constrained devices, sensor misplacement, hardware faults, and other environmental factors. Therefore, anomaly detection is envisioned as a promising approach to deal with unreliable and malicious data injection to improve remote patient monitoring systems and reduce false medical diagnosis. In this context, several data analysis and machine learning tools have been proposed to detect abnormal deviations in WBAN. Nevertheless, no one considers the dynamic context changes of WBAN to provide adaptive and dynamic outlier detection. In addition, most of them ignore the co-existence of strong spatial and temporal correlations between monitored physiological attributes. To this end, we propose a two-level lightweight and adaptive anomaly detection approach to discard false alarms caused by faulty measurements and raise alarms only when a patient seems to be in emergency situations. In the first level, a game-theoretic technique is introduced wherein body-worn sensor nodes exploit the spatiotemporal correlation among readings to locally and adaptively detect anomalous events according to the dynamic context changes of WBAN. In the second level, we apply the Mahalanobis distance in the Local Processing Unit (LPU) which has a global view for multivariate analysis. Our main objective is to ensure a tradeoff between detection accuracy, false positive rates, and network performance while considering the WBAN environment constraints. The proposed approach is evaluated through numerical simulations on a real physiological data set. Simulation results prove the effectiveness of the proposed approach in terms of achieving high detection accuracy with low false alarm rate and energy consumption.",health
10.1016/j.jmoldx.2019.07.002,Journal,Journal of Molecular Diagnostics,scopus,2019-11-01,sciencedirect,Analytical Comparison of Methods for Extraction of Short Cell-Free DNA from Urine,https://api.elsevier.com/content/abstract/scopus_id/85073530416,"Urine cell-free DNA (cfDNA) is a valuable noninvasive biomarker for cancer mutation detection, infectious disease diagnosis (eg, tuberculosis), organ transplantation monitoring, and prenatal screening. Conventional silica DNA extraction does not efficiently capture urine cfDNA, which is dilute (ng/mL) and highly fragmented [30 to 100 nucleotides (nt)]. The clinical sensitivity of urine cfDNA detection increases with decreasing target length, motivating use of sample preparation methods designed for short fragments. We compared the analytical performance of two published protocols (Wizard resin/guanidinium thiocyanate and Q Sepharose), three commercial kits (Norgen, QIAamp, and MagMAX), and an in-house sequence-specific hybridization capture technique. Dependence on fragment length (25 to 150 nt), performance at low concentrations (10 copies/mL), tolerance to variable urine conditions, and susceptibility to PCR inhibition were characterized. Hybridization capture and Q Sepharose performed best overall (60% to 90% recovery), although Q Sepharose had reduced recovery (<10%) of the shortest 25-nt fragment. Wizard resin/guanidinium thiocyanate recovery was dependent on pH and background DNA concentration and was limited to <35%, even under optimal conditions. The Norgen kit led to consistent PCR inhibition but had high recovery of short fragments. The QIAamp and MagMAX kits had minimal recovery of fragments <150 and <80 nt, respectively. Urine cfDNA extraction methods differ widely in ability to capture short, dilute cfDNA in urine; using suboptimal methods may profoundly impair clinical results.",health
10.1016/j.fsi.2019.09.068,Journal,Fish and Shellfish Immunology,scopus,2019-11-01,sciencedirect,Atrazine induces necroptosis by miR-181–5p targeting inflammation and glycometabolism in carp lymphocytes,https://api.elsevier.com/content/abstract/scopus_id/85072783135,"Atrazine (ATR) causes environmental problems and damages the health of fish and aquatic animals. MicroRNAs (miRNAs) play important roles in immune regulation. However, the immunotoxicity mechanism of ATR in fish lymphocytes and the role of miRNA in this process remain unclear. To further study these mechanisms, spleen lymphocytes were exposed to 20, 40 and 60 μg/ml ATR for 18 h. Fluorescence staining and flow cytometry showed that the number of necrotic lymphocytes increased after ATR exposure. Compared with the control group, the mRNA expression of miR-181–5p was inhibited and the mRNA levels of TNF-α and HK2 were increased after ATR exposure. Additionally, the NF-κB inflammatory pathway and the levels of glycometabolism-related genes were upregulated. These results suggest that ATR induces inflammation and elevates glycometabolism in lymphocytes. We further found that the mRNA levels of receptor-interacting serine-threonine kinase 1 (RIP1), receptor-interacting serine-threonine kinase 3 (RIP3), mixed lineage kinase domain-like pseudokinase (MLKL), cylindromatosis (CYLD) and Fas-Associated protein with Death Domain (FADD) and the protein levels of RIP3 and MLKL in the treatment groups were significantly increased compared to those in control group, suggesting that ATR causes lymphocyte necroptosis. We conclude that miR-181–5p plays a key role in necroptosis in carp lymphocytes exposed to ATR by downregulating the expression of HK and TNF-α, which increases the level of glycometabolism and induces the inflammatory response, respectively.",health
10.1016/j.fsi.2019.09.054,Journal,Fish and Shellfish Immunology,scopus,2019-11-01,sciencedirect,Novel pectin isolated from Spirulina maxima enhances the disease resistance and immune responses in zebrafish against Edwardsiella piscicida and Aeromonas hydrophila,https://api.elsevier.com/content/abstract/scopus_id/85072562304,"In this study, we demonstrate the enhanced disease resistance and positive immunomodulation of novel pectin isolated from Spirulina maxima (SmP) in zebrafish model. Zebrafish larvae exposed to SmP had significantly (p < 0.05) higher cumulative percent survival (CPS) at 25 (44.0%) and 50 μg/mL (67.0%) against Edwardsiella piscicida compared to the control. However, upon Aeromonas hydrophila challenge, SmP exposed larvae at 50 μg/mL had slightly higher CPS (33.3%) compared to control group (26.7%). SmP supplemented zebrafish exhibited the higher CPS against E. piscicida (93.3%) and A. hydrophila (60.0%) during the early stage of post-infection (<18 hpi). qRT-PCR results demonstrated that exposing (larvae) and feeding (adults) of SmP, drive the modulation of a wide array of immune response genes. In SmP exposed larvae, up-regulation of the antimicrobial enzyme (lyz: 3.5-fold), mucin (muc5.1: 2.84, muc5.2: 2.11 and muc5.3: 2.40-fold), pro-inflammatory cytokines (il1β: 1.79-fold) and anti-oxidants (cat: 2.87 and sod1: 1.82-fold) were identified. In SmP fed adult zebrafish (gut) showed >2-fold induced pro-inflammatory cytokine (il1β) and chemokines (cxcl18b, ccl34a.4 and ccl34b.4). Overall results confirmed the positive modulation of innate immune responses in larval stage and it could be the main reason for developing disease resistance against E. piscicida and A. hydrophila. Thus, non-toxic, natural and biodegradable SmP could be considered as the potential immunomodulatory agent for sustainable aquaculture.",health
10.1016/j.fsi.2019.08.073,Journal,Fish and Shellfish Immunology,scopus,2019-11-01,sciencedirect,Florfenicol alleviated lipopolysaccharide (LPS)-induced inflammatory responses in Ctenopharyngodon idella through inhibiting toll / NF-κB signaling pathways,https://api.elsevier.com/content/abstract/scopus_id/85072323967,"The present study was conducted to evaluate the anti-inflammatory activity of florfenicol (FFC) against lipopolysaccharide (LPS)-induced inflammatory responses in Ctenopharyngodon idella in vivo and in vitro. Head-kidney (HK) macrophages were pre-treated with 10 μg/mL LPS and then exposed to different concentrations of FFC to determine its in vitro anti-inflammatory activity. Inhibitory effect of FFC on inflammatory mediators TNF-α, IL-6 and IL-1β, as well as LPS-induced nitric oxide (NO) and prostaglandin E 2 (PGE 2) production were assayed by ELISA. The expression level of nitric oxide synthase (iNOS) and cyclooxygenase-2 (COX-2) were investigated by RT-PCR. Expression level of TLR-related genes (TLR1, TLR2, TLR4, TLR7, TLR8) expression, tumor necrosis factor receptor-associated factor 6 (TRAF6), transforming growth factor-b-activated kinase 1 (TAK1), Myeloid differentiation factor 88 (MyD88), nucleus p65, NF-κBα (IκBα) were measured by RT-PCR after grass carp were treated with 50, 100 and 200 mg FFC/kg body weight for 3 days. Results from in vitro tests demonstrated that FFC dose-dependently inhibited LPS-induced inflammatory cytokines TNF-α, IL-6 and IL-1β, inflammatory factors NO and PGE 2 production in macrophages. In addition, iNOS and COX-2 expression levels decreased significantly as compared with LPS treated group. In vivo test demonstrated that treatment with FFC prevented the LPS-induced upregulation of TNF-α, IL-6, IL-1β, NO and PGE 2. The expression level of iNOS, and COX-2 in FFC-treated grass carp were also downregulated as compared with LPS treated fish. Besides, FFC blocked the expression of Toll-like receptor 2 (TLR2) and then suppressed the phosphorylation of nuclear transcription factor-kappa B (NF-κB) p65 and degradation inhibitor of IκBα. Furthermore, administration of FFC inhibited the up-regulation of IRAK4, TRAF6 and TAK1 induced by LPS. These results suggest that the anti-inflammatory properties of FFC might be the results from the inhibition of iNOS, COX-2, IL-6, IL-1β, and TNF-α expressions through the down-regulation of Toll/NF-κB signaling pathways.",health
10.1016/j.enbuild.2019.109440,Journal,Energy and Buildings,scopus,2019-11-01,sciencedirect,A deep reinforcement learning-based autonomous ventilation control system for smart indoor air quality management in a subway station,https://api.elsevier.com/content/abstract/scopus_id/85072289855,"Mechanical ventilation has been widely implemented to alleviate poor indoor air quality (IAQ) in confined underground public facilities. However, due to time-varying IAQ properties that are influenced by unpredictable factors, including outdoor air quality, subway schedules, and passenger volumes, real-time control that incorporates a trade-off between energy saving and IAQ is limited in conventional rule-based and model-based approaches. We propose a data-driven and intelligent approach for a smart ventilation control system based on a deep reinforcement learning (DeepRL) algorithm. This study utilized a deep Q-network (DQN) algorithm of DeepRL to design the ventilation system. The DQN agent was trained in a virtual environment defined by a gray-box model to simulate an IAQ system in a subway station. Performance of the proposed method over three weeks was evaluated by a comprehensive indoor air-quality index (CIAI) and energy consumption under different outdoor air quality scenarios. The results show that the proposed DeepRL-based ventilation control system reduced energy consumption by up to 14.4% for the validation dataset time interval and improved IAQ from unhealthy to acceptable.",health
10.1016/j.ijmedinf.2019.06.022,Journal,International Journal of Medical Informatics,scopus,2019-11-01,sciencedirect,Automatic classification of free-text medical causes from death certificates for reactive mortality surveillance in France,https://api.elsevier.com/content/abstract/scopus_id/85072199154,"Background
                  Mortality surveillance is of fundamental importance to public health surveillance. The real-time recording of death certificates, thanks to Electronic Death Registration System (EDRS), provides valuable data for reactive mortality surveillance based on medical causes of death in free-text format. Reactive mortality surveillance is based on the monitoring of mortality syndromic groups (MSGs). An MSG is a cluster of medical causes of death (pathologies, syndromes or symptoms) that meets the objectives of early detection and impact assessment of public health events. The aim of this study is to implement and measure the performance of a rule-based method and two supervised models for automatic free-text cause of death classification from death certificates in order to implement them for routine surveillance.
               
                  Method
                  A rule-based method was implemented using four processing steps: standardization rules, splitting causes of death using delimiters, spelling corrections and dictionary projection. A supervised machine learning method using a linear Support Vector Machine (SVM) classifier was also implemented. Two models were produced using different features (SVM1 based solely on surface features and SVM2 combining surface features and MSGs classified by the rule-based method as feature vectors). The evaluation was conducted using an annotated subset of electronic death certificates received between 2012 and 2016. Classification performance was evaluated on seven MSGs (Influenza, Low respiratory diseases, Asphyxia/abnormal respiration, Acute respiratory disease, Sepsis, Chronic digestive diseases, and Chronic endocrine diseases).
               
                  Results
                  The rule-based method and the SVM2 model displayed a high performance with F-measures over 0.94 for all MSGs. Precision and recall were slightly higher for the rule-based method and the SVM2 model. An error-analysis shows that errors were not specific to an MSG.
               
                  Conclusion
                  The high performance of the rule-based method and SVM2 model will allow us to set-up a reactive mortality surveillance system based on free-text death certificates. This surveillance will be an added-value for public health decision making.",health
10.1016/j.enconman.2019.111932,Journal,Energy Conversion and Management,scopus,2019-11-01,sciencedirect,Cultural coyote optimization algorithm applied to a heavy duty gas turbine operation,https://api.elsevier.com/content/abstract/scopus_id/85070893013,"In the past decades, the quantity of researches regarding industrial gas turbines (GT) has increased exponentially in terms of number of publications and diversity of applications. The GTs offer high power output along with a high combined cycle efficiency and high fuel flexibility. As consequence, the energy efficiency, the pressure oscillations, the pollutant emissions and the fault diagnosis have become some of the recent concerns related to this type of equipment. In order to solve these GTs related problems and many other real-world engineering and industry 4.0 issues, a set of new technological approaches have been tested, such as the combination of Artificial Neural Networks (ANN) and metaheuristics for global optimization. In this paper, the recently proposed metaheuristic denoted Coyote Optimization Algorithm (COA) is applied to the operation optimization of a heavy duty gas turbine placed in Brazil and used in power generation. The global goal is to find the best valves setup to reduce the fuel consumption while coping with environmental and physical constraints from its operation. In order to treat it as an optimization problem, an integrated simulation model is implemented from original data-driven models and others previously proposed in literature. Moreover, a new version of the COA that links some concepts from Cultural Algorithms (CA) is proposed, which is validated under a set of benchmarks functions from the Institute of Electrical and Electronics Engineers (IEEE) Congress on Evolutionary Computation (CEC) 2017 and tested to the GT problem. The results show that the proposed Cultural Coyote Optimization Algorithm (CCOA) outperforms its counterpart for benchmark functions. Further, non-parametric statistical significance tests prove that the CCOA’s performance is competitive when compared to other state-of-the-art metaheuristics after a set of experiments for five case studies. In addition, the convergence analysis shows that the cultural mechanism employed in the CCOA has improved the COA balance between exploration and exploitation. As a result, the CCOA can improve the current GT operation significantly, reducing the fuel consumption up to 
                        
                           3.6
                           %
                        
                      meanwhile all constraints are accomplished.",health
10.1016/j.snb.2019.126851,Journal,"Sensors and Actuators, B: Chemical",scopus,2019-11-01,sciencedirect,A digital quantification method for the detection of biomarkers on a microfluidic array chip,https://api.elsevier.com/content/abstract/scopus_id/85069665496,"In this study, a digital quantification method is proposed for the detection of biomarkers. The proposed method is applied to detect alpha-fetoprotein (AFP), which is a biomarker of hepatocellular carcinoma. This digital quantification method is implemented with modified magnetic microparticles (MMPs) and a microfluidic array chip. The MMPs are modified with 186 ± 6 β-galactosidases (β-gal) and 117 ± 8 anti-human AFP antibodies (capture Ab) with a high capture efficiency and catalytic ability. The microfluidic array chip is modified with an AFP monoclonal antibody (coating Ab). The AFP captured by the modified MMPs is distributed in microwells, obeying the Poisson distribution. The modified MMPs that captured the AFP are captured by a coating Ab and anchored in the microwells, while the modified MMPs that did not capture the AFP are removed by a washing process. Therefore, the AFP can be detected by this digital quantification method with high sensitivity, selectivity and anti-interference ability. There is a linear relationship between –ln (1 - proportion of positive microwell (PPM)) and the AFP concentrations from 1 to 100 fg/mL, and the lowest AFP concentration that can be quantified is 1 fg/mL. This digital quantification method can also be used for real serum sample analysis, which holds great potential for the early diagnosis of cancer and therapeutic management.",health
10.1016/j.cyto.2019.154767,Journal,Cytokine,scopus,2019-11-01,sciencedirect,Effect of proinflammatory cytokines on endometrial collagen and metallopeptidase expression during the course of equine endometrosis,https://api.elsevier.com/content/abstract/scopus_id/85068091878,"Equine endometrosis (endometrial fibrosis) is a degenerative chronic process that occurs in the uterus of the mare and disturbs proper endometrial function. Fibrosis is attributed to excessive deposition of extracellular matrix (ECM) components. The turnover of ECM is mediated by matrix metallopeptidases (MMP). Previously, it was shown that cytokines modulate MMP expression in other tissues and may regulate fibrosis indirectly by attracting inflammatory cells to the site of inflammation and directly on various tissues. However, the regulation of MMP expression in equine endometrosis is still relatively unknown. Thus, our aim was to determine if interleukin (IL)-1β and IL-6 regulate ECM, MMPs, or their inhibitors (TIMPs) and whether this regulation differs during endometrosis in the mare. Endometrial fibrosis was divided into four categories according to severity: I (no degenerative changes), IIA (mild degenerative changes), IIB (moderate degenerative changes) and III (severe degenerative changes) according to Kenney and Doig classification. Endometrial explants (n = 5 for category I, IIA, IIB and III according to Kenney and Doig) were incubated with IL-1β (10 ng/ml) or IL-6 (10 ng/ml) for 24 h. Secretion and mRNA transcription of collagen type 1 (Col1a1) and type 3 (Col3a1), fibronectin (Fn1), Mmp-1, -2, -3, -9, -13, Timp-1, -2 were analyzed by real-time PCR and ELISA, respectively. IL-1β treatment up-regulated secretion of COL1, MMP-2, TIMP1, and TIMP2 in category I endometrial fibrosis tissues (P < 0.05). IL-6 treatment up-regulated secretion of ECM, MMP-2, and MMP-3 and down-regulated secretion of MMP-9 in category I tissues (P < 0.05). In category IIA tissues, IL-1β and IL-6 treatment up-regulated secretion of COL3 (P < 0.05; P < 0.05), and IL-6 treatment also down-regulated secretion of MMP-9 (P < 0.05). In category IIB tissues, IL-1β treatment down-regulated secretion of COL3 (P < 0.05) and up-regulated secretion of MMP-3 (P < 0.01), while IL-6 treatment up-regulated secretion of MMP-3, MMP-9, and MMP-13 (P < 0.05). In category III tissues, IL-1β treatment up-regulated secretion of COL1, MMP-1, MMP-9 and TIMP-2 (P < 0.05), and IL-6 up-regulated secretion of all investigated ECM components, MMPs and TIMPs. These results reveal that the effect of IL-1β and IL-6 on equine endometrium differs depending on the severity of endometrial fibrosis. Our findings indicate an association between inflammation and development of endometrosis through the effect of IL-1β and IL-6 on expression of ECM components, MMPs, and TIMPs in the mare.",health
10.1016/j.msec.2019.109869,Journal,Materials Science and Engineering C,scopus,2019-11-01,sciencedirect,Selective detection of Escherichia coli caused UTIs with surface imprinted plasmonic nanoscale sensor,https://api.elsevier.com/content/abstract/scopus_id/85067361200,"The aim of the present study was developing a surface plasmon resonance (SPR) nanosensor to detect Escherichia coli (E. coli) for the diagnosis of urinary tract infections by using surface imprinted Au nanoparticles (AuNPs) as a recognition element. In order to realize imprinting, Cu(II) ions were used to provide interaction between E. coli cell wall and amine functionalized AuNPs forming cavities on the surface of nanosensor. E. coli surface imprinted AuNPs nanosensor was characterized by using ellipsometry, contact angle measurement, scanning electron microscopy (SEM) and atomic force microscopy (AFM). The real time detection of E. coli was evaluated by using E. coli suspensions in the concentration range of 1 × 103–0.5 × 101 CFU/mL. Combination of the signal enhancing properties of AuNPs and surface imprinting technique provided ultrasensitive detection with a comparatively low limit of detection value (1 CFU/mL) to the SPR nanosensor system. Selectivity experiments were performed by using Staphylococcus aureus, Klebsiella pneumoniae and Pseudomonas aeruginosa. The highest response was recorded for E. coli, as expected. Additionally, the recognition of E. coli even in a complex medium such as artificial urine sample was achieved by the developed nanosensing system. Also, this chip can be used repeatedly without seen signal reducing for four-time consecutive. In the view of these results, it was emphasized that this novel sensing system has a potency for the selective, very sensitive, rapid and real time detection of causative agent in order to diagnose E. coli caused infections.",health
10.1016/j.inffus.2019.02.008,Journal,Information Fusion,scopus,2019-11-01,sciencedirect,iFusion: Towards efficient intelligence fusion for deep learning from real-time and heterogeneous data,https://api.elsevier.com/content/abstract/scopus_id/85062022353,"Deep learning has shown great strength in many fields and has allowed people to live more conveniently and intelligently. However, deep learning requires a considerable amount of uniform training data, which introduces difficulties in many application scenarios. On the one hand, in real-time systems, training data are constantly generated, but users cannot immediately obtain this vast amount of training data. On the other hand, training data from heterogeneous sources have different data formats. Therefore, existing deep learning frameworks are not able to train all data together. In this paper, we propose the iFusion framework, which achieves efficient intelligence fusion for deep learning from real-time data and heterogeneous data. For real-time data, we train only newly arrived data to obtain a new discrimination model and fuse the previously trained models to obtain the discrimination result. For heterogeneous data, different types of data are trained separately; then, we fuse the different discrimination models so that it is not necessary to consider heterogeneous data formats. We use a method based on Dempster-Shafer theory (DST) to fuse the discrimination models. We apply iFusion to the deep learning of medical image data, and the results of the experiments show the effectiveness of the proposed method.",health
10.1016/j.ecoenv.2019.109447,Journal,Ecotoxicology and Environmental Safety,scopus,2019-10-30,sciencedirect,Selenium decreases methylmercury and increases nutritional elements in rice growing in mercury-contaminated farmland,https://api.elsevier.com/content/abstract/scopus_id/85069005684,"Methylmercury (MeHg) in rice grains grown in Hg-contaminated areas has raised environmental health concerns. Pot experiments found that selenium (Se) could reduce MeHg levels in rice grains. However, relatively high levels of Se (up to 6 mg/kg) were applied in these pot experiments, which may have adverse effects on the soil ecology due to the toxicity of Se. The aims of this work were thus to study 1) the effect of low levels of Se on the accumulation and distribution of Hg, especially MeHg, in rice plants grown in a real Hg-contaminated paddy field and 2) the effect of Se treatment on Se and other nutritional elements (e.g., Cu, Fe, Zn) in grains. A field study amended with different levels of Se was carried out in Hg-contaminated paddy soil in Qingzhen, Guizhou, China. The levels of MeHg and total Hg were studied using cold vapor atomic fluorescence spectrometry (CVAFS) and inductively coupled plasma mass spectrometry (ICP-MS). The distribution and relative quantification of elements in grains were examined by synchrotron radiation X-ray fluorescence analysis (SR-XRF). This field study showed that low levels of Se (0.5 μg/mL, corresponding to 0.15 mg Se/kg soils) could significantly reduce total Hg and MeHg in rice tissues. Se treatment also reduced Hg distribution in the embryo and endosperm and increased the levels of Fe, Cu, Zn and Se in grains and especially embryos. This field study implied that treatment with an appropriate level of Se is an effective approach to not only decrease the level of MeHg but to also increase the levels of nutritional elements such as Fe, Cu, Zn and Se in rice grains, which could bring beneficial effects for rice-dependent residents living in Hg-contaminated areas.",health
10.1016/j.brainres.2019.146341,Journal,Brain Research,scopus,2019-10-15,sciencedirect,Automatic detection and sonification of nonmotor generalized onset epileptic seizures: Preliminary results,https://api.elsevier.com/content/abstract/scopus_id/85069698124,"Long-term video-EEG monitoring has improved diagnosis and treatment of epilepsy, especially in children. However, the amount of data neurophysiologists must analyze has grown remarkably.
                  The main purpose of this paper is to provide a diagnostic support to speed up and ease EEG interpretation for a specific application concerning absence seizures, a type of non-motor generalized epileptic seizures.
                  The proposed method consists of a pre-processing step where signals are filtered through the Stationary Wavelet Transform for the reduction of possible artefacts. Subsequently, a supervised automatic classification method is implemented for seizure detection, based on the Support Vector Machine Fine Gaussian method. Finally, a post-processing step is implemented in which spatial and temporal thresholds are defined for both online and offline application.
                  In addition, a method that applies sonification techniques is developed. Sonification techniques could speed up the process of interpreting information, allowing rapid clinical intervention and a continuous monitoring of the event.
                  The dataset consists of 30 EEG recordings performed in 24 children with absence seizures, clinically evaluated at the Meyer Children's Hospital in Firenze, Italy.
                  The method shows encouraging results both in terms of balanced accuracy (about 96%) and latency times (1.25 s on average), which might make it suitable for online clinical trials. In fact, it was implemented in the perspective of a possible real-time application in clinical practice.",health
10.1016/j.enconman.2019.111793,Journal,Energy Conversion and Management,scopus,2019-10-15,sciencedirect,Deep residual network based fault detection and diagnosis of photovoltaic arrays using current-voltage curves and ambient conditions,https://api.elsevier.com/content/abstract/scopus_id/85068739054,"Automatic fault detection and diagnosis techniques for photovoltaic arrays are crucial to promote the efficiency, reliability and safety of photovoltaic systems. In recent decades, many conventional artificial intelligence approaches have been successfully applied to automatically establish fault detection and diagnosis model using fault data samples, but most of them rely on manual feature extraction or expert knowledge to build diagnosis models, which is inefficient and may ignore some potential useful features. In addition, they usually use shallow neural networks with limited performance. Addressing the issues, this paper proposes a novel intelligent fault detection and diagnosis method for photovoltaic arrays based on a newly designed deep residual network model trained by the adaptive moment estimation deep learning algorithm, which can automatically extract features from raw current-voltage curves and ambient irradiance and temperature, and effectively improve the performance with a deeper network. In order to validate the proposed fault diagnosis model, a Simulink based simulation model is designed for a real laboratory photovoltaic array, and both fault simulation and real experiments are carried out to obtain simulation and experimental fault datasets. Furthermore, two other popular deep learning based models are used for comparison, including convolution neural network and convolutional auto-encoder. Both of simulation and real experimental comparison results demonstrate that the proposed deep residual network based method achieves high and best overall performance in terms of accuracy, generalization performance, reliability and training efficiency.",health
10.1016/j.bios.2019.111549,Journal,Biosensors and Bioelectronics,scopus,2019-10-01,sciencedirect,Efficient electron-mediated electrochemical biosensor of gold wire for the rapid detection of C-reactive protein: A predictive strategy for heart failure,https://api.elsevier.com/content/abstract/scopus_id/85071785022,"C-reactive protein (CRP) is considered a promising biomarker for the rapid and high-throughput real-time monitoring of cardiovascular disease and inflammation in unprocessed clinical samples. Implementation of this monitoring would enable various transformative biomedical applications. We have fabricated a highly specific sensor chip to detect CRP with a detection limit of 2.25 fg/mL. The protein was immobilized on top of a gold (Au) wire/polycarbonate (PC) substrate using 1-ethyl-3-(3-dimethylamino-propyl) carbodiimide hydrochloride/N-hydroxy succinimide-activated 3-mercaptoproponic acid (MPA) as a self-assembled monolayer agent and bovine serum albumin (BSA) as a blocking agent. In contrast to the bare PC substrate, the CRP/BSA/anti-CRP/MPA/Au substrate exhibited a considerably high electrochemical signal toward CRP. The influence of the experimental parameters on CRP detection was assessed via various analysis methods, and these parameters were then optimized. The linear dynamic range of the CRP was 5–220 fg/mL for voltammetric and impedance analysis. Morever, the strategy exhibited high selectivity against various potential interfering species and was capable of directly probing trace amounts of the target CRP in human serum with excellent selectivity. The analytical assay based on the CRP/BSA/anti-CRP/MPA/Au substrate could be exploited as a potentially useful tool for detecting CRP in clinical samples.",health
10.1016/j.jacr.2019.06.009,Journal,Journal of the American College of Radiology,scopus,2019-10-01,sciencedirect,Bending the Artificial Intelligence Curve for Radiology: Informatics Tools From ACR and RSNA,https://api.elsevier.com/content/abstract/scopus_id/85071398084,"Artificial intelligence (AI) will reshape radiology over the coming years. The radiology community has a strong history of embracing new technology for positive change, and AI is no exception. As with any new technology, rapid, successful implementation faces several challenges that will require creation and adoption of new integration technology. Use cases important to real-world application of AI are described, including clinical registries, AI research, AI product validation, and computer assistance for radiology reporting. Furthermore, the informatics technologies required for successful implementation of the use cases are described, including open Computer-Assisted Radiologist Decision Support, ACR Assist, ACR Data Science Institute use cases, common data elements (radelement.org), RadLex (radlex.org), LOINC/RSNA RadLex Playbook (loinc.org), and Radiology Report Templates (radreport.org).",health
10.1016/j.cmpb.2019.105012,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-10-01,sciencedirect,Learning from adversarial medical images for X-ray breast mass segmentation,https://api.elsevier.com/content/abstract/scopus_id/85070217245,"Background and Objective
                  Simulation of diverse lesions in images is proposed and applied to overcome the scarcity of labeled data, which has hindered the application of deep learning in medical imaging. However, most of current studies focus on generating samples with class labels for classification and detection rather than segmentation, because generating images with precise masks remains a challenge. Therefore, we aim to generate realistic medical images with precise masks for improving lesion segmentation in mammagrams.
               
                  Methods
                  In this paper, we propose a new framework for improving X-ray breast mass segmentation performance aided by generated adversarial lesion images with precise masks. Firstly, we introduce a conditional generative adversarial network (cGAN) to learn the distribution of real mass images as well as a mapping between images and corresponding segmentation masks. Subsequently, a number of lesion images are generated from various binary input masks using the generator in the trained cGAN. Then the generated adversarial samples are concatenated with original samples to produce a dataset with increased diversity. Furthermore, we introduce an improved U-net and train it on the previous augmented dataset for breast mass segmentation.
               
                  Results
                  To demonstrate the effectiveness of our proposed method, we conduct experiments on publicly available mammogram database of INbreast and a private database provided by Nanfang Hospital in China. Experimental results show that an improvement up to 7% in Jaccard index can be achieved over the same model trained on original real lesion images.
               
                  Conclusions
                  Our proposed method can be viewed as one of the first steps toward generating realistic X-ray breast mass images with masks for precise segmentation.",health
10.1016/j.cie.2019.07.042,Journal,Computers and Industrial Engineering,scopus,2019-10-01,sciencedirect,Real-time quality monitoring and diagnosis for manufacturing process profiles based on deep belief networks,https://api.elsevier.com/content/abstract/scopus_id/85070093845,"A large number of real-time quality data are collected through various sensors in the manufacturing process. However, most process data are high-dimension, nonlinear and high-correlated, so that it is difficult to model the process profiles, which restricts the application of conventional statistical process control technique. Motivated by the powerful ability of deep belief network (DBN) to extract the essential features of input data, this paper develops a real-time quality monitoring and diagnosis scheme for manufacturing process profiles based on DBN. The profiles collected from a manufacturing process are mapped into quality spectra. A novel DBN recognition model for quality spectra is established in the off-line learning phase, which can be applied to monitor and diagnose the process profiles in the on-line phase. The effectiveness of DBN recognition model for manufacturing process profiles is demonstrated by simulation experiment, and a real injection molding process example is applied to analyze the performance. The results show that the proposed DBN model outperforms alternative methods.",health
10.1016/j.asoc.2019.105650,Journal,Applied Soft Computing Journal,scopus,2019-10-01,sciencedirect,Unsupervised anomaly detection in unmanned aerial vehicles,https://api.elsevier.com/content/abstract/scopus_id/85069952423,"A real-time anomaly detection solution indicates a continuous stream of operational and labelled data that must satisfy several resources and latency requirements. Traditional solutions to the problem rely heavily on well-defined features and prior supervised knowledge, where most techniques refer to hand-crafted rules derived from known conditions. While successful in controlled situations, these rules assume that good data is available for them to detect anomalies; indicating that these rules will fail to generalise beyond known scenarios.
                  To investigate these issues, current literature is examined for solutions that can be used to detect known and unknown anomalous instances whilst functioning as an out-of-the-box approach for efficient decision-making. The applicability of the isolation forest is discussed for engineering applications using the Aero-Propulsion System Simulation dataset as a benchmark where it is shown to outperform other unsupervised distance-based approaches. Also, the authors have carried out real-time experiments on an unmanned aerial vehicle to highlight further applications of the method. Finally, some conclusions are drawn concerning its simplicity and robustness in handling diagnostic problems.",health
10.1016/j.cmpb.2019.104993,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-10-01,sciencedirect,TTTS-GPS: Patient-specific preoperative planning and simulation platform for twin-to-twin transfusion syndrome fetal surgery,https://api.elsevier.com/content/abstract/scopus_id/85069856373,"Twin-to-twin transfusion syndrome (TTTS) is a serious condition that may occur in pregnancies when two or more fetuses share the same placenta. It is characterized by abnormal vascular connections in the placenta that cause blood to flow unevenly between the babies. If left untreated, perinatal mortality occurs in 90% of cases, whilst neurological injuries are still present in TTTS survivors. Minimally invasive fetoscopic laser surgery is the standard and optimal treatment for this condition, but is technically challenging and can lead to complications. Acquiring and maintaining the required surgical skills need consistent practice, and a steep learning curve. An accurate preoperative planning is thus vital for complex TTTS cases. To this end, we propose the first TTTS fetal surgery planning and simulation platform. The soft tissue of the mother, the uterus, the umbilical cords, the placenta and its vascular tree are segmented and registered automatically from magnetic resonance imaging and 3D ultrasound using computer vision and deep learning techniques. The proposed state-of-the-art technology is integrated into a flexible C++ and MITK-based application to provide a full exploration of the intrauterine environment by simulating the fetoscope camera as well as the laser ablation, determining the correct entry point, training doctors’ movements and trajectory ahead of operation, which allows improving upon current practice. A comprehensive usability study is reported. Experienced surgeons rated highly our TTTS planner and simulator, thus being a potential tool to be implemented in real and complex TTTS surgeries.",health
10.1016/j.fsi.2019.07.064,Journal,Fish and Shellfish Immunology,scopus,2019-10-01,sciencedirect,Screening of immuno-modulatory potential of different herbal plant extracts using striped catfish (Pangasianodon hypophthalmus) leukocyte-based in vitro tests,https://api.elsevier.com/content/abstract/scopus_id/85069843218,"Many medicinal plants have been shown to possess biological effects, including immuno-modulatory activities on human and other mammals. However, studies about the potential mechanisms of plant extracts on the humoral and tissular immunities in fish have received less attention. This study aimed to screen the immunestimulating properties of 20 ethanol plant extracts on striped catfish Pangasianodon hypophthalmus leukocytes. The peripheral blood mononuclear cells (PBMCs) and head kidney leukocytes (HKLs) of striped catfish (50 ± 5 g per fish) were stimulated at 10 and 100 μg of each plant extract per mL of cell culture medium. Several humoral immune parameters (lysozyme, complement and total immunoglobulin) were examined at 24-h post stimulation (hps). Furthermore, the responses of four cytokine genes, namely il1β, ifrγ 2a and b, and mhc class II were assessed by quantitative real-time PCR at 6, 12, 24, and 48 hps. The results showed that lysozyme, complement as well as total immunoglobulin levels in both PBMCs and HKLs were regulated by some of the plant extracts tested in a concentration-dependent manner; some plant extracts induced the highest immune responses at the low dose (10 μg mL−1) while others were more efficient at high dose (100 μg mL−1). Among the extracts, five extracts including garlic Allium sativum L. (As), neem Azadirachta indica A. Juss (Ai), asthma-plant Euphorbia hirta L. (Eh), bhumi amla Phyllanthus amarus Schum. et Thonn (Pa), and ginger Zingiber officinale Rosc (Zo) induced significant changes in the expression of pro-inflammatory cytokine (il1β), antiviral cytokines (ifrγ 2a and b) and adaptive immune cytokine (mhc class II) in striped catfish cells. Pa always modulated the strongest expression of the four cytokines in PBMCs and HKLs over the whole experimental period (p < 0.05), whereas Zo did not stimulate the mhc class II expression in striped catfish leukocytes throughout experimental periods. These in vitro results demonstrated that some plant extracts could differently modulate great potential immune response in fish, supporting their applications in further in vivo experiments.",health
10.1016/j.ijcard.2019.05.070,Journal,International Journal of Cardiology,scopus,2019-10-01,sciencedirect,Best practices in digital health literacy,https://api.elsevier.com/content/abstract/scopus_id/85067503480,"The connection between health literacy and health outcomes includes access and utilization of healthcare services, patient/provider interaction and self-care. Digital approaches can be designed to simplify or expand on a concept, test for understanding, and do not have a time constraint. New technologies, such as artificial intelligence and machine learning, virtual and augmented reality, and blockchain can move the role of technology beyond data collection to a more integrated system. Rather than being a passive participant, digital solutions provide the opportunity for the individual to be an active participant in their health. These solutions can be delivered in a way that builds or enhances the individual's belief that the plan will be successful and more confidence that they can stick with it. Digital solutions allow for the delivery of multi-media education, such as videos, voice, and print, at different reading levels, in multiple languages, using formal and informal teaching methods. By giving the patient a greater voice and empowering them to be active participants in their care, they can develop their decision making and shared decision making skills. The first step in our health literacy instructional model is to address the emotional state of the person. Once the emotional state has been addressed, and an engagement strategy has been deployed the final phase is the delivery of an educational solution. While a clear definition of health literacy and an instructional model are important, further research must be done to continually determine more effective ways to incorporate health technology in the process of improving health outcomes.",health
10.1016/j.ijadhadh.2019.05.002,Journal,International Journal of Adhesion and Adhesives,scopus,2019-10-01,sciencedirect,Electromechanical admittance based integrated health monitoring of adhesive bonded beams using surface bonded piezoelectric transducers,https://api.elsevier.com/content/abstract/scopus_id/85066737182,"Adhesive bonded structures are gaining attention in engineering and research communities due to their advantages over conventional joining methods. Non-destructive testing and health monitoring of adhesive bonded structures are challenges requiring focused research. Piezoelectric transducers are used for the actuation and sensing purposes in structural health monitoring procedures. These transducers which are adhesive bonded, get disbonds from the host structure during their service period. Presence of a transducer disbond between the transducer and host structure can be inferred as structural disbond and may produce false alarms. It is necessary that both the types of disbonds are distinguished from each other so that an integrated health monitoring procedure can be developed. This paper presents the use of electromechanical admittance technique for the integrated health monitoring of adhesive bonded beams using surface bonded piezoelectric patches. Electromechanical admittance model for one degree of freedom system is revisited and used as a governing model for the adhesive bonded beams. The analytical results are validated with simulations and experimental results. Conventional non-destructive techniques like X-ray and ultrasonics testing are also employed to justify the use of the electromechanical admittance scheme for disbond detection in the adhesive bonded structures. The electromechanical admittance values (both real and imaginary parts) for three levels of transducer and structural disbonds along with the combination cases are collected from the precision impedance analyzer in a frequency range of 1–30 kHz. Numerical study of coupled-domain harmonic analysis is utilized to study the disbond cases. It is shown that the directional shifting of the electromechanical admittance spectrum distinguishes both the types of disbonds. In addition, artificial neural networks are also employed on electromechanical admittance data from simulations and experiments to predict disbond type and the severity levels.",health
10.1016/j.inffus.2018.11.016,Journal,Information Fusion,scopus,2019-10-01,sciencedirect,Revealing causality between heterogeneous data sources with deep restricted Boltzmann machines,https://api.elsevier.com/content/abstract/scopus_id/85061035830,"In a number of real life applications, scientists do not have access to temporal data, since budget for data acquisition is always limited. Here we challenge the problem of causal inference between groups of heterogeneous non-temporal observations obtained from multiple sources. We consider a family of probabilistic algorithms for causal inference based on an assumption that in case where X causes Y, P(X) and P(Y|X) are statistically independent. For a number of real world applications, deep learning methods were reported to achieve the most accurate empirical performance, what motivates us to use deep Boltzmann machines to approximate the marginal and conditional probabilities of heterogeneous observations as accurate as possible.
                  We introduce a novel algorithm to infer causal relationships between blocks of variables. The proposed method was tested on a benchmark of multivariate cause-effect pairs. We show by our experiments that our method achieves the state-of-the-art empirical accuracy, and sometimes outperforms the state-of-the-art methods. An important part of our contribution is an application of the proposed algorithm to an original medical data set, where we explore relations between alimentary patters, human gut microbiome composition, and health status.",health
10.1016/j.jep.2019.111975,Journal,Journal of Ethnopharmacology,scopus,2019-09-15,sciencedirect,Danhong Huayu Koufuye prevents venous thrombosis through antiinflammation via Sirtuin 1/NF-κB signaling pathway,https://api.elsevier.com/content/abstract/scopus_id/85066272741,"Ethnopharmacological relevance
                  Danhong Huayu Koufuye (DHK), a compound traditional Chinese medicine, is composed of Salvia miltiorrhiza radix (Salvia miltiorrhiza Bge.), Angelicae Sinensis radix (Angelicae Sinensis (Oliv.) Diels.), Chuanxiong rhizoma (Ligusticum chuanxiong Hort.), Persicae semen (Prunus persica (L.) Batsch), Carthami flos (Carthamus tinctorius L.), Bupleuri radix (Bupleurum chinense DC.) and Aurantii fructus (Citrus aurantium L.). DHK prevents deep vein thrombosis (DVT) through antiinflammation. However, the antiinflammatory mechanism of DHK is still unknown.
               
                  Objective
                  The aim of this study was to evaluate whether DHK prevented venous thrombosis through antiinflammation via Sirtuin 1 (SIRT1)/NF-κB signaling pathway.
               
                  Methods
                  Inferior vena cava (IVC) stenosis-induced DVT rat model was established. Rats were administered with DHK (1.6, 3.2 or 6.4 mL/kg/d, p.o.), heparin (200 U/kg/d, i.v.), clopidogrel (25 mg/kg/d, p.o.), resveratrol (50 mg/kg/d, p.o.) or vehicle (p.o.) once daily for two days. Blood coagulation, blood fibrinolysis, blood viscosity, blood cell counts and platelet activity were evaluated. Serum levels of inflammatory cytokines were analyzed by enzyme-linked immunosorbent assay. Pathological changes were observed by hematoxylin-eosin (HE) staining. Protein expressions in thrombosed IVCs were evaluated by Western blot and/or immunofluorescence analyses. SIRT1 mRNA expression was analyzed by real-time quantitative polymerase chain reaction. Besides, SIRT1-specific inhibitor EX527 was pretreated to confirm the role of SIRT1/NF-κB signaling pathway in the antithrombotic effect of DHK.
               
                  Results
                  DHK remarkably prevented DVT. DHK had no effects on blood coagulation, blood fibrinolysis, blood viscosity, blood cell counts or platelet activity. But DHK significantly up-regulated protein and mRNA expressions of SIRT1, and reduced leukocytes infiltration into thrombus and vein wall, serum levels of inflammatory cytokines, and protein expressions of acetylated p65 (Ace-p65), phosphorylated p65 (p-p65) and tissue factor (TF). Moreover, the antithrombotic effect of DHK was significantly abolished by EX527.
               
                  Conclusion
                  DHK may prevent DVT by inhibiting inflammation via SIRT1/NF-κB signaling pathway.",health
10.1016/j.neucom.2019.05.041,Journal,Neurocomputing,scopus,2019-09-10,sciencedirect,Breast cancer diagnosis through active learning in content-based image retrieval,https://api.elsevier.com/content/abstract/scopus_id/85065842242,"One of the cornerstones of content-based image retrieval (CBIR) for medical image diagnosis is to select the images that present higher similarity with a given query image. Different from previous literature efforts, the present work aims to seamlessly fuse a powerful machine learning strategy based on the active learning paradigm, in order to obtain greater efficacy regarding similarity queries in medical CBIR systems. To do so, we propose a new approach, named as Medical Active leaRning and Retrieval (MARRow) to aid the breast cancer diagnosis. It enables to deal with more feasible strategies, specifically for the medical context and its inherent constraints. We also proposed an active learning strategy to select a small set of more informative images, considering selection criteria based on not only similarity, but also on certain degrees of diversity and uncertainty. To validate our proposed approach, we performed experiments using public medical image datasets, different descriptors for each one and compared our approach against four widely applied and well-known literature approaches, such as: Traditional CBIR without relevance feedback strategies, Query Point Movement Strategy (QPM), Query Expansion (QEX) and SVM Active Learning (SVM-AL). From the experiments, we can observe that our approach presents a strong performance over state-of-the-art ones reaching a precision gain of up to 87.3%. MARRow also presented a well-suited and consistent increasing rate along the learning iterations. Moreover, our approach can significantly minimize the expert’s involvement in the analysis and annotation process (reducing up to 88%). The results testify that MARRow improves the precision of the similarity queries. It is capable to explore at the maximum the experts’ intentions, which are captured during the relevance feedback process, incrementally improving the learning model. Therefore, our approach can be suitable and applied in challenging processes, such as real and medical contexts, enhancing medical decision support systems (e.g. breast cancer diagnosis).",health
10.1016/B978-0-12-814725-2.00015-7,Book,Riemannian Geometric Statistics in Medical Image Analysis,scopus,2019-09-04,sciencedirect,Efficient recursive estimation of the Riemannian barycenter on the hypersphere and the special orthogonal group with applications,https://api.elsevier.com/content/abstract/scopus_id/85080840239,"Finding the Riemannian barycenter (center of mass) or the Fréchet mean (FM) of manifold-valued data sets is a commonly encountered problem in a variety of fields of science and engineering, including, but not limited to, medical image computing, machine learning, and computer vision. For example, it is encountered in tasks such as atlas construction, clustering, principal geodesic analysis, and so on. Traditionally, algorithms for computing the FM of the manifold-valued data require that the entire data pool be available a priori and not incrementally. Thus, when encountered with new data, the FM needs to be recomputed over the entire pool, which can be computationally and storage inefficient. A computational and storage efficient alternative is to consider a recursive algorithm for computing the FM, which simply updates the previously computed FM when presented with a new data sample. In this chapter we present such an alternative called the inductive/incremental Fréchet mean estimator (iFME) for data residing on two well-known Riemannian manifolds, namely the hypersphere 
                     S
                     (
                     d
                     )
                   and the special orthogonal group 
                     
                        SO
                     
                     (
                     d
                     )
                  . We prove the asymptotic convergence of iFME to the true FM of the underlying distribution from which the data samples were drawn. Further we present several experiments demonstrating the performance iFME on synthetic and real data sets.",health
10.1016/j.jacr.2019.04.005,Journal,Journal of the American College of Radiology,scopus,2019-09-01,sciencedirect,An Initiative to Reduce Unnecessary Gadolinium-Based Contrast in Multiple Sclerosis Patients,https://api.elsevier.com/content/abstract/scopus_id/85069944004,"Objective
                  Patients with multiple sclerosis (MS) routinely undergo serial contrast-enhanced MRIs. Given concerns regarding tissue deposition of gadolinium-based contrast agents (GBCAs) and evidence that enhancement of lesions is only seen in patients with new disease activity on noncontrast imaging, we set out to implement a prospective quality improvement project whereby intravenous contrast would be reserved only for patients with evidence of new disease activity on noncontrast images.
               
                  Methods
                  To prospectively implement such a protocol, we leveraged our in-house computer-assisted detection (CAD) software and 3-D laboratory radiology technologists to perform real-time preliminary assessments of the CAD-processed T2 fluid attenuated inversion recovery (FLAIR) noncontrast images as a basis for deciding whether to inject contrast. Before implementation, we held multidisciplinary meetings with neurology, neuroradiology, and MR technologists and distributed surveys to objectively assess opinions and obstacles to clinical implementation. We evaluated reduction in GBCA utilization and technologist performance relative to final neuroradiologist interpretations.
               
                  Results
                  During a 2-month trial period, 153 patients were imaged under the new protocol. Technologists using the CAD software were able to identify patients with new or enlarging lesions on FLAIR images with 95% accuracy and 97% negative predictive value relative to final neuroradiologist interpretations, which allowed us to avoid the use of contrast and additional imaging sequences in 87% of patients.
               
                  Discussion
                  A multidisciplinary effort to implement a quality improvement project to limit contrast in MS patients receiving follow-up MRIs allowed for improved safety and cost by targeting patients that would benefit from the use of intravenous contrast in real-time.",health
10.1016/j.jacr.2019.05.047,Journal,Journal of the American College of Radiology,scopus,2019-09-01,sciencedirect,"Strengths, Weaknesses, Opportunities, and Threats Analysis of Artificial Intelligence and Machine Learning Applications in Radiology",https://api.elsevier.com/content/abstract/scopus_id/85069706449,"Currently, the use of artificial intelligence (AI) in radiology, particularly machine learning (ML), has become a reality in clinical practice. Since the end of the last century, several ML algorithms have been introduced for a wide range of common imaging tasks, not only for diagnostic purposes but also for image acquisition and postprocessing. AI is now recognized to be a driving initiative in every aspect of radiology. There is growing evidence of the advantages of AI in radiology creating seamless imaging workflows for radiologists or even replacing radiologists. Most of the current AI methods have some internal and external disadvantages that are impeding their ultimate implementation in the clinical arena. As such, AI can be considered a portion of a business trying to be introduced in the health care market. For this reason, this review analyzes the current status of AI, and specifically ML, applied to radiology from the scope of strengths, weaknesses, opportunities, and threats (SWOT) analysis.",health
10.1016/j.clineuro.2019.105442,Journal,Clinical Neurology and Neurosurgery,scopus,2019-09-01,sciencedirect,Artificial intelligence for assisting diagnostics and assessment of Parkinson's disease—A review,https://api.elsevier.com/content/abstract/scopus_id/85069629950,"Artificial intelligence, specifically machine learning, has found numerous applications in computer-aided diagnostics, monitoring and management of neurodegenerative movement disorders of parkinsonian type. These tasks are not trivial due to high inter-subject variability and similarity of clinical presentations of different neurodegenerative disorders in the early stages. This paper aims to give a comprehensive, high-level overview of applications of artificial intelligence through machine learning algorithms in kinematic analysis of movement disorders, specifically Parkinson’s disease (PD). We surveyed papers published between January 2007 and January 2019, within online databases, including PubMed and Science Direct, with a focus on the most recently published studies. The search encompassed papers dealing with the implementation of machine learning algorithms for diagnosis and assessment of PD using data describing motion of upper and lower extremities. This systematic review presents an overview of 48 relevant studies published in the abovementioned period, which investigate the use of artificial intelligence for diagnostics, therapy assessment and progress prediction in PD based on body kinematics. Different machine learning algorithms showed promising results, particularly for early PD diagnostics. The investigated publications demonstrated the potentials of collecting data from affordable and globally available devices. However, to fully exploit artificial intelligence technologies in the future, more widespread collaboration is advised among medical institutions, clinicians and researchers, to facilitate aligning of data collection protocols, sharing and merging of data sets.",health
10.1016/j.envres.2019.108535,Journal,Environmental Research,scopus,2019-09-01,sciencedirect,Urban greenery and mental wellbeing in adults: Cross-sectional mediation analyses on multiple pathways across different greenery measures,https://api.elsevier.com/content/abstract/scopus_id/85067848081,"Background
                  Multiple mechanisms have been proposed to explain how greenery in the vicinity of people's homes enhances their mental health and wellbeing. Mediation studies, however, focus on a limited number of mechanisms and rely on remotely sensed greenery measures, which do not accurately capture how neighborhood greenery is perceived on the ground.
               
                  Objective
                  To examine: 1) how streetscape and remote sensing-based greenery affect people's mental wellbeing; 2) whether and, if so, to what extent the associations are mediated by physical activity, stress, air quality and noise, and social cohesion; and 3) whether differences in the mediation across the streetscape greenery and NDVI exposure metrics occurred.
               
                  Methods
                  We used a population sample of 1029 adult residents of the metropolis of Guangzhou, China, from 2016. Mental wellbeing was quantified by the World Health Organization Well-Being Index (WHO-5). Two objective greenery measures were extracted at the neighborhood level: 1) streetscape greenery from street view data via a convolutional neural network, and 2) the normalized difference vegetation index (NDVI) from Landsat 8 remote sensing images. Single and multiple mediation analyses with multilevel regressions were conducted.
               
                  Results
                  Streetscape and NDVI greenery were weakly and positively, but not significantly, correlated. Our regression results revealed that streetscape greenery and NDVI were, individually and jointly, positively associated with mental wellbeing. Significant partial mediators for the streetscape greenery were physical activity, stress, air quality and noise, and social cohesion; together, they explained 62% of the association. For NDVI, only physical activity and social cohesion were significant partial mediators, accounting for 22% of the association.
               
                  Conclusions
                  Mental health and wellbeing and both streetscape and satellite-derived greenery seem to be both directly correlated and indirectly mediated. Our findings signify that both greenery measures capture different aspects of natural environments and may contribute to people's wellbeing by means of different mechanisms.",health
10.1016/j.enbuild.2019.06.034,Journal,Energy and Buildings,scopus,2019-09-01,sciencedirect,A novel data-temporal attention network based strategy for fault diagnosis of chiller sensors,https://api.elsevier.com/content/abstract/scopus_id/85067404776,"In the air-cooled chiller system, sensor fault diagnosis has great significance for ensuring normal operation. However, according to the operating mechanism of the chiller system, sensors’ readings exhibit dynamical data-temporal dependencies and are easily affected by external factors and control parameters. To further capture the data characteristics existed in the sensors time series, in this paper, we propose a novel data-temporal attention network (DAN) for the chiller sensor fault diagnosis. Based on the conventional encoder-decoder network (EDN), the proposed DAN model is firstly built by adding three novel parts: the first one is a data attention mechanism embedded in the encoder, which is used to capture the dynamic data correlation between different sensors; the second part is a temporal attention mechanism, which is employed in the decoder to model the dynamic time-dependencies among the sensors time series; considering the influence of external factors and control parameters, the third part is a fusion module to incorporate these influential factors from different domains. Thereafter, we design a specific chiller sensor fault diagnosis strategy using the proposed DAN model. The sensor fault diagnosis strategy uses only normal sequences for training and learns to reconstruct normal time series behaviors, and then determines the fault threshold of each chiller sensor, and finally identifies the specific sensor fault by comparing the absolute reconstruction error vector with the fault threshold vector. In the end, the experiments which adopt data sets from a real air-cooled chiller platform are conducted, and detailed comparisons are made. Various magnitudes of fixed biases are introduced into eleven sensors for validation. Experimental results reveal that the sensor fault diagnosis strategy with the proposed DAN model achieves the best training and fault diagnosis performance compared with its variants and the traditional EDN model. Especially for the sensor fault diagnosis performance, comparison results demonstrate that the proposed DAN model is more sensitive to the small biases than the other contrast models and has better robustness for impacts on fault sensor in the reconstruction of the fault-free sensors.",health
10.1016/j.future.2019.01.049,Journal,Future Generation Computer Systems,scopus,2019-09-01,sciencedirect,Evolution-based configuration optimization of a Deep Neural Network for the classification of Obstructive Sleep Apnea episodes,https://api.elsevier.com/content/abstract/scopus_id/85063745269,"Deep Neural Networks (DNNs) may be very effective for the classification over highly-sized data sets, especially in the medical domain, where the recognition of the occurrence of a specific event related to a disease is of high importance. Unfortunately, DNNs suffer from the drawback that a good set of values for their configuration hyper-parameters must be found. Currently, this is done through the use of either trial-and-error methods or sampling-based ones. In this paper we propose a new approach to find the most suitable structure for a DNN used for a classification problem in terms of achievement of the highest classification accuracy. This approach is based on a distributed version of Differential Evolution (DE), a variety of an Evolutionary Algorithm. To evaluate the approach, in this paper we investigate this issue with reference to Obstructive Sleep Apnea (OSA). OSA is an important medical problem consisting of episodes taking place during night in which a subject stops breathing due to a constriction of the upper airways. This deteriorates the quality of life and may have dangerous, and even lethal, consequences on both short and long term. An accurate classification is a very crucial step for the OSA treatment, because understanding automatically that a subject is experiencing such an episode may be decisive if prompt medical action is needed. In our experiments, classification takes place on a data set in which each item contains the values of 17 Heart Rate Variability parameters, extracted from ElectroCardiography signals, and the annotation of OSA events. We have extracted this data set from the real-world Sleep Heart Health Study database. The results obtained by the distributed DE are compared against those of the Grid Search as well as against those achieved by 13 well-known classification tools. The use of a distributed DE version turns out to be very effective in automatically obtaining DNN structures with higher classification accuracy with respect to Grid Search (72.95% versus 72.61%), and allows saving a high amount of time (three hours as opposed to 65 h and 40 min). Moreover, the proposed method outperforms in terms of higher accuracy all the other classifiers investigated, as it is evidenced also by statistical analysis. Numerically, the runner-up, i.e., JRip, achieves as its best value 72.01% and 71.50% on average over 25 runs, both values being lower than 72.95% and 72.74% obtained by our dDE.",health
10.1016/j.future.2019.01.033,Journal,Future Generation Computer Systems,scopus,2019-09-01,sciencedirect,An e-Health care services framework for the detection and classification of breast cancer in breast cytology images as an IoMT application,https://api.elsevier.com/content/abstract/scopus_id/85063651524,"One of the primary causes of mortality among women aged 20–59 worldwide is breast cancer. Early detection and getting proper treatment can reduce the rate of morbidity of breast cancer. In this paper, we proposed a framework which combines machine learning and computational intelligence-based approaches in e-Health care service as an application of the Internet of Medical Things (IoMT) technology, for the early detection and classification of malignant cells in breast cancer. In the proposed approach, the detection of malignant cells is achieved by extracting various shapes and textured based features, whereas the classification is performed using three well-known classification algorithms. The most innovative part of the proposed approach is the use of Evolutionary Algorithms (EA) for the selection of optimal features, which reduces the computational complexity and accelerates the classification process in cloud-based e-Health care service. Similarly, an ensemble based classifier is used to select the best classifier by adopting the majority voting technique. The performance of the proposed approach is validated through experiments on real data sets which provide an accuracy of 98.0% in the detection and classification of malignant cells in breast cytology images.",health
10.1016/j.future.2019.01.019,Journal,Future Generation Computer Systems,scopus,2019-09-01,sciencedirect,Predictive analysis in outpatients assisted by the Internet of Medical Things,https://api.elsevier.com/content/abstract/scopus_id/85063504138,"With the rise of the Internet of Things era, data resources can be acquired in real time through intelligent sensing technology of IoMT (Internet of Medical Things), and it is very helpful for the analysis and prediction of medical data. Through the analysis and study of the data of the department of respiration combined with the data of the air quality dimension, meteorological dimension, and time dimension, this paper studies its related features and establishes a multidimensional features prediction model based on a BP neural network. The comparative experiments prove that the model prediction has a good effect. At the same time, this paper clarifies the validity of the multidimensional prediction model by comparing the relevant research. The results of the comparative experiments in this paper show that the outpatient quantity prediction is not a simple time-series problem, and it contains a variety of nonlinear influencing factors. In the contrast experiments, the multi-dimensional prediction model including air quality feature is better than others, and the experimental results prove that air quality indicators play an important role in the prediction of respiratory clinic outpatient visits. In addition, this paper discusses the significant lag effect on the prediction of respiratory consultations, and the four-day lag prediction has the best effect in the relatively short-term study. It indirectly proves that air has a lagging effect on respiratory diseases, and provides a reference for future research, no matter medical or modeling. The research has important reference value for the management and distribution of medical resources and the formulation of medical policies as well as important significance for the formulation of policies for disease prevention and the prevention and control of environmental pollution.",health
10.1016/j.ejor.2019.02.051,Journal,European Journal of Operational Research,scopus,2019-09-01,sciencedirect,Appointment scheduling with multiple providers and stochastic service times,https://api.elsevier.com/content/abstract/scopus_id/85063228230,"In many appointment scheduling systems with multiple providers, customers are assigned appointment times but they are not assigned a specific provider in advance – that is, customers can be seen by any available provider. This type of system is common in a variety of service sectors, such as healthcare, banking, and legal counseling. The majority of the existing literature assumes constant service times or does not consider customer no-shows, which are unrealistic assumptions in many situations. In this paper, we overcome this shortcoming by developing an appointment scheduling model that considers stochastic service times along with customer no-shows for multiple-provider systems with identical providers. The objective is to minimize the weighted sum of customers’ waiting time, and providers’ idle time and overtime. We model this problem as a time-inhomogeneous Discrete-Time Markov Chain process. We use analytical results to reduce the space of optimal schedule candidates, and we employ machine learning techniques to detect patterns among optimal or near-optimal schedules. We then develop an effective heuristic method which provides schedules that perform better than the ones generated by existing models. We test our heuristic both on simulated data and a real-world application. As the real-world application, we collaborate with a local counseling center to implement the schedules suggested by our method. Results from this field experiment reveal an average schedule cost reduction of 16% per day, with a maximum reduction of 40% per day.",health
10.1016/j.chemolab.2019.07.006,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2019-08-15,sciencedirect,Optical detection of contamination event in water distribution system using online Bayesian method with UV–Vis spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85069656799,"The detection of contamination events in water distribution systems remains a major concern to public health. However, much of the contaminant detection methods are supervised learning which cannot adapt to the complex environment in practical applications. In this work, a contaminant detection method using ultraviolet–visible spectroscopy technique was developed to achieve a goal of real-time detection on online acquisition of absorbance spectra. This method combined the advantages of probability distribution, message-passing algorithm and Bayesian theory. Message-passing algorithm was used to achieve a goal of online detection on noisy UV–Vis spectra signals. The proposed Bayesian algorithm organized the message passing schedule and helped to extract sequential patterns for event classification, which can avoid extreme conclusions. In addition, parameters were set up based on reasonable prior, by which the detection model was dynamically updated. Pilot scale experiment was conducted for long-term online monitoring of the water distribution system. And the experiment results showed improved performances in its ability to detect contamination events with higher probabilities, compared to previous studies.",health
10.1016/j.knosys.2019.04.022,Journal,Knowledge-Based Systems,scopus,2019-08-15,sciencedirect,Evolutionary manifold regularized stacked denoising autoencoders for gearbox fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85065582506,"Vibration signals are widely employed to fulfill gearbox fault diagnosis in real-world cases. However, it is quite challenging to extract effective fault features from noised vibration signals and then to construct an effective defect recognition model. Although deep neural networks (DNNs) have been used for feature extraction from vibration signals, the optimization of parameters and structure of DNNs simultaneously is still a difficult task in many applications. This paper proposes a new stacked denoising autoencoders (SDAE) algorithm, called manifold regularized SDAE (MRSDAE) based on particle swarm optimization (PSO), where manifold regularization and feature selection are embedded in the deep network smoothly. This study puts its emphasis on using PSO to simultaneously learn structure and parameters of MRSDAE based on a specific individual representation and learning scheme. MRSDAE aims to generate discriminant features from vibration signal data by using the integration of these effective techniques, i.e., structure and parameter optimization, manifold regularization and feature selection. MRSDAE-based fault diagnosis is implemented by an unsupervised representation learning followed by a supervised fine-tuning. The effectiveness of the MRSDAE-based fault diagnosis method has been verified by experimental results on vibration signal data from a gearbox defect test rig. The results illustrate that MRSDAE learns effective discriminative features and achieves the better diagnosis accuracy in comparison with that of the regular DNNs. Finding from this study can be used as the effective guidance in feature learning for machinery fault diagnosis based on evolutionary DNNs with manifold regularization and feature selection techniques.",health
10.1016/j.eswa.2019.03.011,Journal,Expert Systems with Applications,scopus,2019-08-15,sciencedirect,Constraint learning based gradient boosting trees,https://api.elsevier.com/content/abstract/scopus_id/85063576343,"Predictive regression models aim to find the most accurate solution to a given problem, often without any constraints related to the model’s predicted values. Such constraints have been used in prior research where they have been applied to a subpopulation within the training dataset which is of greater interest and importance. In this research we introduce a new setting of regression problems, in which each instance can be assigned a different constraint, defined based on the value of the target (predicted) attribute. The new use of constraints is taken into account and incorporated into the learning process, and is also considered when evaluating the induced model. We propose two algorithms which are modifications to the regression boosting method. There are two advantages of the proposed algorithms: they are not dependent on the base learner used during the learning process, and they can be adopted by any boosting technique. We implemented the algorithms by modifying the gradient boosting trees (GBT) model, and we also introduced two measures for evaluating the models that were trained to solve the constraint problems. We compared the proposed algorithms to three baseline algorithms using four real-life datasets. Due to the algorithms’ focus on satisfying the constraints, in most cases the results showed significant improvement in the constraint-related measures, with just a minimal effect on the general prediction error. The main impact of the proposed approach is in its ability to derive a model with a higher level of assurance for specific cases of interest (i.e., the constrained cases). This is extremely important and has great significance in various use cases and expert and intelligent systems, particularly critical systems, such as critical healthcare systems (e.g., when predicting blood pressure or blood sugar level), safety systems (e.g., when aiming to estimate the distance of cars or airplanes from other objects), or critical industrial systems (e.g., require to estimate their usability along time). In each of these cases, there is a subpopulation of all instances that is of greater interest to the expert or system, and the sensitivity of the model’s error changes according to the real value of the predicted feature. For example, for a subpopulation of patients (e.g., patients under the age of eight, or patients known to be at risk), physicians often require a sensitive model that accurately predicts blood pressure values.",health
10.1016/j.cmpb.2019.05.020,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-08-01,sciencedirect,Computer-aided diagnosis of endobronchial ultrasound images using convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85066448694,"Background and objective
                  In the United States, lung cancer is the leading cause of cancer death. The survival rate could increase by early detection. In recent years, the endobronchial ultrasonography (EBUS) images have been utilized to differentiate between benign and malignant lesions and guide transbronchial needle aspiration because it is real-time, radiation-free and has better performance. However, the diagnosis depends on the subjective judgment from doctors. In some previous studies, which using the grayscale image textures of the EBUS images to classify the lung lesions but it belonged to semi-automated system which still need the experts to select a part of the lesion first. Therefore, the main purpose of this study was to achieve full automation assistance by using convolution neural network.
               
                  Methods
                  First of all, the EBUS images resized to the input size of convolution neural network (CNN). And then, the training data were rotated and flipped. The parameters of the model trained with ImageNet previously were transferred to the CaffeNet used to classify the lung lesions. And then, the parameter of the CaffeNet was optimized by the EBUS training data. The features with 4096 dimension were extracted from the 7th fully connected layer and the support vector machine (SVM) was utilized to differentiate benign and malignant. This study was validated with 164 cases including 56 benign and 108 malignant.
               
                  Results
                  According to the experiment results, applying the classification by the features from the CNN with transfer learning had better performance than the conventional method with gray level co-occurrence matrix (GLCM) features. The accuracy, sensitivity, specificity, and the area under ROC achieved 85.4% (140/164), 87.0% (94/108), 82.1% (46/56), and 0.8705, respectively.
               
                  Conclusions
                  From the experiment results, it has potential ability to diagnose EBUS images with CNN.",health
10.1016/j.bspc.2019.101562,Journal,Biomedical Signal Processing and Control,scopus,2019-08-01,sciencedirect,Adversarial learning for deformable registration of brain MR image using a multi-scale fully convolutional network,https://api.elsevier.com/content/abstract/scopus_id/85065982893,"Background and objective
                  Deformable registration is very significant for various clinical image applications. Unfortunately, existing conventional medical image registration approaches, which involve time-consuming iterative optimization, have not reached the level of routine clinical practice in terms of registration time and robustness. The aim of this study is to propose a tuning-free 3D image registration model based on adversarial deep network, and to achieve rapid and high-accurate registration.
               
                  Methods
                  We propose a fully convolutional network (FCN) to regress the 3D dense deformation field in one shot from the to-be-registered image pair. To precisely regress the complex deformation and produce optimal registration, we design the FCN as a novel multi-scale frame to capture the complementary multi-scale image features and effectively characterize the spatial correspondence between the image pair. Moreover, we learn a discriminator network simultaneously to discriminate the registered two images, where the discrimination loss helps further update the FCN. Thus by the adversarial training strategy, the registration network is urged to produce well-registered two images that are indistinguishable for the discriminator.
               
                  Results
                  We perform registration experiments on four different brain MR datasets using the model trained by ANDI database. Compared with some state-of-the-art registration algorithms including other newest deeplearning-based methods, the proposed method provides a considerable increase of large than 4% in terms of Dice similarity coefficient (DSC). Moreover, our model also obtains comparable distance errors. More significantly, our model can achieve a high-accurate 3D registration result in average 0.74 s, with roughly hundred speed-up over conventional registration methods.
               
                  Conclusions
                  The proposed model shows consistent high performance for various registration tasks under a second without any additional parameter tuning, which proves its potential for real-time clinical applications.",health
10.1016/j.biomaterials.2019.05.010,Journal,Biomaterials,scopus,2019-08-01,sciencedirect,Construction of lanthanide-doped upconversion nanoparticle-Uelx Europaeus Agglutinin-I bioconjugates with brightness red emission for ultrasensitive in vivo imaging of colorectal tumor,https://api.elsevier.com/content/abstract/scopus_id/85065732648,"Lanthanide-doped upconversion nanoparticles (UCNPs)-based active targeting optical bioimaging has attracted tremendous scientific interest because of its noninvasive real-time signal feedback, superior tissue penetration depth and high spatial resolution in early diagnosis of disease. Herein, we synthesize a novel carboxy-terminated silica coated NaErF4: 10% Yb@NaYF4: 40% Yb@NaNdF4: 10% Yb@NaGdF4: 20% Yb UCNPs (termed as UCNP@SiO2-COOH) with 808 nm near-infrared (NIR) excitation and bright 655 nm upconversion luminescence (UCL) emission for realizing deep tissue imaging. Under 808 nm NIR laser excitation (1.5 W cm−2), the UCL of UCNP@SiO2-COOH with relative low concentration (2 mg mL−1) can be successfully visualized under a chicken breast slice with 10 mm thickness. After conjugated with various molecules including NH2-PEG3400-COOH, peptide D-SP5 and Uelx Europaeus Agglutinin-I (UEA-I), biodistributions, clearance pathways and tumor-targeting capacities of the UCNP@SiO2-COOH and corresponding bioconjugates (termed as UCNP@SiO2-PEG, UCNP@SiO2-D-SP5 and UCNP@SiO2-UEA-I, respectively) were investigated by tracking the UCL intensities of livers, kidneys and tumors. Both of in vitro and in vivo experimental results reveal that there is no significant difference for their in vivo biodistributions and clearance pathways. The UCNP@SiO2-UEA-I exhibits much higher SW480 tumor-targeting capacity than those of other bioconjugates. In particular, the as-prepared UCNP@SiO2-UEA-I even to visualize ultrasmall (c.a. 3 mm3 in volume) subcutaneous SW480 tumor in Balb/c nude mouse through intravenous administration. The study implies that the red UCL emitted UCNPs with a minimized heating effect is suitable for deep tissue biomedical imaging and UCNP@SiO2-UEA-I can serve as an efficient optical probe for early diagnosis of SW480 tumor.",health
10.1016/j.future.2019.03.026,Journal,Future Generation Computer Systems,scopus,2019-08-01,sciencedirect,Pairwise comparison learning based bearing health quantitative modeling and its application in service life prediction,https://api.elsevier.com/content/abstract/scopus_id/85063195689,"Cognitive computing is expected to meet the challenges posed by the avalanche problem of data being produced by experimental instruments and sensors in academia and industry. How to systematically, purposefully and reasonably interact with human beings and make-decision accordingly is one of the key factors for exerting the potential of cognitive computing and providing services for human beings. As one of the crucial supporting technologies for industrial equipment health management, bearing health analysis has increasingly become an important research field that is promising to improve the reliability and efficiency of modern industrial systems. One of the main challenges in condition-based maintenance and management of bearing is the health quantitative modeling and assessment. Therefore, a learning-based health modeling method, on the basis of newly defined multidimensional frequency-domain health feature, is proposed to realize quantitative assessment of bearing health state. First, a multilayer neural network with a special structure is designed. Then, a novel algorithm, namely PAirwiSe CompArison Learning (PASCAL) is proposed for network parameters learning. In addition, experiments are designed and carried out on a real industrial bearing testing dataset to verify the feasibility and efficiency of the proposed health modeling method. Experimental results are compared with those of two others recent research works, and the performance is measured with a percentage error metric.",health
10.1016/j.eswa.2019.02.013,Journal,Expert Systems with Applications,scopus,2019-08-01,sciencedirect,Machine learning algorithms for predicting drugs–tissues relationships,https://api.elsevier.com/content/abstract/scopus_id/85062845878,"The prediction of drug candidates for given tissues of organisms based on expression data is a critical biological problem. By correctly predicting drug candidates for given tissues, biologists can (1) avoid an experimental process of high-throughput screening that requires excessive time and costly equipment and (2) accelerate the drug discovery process by automatically assigning drug candidates. Although high throughput screening for therapeutic compounds lead to the generation of expression data, the process of correctly assigning candidate drugs based on such data remains a rigorous task. Hence, the design of high-performance machine learning (ML) algorithms is crucial for data analysts who work with clinicians. Clinicians incorporate advanced ML tools into expert and intelligent systems to improve the drug discovery process by accurately identifying drug candidates. The transfer learning approaches that are necessary to improve the prediction performance of several tasks that are involved in identifying drug candidates are presented in this paper. The performances of machine learning algorithms are compared in the transfer learning setting by employing several evaluation measures on real data that are obtained from experiments conducted on rats to identify drug candidates. The experimental results show that the proposed transfer learning approaches outperform baseline approaches in terms of prediction performance and statistical significance.",health
10.1016/j.jcin.2019.04.048,Journal,JACC: Cardiovascular Interventions,scopus,2019-07-22,sciencedirect,Impact of Artificial Intelligence on Interventional Cardiology: From Decision-Making Aid to Advanced Interventional Procedure Assistance,https://api.elsevier.com/content/abstract/scopus_id/85068485437,"Access to big data analyzed by supercomputers using advanced mathematical algorithms (i.e., deep machine learning) has allowed for enhancement of cognitive output (i.e., visual imaging interpretation) to previously unseen levels and promises to fundamentally change the practice of medicine. This field, known as “artificial intelligence” (AI), is making significant progress in areas such as automated clinical decision making, medical imaging analysis, and interventional procedures, and has the potential to dramatically influence the practice of interventional cardiology. The unique nature of interventional cardiology makes it an ideal target for the development of AI-based technologies designed to improve real-time clinical decision making, streamline workflow in the catheterization laboratory, and standardize catheter-based procedures through advanced robotics. This review provides an introduction to AI by highlighting its scope, potential applications, and limitations in interventional cardiology.",health
10.1016/j.jep.2019.111928,Journal,Journal of Ethnopharmacology,scopus,2019-07-15,sciencedirect,The repression and reciprocal interaction of DNA methyltransferase 1 and specificity protein 1 contributes to the inhibition of MET expression by the combination of Chinese herbal medicine FZKA decoction and erlotinib,https://api.elsevier.com/content/abstract/scopus_id/85065504267,"Ethnopharmacological relevance
                  The Chinese herbal medicine Fuzheng Kang-Ai (FZKA) decoction obtained from Guangdong Kangmei Pharmaceutical Company, which contains 12 components with different types of constituents, has been used as part of the adjuvant treatment of lung cancer for decades. We previously showed that FZKA decoction enhances the growth inhibition of epidermal growth factor receptor-tyrosine kinase inhibitor (EGFR-TKI)-resistant non-small cell lung cancer (NSCLC) cells by suppressing glycoprotein mucin 1 (MUC1) expression. However, the molecular mechanism underlying the therapeutic potential, particularly in sensitizing or/and enhancing the anti-lung cancer effect of EGFR-TKIs, remains unclear.
               
                  Materials and methods
                  Cell viability was measured using 3-(4, 5-diMEThylthiazol-2-yl)-2, 5-diphenyltetrazolium bromide (MTT) and 5-ethynyl -2′-deoxyuridine (EdU) assays. Western blot analysis was performed to examine the protein expressions of DNA methyltransferase 1 (DNMT1), specificity protein 1 (SP1), and MET, an oncogene encoding for a trans-membrane tyrosine kinase receptor activated by the hepatocyte growth factor (HGF). The expression of MET mRNA was measured by quantitative real-time PCR (qRT-PCR). Exogenous expression of DNMT1 and SP1, and MET were carried out by transient transfection assays. The promoter activity of MET was tested using Dual-luciferase reporter assays. A nude mouse xenografted tumor model further evaluated the effect of the combination of FZKA decoction and erlotinib in vivo.
               
                  Results
                  The combination of FZKA and erlotinib produced an even greater inhibition of NSCLC cell growth. FZKA decreased the expressions of DNMT1, SP1, and MET (c-MET) proteins, and the combination of FZKA and erlotinib demonstrated enhanced responses. Interestingly, there was a mutual regulation of DNMT1 and SP1. In addition, exogenously expressed DNMT1 and SP1 blocked the FZKA-inhibited c-MET expression. Moreover, excessive expressed MET neutralized FZKA-inhibited growth of NSCLC cells. FZKA decreased the mRNA and promoter activity of c-MET, which was not observed in cells with ectopic expressed DNMT1 gene. Similar findings were observed in vivo.
               
                  Conclusion
                  FZKA decreases MET gene expression through the repression and mutual regulation of DNMT1 and SP1 in vitro and in vivo. This leads to inhibit the growth of human lung cancer cells. The combination of FZKA and EGFR-TKI erlotinib exhibits synergy in this process. The regulatory loops among the DNMT1, SP1 and MET converge in the overall effects of FZKA and EGFR-TKI erlotinib. This in vitro and in vivo study clarifies an additional novel molecular mechanism underlying the anti-lung cancer effects in response to the combination of FZKA and erlotinib in gefitinib-resistant NSCLC cells.",health
10.1016/j.vetmic.2019.05.015,Journal,Veterinary Microbiology,scopus,2019-07-01,sciencedirect,Enhancing immunogenicity and protective efficacy of inactivated avian influenza H9N2vaccine with recombinant chicken IFN-α in chicken,https://api.elsevier.com/content/abstract/scopus_id/85066414611,"Control of currently circulating re-assorted low-pathogenicity avian influenza (LPAI) H9N2 is a major concern for both animal and human health. Thus, an improved LPAI H9N2 vaccination strategy is needed to induce complete immunity in chickens against LPAI H9N2 virus strains. Cytokines play a crucial role in mounting both the type and extent of an immune response generated following infection with a pathogen or after vaccination. To improve the efficacy of inactivated LPAI H9N2 vaccine, prokaryotic expression recombination chicken interferon-α (rchIFN-α) was used as vaccine adjuvant.In this study chIFN-α was used as adjuvant in inactivated AI H9N2 vaccine, modulated the immune response of chickens against the vaccine antigen through enhanced humoral and Th1-biased cell-mediated immunity, compared to chickens that received single AI H9N2 vaccine. To further test the protective efficacy of this improved vaccination regimen, immunized chickens were challenged with a high dose of LPAI H9N2 virus. Combined administration rchIFN-α showed markedly enhanced protection compared to single administration of the vaccine, as determined by mortality, clinical severity, and feed and water intake. This enhancement of protective immunity was further confirmed by reduced rectal shedding and replication of AIV H9N2 in challenged chickens. Our results indicate the value of combined administration of rchIFN-α to generate an effective immunization strategy in chickens against LPAI H9N2.",health
10.1016/j.gie.2019.03.019,Journal,Gastrointestinal Endoscopy,scopus,2019-07-01,sciencedirect,Quality assurance of computer-aided detection and diagnosis in colonoscopy,https://api.elsevier.com/content/abstract/scopus_id/85065917454,"Recent breakthroughs in artificial intelligence (AI), specifically via its emerging sub-field “deep learning,” have direct implications for computer-aided detection and diagnosis (CADe and/or CADx) for colonoscopy. AI is expected to have at least 2 major roles in colonoscopy practice—polyp detection (CADe) and polyp characterization (CADx). CADe has the potential to decrease the polyp miss rate, contributing to improving adenoma detection, whereas CADx can improve the accuracy of colorectal polyp optical diagnosis, leading to reduction of unnecessary polypectomy of non-neoplastic lesions, potential implementation of a resect-and-discard paradigm, and proper application of advanced resection techniques. A growing number of medical-engineering researchers are developing both CADe and CADx systems, some of which allow real-time recognition of polyps or in vivo identification of adenomas, with over 90% accuracy. However, the quality of the developed AI systems as well as that of the study designs vary significantly, hence raising some concerns regarding the generalization of the proposed AI systems. Initial studies were conducted in an exploratory or retrospective fashion by using stored images and likely overestimating the results. These drawbacks potentially hinder smooth implementation of this novel technology into colonoscopy practice. The aim of this article is to review both contributions and limitations in recent machine-learning-based CADe and/or CADx colonoscopy studies and propose some principles that should underlie system development and clinical testing.",health
10.1016/j.cmpb.2019.05.006,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-07-01,sciencedirect,Segmenting brain tumors from FLAIR MRI using fully convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85065640821,"Background and Objective
                  Magnetic resonance imaging (MRI) is an indispensable tool in diagnosing brain-tumor patients. Automated tumor segmentation is being widely researched to accelerate the MRI analysis and allow clinicians to precisely plan treatment—accurate delineation of brain tumors is a critical step in assessing their volume, shape, boundaries, and other characteristics. However, it is still a very challenging task due to inherent MR data characteristics and high variability, e.g., in tumor sizes or shapes. We present a new deep learning approach for accurate brain tumor segmentation which can be trained from small and heterogeneous datasets annotated by a human reader (providing high-quality ground-truth segmentation is very costly in practice).
               
                  Methods
                  In this paper, we present a new deep learning technique for segmenting brain tumors from fluid attenuation inversion recovery MRI. Our technique exploits fully convolutional neural networks, and it is equipped with a battery of augmentation techniques that make the algorithm robust against low data quality, and heterogeneity of small training sets. We train our models using only positive (tumorous) examples, due to the limited amount of available data.
               
                  Results
                  Our algorithm was tested on a set of stage II-IV brain-tumor patients (image data collected using MAGNETOM Prisma 3T, Siemens). Rigorous experiments, backed up with statistical tests, revealed that our approach outperforms the state-of-the-art approach (utilizing hand-crafted features) in terms of segmentation accuracy, offers very fast training and instant segmentation (analysis of an image takes less than a second). Building our deep model is 1.3 times faster compared with extracting features for extremely randomized trees, and this training time can be controlled. Finally, we showed that too aggressive data augmentation may lead to deteriorated performance of the model, especially in the fixed-budget training (with maximum numbers of training epochs).
               
                  Conclusions
                  Our method yields the better performance when compared with the state of the art method which utilizes hand-crafted features. In addition, our deep network can be effectively applied to difficult (small, imbalanced, and heterogeneous) datasets, offers controllable training time, and infers in real-time.",health
10.1016/j.media.2019.05.001,Journal,Medical Image Analysis,scopus,2019-07-01,sciencedirect,Denoising of 3D magnetic resonance images using a residual encoder–decoder Wasserstein generative adversarial network,https://api.elsevier.com/content/abstract/scopus_id/85065426790,"Structure-preserved denoising of 3D magnetic resonance imaging (MRI) images is a critical step in medical image analysis. Over the past few years, many algorithms with impressive performances have been proposed. In this paper, inspired by the idea of deep learning, we introduce an MRI denoising method based on the residual encoder–decoder Wasserstein generative adversarial network (RED-WGAN). Specifically, to explore the structure similarity between neighboring slices, a 3D configuration is utilized as the basic processing unit. Residual autoencoders combined with deconvolution operations are introduced into the generator network. Furthermore, to alleviate the oversmoothing shortcoming of the traditional mean squared error (MSE) loss function, the perceptual similarity, which is implemented by calculating the distances in the feature space extracted by a pretrained VGG-19 network, is incorporated with the MSE and adversarial losses to form the new loss function. Extensive experiments are implemented to assess the performance of the proposed method. The experimental results show that the proposed RED-WGAN achieves performance superior to several state-of-the-art methods in both simulated and real clinical data. In particular, our method demonstrates powerful abilities in both noise suppression and structure preservation.",health
10.1016/j.jtos.2019.03.003,Journal,Ocular Surface,scopus,2019-07-01,sciencedirect,Novel automated non invasive detection of ocular surface squamous neoplasia using multispectral autofluorescence imaging,https://api.elsevier.com/content/abstract/scopus_id/85065047875,"Purpose
                  Diagnosing Ocular surface squamous neoplasia (OSSN) using newly designed multispectral imaging technique.
               
                  Methods
                  Eighteen patients with histopathological diagnosis of Ocular Surface Squamous Neoplasia (OSSN) were recruited. Their previously collected biopsy specimens of OSSN were reprocessed without staining to obtain auto fluorescence multispectral microscopy images. This technique involved a custom-built spectral imaging system with 38 spectral channels. Inter and intra-patient frameworks were deployed to automatically detect and delineate OSSN using machine learning methods. Different machine learning methods were evaluated, with K nearest neighbor and Support Vector Machine chosen as preferred classifiers for intra- and inter-patient frameworks, respectively. The performance of the technique was evaluated against a pathological assessment.
               
                  Results
                  Quantitative analysis of the spectral images provided a strong multispectral signature of a relative difference between neoplastic and normal tissue both within each patient (at p < 0.0005) and between patients (at p < 0.001). Our fully automated diagnostic method based on machine learning produces maps of the relatively well circumscribed neoplastic-non neoplastic interface. Such maps can be rapidly generated in quasi-real time and used for intraoperative assessment. Generally, OSSN could be detected using multispectral analysis in all patients investigated here. The cancer margins detected by multispectral analysis were in close and reasonable agreement with the margins observed in the H&E sections in intra- and inter-patient classification, respectively.
               
                  Conclusions
                  This study shows the feasibility of using multispectral auto-fluorescence imaging to detect and find the boundary of human OSSN. Fully automated analysis of multispectral images based on machine learning methods provides a promising diagnostic tool for OSSN which can be translated to future clinical applications.",health
10.1016/j.media.2019.04.009,Journal,Medical Image Analysis,scopus,2019-07-01,sciencedirect,Automatic CNN-based detection of cardiac MR motion artefacts using k-space data augmentation and curriculum learning,https://api.elsevier.com/content/abstract/scopus_id/85064952229,"Good quality of medical images is a prerequisite for the success of subsequent image analysis pipelines. Quality assessment of medical images is therefore an essential activity and for large population studies such as the UK Biobank (UKBB), manual identification of artefacts such as those caused by unanticipated motion is tedious and time-consuming. Therefore, there is an urgent need for automatic image quality assessment techniques. In this paper, we propose a method to automatically detect the presence of motion-related artefacts in cardiac magnetic resonance (CMR) cine images. We compare two deep learning architectures to classify poor quality CMR images: 1) 3D spatio-temporal Convolutional Neural Networks (3D-CNN), 2) Long-term Recurrent Convolutional Network (LRCN). Though in real clinical setup motion artefacts are common, high-quality imaging of UKBB, which comprises cross-sectional population data of volunteers who do not necessarily have health problems creates a highly imbalanced classification problem. Due to the high number of good quality images compared to the relatively low number of images with motion artefacts, we propose a novel data augmentation scheme based on synthetic artefact creation in k-space. We also investigate a learning approach using a predetermined curriculum based on synthetic artefact severity. We evaluate our pipeline on a subset of the UK Biobank data set consisting of 3510 CMR images. The LRCN architecture outperformed the 3D-CNN architecture and was able to detect 2D+time short axis images with motion artefacts in less than 1ms with high recall. We compare our approach to a range of state-of-the-art quality assessment methods. The novel data augmentation and curriculum learning approaches both improved classification performance achieving overall area under the ROC curve of 0.89.",health
10.1016/j.ijmedinf.2019.04.012,Journal,International Journal of Medical Informatics,scopus,2019-07-01,sciencedirect,Touchscreen games to detect cognitive impairment in senior adults. A user-interaction pilot study,https://api.elsevier.com/content/abstract/scopus_id/85064632298,"Introduction
                  Alzheimer’s disease is a degenerative brain disease and the most common cause of dementia. Today, 47 million people live with dementia worldwide. This number is projected to increase to more than 131 million by 2050, as populations age. Therefore, the World Health Organization considers serious cognitive deterioration a public health priority.
               
                  Objectives
                  Advanced cognitive evaluation mechanisms are needed to help make an early diagnosis. These new mechanisms should overcome the limitations of current neuropsychological tests, including delayed detection; being perceived as intrusive; being non-ecological; being dependent on confounding factors; or their administration being expensive, among others. A promising novel approach consists of the introduction of serious games based on virtual reality and machine learning able to assess cognitive traits relevant to the diagnosis of mild cognitive impairment and Alzheimer's disease.
               
                  Methods
                  As a result of a preliminary pilot experiment, promising evidence was obtained about the predictive power of this solution. However, for these new serious games to be effective, evidence has to be gathered on the player experience by senior adults, avoiding the limitations of traditional tests at the same time. This study addresses these aspects with the participation of 74 senior users and 15 test administrators.
               
                  Results
                  Main findings confirm the usability and playability of Panoramix, a game battery designed according to the principles discussed above, its technological acceptability and its accessibility. For example, in relation to acceptability, the game battery was scored 4.39 in a 5-point scale, while its average usability score was 4.45 regardless of socio-cultural level or previous experience with digital technologies. In addition, health professionals confirm both, usability and playability, levels with an average score of 6.5 in a 7-point scale. Participants’ willingness of using this kind of systems for cognitive evaluation was also confirmed.
               
                  Conclusion
                  Promising results obtained pave the way for additional work to confirm the diagnostic validity according to clinical standards of these new cognitive assessment tools.",health
10.1016/j.jviromet.2019.04.010,Journal,Journal of Virological Methods,scopus,2019-07-01,sciencedirect,Development of an RT-LAMP assay for the detection of Lassa viruses in southeast and south-central Nigeria,https://api.elsevier.com/content/abstract/scopus_id/85064184174,"Lassa virus (LASV) causes Lassa fever (LF), a viral hemorrhagic fever endemic in West Africa. LASV strains are clustered into six lineages according to their geographic location. To confirm a diagnosis of LF, a laboratory test is required. Here, a reverse transcription loop-mediated isothermal amplification (RT-LAMP) assay using a portable device for the detection of LASV in southeast and south-central Nigeria using three primer sets specific for strains clustered in lineage II was developed. The assay detected in vitro transcribed LASV RNAs within 23 min and was further evaluated for detection in 73 plasma collected from suspected LF patients admitted into two health settings in southern Nigeria. The clinical evaluation using the conventional RT-PCR as the reference test revealed a sensitivity of 50% in general with 100% for samples with a viral titer of 9500 genome equivalent copies (geq)/mL and higher. The detection limit was estimated to be 4214 geq/mL. The assay showed 98% specificity with no cross-reactivity to other viruses which cause similar symptoms. These results suggest that this RT-LAMP assay is a useful molecular diagnostic test for LF during the acute phase, contributing to early patient management, while using a convenient device for field deployment and in resource-poor settings.",health
10.1016/j.jenvman.2019.04.026,Journal,Journal of Environmental Management,scopus,2019-07-01,sciencedirect,Validated predictive modelling of sulfonamide and beta-lactam resistance genes in landfill leachates,https://api.elsevier.com/content/abstract/scopus_id/85064155267,"The spread of antimicrobial resistance via landfill leachates jeopardizes millions of people's health, which can be exacerbated due to the unclear quantitative relationships between leachate characteristics and occurrences of antibiotic resistance genes (ARGs). Here, in parallel with sampling raw leachates from a real landfill, we constructed a lab-scale landfill and collected its leachates for 260 days. All leachate samples were analyzed for the abundance of integrons, sulfonamide resistance (sulR; sul1 and sul2) and beta-lactams resistance (blaR; bla
                     OXA, bla
                     CTX-M, and bla
                     TEM) genes. The enrichment of sulR subtypes was closely associated with the integrons' prevalence during the landfilling process (0.65–0.75 log10(copies/mL)), which can be explained by the multiple linear regression that contained intl1, pH, and nitrogen compounds as variables. The predicted abundance of sulR genes (6.06 ± 0.6 log10(copies/mL)) was statistically the same as the observed value in raw leachates (P = 0.73). The abundance of blaR genes decreased from 5.0 to 2.5 log10(copies/mL) during the experiment (P < 0.001); and a locally weighted regression of blaR genes with integrons, COD and total nitrogen accurately predicted blaR genes abundance in raw leachate (Bootstrap = 10,000, P = 0.67). The partial least squares path modelling (PLS-PM) showed that variations of blaR genes in the lab and raw leachates shared an identical pattern (PLS-PM, Bootstrap = 10,000, P > 0.05), which was influenced by integrons and environmental factors with the coefficients of −0.11 and 0.39, respectively. We believe the validated models are highly useful tools to streamline the strategies for monitoring and prediction of ARGs.",health
10.1016/j.bspc.2019.03.009,Journal,Biomedical Signal Processing and Control,scopus,2019-07-01,sciencedirect,Automatic staging model of heart failure based on deep learning,https://api.elsevier.com/content/abstract/scopus_id/85063688039,"Heart failure (HF) is a disease that is harmful to human health. Recent advances in machine learning yielded new techniques to train deep neural networks, which resulted in highly successful applications in many pattern recognition tasks such as object detection and speech recognition. To improve the diagnostic accuracy of HF staging, this study evaluates the performance of deep learning-based models on combined features for its categorization. We proposed a novel deep convolutional neural network-Recurrent neural network (CNN-RNN) model for automatic staging of heart failure diseases in real-time and dynamically. We employed the data segmentation and data augmentation pre-processing dataset to make the classification performance of the proposed architecture better. Specifically, this paper use convolutional neural network (CNN) as a feature extractor instead of training the entire network to extract the characteristics of the electrocardiogram (ECG) signals and form a feature set. We combine the above feature set with other clinical features, feed the combined features to RNN for classification, and finally obtain 5 classification results. Experiments shows that the CNN-RNN model proposed in this paper achieved an accuracy of 97.6%, the sensitivity of 96.3%, specificity of 97.4% and proportion of 97.1% for two seconds of ECG segments. We obtained an accuracy, sensitivity, specificity and proportion of 96.2%, 96.9%, 95.7%, and 94.3% respectively for five seconds of ECG duration. The model can be used as an aid to help clinicians confirm their diagnosis.",health
10.1016/j.bspc.2019.03.011,Journal,Biomedical Signal Processing and Control,scopus,2019-07-01,sciencedirect,Are you afraid of heights and suitable for working at height?,https://api.elsevier.com/content/abstract/scopus_id/85063350700,"Fear of highs is one of the most common phobias all around world. It could affect people’s life, work and health. Standing on high-altitude can lead to fear, anxiety or even panic to some people. In this paper, EEG method is creatively combined with VR technology to assess the severity of fear of heights. By doing time-frequency analysis, we found that alpha band (8–13 Hz) and high beta (20–30 Hz) are sensitive to fear of heights and frontal and parietotemporal areas are the regions of interests for fear of heights. Then using cross mutual information we built up a functional brain networks of every subject. And we extracted EEG features from the brain networks. Statistical analysis was performed to select the features based on significance of difference. Finally, we implemented classification. The performance of classifiers (the average accuracy could reach 94.44%) based on the proposed method was compared to the performance of classifiers based on the traditional physiological features. As a result, the proposed method was verified to be reliable and superior on estimating the severity of fear of heights. In addition, the system was tested on elderly people and came out with good performance. It turns out that the proposed system has good generalization capability and adaptability.",health
10.1016/j.ymssp.2019.02.048,Journal,Mechanical Systems and Signal Processing,scopus,2019-07-01,sciencedirect,Real-time combustion torque estimation and dynamic misfire fault diagnosis in gasoline engine,https://api.elsevier.com/content/abstract/scopus_id/85062219984,"In this research, an innovative state observer of gasoline engine based on the combination of Luenberger and sliding mode technique is proposed. This state observer is designed to track crankshaft angular speed and estimate engine combustion torque based on the experimental crankshaft angular speed of a four-cylinder Spark Ignition (SI) engine. Then, a new advance in the application of Artificial Neural Networks (ANNs) based on the estimated results of automated dynamic misfire fault diagnosis both under steady state and non-stationary condition is discussed in detailed. In order to effectively obtain data for network training, the estimated engine combustion torque is segmentally preprocessed according to the crank angle displacement of automobile engine. Furthermore, a series of experiments are carried out under normal and a variety of misfire conditions. The ANN systems are trained and tested using prepared cases. Finally, the Back-Propagation Neural Network (BPNN), Elman Neural Network (ENN), and Support Vector Machine (SVM) are applied to diagnose misfire fault, the effectiveness of each is evaluated respectively. Based on the estimated engine combustion torque, the experimental results show that the designed ENN is able to correctly diagnose misfire fault with a running time of 0.6 s, including single misfire, intermittent double-cylinder misfire, and continuous double-cylinder misfire in transient working condition.",health
10.1016/j.eswa.2019.01.066,Journal,Expert Systems with Applications,scopus,2019-06-15,sciencedirect,Enhancing batch normalized convolutional networks using displaced rectifier linear units: A systematic comparative study,https://api.elsevier.com/content/abstract/scopus_id/85060885669,"A substantial number of expert and intelligent systems rely on deep learning methods to solve problems in areas such as economics, physics, and medicine. Improving the accuracy of the activation functions used by such methods can directly and positively impact the overall performance and quality of the mentioned systems at no cost whatsoever. In this sense, enhancing the design of such theoretical fundamental blocks is of great significance as it immediately impacts a broad range of current and future real-world deep learning based applications. Therefore, in this paper, we turn our attention to the interworking between the activation functions and the batch normalization, which is practically a mandatory technique to train deep networks currently. We propose the activation function Displaced Rectifier Linear Unit (DReLU) by conjecturing that extending the identity function of ReLU to the third quadrant enhances compatibility with batch normalization. Moreover, we used statistical tests to compare the impact of using distinct activation functions (ReLU, LReLU, PReLU, ELU, and DReLU) on the learning speed and test accuracy performance of standardized VGG and Residual Networks state-of-the-art models. These Convolutional Neural Networks were trained on CIFAR-100 and CIFAR-10, the most commonly used deep learning computer vision datasets. The results showed DReLU speeded up learning in all models and datasets. Besides, statistical significant performance assessments (p < 0.05) showed DReLU enhanced the test accuracy presented by ReLU in all scenarios. Furthermore, DReLU showed better test accuracy than any other tested activation function in all experiments with one exception, in which case it presented the second best performance. Therefore, this work demonstrates that it is possible to increase performance replacing ReLU by an enhanced activation function.",health
10.1016/j.neuropsychologia.2019.04.004,Journal,Neuropsychologia,scopus,2019-06-01,sciencedirect,Exploring the fatigue affecting electroencephalography based functional brain networks during real driving in young males,https://api.elsevier.com/content/abstract/scopus_id/85067960467,"In recent years, a large proportion of traffic accidents are caused by driver fatigue. The brain has been conceived as a complex network, whose function can be assessed with EEG. Hence, in this research, fourteen subjects participated in the real driving experiments, and a comprehensive EEG-based expert system was designed for detecting driver fatigue. Collected EEG signals were first decomposed into delta-range, theta-range, alpha-range and beta-range by wavelet packet transform (WPT). Unlike other approaches, a multi-channel network construction method based on Phase Lag Index (PLI) was then proposed in this paper. Finally, the functional connectivity between alert state (at the beginning of the drive) and fatigue state (at the end of the drive) in multiple frequency bands were analyzed. The results indicate that functional connectivity of the brain area was significantly different between alert and fatigue states, especially in alpha-range and beta-range. Particularly, the frontal-to-parietal functional connectivity was weakened. Meanwhile, lower clustering coefficient (C) values and higher characteristic path length (L) values were observed in fatigue state in comparison with alert state. Based on this, two new EEG feature selection approaches, C and L in the corresponding sub-frequency range were applied to feature recognition and classification system. Using a support vector machine (SVM) machine learning algorithm, these features were combined to distinguish between alert and fatigue states, achieving an accuracy of 94.4%, precision of 94.3%, sensitivity of 94.6% and false alarm rate of 5.7%. The results suggest that brain network analysis approaches combined with SVM are helpful to alert drivers while being sleepy or even fatigue.",health
10.1016/j.compbiomed.2019.04.030,Journal,Computers in Biology and Medicine,scopus,2019-06-01,sciencedirect,A novel deep learning method for automatic assessment of human sperm images,https://api.elsevier.com/content/abstract/scopus_id/85064992079,"Sperm morphology analysis (SMA) is a very important factor in the diagnosis process of male infertility. This research proposes a novel deep learning algorithm for malformation detection of sperm morphology using human sperm cell images. Our proposed method detects and analyzes different parts of human sperms. First of all, we have prepared an image collection, called the MHSMA dataset, which can be used as a standard benchmark for future machine learning studies in this problem. This collection consists of 1,540 sperm images from 235 patients with male factor infertility. This unique dataset is freely available to the public. After applying data augmentation techniques, we have proposed a sampling method for fixing data imbalance. Then, we have designed a deep neural network architecture and trained it to detect morphological deformities in different parts of human sperm—head, acrosome, and vacuole. Our proposed method is one of the first algorithms that considers the acrosome. In addition, our method can work very well with non-stained and low-resolution images. Our experimental results on the proposed benchmark show the high accuracy of our deep learning algorithm for detection of morphological deformities from images. In these experiments, the proposed algorithm has achieved 
                        
                           
                              
                                 F
                              
                              
                                 0.5
                              
                           
                        
                      scores of 
                        
                           84.74
                           %
                        
                     , 
                        
                           83.86
                           %
                        
                     , and 
                        
                           94.65
                           %
                        
                      in acrosome, head, and vacuole abnormality detection, respectively. It should be noted that our algorithm achieves a better accuracy than existing state-of-the-art methods in acrosome and vacuole abnormality detection on the proposed benchmark. Also, our method works very fast. It can classify images in real-time, even on a mainstream laptop computer. This allows an embryologist to quickly decide whether or not the analyzed sperm should be selected.",health
10.1016/j.mimet.2019.03.003,Journal,Journal of Microbiological Methods,scopus,2019-06-01,sciencedirect,A duplex quantitative real-time PCR assay for the detection and quantification of Xanthomonas phaseoli pv. dieffenbachiae from diseased and latently infected anthurium tissue,https://api.elsevier.com/content/abstract/scopus_id/85064711930,"Anthurium bacterial blight caused by Xanthomonas phaseoli pv. dieffenbachiae (formerly Xanthomonas axonopodis pv. dieffenbachiae) is the major phytosanitary threat in many anthurium growing areas worldwide. Reliable and sensitive diagnostic tools are required for surveillance and certification programs. A duplex real–time quantitative PCR assay was developed for the detection and quantification of X. phaseoli pv. dieffenbachiae from anthurium tissue. This PCR assay targeted a X. phaseoli pv. dieffenbachiae–specific gene encoding an ABC transporter and an internal control encoding for chalcone synthase in Anthurium andreanum. A cycle threshold (Ct), using a receiver-operating characteristic approach (ROC), was implemented to ensure that the declaration of a positive sample was reliable. The duplex real–time assay displayed very high performance with regards to analytical specificity (100% inclusivity, 98.9% exclusivity), analytical sensitivity (LOD95% = 894 bacteria/ml corresponding to 18 bacteria per reaction) and repeatability. We demonstrated the pertinence of this real–time quantitative PCR assay for detecting X. phaseoli pv. dieffenbachiae from diseased leaf tissue (collected from outbreaks on anthurium) and from asymptomatic, latently infected anthurium plants. This assay could be useful for surveillance, as well as for indexing propagative plant material for the presence of X. phaseoli pv. dieffenbachiae.",health
10.1016/j.fsi.2019.04.022,Journal,Fish and Shellfish Immunology,scopus,2019-06-01,sciencedirect,Dynamic distribution of formalin-inactivated Edwardsiella tarda in flounder (Paralichthys olivaceus) post intraperitoneal vaccination,https://api.elsevier.com/content/abstract/scopus_id/85064172689,"In order to investigate the dynamic distribution of antigen in different tissues post vaccination, an absolute real-time quantitative PCR was employed to detect the amount of antigen in flounder (Paralichthys olivaceus) post intraperitoneal (i.p.) injection with three concentrations (107, 108, 109 CFU ml−1) of formalin-inactivated Edwardsiella tarda bacterin. The results showed that the amount of uptaken antigen quickly increased and then decreased in different tissues. The peak occurred first in the spleen and head kidney at 6–9 h after injection, and in the liver and blood at 9–15 h, then in the gill, intestine and skin at 15–24 h, finally in the muscle at 24–36 h. The amount of antigen was highest in the spleen and head kidney, followed by the blood, liver and gill, and lowest in the intestine, skin and muscle. Among the three concentration groups, the amount of antigen increased with the increasing concentration of the vaccine in the blood, liver, gill, intestine, skin and muscle, except for the spleen and head kidney, in which more antigens were found in the 108 CFU ml−1 group than that in 109 CFU ml−1 group. Moreover, IIFA and western blotting was performed to examine the tissue distribution of antigen at 9 h after vaccination with 108 CFU ml−1 formalin-inactivated E. tarda. The bacteria were mainly observed in the spleen and head kidney, then the liver, gill and blood, and least in the intestine, skin and muscle, which was roughly in accordance with the results of absolute qPCR. Furthermore, the expressions of CD4-1, MHC IIα, CD8α and MHC Iα in different tissues were detected by RT-qPCR, and the expression levels of these genes were highest in the spleen and head kidney, then in the blood, gill, liver, and lowest in the intestine, skin and muscle. All these results provided useful information for dynamic transportation of antigen uptake post vaccination, and also deepened the understanding of immune response to the injection vaccination.",health
10.1016/j.ijmedinf.2019.03.015,Journal,International Journal of Medical Informatics,scopus,2019-06-01,sciencedirect,BTS-DSN: Deeply supervised neural network with short connections for retinal vessel segmentation,https://api.elsevier.com/content/abstract/scopus_id/85063903882,"Background and objective
                  The condition of vessel of the human eye is an important factor for the diagnosis of ophthalmological diseases. Vessel segmentation in fundus images is a challenging task due to complex vessel structure, the presence of similar structures such as microaneurysms and hemorrhages, micro-vessel with only one to several pixels wide, and requirements for finer results.
               
                  Methods
                  In this paper, we present a multi-scale deeply supervised network with short connections (BTS-DSN) for vessel segmentation. We used short connections to transfer semantic information between side-output layers. Bottom-top short connections pass low level semantic information to high level for refining results in high-level side-outputs, and top-bottom short connection passes much structural information to low level for reducing noises in low-level side-outputs. In addition, we employ cross-training to show that our model is suitable for real world fundus images.
               
                  Results
                  The proposed BTS-DSN has been verified on DRIVE, STARE and CHASE_DB1 datasets, and showed competitive performance over other state-of-the-art methods. Specially, with patch level input, the network achieved 0.7891/0.8212 sensitivity, 0.9804/0.9843 specificity, 0.9806/0.9859 AUC, and 0.8249/0.8421 F1-score on DRIVE and STARE, respectively. Moreover, our model behaves better than other methods in cross-training experiments.
               
                  Conclusions
                  BTS-DSN achieves competitive performance in vessel segmentation task on three public datasets. It is suitable for vessel segmentation. The source code of our method is available at: https://github.com/guomugong/BTS-DSN.",health
10.1016/j.ins.2019.02.065,Journal,Information Sciences,scopus,2019-06-01,sciencedirect,Computer Aided detection for fibrillations and flutters using deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85062047707,"Fibrillations and flutters are serious diseases influence the normal functioning of the heart. Among the most frequently occurring heart disorders belong atrial fibrillation (A
                        fib
                     ), atrial flutter (A
                        fl
                     ), and ventricular fibrillation (V
                        fib
                     ). Nowadays, heart failures are mostly detected by electrocardiogram (ECG) device by examining the signal transferred from electrodes placed on the human body to the output display. The signal is examined by professional health personnel, who are looking for an obvious pattern representing the normal or abnormal rhythm of the heart. Nevertheless, information from ECG can be distorted by noise on data transmission. Moreover,problematic pattern does not have to be so much different from normal and it can be difficult to recognize them just by human eye even by an expert in the field. An automated computer-aided diagnosis (CAD) is an approach to make decision support for elimination of these lacks. For early diagnosis, CAD tool should work in like real-time system without big time consuming and dependency on data and measuring differences of each device. This paper proposes a novel approach of a CAD system to the detection of fibrillations and flutters by our 8-layer deep convolutional neural network. Proposed model requires only basic data normalization without pre-processing and feature extraction from raw ECG samples. We have achieved the accuracy, specificity, and sensitivity of 98.45%, 99.27%, and 99.87% respectively. Designed system can be directly implemented like decision support system in clinical environment.",health
10.1016/j.neucom.2018.11.094,Journal,Neurocomputing,scopus,2019-05-21,sciencedirect,Boolean kernels for rule based interpretation of support vector machines,https://api.elsevier.com/content/abstract/scopus_id/85061737830,"Machine learning started as an academic-oriented domain, but nowadays it is becoming more and more widespread across diverse domains, such as retail, healthcare, finance, and many more. This non-academic face of machine learning creates a new set of challenges. The usage of such complex methods by non-expert users has increased the need for interpretable models. To this end, in this paper we propose an approach for extracting explanation rules from support vector machines. The core idea is based on using kernels with feature spaces composed by logical propositions. On top of that, a searching algorithm tries to retrieve the most relevant features/rules that can be used to explain the trained model. Experiments on both categorical and real-valued datasets show the effectiveness of the proposed approach.",health
10.1016/j.scitotenv.2019.02.309,Journal,Science of the Total Environment,scopus,2019-05-20,sciencedirect,Integrated system for population dose calculation and decision making on protection measures in case of an accident with air emissions in a nuclear power plant,https://api.elsevier.com/content/abstract/scopus_id/85061901769,"The accidents in Chernobyl and Fukushima remind us that nuclear power plants should continuously invest resources in improving safety and in risk management.
                  This paper presents the methodology for developing a measuring and modelling system with a high degree of automation, which enables predicting the effects of the spreading of radionuclides from the nuclear power plant to the atmosphere. The end result is the calculated population doses in the event of an accidental release, which is an essential piece of information needed by first responders to take proper action.
                  The key challenge addressed by this methodology is how to build a system so that its operation is maximally automated, ongoing and in real time. Moreover, in a way that “fresh”, normalized results for the hypothetically most probable types of emissions are always available to operators. The principle that normalized, fresh results are always automatically available to operators is the only real assurance that they will almost surely be available in the event of an accident and panic. This way, we can avoid performing complex model calculations at the operator's request when the accident is already taking place.
                  The methodology divides the building of the system into key modules, which are substantiated and described.
                  The theoretical section is followed by a description of implementation on the example of the Measuring and Modelling System at the Krško Nuclear Power Plant (in Slovenia). The system has been tested in regular nuclear emergency exercises and rated excellent by IAEA inspections; it has been operating automatically, continuously and in real time for many years. The availability of automatic results is counted for the last two years. Measurements and diagnostic modelling results were available for more than 96% and forecasts were available in more than 91% of all half-hour intervals.",health
10.1016/j.jenvman.2019.02.110,Journal,Journal of Environmental Management,scopus,2019-05-15,sciencedirect,Real-time detection of potable-reclaimed water pipe cross-connection events by conventional water quality sensors using machine learning methods,https://api.elsevier.com/content/abstract/scopus_id/85062705303,"Risk of cross-connection is becoming higher due to greater construction of potable-reclaimed water dual distribution systems. Cross-connection events can result in serious health concerns and reduce public confidence in reclaimed water. Thus, reliable, cost-effective and real-time online detection methods for early warning are required. The current study carried out pilot-scale experiments to simulate potable-reclaimed water pipe cross-connection events for different mixing ratios (from 30% to 1%) using machine learning methods based on multiple conventional water quality parameters. The parameters included residual chlorine, pH, turbidity, temperature, conductivity, oxidation-reduction potential and chemical oxygen demand. The results showed that correlated variation occurred among water quality parameters at the time of the cross-connection event. A single parameter-based method can be effective at high mixing ratios, but not at low mixing ratios. The direct supporting vector machine (SVM)-based method managed to overcome this drawback, but coped poorly with abnormal readings of water parameter sensors. In that respect, a Pearson correlation coefficient (PCC)-SVM-based method was developed. It provided not only high detection performance under normal conditions, but also remained reliable when abnormal readings occurred. The detection accuracy and true positive rate of this method was still over 88%, and the false positive rate was below 12%, given a sudden variation of an individual water quality parameter. The receiver operating characteristic curves further confirmed the promising practical applicability of this PCC-SVM-based method for early detection of cross-connection events.",health
10.1016/j.watres.2019.02.027,Journal,Water Research,scopus,2019-05-15,sciencedirect,"Water characterization and early contamination detection in highly varying stochastic background water, based on Machine Learning methodology for processing real-time UV-Spectrophotometry",https://api.elsevier.com/content/abstract/scopus_id/85062478863,"Water is a resource that affects every aspect of life. Intentional (terrorist or wartime events) or accidental water contamination events could have a tremendous impact on public health, behavior and morale. Quick detection of such events can mitigate their effects and reduce the potential damage. Continuous on-line monitoring is the first line of defense for reducing contamination associated damage. One of the available tools for such detection is the UV-absorbance spectrophotometry, where the absorbance spectra are compared against a set of normal and contaminated water fingerprints. However, as there are many factors at play that affect this comparison, it is an elusive and tedious task. Further, the comparison against a set of known fingerprints is futile when the water in the supply system are a mix, with varying proportions, of water from different sources, which differ significantly in their physicochemical characteristics. This study presents a new scheme for early detection of contamination events through UV absorbance under unknown routine conditions. The detection mechanism is based on a new affinity measure, Fitness, and a procedure similar to Gram based amplification, which result in a flexible mechanism to alert if a contamination is present. The method was shown to be most effective when applied to a set of comprehensive experiments, which examined the absorbance of various contaminants in drinking water in lab and real-life configurations. Four datasets, which contained real readings from either laboratory experiments or monitoring station of an operational water supply system were used. To extend the testbed even further, an artificial dataset, simulating a vast array of proportions between specific water sources is also presented. The results show, that for all datasets, high detection rates, while maintaining low levels of false alarms, were obtained by the algorithm.",health
10.1016/j.amsu.2019.04.001,Journal,Annals of Medicine and Surgery,scopus,2019-05-01,sciencedirect,"Artificial intelligence, regenerative surgery, robotics? What is realistic for the future of surgery?",https://api.elsevier.com/content/abstract/scopus_id/85064430299,"The potential of surgery lies in the technological advances that would complement it. The landscape of the field will differ depending on the time period being looked at and would no doubt include conjecture. Initial breakthroughs will need to pave the way for future medical technology and apply to the surgical sciences. Within the next 10 years we would expect to see the emergence of big data analysis, cuttingedge image processing techniques for surgical planning and better implementation of virtual and augmented reality in operating theatres for both patient care and teaching purposes. Over the next 50 to 100 years, the use of quantum computing should lead to increased automation in our healthcare systems. The inception of novel biomaterial invention and advanced genetic engineering will usher in the new age of regenerative medicine in the clinical setting. The future of surgery includes many predictions and promises, but it is apparent that the development will lead to bettering outcome and focus on patient care.",health
10.1016/j.ijleo.2019.04.034,Journal,Optik,scopus,2019-05-01,sciencedirect,Concealed object segmentation in terahertz imaging via adversarial learning,https://api.elsevier.com/content/abstract/scopus_id/85064317470,"Terahertz imaging (frequency between 0.1 to 10 THz) is a modern technique for public security check. Due to poor imaging quality, traditional machine vision methods often fail to detect concealed weapons in Terahertz samples, while modern instance segmentation approaches have complex multiple-stage concatenation and often hunger for massive and accurate training data. In this work, we realize a novel Conditional Generative Adversarial Nets (CGANs), named as Mask-CGANs to segment weapons in such a challenging imaging quality. The Mask-Generator network employs a “selected-connection U-Net” to restrain false alarms and speed up training convergence. The loss function takes reconstruction errors and sparse priors into consideration to preserve precise segmentation. Such a learning architecture works well with a small training dataset. Experiments show that the proposed model outperforms CGANs (more than 16–32% in Recall, Precision and Accuracy) and Mask-RCNN (more than 3–6%). Moreover, its testing speed (69.7 FPS) is fast enough to be implemented in a real-time security check system, which is 44 times faster than Mask-RCNN. In the experiments for mammographic mass segmentation on INBreast dataset, the Dice index of the proposed method is 91.29, surpasses the-state-of-the-art medical issue segmentation methods. The full implementation (based on TensorFlow) is available at https://github.com/JXPanzz/THz).",health
10.1016/j.actbio.2019.04.004,Journal,Acta Biomaterialia,scopus,2019-05-01,sciencedirect,72-Hour in vivo evaluation of nitric oxide generating artificial lung gas exchange fibers in sheep,https://api.elsevier.com/content/abstract/scopus_id/85063997512,"The large, densely packed artificial surface area of artificial lungs results in rapid clotting and device failure. Surface generated nitric oxide (NO) can be used to reduce platelet activation and coagulation on gas exchange fibers, while not inducing patient bleeding due to its short half-life in blood. To generate NO, artificial lungs can be manufactured with PDMS hollow fibers embedded with copper nanoparticles (Cu NP) and supplied with an infusion of the NO donor S-nitroso-N-acetyl-penicillamine (SNAP). The SNAP reacts with Cu NP to generate NO. This study investigates clot formation and gas exchange performance of artificial lungs with either NO-generating Cu-PDMS or standard polymethylpentene (PMP) fibers. One miniature artificial lung (MAL) made with 10 wt% Cu-PDMS hollow fibers and one PMP control MAL were attached to sheep in parallel in a veno-venous extracorporeal membrane oxygenation circuit (n = 8). Blood flow through each device was set at 300 mL/min, and each device received a SNAP infusion of 0.12 μmol/min. The ACT was between 110 and 180 s in all cases. Blood flow resistance was calculated as a measure of clot formation on the fiber bundle. Gas exchange experiments comparing the two groups were conducted every 24 h at blood flow rates of 300 and 600 mL/min. Devices were removed once the resistance reached 3x baseline (failure) or following 72 h. All devices were imaged using scanning electron microscopy (SEM) at the inlet, outlet, and middle of the fiber bundle. The Cu-PDMS NO generating MALs had a significantly smaller increase in resistance compared to the control devices. Resistance rose from 26 ± 8 and 23 ± 5 in the control and Cu-PDMS devices, respectively, to 35 ± 8 mmHg/(mL/min) and 72 ± 23 mmHg/(mL/min) at the end of each experiment. The resistance and SEM imaging of fiber surfaces demonstrate lower clot formation on Cu-PDMS fibers. Although not statistically significant, oxygen transfer for the Cu-PDMS MALs was 13.3% less than the control at 600 mL/min blood flow rate. Future in vivo studies with larger Cu–PDMS devices are needed to define gas exchange capabilities and anticoagulant activity over a long-term study at clinically relevant ACTs.
               
                  Statement of Significance
                  In artificial lungs, the large, densely-packed blood contacting surface area of the hollow fiber bundle is critical for gas exchange but also creates rapid, surface-generated clot requiring significant anticoagulation. Monitoring of anticoagulation, thrombosis, and resultant complications has kept permanent respiratory support from becoming a clinical reality. In this study, we use a hollow fiber material that generates nitric oxide (NO) to prevent platelet activation at the blood contacting surface. This material is tested in vivo in a miniature artificial lung and compared against the clinical standard. Results indicated significantly reduced clot formation. Surface-focused anticoagulation like this should reduce complication rates and allow for permanent respiratory support by extending the functional lifespan of artificial lungs and can further be applied to other medical devices.",health
10.1016/j.jbi.2019.103151,Journal,Journal of Biomedical Informatics,scopus,2019-05-01,sciencedirect,Predicting anxiety state using smartphone-based passive sensing,https://api.elsevier.com/content/abstract/scopus_id/85063516889,"This study predicts the change of stress levels using real-world and online behavioral features extracted from smartphone log information. Previous studies of stress detection using smartphone data focused on a single feature and did not consider all features simultaneously. We propose a method to extract a co-occurring combination of a user’s real-world and online behavioral features by converting raw sensor data into categorical features. We conducted an experiment in which the State Trait Anxiety Inventory (STAI) was used to assess the anxiety-related stress levels of 20 healthy participants. The participants installed a log-collecting application on their smartphones and answered the STAI questions once a day for one month. The proposed method showed an F-score of 74.2%, which is 4.0% higher than the F-score of previous studies (70.2%) that used single non-combined features. The results demonstrate that anxiety-related stress levels can be predicted using combined features extracted from smartphone log data.",health
10.1016/j.crad.2019.02.006,Journal,Clinical Radiology,scopus,2019-05-01,sciencedirect,Artificial intelligence in breast imaging,https://api.elsevier.com/content/abstract/scopus_id/85062980487,"This article reviews current limitations and future opportunities for the application of computer-aided detection (CAD) systems and artificial intelligence in breast imaging. Traditional CAD systems in mammography screening have followed a rules-based approach, incorporating domain knowledge into hand-crafted features before using classical machine learning techniques as a classifier. The first commercial CAD system, ImageChecker M1000, relies on computer vision techniques for pattern recognition. Unfortunately, CAD systems have been shown to adversely affect some radiologists' performance and increase recall rates. The Digital Mammography DREAM Challenge was a multidisciplinary collaboration that provided 640,000 mammography images for teams to help decrease false-positive rates in breast cancer screening. Winning solutions leveraged deep learning's (DL) automatic hierarchical feature learning capabilities and used convolutional neural networks. Start-ups Therapixel and Kheiron Medical Technologies are using DL for breast cancer screening. With increasing use of digital breast tomosynthesis, specific artificial intelligence (AI)-CAD systems are emerging to include iCAD's PowerLook Tomo Detection and ScreenPoint Medical's Transpara. Other AI-CAD systems are focusing on breast diagnostic techniques such as ultrasound and magnetic resonance imaging (MRI). There is a gap in the market for contrast-enhanced spectral mammography AI-CAD tools. Clinical implementation of AI-CAD tools requires testing in scenarios mimicking real life to prove its usefulness in the clinical environment. This requires a large and representative dataset for testing and assessment of the reader's interaction with the tools. A cost-effectiveness assessment should be undertaken, with a large feasibility study carried out to ensure there are no unintended consequences. AI-CAD systems should incorporate explainable AI in accordance with the European Union General Data Protection Regulation (GDPR).",health
10.1016/j.jad.2019.03.044,Journal,Journal of Affective Disorders,scopus,2019-05-01,sciencedirect,Short-term prediction of suicidal thoughts and behaviors in adolescents: Can recent developments in technology and computational science provide a breakthrough?,https://api.elsevier.com/content/abstract/scopus_id/85062497590,"Background
                  Suicide is one of the leading causes of death among adolescents, and developing effective methods to improve short-term prediction of suicidal thoughts and behaviors (STBs) is critical. Currently, the most robust predictors of STBs are demographic or clinical indicators that have relatively weak predictive value. However, there is an emerging literature on short-term prediction of suicide risk that has identified a number of promising candidates, including (but not limited to) rapid escalation of: (a) emotional distress, (b) social dysfunction (e.g., bullying, rejection), and (c) sleep disturbance. However, these prior studies are limited in two critical ways. First, they rely almost entirely on self-report. Second, most studies have not focused on assessment of these risk factors using intensive longitudinal assessment techniques that are able to capture the dynamics of changes in risk states at the individual level.
               
                  Method
                  In this paper we explore how to capitalize on recent developments in real-time monitoring methods and computational analysis in order to address these fundamental problems.
               
                  Results
                  We now have the capacity to use: (a) smartphone, wearable computing, and smart home technology to conduct intensive longitudinal assessments monitoring of putative risk factors with minimal participant burden and (b) modern computational techniques to develop predictive algorithms for STBs. Current research and theory on short-term risk processes for STBs, combined with the emergent capabilities of new technologies, suggest that this is an important research agenda for the future.
               
                  Limitations
                  Although these approaches have enormous potential to create new knowledge, the current empirical literature is limited. Moreover, passive monitoring of risk for STBs raises complex ethical issues that will need to be resolved before large scale clinical applications are feasible.
               
                  Conclusions
                  Smartphone, wearable, and smart home technology may provide one point of access that might facilitate both early identification and intervention implementation, and thus, represents a key area for future STB research.",health
10.1016/j.measurement.2019.02.073,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2019-05-01,sciencedirect,A novel transfer learning method for robust fault diagnosis of rotating machines under variable working conditions,https://api.elsevier.com/content/abstract/scopus_id/85062273887,"Vibration signals are closely linked with health conditions of rotating machines and widely used in fault diagnosis. Unfortunately, traditional vibration signal-based fault diagnosis methods are under a universal assumption that the target vibration signals for application and the available vibration signals for model training are collected from the same distribution, which is always impractical in real-world scenarios due to working condition variation. For robust fault diagnosis under variable working conditions, although some transfer learning-based methods are proposed, they mostly aim at aligning only the marginal distribution discrepancy of datasets, which is validated not sufficient in some cases. Hence, we propose a new transfer learning method called improved joint distribution adaptation (IJDA) to align both the marginal and conditional distributions of datasets more comprehensively. Meanwhile, built on it, a working condition-robust fault diagnosis method is developed, which utilizes vibration signals and is mainly composed of three parts. Firstly, a new data augmentation method is developed to generate more useful samples for imbalanced vibration signals, which innovatively uses noise to boost network performance. Secondly, sparse filtering (SF) is employed to reduce the input dimension of IJDA. Finally, IJDA is utilized to firstly extract both sharing and principal features and then diagnose the features. Experiments on vibration signal datasets of roller bearings and a gearbox and comparisons with other methods verify its effectiveness and applicability.",health
10.1016/j.media.2019.01.010,Journal,Medical Image Analysis,scopus,2019-05-01,sciencedirect,f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85062268629,"Obtaining expert labels in clinical imaging is difficult since exhaustive annotation is time-consuming. Furthermore, not all possibly relevant markers may be known and sufficiently well described a priori to even guide annotation. While supervised learning yields good results if expert labeled training data is available, the visual variability, and thus the vocabulary of findings, we can detect and exploit, is limited to the annotated lesions. Here, we present fast AnoGAN (f-AnoGAN), a generative adversarial network (GAN) based unsupervised learning approach capable of identifying anomalous images and image segments, that can serve as imaging biomarker candidates. We build a generative model of healthy training data, and propose and evaluate a fast mapping technique of new data to the GAN’s latent space. The mapping is based on a trained encoder, and anomalies are detected via a combined anomaly score based on the building blocks of the trained model – comprising a discriminator feature residual error and an image reconstruction error. In the experiments on optical coherence tomography data, we compare the proposed method with alternative approaches, and provide comprehensive empirical evidence that f-AnoGAN outperforms alternative approaches and yields high anomaly detection accuracy. In addition, a visual Turing test with two retina experts showed that the generated images are indistinguishable from real normal retinal OCT images. The f-AnoGAN code is available at https://github.com/tSchlegl/f-AnoGAN.",health
10.1016/j.patrec.2019.02.020,Journal,Pattern Recognition Letters,scopus,2019-05-01,sciencedirect,Towards recovery of conditional vectors from conditional generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85062230178,"A conditional Generative Adversarial Network allows for generating samples conditioned on certain external information. Being able to recover latent and conditional vectors from a conditional GAN can be potentially valuable in various applications, ranging from image manipulation for entertaining purposes to diagnosis of the neural networks for security purposes. In this work, we show that it is possible to recover both latent and conditional vectors from generated images given the generator of a conditional generative adversarial network. Such a recovery is not trivial due to the often multi-layered non-linearity of deep neural networks. Furthermore, the effect of such recovery applied on real natural images are investigated. We discovered that there exists a gap between the recovery performance on generated and real images, which we believe comes from the difference between generated data distribution and real data distribution. Experiments are conducted to evaluate the recovered conditional vectors and the reconstructed images from these recovered vectors quantitatively and qualitatively, showing promising results.",health
10.1016/j.surg.2019.01.002,Journal,Surgery (United States),scopus,2019-05-01,sciencedirect,Comparing clinical judgment with the MySurgeryRisk algorithm for preoperative risk assessment: A pilot usability study,https://api.elsevier.com/content/abstract/scopus_id/85061644981,"Background
                  Major postoperative complications are associated with increased cost and mortality. The complexity of electronic health records overwhelms physicians’ abilities to use the information for optimal and timely preoperative risk assessment. We hypothesized that data-driven, predictive-risk algorithms implemented in an intelligent decision-support platform simplify and augment physicians’ risk assessments.
               
                  Methods
                  This prospective, nonrandomized pilot study of 20 physicians at a quaternary academic medical center compared the usability and accuracy of preoperative risk assessment between physicians and MySurgeryRisk, a validated, machine-learning algorithm, using a simulated workflow for the real-time, intelligent decision-support platform. We used area under the receiver operating characteristic curve to compare the accuracy of physicians’ risk assessment for six postoperative complications before and after interaction with the algorithm for 150 clinical cases.
               
                  Results
                  The area under the receiver operating characteristic curve of the MySurgeryRisk algorithm ranged between 0.73 and 0.85 and was significantly better than physicians' initial risk assessments (area under the receiver operating characteristic curve between 0.47 and 0.69) for all postoperative complications except cardiovascular. After interaction with the algorithm, the physicians significantly improved their risk assessment for acute kidney injury and for an intensive care unit admission greater than 48 hours, resulting in a net improvement of reclassification of 12% and 16%, respectively. Physicians rated the algorithm as easy to use and useful.
               
                  Conclusion
                  Implementation of a validated, MySurgeryRisk computational algorithm for real-time predictive analytics with data derived from the electronic health records to augment physicians’ decision-making is feasible and accepted by physicians. Early involvement of physicians as key stakeholders in both design and implementation of this technology will be crucial for its future success.",health
10.1016/j.ins.2019.01.073,Journal,Information Sciences,scopus,2019-05-01,sciencedirect,A lightweight machine learning-based authentication framework for smart IoT devices,https://api.elsevier.com/content/abstract/scopus_id/85061004380,"The Internet of Things (IoT) is the next generation plethora of interconnected devices that includes sensors, actuators, etc. and that can provide personalized services such as healthcare, security, and surveillance. The quality of our daily lives is improved by the IoT through pervasive computation and communication. Innumerable devices are being connected each day to IoT applications. Although the quality of our lives is enhanced by the IoT, IoT applications also cause serious challenges in securing networks and data in transit. Existing security solutions, such as password-based two-factor authentication and traditional biometric template-based authentication, can be challenged because of several threats that affect the reliability and efficiency of the entire system. Hence, there is a need for a highly secure authentication mechanism such as the Cancelable Biometric System (CBS). In essence, the CBS is a biometric template protection scheme that operates based on repeated distortions/transformations at the feature/signal level. Therefore, in this paper, we propose a framework for a cloud-based lightweight cancelable biometric authentication system. Findings from our study are used to demonstrate the potential for the proposed approach to be deployed in real-world settings (i.e., the capability to authenticate client devices with high accuracy and minimal overhead without affecting the security of the sensitive biometric templates in the cloud environment). Both theoretical and experimental analyses suggest that the proposed approach has a minimal equal error rate compared with those of the state-of-the-art techniques. Moreover, the proposed approach has been proven to consume less time, making it suitable for IoT environments.",health
10.1016/j.mfglet.2019.05.003,Journal,Manufacturing Letters,scopus,2019-04-01,sciencedirect,A blockchain enabled Cyber-Physical System architecture for Industry 4.0 manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85066168835,"Cyber-Physical Production Systems (CPPSs) are complex manufacturing systems which aim to integrate and synchronize machine world and manufacturing facility to the cyber computational space. However, having intensive interconnectivity and a computational platform is crucial for real-world implementation of CPPSs. In this paper, the potential impacts of blockchain technology in development and realization of real-world CPPSs are discussed. A unified three-level blockchain architecture is proposed as a guideline for researchers and industries to clearly identify the potentials of blockchain and adapt, develop, and incorporate this technology with their manufacturing developments towards Industry 4.0.",health
10.1016/j.vetpar.2019.03.007,Journal,Veterinary Parasitology,scopus,2019-04-01,sciencedirect,Tissue (re)distribution of Trypanosoma equiperdum in venereal infected and blood transfused horses,https://api.elsevier.com/content/abstract/scopus_id/85063752529,"Dourine, caused by Trypanosoma equiperdum, is a life-threatening venereal disease in equidae. So far, there is no clear evidence on how and when stallions become infectious, nor which tissues are affected by the parasite in diseased animals. Post-infection, after a transient, temporary phase of parasitaemia, the parasite disperses to different tissues in an unknown distribution pattern. This study describes the distribution of the parasite after infection by artificial insemination (AI) or blood transfusion. Mares (N = 4) were artificially inseminated with T. equiperdum spiked semen whereas stallions (N = 4) were infected by blood transfusion. The course of the disease was monitored by parasitological (Woo) and molecular (PCR) tests and clinical signs and haematological parameters were recorded. At 120 days post infection, horses had a full necropsy, histopathology and PCR. A similar pattern of parasitaemia, disease progression and tissue distribution were seen in all horses. Ejaculated semen in the preclinical stage and epididymal semen in the chronic stage of the disease was positive on PCR and caused infection in mice. Cymelarsan® treatment in the chronic stage did not result in a clinico-haematological or histopathological improvement. At necropsy, lesions were observed in the nervous and reproductive system. Histopathological lesions were most severe in the peripheral nerves and associated ganglia, the testicles and genital mucosae with multifocal infiltration of lymphocytes, plasma cells and histocytes. The parasites disseminated to several tissues including the nervous system, testicles and semen. The results indicate that transmission of T. equiperdum is possible through semen even from symptomless stallions post-treatment.",health
10.1016/j.eng.2018.11.027,Journal,Engineering,scopus,2019-04-01,sciencedirect,The State of the Art of Data Science and Engineering in Structural Health Monitoring,https://api.elsevier.com/content/abstract/scopus_id/85062663661,"Structural health monitoring (SHM) is a multi-discipline field that involves the automatic sensing of structural loads and response by means of a large number of sensors and instruments, followed by a diagnosis of the structural health based on the collected data. Because an SHM system implemented into a structure automatically senses, evaluates, and warns about structural conditions in real time, massive data are a significant feature of SHM. The techniques related to massive data are referred to as data science and engineering, and include acquisition techniques, transition techniques, management techniques, and processing and mining algorithms for massive data. This paper provides a brief review of the state of the art of data science and engineering in SHM as investigated by these authors, and covers the compressive sampling-based data-acquisition algorithm, the anomaly data diagnosis approach using a deep learning algorithm, crack identification approaches using computer vision techniques, and condition assessment approaches for bridges using machine learning algorithms. Future trends are discussed in the conclusion.",health
10.1016/j.compbiomed.2019.02.016,Journal,Computers in Biology and Medicine,scopus,2019-04-01,sciencedirect,Layout-aware information extraction from semi-structured medical images,https://api.elsevier.com/content/abstract/scopus_id/85062443963,"Textual information embedded in the medical image contains rich structured information about the medical condition of a patient. This paper aims at extracting structured textual information from semi-structured medical images. Given the recognized text spans of an image preprocessed by optical character recognition (OCR), due to the spatial discontinuity of texts spans as well as potential errors brought by OCR, the structured information extraction becomes more challenging. In this paper, we propose a domain-specific language, called ODL, which allows users to describe the value and layout of text data contained in the images. Based on the value and spatial constraints described in ODL, the ODL parser associates values found in the image with the data structure in the ODL description, while conforming to the aforementioned constraints. We conduct experiments on a dataset consisting of real medical images, our ODL parser consistently outperforms existing approaches in terms of extraction accuracy, which shows the better tolerance of incorrectly recognized texts, and positional variances between images. This accuracy can be further improved by learning from a few manual corrections.",health
10.1016/j.forsciint.2019.02.028,Journal,Forensic Science International,scopus,2019-04-01,sciencedirect,Chat Analysis Triage Tool: Differentiating contact-driven vs. fantasy-driven child sex offenders,https://api.elsevier.com/content/abstract/scopus_id/85062400557,"Investigating crimes against children, specifically sexual solicitations, are complicated because not all offenders are contact-driven, meaning they want to meet the minor for sex in the physical world; instead, some offenders are fantasy-driven, in that they are more interested in cybersex and role-play. In addition, the sheer volume of cases involving the online sexual solicitation of minors makes it difficult for law enforcement to determine whether an offender is contact-driven vs. fantasy-driven. However, research shows that there are language-based differences between minors and contact-driven offenders vs. fantasy driven-offenders. Thus, we developed the Chat Analysis Triage Tool (CATT), a forensically sound investigative tool that, based on natural language processing methods, analyzes and compares chats between minors and contact-driven vs. non-contract driven offenders. Using an SVM classifier, we were successful in differentiating the classes based on character trigrams. In a matter of seconds, the existing algorithms provide an identification of an offender’s risk level based on the likelihood of contact offending as inferred from the model, which assists law enforcement in their ability to triage and prioritize cases involving the sexual solicitation of minors.",health
10.1016/j.jbi.2019.103138,Journal,Journal of Biomedical Informatics,scopus,2019-04-01,sciencedirect,Distributed learning from multiple EHR databases: Contextual embedding models for medical events,https://api.elsevier.com/content/abstract/scopus_id/85062392033,"Electronic health record (EHR) data provide promising opportunities to explore personalized treatment regimes and to make clinical predictions. Compared with regular clinical data, EHR data are known for their irregularity and complexity. In addition, analyzing EHR data involves privacy issues and sharing such data is often infeasible among multiple research sites due to regulatory and other hurdles. A recently published work uses contextual embedding models and successfully builds one predictive model for more than seventy common diagnoses. Despite of the high predictive power, the model cannot be generalized to other institutions without sharing data. In this work, a novel method is proposed to learn from multiple databases and build predictive models based on Distributed Noise Contrastive Estimation (Distributed NCE). We use differential privacy to safeguard the intermediary information sharing. The numerical study with a real dataset demonstrates that the proposed method not only can build predictive models in a distributed manner with privacy protection, but also preserve model structure well and achieve comparable prediction accuracy. The proposed methods have been implemented as a stand-alone Python library and the implementation is available on Github (https://github.com/ziyili20/DistributedLearningPredictor) with installation instructions and use-cases.",health
10.1016/j.cie.2019.02.038,Journal,Computers and Industrial Engineering,scopus,2019-04-01,sciencedirect,Estimating gene expression from high-dimensional DNA methylation levels in cancer data: A bimodal unsupervised dimension reduction algorithm,https://api.elsevier.com/content/abstract/scopus_id/85062283529,"Recent molecular and genetic studies have revealed the importance of DNA methylation, a key epigenetic mark, in regulating gene expression and the abnormal profiles of DNA methylation in various diseases including cancer. Here, unsupervised learning methods that are geared towards high-throughput DNA methylation analysis are used to extract useful information from high-dimensional genome wide methylation data in order to provide crucial insights for accurate early diagnosis and treatment of cancer. Herein, these methods are highly dependent on the performance of an earlier step of dimension reduction that aims to find the best subset of attributes to be retained for learning. Widely used algorithms in the literature commonly suffer from resulting in trivial cluster structures and failing to shed light on the relationship between DNA methylation and cancer types due to their myopic and arbitrary search mechanisms. Addressing this issue, we introduce a bimodal unsupervised dimension reduction algorithm (BOUNDER) that identifies the best subset of loci for downstream analysis considering the variability and redundancy across all the samples using bimodal modeling before it feeds into the learning method. BOUNDER models each locus as a bimodal representation using a piecewise linear function with two segments and filters the informative loci based on the fitted line characteristics. To the best of our knowledge, the work presented here is the first study that uses bimodal modeling in unsupervised learning in DNA methylation analysis. BOUNDER is tailored for DNA methylation analysis using a detailed parameter tuning analysis. The performance of BOUNDER is benchmarked against those of widely used conventional algorithms using real lung, breast, kidney, and urological cancer datasets obtained from Gene Expression Omnibus in terms of their accuracies in hierarchical clustering and k-means clustering. Computational experiments reveal that BOUNDER outperforms the PCA and filtering based approach by providing the highest accuracy in 6 out of 9 datasets while providing more interpretable results through a correlation analysis. The BOUNDER algorithm is also shown to be more robust when compared to multiple other conventional dimension reduction algorithms across different datasets.",health
10.1016/j.fsi.2019.02.007,Journal,Fish and Shellfish Immunology,scopus,2019-04-01,sciencedirect,Analysis of immunoglobulin and T cell receptor gene expression in ballan wrasse (Labrus bergylta) revealed an extraordinarily high IgM expression in the gut,https://api.elsevier.com/content/abstract/scopus_id/85061368016,"The serum IgM concentration of ballan wrasse is relatively high, estimated to approximately 13 mg/ml in adult wild fish of 800 g. The present study revealed an unusual high abundance of IgM mRNA in the gut of ballan wrasse. Initially, transcripts encoding IgM, IgT, IgD, TCRα, TCRδ and CD3ε were quantified by RT-qPCR in several tissues of wild caught fish (approx. 800 g), indicating an elevated immune activity in hindgut and an extraordinarily high expression of IgM. Subsequently, a new RT-qPCR analysis was performed on the entire intestine, cut into four different segments, of reared fish (32–100 g). The analysis indicated immune activity along the entire intestine, but not as strong as in the hindgut. Furthermore, similar to the larger fish, the relative abundance of IgM transcripts was higher in the hindgut than in kidney and spleen, although the absolute level of IgM was in general higher in the larger fish. The secreted form of IgM was completely dominant in comparison to the membrane bound form of IgM and the other analysed genes. IgM was purified from gut mucus and external mucosal surfaces by magnetic beads coated with protein A. Mucus IgM reacted with rabbit antisera raised against serum IgM and contained subunits of the same size. Regarding the elevated immune activity in the intestine it is tempting to speculate on a possible compensatory strategy in this lineage of stomach-less fish, and that natural antibodies have an important role in the first line defence.",health
10.3168/jds.2018-14616,Journal,Journal of Dairy Science,scopus,2019-04-01,sciencedirect,Effect of repeated intravenous lipopolysaccharide infusions on systemic inflammatory response and endometrium gene expression in Holstein heifers,https://api.elsevier.com/content/abstract/scopus_id/85061058344,"This study aimed to evaluate the effect of repeated intravenous lipopolysaccharide (LPS) infusions in nonlactating heifers on (1) the systemic proinflammatory state as measured by biomarkers in blood and plasma, and (2) endometrial gene expression of candidate transcripts on d 15 of gestation. Our hypothesis was that target transcripts related to a major functional group would be negatively modified in the preimplantation endometrium by the LPS treatments. In the first experiment (n = 13), a systemic proinflammatory state [defined as increased plasma concentrations of tumor necrosis factor (TNF)-α and haptoglobin for 2 wk] was established using 2 different sequential LPS infusion protocols. In the second experiment, heifers (n = 22; 11 mo of age) had their time of ovulation synchronized by a modified Ovsynch protocol and were enrolled in 1 of 2 treatments: control (CON; n = 11), which received sterile saline solution i.v., and LPS treatment (LPS; n = 11), submitted to repeated i.v. LPS injections (0.10, 0.25, 0.50, 0.75, 1.00, and 1.25 µg/kg) starting 2 d after artificial insemination (AI; d 0) and then every other day until d 15 after AI. At each LPS injection, rectal temperatures were measured hourly for 6 h. Blood samples were collected from d −1 to d 13 for analyses of progesterone, TNF-α, and haptoglobin in plasma, along with white blood cell (WBC) count and differential analysis. On d 15, endometrium tissue biopsies were taken and kept at −80°C until quantitative real-time PCR analysis of 30 target transcripts related to the immune system, adhesion molecules, and endometrium receptivity. Data were checked for normality and analyzed by repeated-measures ANOVA using PROC UNIVARIATE and PROC MIXED of SAS (SAS Institute Inc., Cary, NC). After each LPS injection, temperature was greater in the first 4 h in the LPS group compared with CON. Both TNF-α and haptoglobin increased in the LPS treatment with a significant treatment by day interaction. Total leukocyte count did not differ between treatments, but the differential count increased for neutrophils, band cells, and monocytes, and decreased for lymphocytes and eosinophils in LPS compared with CON. Progesterone concentrations in plasma did not differ between treatments during the experimental period. Out of 30 target genes analyzed, 3 transcripts were differentially expressed: indoleamine 2,3-dioxygenase (IDO; fold-change = 0.48) and pentraxin-3 (PTX3; fold-change = 0.38) were downregulated, whereas myxovirus-resistance protein (MX1; fold-change = 2.85) was upregulated in the LPS group. Sequential LPS injections were able to induce a prolonged systemic proinflammatory state, but effects on gene expression were limited to transcripts associated with the immune system. These results suggest that a mechanism for subfertility is linked to a proinflammatory state in dairy heifers.",health
10.1016/j.artmed.2018.10.002,Journal,Artificial Intelligence in Medicine,scopus,2019-04-01,sciencedirect,A comparison between discrete and continuous time Bayesian networks in learning from clinical time series data with irregularity,https://api.elsevier.com/content/abstract/scopus_id/85060186293,"Background
                  Recently, mobile devices, such as smartphones, have been introduced into healthcare research to substitute paper diaries as data-collection tools in the home environment. Such devices support collecting patient data at different time points over a long period, resulting in clinical time-series data with high temporal complexity, such as time irregularities. Analysis of such time series poses new challenges for machine-learning techniques. The clinical context for the research discussed in this paper is home monitoring in chronic obstructive pulmonary disease (COPD).
               
                  Objective
                  The goal of the present research is to find out which properties of temporal Bayesian network models allow to cope best with irregularly spaced multivariate clinical time-series data.
               
                  Methods
                  Two mainstream temporal Bayesian network models of multivariate clinical time series are studied: dynamic Bayesian networks, where the system is described as a snapshot at discrete time points, and continuous time Bayesian networks, where transitions between states are modeled in continuous time. Their capability of learning from clinical time series that vary in nature are extensively studied. In order to compare the two temporal Bayesian network types for regularly and irregularly spaced time-series data, three typical ways of observing time-series data were investigated: (1) regularly spaced in time with a fixed rate; (2) irregularly spaced and missing completely at random at discrete time points; (3) irregularly spaced and missing at random at discrete time points. In addition, similar experiments were carried out using real-world COPD patient data where observations are unevenly spaced.
               
                  Results
                  For regularly spaced time series, the dynamic Bayesian network models outperform the continuous time Bayesian networks. Similarly, if the data is missing completely at random, discrete-time models outperform continuous time models in most situations. For more realistic settings where data is not missing completely at random, the situation is more complicated. In simulation experiments, both models perform similarly if there is strong prior knowledge available about the missing data distribution. Otherwise, continuous time Bayesian networks perform better. In experiments with unevenly spaced real-world data, we surprisingly found that a dynamic Bayesian network where time is ignored performs similar to a continuous time Bayesian network.
               
                  Conclusion
                  The results confirm conventional wisdom that discrete-time Bayesian networks are appropriate when learning from regularly spaced clinical time series. Similarly, we found that time series where the missingness occurs completely at random, dynamic Bayesian networks are an appropriate choice. However, for complex clinical time-series data that motivated this research, the continuous-time models are at least competitive and sometimes better than their discrete-time counterparts. Furthermore, continuous-time models provide additional benefits of being able to provide more fine-grained predictions than discrete-time models, which will be of practical relevance in clinical applications.",health
10.1016/j.sigpro.2018.12.005,Journal,Signal Processing,scopus,2019-04-01,sciencedirect,Multi-Layer domain adaptation method for rolling bearing fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85058167521,"In the past years, data-driven approaches such as deep learning have been widely applied on machinery signal processing to develop intelligent fault diagnosis systems. In real-world applications, domain shift problem usually occurs where the distribution of the labeled training data, denoted as source domain, is different from that of the unlabeled testing data, known as target domain. That results in serious diagnosis performance degradation. This paper proposes a novel domain adaptation method for rolling bearing fault diagnosis based on deep learning techniques. A deep convolutional neural network is used as the main architecture. The multi-kernel maximum mean discrepancies (MMD) between the two domains in multiple layers are minimized to adapt the learned representations from supervised learning in the source domain to be applied in the target domain. The domain-invariant features can be efficiently extracted in this way, and the cross-domain testing performance can be significantly improved. Experiments on two rolling bearing datasets are carried out to validate the effectiveness of the domain adaptation approach. Comparisons with other approaches and related works demonstrate the superiority of the proposed method. The experimental results of this study suggest the proposed domain adaptation method offers a new and promising tool for intelligent fault diagnosis.",health
10.1016/j.encep.2018.08.002,Journal,Encephale,scopus,2019-04-01,sciencedirect,Toward a motor signature in autism: Studies from human-machine interaction,https://api.elsevier.com/content/abstract/scopus_id/85057386595,"Background
                  Autism spectrum disorder (ASD) is a heterogeneous group of neurodevelopmental disorders which core symptoms are impairments in socio-communication and repetitive symptoms and stereotypies. Although not cardinal symptoms per se, motor impairments are fundamental aspects of ASD. These impairments are associated with postural and motor control disabilities that we investigated using computational modeling and developmental robotics through human-machine interaction paradigms.
               
                  Method
                  First, in a set of studies involving a human–robot posture imitation, we explored the impact of 3 different groups of partners (including a group of children with ASD) on robot learning by imitation. Second, using an ecological task, i.e. a real-time motor imitation with a tightrope walker (TW) avatar, we investigated interpersonal synchronization, motor coordination and motor control during the task in children with ASD (n
                     =29), TD children (n
                     =39) and children with developmental coordination disorder (n
                     =17, DCD).
               
                  Results
                  From the human–robot experiments, we evidenced that motor signature at both groups’ and individuals’ levels had a key influence on imitation learning, posture recognition and identity recognition. From the more dynamic motor imitation paradigm with a TW avatar, we found that interpersonal synchronization, motor coordination and motor control were more impaired in children with ASD compared to both TD children and children with DCD. Taken together these results confirm the motor peculiarities of children with ASD despite imitation tasks were adequately performed.
               
                  Discussion
                  Studies from human-machine interaction support the idea of a behavioral signature in children with ASD. However, several issues need to be addressed. Is this behavioral signature motoric in essence? Is it possible to ascertain that these peculiarities occur during all motor tasks (e.g. posture, voluntary movement)? Could this motor signature be considered as specific to autism, notably in comparison to DCD that also display poor motor coordination skills? We suggest that more work comparing the two conditions should be implemented, including analysis of kinematics and movement smoothness with sufficient measurement quality to allow spectral analysis.",health
10.1016/j.renene.2018.10.062,Journal,Renewable Energy,scopus,2019-04-01,sciencedirect,Real-time condition monitoring and fault detection of components based on machine-learning reconstruction model,https://api.elsevier.com/content/abstract/scopus_id/85056176666,"Reconstruction model is a powerful method for component condition monitoring and fault detection by considering the model prediction residuals. In this article, a new signal reconstruction modeling technique is proposed using support vector regression. Multiple indicators are calculated to recognize slight shift from normal condition, and detect the fault at an early stage. Input variables are selected based on correlation analysis and failure mode analysis. A sliding-time-window technique is employed to incorporate temporal information inherent in time-series data. Residuals between the observed signal and the reconstruction signal are utilized to indicate whether the desired quantity is different from its normal operation condition or not. Three statistical indicators (Deviation Index, Volatility Index and Significance Index) are defined to quantify the deviation level from normal condition to abnormal condition. Health index (HI) of a specific fault is derived from responsive statistical indicators, and the integral health index (integral-HI) of an entire component is composed of all individual health index. An experiment of real-life wind turbine high temperature fault detection scheme is studied. Results show that the proposed approach demonstrates improved performance in detecting wind turbine faults, and controlling false and missed alarms.",health
10.1016/j.jmii.2018.09.007,Journal,"Journal of Microbiology, Immunology and Infection",scopus,2019-04-01,sciencedirect,Implementation of a national quality improvement program to enhance hand hygiene in nursing homes in Taiwan,https://api.elsevier.com/content/abstract/scopus_id/85054556655,"Background/purpose
                  This study investigated the cause of hand hygiene deficit, and further implemented a quality improvement program using WHO's hand-hygiene strategy to enhance the compliance of hand hygiene in the nursing home in Taiwan.
               
                  Methods
                  This prospective study was conducted in eleven nursing homes in Taiwan from January 2015 to December 2016. After intervention, we monitor the compliance, and accuracy of hand hygiene. In addition, we also calculated the number of episodes of infection per 1000 resident-days in each nursing home in the intervention period (July–December 2015) and post-intervention period (January–October 2016).
               
                  Results
                  Overall, the consumption of alcohol-based handrubs increased from 10.1 ml per resident-day in intervention period to 12.2 ml per resident-day in post intervention period. The compliance of hand hygiene increased from 74% in intervention period to 79% in post-intervention period and the rate of correct hand hygiene increased from 81% in intervention period to 87% in post-intervention period. Most importantly, the infection density decreased from 2.39 per 1000 resident-day in intervention period to 1.89 per 1000 resident-day.
               
                  Conclusions
                  A national quality-improvement program using WHO's hand-hygiene strategy to enhance hand hygiene and reduce healthcare associated infection is effective in nursing homes in Taiwan.",health
10.1016/j.jep.2018.12.003,Journal,Journal of Ethnopharmacology,scopus,2019-03-25,sciencedirect,Water extract of ginseng and astragalus regulates macrophage polarization and synergistically enhances DDP's anticancer effect,https://api.elsevier.com/content/abstract/scopus_id/85058223879,"Ethnopharmacological relevance
                  In traditional Chinese medicine, supplementing Qi and strengthening body resistance are an important principle of anticancer treatment. Panax ginseng C.A.Mey. (ginseng) and Astragalus membranaceus Bunge (astragalus) are the representative herbs for this therapeutic principle.
               
                  Aim of the study
                  This study aims to explore the effect of the water extract of ginseng and astragalus (WEGA) on regulating macrophage polarization and mediating anticancer in the tumor microenvironment.
               
                  Materials and methods
                  A549 cells were cultured in tumor-associated macrophage (TAM) supernatant with various concentrations of WEGA (0, 5, 10, 20 mg/mL). A549 cell proliferation was determined through methyl thiazole tetrazolium (MTT) assay and real-time cell analysis (RTCA), respectively. In vivo experiments were performed with a Lewis lung cancer (LLC) xenograft mouse model. Forty-eight mice were divided into six groups and treated with saline, WEGA, or cis-diamine dichloro platinum (DDP) with dosage of WEGA (0, 30, 60, 120 mg/kg body weight/day). The different groups were administered with drugs via oral or intraperitoneal injection once a day for 21 consecutive days. Tumor inhibition rate, spleen index, thymus index, cytokine, protein, and mRNA expression levels were detected in mice.
               
                  Results
                  In a co-culture system, WEGA remarkably inhibited A549 cell proliferation, promoted the expression of M1 macrophage markers and inhibited M2 TAMs markers. Therefore, WEGA affected the biological behavior of cancer cells by regulating the expression of some markers relevant to macrophage polarization. In addition, the group of WEGA and DDP chemotherapy effectively inhibited the transplanted tumor growth in mice and improved weight loss and immunosuppressive with the cisplatin inducing.
               
                  Conclusions
                  This study provides mechanistic insights into the anticancer effect of WEGA through the regulation of macrophage polarization and highlights that WEGA could be a novel option for integrative cancer therapies.",health
10.1016/j.bios.2018.12.047,Journal,Biosensors and Bioelectronics,scopus,2019-03-15,sciencedirect,Fabrication of an ultrasensitive and selective electrochemical aptasensor to detect carcinoembryonic antigen by using a new nanocomposite,https://api.elsevier.com/content/abstract/scopus_id/85060201085,"A lable-free electrochemical aptasensor was successfully developed for the sensitive detection of carcinoembryonic antigen as a tumor biomarker. To do this, a ternary nanocomposite of hemin, graphene oxide and multi-walled carbon nanotubes was used. The aptamer can be attached to the surface of a hemin, graphene oxide and multi-walled carbon nanotubes glassy carbon electrode through –NHCO- covalent bonds to form a sensing surface. Through fourier transform infrared spectroscopy and scanning electron microscopy, it was indicated that hemin can be successfully incorporated into hemin, graphene oxide and multi-walled carbon nanotubes. Hemin, which protects graphene nanosheets, also serves as an in-situ probe owing to its well-defined redox properties. Multi-walled carbon nanotubes in the modifier enhance conductivity and facilitate the electron transfer between hemin and the glassy carbon electrode. In this study, carcinoembryonic antigen got specifically bound to the aptamer, and the current changes were used for selective and specific detection of that antigen. The devised aptasensor proved to have excellent performance with a wide linear range of 1.0 × 10–15 – 1.0 × 10−8 gmL−1 and a detection limit of 0.82 fg mL−1. The inter-day and intra-day values of RSD% were obtained in the range of 0.10–2.91 and 2.21–4.56 respectively. According to the experiments conducted on real samples, it may be claimed that the proposed label-free electrochemical aptasensor is capable enough of determining carcinoembryonic antigen in clinical diagnostics.",health
10.1053/j.semvascsurg.2018.12.006,Journal,Seminars in Vascular Surgery,scopus,2019-03-01,sciencedirect,The pathway to a national vascular skills examination and the role of simulation-based training in an increasingly complex specialty,https://api.elsevier.com/content/abstract/scopus_id/85068518473,"The evolving demands of surgical training have led to the successful implementation of skills examinations in the areas of laparoscopic and endoscopic surgery. Currently, there is no similar formal skills assessment in vascular surgery, despite endovascular intervention replacing open surgery in treatment of many vascular conditions. The adoption of less invasive techniques to treat aneurysm and occlusive disease has resulted in new training paradigms and technical challenges for trainees. The duty hour restriction for trainees and declining numbers of complex open vascular interventions have added to the challenges of vascular surgery training. Simulation is a promising avenue for both skills training and assessment. The ability to evaluate the fundamental skills of trainees would be an important step to ensure a degree of uniformity in trainees’ technical abilities. The role of simulation-based training in acquiring, testing, and refining these skills is still in its infancy in the vascular surgery training paradigm. This article aims to impart a deeper understanding of the conditions for developing and implementing the fundamentals of vascular and endovascular surgery, and to provide guidance regarding the role of simulation-based training in a rapidly evolving specialty. There are various forms of simulation available, including benchtop models, high-fidelity simulators, and virtual-reality simulators, and each requires a different method of proficiency assessment. Both open surgery and endovascular skills can be assessed and the application of successful implementation in academic vascular surgery training program is presented.",health
10.1016/j.jbi.2019.103114,Journal,Journal of Biomedical Informatics,scopus,2019-03-01,sciencedirect,Automatic ICD code assignment of Chinese clinical notes based on multilayer attention BiRNN,https://api.elsevier.com/content/abstract/scopus_id/85061803390,"International Classification of Diseases (ICD) code is an important label of electronic health record. The automatic ICD code assignment based on the narrative of clinical documents is an essential task which has drawn much attention recently. When Chinese clinical notes are the input corpus, the nature of Chinese brings some issues that need to be considered, such as the accuracy of word segmentation and the representation of single Chinese characters which contain semantics. Taking the lengthy text of patient notes and the representation of Chinese words into account, we present a multilayer attention bidirectional recurrent neural network (MA-BiRNN) model to implement the assignment of disease codes. A hierarchical approach is used to represent the feature of discharge summaries without manual feature engineering. The combination of character level embedding and word level embedding can improve the representation of words. Attention mechanism is introduced into bidirectional long short term memory networks, which helps to solve the performance dropping problem when plain recurrent neural networks encounter long text sequences. The experiment is carried out on a real-world dataset containing 7732 admission records in Chinese and 1177 unique ICD-10 labels. The proposed model achieves 0.639 and 0.766 in F1-score on full-level code and block-level code, respectively. It outperforms the baseline neural network models and achieves the lowest Hamming loss value. Ablation analysis indicates that the multilevel attention mechanism plays a decisive role in the system for dealing with Chinese clinical notes.",health
10.1016/j.vaa.2018.09.044,Journal,Veterinary Anaesthesia and Analgesia,scopus,2019-03-01,sciencedirect,Neurotoxicity of intraneural injection of bupivacaine liposome injectable suspension versus bupivacaine hydrochloride in a porcine model,https://api.elsevier.com/content/abstract/scopus_id/85060719795,"Objective
                  To test whether neurotoxic effects of a bupivacaine liposome injectable suspension differ from those of a standard formulation of bupivacaine hydrochloride (HCl) after intraneural injection into the sciatic nerves in pigs.
               
                  Study design
                  Prospective, randomized study.
               
                  Animals
                  Fifteen pigs, hybrids of Landrace and Large White.
               
                  Methods
                  After the National Ethics Committee approval, 15 pigs were randomly allocated to three groups (n = 5/group) to receive intraneural injections of 4 mL of 1.33% bupivacaine liposome injectable suspension, 0.5% bupivacaine HCl or normal saline. Serial neurologic examinations were conducted to detect sensory and motor response to noxious stimuli using a modified Thalhammer’s scale at 2 hour intervals for the first 12 hours after injection and daily thereafter for 2 weeks. Fiber characteristics (density) of the harvested sciatic nerves were measured during histomorphometric analysis. Inflammatory response was studied using immunohistochemical analysis. Data were tested using analyses of variance; p values for paired comparisons were Bonferroni adjusted.
               
                  Results
                  Compared with bupivacaine HCl, bupivacaine liposome injectable suspension provided longer sensory (11.2 ± 1.8 hours versus 3.2 ± 1.1 hours, respectively, p < 0.0001) and motor (10.0 ± 2.0 hours versus 4.0 ± 1.4 hours respectively, p < 0.0001) blockade. Histomorphometric parameters were similar among the groups. No changes in axonal density or myelin structure indicative of injury to the sciatic nerves were observed in any of the groups. Number of immunopositive cells did not differ between the bupivacaine liposome injectable suspension (23 ± 6 cells per mm2) and the bupivacaine HCl groups (21 ± 4 cells per mm2), p > 0.90.
               
                  Conclusions and clinical relevance
                  Intraneural injections of bupivacaine liposome injectable suspension or bupivacaine HCl in our porcine model did not result in evidence of neurotoxicity.",health
10.1016/j.healthplace.2019.01.014,Journal,Health and Place,scopus,2019-03-01,sciencedirect,Public spaces and happiness: Evidence from a large-scale field experiment,https://api.elsevier.com/content/abstract/scopus_id/85060243870,"This study examines the relationships between public spaces, immediate environment and momentary subjective wellbeing (M-SWB). The empirical findings are based on a unique dataset collected from tens of thousands of students in Singapore. The students wore a sensor for one week, and happy moments were captured as well as geospatial an environmental data throughout the country. This is a large-scale in-the-wild user study. The findings provide weak empirical evidence that visiting parks and community centers increase the probability of experiencing M-SWB compared with commercial areas. In line with previous studies, proximity to natural influencers such as green-, blue spaces or reservoirs was found to be not statistically significant. On the other hand, immediate noise levels and air temperature were strongly associated with M-SWB. The unique contribution of the paper is the estimation of place-, environment-, and personal-effects on momentary happiness using nearly-real time data.",health
10.1016/j.measurement.2019.01.014,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2019-03-01,sciencedirect,An analytical method for measuring the Parkinson's disease progression: A case on a Parkinson's telemonitoring dataset,https://api.elsevier.com/content/abstract/scopus_id/85060099109,"The use of machine learning techniques for early diseases diagnosis has attracted the attention of scholars worldwide. Parkinson’s Disease (PD) is one of themost common neurological and complicated diseases affecting the central nervous system. Unified Parkinson’s Disease Rating Scale (UPDRS) is widely used for tracking PD symptom progression. Motor- and Total-UPDRS are two important clinical scales of PD. The aim of this study is to predict UPDRS scores through analyzing the speech signal properties which is important in PD diagnosis. We take the advantages of ensemble learning and dimensionality reduction techniques and develop a new hybrid method to predict Total- and Motor-UPDRS. We accordingly improve the time complexity and accuracy of the PD diagnosis systems, respectively, by using Singular Value Decomposition (SVD) and ensembles of Adaptive Neuro-Fuzzy Inference System (ANFIS). We evaluate our method on a large PD dataset and present the results. The results showed that the proposed method is effective in predicting PD progression by improving the accuracy and computation time of the disease diagnosis. The method can be implemented as a medical decision support system for real-time PD diagnosis when big data from the patients is available in the medical datasets.",health
10.1016/j.fsi.2018.12.046,Journal,Fish and Shellfish Immunology,scopus,2019-03-01,sciencedirect,Molecular characterization and expression analysis of signal transducer and activator of transcription 1 (STAT1) in Japanese eel Anguilla japonica,https://api.elsevier.com/content/abstract/scopus_id/85059159927,"Signal transducer and activator of transcription 1 (STAT1) is one of critical signal transduction proteins of interferon (IFN) pathway and the structure and function of this protein have been well identified in mammals, but the information about the STAT1 is still limited in teleost fishes. In the present study, the full-length cDNA sequence of STAT1 (AjSTAT1) in Japanese eel (Anguilla japonica) was identified and characterized. Multiple alignment of the amino acid sequence showed that the AjSTAT1 protein has the typical conserved domains including the amino-terminal, coiled-coil, DNA-binding, linker, Src homology 2 (SH2), transcriptional activation domains (TAD). Quantitative real-time polymerase chain reaction (qRT-PCR) analysis revealed a broad expression for AjSTAT1 in a wide range of tissues, with the predominant expression in liver, followed by the spleen, intestine, gills, skin, kidney, and the very low expression in heart and muscle. The AjSTAT1 expressions in liver, spleen and kidney were significantly induced following injection with LPS, the viral mimic poly I:C, and Aeromonas hydrophila infection. In vitro, the AjSTAT1 transcripts of Japanese eel liver cells were significantly enhanced by the treatment of poly I:C or the stimulation of the high concentration of Aeromonas hydrophila (1 × 107 cfu/mL and 1 × 108 cfu/mL). Subcellular localization showed that in the natural state AjSTAT1was uniformly distributed in the cytoplasm, but AjSTAT1 was found to aggregated in the cytoplasm as well as partly in the nucleus after the stimulation of LPS and poly I:C. These results collectively suggested AjSTAT1 is an important transcription factor possibly involved in Japanese eel defense against viral and bacterial infection.",health
10.1016/j.future.2018.09.033,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Life Model: A novel representation of life-long temporal sequences in health predictive analytics,https://api.elsevier.com/content/abstract/scopus_id/85054711685,"Predictive analytics in healthcare can prevent patients’ emergency health conditions, and reduce costs in the long term. Moreover, accurate and timely anomaly predictions by focusing on recent events can save lives. In real-time IoT predictive analytics, modeling historical temporal health records with missing values in diagnosis prediction is a major challenge. Recent studies have started using deep learning and data abstraction techniques to model health data. However, it is difficult to train a model to predict anomalies based on temporal sparse data, especially to classify all disease diagnosis classes. Modeling a lifetime of an individual’s medical history in a short, concise sequence is a challenge. Moreover, the model should be robust and preserve the concept of time for variety of examples despite the missing values; especially in an IoT system, in which real-time prediction depends on both recent data and historical records.
                  The proposed solution in this research for modelingtemporal pattern sequences is called as Life Model (LM). 
                        L
                        M
                      provides a concise sequence to represent the history or future, using the novel intensity temporal sequence (ITS) tensors. LM algorithms and properties enable ITS tensors to train long short-term memory (LSTM) recurrent neural networks (RNN) efficiently in order to predict anomalies and diagnosis in real-time, even in the absence of some values.
                  LM is used to predict mortality of 10,000 patients from MIMIC III dataset based on their diagnosis and procedures codes. The results show improvement in the model trained by LM-mapped data compared to fixed-sized intervals which achieved an accuracy of 99.6% with AUROC and brier score of 99.5% and of 0.00 respectively. In addition, the LM model can predict the approximate time of activities, with different granularity of seconds and up to years; tested on an activity dataset.
                  Furthermore, a new LM-powered predictive health analytics and real-time monitoring schema (PHARMS) is proposed to enable design and implementation of predictive health analytic systems. PHARMS uses deep learning for real-time minimally-invasive intelligent activity monitoring and predictive analysis in a medical IoT scheme.",health
10.1016/j.inffus.2018.06.002,Journal,Information Fusion,scopus,2019-03-01,sciencedirect,Data fusion and multiple classifier systems for human activity detection and health monitoring: Review and open research directions,https://api.elsevier.com/content/abstract/scopus_id/85048959618,"Activity detection and classification using different sensor modalities have emerged as revolutionary technology for real-time and autonomous monitoring in behaviour analysis, ambient assisted living, activity of daily living (ADL), elderly care, rehabilitations, entertainments and surveillance in smart home environments. Wearable devices, smart-phones and ambient environments devices are equipped with variety of sensors such as accelerometers, gyroscopes, magnetometer, heart rate, pressure and wearable camera for activity detection and monitoring. These sensors are pre-processed and different feature sets such as time domain, frequency domain, wavelet transform are extracted and transform using machine learning algorithm for human activity classification and monitoring. Recently, deep learning algorithms for automatic feature representation have also been proposed to lessen the burden of reliance on handcrafted features and to increase performance accuracy. Initially, one set of sensor data, features or classifiers were used for activity recognition applications. However, there are new trends on the implementation of fusion strategies to combine sensors data, features and classifiers to provide diversity, offer higher generalization, and tackle challenging issues. For instances, combination of inertial sensors provide mechanism to differentiate activity of similar patterns and accurate posture identification while other multimodal sensor data are used for energy expenditure estimations, object localizations in smart homes and health status monitoring. Hence, the focus of this review is to provide in-depth and comprehensive analysis of data fusion and multiple classifier systems techniques for human activity recognition with emphasis on mobile and wearable devices. First, data fusion methods and modalities were presented and also feature fusion, including deep learning fusion for human activity recognition were critically analysed, and their applications, strengths and issues were identified. Furthermore, the review presents different multiple classifier system design and fusion methods that were recently proposed in literature. Finally, open research problems that require further research and improvements are identified and discussed.",health
10.1016/j.future.2018.02.011,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Collaborative prognostics in Social Asset Networks,https://api.elsevier.com/content/abstract/scopus_id/85042391186,"With the spread of Internet of Things (IoT) technologies, assets have acquired communication, processing and sensing capabilities. In response, the field of Asset Management has moved from fleet-wide failure models to individualised asset prognostics. Individualised models are seldom truly distributed, and often fail to capitalise the processing power of the asset fleet. This leads to hardly scalable machine learning centralised models that often must find a compromise between accuracy and computational power. In order to overcome this, we present a novel theoretical approach to collaborative prognostics within the Social Internet of Things. We introduce the concept of Social Asset Networks, defined as networks of cooperating assets with sensing, communicating and computing capabilities. In the proposed approach, the information obtained from the medium by means of sensors is synthesised into a Health Indicator, which determines the state of the asset. The Health Indicator of each asset evolves according to an equation determined by a triplet of parameters. Assets are given the form of the equation but they ignore their parametric values. To obtain these values, assets use the equation in order to perform a non-linear least squares fit of their Health Indicator data. Using these estimated parameters, they are interconnected to a subset of collaborating assets by means of a similarity metric. We show how by simply interchanging their estimates, networked assets are able to precisely determine their Health Indicator dynamics and reduce maintenance costs. This is done in real time, with no centralised library, and without the need for extensive historical data. We compare Social Asset Networks with the typical self-learning and fleet-wide approaches, and show that Social Asset Networks have a faster convergence and lower cost. This study serves as a conceptual proof for the potential of collaborative prognostics for solving maintenance problems, and can be used to justify the implementation of such a system in a real industrial fleet.",health
10.1016/j.comnet.2018.11.024,Journal,Computer Networks,scopus,2019-02-11,sciencedirect,PAIN: A Passive Web performance indicator for ISPs,https://api.elsevier.com/content/abstract/scopus_id/85057533904,"Understanding the quality of web browsing enjoyed by users is key to optimize services and keep users’ loyalty. This is crucial for both Content Providers and Internet Service Providers (ISPs). Quality is intrinsically subjective, and the complexity of today’s websites challenges its measurement. Objective metrics like OnLoad time and SpeedIndex are notable attempts to quantify web performance. However, these metrics can only be computed by instrumenting the browser and, thus, are not available to ISPs.
                  PAIN (PAssive INdicator) is an automatic system to monitor the performance of websites from passive measurements. It is open source and available for download. It leverages only flow-level and DNS measurements which are still possible in the network despite the deployment of HTTPS. With unsupervised learning, PAIN automatically creates a model from the timeline of requests issued by browsers to render web pages, and uses it to measure website performance in real-time.
                  We compare PAIN to objective metrics based on in-browser instrumentation and find strong correlations between the approaches. PAIN correctly highlights worsening network conditions and provides visibility into websites performance. We let PAIN run on an operational ISP network, and find that it is able to pinpoint performance variations across time and groups of users.",health
10.1016/j.oceaneng.2019.01.003,Journal,Ocean Engineering,scopus,2019-02-01,sciencedirect,Data management for structural integrity assessment of offshore wind turbine support structures: data cleansing and missing data imputation,https://api.elsevier.com/content/abstract/scopus_id/85061324147,"Structural Health Monitoring (SHM) and Condition Monitoring (CM) Systems are currently utilised to collect data from offshore wind turbines (OWTs), to enhance the accurate estimation of their operational performance. However, industry accepted practices for effectively managing the information that these systems provide have not been widely established yet. This paper presents a four-step methodological framework for the effective data management of SHM systems of OWTs and illustrates its applicability in real-time continuous data collected from three operational units, with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures. Firstly, a time-efficient synchronisation method that enables the continuous monitoring of these systems is presented, followed by a novel approach to noise cleansing and the posterior missing data imputation (MDI). By the implementation of these techniques those data-points containing excessive noise are removed from the dataset (Step 2), advanced numerical tools are employed to regenerate missing data (Step 3) and fatigue is estimated for the results of these two methodologies (Step 4). Results show that after cleansing, missing data can be imputed with an average absolute error of 2.1%, while this error is kept within the [+ 15.2%−11.0%] range in 95% of cases. Furthermore, only 0.15% of the imputed data fell outside the noise thresholds. Fatigue is found to be underestimated both, when data cleansing does not take place and when it takes place but MDI does not. This makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses.",health
10.1016/j.therap.2018.12.002,Journal,Therapie,scopus,2019-02-01,sciencedirect,"Early access to health products in France: Major advances of the French “Conseil stratégique des industries de santé” (CSIS) to be implemented (modalities, regulations, funding)",https://api.elsevier.com/content/abstract/scopus_id/85061149651,"In a context of perpetual evolution of treatments, access to therapeutic innovation is a major challenge for patients and the various players involved in the procedures of access to medicines. The revolutions in genomic and personalized medicine, artificial intelligence and biotechnology will transform the medicine of tomorrow and the organization of our health system. It is therefore fundamental that France prepares for these changes and supports the development of its companies in these new areas. The recent “Conseil stratégique des industries de santé” launched by Matignon makes it possible to propose a regulatory arsenal conducive to the implementation and diffusion of therapeutic innovations. In this workshop, we present a number of proposals, our approach having remained pragmatic with a permanent concern to be effective in the short term for the patients and to simplify the procedures as much as possible. This was achieved thanks to the participation in this workshop of most of the players involved (industrial companies, “Agence nationale de sécurité du médicament et des produits de santé”, “Haute Autorité de santé”, “Institut national du cancer”, “Les entreprises du médicament”, hospitals, “Observatoire du médicament, des dispositifs médicaux et de l’innovation thérapeutique”…). The main proposals tend to favor the implementation of clinical trials on our territory, especially the early phases, a wider access to innovations by favoring early access programs and setting up a process called “autorisation temporaire d’utilisation d’extension” (ATUext) that make it possible to prescribe a medicinal product even if the latter has a marketing authorisation in another indication. In addition, we propose a conditional reimbursement that will be available based on preliminary data but will require re-evaluation based on consolidated data from clinical trials and/or real-life data. Finally, in order to better carry out these assessments, with a view to access or care, we propose the establishment of partnership agreements with health agencies/hospitals in order to encourage the emergence of field experts, in order to prioritize an ascending expertise closer to patients’ needs and to real life.",health
10.1016/j.cja.2018.12.011,Journal,Chinese Journal of Aeronautics,scopus,2019-02-01,sciencedirect,Aircraft engine fault detection based on grouped convolutional denoising autoencoders,https://api.elsevier.com/content/abstract/scopus_id/85060907128,"Many existing aircraft engine fault detection methods are highly dependent on performance deviation data that are provided by the original equipment manufacturer. To improve the independent engine fault detection ability, Aircraft Communications Addressing and Reporting System (ACARS) data can be used. However, owing to the characteristics of high dimension, complex correlations between parameters, and large noise content, it is difficult for existing methods to detect faults effectively by using ACARS data. To solve this problem, a novel engine fault detection method based on original ACARS data is proposed. First, inspired by computer vision methods, all variables were divided into separated groups according to their correlations. Then, an improved convolutional denoising autoencoder was used to extract the features of each group. Finally, all of the extracted features were fused to form feature vectors. Thereby, fault samples could be identified based on these feature vectors. Experiments were conducted to validate the effectiveness and efficiency of our method and other competing methods by considering real ACARS data as the data source. The results reveal the good performance of our method with regard to comprehensive fault detection and robustness. Additionally, the computational and time costs of our method are shown to be relatively low.",health
10.1016/j.dib.2018.12.063,Journal,Data in Brief,scopus,2019-02-01,sciencedirect,PADI-web corpus: Labeled textual data in animal health domain,https://api.elsevier.com/content/abstract/scopus_id/85059576151,"Monitoring animal health worldwide, especially the early detection of outbreaks of emerging pathogens, is one of the means of preventing the introduction of infectious diseases in countries (Collier et al., 2008) [3]. In this context, we developed PADI-web, a Platform for Automated extraction of animal Disease Information from the Web (Arsevska et al., 2016, 2018). PADI-web is a text-mining tool that automatically detects, categorizes and extracts disease outbreak information from Web news articles. PADI-web currently monitors the Web for five emerging animal infectious diseases, i.e., African swine fever, avian influenza including highly pathogenic and low pathogenic avian influenza, foot-and-mouth disease, bluetongue, and Schmallenberg virus infection. PADI-web collects Web news articles in near-real time through RSS feeds. Currently, PADI-web collects disease information from Google News because of its international and multiple language coverage. We implemented machine learning techniques to identify the relevant disease information in texts (i.e., location and date of an outbreak, affected hosts, their numbers and clinical signs). In order to train the model for Information Extraction (IE) from news articles, a corpus in English has been manually labeled by domain experts. This labeled corpus (Rabatel et al., 2017) is presented in this data paper.",health
10.1016/j.vetmic.2018.12.025,Journal,Veterinary Microbiology,scopus,2019-02-01,sciencedirect,Presence of gammaherpesvirus BoHV-4 in endometrial cytology samples is not associated with subclinical endometritis diagnosed at artificial insemination in dairy cows,https://api.elsevier.com/content/abstract/scopus_id/85059306271,"In the past, bovine herpesvirus 4 (BoHV-4) has been suggested to be associated with metritis and endometritis. However, not many field studies investigated the association between BoHV-4 and subclinical endometritis (SCE). In the present study, the association between the intrauterine presence of BoHV-4 and SCE diagnosed during artificial insemination (AI) was examined on two dairy farms in Belgium. An immunoperoxidase monolayer assay (IPMA) and an enzyme-linked immuno sorbent assay (ELISA) were used to screen the serum for anti-BoHV-4 antibodies. A SYBR green based one step real time qPCR was used to detect and quantify BoHV-4 (ORF20) in nasal, uterine and vaginal samples collected at AI. A reverse transcription qPCR (RT-qPCR) was used to detect mRNA (gB) as proof of a productive BoHV-4 infection. BoHV-4 was detected in 39.4% (farm A)/23.8% (farm B) of the nasal samples, 48.5% (farm A)/19.0% (farm B) of the uterine samples and 51.5% (farm A)/42.9% (farm B) of the vaginal samples. Active replication was only detected in farm A in 38.5% of the BoHV-4 positive nasal samples and in 5.9% positive cases of the vaginal samples. The prevalence of SCE diagnosed at AI was 45.5% and 42.9% in farm A and farm B, respectively. The presence of SCE was associated with a reduced pregnancy outcome at artificial insemination (AI) (P＜0.001). The occurrence of SCE at AI was not associated with the presence of latent or productive BoHV4 infections in the uterus nor in the vagina and nose (P＞0.05).",health
10.1016/j.compag.2018.12.028,Journal,Computers and Electronics in Agriculture,scopus,2019-02-01,sciencedirect,Detection of grapevine yellows symptoms in Vitis vinifera L. with artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85059032087,"Grapevine yellows (GY) are a significant threat to grapes due to the severe symptoms and lack of treatments. Conventional diagnosis of the phytoplasmas associated to GYs relies on symptom identification, due to sensitivity limits of diagnostic tools (e.g. real time PCR) in asymptomatic vines, where the low concentration of the pathogen or its erratic distribution can lead to a high rate of false-negatives. GY’s primary symptoms are leaf discoloration and irregular wood ripening, which can be easily confused for symptoms of other diseases making recognition a difficult task. Herein, we present a novel system, utilizing convolutional neural networks, for end-to-end detection of GY in red grape vine (cv. Sangiovese), using color images of leaf clippings. The diagnostic test detailed in this work does not require the user to be an expert at identifying GY. Data augmentation strategies make the system robust to alignment errors during data capture. When applied to the task of recognizing GY from digital images of leaf clippings—amongst many other diseases and a healthy control—the system has a sensitivity of 98.96% and a specificity of 99.40%. Deep learning has 35.97% and 9.88% better predictive value (PPV) when recognizing GY from sight, than a baseline system without deep learning and trained humans respectively. We evaluate six neural network architectures: AlexNet, GoogLeNet, Inception v3, ResNet-50, ResNet-101 and SqueezeNet. We find ResNet-50 to be the best compromise of accuracy and training cost. The trained neural networks, code to reproduce the experiments, and data of leaf clipping images are available on the internet. This work will advance the frontier of GY detection by improving detection speed, enabling a more effective response to the disease.",health
10.1016/j.asoc.2018.10.034,Journal,Applied Soft Computing Journal,scopus,2019-02-01,sciencedirect,Using Multilayer Fuzzy Cognitive Maps to diagnose Autism Spectrum Disorder,https://api.elsevier.com/content/abstract/scopus_id/85056747379,"Autism Spectrum Disorder (ASD) is comprised of a group of heterogeneous neurodevelopmental conditions, typically characterized by a triad of symptoms consisting of (1) impaired communication, (2) restricted interests, and (3) repetitive and stereotypical behavior pattern. An accurate and early diagnosis of autism can provide the basis for an appropriate educational and treatment program. In this work, we propose a computational model using a Multilayer Fuzzy Cognitive Map (hereafter referred to as MFCM) based on standardized behavioral assessments diagnosing the ASD (MFCM-ASD). The two standards used in the model are: the Autism Diagnostic Observation Schedule, Second Edition (ADOS2), and the Autism Diagnostic Interview Revised (ADIR). The MFCM’s are a soft computing technique characterized by robust properties that make it an effective technique for medical decision support systems. For the evaluation of the MFCM-ASD model, we have used real datasets of diagnosed cases, so as to compare against other method/approaches. Initial experiments demonstrated that the proposed model outperforms conventional Fuzzy Cognitive Maps (FCMs) for ASD diagnosis. Our MFCM-ASD model serves as a diagnostic tool required to support the medical decisions when determining the correct diagnosis of Autism in children with different cognitive characteristics.",health
10.1016/j.wneu.2018.10.091,Journal,World Neurosurgery,scopus,2019-02-01,sciencedirect,Surgical Management of Isolated Fourth Ventricular Hydrocephalus Associated with Injury to the Guillain-Mollaret Triangle,https://api.elsevier.com/content/abstract/scopus_id/85056639302,"Background
                  The occurrence of isolated fourth ventricle and injury to the Guillain-Mollaret triangle in the setting of posterior fossa ependymoma represents a new association. In this case report, we discuss the clinical, theoretical, and therapeutic aspects of this problem. We describe a lateral transcerebellar trajectory and shunt valve configuration for safe fourth ventricle shunting in a patient with prior posterior fossa surgery.
               
                  Case Description
                  A 45-year-old woman underwent subtotal resection of a fourth ventricle ependymoma (World Health Organization grade III) followed by radiation therapy to control the residual tumor. Her course was complicated by a cerebral abscess and subsequent communicating hydrocephalus, for which she received a lateral ventriculoperitoneal shunt. After placement of the lateral ventricle shunt, there was a progressive increase in the volume of the fourth ventricle over the next 2 years, from 2.5 to 12.0 mL. She developed palatal myoclonus, hand incoordination, bilateral foot numbness, and progressive ataxia. Neuroimaging also revealed hypertrophic degeneration of the inferior olivary nuclei bilaterally. The isolated fourth ventricle was treated by a separate fourth ventriculoperitoneal shunt inserted through a lateral transcerebellar trajectory. A programmable variable pressure valve was implemented.
               
                  Conclusions
                  Development of an isolated fourth ventricle and injury to the Guillain-Mollaret triangle in the setting of fourth ventricular ependymoma is a newly encountered complication. Choice of treatment modality and timing of intervention should be carefully considered on a case-by-case basis. The data presented in this report may assist in the selection of surgical treatment for isolated fourth ventricle.",health
10.1016/j.ymssp.2018.06.051,Journal,Mechanical Systems and Signal Processing,scopus,2019-02-01,sciencedirect,Torsional system dynamics of low speed diesel engines based on instantaneous torque: Application to engine diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85050400148,"Low speed large engines such as those found in marine applications or power plants present large and flexible crankshafts. These elements as well as all the others linked to them, such as the pistons, connecting rods, camshaft and the flywheel, form a torsional system of nonlinear nature for which it is very worthwhile to identify and solve relevant anomalies such as efficiency losses, power imbalance or injection system malfunctions. This work presents a torsional nonlinear model of a two-stroke low speed diesel engine that has been developed and validated through experiments, using the instantaneous torque (IT) between the generator and engine as the validation magnitude. The analysed system loads covered the whole operational range of the system, i.e. 55%, 70%, 85% and 100% of the engine’s attainable power. The lumped torsional system was modelled with 16 degrees of freedom and was solved applying Fourier series expansion for the linear part of the system and with an iterative procedure for the nonlinear character of the system dynamics, which requires up to 12 iterations. A parameter model identification process was performed in Section 4 due to the uncertainty between the data supplied by the manufacturer and real data. As a result, the maximum error between the model and experimental data was reduced to 1.5%. In Section 5 a parametric study was developed that made it possible to establish the relationship between the in-cylinder combustion process and IT. This knowledge is taken into account in Section 6 to generate a proper set of inputs and outputs which is used to train an artificial neural network (ANN). Once trained, this network simulates the indicated mean power (WMI) at each cylinder with an error less than 1% for any load and engine condition. The main goal of the work is to develop a diagnostic tool for the identification and quantification of combustion-related anomalies that can contribute to maintaining the system efficiency as new.",health
10.1016/j.scitotenv.2018.08.221,Journal,Science of the Total Environment,scopus,2019-01-15,sciencedirect,Design and implementation of a hybrid model based on two-layer decomposition method coupled with extreme learning machines to support real-time environmental monitoring of water quality parameters,https://api.elsevier.com/content/abstract/scopus_id/85051670088,"Accurate prediction of water quality parameters plays a crucial and decisive role in environmental monitoring, ecological systems sustainability, human health, aquaculture and improved agricultural practices. In this study a new hybrid two-layer decomposition model based on the complete ensemble empirical mode decomposition algorithm with adaptive noise (CEEMDAN) and the variational mode decomposition (VMD) algorithm coupled with extreme learning machines (ELM) and also least square support vector machine (LSSVM) was designed to support real-time environmental monitoring of water quality parameters, i.e. chlorophyll-a (Chl-a) and dissolved oxygen (DO) in a Lake reservoir. Daily measurements of Chl-a and DO for June 2012–May 2013 were employed where the partial autocorrelation function was applied to screen the relevant inputs for the model construction. The variables were then split into training, validation and testing subsets where the first stage of the model testing captured the superiority of the ELM over the LSSVM algorithm. To improve these standalone predictive models, a second stage implemented a two-layer decomposition with the model inputs decomposed in the form of high and low frequency oscillations, represented by the intrinsic mode function (IMF) through the CEEMDAN algorithm. The highest frequency component, IMF1 was further decomposed with the VMD algorithm to segregate key model input features, leading to a two-layer hybrid VMD-CEEMDAN model. The VMD-CEEMDAN-ELM model was able to reduce the root mean square and the mean absolute error by about 14.04% and 7.12% for the Chl-a estimation and about 5.33% and 4.30% for the DO estimation, respectively, compared with the standalone counterparts. Overall, the developed methodology demonstrates the robustness of the two-phase VMD-CEEMDAN-ELM model in identifying and analyzing critical water quality parameters with a limited set of model construction data over daily horizons, and thus, to actively support environmental monitoring tasks, especially in case of high-frequency, and relatively complex, real-time datasets.",health
10.1016/j.neucom.2018.03.074,Journal,Neurocomputing,scopus,2019-01-09,sciencedirect,Wave2Vec: Deep representation learning for clinical temporal data,https://api.elsevier.com/content/abstract/scopus_id/85047795765,"Representation learning for time series has gained increasing attention in healthcare domain. The recent advancement in semantic learning allows researcher to learn meaningful deep representations of clinical medical concepts from Electronic Health Records (EHRs). However, existing models cannot deal with continuous physiological records, which are often included in EHRs. The major challenges for this task are to model non-obvious representations from observed high-resolution biosignals, and to interpret the learned features. To address these issues, we propose Wave2Vec, an end-to-end deep representation learning model, to bridge the gap between biosignal processing and semantic learning. Wave2Vec not only jointly learns both inherent and temporal representations of biosignals, but also allows us to interpret the learned representations reasonably over time. We propose two embedding mechanisms to capture the temporal knowledge within signals, and discover latent knowledge from signals in time-frequency domain, namely component-based motifs. To validate the effectiveness of our model in clinical task, we carry out experiments on two real-world benchmark biosignal datasets. Experimental results demonstrate that the proposed Wave2Vec model outperforms six feature learning baselines in biosignal processing. Analytical results show that the proposed model can incorporate both motif co-occurrence information and time series information of biosignals, and hence provides clinically meaningful interpretation.",health
10.1016/B978-0-12-817594-1.00014-0,Book,Artificial Intelligence for Computational Modeling of the Heart,scopus,2019-01-01,sciencedirect,Learning cardiac anatomy,https://api.elsevier.com/content/abstract/scopus_id/85093487304,"An essential prerequisite for constructing the heart model is fast and robust parsing of the cardiovascular anatomy based on image data. This entails the detection, segmentation and tracking of anatomical structures or pathologies in the human heart and vascular system. Current solutions for these problems are based on machine learning and require large annotated image databases for effective training. In practice, however, these techniques often suffer from inherent limitations related to the efficiency in scanning high-dimensional parametric spaces and the learning of representative features for describing the image content. In this chapter, we present several established techniques for cardiac image parsing and structure tracking. For image parsing, we describe the marginal space learning framework, including the original version of the system that relies on handcrafted steerable features, as well as the modern redesign of the framework based on the latest automatic feature learning technology using deep learning. To address the limitations of these techniques that rely on exhaustive search, we present the concept of intelligent image parsing. Based on deep reinforcement learning and scale-space theory, this approach enables the efficient parsing of high-resolution volumetric data in real-time. Several experiments are included to analyze the performance of these methods on different problems using large datasets. This chapter also briefly describes a modern deep image-to-image neural network architecture for whole heart isolation. For cardiac structure tracking, a comprehensive review is presented of state-of-the-art structure tracking methods based on convolutional neural networks and recurrent neural networks.",health
10.1016/B978-0-12-819178-1.00035-6,Book,"Precision Medicine for Investigators, Practitioners and Providers",scopus,2019-01-01,sciencedirect,Precision medicine in ophthalmology: An evolving revolution in diagnostic and therapeutic tools,https://api.elsevier.com/content/abstract/scopus_id/85093483812,"Precision medicine refers to a stratification of patients using a wide array of individual-specific data to enable precise targeting of disease subgroups with the best available diagnostic and therapeutic approaches. Within ophthalmology, this strategy is being applied successfully and is most evident in the management of the inherited diseases. This paradigm shift in provision of care is accelerated by the emergence of novel imaging technologies, robotics, and artificial intelligence, as well as emerging technologies that integrate bioinformatics data into clinically relevant knowledge. This knowledge is used in turn to develop a system capable of supporting clinical decision-making and utilization of high-precision therapeutic options in both a personalized and cost-effective way. Examples of the diverse areas making rapid progress toward full implementation of precision medicine include, but are not limited to, ocular genetic diseases, robotic surgery, virtual reality simulations, modern imaging techniques, and the role of healthcare providers.",health
10.1016/B978-0-12-818318-2.00009-X,Book,Handbook of Data Science Approaches for Biomedical Engineering,scopus,2019-01-01,sciencedirect,Semisupervised fuzzy clustering methods for X-ray image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85084967350,"In the modern world, people care more about dental health care, and dentistry has an important role in our health. Using dental X-ray images, dentists can diagnose possible dental diseases and create an effective treatment for patients. In this chapter, we introduce several machine learning methods to segment the dental images to support dentists in dental disease diagnoses. The proposed methods have been implemented on the real dataset of radiography patients from Hanoi Medical University Hospital. The empirical results show that these methods have a higher performance than the related ones through various validity indices. The content of this chapter presents the results of our research that has been performed since 2015.",health
10.1016/j.promfg.2020.01.333,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Prognostic health management of production systems. New proposed approach and experimental evidences,https://api.elsevier.com/content/abstract/scopus_id/85082764769,"Prognostic Health Management (PHM) is a maintenance policy aimed at predicting the occurrence of a failure in components and consequently minimizing unexpected downtimes of complex systems. Recent developments in condition monitoring (CM) techniques and Artificial Intelligence (AI) tools enabled the collection of a huge amount of data in real-time and its transformation into meaningful information that will support the maintenance decision-making process. The emerging Cyber-Physical Systems (CPS) technologies connect distributed physical systems with their virtual representations in the cyber computational world. The PHM assumes a key role in the implementation of CPS in manufacturing contexts, since it allows to keep CPS and its machines in proper conditions. On the other hand, CPS-based PHM provide an efficient solution to maximize availability of machines and production systems. In this paper, evolving and unsupervised approaches for the implementation of PHM at a component level are described, which are able to process streaming data in real-time and with almost-zero prior knowledge about the monitored component. A case study from a real industrial context is presented. Different unsupervised and online anomaly detection methods are combined with evolving clustering models in order to detect anomalous behaviours in streaming vibration data and integrate the so-generated knowledge into supervised and adaptive models; then, the degradation model for each identified fault is built and the resulting RUL prediction model integrated into the online analysis. Supervised methods are applied to the same dataset, in batch mode, to validate the proposed procedure.",health
10.1016/j.procs.2019.12.023,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Next generation IoT and its influence on decision-making. An illustrative case study,https://api.elsevier.com/content/abstract/scopus_id/85081057182,"The next generation of IoT is characterized by the usage of smart solutions with embedded intelligence at the edge that relies on high connectivity, processing capabilities for edge devices and real-time analysis of information. This evolution is based on the convergence of some key ICT technologies like hyperconnectivity and new network architectures, edge computing, artificial intelligence, and blockchain. Considering the high expectations regarding the wide use in various domains of the new, interoperable IoT platforms built on these technologies, it is assumed that they will influence also the decision-making processes specific to these domains. The paper provides a short overview of these technologies with the aim to identify such potential influences. Then a case study in the field of health monitoring is presented, which consists in proposing a new version of a current pilot solution built around the sensing service offer integrator role. This new version is compliant with the RO-Smart Ageing architecture and will provide specific support for all three decision levels implemented in the medical unit practice, with special emphases on risk evaluation in real time monitoring regime.",health
10.1016/j.procs.2019.09.442,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Unmanned aerial vehicle in the machine learning environment,https://api.elsevier.com/content/abstract/scopus_id/85079097933,"Unmanned Aerial Vehicles and machine learning have started gaining attentions of academic and industrial research. The Unmanned Aerial Vehicles have extended the freedom to operate and monitor the activities from remote locations. This study retrieved and synthesized research on the use of Unmanned Aerial Vehicles along with machine learning and its algorithms in different areas and regions. The objective was to synthesize the scope and importance of machine learning models in enhancing Unmanned Aerial Vehicles capabilities, solutions to problems, and numerous application areas.
                  The machine learning implementation has reduced numbers of challenges to Unmanned Aerial Vehicles besides enhancing the capabilities and opening the door to the different sectors. The Unmanned Aerial Vehicles and machine learning association has resulted in fast and reliable outputs. The combination of Unmanned Aerial Vehicles and machine learning has helped in real time monitoring, data collection and processing, and prediction in the computer/wireless networks, smart cities, military, agriculture, and mining.",health
10.1016/j.procs.2019.11.044,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,An extended-input grnn and its application,https://api.elsevier.com/content/abstract/scopus_id/85079097483,"A new extended-input General Regression Neural Network scheme is proposed. The main objective of such a step was to increase the accuracy of the regression tasks. Such an extension is based on using of the Ito decomposition. This scheme is more appropriate in comparison with existing ones and provides an increase of the prediction accuracy due to the high approximation properties of this decomposition. The developed ANN is used to solve the missing data recovery task. This real dataset was collected by the IoT device, and it is characterized by a large number of passes. A number of practical experiments were carried out on setting of the optimal parameters of the proposed scheme. It has been established that the values ​​of Gaussian functions deviations greater than 0.1 greatly increase the errors of extended-input GRNN. In addition, the larger than the second order Ito decomposition does not improve the accuracy of the ANN and substantially increases the duration of its use. Experimentally established the highest accuracy of the developed ANN in comparison with existing methods.",health
10.1016/j.procs.2019.09.458,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,A comparative study of predictive approaches for load forecasting in smart buildings,https://api.elsevier.com/content/abstract/scopus_id/85079086707,"Predicting electricity consumption represents one of most important information for efficient energy management in smart buildings. It is mainly used for occupancy prediction and the development of optimized control approaches of building’s appliances (e.g., lighting and heating/air conditioning systems). Recently, several approaches have been proposed for load profiling, prediction and forecasting. The work presented in this paper is towards the development of load forecasting approaches for being integrated for occupancy prediction and context-driven control of building’s appliances. We mainly investigated the accuracy of various machine learning and statistical methods for forecasting energy consumption. An IoT and Big Data based platform was deployed for gathering near-real time data about electricity/load consumption. Recorded data were used to deploy predictive models using ARIMA, SARIMA, XGBoost, Random Forest (RF), and Long Short-Term Memory. Experiments have been conducted and results are reported to shed more light on the accuracy of these methods for load forecasting.",health
10.1016/j.procir.2019.04.249,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,Automated learning of user preferences for selection of high quality 3D designs,https://api.elsevier.com/content/abstract/scopus_id/85076776351,"3D object design is one of the most sought-after topics due to its application in many domains including Medical imaging, Virtual Reality, Computer Graphics, Animation etc. Manual 3D object design is inherently an expensive and labour intensive task. Several techniques such as GAN (Generative Adversarial Nets), SFM (Structure from Motion) and MVS (Multi-View Stereo) are employed to automate 3D design. 3D-GAN is one such method that allows the fully automated design of 3D objects using deep artificial neural networks. However, such generated 3D objects often suffer from distortions, obscure/missing parts, and other artefacts. For a large number of generated models, it becomes time-consuming for the human expert to select models of high quality among the set of generated ones. In this paper, we tackle this problem through machine learning powered 3D model quality assessment algorithm, that mimics the users preferences. For our experiments, we generate 3D objects using 3D-GAN and investigate several machine learning algorithms including Support Vector Machines, Gradient Boosting, Deep Neural Networks to classify generated models based on their visual appealability. We find that our model successfully mimics user choices with 90% accuracy, thus eliminating the need for human intervention in the subjective quality analysis, once user preferences have been learned. The proposed system can be seamlessly integrated into existing automated 3D design systems further augmenting the capabilities of human designers.",health
10.1016/j.ifacol.2019.09.143,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,Machine Learning approaches for Anomaly Detection in Multiphase Flow Meters,https://api.elsevier.com/content/abstract/scopus_id/85076262725,"Multiphase Flow Meters (MPFM) are important metering tools in the oil and gas industry. A MPFM provides real-time measurements of gas, oil and water flows of a well without the need to separate the phases, a time-consuming procedure that has been classically adopted in the industry. Evaluating the composition of the flow is fundamental for the well management and productivity prediction; therefore, procedures for measuring quality assessment are of crucial importance. In this work we propose an Anomaly Detection approach to MPFM that is effectively able to hand the complexity and variability associated with MPFM data. The proposed approach is designed for embedded implementation and it exploits unsupervised Anomaly Detection approaches like Cluster Based Local Outlier Factor and Isolation Forest.",health
10.1016/j.procs.2019.09.224,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Hybrid system for information extraction from social media text: Drug abuse case study,https://api.elsevier.com/content/abstract/scopus_id/85076256057,"Social media are becoming widely used in the healthcare field as a patients-caregivers communication tool giving birth to new sources of information rich with the knowledge that may improve this field. Therefore, social media data analysis becomes a real business requirement for healthcare industrials and data scientists.
                  However, regarding their complexity and unstructured character, existing natural language processing tools cannot succeed their exploitation. In the literature, a wide range of approaches appeared based on dictionaries, linguistic patterns and machine learning having their strengths and weaknesses.
                  In this work, we propose a hybrid system combining the above approaches by taking the advantage of each of them to extract structured and salient drug abuse information from health-related tweets. We improve the system accuracy by real time update of the domain dictionary. We collected 1000000 tweets and we conducted different experiments showing the advantage of hybridization on efficient information extraction from social media data.",health
10.1016/j.procs.2019.09.069,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,An Innovative Technology: Augmented Reality Based Information Systems,https://api.elsevier.com/content/abstract/scopus_id/85076255225,"In our generation the information systems evolve with new technologies: augmented reality (AR), IoT, artificial intelligence, blockchain etc. Anymore they perform information exchange by sensors. It is estimated that the systems will be in a state of extreme interaction and reach 50 billion devices connected in Internet in 2020. We know that everything around us will be in interaction and they will do everything without any need of human interference. For example, when our dishwasher is full, it will start to wash automatically, or when the run out of the gasoline, our car will drive to the nearest station, or even when a burglar is entered to our house, it will automatically be detected and be announced to the police office. In business life, the processes will be automatical in maximum level and this technology will increase productivity and efficiency. Next to mobile technology, it is thought that these new generation information systems (IS) will take the biggest place in our lives. AR also will be integrated to these systems to augment the information in real world. Humanity will augment its habitat in an innovative way thanks to these AR based IS. This paper surveys the current state-of-the-art AR systems related with aerospace & defense, industry, education, medical and gaming sectors. The connection of AR based IS and innovation is explained with a technological insight. In addition to international use cases HAVELSAN’s use cases are also given that are performed from the aspect of applied open innovation strategy. This strategy is addressed specific to the implemented activities of AR based IS.",health
10.1016/j.tgie.2019.150631,Journal,Techniques in Gastrointestinal Endoscopy,scopus,2019-01-01,sciencedirect,Artificial intelligence for colon polyp detection: Why should we embrace this?,https://api.elsevier.com/content/abstract/scopus_id/85074523579,"Optimal success of colonoscopy for prevention of colorectal cancer is currently measured by adenoma detection rate (ADR), which reflects a colonoscopists ability to identify colorectal and remove precancerous polyps. Among colonoscopists in the same health care system and shared patient population, ADR varies from 7% to 53%. For every 1% increase in ADR, risk of interval colorectal cancer is reduced by 3%-6%. Beyond attaining excellent exposure of entire mucosal surface during colonoscopy, ADR can be improved with a second observer. Computer-aided detection (“facial recognition” for polyps) has potential to improve ADR as a second observer. Several groups are working to bring this technology into the endoscopy unit. Success will require real-time implementation of an affordable system with very high accuracy and proven benefit to improve ADR and reduce miss rate of precancerous lesions. In just the past year, computer-aided detection systems that run live during colonoscopy have been shown to improve ADR using affordable off-the-shelf computers.",health
10.1016/j.procs.2019.08.224,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Air pollution mapping using mobile sensor based on internet of things,https://api.elsevier.com/content/abstract/scopus_id/85073097835,"Air pollution is hazardous to our health, especially carbon monoxide. It can cause diseases such as cough, runny nose, eye irritation, and even death. The main objective of this research is to create a device capable of detecting carbon monoxide pollution levels by using mobile sensors and map the results into heatmaps overlayed on Google Maps. We have implemented an integrated pollution monitoring and mapping system that consists of MQ-7 sensor, GPS, GSM, display module, Arduino board, and web-server. We also evaluated two sampling methods, time-based and distance-based sampling. Based on our experiments, the distance-based sampling method produced well-distributed data and closer to the expected between-samples distances compared to the time-based method. We have also shown that our system can run in real time to monitor the carbon monoxide pollution levels.",health
10.1016/j.promfg.2018.12.017,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,AI based injection molding process for consistent product quality,https://api.elsevier.com/content/abstract/scopus_id/85072584818,"In manufacturing processes, Injection Molding is widely used for producing plastic components with large lot size. So, continuous improvements in product quality consistency is crucial to maintaining a competitive edge in the injection molding industry. Various optimization techniques like ANN, GA, Iterative method, and simulation based are being used for optimization of Injection Molding process and obtaining optimal processing conditions. But still due to variation during molding cycles, quality failure occurs. As many constituents like process, Material, machine together yields product quality. This paper is focused on Real time AI based control of process parameters in injection molding cycle. Process parameters and their interrelationship with quality failure has been studied and later supposed to be used to generate algorithm for compensating the deviation of process parameters. Pressure and temperature sensor assisted monitoring system is used to collect data in real time and based on its comparison with the standard values an interrelationship is formed between parameters and plastic material properties. Algorithm generates new process parameter values to compensate the deviation and machine control follows the same. The entire process is supposed to be smart and automatic after being trained with AI and machine learning techniques. Simulation using Moldflow software and real industry collected data has been used for understanding whole molding process establishing relationship between failure and parameters. An automotive product in real industry is chosen for data acquisition, implementation and validation of entire AI based system.",health
10.1016/j.matpr.2019.06.045,Conference Proceeding,Materials Today: Proceedings,scopus,2019-01-01,sciencedirect,Human wrist motion classification using decision tree and principle component analysis,https://api.elsevier.com/content/abstract/scopus_id/85072383423,"This study investigates and acts as a trial clinical outcome for human motion and behaviour analysis in consensus of health related quality of life in Malaysia. Both methods were developed in MATLAB platform by managing and analyzing motion data in graphical user interface (GUI) form. By attaching the wearable sensors to each segments of interest, the collected data can be reconstructed in real time basis. Artificial intelligence technique is proposed to classify the subjects’ motions. Data reconstruction technique can be used to regenerate the motion of subjects’ limbs movement in 2D representation. Corresponding tests are performed to validate the accuracy of the application. The application is potentially to be used to access the quality of human motion in hospitals, clinics and human motion research. An experiment was set up in a laboratory environment for data collecting. Subjects were asked to perform three shape drawings using left and right hands. The instruments demonstrate adequate internal consistency of optimum average accuracy of 52 % for decision tree and 80 % for principle component analysis. Results were presented in tabular, image and graphical forms. The expected output of the study can be used to estimate joint angles in predicting Parkinson Disease for early stage symptoms, to track the moving behaviour in clinical gait analysis, to analyse limb movement in detecting resting tremor, to trace wrist motion in regenerating children handwriting difficulty, and to measure joint motion in evaluating patient rehabilitation progress.",health
10.1016/j.jagp.2019.05.013,Journal,American Journal of Geriatric Psychiatry,scopus,2019-01-01,sciencedirect,A Future Research Agenda for Digital Geriatric Mental Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85067070294,"The proliferation of mobile, online, and remote monitoring technologies in digital geriatric mental health has the potential to lead to the next major breakthrough in mental health treatments. Unlike traditional mental health services, digital geriatric mental health has the benefit of serving a large number of older adults, and in many instances, does not rely on mental health clinics to offer real-time interventions. As technology increasingly becomes essential in the everyday lives of older adults with mental health conditions, these technologies will provide a fundamental service delivery strategy to support older adults’ mental health recovery. Although ample research on digital geriatric mental health is available, fundamental gaps in the scientific literature still exist. To begin to address these gaps, we propose the following recommendations for a future research agenda: 1) additional proof-of-concept studies are needed; 2) integrating engineering principles in methodologically rigorous research may help science keep pace with technology; 3) studies are needed that identify implementation issues; 4) inclusivity of people with a lived experience of a mental health condition can offer valuable perspectives and new insights; and 5) formation of a workgroup specific for digital geriatric mental health to set standards and principles for research and practice. We propose prioritizing the advancement of digital geriatric mental health research in several areas that are of great public health significance, including 1) simultaneous and integrated treatment of physical health and mental health conditions; 2) effectiveness studies that explore diagnostics and treatment of social determinants of health such as “social isolation” and “loneliness;” and 3) tailoring the development and testing of innovative strategies to minority older adult populations.",health
10.3382/ps/pey325,Journal,Poultry Science,scopus,2019-01-01,sciencedirect,Protection against duck hepatitis a virus type 1 conferred by a recombinant avian adeno-associated virus,https://api.elsevier.com/content/abstract/scopus_id/85060577845,"The avian adeno-associated virus (AAAV) has been proved to be an efficient gene transfer vector for human gene therapy and vaccine research. In this experiment, an AAAV-based vaccine was evaluated for the development of a vaccine against duck hepatitis a virus type 1 (DHAV-1). The major capsid VP1 gene was amplified and subcloned into pFBGFP containing the inverted terminal repeats of AAAV, and then the recombinant baculovirus rBac-VP1 was generated. The recombinant AAAV expressing the VP1 protein (rAAAV-VP1) was produced by co-infecting Sf9 cells with rBac-VP1 and the other 2 baculoviruses containing AAAV functional genes and structural genes respectively, and confirmed by electron microscopy, Western blotting and immunofluorescence assays. Quantitative real-time PCR revealed that the titer of rAAAV-VP1 was about 9 × 1012 VG/mL. Immunogenicity was studied in ducklings. One day ducklings were injected intramuscularly once with rAAAV-VP1. Serum from rAAAV-VP1-vaccinated ducklings showed a systemic immune response evidenced by VP1-specific enzyme-linked immunosorbent assay and virus neutralization test. Furthermore, all ducklings inoculated with rAAAV-VP1 were protected against DHAV-1 challenge. The data of quantitative real-time RT-PCR from livers of challenged ducklings also showed that the level of virus copies in rAAAV-VP1 group was significantly lower than that of the PBS group. Collectively, these results demonstrate that the AAAV-based vaccine is a potential vaccine candidate for the control of duck viral hepatitis.",health
10.1016/j.aei.2019.01.001,Journal,Advanced Engineering Informatics,scopus,2019-01-01,sciencedirect,BA-PNN-based methods for power transformer fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85059870064,"This paper presents a machine learning-based approach to power transformer fault diagnosis based on dissolved gas analysis (DGA), a bat algorithm (BA), optimizing the probabilistic neural network (PNN). PNN is a radial basis function feedforward neural network based on Bayesian decision theory, which has a strong fault tolerance and significant advantages in pattern classification. However, one challenge still remains: the performance of PNN is greatly affected by its hidden layer element smooth factor which impacts the classification performance. The proposed approach addresses this challenge by deploying the BA algorithm, a kind of bio-inspired algorithm to optimize PNN. Using the real data collected from a transformer system, we conducted the experiments for validating the performance of the developed method. The experimental results demonstrated that BA is an effective algorithm for optimizing PNN smooth factor and BA-PNN can improve the fault diagnosis performance; in turn, and the machine learning-based model (BA-PNN) can significantly enhance the accuracies of power transformer fault diagnosis.",health
10.1016/j.imu.2018.12.002,Journal,Informatics in Medicine Unlocked,scopus,2019-01-01,sciencedirect,Implementation of a TCM-based computational health informatics diagnostic tool for Sub-Saharan African students,https://api.elsevier.com/content/abstract/scopus_id/85058678042,"Health status checkup is a crucial step towards early detection of diseases. Health status diagnosis, in university health centers, within the sub-Saharan African region, can be cumbersome and time consuming. In many cases, facilities for health checkup are not available. Traditional Chinese Medicine (TCM) is a promising approach, when integrated with in-silico methods. This study was conducted to implement a TCM-based computational health informatics diagnostic tool. The tool was applied to diagnose African students. This study was also conducted to stimulate further research into in-silico TCM diagnostics. Besides developing a reliable biometric verification system, to ascertain the real identities of patients brought to university health centers, it is assistive to create a platform that provides automated and complementary support for preliminary health diagnostic activities. It also mitigates stress, by helping to efficiently decipher and provide quick objective opinion from the perspective of a computerized decision support system. The diagnostic module of the computational health informatics diagnostic tool adopts knowledge from a TCM facial color diagnosis.
                  A comprehensive literature search was conducted for relevant full-text research papers. Only research publications written in English language were reviewed. The present work was compared qualitatively and quantitatively with the existing works noted in the literature. Facial detection and matching algorithms were implemented for the TCM-based computational health informatics diagnostic tool by using Java programming language. Facial image acquisition processes were conducted. Captured facial images of African students were preprocessed. Facial feature extraction was performed by implementing feature extraction algorithms. An algorithm for the extraction of color information and measurement was also implemented. Knowledge of machine learning was applied to extract and collate facial features, and to machine learn from them. Facial classification and recognition algorithms were implemented. Finally, the results from the computational health informatics diagnostic tool were evaluated, by conducting a performance evaluation and validation.
                  This study provides qualitative and quantitative information on facial recognition, facial color information measurement, as well as prediction of health status, for some sub-Saharan African University students. Performance evaluation was shown using confusion matrix and ROC curves. Statistical analysis of the experimental results was presented. The parameters in each diagnostic illustration were shown with valid range. In order to justify the effectiveness of the computational tool, further explanations were provided from relevant methodology guides on the evaluation of diagnostic tests.
                  The computational health informatics diagnostic tool will complement the diagnostic efforts in university health centers of sub-Saharan African universities. It will also be useful for personal health diagnosis of interested individuals. The tool will also be viable for educating health professionals. TCM will be of immense benefit to developing countries by positively contributing towards diagnosing different non-communicable diseases and some infectious diseases in such countries.",health
10.1016/j.impact.2018.12.001,Journal,NanoImpact,scopus,2019-01-01,sciencedirect,SUNDS probabilistic human health risk assessment methodology and its application to organic pigment used in the automotive industry,https://api.elsevier.com/content/abstract/scopus_id/85058641247,"The increasing use of engineered nanomaterials (ENMs) in nano-enabled products (NEPs) has raised societal concerns about their possible health and ecological implications. To ensure a high level of human and environmental protection it is essential to properly estimate the risks of these new materials and to develop adequate risk management strategies. To this end, we propose a quantitative Human Health Risk Assessment (HHRA) methodology, which was developed in the European Seventh Framework research project SUN (Sustainable Nanotechnologies) and implemented in the web-based SUN Decision Support System (SUNDS). One of the major strengths of this probabilistic approach as compared to its deterministic alternatives is its ability to clearly communicate the uncertainties in the estimated risks in order to support better risk communication for more objective decision making by industries and regulators.
                  To demonstrate this methodology, we applied it in a real case study involving a nanoscale organic red pigment used in the automotive industry. Our analysis clearly showed that the main source of uncertainty was the extrapolation from (sub)acute in vivo toxicity data to long-term risk. This extrapolation was necessary due to a lack of (sub)chronic in vivo studies for the investigated nanomaterial. Despite the high uncertainty in the final results due to the conservative assumptions made in the risks assessment, the estimated risks are acceptable for all investigated exposure scenarios along the product lifecycle.",health
10.1016/j.media.2018.10.010,Journal,Medical Image Analysis,scopus,2019-01-01,sciencedirect,"A collaborative computer aided diagnosis (C-CAD) system with eye-tracking, sparse attentional model, and deep learning",https://api.elsevier.com/content/abstract/scopus_id/85055895805,"Computer aided diagnosis (CAD) tools help radiologists to reduce diagnostic errors such as missing tumors and misdiagnosis. Vision researchers have been analyzing behaviors of radiologists during screening to understand how and why they miss tumors or misdiagnose. In this regard, eye-trackers have been instrumental in understanding visual search processes of radiologists. However, most relevant studies in this aspect are not compatible with realistic radiology reading rooms. In this study, we aim to develop a paradigm shifting CAD system, called collaborative CAD (C-CAD), that unifies CAD and eye-tracking systems in realistic radiology room settings. We first developed an eye-tracking interface providing radiologists with a real radiology reading room experience. Second, we propose a novel algorithm that unifies eye-tracking data and a CAD system. Specifically, we present a new graph based clustering and sparsification algorithm to transform eye-tracking data (gaze) into a graph model to interpret gaze patterns quantitatively and qualitatively. The proposed C-CAD collaborates with radiologists via eye-tracking technology and helps them to improve their diagnostic decisions. The C-CAD uses radiologists’ search efficiency by processing their gaze patterns. Furthermore, the C-CAD incorporates a deep learning algorithm in a newly designed multi-task learning platform to segment and diagnose suspicious areas simultaneously. The proposed C-CAD system has been tested in a lung cancer screening experiment with multiple radiologists, reading low dose chest CTs. Promising results support the efficiency, accuracy and applicability of the proposed C-CAD system in a real radiology room setting. We have also shown that our framework is generalizable to more complex applications such as prostate cancer screening with multi-parametric magnetic resonance imaging (mp-MRI).",health
10.1016/j.media.2018.10.008,Journal,Medical Image Analysis,scopus,2019-01-01,sciencedirect,3D regression neural network for the quantification of enlarged perivascular spaces in brain MRI,https://api.elsevier.com/content/abstract/scopus_id/85055753914,"Enlarged perivascular spaces (EPVS) in the brain are an emerging imaging marker for cerebral small vessel disease, and have been shown to be related to increased risk of various neurological diseases, including stroke and dementia. Automated quantification of EPVS would greatly help to advance research into its etiology and its potential as a risk indicator of disease. We propose a convolutional network regression method to quantify the extent of EPVS in the basal ganglia from 3D brain MRI. We first segment the basal ganglia and subsequently apply a 3D convolutional regression network designed for small object detection within this region of interest. The network takes an image as input, and outputs a quantification score of EPVS. The network has significantly more convolution operations than pooling ones and no final activation, allowing it to span the space of real numbers. We validated our approach using a dataset of 2000 brain MRI scans scored visually. Experiments with varying sizes of training and test sets showed that a good performance can be achieved with a training set of only 200 scans. With a training set of 1000 scans, the intraclass correlation coefficient (ICC) between our scoring method and the expert’s visual score was 0.74. Our method outperforms by a large margin - more than 0.10 - four more conventional automated approaches based on intensities, scale-invariant feature transform, and random forest. We show that the network learns the structures of interest and investigate the influence of hyper-parameters on the performance. We also evaluate the reproducibility of our network using a set of 60 subjects scanned twice (scan-rescan reproducibility). On this set our network achieves an ICC of 0.93, while the intrarater agreement reaches 0.80. Furthermore, the automated EPVS scoring correlates similarly to age as visual scoring.",health
10.1016/j.jneumeth.2018.10.019,Journal,Journal of Neuroscience Methods,scopus,2019-01-01,sciencedirect,Unsupervised and real-time spike sorting chip for neural signal processing in hippocampal prosthesis,https://api.elsevier.com/content/abstract/scopus_id/85055320745,"Background
                  Damage to the hippocampus will result in the loss of ability to form new long-term memories and cognitive disorders. At present, there is no effective medical treatment for this issue. Hippocampal cognitive prosthesis is proposed to replace damaged regions of the hippocampus to mimic the function of original biological tissue. This prosthesis requires a spike sorter to detect and classify spikes in the recorded neural signal.
               
                  New method
                  A 16-channel spike sorting processor is presented in this paper, where all channels are considered as independent. An automatic threshold estimation method suitable for hardware implementation is proposed for the Osort clustering algorithm. A new distance metric is also introduced to facilitate clustering. Bayes optimal template matching classification algorithm is optimized to reduce computational complexity by introducing a preselection mechanism.
               
                  Results
                  The chip was fabricated in 40-nm CMOS process with a core area of 0.0175 mm2/ch and power consumption of 19.0 μW/ch. Synthetic and realistic test data are used to evaluate the chip. The test result shows that it has high performance on both data.
               
                  Comparison with existing method(s)
                  Compared with the other three spike sorting processors, the proposed chip achieves the highest detection and classification accuracy. It also has the ability to deal with partially overlapping spikes, which is not reported in the other work.
               
                  Conclusions
                  We have developed a 16-channel spike sorting chip used in hippocampal prosthesis, which provides unsupervised clustering and real-time detection and classification. It also has the ability to deal with partially overlapping spikes.",health
10.1016/j.midw.2018.10.004,Journal,Midwifery,scopus,2019-01-01,sciencedirect,Developing and evaluating an online learning tool to improve midwives’ accuracy of visual estimation of blood loss during waterbirth: An experimental study,https://api.elsevier.com/content/abstract/scopus_id/85055294797,"Objective
                  The principal objective was to test the effectiveness of an online learning tool to improve midwives’ accuracy of blood loss estimations in a birthing pool environment. The secondary objective was to assess the acceptability of the online learning tool to the midwives using it.
               
                  Design
                  A one group pre-test, post-test experiment with immediate and six weeks follow-up to test ability together with an online questionnaire to assess perceived usefulness of an online learning tool.
               
                  Setting
                  A large NHS maternity hospital comprising an acute care obstetric unit, a small district unit labour ward, one alongside midwifery-led unit and three freestanding midwifery-led units.
               
                  Participants
                  Volunteer NHS employed midwives who had experience in caring for women labouring and giving birth in water (n = 24).
               
                  Intervention
                  An online learning tool comprising six randomly ordered short video simulations of blood loss in a birthing pool in real time, and a tutorial giving verbal and pictorial guidance on making accurate blood loss estimations in water was developed then piloted. Midwives’ accuracy scores for estimating blood loss in each of the videos were calculated at three timepoints; pre and immediately post the learning component, and six weeks later. The estimated blood loss volume was subtracted from the actual blood loss volume, to give the difference between estimated and real blood loss in millilitres (ml) which was then converted to percentage difference to standardise comparison across the six volumes. The differences between pre- and post-learning for each of the six blood volumes was analysed using a repeated measures ANOVA. Statistical significance was set at p < 0.05. An online questionnaire incorporated questions using Likert scales to gauge confidence and competence and free text. Free text responses were analysed using a modified form of inductive content analysis.
               
                  Findings
                  Twenty-two midwives completed the online learning and immediate post-test, 14 completed a post-test after six weeks, and 15 responded to the online questionnaire. Pre-test results showed under-estimation of all blood loss volumes and particularly for the two largest volumes (1000 and 1100 ml). Across all volumes, accuracy of estimation was significantly improved at post-test 1. Accuracy diminished slightly, but overall improvement remained, at post-test 2. Participants rated the online tool positively and made suggestions for refining it.
               
                  Key conclusions and implications for practice
                  This is the first study measuring the accuracy of midwives’ blood loss estimations in a birthing pool using real-time simulations and testing the effectiveness of an online learning tool to improve this important skill. Our findings indicate a need to develop interventions to improve midwives’ accuracy at visually estimating blood loss in water, and the potential of an online approach. Most women who labour and/or give birth in water do so in midwifery-led settings without immediate access to medical support. Accuracy in blood loss estimations is an essential core skill",health
10.1016/j.cmpb.2017.11.015,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-01-01,sciencedirect,White blood cells identification system based on convolutional deep neural learning networks,https://api.elsevier.com/content/abstract/scopus_id/85034981078,"Background and objectives
                  White blood cells (WBCs) differential counting yields valued information about human health and disease. The current developed automated cell morphology equipments perform differential count which is based on blood smear image analysis. Previous identification systems for WBCs consist of successive dependent stages; pre-processing, segmentation, feature extraction, feature selection, and classification. There is a real need to employ deep learning methodologies so that the performance of previous WBCs identification systems can be increased. Classifying small limited datasets through deep learning systems is a major challenge and should be investigated.
               
                  Methods
                  In this paper, we propose a novel identification system for WBCs based on deep convolutional neural networks. Two methodologies based on transfer learning are followed: transfer learning based on deep activation features and fine-tuning of existed deep networks. Deep acrivation featues are extracted from several pre-trained networks and employed in a traditional identification system. Moreover, a novel end-to-end convolutional deep architecture called “WBCsNet” is proposed and built from scratch. Finally, a limited balanced WBCs dataset classification is performed through the WBCsNet as a pre-trained network.
               
                  Results
                  During our experiments, three different public WBCs datasets (2551 images) have been used which contain 5 healthy WBCs types. The overall system accuracy achieved by the proposed WBCsNet is (96.1%) which is more than different transfer learning approaches or even the previous traditional identification system. We also present features visualization for the WBCsNet activation which reflects higher response than the pre-trained activated one.
               
                  Conclusion
                  a novel WBCs identification system based on deep learning theory is proposed and a high performance WBCsNet can be employed as a pre-trained network.",health
10.1016/j.enbuild.2018.10.016,Journal,Energy and Buildings,scopus,2018-12-15,sciencedirect,Semi-supervised learning for early detection and diagnosis of various air handling unit faults,https://api.elsevier.com/content/abstract/scopus_id/85055560300,"Modern data-driven fault detection and diagnosis (FDD) techniques show impressive high diagnostic accuracy in recognizing various air handling units (AHUs) faults. Most existing data-driven FDD approaches simply adopt supervised machine learning techniques that presume the availability of a sufficient number of faulty training data samples. However, in real-world AHU FDD scenarios, the number of faulty training samples is not enough to support supervised learning methods, since faults are usually fixed within short periods of time. In this study, a semi-supervised learning FDD framework is proposed to deal with the above problem. By using the proposed framework, the training pool can be enriched by iteratively inserting confidently labeled testing samples, which mimics the scenario of detecting faults the earliest possible. Furthermore, the proposed framework can be easily extended with various kinds of state-of-art classifiers. Three important tradeoffs are observed through a series of experiments. With a reasonably small number of faulty training data samples available, the performance of the proposed semi-supervised learning technique is comparable to the classic supervised FDD methods.",health
10.1016/j.enconman.2018.10.040,Journal,Energy Conversion and Management,scopus,2018-12-15,sciencedirect,Random forest based intelligent fault diagnosis for PV arrays using array voltage and string currents,https://api.elsevier.com/content/abstract/scopus_id/85054901450,"With the rapid growth of installed capacity of photovoltaic power systems, status monitoring and fault diagnosis of PV arrays becomes increasingly important for improving the energy conversion and maintenance efficiency. In recent years, many machine learning algorithms were successfully applied to automatically build fault diagnosis models using the fault data samples. However, most of them suffer overfitting problem and the generalization performance is still limited. In this paper, the random forest (RF) ensemble learning algorithm is explored for the detection and diagnosis of PV arrays early faults (including line-line faults, degradation, open circuit, and partial shading), which combines multiple learning algorithms to achieve a superior diagnostic performance. The proposed RF based fault diagnosis model only takes the real-time operating voltage and string currents of the PV arrays as the fault features, which is irrelevant to the environment conditions. In addition, a grid-search method is used to optimize the parameters of the RF model by minimizing the out-of-bag error estimation, so as to improve the fault diagnosis model. In order to obtain sufficient fault data samples, comprehensive fault experiments are conducted on both a Simulink based simulated PV system and a laboratory PV system. The simulation and experimental results both demonstrate that the optimized RF based fault diagnosis model can achieve a high overall detection and diagnosis performance. Moreover, the comparison results indicate that the generalization performance of the proposed RF based model is better than the one of the decision tree based model. Therefore, the proposed optimal RF based method is an effective and efficient alternative to detect and classify the faults of PV arrays. Furthermore, the proposed RF based fault diagnosis model is successfully integrated into a Matlab based real-time monitoring system prototype developed for the laboratory PV system, which validates the practicability as well.",health
10.1016/S2213-2600(18)30300-X,Journal,The Lancet Respiratory Medicine,scopus,2018-12-01,sciencedirect,Machine learning for real-time prediction of complications in critical care: a retrospective study,https://api.elsevier.com/content/abstract/scopus_id/85059098244,"Background
                  The large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery.
               
                  Methods
                  We used deep learning methods (recurrent neural networks) to predict several severe complications (mortality, renal failure with a need for renal replacement therapy, and postoperative bleeding leading to operative revision) in post cardiosurgical care in real time. Adult patients who underwent major open heart surgery from Jan 1, 2000, to Dec 31, 2016, in a German tertiary care centre for cardiovascular diseases formed the main derivation dataset. We measured the accuracy and timeliness of the deep learning model's forecasts and compared predictive quality to that of established standard-of-care clinical reference tools (clinical rule for postoperative bleeding, Simplified Acute Physiology Score II for mortality, and the Kidney Disease: Improving Global Outcomes staging criteria for acute renal failure) using positive predictive value (PPV), negative predictive value, sensitivity, specificity, area under the curve (AUC), and the F1 measure (which computes a harmonic mean of sensitivity and PPV). Results were externally retrospectively validated with 5898 cases from the published MIMIC-III dataset.
               
                  Findings
                  Of 47 559 intensive care admissions (corresponding to 42 007 patients), we included 11 492 (corresponding to 9269 patients). The deep learning models yielded accurate predictions with the following PPV and sensitivity scores: PPV 0·90 and sensitivity 0·85 for mortality, 0·87 and 0·94 for renal failure, and 0·84 and 0·74 for bleeding. The predictions significantly outperformed the standard clinical reference tools, improving the absolute complication prediction AUC by 0·29 (95% CI 0·23–0·35) for bleeding, by 0·24 (0·19–0·29) for mortality, and by 0·24 (0·13–0·35) for renal failure (p<0·0001 for all three analyses). The deep learning methods showed accurate predictions immediately after patient admission to the intensive care unit. We also observed an increase in performance in our validation cohort when the machine learning approach was tested against clinical reference tools, with absolute improvements in AUC of 0·09 (95% CI 0·03–0·15; p=0·0026) for bleeding, of 0·18 (0·07–0·29; p=0·0013) for mortality, and of 0·25 (0·18–0·32; p<0·0001) for renal failure.
               
                  Interpretation
                  The observed improvements in prediction for all three investigated clinical outcomes have the potential to improve critical care. These findings are noteworthy in that they use routinely collected clinical data exclusively, without the need for any manual processing. The deep machine learning method showed AUC scores that significantly surpass those of clinical reference tools, especially soon after admission. Taken together, these properties are encouraging for prospective deployment in critical care settings to direct the staff's attention towards patients who are most at risk.
               
                  Funding
                  No specific funding.",health
10.1016/j.jbi.2018.10.008,Journal,Journal of Biomedical Informatics,scopus,2018-12-01,sciencedirect,Toward analyzing and synthesizing previous research in early prediction of cardiac arrest using machine learning based on a multi-layered integrative framework,https://api.elsevier.com/content/abstract/scopus_id/85056849885,"Background
                  One of the significant problems in the field of healthcare is the low survival rate of people who have experienced sudden cardiac arrest. Early prediction of cardiac arrest can provide the time required for intervening and preventing its onset in order to reduce mortality. Traditional statistical methods have been used to predict cardiac arrest. They have often analyzed group-level differences using a limited number of variables. On the other hand, machine learning approach, which is part of a growing trend of predictive medical analysis, has provided personalized predictive analyses on more complex data and produced remarkable results.
               
                  Objective
                  This paper has two aims. First, it offers a systematic review to evaluate the capability and performance of machine learning techniques in predicting the risk of cardiac arrest. Second, it offers an integrative framework to synthesize the researches in this field.
               
                  Method
                  A systematic review of cardiac arrest prediction studies was carried out through Pubmed, ScienceDirect, Google Scholar and SpringerLink databases. These studies used machine learning techniques and were conducted between the years 2000 and 2018.
               
                  Results
                  From a total of 1617 papers retrieved from the literature search, 75 studies were included in the final analysis. In order to explore how machine learning techniques were employed to predict cardiac arrest, a multi-layered framework was proposed. Each layer of the framework represents a classification of the current literature and contains taxonomies of relevant observed information. The framework integrates these classifications and illustrates the relative influence of a layer on other layers. The included papers were analyzed and synthesized through this framework. The used machine learning techniques were evaluated in terms of application and efficiency. The results illustrated the prediction capability of machine learning methods in predicting cardiac arrest.
               
                  Conclusion
                  According to the results, machine learning techniques can improve the outcome of cardiac arrest prediction. However, future research should be carried out to evaluate the efficiency of rarely-used algorithms and to address the challenges of external validation, implementation and adoption of machine learning models in real clinical environments.",health
10.1016/j.compmedimag.2018.09.007,Journal,Computerized Medical Imaging and Graphics,scopus,2018-12-01,sciencedirect,Multi-dimensional proprio-proximus machine learning for assessment of myocardial infarction,https://api.elsevier.com/content/abstract/scopus_id/85054266059,"This work presents a novel analysis methodology that utilises high-resolution, multi-dimensional information to better classify regions of the left ventricle after myocardial infarction. Specifically, the focus is to determine degree of infarction in regions of the left ventricle based on information extracted from cardiac magnetic resonance imaging. Enhanced classification accuracy is achieved using three mechanisms: Firstly, a plurality of indices/features is used in the pattern classification process, rather than a single index/feature (hence the term “multi-dimensional). Secondly, the method incorporates not only the indices/features of the region in consideration, but also indices/features from the neighbouring regions (hence the term “proprio-proximus”). Thirdly, advanced machine learning techniques are used for both feature selection and pattern classification process to ameliorate the effect of class-imbalance existing in the data. Numerical results from multiple experiments on real data showed that using multiple features improved the ability to distinguish between infarcted and non-infarcted remote segments, and using neighbouring information improved classification performance. The proposed methodology is general and can be adapted for the analysis of biological functions of other human organs.",health
10.1016/j.biopha.2018.09.035,Journal,Biomedicine and Pharmacotherapy,scopus,2018-12-01,sciencedirect,SRT1720 ameliorates sodium taurocholate-induced severe acute pancreatitis in rats by suppressing NF-κB signalling,https://api.elsevier.com/content/abstract/scopus_id/85053186406,"Severe acute pancreatitis (SAP) is a medical emergency that is often associated with multiple organ failure and high mortality. Although an SAP diagnosis requires prompt treatment, therapeutic options remain limited. SRT1720 is a newly formulatedSIRT1 activator that exerts multiple pharmacological activities with beneficial health effects. However, its potential as an SAP treatment has not been explored. The current study assessed the effect of SRT1720 on a rat model of sodium taurocholate-induced SAP and explored the underlying mechanism. SAP was induced in rats by retrograde injection of a 3.5% sodium taurocholate solution (1 ml/kg) in the biliopancreatic duct. SRT1720 (5 mg/kg) was administered intraperitoneally after sodium taurocholate exposure. Serum samples were analysed for inflammatory cytokine levels and select enzymatic activities using the enzyme-linked immunosorbent assay and commercial enzyme activity assay kits, respectively; protein expression levels were evaluated by western blotting; mRNA levels of biomarkers were determined by quantitative real-time PCR; histopathological changes were analysed by haematoxylin and eosin staining and immunohistochemistry.SRT1720 treatment significantly reduced serum amylase, lipase, pancreatic histological scores, proinflammatory cytokine (TNF-α and IL-6) levels, and expression of NF-κB and p65 in sodium taurocholate-induced SAP rats. Importantly, the treatment stimulated SIRT1 and IκBα levels in pancreatic tissue. Our data suggest that SRT1720 protects rats from sodium taurocholate-induced SAP by suppressing the NF-κB signalling pathway.",health
10.1016/j.neuroimage.2018.07.005,Journal,NeuroImage,scopus,2018-12-01,sciencedirect,Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images,https://api.elsevier.com/content/abstract/scopus_id/85052893805,"White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80%, 84% and 6.30 mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. Detailed descriptions and quantitative analysis on key components of the system were provided. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to show the effect of ensemble size and the effectiveness of the ensemble model. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice.",health
10.1016/j.neuroimage.2018.08.066,Journal,NeuroImage,scopus,2018-12-01,sciencedirect,Creatures great and small: Real-world size of animals predicts visual cortex representations beyond taxonomic category,https://api.elsevier.com/content/abstract/scopus_id/85052881210,"Human occipitotemporal cortex contains neural representations for a variety of perceptual and conceptual features. We report a study examining neural representations of real-world size along the visual ventral stream, while carefully accounting for taxonomic categories that typically co-vary with size. We recorded brain activity during a functional Magnetic Resonance Imaging (fMRI) scan from eighteen participants as they were presented with images of twelve animal species. The animals were selected to vary on a number of dimensions, including taxonomic group, real-world size and prior familiarity. We apply multivariate analysis methods, including representational similarity analysis (RSA) and machine learning classifiers, to probe the distributed patterns of neural activity evoked by these presentations. We find that the real-world size of visually presented animate items is represented in posterior, but not anterior, regions of the ventral stream. A significant linear relationship is present for real-world size representation along the ventral stream. These representations remain after controlling for factors such as taxonomic category, familiarity and models of visual similarity, and even after restricting examinations to within-taxonomic category comparisons, suggesting that size information is found for within, as well as between, taxonomic categories. These findings are consistent with real-world size having an influence on activity patterns in early regions of the visual system.",health
10.1016/j.vprsr.2018.08.002,Journal,Veterinary Parasitology: Regional Studies and Reports,scopus,2018-12-01,sciencedirect,Management practices associated with strongylid parasite prevalence on horse farms in rural counties of Kentucky,https://api.elsevier.com/content/abstract/scopus_id/85052492411,"Anthelmintic resistance among cyathostomin parasites is a wide-spread problem. The parasite control guidelines written by the American Association of Equine Practitioners (AAEP) encourages the preservation of anthelmintic efficacy by reducing treatment frequency, using targeted deworming, and implementing environmental management practices. While there is knowledge regarding parasite management practices of affluent horse farms in the United States, surveys rarely explore the rural and underserved regions. The purpose of this study was to observe the management practices of horse farms in rural regions Kentucky, including working Amish farms, and determine factors associated with strongyle prevalence. A total of 160 horses among 38 owners from 28 different farms were enrolled in this study. A questionnaire survey regarding equine information, farm management, and deworming history was performed with each owner. Fecal samples were collected to determine fecal egg counts, perform coprocultures for subsequent strongyle larvae identification, and Strongylus vulgaris specific PCR. Serum samples were collected for the S. vulgaris antibody specific ELISA. The mean number of deworming treatments given in the last year was 2.1 with a 95% confidence interval of 1.9–2.3 with ivermectin being the most common active used. Statistical analysis showed horses treated within the last three months with a macrocylic lactone (ML) drug had significantly lower egg counts than horses treated with a ML 7–9 months ago (p = .0005). Despite the AAEP recommendations to reduce the overall number of treatments by using a surveillance-based approach and to no longer rotate treatments, only 17 horses reportedly had a fecal sample submitted for a fecal egg count and 65 horses were dewormed in a rotational manner. Horses whose owners utilized an informative deworming source (i.e., veterinarian, internet, magazine, local feed store) also had significantly lower counts (p = .0026). All coprocultures were negative for S. vulgaris while five horses were PCR positive. Interestingly, 95 horses tested ELISA positive for S. vulgaris. The strongyle egg counts of the working Amish horses were not significantly different from the other horses in this study and deworming practices including the use of efficacious drugs and low treatment frequencies were in accordance with the AAEP guidelines. This study was the first to summarize deworming management practices of rural regions in Kentucky, including a working Amish community. Overall, horse owners employed deworming practices recommended by the AAEP, however rotational deworming is still commonly implemented and fecal egg counts are rarely used.",health
10.1016/j.patcog.2018.07.011,Journal,Pattern Recognition,scopus,2018-12-01,sciencedirect,Correntropy-based robust multilayer extreme learning machines,https://api.elsevier.com/content/abstract/scopus_id/85049905752,"In extreme learning machines (ELM), the hidden node parameters are randomly generated and the output weights can be analytically computed. To overcome the bad feature extraction ability of the shallow architecture of ELM, the hierarchical ELM has been extensively studied as a deep architecture with multilayer neural network. However, the commonly used mean square error (MSE) criterion is very sensitive to outliers and impulsive noises, generally existing in real world data. In this paper, we investigate the correntropy to improve the robustness of the multilayer ELM and provide sparser representation. The correntropy, as a nonlinear measure of similarity, is robust to outliers and can approximate different norms (from ℓ0 to ℓ2). A new full correntropy based multilayer extreme learning machine (FC-MELM) algorithm is proposed to handle the classification of datasets which are corrupted by impulsive noises or outliers. The contributions of this paper are three-folds: (1) The MSE based reconstruction loss is replaced by the correntropy based loss function; In this way, the robustness of the ELM based multilayer algorithms is enhanced. (2) The traditional ℓ1-based sparsity penalty term is also replaced by a correntropy-based sparsity penalty term, which can further improve the performance of the proposed algorithm with a sparser representation of the data. The combination of (1) and (2) provides the correntropy-based ELM autoencoder. (3) The FC-MELM is proposed by using the correntropy-based ELM autoencoder as a building block. It is notable that the FC-MELM is trained in a forward manner, which means fine-tuning procedure is not required. Thus, the FC-MELM has great advantage in learning efficiently when compared with traditional deep learning algorithms. The good property of the proposed algorithm is confirmed by the experiments on well-known benchmark datasets, including the MNIST datasets, the NYU Object Recognition Benchmark dataset, and the Moore network traffic dataset. Finally, the proposed FC-MELM algorithm is applied to address Computer Aided Cancer Diagnosis. Experiments conducted on the well-known Wisconsin Breast Cancer Data (Diagnostic) dataset are presented and show that the proposed FC-MELM outperforms state-of-the-art methods in solving computer aided cancer diagnosis problems.",health
10.1016/j.bdr.2018.05.005,Journal,Big Data Research,scopus,2018-12-01,sciencedirect,evoStream – Evolutionary Stream Clustering Utilizing Idle Times,https://api.elsevier.com/content/abstract/scopus_id/85047928365,"Clustering is an important field in data mining that aims to reveal hidden patterns in data sets. It is widely popular in marketing or medical applications and used to identify groups of similar objects. Clustering possibly unbounded and evolving data streams is of particular interest due to the widespread deployment of large and fast data sources such as sensors. The vast majority of stream clustering algorithms employ a two-phase approach where the stream is first summarized in an online phase. Upon request, an offline phase reclusters the aggregations into the final clusters. In this setup, the online component will idle and wait for the next observation in times where the stream is slow. This paper proposes a new stream clustering algorithm called evoStream which performs evolutionary optimization in the idle times of the online phase to incrementally build and refine the final clusters. Since the online phase would idle otherwise, our approach does not reduce the processing speed while effectively removing the computational overhead of the offline phase. In extensive experiments on real data streams we show that the proposed algorithm allows to output clusters of high quality at any time within the stream without the need for additional computational resources.",health
10.1016/j.neucom.2018.07.004,Journal,Neurocomputing,scopus,2018-11-07,sciencedirect,Detection of weak transient signals based on unsupervised learning for bearing fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85050276905,"Transient impulse contains abundant information of bearings status. When fault occurs, it is activated and would recur periodically or quasi-periodically. Its period can indicate where defects lie in. However, transient impulse is easily swallowed by background noise or interferences in part or in whole, especially at early stage of fault. This problem brings hard obstacles into faults detection. Considering that transient impulses are periodical or quasi-periodical and vibration signal has local similarity, the single transient impulse can be seen as one of shift-invariant features. In view of this, this paper derives adaptive and non-linear signal decomposition formulas and further proposes adaptive and unsupervised feature learning method by using convolutional restricted Boltzmann machine model. With respecting local waveform structures, this method can automatically capture shift-invariant patterns hidden in original signal and decompose the original signal into several sub-components at the cost of minimizing reconstruction error. Among these sub-components, the fault-related information, i.e., transient impulses signal, could be extracted likely. It provides a promising idea for intelligent signal processing by using unsupervised learning. Afterwards, Maximizing kurtosis is applied to select optimally latent fault component. Two real bearing experiments validate this method is effective and reliable in extraction of weak transient impulses.",health
10.1016/j.neucom.2018.06.049,Journal,Neurocomputing,scopus,2018-11-07,sciencedirect,A Deep Spatial-Temporal Ensemble Model for Air Quality Prediction,https://api.elsevier.com/content/abstract/scopus_id/85049832090,"Air quality has drawn much attention in the recent years because it seriously affects people’s health. Nowadays, monitoring stations in a city can provide real-time air quality, but people also strongly desire air quality prediction, which is a challenging problem as it depends on several complicated factors, such as weather patterns and spatial-temporal dependencies of air quality. In this paper, we design a data-driven approach that utilizes historical air quality and meteorological data to predict air quality in the future. We propose a deep spatial-temporal ensemble(STE) model which is comprised of three components. The first component is an ensemble method with a weather-pattern-based partitioning strategy. It trains multiple individual models and combines them dynamically. The second one is to discover spatial correlation by analyzing Granger causalities among stations and generating spatial data as relative stations and relative areas. The last one is a temporal predictor based on deep LSTM to learn both long-term and short-term dependencies of air quality. We evaluate our model with data from 35 monitoring stations in Beijing, China. The experiments show that each component of our model makes contribution to the improvement in prediction accuracy and the model is superior to baselines.",health
10.1016/j.compbiomed.2018.09.009,Journal,Computers in Biology and Medicine,scopus,2018-11-01,sciencedirect,Arrhythmia detection using deep convolutional neural network with long duration ECG signals,https://api.elsevier.com/content/abstract/scopus_id/85053715332,"This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing.",health
10.1016/j.jsurg.2018.06.004,Journal,Journal of Surgical Education,scopus,2018-11-01,sciencedirect,Novel Educational Information Management Platform Improves the Surgical Skill Evaluation Process of Surgical Residents,https://api.elsevier.com/content/abstract/scopus_id/85050826890,"Objective
                  We sought to increase compliance and timeliness of surgery resident operative evaluation, by providing faculty and residents with a Platform-linking evaluation to analytics and machine-learning-facilitated case logging.
               
                  Design
                  We built a HIPAA-compliant web-based Platform for comprehensive management of resident education information, including resident operative performance evaluations. To assess evaluation timeliness, we compared the lag time for Platform-based evaluations to that of end-of-rotation evaluations. We also assessed evaluation compliance, based on a time threshold of 5 days for Platform evaluations and 2 weeks for end-of-rotation evaluations.
               
                  Setting
                  University of Massachusetts, Baystate Medical Center, General Surgery Residency.
               
                  Participants
                  Twenty three attendings and 43 residents for the Platform cohort; 15 services and 45 residents for the end-of-rotation cohort.
               
                  Results
                  Three hundred and fifty-eight Platform evaluations were completed by 23 attendings for 43 residents for March through October 2017. Six hundred and ten end-of-rotation evaluations by 15 attendings for 45 residents were used for comparison (September 2015 through June 2017). Of Platform evaluations, 41.3% were completed within 24 hours of the operation (16.5% in 6 hours, 33.3% in 12 hours, and 62.2% in 48 hours), with 24.3% of evaluations completed within 3 hours after e-mail reminders. In the first 6 weeks (March 1 through April 12) 4.5 ± 3.7 evaluations were completed per week compared to 18.8 ± 5.8 in the last (September 18 through October 31). Evaluation lag times improved with the use of the Platform, both for median lag of 35 days earlier (1 ± 1.5 days Platform, 36 ± 28.2 days traditional, p < 0.0001) and a mean lag of 41 days earlier (3.0 ± 4.7 days Platform, 44.0 ± 32.6 days traditional, p < 0.0001).
               
                  Conclusions
                  Our comprehensive Platform facilitated faculty compliance with evaluation requirements and timeliness of availability of performance information (often in near real time) for both residents and residency leadership. The added value of the Platform's integration of evaluations with resident and attending case logging may account for the rapidly increasing number of operative skill evaluations over the short time span since implementation.",health
10.1016/j.adhoc.2018.07.014,Journal,Ad Hoc Networks,scopus,2018-11-01,sciencedirect,DDA: A deep neural network-based cognitive system for IoT-aided dermatosis discrimination,https://api.elsevier.com/content/abstract/scopus_id/85050353560,"The rapid development of the Internet of Things (IoT) and cognitive cyber-physical systems (CPS) has made people's daily lives more intelligent. Additionally, emerging technologies, such as wearable devices and machine learning, have demonstrated the potential for acquiring and processing large amounts of data from the physical world. In the medical field, effectively utilizing the collected medical data and providing more intelligent systems for doctors and patients to assist in diagnoses have also become important research topics. This paper presents a deep neural network-based cognitive system named DDA (dermatosis discrimination assistant) for classifying the dermatosis images generated by confocal laser scanning microscopes. Considering the lack of labels, we increase the labeled data automatically using an incremental model based on a small amount of labeled data and propose a disease discrimination model to distinguish and diagnose the categories of the disease images. In this system, the diagnoses of seborrheic keratosis (SK) and flat wart (FW) are used as examples, and experiments are conducted using the proposed models. Experimental results show that this system performs almost as well as individual dermatologists and can identify and diagnose other common dermatoses.",health
10.1016/j.ssci.2018.06.012,Journal,Safety Science,scopus,2018-11-01,sciencedirect,Occupational health and safety in the industry 4.0 era: A cause for major concern?,https://api.elsevier.com/content/abstract/scopus_id/85049323662,"Real-time communication, Big Data, human–machine cooperation, remote sensing, monitoring and process control, autonomous equipment and interconnectivity are becoming major assets in modern industry. As the fourth industrial revolution or Industry 4.0 becomes the predominant reality, it will bring new paradigm shifts, which will have an impact on the management of occupational health and safety (OHS).
                  In the midst of this new and accelerating industrial trend, are we giving due consideration to changes in OHS imperatives? Are the OHS consequences of Industry 4.0 being evaluated properly? Do we stand to lose any of the gains made through proactive approaches? Are there rational grounds for major concerns? In this article, we examine these questions in order to raise consciousness with regard to the integration of OHS into Industry4.0.
                  It is clear that if the technologies driving Industry 4.0 develop in silos and manufacturers’ initiatives are isolated and fragmented, the dangers will multiply and the net impact on OHS will be negative. As major changes are implemented, previous gains in preventive management of workplace health and safety will be at risk. If we are to avoid putting technological progress and OHS on a collision course, researchers, field experts and industrialists will have to collaborate on a smooth transition towards Industry 4.0.",health
10.1016/j.eij.2018.03.003,Journal,Egyptian Informatics Journal,scopus,2018-11-01,sciencedirect,A contemporary feature selection and classification framework for imbalanced biomedical datasets,https://api.elsevier.com/content/abstract/scopus_id/85044607905,"Due to the availability of a large number of biomedical documents in the PubMed and Medline repositories, it is difficult to analyze, predict and interpret the document’s information using the traditional document clustering and classification models. Traditional document clustering and classification models were failed to analyze the document sets based on the user’s keyword and MESH terms. Due to the large number of feature sets, conventional models, such as SVM, Neural Networks, Multi-nominal naïve bayes have been used as feature classification, where additional text filtering measures are typically used as feature selection process. Also, as the size of the document’s increases, it becomes difficult to find the outliers using the document’s features and MESH terms. Biomedical document clustering and classification is one of the essential machine learning models for the knowledge extraction process of the real-time user recommended systems. In this paper, we developed a novel biomedical document feature clustering and classification model as a user recommended system for large document sets using the Hadoop framework. In this model, a novel gene feature clustering with ensemble document classification was implemented on biomedical repositories (PubMed and Medline) using the MapReduce framework. Experimental results show that the proposed model has a high computational cluster quality rate and true positive classification rate compared to traditional document clustering and classification models.",health
10.1016/j.jlp.2018.01.011,Journal,Journal of Loss Prevention in the Process Industries,scopus,2018-11-01,sciencedirect,Deep neural network and random forest classifier for source tracking of chemical leaks using fence monitoring data,https://api.elsevier.com/content/abstract/scopus_id/85041960230,"Chemical plant leak accidents are classified as one of the major industrial accidents that can spread secondary and tertiary major disasters. It is very important to keep track and diagnose the source location(s) and notify the plant manager and emergency responders promptly to alleviate secondary and tertiary damages, improving the effectiveness of emergency responses. In this study, we propose an emergency response system that can cope with leak accidents of a chemical plant by monitoring sensor data and track down the suspected leak source using machine learning: Deep-learning and Random Forest classifiers. It is also difficult to get enough chemical leak accident scenario data or perform actual leak experiments on real plants due to high risk and cost factors. Consequently, Computational Fluid Dynamics (CFD) simulations are used to derive fence monitoring data for chemical leak accident scenarios. These data are to train the machine learning models to predict leak source locations. Six time-series Deep Neural Network (DNN) structures and three Random Forest (RF) structures are trained using CFD dispersion simulation results for 640 leak accident scenarios of a real chemical plant, divided as training and test datasets. As a result, on DNN model using 25 hidden layers and on RF model using 100 decision trees, 75.43% and 86.33% prediction accuracy are achieved, respectively, classifying the most probable leak source out of 40 potential leak source locations. Analyzing the predicted leak source locations that are wrongly classified, those predicted leak sources are also quite adjacent to the actual leak location and hardly called as misclassifications. Considering the superb performance of DNN and RF classifiers for chemical leak tracking, the proposed method would be very useful for chemical emergency management and is highly recommended for real-time diagnosis of the chemical leak sources.",health
10.1016/j.artmed.2015.09.006,Journal,Artificial Intelligence in Medicine,scopus,2018-11-01,sciencedirect,Pediatric decision support using adapted Arden Syntax,https://api.elsevier.com/content/abstract/scopus_id/84964998606,"Background
                  Pediatric guidelines based care is often overlooked because of the constraints of a typical office visit and the sheer number of guidelines that may exist for a patient's visit. In response to this problem, in 2004 we developed a pediatric computer based clinical decision support system using Arden Syntax medical logic modules (MLM).
               
                  Methods
                  The Child Health Improvement through Computer Automation system (CHICA) screens patient families in the waiting room and alerts the physician in the exam room. Here we describe adaptation of Arden Syntax to support production and consumption of patient specific tailored documents for every clinical encounter in CHICA and describe the experiments that demonstrate the effectiveness of this system.
               
                  Results
                  As of this writing CHICA has served over 44,000 patients at 7 pediatric clinics in our healthcare system in the last decade and its MLMs have been fired 6182,700 times in “produce” and 5334,021 times in “consume” mode. It has run continuously for over 10 years and has been used by 755 physicians, residents, fellows, nurse practitioners, nurses and clinical staff. There are 429 MLMs implemented in CHICA, using the Arden Syntax standard. Studies of CHICA's effectiveness include several published randomized controlled trials.
               
                  Conclusions
                  Our results show that the Arden Syntax standard provided us with an effective way to represent pediatric guidelines for use in routine care. We only required minor modifications to the standard to support our clinical workflow. Additionally, Arden Syntax implementation in CHICA facilitated the study of many pediatric guidelines in real clinical environments.",health
10.1016/j.jnca.2018.06.010,Journal,Journal of Network and Computer Applications,scopus,2018-10-15,sciencedirect,A framework for healthcare support in the rural and low income areas of the developing world,https://api.elsevier.com/content/abstract/scopus_id/85049924793,"Cyber-Healthcare is an emerging field of the healthcare domain that builds upon cyber physical health systems (CPHSs) to provide pervasive access to medical services any time and from anywhere in the world where medical expertise is available. It is expected to change the way healthcare is delivered in the developing world and enable both its rural and urban settings to leapfrog from poorly equipped to medically prepared environments capable of tackling some of its most challenging health issues. However, owing to their infancy stage in the developing world, CPHSs require substantial research and practical work to move from their theoretical boundaries into the development, deployment and exploitation phase. This paper proposes a Cyber-Healthcare framework and its implementation as a fog-based CPHS infrastructure using low-cost lightweight devices to achieve patients' condition recognition as a first step towards the implementation of digital healthcare support systems in the developing world. We propose a multi-layer architecture for the framework and consider a patients' condition recognition system that uses machine learning techniques as a key component of the framework. We present experimental results that reveal i) the relative efficiency of different machine learning algorithms used for patient condition recognition and ii) the storage and processing overheads incurred by two popular lightweight embedded devices when used as fog computing devices in the CPHS.",health
10.1016/j.neucom.2018.05.021,Journal,Neurocomputing,scopus,2018-10-08,sciencedirect,A robust intelligent fault diagnosis method for rolling element bearings based on deep distance metric learning,https://api.elsevier.com/content/abstract/scopus_id/85047276386,"Intelligent data-driven fault diagnosis methods for rolling element bearings have been widely developed in the recent years. In real industries, the collected machinery signals are usually exposed to environmental noises, and the bearing operating condition changes in different working scenarios. That leads to distribution discrepancy between the labeled training data and the unlabeled testing data, and consequently the diagnosis performance deteriorates. This paper proposes a novel deep distance metric learning method for rolling bearing fault diagnosis based on deep learning. A deep convolutional neural network is used as the main architecture. Based on the learned representations through multiple hidden layers, a representation clustering algorithm is proposed to minimize the distance of intra-class variations and maximize the distance of inter-class variations simultaneously. A domain adaptation method is adopted to minimize the maximum mean discrepancy between training and testing data. In this way, the robustness of the fault diagnosis method can be significantly improved against noise and variation of working condition. Extensive experiments on a popular rolling bearing dataset are carried out to validate the effectiveness of the proposed method, and the diagnosis performance is widely evaluated in different scenarios. Comparisons with other approaches and the related works on the same dataset demonstrate the superiority of the proposed method. The experimental results of this study suggest the proposed deep distance metric learning method offers a new and promising tool for intelligent fault diagnosis of rolling bearings.",health
10.1016/j.vetmic.2018.08.026,Journal,Veterinary Microbiology,scopus,2018-10-01,sciencedirect,Detection of non-notifiable H4N6 avian influenza virus in poultry in Great Britain,https://api.elsevier.com/content/abstract/scopus_id/85053845094,"A 12-month pilot project for notifiable avian disease (NAD) exclusion testing in chicken and turkey flocks in Great Britain (GB) offered, in partnership with industry, opportunities to carry out differential diagnosis in flocks where NAD was not suspected, and to identify undetected or undiagnosed infections. In May 2014, clinical samples received from a broiler breeder chicken premises that had been experiencing health and production problems for approximately one week tested positive by avian influenza (AI) real-time reverse transcription polymerase chain reaction (RRT-PCR). Following immediate escalation to an official, statutory investigation to rule out the presence of notifiable AI virus (AIV; H5 or H7 subtypes), a non-notifiable H4N6 low pathogenicity (LP) AIV was detected through virus isolation in embryonated specific pathogen free (SPF) fowls’ eggs, neuraminidase inhibition test, cleavage site sequencing and AIV subtype H4-specific serology. Premises movement restrictions were lifted, and no further disease control measures were implemented as per the United Kingdom (UK) legislation. Phylogenetic analysis of the haemagglutinin and neuraminidase genes of the virus revealed closest relationships to viruses from Mallard ducks in Sweden during 2007 and 2009. In June 2014, clinical suspicion of NAD was reported in a flock of free-range laying chickens elsewhere in GB, due to increasing daily mortality and reduced egg production over a five-day period. An H4N6 LPAIV with an intravenous pathogenicity index of 0.50 was isolated. This virus was genetically highly similar, but not identical, to the virus detected during May 2014. Full viral genome analyses showed characteristics of a strain that had not recently transferred from wild birds, implying spread within the poultry sector had occurred. A stalk deletion in the neuraminidase gene sequence indicated an adaptation of the virus to poultry. Furthermore, there was unexpected evidence of systemic spread of the virus on post-mortem. No other cases were reported. Infection with LPAIVs often result in variable clinical presentation in poultry, making detection of disease more difficult.",health
10.1016/j.cmpb.2018.08.005,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-10-01,sciencedirect,Fast unsupervised nuclear segmentation and classification scheme for automatic allred cancer scoring in immunohistochemical breast tissue images,https://api.elsevier.com/content/abstract/scopus_id/85051670704,"Background and objective
                  This paper presents an improved scheme able to perform accurate segmentation and classification of cancer nuclei in immunohistochemical (IHC) breast tissue images in order to provide quantitative evaluation of estrogen or progesterone (ER/PR) receptor status that will assist pathologists in cancer diagnostic process.
               
                  Methods
                  The proposed segmentation method is based on adaptive local thresholding and an enhanced morphological procedure, which are applied to extract all stained nuclei regions and to split overlapping nuclei. In fact, a new segmentation approach is presented here for cell nuclei detection from the IHC image using a modified Laplacian filter and an improved watershed algorithm. Stromal cells are then removed from the segmented image using an adaptive criterion in order to get fast tumor nuclei recognition. Finally, unsupervised classification of cancer nuclei is obtained by the combination of four common color separation techniques for a subsequent Allred cancer scoring.
               
                  Results
                  Experimental results on various IHC tissue images of different cancer affected patients, demonstrate the effectiveness of the proposed scheme when compared to the manual scoring of pathological experts. A statistical analysis is performed on the whole image database between immuno-score of manual and automatic method, and compared with the scores that have reached using other state-of-art segmentation and classification strategies. According to the performance evaluation, we recorded more than 98% for both accuracy of detected nuclei and image cancer scoring over the truths provided by experienced pathologists which shows the best correlation with the expert's score (Pearson's correlation coefficient = 0.993, p-value < 0.005) and the lowest computational total time of 72.3 s/image (±1.9) compared to recent studied methods.
               
                  Conclusions
                  The proposed scheme can be easily applied for any histopathological diagnostic process that needs stained nuclear quantification and cancer grading. Moreover, the reduced processing time and manual interactions of our procedure can facilitate its implementation in a real-time device to construct a fully online evaluation system of IHC tissue images.",health
10.1016/j.media.2018.07.002,Journal,Medical Image Analysis,scopus,2018-10-01,sciencedirect,Weakly-supervised convolutional neural networks for multimodal image registration,https://api.elsevier.com/content/abstract/scopus_id/85049627637,"One of the fundamental challenges in supervised learning for multimodal image registration is the lack of ground-truth for voxel-level spatial correspondence. This work describes a method to infer voxel-level transformation from higher-level correspondence information contained in anatomical labels. We argue that such labels are more reliable and practical to obtain for reference sets of image pairs than voxel-level correspondence. Typical anatomical labels of interest may include solid organs, vessels, ducts, structure boundaries and other subject-specific ad hoc landmarks. The proposed end-to-end convolutional neural network approach aims to predict displacement fields to align multiple labelled corresponding structures for individual image pairs during the training, while only unlabelled image pairs are used as the network input for inference. We highlight the versatility of the proposed strategy, for training, utilising diverse types of anatomical labels, which need not to be identifiable over all training image pairs. At inference, the resulting 3D deformable image registration algorithm runs in real-time and is fully-automated without requiring any anatomical labels or initialisation. Several network architecture variants are compared for registering T2-weighted magnetic resonance images and 3D transrectal ultrasound images from prostate cancer patients. A median target registration error of 3.6 mm on landmark centroids and a median Dice of 0.87 on prostate glands are achieved from cross-validation experiments, in which 108 pairs of multimodal images from 76 patients were tested with high-quality anatomical labels.",health
10.1016/j.envpol.2018.06.049,Journal,Environmental Pollution,scopus,2018-10-01,sciencedirect,Natural pyrethrins induce autophagy of HepG2 cells through the activation of AMPK/mTOR pathway,https://api.elsevier.com/content/abstract/scopus_id/85049352934,"Natural pyrethrins, one kind of insects’ neural toxin, have been used worldwide for the control of pests of crops, livestock, and human beings. However, their specific mechanisms of action are incompletely understood and hence further investigation is required. Here we used a series of experiments including colony formation, fluorescent staining, western blotting, enzyme activity detection, immunofluorescence analysis, and real-time quantitative PCR (QPCR) to investigate whether natural pyrethrins (0–40 μg/mL) are able to modulate autophagy process through AMPK/mTOR signaling pathway, in order to reveal their cytotoxic mechanisms. The results showed that natural pyrethrins markedly inhibited the proliferation of HepG2 cells in both concentration- and time-dependent manners. Particularly, natural pyrethrins could induce the resulting autophagosome, and the intensification of LC3-II formation and translocation, the accumulation of Beclin-1 and the reduction of p62 and thus autophagy. We clarified that natural pyrethrins induced the abnormal level of oxidation reduction metabolism, leading to mitochondrial permeability transition pore (mPTP) opening, ATP depletion and mitochondria eliminating by autophagy. Moreover, the phosphorylation levels of AMPK were significantly enhanced, and the mTOR and p70s6k phosphorylation were drastically decreased. These results showed that natural pyrethrins induced autophagy of HepG2 cells and activation of the AMPK/mTOR signaling pathway might have potential risk to human health.",health
10.1016/j.biomaterials.2018.06.028,Journal,Biomaterials,scopus,2018-10-01,sciencedirect,Imaging γ-Glutamyltranspeptidase for tumor identification and resection guidance via enzyme-triggered fluorescent probe,https://api.elsevier.com/content/abstract/scopus_id/85049317970,"Development of high selectivity, accurate targeted and noninvasive fluorescent probe for monitoring specific enzyme activity associated with the tumor is urgent needed for early diagnosis of cancer and clinical fluorescence interventional resection guidance treatment. Owing to the invasion of malignant tumor cells, tumor cells are mixed with normal cells in the actual tumor location, which make it quite difficult for clinician to diagnose early diagnosis of tumor as well as resection of tumor. To overcome aforementioned obstacle, herein, an ingenious enzyme-activated one and two-photon fluorescent probe TCF-GGT was constructed and synthesized including γ-GGT enzyme specific identification site and far-red fluorophore for imaging. Under simulative physiological condition, probe TCF-GGT demonstrated high selectivity, sensitivity (DL 0.014 mU/mL), rapid response (T
                     
                        e
                      14 min) for the detection of γ-GGT enzyme. By virtue of its biocompatibility, probe was employed for the identification of ovarian cancer cells (A2780 cells) from normal cells (NIH-3T3 cells), particularly in mixed cultivation dish (simulate the actual environment of tumor) through 2D&3D fluorescence imaging with “dual” mark (Nucleic acid labeling used by Hoechst 33342 dye and γ-GGT enzyme labeling used by probe TCF-GGT) for the first time. Probe TCF-GGT could be visualize endogenous γ-GGT activity in HepG-2 cells and zebrafish on the two-photon confocal platform, which is conduce to estimate the inhibitor of γ-GGT enzyme in vivo. Through NaBu (a potential anticancer drug) stimulation, the changes of γ-GGT activity were observed in living MCF-7 cells by using this probe. More importantly, the deep tissue penetration ability of far-red fluorescence allowed the two-photon fluorescent probe TCF-GGT to real-time track γ-GGT activity in tissue slices and tumor xenotransplantation model of mice by the tail vein injection, which showed that this enzyme-triggered fluorogenic probe would be a potential tool for preclinical applications of tumor resection.",health
10.1016/j.diagmicrobio.2018.05.016,Journal,Diagnostic Microbiology and Infectious Disease,scopus,2018-10-01,sciencedirect,A new dual-targeting real-time RT-PCR assay for hepatitis D virus RNA detection,https://api.elsevier.com/content/abstract/scopus_id/85048886531,"In this study, a real-time reverse transcription–polymerase chain reaction (real time RT-PCR) assay targeting 2 genetic segments was established to detect HDV RNA. Utilizing the World Health Organization International Standard for Hepatitis D Virus RNA, the lower limit of detection was 575 IU/mL, and the linearity of quantification ranged from 575,000 IU/mL to 575 IU/mL. 384 HBsAg-positive samples collected from China were tested by this method and HDV antibody detection. Eleven samples were positive for anti-HDV IgG which may persist after HDV resolution, 6 samples were HDV RNA positive, and 5 samples were positive for anti-HDV IgM. This assay showed more sensitivity than the detection of anti-HDV IgM. These data demonstrate that the real-time RT-PCR assay for HDV RNA could be implemented in the clinical detection of HDV infection in chronic HBV-infected patients in China.",health
10.1016/j.jhin.2018.04.004,Journal,Journal of Hospital Infection,scopus,2018-10-01,sciencedirect,Feasibility of a real-time hand hygiene notification machine learning system in outpatient clinics,https://api.elsevier.com/content/abstract/scopus_id/85046810779,"Background
                  Various technologies have been developed to improve hand hygiene (HH) compliance in inpatient settings; however, little is known about the feasibility of machine learning technology for this purpose in outpatient clinics.
               
                  Aim
                  To assess the effectiveness, user experiences, and costs of implementing a real-time HH notification machine learning system in outpatient clinics.
               
                  Methods
                  In our mixed methods study, a multi-disciplinary team co-created an infrared guided sensor system to automatically notify clinicians to perform HH just before first patient contact. Notification technology effects were measured by comparing HH compliance at baseline (without notifications) with real-time auditory notifications that continued till HH was performed (intervention I) or notifications lasting 15 s (intervention II). User experiences were collected during daily briefings and semi-structured interviews. Costs of implementation of the system were calculated and compared to the current observational auditing programme.
               
                  Findings
                  Average baseline HH performance before first patient contact was 53.8%. With real-time auditory notifications that continued till HH was performed, overall HH performance increased to 100% (P < 0.001). With auditory notifications of a maximum duration of 15 s, HH performance was 80.4% (P < 0.001). Users emphasized the relevance of real-time notification and contributed to technical feasibility improvements that were implemented in the prototype. Annual running costs for the machine learning system were estimated to be 46% lower than the observational auditing programme.
               
                  Conclusion
                  Machine learning technology that enables real-time HH notification provides a promising cost-effective approach to both improving and monitoring HH, and deserves further development in outpatient settings.",health
10.1016/j.chroma.2018.06.035,Journal,Journal of Chromatography A,scopus,2018-09-14,sciencedirect,Tandem column isolation of zirconium-89 from cyclotron bombarded yttrium targets using an automated fluidic platform: Anion exchange to hydroxamate resin columns,https://api.elsevier.com/content/abstract/scopus_id/85051041242,"The development of a tandem column purification method for the preparation of high-purity 89Zr(IV) oxalate is presented. The primary column was a macroporous strongly basic anion exchange resin on styrene divinylbenzene co-polymer. The secondary column, with an internal volume of 33 μL, was packed with hydroxamate resin. A condition of inverted selectivity was developed, whereby the 89Zr eluent solution for the primary column is equivalent to the 89Zr load solution for the secondary column. The ability to transfer 89Zr from one column to the next allows two sequential column clean-up methods to be performed prior to the final elution of the 89Zr(IV) oxalate. This approach assures delivery of high purity 89Zr product and assures a 89Zr product that is eluted in a substantially smaller volume than is possible when using the traditionally-employed single hydroxamate resin column method. The tandem column purification process has been implemented into a prototype automated fluidic system. The system is configured with on-line gamma detection so column effluents can be monitored in near-real time. The automated method was tested using seven cyclotron bombarded Y foil targets. It was found that 95.1 ± 1.3% of the 89Zr present in the foils was recovered in the secondary column elution fraction. Furthermore, elution peak analysis of several 89Zr elution profile radiochromatograms made possible the determination of 89Zr recovery as a function of volume; a 89Zr product volume that contains 90% of the mean secondary column elution peak can be obtained in 0.29 ± 0.06 mL (representing 86 ± 5% of the 89Zr activity in the target). This product volume represents a significant improvement in radionuclide product concentration over the predominant method used in the field. In addition to the reduced 89Zr product elution volume, titrations of the 89Zr product with deferoxamine mesylate salt across two preparatory methods resulted in mean effective specific activity (ESA) values of 279 and 340 T Bq·mmole−1 and mean bindable metals concentrations ([MB]) of 13.5 and 16.7 nmole·g−1. These ESA and [MB] values infer that the 89Zr(IV) oxalate product resulting from this tandem column isolation method has the highest purity reported to date.",health
10.1016/j.ergon.2018.06.005,Journal,International Journal of Industrial Ergonomics,scopus,2018-09-01,sciencedirect,Artificial intelligence models for predicting the performance of hydro-pneumatic suspension struts in large capacity dump trucks,https://api.elsevier.com/content/abstract/scopus_id/85049336711,"Large dump trucks are being matched with large shovels to achieve bulk economic production in surface mining operations. This process results in high impact shovel loading operations (HISLO) and exposes operators to severe levels of whole-body vibrations (WBV). The performance of the hydro-pneumatic suspension struts, responsible for vibration attenuation in large dump trucks, decreases as a truck age. There is a need for a system for monitoring and predicting the performance of the suspension struts in real time. Artificial intelligence (AI) has been applied for modeling and predicting the suspension system performance for light/smaller vehicles. However, no work has been done to implement AI for modeling and predicting the performance of hydro-pneumatic struts in large dump trucks. This paper is a pioneering effort towards developing AI models for solving this problem. These AI models would incorporate the Artificial Neural Networks (ANN), Mamdani Fuzzy Logic (MFL) and a hybrid system, the Hybrid Neural Fuzzy Interference System (HyFIS), for achieving this goal. Experiments were conducted using a 3D virtual simulator for the CAT 793D in MSC.ADMAS. RMS accelerations in the vertical and horizontal directions at the operator seat were recorded as the two main outputs for the suspension system performance. Eighty percent (80%) of the total experimental data was used in training and developing the models and the remaining 20% for testing and validating the developed models. With an R2 and RMSE of 0.98168505 and 0.00852251 for the training phase, respectively, and 0.9660429 and 0.0195620 for the testing phase, HyFIS model showed the best accuracy for predicting the hydro-pneumatic suspension struts performance for dump trucks. This is the first time that AI models have been developed for dump truck suspension system performance prediction. With the implementation of these models in the dump truck, maintenance personnel can monitor the performance of the suspension system in real-time and schedule proper maintenance and/or replacement. Implementation of such a system will improve the workplace safety, operator's health and the overall system efficiency.",health
10.1016/j.artmed.2018.06.001,Journal,Artificial Intelligence in Medicine,scopus,2018-09-01,sciencedirect,Early anomaly detection in smart home: A causal association rule-based approach,https://api.elsevier.com/content/abstract/scopus_id/85049319216,"As the world's population grows older, an increasing number of people are facing health issues. For the elderly, living alone can be difficult and dangerous. Consequently, smart homes are becoming increasingly popular. A sensor-rich environment can be exploited for healthcare applications, in particular, anomaly detection (AD). The literature review for this paper showed that few works consider environmental factors to detect anomalies. Instead, the focus is on user activity and checking whether it is abnormal, i.e., does not conform to expected behavior. Furthermore, reducing the number of anomalies using early detection is a major issue in many applications. In this context, anomaly-cause discovery may be helpful in recommending actions that may prevent risk. In this paper, we present a novel approach for detecting the risk of anomalies occurring in the environment regarding user activities. The method relies on anomaly-cause extraction from a given dataset using causal association rules mining. These anomaly causes are utilized afterward for real-time analysis to detect the risk of anomalies using the Markov logic network machine learning method. The detected risk allows the method to recommend suitable actions to perform in order to avoid the occurrence of an actual anomaly. The proposed approach is implemented, tested, and evaluated for each contribution using real data obtained from an intelligent environment platform and real data from a clinical datasets. Experimental results prove our approach to be efficient in terms of recognition rate.",health
10.1016/j.cmpb.2018.06.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-09-01,sciencedirect,Fuzzy decision support systems to diagnose musculoskeletal disorders: A systematic literature review,https://api.elsevier.com/content/abstract/scopus_id/85048589929,"Background and objective
                  Musculoskeletal disorders (MSDs) are one of the most important causes of disability with a high prevalence. The accurate and timely diagnosis of these disorders is often difficult. Clinical decision support systems (CDSSs) can help physicians to diagnose diseases quickly and accurately. Given the ambiguous nature of MSDs, fuzzy logic can be helpful in designing the CDSSs knowledge bases. The present study aimed to review the studies on fuzzy CDSSs to diagnose MSDs.
               
                  Methods
                  A comprehensive search was conducted in Medline, Scopus, Cochrane Library, and ISI Web of Science databases to identify relevant studies published until March 15, 2016. Studies were included in which CDSSs were developed using fuzzy logic to diagnose MSDs, and tested their accuracy using real data from patients.
               
                  Results
                  Of the 3188 papers examined, 23 papers included according to the inclusion criteria. The results showed that among all the designed CDSSs only one (CADIAG-2) was implemented in the clinical environment. In about half of the included studies (52%), CDSSs were designed to diagnose inflammatory/infectious disorder of the bone and joint. In most of the included studies (70%), the knowledge was extracted using a combination of three methods (acquiring from experts, analyzing the data, and reviewing the literature). The median accuracy of fuzzy rule-based CDSSs was 91% and it was 90% for other fuzzy models. The most frequently used membership functions were triangular and trapezoidal functions, and the most used method for inference was the Mamdani.
               
                  Conclusions
                  In general, fuzzy CDSSs have a high accuracy to diagnose MSDs. Despite the high accuracy, these systems have been used to a limited extent in the clinical environments. To design of knowledge base for CDSSs to diagnose MSDs, rule-based methods are used more than other fuzzy methods.",health
10.1016/j.diin.2018.05.004,Journal,Digital Investigation,scopus,2018-09-01,sciencedirect,Laying foundations for effective machine learning in law enforcement. Majura – A labelling schema for child exploitation materials,https://api.elsevier.com/content/abstract/scopus_id/85047981760,"The health impacts of repeated exposure to distressing concepts such as child exploitation materials (CEM, aka ‘child pornography’) have become a major concern to law enforcement agencies and associated entities. Existing methods for ‘flagging’ materials largely rely upon prior knowledge, whilst predictive methods are unreliable, particularly when compared with equivalent tools used for detecting ‘lawful’ pornography. In this paper we detail the design and implementation of a deep-learning based CEM classifier, leveraging existing pornography detection methods to overcome infrastructure and corpora limitations in this field. Specifically, we further existing research through direct access to numerous contemporary, real-world, annotated cases taken from Australian Federal Police holdings, demonstrating the dangers of overfitting due to the influence of individual users' proclivities. We quantify the performance of skin tone analysis in CEM cases, showing it to be of limited use. We assess the performance of our classifier and show it to be sufficient for use in forensic triage and ‘early warning’ of CEM, but of limited efficacy for categorising against existing scales for measuring child abuse severity.
                  We identify limitations currently faced by researchers and practitioners in this field, whose restricted access to training material is exacerbated by inconsistent and unsuitable annotation schemas. Whilst adequate for their intended use, we show existing schemas to be unsuitable for training machine learning (ML) models, and introduce a new, flexible, objective, and tested annotation schema specifically designed for cross-jurisdictional collaborative use.
                  This work, combined with a world-first ‘illicit data airlock’ project currently under construction, has the potential to bring a ‘ground truth’ dataset and processing facilities to researchers worldwide without compromising quality, safety, ethics and legality.",health
10.1016/j.jstrokecerebrovasdis.2018.05.004,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2018-09-01,sciencedirect,Intravenous Thrombolysis in Patients with Acute Ischemic Stroke after a Reversal of Dabigatran Anticoagulation with Idarucizumab: A Real-World Clinical Experience,https://api.elsevier.com/content/abstract/scopus_id/85047416159,"Background
                  Intravenous thrombolysis (IVT) is contraindicated in patients with acute ischemic stroke (AIS) using oral anticoagulants. A specific human monoclonal antibody was introduced to reverse immediately the anticoagulation effect of the direct inhibitor of thrombin, dabigatran. Until now, mostly individual cases presenting with successful IVT after a reversal of dabigatran anticoagulation in patients with AIS were published. Thus, we aimed to report real-world data from clinical practice.
               
                  Methods
                  Patients with AIS on dabigatran treated with IVT after antidote reversal were enrolled in the retrospective nationwide study. Neurological deficit was scored using the National Institutes of Health Stroke Scale (NIHSS) and 90-day clinical outcome using modified Rankin scale (mRS) with a score 0-2 for a good outcome. Intracerebral hemorrhage (ICH) was defined as a presence of any sign of bleeding on control imaging after IVT, and symptomatic intracerebral hemorrhage (SICH) was assessed according to the Safe Implementation of Thrombolysis in Stroke-Monitoring Study (SITS-MOST) criteria.
               
                  Results
                  In total, 13 patients (7 men, mean age 70.0 ± 9.1 years) with a median NIHSS admission score of 7 points were analyzed. Of these patients, 61.5% used 2 × 150 mg of dabigatran daily. Antidote was administrated 427 ± 235 minutes after the last intake of dabigatran, with a mean activated prothrombin time of 38.1 ± 27.8 seconds and a mean thrombin time of 72.2 ± 56.1 seconds. Of the 13 patients, 2 had ICH and 1 had SICH, and no other bleeding complications were observed after IVT. Of the total number of patients, 76.9% had a good 3-month clinical outcome and 3 patients (23.1%) died. Recurrent ischemic stroke occurred in 2 patients (15.4%).
               
                  Conclusion
                  The data presented in the study support the safety and efficacy of IVT after the reversal of the anticoagulation effect of dabigatran with antidote in a real-world clinical practice.",health
10.1016/j.bdr.2018.05.001,Journal,Big Data Research,scopus,2018-09-01,sciencedirect,Efficient In-Database Patient Similarity Analysis for Personalized Medical Decision Support Systems,https://api.elsevier.com/content/abstract/scopus_id/85047072435,"Patient similarity analysis is a precondition to apply machine learning technology on medical data. In this sense, patient similarity analysis harnesses the information wealth of electronic medical records (EMRs) to support medical decision making. A pairwise similarity computation can be used as the basis for personalized health prediction. With n patients the amount of 
                        (
                        
                           
                              
                                 n
                              
                           
                           
                              
                                 2
                              
                           
                        
                        )
                      similarity calculations is required. Thus, analyzing patient similarity leads to data explosion when exploiting big data. By increasing the data size the computational burden of this analysis increases. A real-life medical application may exceed the limits of current hardware in a fairly short amount of time. Finding ways to optimize patient similarity analysis and handling this data explosion is the topic of this paper.
                  Current implementations for patient similarity analysis require their users to have knowledge of complex data analysis tools. Moreover, data pre-processing and analysis are performed in synthetic conditions: the data are extracted from the EMR database and then the data preparation and analysis are processed in external tools. After all of this effort the users might not experience a superior performance of the patient similarity analysis. We propose methods to optimize the patient similarity analysis in order to make it scalable to big data. Our method was tested against two real datasets and a low execution time was accomplished. Our result hence benefits a comprehensive medical decision support system. Moreover, our implementation comprises a balance between performance and applicability: the majority of the workload is processed within a database management system to enable a direct implementation on an EMR database.",health
10.1016/j.future.2018.04.036,Journal,Future Generation Computer Systems,scopus,2018-09-01,sciencedirect,Cloud and IoT based disease prediction and diagnosis system for healthcare using Fuzzy neural classifier,https://api.elsevier.com/content/abstract/scopus_id/85046118110,"Recently, the mobile health care (m-healthcare) applications with Internet of Things (IoT) are providing the various dimensionalities and the online services. These applications have provided a new platform to the millions of people for getting benefit over the health tips frequently for living a healthy life. After the introduction of IoT technology and the related devices which are used in medical field, strengthened the various features of these healthcare online applications. The huge volume of big data is generated by IoT devices in healthcare environment. Cloud computing technology is used to handle the large volume of data and also provide the ease of use. In this scenario, cloud based applications are playing major role in this fast world. These medical applications are also used the Cloud Computing technology for secured storage and accessibility. For availing better services to the people over the online healthcare applications, we propose a new Cloud and IoT based Mobile Health care application for monitoring and diagnosing the serious diseases. Here, a new framework is developed for the public. In this work, a new systematic approach is used for the diabetes diseases and the related medical data is generated by using the UCI Repository dataset and the medical sensors for predicting the people who has affected with diabetes severely. In addition, we propose a new classification algorithm called Fuzzy Rule based Neural Classifier for diagnosing the disease and the severity. The experiments have been conducted by the standard UCI Repository dataset and the real health records which are collected from various hospitals. The experimental results show that the performance of the proposed work which outperforms the existing systems for disease prediction.",health
10.1016/j.inffus.2017.05.004,Journal,Information Fusion,scopus,2018-09-01,sciencedirect,Real-time activity monitoring with a wristband and a smartphone,https://api.elsevier.com/content/abstract/scopus_id/85020177947,"Activity monitoring is a very important task in lifestyle and health domains where physical activity of a person plays an important role in further reasoning or for providing personalized recommendations. To make such services available to a broader population, one should use devices that most users already have, such as smartphones. Since trends show an increasing popularity of wrist-worn wearables we also consider a sensor-rich wristband as an optional device in this research. We present a real-time activity monitoring algorithm which utilizes data from the smartphone sensors, wristband sensors or their fusion for activity recognition and estimation of energy expenditure of the user. The algorithm detects which devices are present and uses an interval of walking for gravity detection and normalization of the orientation of the devices. The normalized data is afterwards used for the detection of the location of the smartphone on the body, which serves as a context for the selection of location-specific classification model for activity recognition. The recognized activity is finally used for the selection of one or multiple regression models for the estimation of the user’s energy expenditure. To develop the machine-learning models, which can be deployed on the smartphone, we optimized the number and type of extracted features via automatic feature selection. We evaluated each step of the algorithm and each device configuration, and compared the human energy expenditure estimation results against the Bodymedia armband and Microsoft Band 2. We also evaluated the benefit of decision fusion where appropriate. The results show that we achieve a 87% ± 5% average accuracy for activity recognition and that we outperformed both competing devices in the estimation of human energy expenditure by achieving the mean absolute error of 0.6 ± 0.1 MET on average.",health
10.1016/j.cyto.2018.03.035,Journal,Cytokine,scopus,2018-08-01,sciencedirect,"Analogous corticosteroids, 9A and EK100, derived from solid-state-cultured mycelium of Antrodia camphorata inhibit proinflammatory cytokine expression in macrophages",https://api.elsevier.com/content/abstract/scopus_id/85056423364,"Antrodia camphorata mycelium is used in traditional Chinese medicine in Taiwan. The wild-type mycelium is rare and expensive, so a solid-state-cultured mycelium of A. camphorata (SCMAC) has been developed. Previous studies have found SCMAC to have anti-inflammatory effects. However, the immunomodulatory effects of SCMAC and of its active phytosterol compounds EK100 and 9A on asthma remain unknown. In this study, BALB/c mice were repeatedly exposed to Dermatogoides pteronyssinus (Der p) at 1-week intervals and were orally administered crude SCMAC extract before the Der p challenge. The mice were sacrificed 72 h after the last challenge to examine the airway remodeling, inflammation, and expression profiles of cytokines and various genes. Then, 30-µg/mL Der p-stimulated MH-S cells with 9A or EK100 were collected for real-time PCR analysis, and the effects of 9A and EK100 on macrophages were evaluated. The crude extract reduced Der p-induced airway hyperresponsiveness, total serum immunoglobulin E levels, and recruitment of inflammatory cells to the bronchoalveolar lavage fluid through cytokine downregulation and Th1/Th2/Th17 response modulation. Additionally, 9A and EK100 inhibited IL-1β and IL-6 expression in alveolar macrophages. These results indicate that the pharmacologically active compounds in a crude SCMAC extract exert synergistic effects on multiple targets to relieve asthma symptoms.",health
10.1016/j.jbi.2018.07.003,Journal,Journal of Biomedical Informatics,scopus,2018-08-01,sciencedirect,A decision support system for antibiotic prescription based on local cumulative antibiograms,https://api.elsevier.com/content/abstract/scopus_id/85049432919,"Background
                  Local cumulative antibiograms are useful tools with which to select appropriate empiric or directed therapies when treating infectious diseases at a hospital. However, data represented in traditional antibiograms are static, incomplete and not well adapted to decision-making.
               
                  Methods
                  We propose a decision support method for empiric antibiotic therapy based on the Number Needed to Fail (NNF) measure. NNF indicates the number of patients that would need to be treated with a specific antibiotic for one to be inadequately treated. We define two new measures, Accumulated Efficacy and Weighted Accumulated Efficacy in order to determine the efficacy of an antibiotic. We carried out two experiments: the first during which there was a suspicion of infection and the patient had empiric therapy, and the second by considering patients with confirmed infection and directed therapy. The study was performed with 15,799 cultures with 356,404 susceptibility tests carried out over a four-year period.
               
                  Results
                  The most efficient empiric antibiotics are Linezolid and Vancomycin for blood samples and Imipenem and Meropenem for urine samples. In both experiments, the efficacies of recommended antibiotics are all significantly greater than the efficacies of the antibiotics actually administered (P < 0.001). The highest efficacy is obtained when considering 2 years of antibiogram data and 80% of the cumulated prevalence of microorganisms.
               
                  Conclusion
                  This extensive study on real empiric therapies shows that the proposed method is a valuable alternative to traditional antibiograms as regards developing clinical decision support systems for antimicrobial stewardship.",health
10.1016/j.media.2018.06.007,Journal,Medical Image Analysis,scopus,2018-08-01,sciencedirect,Towards intelligent robust detection of anatomical structures in incomplete volumetric data,https://api.elsevier.com/content/abstract/scopus_id/85049348377,"Robust and fast detection of anatomical structures represents an important component of medical image analysis technologies. Current solutions for anatomy detection are based on machine learning, and are generally driven by suboptimal and exhaustive search strategies. In particular, these techniques do not effectively address cases of incomplete data, i.e., scans acquired with a partial field-of-view. We address these challenges by following a new paradigm, which reformulates the detection task to teaching an intelligent artificial agent how to actively search for an anatomical structure. Using the principles of deep reinforcement learning with multi-scale image analysis, artificial agents are taught optimal navigation paths in the scale-space representation of an image, while accounting for structures that are missing from the field-of-view. The spatial coherence of the observed anatomical landmarks is ensured using elements from statistical shape modeling and robust estimation theory. Experiments show that our solution outperforms marginal space deep learning, a powerful deep learning method, at detecting different anatomical structures without any failure. The dataset contains 5043 3D-CT volumes from over 2000 patients, totaling over 2,500,000 image slices. In particular, our solution achieves 0% false-positive and 0% false-negative rates at detecting whether the landmarks are captured in the field-of-view of the scan (excluding all border cases), with an average detection accuracy of 2.78 mm. In terms of runtime, we reduce the detection-time of the marginal space deep learning method by 20–30 times to under 40 ms, an unmatched performance for high resolution incomplete 3D-CT data.",health
10.1016/j.jcv.2018.06.013,Journal,Journal of Clinical Virology,scopus,2018-08-01,sciencedirect,A fully automated system using transcription-mediated amplification for the molecular diagnosis of hepatitis E virus in human blood and faeces,https://api.elsevier.com/content/abstract/scopus_id/85048892338,"Background and objectives
                  We evaluated the performance of the Procleix HEV RNA assay implemented on the Panther automated platform for detecting HEV RNA.
               
                  Study design and results
                  Analytical specificity was 100% and there was no cross contamination, as assessed by assaying 122 plasma samples from HEV RNA-negative blood donors. The limits of detection were determined by Probit analysis with the WHO HEV standard (HEV subtype 3a) and subtype 3f and 3c reference strains. The limit of detection was 24 [CI 95%: 19–33] IU/ml for subtype 3a, 34 [28–44] IU/ml for subtype 3c and 53 [41–76] IU/ml for subtype 3f.
                  Inclusivity was assessed by testing 91 samples: HEV genotype 3 subtypes 3c (n = 29), 3e (n = 8), 3f (n = 50), genotype 4 (n = 3), and genotype 1 (n = 1). All the samples tested positive.
                  Clinical performance was determined by testing prospectively 500 consecutive plasma samples and 19 faecal samples with the Procleix assay and a reference accredited quantitative RT-PCR assay. The assays were concordant for 492/500 plasma samples (98.4%) and 18/19 (94.7%) fecal samples.
                  We also tested 92 IgM-positive/HEV RNA-negative samples with the reference assay. The IgM-positive samples included 43 (46%) that tested negative with the reference RT-PCR assay and positive with the Procleix HEV assay.
               
                  Conclusions
                  The Procleix HEV assay performed well and appears to be suitable for molecular diagnosis of HEV infection, monitoring HEV infections, and facilitating epidemiological investigations.",health
10.1016/j.cmpb.2018.05.024,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-08-01,sciencedirect,Fine-grained leukocyte classification with deep residual learning for microscopic images,https://api.elsevier.com/content/abstract/scopus_id/85047623655,"Background and objective: Leukocyte classification and cytometry have wide applications in medical domain, previous researches usually exploit machine learning techniques to classify leukocytes automatically. However, constrained by the past development of machine learning techniques, for example, extracting distinctive features from raw microscopic images are difficult, the widely used SVM classifier only has relative few parameters to tune, these methods cannot efficiently handle fine-grained classification cases when the white blood cells have up to 40 categories.
                  Methods: Based on deep learning theory, a systematic study is conducted on finer leukocyte classification in this paper. A deep residual neural network based leukocyte classifier is constructed at first, which can imitate the domain expert’s cell recognition process, and extract salient features robustly and automatically. Then the deep neural network classifier’s topology is adjusted according to the prior knowledge of white blood cell test. After that the microscopic image dataset with almost one hundred thousand labeled leukocytes belonging to 40 categories is built, and combined training strategies are adopted to make the designed classifier has good generalization ability.
                  Results: The proposed deep residual neural network based classifier was tested on microscopic image dataset with 40 leukocyte categories. It achieves top-1 accuracy of 77.80%, top-5 accuracy of 98.75% during the training procedure. The average accuracy on the test set is nearly 76.84%.
                  Conclusions: This paper presents a fine-grained leukocyte classification method for microscopic images, based on deep residual learning theory and medical domain knowledge. Experimental results validate the feasibility and effectiveness of our approach. Extended experiments support that the fine-grained leukocyte classifier could be used in real medical applications, assist doctors in diagnosing diseases, reduce human power significantly.",health
10.1016/j.jchromb.2018.05.030,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2018-08-01,sciencedirect,"Micellar HPLC-UV method for the simultaneous determination of levodopa, carbidopa and entacapone in pharmaceuticals and human plasma",https://api.elsevier.com/content/abstract/scopus_id/85047428534,"A method based on micellar liquid chromatography to quantify levodopa, carbidopa and entacapone in plasma is reported. The sample pretreatment was a simple dilution in a pure micellar solution then filtration and direct injection, without requiring extraction or purification steps. The three drugs were resolved from the matrix in 7 min, using an aqueous solution of 0.1 M sodium dodecyl sulphate-10% n-propanol-0.3 tiethylamine, adjusted at pH 2.8 with 0.02 M orthophosphoric acid as mobile phase, running under isocratic mode at 1.0 mL/ min through VP-ODS column. The detection was done by UV (ultraviolet) absorbance at 225 nm. The method was successfully validated by the International Conference Harmonization guidelines in terms of: selectivity, linearity (r2 > 0.998) over the concentration ranges of 0.025–1.2, 0.05–1.0 and 0.3–2.0 μg mL−1 with limits of detection of 0.01, 6.16 × 10−3 and 0.02 μg mL−1 and limits of quantification of 0.03, 0.02 and 0.07 μg mL−1 for levodopa, carbidopa and entacapone, respectively. The proposed method was applied successfully for quantification of the studied drugs in their different dosage forms. Moreover, the method was further extensive to the quantification of the studied drugs in spiked human plasma and was successfully validated by the guidelines of the European Medicines Agency. The proposed procedures were successfully evaluated to determine the studied drugs in real human plasma. The procedure was found reliable, practical, cost-effective, available, short period, easy-to-handle, low-cost, environmental-friendly, secure, useful for the analysis of numerous samples per day. Lastly, the method was performed to the analysis of incurred, using quality control samples in the same analytical run, with adequate results. Therefore, it can be implementable for custom analysis in clinical laboratories.",health
10.1016/j.bspc.2018.05.013,Journal,Biomedical Signal Processing and Control,scopus,2018-08-01,sciencedirect,Multiple-feature-branch convolutional neural network for myocardial infarction diagnosis using electrocardiogram,https://api.elsevier.com/content/abstract/scopus_id/85047257304,"Generally, 12-lead electrocardiogram (ECG) is widely used in MI diagnosis. It has two unique attributes namely integrity and diversity. But most of the previous studies on automated MI diagnosis algorithm didn’t utilize these two attributes simultaneously. In this paper, a novel Multiple-Feature-Branch Convolutional Neural Network (MFB-CNN) is proposed for automated MI detection and localization using ECG. Each independent feature branch of the MFB-CNN corresponds to a certain lead. Individual features of a lead can be learned by a feature branch, exploiting the diversity among the 12 leads. Global fully-connected softmax layer can exploit the integrity, summarizing all the feature branches. Based on deep learning framework, no hand-designed features are required for analysis. Furthermore, patient-specific paradigm is adopted to manage the inter-patient variability, which is a significant challenge for automated diagnosis. Also, class-based experiment (regardless of the inter-patient variability) is performed. The proposed algorithm is evaluated using the ECG data from PTB diagnostic database. It can achieve a good performance in MI diagnosis. For class-based MI detection and localization, the average accuracies are up to 99.95% and 99.81%, respectively; for patient-specific experiment, the average accuracies of MI detection and localization are 98.79% and 94.82%, respectively. Considering its excellent performance, the MFB-CNN can be applied to computer-aided diagnosis platform to assist the real-world MI detection and localization.",health
10.1016/j.isatra.2018.05.003,Journal,ISA Transactions,scopus,2018-08-01,sciencedirect,Heart rate monitoring and therapeutic devices: A wavelet transform based approach for the modeling and classification of congestive heart failure,https://api.elsevier.com/content/abstract/scopus_id/85047250258,"Heart rate monitoring and therapeutic devices include real-time sensing capabilities reflecting the state of the heart. Current circuitry can be interpreted as a cardiac electrical signal compression algorithm representing the time signal information into a single event description of the cardiac activity. It is observed that some detection techniques developed for ECG signal detection like artificial neural network, genetic algorithm, Hilbert transform, hidden Markov model are some sophisticated algorithms which provide suitable results but their implementation on a silicon chip is very complicated. Due to less complexity and high performance, wavelet transform based approaches are widely used. In this paper, after a thorough analysis of various wavelet transforms, it is found that Biorthogonal wavelet transform is best suited to detect ECG signal's QRS complex. The main steps involved in ECG detection process consist of de-noising and locating different ECG peaks using adaptive slope prediction thresholding. Furthermore, the significant challenges involved in the wireless transmission of ECG data are data conversion and power consumption. As medical regulatory boards demand a lossless compression technique, lossless compression technique with a high bit compression ratio is highly required. Furthermore, in this work, LZMA based ECG data compression technique is proposed. The proposed methodology achieves the highest signal to noise ratio, and lowest root mean square error. Also, the proposed ECG detection technique is capable of distinguishing accurately between healthy, myocardial infarction, congestive heart failure and coronary artery disease patients with a detection accuracy, sensitivity, specificity, and error of 99.92%, 99.94%, 99.92% and 0.0013, respectively. The use of LZMA data compression of ECG data achieves a high compression ratio of 18.84. The advantages and effectiveness of the proposed algorithm are verified by comparing with the existing methods.",health
10.1016/j.cmpb.2018.04.030,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-08-01,sciencedirect,Computerized decision support for beneficial home-based exercise rehabilitation in patients with cardiovascular disease,https://api.elsevier.com/content/abstract/scopus_id/85046622771,"Background
                  Exercise-based rehabilitation plays a key role in improving the health and quality of life of patients with Cardiovascular Disease (CVD). Home-based computer-assisted rehabilitation programs have the potential to facilitate and support physical activity interventions and improve health outcomes.
               
                  Objectives
                  We present the development and evaluation of a computerized Decision Support System (DSS) for unsupervised exercise rehabilitation at home, aiming to show the feasibility and potential of such systems toward maximizing the benefits of rehabilitation programs.
               
                  Methods
                  The development of the DSS was based on rules encapsulating the logic according to which an exercise program can be executed beneficially according to international guidelines and expert knowledge. The DSS considered data from a prescribed exercise program, heart rate from a wristband device, and motion accuracy from a depth camera, and subsequently generated personalized, performance-driven adaptations to the exercise program. Communication interfaces in the form of RESTful web service operations were developed enabling interoperation with other computer systems.
               
                  Results
                  The DSS was deployed in a computer-assisted platform for exercise-based cardiac rehabilitation at home, and it was evaluated in simulation and real-world studies with CVD patients. The simulation study based on data provided from 10 CVD patients performing 45 exercise sessions in total, showed that patients can be trained within or above their beneficial HR zones for 67.1 ± 22.1% of the exercise duration in the main phase, when they are guided with the DSS. The real-world study with 3 CVD patients performing 43 exercise sessions through the computer-assisted platform, showed that patients can be trained within or above their beneficial heart rate zones for 87.9 ± 8.0% of the exercise duration in the main phase, with DSS guidance.
               
                  Conclusions
                  Computerized decision support systems can guide patients to the beneficial execution of their exercise-based rehabilitation program, and they are feasible.",health
10.1016/j.ijfoodmicro.2018.04.008,Journal,International Journal of Food Microbiology,scopus,2018-07-20,sciencedirect,Hepatitis E virus in lettuce and water samples: A method-comparison study,https://api.elsevier.com/content/abstract/scopus_id/85045580361,"The hepatitis E virus (HEV), which is an increasing cause of acute viral hepatitis in Europe, is a zoonotic virus that is mainly transmitted through contaminated water, consumption of raw or undercooked meat from pigs or wild boar, blood transfusion, and organ transplantation. Although the role of HEV transmission through contaminated produce has not been confirmed, the presence of HEV has been reported in irrigation waters and in vegetables. The present study used a World Health Organization (WHO) international standard and clinical samples to evaluate the performance characteristics of three RT-qPCR assays for detection and quantification of HEV. Two of the evaluated assays provided good analytical sensitivity, as 250 international units (IU) per ml could be detected. Then, experiments focused on evaluating the elution conditions suitable for HEV release from vegetables, with the method proposed by the ISO 15216:2017 selected for evaluation in three types of fresh vegetables. The concentration method proposed by the ISO 15216:2017 combined with the RT-qPCR described by Schlosser et al. (2014) resulted in average HEV recoveries of 1.29%, 0.46%, and 3.95% in lettuce, spinach, and pepper, respectively, with an average detection limit of 1.47 × 105 IU/25 g. In naturally contaminated samples, HEV was detected in sewage only (10/14), while no detection was reported in lettuce (0/36) or in irrigation water samples (0/24).",health
10.1016/j.ijantimicag.2018.02.018,Journal,International Journal of Antimicrobial Agents,scopus,2018-07-01,sciencedirect,Identification and bioevaluation of SRI-12742 as an antimicrobial agent against multidrug-resistant Acinetobacter baumannii,https://api.elsevier.com/content/abstract/scopus_id/85048519265,"Multidrug-resistant Acinetobacter baumannii (MDR-Ab) is one of the most significant nosocomial pathogens that is being increasingly isolated in healthcare settings worldwide. Owing to its inherent drug-resistant nature, coupled with its ability to readily acquire resistance to other antibiotic classes, there is a real dearth of antibiotics available to treat infections with MDR-Ab. A commercially available library was screened against MDR-Ab BAA-1605 to identify novel inhibitory molecules. The selectivity index of a hit was tested against Vero cells and in vitro efficacy was profiled against a panel of clinical MDR-Ab. The bacteriostatic or bactericidal nature was determined by time–kill experiments, and synergy with clinically approved drugs was determined by the chequerboard method. Additionally, in vivo efficacy was measured in a murine neutropenic A. baumannii thigh infection model. SRI-12742 was identified as a potent active hit, with a minimum inhibitory concentration (MIC) of 4 mg/L against BAA-1605. Its activity was then profiled against a MDR-Ab clinical strain panel (MICs 4 mg/L to >64 mg/L). SRI-12742 exhibited concentration-dependent bactericidal activity and caused an ca. 16 log10 CFU/mL reduction at 10 × MIC in 24 h, which is comparable with minocycline. In a murine neutropenic thigh infection model of A. baumannii infection, SRI-12742 reduced CFU counts by ca. 0.9 log10 CFU, which is comparable with polymyxin B. In addition, SRI-12742 synergised with all classes of antibiotics tested. SRI-12742 exhibits all of the criteria necessary to be positioned as a novel lead with potential to be deployed for the treatment of infections caused by MDR-Ab.",health
10.1016/j.compbiomed.2018.05.004,Journal,Computers in Biology and Medicine,scopus,2018-07-01,sciencedirect,Evaluation of machine learning algorithms for improved risk assessment for Down's syndrome,https://api.elsevier.com/content/abstract/scopus_id/85046822586,"Prenatal screening generates a great amount of data that is used for predicting risk of various disorders. Prenatal risk assessment is based on multiple clinical variables and overall performance is defined by how well the risk algorithm is optimized for the population in question. This article evaluates machine learning algorithms to improve performance of first trimester screening of Down syndrome. Machine learning algorithms pose an adaptive alternative to develop better risk assessment models using the existing clinical variables. Two real-world data sets were used to experiment with multiple classification algorithms. Implemented models were tested with a third, real-world, data set and performance was compared to a predicate method, a commercial risk assessment software. Best performing deep neural network model gave an area under the curve of 0.96 and detection rate of 78% with 1% false positive rate with the test data. Support vector machine model gave area under the curve of 0.95 and detection rate of 61% with 1% false positive rate with the same test data. When compared with the predicate method, the best support vector machine model was slightly inferior, but an optimized deep neural network model was able to give higher detection rates with same false positive rate or similar detection rate but with markedly lower false positive rate. This finding could further improve the first trimester screening for Down syndrome, by using existing clinical variables and a large training data derived from a specific population.",health
10.1016/j.artmed.2018.04.012,Journal,Artificial Intelligence in Medicine,scopus,2018-07-01,sciencedirect,An interoperable clinical decision-support system for early detection of SIRS in pediatric intensive care using openEHR,https://api.elsevier.com/content/abstract/scopus_id/85046668398,"Background
                  Clinical decision-support systems (CDSS) are designed to solve knowledge-intensive tasks for supporting decision-making processes. Although many approaches for designing CDSS have been proposed, due to high implementation costs, as well as the lack of interoperability features, current solutions are not well-established across different institutions. Recently, the use of standardized formalisms for knowledge representation as terminologies as well as the integration of semantically enriched clinical information models, as openEHR Archetypes, and their reuse within CDSS are theoretically considered as key factors for reusable CDSS.
               
                  Objective
                  We aim at developing and evaluating an openEHR based approach to achieve interoperability in CDSS by designing and implementing an exemplary system for automated systemic inflammatory response syndrome (SIRS) detection in pediatric intensive care.
               
                  Methods
                  We designed an interoperable concept, which enables an easy integration of the CDSS across different institutions, by using openEHR Archetypes, terminology bindings and the Archetype Query Language (AQL). The practicability of the approach was tested by (1) implementing a prototype, which is based on an openEHR based data repository of the Hannover Medical School (HaMSTR), and (2) conducting a first pilot study.
               
                  Results
                  We successfully designed and implemented a CDSS with interoperable knowledge bases and interfaces by reusing internationally agreed-upon Archetypes, incorporating LOINC terminology and creating AQL queries, which allowed retrieving dynamic facts in a standardized and unambiguous form. The technical capabilities of the system were evaluated by testing the prototype on 16 randomly selected patients with 129 days of stay, and comparing the results with the assessment of clinical experts (leading to a sensitivity of 1.00, a specificity of 0.94 and a Cohen’s kappa of 0.92).
               
                  Conclusions
                  We found the use of openEHR Archetypes and AQL a feasible approach to bridge the interoperability gap between local infrastructures and CDSS. The designed concept was successfully transferred into a clinically evaluated openEHR based CDSS. To the authors’ knowledge, this is the first openEHR based CDSS, which is technically reliable and capable in a real context, and facilitates clinical decision-support for a complex task. Further activities will comprise enrichments of the knowledge base, the reasoning processes and cross-institutional evaluations.",health
10.1016/j.nedt.2018.04.008,Journal,Nurse Education Today,scopus,2018-07-01,sciencedirect,‘Doing it for real now’ – The transition from healthcare assistant to newly qualified nurse: A qualitative study,https://api.elsevier.com/content/abstract/scopus_id/85045675099,"Background
                  There has been increasing international research and policy interest concerning the transition from student to newly qualified nurse (NQN). However, the influence of previous employment as a healthcare assistant (HCA) on students' experiences of this transition is comparatively under-researched.
               
                  Aims and Objectives
                  To explore the experiences of NQNs also employed as HCAs during their pre-registration education programme and how this prior and ongoing HCA experience influenced their transition experiences.
               
                  Design
                  Qualitative research design using a descriptive method.
               
                  Setting and Participants
                  Former students (n = 14) of a unique four year, part-time, employer-sponsored pre-registration nursing programme, specifically designed for HCAs and delivered by supported open learning, located in different regions and nations of the United Kingdom who had qualified within the last two years.
               
                  Methods
                  Telephone interviews, digitally recorded, transcribed verbatim and analysed using NVivo8.
               
                  Results
                  Four themes described participants' experiences of transition: In at the deep end, Changing identities, Coming together and Scaffolding. Findings confirm existing literature that all NQNs appear to experience a similar overarching experience of transition, including those with prior HCA experience. However, familiarity with people, place and routines afforded by this previous experience appeared to ease transition, particularly if the NQNs stayed in their previous HCA work location. However, managing the dual roles of being both HCA and student and adapting to their changing identities were frequently cited as particular challenges.
               
                  Conclusions
                  Van Gennep's Rites de Passage and Bridge's work on organisational change were combined to theoretically analyse participants' accounts of transition. This illustrated that transition is not always linear with clearly defined and bounded stages but can also be seen as a more undulating or organic process with curving, slanting and overlapping phases. NQNs can therefore simultaneously occupy more than once phase in their journey of transition. Implications for students, higher education and practice are highlighted.",health
10.1016/j.enpol.2018.04.011,Journal,Energy Policy,scopus,2018-07-01,sciencedirect,Decision support system for Pradhan Mantri Ujjwala Yojana,https://api.elsevier.com/content/abstract/scopus_id/85045255236,"Pradhan Mantri Ujjwala Yojana (PMUY) is a flagship energy policy initiated by the government of India to provide women below poverty line (BPL) access to clean energy fuel, Liquefied Petroleum Gas (LPG). This policy has led to the empowerment of women and protection against health hazards. A decision support system (DSS) is proposed to quantitatively analyse the implementation of PMUY in real time. This approach is first of its kind for analysis of a national level energy policy. The system uses mixed integer linear programming approach to mathematically formulate the policy using input parameters, decision variables and their relationships. The DSS requires input parameters namely distributing capacity of a LPG dealer, subsidised cylinders available per connection, number of households, and LPG penetration required. We have analysed different scenarios varying the input parameters mentioned. The decision support system has deterministically found the number of dealers required and LPG penetration in a region projecting both BPL and aggregate household coverage. The system helps in making sound decisions based on quantitative modelling ensuring optimal implementation of the policy. This kind of decision support system can be formulated for various policies to make sound decisions based on strong quantitative evidences.",health
10.1016/j.bdr.2018.02.004,Journal,Big Data Research,scopus,2018-07-01,sciencedirect,Scalable Machine Learning for Predicting At-Risk Profiles Upon Hospital Admission,https://api.elsevier.com/content/abstract/scopus_id/85043390972,"We show how the analysis of very large amounts of drug prescription data make it possible to detect, on the day of hospital admission, patients at risk of developing complications during their hospital stay. We explore, for the first time, to which extent volume and variety of big prescription data help in constructing predictive models for the automatic detection of at-risk profiles.
                  Our methodology is designed to validate our claims that: (1) drug prescription data on the day of admission contain rich information about the patient's situation and perspectives of evolution, and (2) the various perspectives of big medical data (such as veracity, volume, variety) help in extracting this information. We build binary classification models to identify at-risk patient profiles. We use a distributed architecture to ensure scalability of model construction with large volumes of medical records and clinical data.
                  We report on practical experiments with real data of millions of patients and hundreds of hospitals. We demonstrate how the fine-grained analysis of such big data can improve the detection of at-risk patients, making it possible to construct more accurate predictive models that significantly benefit from volume and variety, while satisfying important criteria to be deployed in hospitals.",health
10.1016/j.jsv.2018.03.008,Journal,Journal of Sound and Vibration,scopus,2018-06-23,sciencedirect,Wireless and real-time structural damage detection: A novel decentralized method for wireless sensor networks,https://api.elsevier.com/content/abstract/scopus_id/85044102066,"Being an alternative to conventional wired sensors, wireless sensor networks (WSNs) are extensively used in Structural Health Monitoring (SHM) applications. Most of the Structural Damage Detection (SDD) approaches available in the SHM literature are centralized as they require transferring data from all sensors within the network to a single processing unit to evaluate the structural condition. These methods are found predominantly feasible for wired SHM systems; however, transmission and synchronization of huge data sets in WSNs has been found to be arduous. As such, the application of centralized methods with WSNs has been a challenge for engineers. In this paper, the authors are presenting a novel application of 1D Convolutional Neural Networks (1D CNNs) on WSNs for SDD purposes. The SDD is successfully performed completely wireless and real-time under ambient conditions. As a result of this, a decentralized damage detection method suitable for wireless SHM systems is proposed. The proposed method is based on 1D CNNs and it involves training an individual 1D CNN for each wireless sensor in the network in a format where each CNN is assigned to process the locally-available data only, eliminating the need for data transmission and synchronization. The proposed damage detection method operates directly on the raw ambient vibration condition signals without any filtering or preprocessing. Moreover, the proposed approach requires minimal computational time and power since 1D CNNs merge both feature extraction and classification tasks into a single learning block. This ability is prevailingly cost-effective and evidently practical in WSNs considering the hardware systems have been occasionally reported to suffer from limited power supply in these networks. To display the capability and verify the success of the proposed method, large-scale experiments conducted on a laboratory structure equipped with a state-of-the-art WSN are reported.",health
10.1016/j.vaccine.2018.05.043,Journal,Vaccine,scopus,2018-06-14,sciencedirect,Plasmid pcDNA3.1-s11 constructed based on the S11 segment of grass carp reovirus as DNA vaccine provides immune protection,https://api.elsevier.com/content/abstract/scopus_id/85046864452,"Although some commercial vaccines against grass carp reovirus (GCRV) are available, given the many varieties of GCRV and limited types of vaccines, the disease caused by GCRV remains a major problem, which leads to economic losses in grass carp aquaculture. A reovirus strain (GCRV-HN14) was recently isolated from local diseased fish in our laboratory. The S11 segment of GCRV-HN14 was speculated to encode the virus capsid protein VP35. In our study, the S11 segment was cloned into the eukaryotic expression vector pcDNA3.1(+) to construct the recombinant plasmid pcDNA3.1-s11, which was then transfected into CIK cells, and the VP35 protein was successfully expressed. Grass carp was immunized with pcDNA3.1-s11, and the in vivo distribution and expression of the pcDNA3.1-s11 plasmids were analyzed by PCR and Western blot. Recombinant plasmids were detected in the blood, liver, spleen, kidney, and muscle. However, protein expression could only be detected in the muscle. The immune protection of the pcDNA3.1-s11 plasmid in grass carp was evaluated using a series of experiments. Results showed that the population of white blood cells significantly increased at 1, 7, and 14 days post-immunization (dpi) and reached a peak with (9.58 ± 0.72) × 107/ml at 7 dpi (P < 0.01 or P < 0.05). The percentage of neutrophils reached a peak with (24.13 ± 2.38)% at 7 dpi (P < 0.01), whereas the lymphocytes peaked with (93.30 ± 4.71)% at 14 dpi (P < 0.05). Serum antibody levels were significantly enhanced in immunized fish at 14, 21, and 28 dpi (P < 0.01). The mRNA expression levels of type I interferon, immunoglobulin M, Toll-like receptor 22, and major histocompatibility complex class I were significantly up-regulated in the head kidney and spleen of immunized fish (P < 0.05). Grass carp immunized with pcDNA3.1-s11 exhibited a higher survival percentage (70.4%–73.3%) than the controls (5%–13%). Overall, as a DNA vaccine, the pcDNA3.1-s11 plasmid could induce immune protection against GCRV.",health
10.1016/j.jep.2017.11.005,Journal,Journal of Ethnopharmacology,scopus,2018-06-12,sciencedirect,Anti-thrombotic and pro-angiogenic effects of Rubia cordifolia extract in zebrafish,https://api.elsevier.com/content/abstract/scopus_id/85044162661,"Ethnopharmacological relevance
                  
                     Rubia cordifolia is a common traditional Chinese medicine that promotes blood circulation and eliminates blood stasis, and has been used to cure diseases related to blood stasis syndrome (BSS) clinically for many years. It has been previously demonstrated that anti-thrombosis and pro-angiogenesis can improve BSS. However, the anti-thrombotic and pro-angiogenic activities of Rubia cordifolia have not been well investigated.
               
                  Aim of study
                  To determine the potential anti-thrombotic and pro-angiogenic activities of Rubia cordifolia and to elucidate the underlying mechanisms. In addition, the major chemical constituents of Rubia cordifolia extract (QC) were qualitatively analysed by UPLC-Q-TOF/MS to explore the association between pharmacological activity and chemical constituents.
               
                  Material and methods
                  The QC samples were composed of a 95% ethanol extract and an aqueous extract following extraction using 95% ethanol. UPLC-Q-TOF/MS was used to analyse the major chemical constituents of QC. For the anti-thrombotic experiment of QC, a phenylhydrazine (PHZ)-induced AB strain zebrafish thrombosis model was used. The zebrafish larvae were stained using O-dianisidine, and the heart and caudal vein of the zebrafish were observed and imaged with a fluorescence microscope. The staining intensity of erythrocytes in the heart (SI) of each group and the morphology of thrombus in the caudal vein were used to assess the anti-thrombotic effect of QC. For the pro-angiogenic assay of QC, the intersegmental blood vessel (ISV) insufficiency model of Tg(fli-1: EGFP)y1 transgenic zebrafish (Flik zebrafish), which was induced by the VEGF receptor tyrosine kinase inhibitor II (VRI), was used. The morphology of the intact ISVs and defective ISVs was observed to evaluate the pro-angiogenic activity of QC. The mechanism involved in promoting angiogenesis was studied with real-time PCR.
               
                  Results
                  A total of 12 components in QC were identified based on standard compounds and references, including nine anthraquinones and three naphthoquinones. After treatment with QC, the PHZ-induced thrombosis in AB strain zebrafish larvae decreased to a certain degree, which we believe was related to its dosages, and the therapeutic effect within the 50–200 µg/mL QC treatment groups was especially prominent (P < 0.01, P < 0.001) compared to that in the PHZ model group. Similarly, QC also recovered the loss of the ISVs, which was induced by VRI in Flik zebrafish larvae, which have a certain dose-effect relationship. The pro-angiogenic activity of QC was also conspicuous (P < 0.01, P < 0.001) compared to that of the VRI model group. The following real-time PCR assay proved that QC significantly restored the VRI-induced downregulation of vWF, VEGF-A, kdrl, and flt-1 in Flik zebrafish (P < 0.05, P < 0.01, P < 0.001).
               
                  Conclusions
                  A total of 12 compounds from QC were analysed by UPLC-Q-TOF/MS. The data of the pharmacological experiments demonstrated that QC presented anti-thrombotic and pro-angiogenic activities in zebrafish, and the principal active components were likely anthraquinones and naphthoquinones. Thus, the current study provided a theoretical basis for the clinical use of Rubia cordifolia as a traditional Chinese medicine in promoting blood circulation and eliminating stasis.",health
10.1016/j.jconrel.2018.04.017,Journal,Journal of Controlled Release,scopus,2018-06-10,sciencedirect,Overcoming safety challenges in CO therapy – Extracorporeal CO delivery under precise feedback control of systemic carboxyhemoglobin levels,https://api.elsevier.com/content/abstract/scopus_id/85046347956,"Carbon monoxide (CO) has demonstrated therapeutic potential in multiple inflammatory conditions including intensive care applications such as organ transplantation or sepsis. Approaches to translate these findings into future therapies, however, have been challenged by multiple hurdles including handling and toxicity issues associated with systemic CO delivery. Here, we describe a membrane-controlled Extracorporeal Carbon Monoxide Release System (ECCORS) for easy implementation into Extracorporeal Membrane Oxygenation (ECMO) setups, which are being used to treat cardiac and respiratory diseases in various intensive care applications. Functionalities of the ECCORS were investigated in a pig model of veno-arterial ECMO. By precisely controlling CO generation and delivery as a function of systemic carboxyhemoglobin levels, the system allows for an immediate onset of therapeutic CO-levels while preventing CO-toxicity. Systemic carboxyhemoglobin levels were profiled in real-time by monitoring exhaled CO levels as well as by pulse oximetry, enabling self-contained and automatic feedback control of CO generation within ECCORS. Machine learning based mathematical modeling was performed to increase the predictive power of this approach, laying foundation for high precision systemic CO delivery concepts of tomorrow.",health
10.1016/j.jbi.2018.04.011,Journal,Journal of Biomedical Informatics,scopus,2018-06-01,sciencedirect,Label-indicator morpheme growth on LSTM for Chinese healthcare question department classification,https://api.elsevier.com/content/abstract/scopus_id/85047269121,"Background
                  Current Chinese medicine has an urgent demand for convenient medical services. When facing a large number of patients, understanding patients’ questions automatically and precisely is useful. Different from the high professional medical text, patients’ questions contain only a small amount of descriptions regarding the symptoms, and the questions are slightly professional and colloquial.
               
                  Object
                  The aim of this paper is to implement a department classification system for patient questions. Patients’ questions will be classified into 11 departments, such as surgery and others.
               
                  Methods
                  This paper presents a morpheme growth model that enhances the memories of key elements in questions, and later extracts the “label-indicators” and germinates the expansion vectors around them. Finally, the model inputs the expansion vectors into a neural network to assign department labels for patients’ questions.
               
                  Results
                  All compared methods are validated by experiments on three datasets that are composed of real patient questions. The proposed method has some ability to improve the performance of the classification.
               
                  Conclusions
                  The proposed method is effective for the departments classification of patients questions and serves as a useful system for the automatic understanding of patient questions.",health
10.1016/j.vetimm.2018.04.005,Journal,Veterinary Immunology and Immunopathology,scopus,2018-06-01,sciencedirect,Threshold level of Riemerella anatipestifer crossing blood-brain barrier and expression profiles of immune-related proteins in blood and brain tissue from infected ducks,https://api.elsevier.com/content/abstract/scopus_id/85045740296,"Riemerella anatipestifer (R. anatipestifer) is a Gram-negative bacterium that crosses the blood–brain barrier (BBB) and causes meningitis with neurological symptoms in infected ducks. A threshold level of bacteremia must be reached before the BBB can be breached. In this study, the bacterial burden and expression profiles of immune-related proteins in blood and brain tissue samples from R. anatipestifer-infected ducks were investigated. The data showed that R. anatipestifer could cross the BBB with low-level bacteremia of 7.5 × 102 CFU/ml in infected blood. Analysis of immune-related proteins revealed that IL-4, IL-17A, IL-17D, TLR3, TLR4, TLR7, and TGF-β in blood, as well as IL-1β, IL-2, IL-4, IL-17A, IL-17D, IL-17F, TLR3, TLR4, and TGF-β in brain tissue were upregulated at an early stage in infection. The expression levels of Th1 and Th17-specific cytokines were significantly higher than those of Th2-specific cytokines, which indicated that mainly Th1 and Th17 immune responses were induced during R. anatipestifer infection.",health
10.1016/j.ijmedinf.2018.03.003,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,SCADI: A standard dataset for self-care problems classification of children with physical and motor disability,https://api.elsevier.com/content/abstract/scopus_id/85044939032,"Self-care problems diagnosis and classification is an important challenge in exceptional children health care systems. Since, self-care problems classification is a time-consuming process and requires expert occupational therapists, using an expert system in classifying these problems can decrease cost and time, efficiently. Expert systems refer to the systems that are based on artificial intelligence methods, which have the ability to learn, infer, and predict. In order to configure and train an expert system, a standard dataset is critical for the learning phase. Hence, in this research, a new standard dataset called SCADI (Self-Care Activities Dataset based on ICF-CY) is introduced innovatively. SCADI is based on ICF-CY, which is a conceptual framework, released by the World Health Organization. According to the best of our knowledge, SCADI is the first standard dataset in the self-care activates based on ICF-CY in which 29 self-care activities are considered. In this research, to show the applicability of SCADI in the expert systems, two different types of expert systems are proposed for the self-care problems classification of children with physical and motor disability. In the first expert system, an Artificial Neural Network (ANN) is employed as a classifier. This classifier is trained by using SCADI during the learning process. Since ANNs do not provide any explanation for the inference rules and manners, in the second expert system, to evaluate the applicability of SCADI in the rule-based systems, C4.5, a popular decision tree algorithm is used to extract self-care problems classification rules precisely. The experiment results show that the ANN-based system has high accuracy in self-care problems classification, which is 83.1% and SCADI has the high applicability to be employed in the different classification systems such as neural networks and rule-based systems.",health
10.1016/j.onehlt.2018.02.001,Journal,One Health,scopus,2018-06-01,sciencedirect,First ‘Global Flipped Classroom in One Health’: From MOOCs to research on real world challenges,https://api.elsevier.com/content/abstract/scopus_id/85042283298,"In 2016 and 2017 the first three MOOCs (Massive Online Open Course) addressing One Health were released, two of them by University of Geneva and University of Basel (Switzerland). With the support of Swiss School of Public Health and using these two highly interdisciplinary MOOCs, the first 'Global Flipped Classroom in One Health' was organized in Geneva and Basel in July 2017. This innovative event gathered 12 Swiss and international MOOC learners to work on specific public/global health challenges at the human-animal-ecosystem interface in interdisciplinary teams supported by experts from academia and international organisations (e.g. World Health Organization) based in Geneva, Basel and internationally. According to the final survey, the level of satisfaction by learners was high and they benefited from the experience in different ways: reinforcement of their knowledge and capacity to perform innovative research in One Health (e.g. using digital epidemiology), visits and meetings with experts in Global Health (e.g. World Health Organization and Institute of Global Health in Geneva, Swiss Tropical and Public Health Institute in Basel) and emerging research collaborations etc. A novel project-based learning and research model arising from MOOCs was successfully created, which offers opportunities for global education and research addressing real world challenges utilising a One Health approach.",health
10.1016/j.snb.2017.12.190,Journal,"Sensors and Actuators, B: Chemical",scopus,2018-06-01,sciencedirect,Rapid and sensitive detection of Salmonella based on microfluidic enrichment with a label-free nanobiosensing platform,https://api.elsevier.com/content/abstract/scopus_id/85041511353,"Urinary tract infections are among the most common bacterial infections in humans, causing relapses and acute prostatitis as well as significant morbidity and high medical costs. In bacteria with low abundance in urological samples, which contain various contaminating factors, sample analyses should be conducted with meticulous care; therefore, emerging technologies can facilitate the characterization of disease-causing bacteria with more sensitivity, rapidity, and ease of use. In this study, we developed a highly sensitive nanobiosensor based on isothermal amplification combining microfluidic enrichment using a concanavalin A–functionalized microchannel with asymmetric herringbone groove arrays for rapid detection of pathogens. After optimization of enrichment and detection conditions, we demonstrated that Salmonella enterica serotype Typhimurium could be detected in urine samples (10 mL) at a concentration as low as 5 CFU/mL in real-time using a label-free method. Moreover, the use of microfluidic enrichment improved the sensitivity by 1.76 orders of magnitude. The whole experiment was completed within 100 min. This developed method has the potential to provide a simple, rapid, sensitive diagnostic platform and can be used in practical applications for detection of Salmonella or other pathogenic bacteria, causing urinary tract infections.",health
10.1016/j.ijmedinf.2018.01.015,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,Humanitarian health computing using artificial intelligence and social media: A narrative literature review,https://api.elsevier.com/content/abstract/scopus_id/85040945850,"Introduction
                  According to the World Health Organization (WHO), over 130 million people are in constant need of humanitarian assistance due to natural disasters, disease outbreaks, and conflicts, among other factors. These health crises can compromise the resilience of healthcare systems, which are essential for achieving the health objectives of the sustainable development goals (SDGs) of the United Nations (UN). During a humanitarian health crisis, rapid and informed decision making is required. This is often challenging due to information scarcity, limited resources, and strict time constraints. Moreover, the traditional approach to digital health development, which involves a substantial requirement analysis, a feasibility study, and deployment of technology, is ill-suited for many crisis contexts. The emergence of Web 2.0 technologies and social media platforms in the past decade, such as Twitter, has created a new paradigm of massive information and misinformation, in which new technologies need to be developed to aid rapid decision making during humanitarian health crises.
               
                  Objective
                  Humanitarian health crises increasingly require the analysis of massive amounts of information produced by different sources, such as social media content, and, hence, they are a prime case for the use of artificial intelligence (AI) techniques to help identify relevant information and make it actionable. To identify challenges and opportunities for using AI in humanitarian health crises, we reviewed the literature on the use of AI techniques to process social media.
               
                  Methodology
                  We performed a narrative literature review aimed at identifying examples of the use of AI in humanitarian health crises. Our search strategy was designed to get a broad overview of the different applications of AI in a humanitarian health crisis and their challenges. A total of 1459 articles were screened, and 24 articles were included in the final analysis.
               
                  Results
                  Successful case studies of AI applications in a humanitarian health crisis have been reported, such as for outbreak detection. A commonly shared concern in the reviewed literature is the technical challenge of analyzing large amounts of data in real time. Data interoperability, which is essential to data sharing, is also a barrier with regard to the integration of online and traditional data sources.
                  Human and organizational aspects that might be key factors for the adoption of AI and social media remain understudied. There is also a publication bias toward high-income countries, as we identified few examples in low-income countries. Further, we did not identify any examples of certain types of major crisis, such armed conflicts, in which misinformation might be more common.
               
                  Conclusions
                  The feasibility of using AI to extract valuable information during a humanitarian health crisis is proven in many cases. There is a lack of research on how to integrate the use of AI into the work-flow and large-scale deployments of humanitarian aid during a health crisis.",health
10.1016/j.ijmedinf.2017.12.021,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,The ALMANACH Project: Preliminary results and potentiality from Afghanistan,https://api.elsevier.com/content/abstract/scopus_id/85040258127,"Introduction
                  ALMANACH (ALgorithms for the MANagement of Acute CHildhood illnesses) is an electronic version of IMCI (Integrated Management of Childhood Illness) running on tablets. ALMANACH enhances its concept, it integrates well into health staff's daily consultation work and facilitates diagnosis and treatment. ALMANACH informs when to refer a child or to perform a rapid diagnostic test (RDT), recommends the right treatment dosage and synchronizes collected data real time with a Health Management Information System (DHIS2) for epidemiological evaluation and decision making.
               
                  Objectives
                  Since May 2016, ALMANACH is under investigational deployment in three primary health care facilities in Afghanistan with the goal to improve the quality of care provided to children between 2 months and 5 years old.
               
                  Methods
                  IMCI's algorithms were updated in considering latest scientific publications, national guidelines, innovations in RDTs, the target population's epidemiological profile and the local resources available. Before the implementation of the project, a direct observation of 599 consultations was carried out to assess the daily performance at three selected health facilities in Kabul.
               
                  Results
                  The baseline survey showed that nutritional screening, vitamin A supplementation and deworming were not systematically performed: few patients were diagnosed for malnutrition (1.8%), received vitamin A (2.7%) or deworming (7.5%). Physical examination was appropriate only for 23.8% of the diagnoses of respiratory or gastrointestinal diseases, ear infection and sore throat. Respiratory rate was checked only in 33.5% of the children with fever and cough, dehydration status was assessed in only 16.5% of the diarrhoea cases. Forty-seven percent of patients received incorrect treatment. Sixty-four percent of the children, before the introduction of ALMANACH, received at least one antibiotic, although for 87.1% antibiotic therapy was unnecessary.
                  The review of 8′047 paediatric consultations between May 2016 and September 2017 showed that with ALMANACH, malnutrition detection, deworming and Vitamin A supplementation increased respectively to 4.4%, 50.2% and 27.5%. Antibiotic prescription decreased to 21.83% and all children were examined and treated in compliance with the protocols. Conclusion: A survey will be conducted one year after the implementation to validate these initial promising results. If the efficacy of the approach is confirmed, ALMANACH could establish as a powerful innovation for primary health care.",health
10.1016/j.jneumeth.2017.12.011,Journal,Journal of Neuroscience Methods,scopus,2018-05-15,sciencedirect,Deep learning reveals Alzheimer's disease onset in MCI subjects: Results from an international challenge,https://api.elsevier.com/content/abstract/scopus_id/85044855024,"Background
                  Early diagnosis of Alzheimer's disease (AD) and its onset in subjects affected by mild cognitive impairment (MCI) based on structural MRI features is one of the most important open issues in neuroimaging. Accordingly, a scientific challenge has been promoted, on the international Kaggle platform, to assess the performance of different classification methods for prediction of MCI and its conversion to AD.
               
                  New method
                  This work presents a classification strategy based on Random Forest feature selection and Deep Neural Network classification using a mixed cohort including the four classes of classification problem, that is HC, AD, MCI and cMCI, to train the model. Moreover, we compare this approach with a novel classification strategy based on fuzzy logic learned on a mixed cohort including only HC and AD.
               
                  Experiments
                  A training set of 240 subjects and a test set including mixed cohort of 500 real and simulated subjects were used. The data included AD patients, MCI subjects converting to AD (cMCI), MCI subjects and healthy controls (HC). This work ranked third for overall accuracy (38.8%) over 19 participating teams.
               
                  Comparison with existing method(s)
                  The “International challenge for automated prediction of MCI from MRI data” hosted by the Kaggle platform has been promoted to validate different methodologies with a common set of data and evaluation procedures.
               
                  Conclusion
                  DNNs reach a classification accuracy significantly higher than other machine learning strategies; on the other hand, fuzzy logic is particularly accurate with cMCI, suggesting a combination of these approaches could lead to interesting future perspectives.",health
10.1016/j.snb.2018.01.117,Journal,"Sensors and Actuators, B: Chemical",scopus,2018-05-15,sciencedirect,Graphene oxide functionalized long period fiber grating for highly sensitive hemoglobin detection,https://api.elsevier.com/content/abstract/scopus_id/85041418010,"We present graphene oxide (GO) nanosheets functionalized long period grating (LPG) for ultrasensitive hemoglobin sensing. The sensing mechanism relies on the measurement of LPG resonant intensity change induced by the adsorption of hemoglobin molecules onto GO, where GO as a bio-interface linkage provides the significant light-matter interaction between evanescent field and target molecules. The deposition technique based on chemical-bonding associated with physical-adsorption was developed to immobilize GO nanosheets on cylindrical fiber device. The surface morphology was characterized by scanning electron microscope, atomic force microscopy, and Raman spectroscopy. With relatively thicker GO coating, the refractive index (RI) sensitivity of GO-LPG was extremely enhanced and achieved −76.5 dB/RIU, −234.2 dB/RIU and +1580.5 dB/RIU for RI region of 1.33–1.38, 1.40–1.44 and 1.45–1.46, respectively. The GO-LPG was subsequently implemented as an optical biosensor to detect human hemoglobin giving a sensitivity of 1.9 dB/(mg/mL) and a detectable concentration of 0.05 mg/mL, which was far below the hemoglobin threshold value for anemia defined by World Health Organization. The proposed GO-LPG architecture can be further developed as an optical biosensing platform for anemia diagnostics and biomedical applications.",health
10.1016/j.saa.2018.01.067,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2018-05-05,sciencedirect,Simultaneous determination of Magnolol and Honokiol by amino acid ionic liquid synchronous fluorescence spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85041798656,"A novel method based on amino acid ionic liquids (AAILs) as an additive synchronous fluorescence spectrometry is proposed for simultaneous determination of magnolol (MN) and honokiol (HN) in traditional Chinese medicine Houpu. The overlapping fluorescence spectrum of MN and HN could be completely separated in the AAILs medium. Experiment parameters (the type and concentration of AAILs, pH values and temperature) were discussed. The detection limits of MN and HN reached 1.46ng/mL, 0.92ng/mL and the recovery rates ranged from 98.6%–100.7%, 99.7%–100.6%, respectively. This methods was successfully employed for simultaneously determination of MN and HN in real samples. No significant differences could be found in the results of this method and the pharmacopoeia of People's Republic of China 2015 (Ch.P.2015). The experiment mechanisms were discussed by the Gaussian simulation and fluorescence quantum yield.",health
10.1016/j.vetimm.2018.03.007,Journal,Veterinary Immunology and Immunopathology,scopus,2018-05-01,sciencedirect,Dynamic distribution of formalin-inactivated Edwardsiella tarda in olive flounder (Paralichthys olivaceus) post intramuscular injection,https://api.elsevier.com/content/abstract/scopus_id/85044580042,"Intramuscular (i.m.) injection is one of the common delivery methods of vaccination in aquaculture, which could induce an ideal immune protection to fish. In the present study, the olive flounders (Paralichthys olivaceus) were injected intramuscularly with 200 μl of three concentrations of formalin-inactivated Edwardsiella tarda bacterin (107, 108, 109 CFU ml−1) to investigate the transportation and dynamic distribution of antigen uptake in tissues by absolute real-time quantitative PCR (qPCR). The amount of uptaken antigen increased firstly, and then decreased. The peak occurred first in the blood at 6–9 h after i.m. injection, and in the spleen and head kidney at 9–15 h, then in the liver, gill and muscle at 15–24 h, finally in the skin and intestine at 36 h. The amount of uptaken antigen was highest in the head kidney, followed by in the spleen, blood, gill, and liver, and lowest in the muscle, skin and intestine. Among the three dose groups, the amount of uptaken antigen in all tested tissues became higher with the increasing dose of injected bacterin. Moreover, the tissue distribution of antigen uptake was investigated by indirect immunofluorescence assay (IIFA) at 15 h after i.m. injection with 200 μl of 108 CFU ml−1 
                     E. tarda bacterin. The distribution of antigen was mainly observed in the head kidney, then in the spleen, blood, liver, gill and muscle, and least in the skin and intestine, which correlated with the results of absolute qPCR detection. Furthermore, the expression levels of MHC Iα, MHC IIα, CD4-1 and CD8α were detected by RT-qPCR. The expression of these four genes peaked highest in the head kidney, followed by in the spleen, liver, blood and gill, and lowest in the muscle, skin and intestine, and the levels increased in parallel with the increasing dose of injected vaccine. All these results provided an important insight into the dynamic transportation of antigen uptake, and also deepened the understanding of immune response to the i.m. injection.",health
10.1016/j.cmpb.2018.02.011,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-05-01,sciencedirect,Hard exudates segmentation based on learned initial seeds and iterative graph cut,https://api.elsevier.com/content/abstract/scopus_id/85042421420,"(Background and Objective): The occurrence of hard exudates is one of the early signs of diabetic retinopathy which is one of the leading causes of the blindness. Many patients with diabetic retinopathy lose their vision because of the late detection of the disease. Thus, this paper is to propose a novel method of hard exudates segmentation in retinal images in an automatic way.
                  (Methods): The existing methods are based on either supervised or unsupervised learning techniques. In addition, the learned segmentation models may often cause miss-detection and/or fault-detection of hard exudates, due to the lack of rich characteristics, the intra-variations, and the similarity with other components in the retinal image. Thus, in this paper, the supervised learning based on the multilayer perceptron (MLP) is only used to identify initial seeds with high confidences to be hard exudates. Then, the segmentation is finalized by unsupervised learning based on the iterative graph cut (GC) using clusters of initial seeds. Also, in order to reduce color intra-variations of hard exudates in different retinal images, the color transfer (CT) is applied to normalize their color information, in the pre-processing step.
                  (Results): The experiments and comparisons with the other existing methods are based on the two well-known datasets, e_ophtha EX and DIARETDB1. It can be seen that the proposed method outperforms the other existing methods in the literature, with the sensitivity in the pixel-level of 0.891 for the DIARETDB1 dataset and 0.564 for the e_ophtha EX dataset. The cross datasets validation where the training process is performed on one dataset and the testing process is performed on another dataset is also evaluated in this paper, in order to illustrate the robustness of the proposed method.
                  (Conclusions): This newly proposed method integrates the supervised learning and unsupervised learning based techniques. It achieves the improved performance, when compared with the existing methods in the literature. The robustness of the proposed method for the scenario of cross datasets could enhance its practical usage. That is, the trained model could be more practical for unseen data in the real-world situation, especially when the capturing environments of training and testing images are not the same.",health
10.1016/j.measurement.2018.02.021,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-05-01,sciencedirect,Development of OCR system on android platforms to aid reading with a refreshable braille display in real time,https://api.elsevier.com/content/abstract/scopus_id/85042330092,"Individuals with visual impairment are limited in terms of communication, interaction and personal autonomy due to the lack of literature in Braille which is mainly attributable to economic reasons. This paper proposes a reading system for visually impaired persons using a portable device. This work proposes and evaluates a combination of segmentation, feature extraction and machine learning techniques to achieve the best conversion of text to braille as quickly and accurately as possible. The experiments showed that the Central Moments extractor with Multi Layer Perceptron were the best combination for the OCR system developed with 99.86% accuracy and 99.93% specificity. Furthermore, we assess the portable device usability with elementary teachers and with teachers and students in an association of the blind. The results of this system can contribute to improved socialization between visually impaired persons and stimulate their intellectual health.",health
10.1016/j.jneumeth.2017.07.020,Journal,Journal of Neuroscience Methods,scopus,2018-04-15,sciencedirect,Automated face recognition of rhesus macaques,https://api.elsevier.com/content/abstract/scopus_id/85026478684,"Background
                  Rhesus macaques are widely used in biomedical research. Automated behavior monitoring can be useful in various fields (including neuroscience), as well as having applications to animal welfare but current technology lags behind that developed for other species. One difficulty facing developers is the reliable identification of individual macaques within a group especially as pair- and group-housing of macaques becomes standard. Current published methods require either implantation or wearing of a tracking device.
               
                  New method
                  I present face recognition, in combination with face detection, as a method to non-invasively identify individual rhesus macaques in videos. The face recognition method utilizes local-binary patterns in combination with a local discriminant classification algorithm.
               
                  Results
                  A classification accuracy of between 90 and 96% was achieved for four different groups. Group size, number of training images and challenging image conditions such as high contrast all had an impact on classification accuracy. I demonstrate that these methods can be applied in real time using standard affordable hardware and a potential application to studies of social structure.
               
                  Comparison with existing method(s)
                  Face recognition methods have been reported for humans and other primate species such as chimpanzees but not rhesus macaques. The classification accuracy with this method is comparable to that for chimpanzees. Face recognition has the advantage over other methods for identifying rhesus macaques such as tags and collars of being non-invasive.
               
                  Conclusions
                  This is the first reported method for face recognition of rhesus macaques, has high classification accuracy and can be implemented in real time.",health
10.1016/j.jclepro.2018.01.104,Journal,Journal of Cleaner Production,scopus,2018-04-10,sciencedirect,Removal of ammonium from groundwater using NaOH-treated activated carbon derived from corncob wastes: Batch and column experiments,https://api.elsevier.com/content/abstract/scopus_id/85042064411,"High ammonium concentration in groundwater represents a major public health concern in Hanoi, Vietnam. In this study, mesoporous activated carbon was prepared from corncob using H3PO4 through a one-stage chemical activation process. Corncob activated carbon (CCAC) was subsequently treated with NaOH to enhance its cation exchange capacity. The results showed that this NaOH-modified corncob activated carbon (M-CCAC) exhibited a large specific surface area (1097 m2/g) and high total pore and mesopore volumes (0.804 cm3/g and 0.589 cm3/g, respectively). The batch experiments indicated that the NH4
                     +-N removal was strongly dependent on the coexisting cations and pH of the solution, while in the kinetic experiments adsorption equilibrium was quickly reached within 60 min. The activation energy was calculated to be 49.7 kJ/mol. The maximum Langmuir adsorption capacity of M-CCAC exhibited the following order: 17.03 mg/g at 20 °C > 15.4 mg/g at 35 °C > 11.99 mg/g at 50 °C. The NH4
                     + adsorption process was spontaneous (–ΔG°) and exothermic (–ΔH°), and it increased the randomness (+ΔS°) in the system. The column experiments were conducted using real underground water to analyze the effects of different flow rates (1–3 mL/min), influent concentrations (10–40 mg/L), and bed heights (8.07–23.9 cm) on the adsorption capacity. The maximum adsorption capacity (8.69 mg/g) was achieved at a flow rate of 2 mL/min, an initial concentration of 40 mg/L, and a column height of 15.8 cm. Ion exchange was found to be the principal mechanism that controls ammonium adsorption, while pore-filling and electrostatic attraction played minor roles in the process. This study proved that M-CCAC is an effective adsorbent to remove ammonium from real groundwater.",health
10.1016/j.artmed.2018.02.004,Journal,Artificial Intelligence in Medicine,scopus,2018-04-01,sciencedirect,Personalized prediction of drug efficacy for diabetes treatment via patient-level sequential modeling with neural networks,https://api.elsevier.com/content/abstract/scopus_id/85042348967,"Patients with type 2 diabetes mellitus are generally under continuous long-term medical treatment based on anti-diabetic drugs to achieve the desired glucose level. Thus, each patient is associated with a sequence of multiple records for prescriptions and their efficacies. Sequential dependencies are embedded in these records as personal factors so that previous records affect the efficacy of the current prescription for each patient. In this study, we present a patient-level sequential modeling approach utilizing the sequential dependencies to render a personalized prediction of the prescription efficacy. The prediction models are implemented using recurrent neural networks that use the sequence of all the previous records as inputs to predict the prescription efficacy at the time the current prescription is provided for each patient. Through this approach, each patient's historical records are effectively incorporated into the prediction. The experimental results of both the regression and classification analyses on real-world data demonstrate improved prediction accuracy, particularly for those patients having multiple previous records.",health
10.1016/j.measurement.2018.01.022,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-04-01,sciencedirect,A machine learning model for improving healthcare services on cloud computing environment,https://api.elsevier.com/content/abstract/scopus_id/85041465388,"Recently, cloud computing gained an important role in healthcare services (HCS) due to its ability to improve the HCS performance. However, the optimal selection of virtual machines (VMs) to process a medical request represents a big challenge. Optimal selection of VMs performs a significant enhancement of the performance through reducing the execution time of medical requests (tasks) coming from stakeholders (patients, doctors, etc.) and maximizing utilization of cloud resources. For that, this paper proposes a new model for HCS based on cloud environment using Parallel Particle Swarm Optimization (PPSO) to optimize the VMs selection. In addition, a new model for chronic kidney disease (CKD) diagnosis and prediction is proposed to measure the performance of our VMs model. The prediction model of CKD is implemented using two consecutive techniques, which are linear regression (LR) and neural network (NN). LR is used to determine critical factors that influence on CKD. NN is used to predict of CKD. The results show that, the proposed model outperforms the state-of-the art models in total execution time the rate of 50%. In addition, the system efficiency regarding real-time data retrieval is greatly improved by 5.2%. In addition, the accuracy of hybrid intelligent model in predicting of CKD is 97.8%. The proposed model is superior to most of the referred models in the related works by 64%.",health
10.1016/j.cmpb.2018.01.015,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-04-01,sciencedirect,Automatic energy expenditure measurement for health science,https://api.elsevier.com/content/abstract/scopus_id/85041430221,"Background and objective
                  It is crucial to predict the human energy expenditure in any sports activity and health science application accurately to investigate the impact of the activity. However, measurement of the real energy expenditure is not a trivial task and involves complex steps. The objective of this work is to improve the performance of existing estimation models of energy expenditure by using machine learning algorithms and several data from different sensors and provide this estimation service in a cloud-based platform.
               
                  Methods
                  In this study, we used input data such as breathe rate, and hearth rate from three sensors. Inputs are received from a web form and sent to the web service which applies a regression model on Azure cloud platform. During the experiments, we assessed several machine learning models based on regression methods.
               
                  Results
                  Our experimental results showed that our novel model which applies Boosted Decision Tree Regression in conjunction with the median aggregation technique provides the best result among other five regression algorithms.
               
                  Conclusions
                  This cloud-based energy expenditure system which uses a web service showed that cloud computing technology is a great opportunity to develop estimation systems and the new model which applies Boosted Decision Tree Regression with the median aggregation provides remarkable results.",health
10.1016/j.cptl.2017.12.018,Journal,Currents in Pharmacy Teaching and Learning,scopus,2018-04-01,sciencedirect,Utilizing desirable difficulties for sterile compounding training in a skills-based laboratory course,https://api.elsevier.com/content/abstract/scopus_id/85040361754,"Background and purpose
                  Sterile compounding skills are essential components of a professional pharmacy curriculum. The theory of desirable difficulties has been used to facilitate deeper learning of material in other disciplines, but has not been described in pharmacy sterile compounding instruction. The purpose of this work was to evaluate whether challenges introduced in sterile compounding would act as desirable difficulties and result in greater student confidence in their sterile compounding competency.
               
                  Educational activity and setting
                  Students in the fourth semester of Pharmacy Skills and Applications, a laboratory-based skills course, were presented with challenges in sterile compounding and were asked to complete a questionnaire rating their confidence and describing their experience.
               
                  Findings
                  The majority (92.8%) of students reported that the activity increased their confidence in their sterile compounding skills. Students’ open-ended responses suggested that most of the knowledge gained was strategic in nature.
               
                  Discussion
                  The results of this activity met the instructors’ initial goals by positively impacting students’ confidence in their ability to overcome challenges with sterile products compounding. Course instructors may explore additional skills in which to introduce desirable difficulties in order to build student confidence.
               
                  Summary
                  Course instructors were pleased with the implementation and results of this desirable difficulties activity and plan to continue its use again in future semesters. Incorporating more real-world challenges throughout the skills-lab course may be beneficial to student learning and confidence. With thoughtful planning, faculty at other institutions can readily incorporate similar activities within their own courses.",health
10.1016/j.ins.2017.08.042,Journal,Information Sciences,scopus,2018-04-01,sciencedirect,Task aware hybrid DVFS for multi-core real-time systems using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85028388448,"There have been renewed interest in embedded battery powered devices due to their widespread applications in sectors such as automotive, industrial, and health care. In order to reduce energy consumption and enhance battery life, dynamic voltage and frequency scaling (DVFS) techniques have been applied to processors (one of the most energy consuming components). In order to keep pace with advancements in fabrication technologies, it is important to scale voltage and frequency intelligently; otherwise, DVFS techniques could result in a higher energy consumption. In our previous work, depending on the execution characteristics of real-time tasks, DVFS decisions were made using machine learning method in unicore processors. We also used learning-based approach to select the best real-time DVFS technique for the situation from a set of techniques and proposed a framework that integrates the selection of various scheduling policies and the optimization of existing real-time DVFS techniques in multi-core processors. In this paper, we describe the design of the framework to make an effective learning-based DVFS system, and demonstrate the utility of the generalized learning-based framework using experiments on multi-core real-time systems for both synthetic tasks and benchmark tasks from real applications. Our findings show that the framework is computationally lightweight and effective in reducing energy consumption.",health
10.1016/j.compmedimag.2017.04.004,Journal,Computerized Medical Imaging and Graphics,scopus,2018-04-01,sciencedirect,Virtual bacterium colony in 3D image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85018988519,"Several heuristic, biologically inspired strategies have been discovered in recent decades, including swarm intelligence algorithms. So far, their application to volumetric imaging data mining is, however, limited. This paper presents a new flexible swarm intelligence optimization technique for segmentation of various structures in three- or two-dimensional images. The agents of a self-organizing colony explore their host, use stigmergy to communicate themselves, and mark regions of interest leading to the object extraction. Detailed specification of the bacterium colony segmentation (BCS) technique in terms of both individual and social behaviour is described in this paper. The method is illustrated and evaluated using several experiments involving synthetic data, computed tomography studies, and ultrasonography images. The obtained results and observations are discussed in terms of parameter settings and potential application of the method in various segmentation tasks.",health
10.1016/j.jep.2017.12.010,Journal,Journal of Ethnopharmacology,scopus,2018-03-25,sciencedirect,Reishi mushroom Ganoderma lucidum Modulates IgA production and alpha-defensin expression in the rat small intestine,https://api.elsevier.com/content/abstract/scopus_id/85039454217,"Ethnopharmacological relevance
                  Immunoglobulin A (IgA) secretion and alpha-defensins play a role in the innate immune system to protect against infection. Ganoderma lucidum (W.Curt.: Fr.) P. Karst. (Reishi) is a well-known mushroom in traditional Chinese medicine. This study aimed to determine the effects of Reishi on IgA secretion from Peyer's patch (PP) cells and alpha-defensin-5 (RD-5) and RD-6 expression in the rat small intestine.
               
                  Materials and methods
                  The rats received an oral injection of 0.5–5mg/kg of Reishi powder (1mL/kg) by sonde. All animals were euthanized 24h after Reishi administration. We examined RD-5, RD-6, and Toll-like receptor (TLR) 4 mRNA levels in the jejunum, ileum, and in Peyer's patches (PP) through quantitative real-time PCR analysis. IgA secretion from PP was measured through enzyme-linked immunosorbent assay of the supernatant after primary culture.
               
                  Results
                  Reishi increased IgA secretion in the presence of lipopolysaccharide (LPS) and increased TLR4 mRNA levels, but had no effect on the viability of PP cells. Moreover, Reishi increased RD-5, RD-6, and TLR4 mRNA levels significantly in the ileum in a concentration-dependent manner.
               
                  Conclusions
                  Reishi can induce IgA secretion and increase the mRNA levels of RD-5 and RD-6 in the rat small intestine, through a TLR4-dependent pathway. The present results indicate that Reishi might reduce the risk of intestinal infection.",health
10.1016/j.neucom.2017.10.044,Journal,Neurocomputing,scopus,2018-03-15,sciencedirect,Mortality prediction for ICU patients combining just-in-time learning and extreme learning machine,https://api.elsevier.com/content/abstract/scopus_id/85032892910,"Mortality prediction for patients in intensive care unit (ICU) is necessary to prioritize resources as well as to help the medical staff to make decisions, and hence more accurate methods for identifying high risk patients are very important for improving clinical care. However, many existing approaches including some scoring systems now being used in the hospital are not good enough since they try to establish a global/average offline model, which may be unsuitable for a specific patient. Thus, a more robust and effective monitoring model adaptable to individual patients is needed. To establish a more personalized model, this study proposes a two-step framework, in which the first step is for clustering and while the second one is for mortality predication. A novel method combining just-in-time learning (JITL) and extreme learning machine (ELM), referred to JITL-ELM, is proposed for mortality prediction, which applies global optimization of variables and neighborhood of appropriate samples to build an accurate patient-specific model. In addition, a simplified JITL-ELM with less key physiological variables is developed. In the experiment, 4000 real clinical records of ICU patients are collected to validate the proposed algorithm, of which the AUC index is 0.8568, which is much better than the existing traditional global/average models, and furthermore the simplified JITL-ELM still performs well.",health
10.1016/j.cmpb.2017.12.018,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-03-01,sciencedirect,Passive magnetic-based localization for precise untethered medical instrument tracking,https://api.elsevier.com/content/abstract/scopus_id/85043295115,"Background and objective
                  Motion tracking and navigation systems are paramount for both safety and efficacy in a variety of surgical insertions, interventions and procedures. Among the state-of-art tracking technology, passive magnetic tracking using permanent magnets or passive magnetic sources for localization is an effective technology to provide untethered medical instrument tracking without cumbersome wires needed for signal or power transmission. Motivated by practical needs in two medical insertion procedures: Nasogastric intubation and Ventriculostomy, we propose a unified method based on passive magnetic-field localization, for enhanced efficacy and safety.
               
                  Methods
                  Traditional approaches to passive magnetic tracking involve solving the inverse localization problem. Limited by the idealistic magnetic field dipole model and computationally intense nonlinear optimization algorithm, the overall accuracy and computational cost are greatly compromised. The method introduced here features direct localization with artificial neural network (ANN) models that bypasses the need to resolve the inverse problem and is adaptable for a variety of real-time localization and tracking applications.
               
                  Results
                  The efficiency of the two methods, the inverse optimization method and the direct ANN method are experimentally evaluated by comparing the estimated position of reference trajectories for typical nasogastric and ventriculostomy insertion paths performed by a dexterous robotic arm which provides ground truth measurement. It was found that within the region of interest (ROI), the direct ANN technique could significantly improve the localization accuracy, with an average experimental localization error of less than 2 mm, while that of the traditional inverse optimization method using a dipole-based mathematical model at greater than 5 mm. Ex-vivo experiments were performed to validate the localization methods in clinical settings.
               
                  Conclusions
                  While the proposed method for passive magnetic tracking requires a procedure-specific pre-procedural calibration, it is able to provide real-time tracking with high accuracy, robustness and diversity. It could be the missing piece to the puzzle to bring passive magnetic tracking technology into practice, therefore leading to untethered medical instrument tracking.",health
10.1016/j.cmpb.2017.12.001,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-03-01,sciencedirect,A novel fuzzy rough selection of non-linearly extracted features for schizophrenia diagnosis using fMRI,https://api.elsevier.com/content/abstract/scopus_id/85038381014,"Background and objectives
                  Schizophrenia is a severe brain disorder primarily diagnosed through externally observed behavioural symptoms due to the dearth of established clinical tests. Functional magnetic resonance imaging (fMRI) can capture the distortions caused by schizophrenia in the brain activation. Hence, it can be useful for developing a decision model that performs computer-aided diagnosis of schizophrenia. But, fMRI data is huge in dimension. Therefore dimension reduction is indispensable. It is additionally required to identify the discriminative brain regions. Hence, we aim to build an effective decision model that incorporates suitable dimension reduction and also identifies discriminative brain regions.
               
                  Methods
                  We propose a three-phase dimension reduction. First phase involves spatially-constrained fuzzy clustering of 3-dimensional spatial maps (obtained from general linear model and independent component analysis). In the second phase, non-linear features are extracted from each cluster using a generalized discriminant analysis. In the third phase, a novel fuzzy rough feature selection is proposed. The features obtained after the third phase are used for learning a decision model by the help of support vector machine classifier. This complete method is implemented within leave-one-out cross-validation on two balanced datasets (respectively acquired on 1.5Tesla and 3Tesla scanners). Both these datasets are created using Function Biomedical Informatics Research Network multisite data and contain fMRI data acquired during auditory oddball task performed by age-matched schizophrenia patients and healthy subjects. A permutation test is also carried out to ensure that no bias is involved in the learning.
               
                  Results
                  The results indicate that the proposed method achieves maximum classification accuracy of 97.1% and 98.0% for the two datasets respectively. The proposed method outperforms the state-of-the-art methods. The results of the permutation test show that p-values are lesser than the significance level i.e. 0.05. Therefore, the classifier has found a significant class structure and does not involve any bias. Further, discriminative brain regions are identified and are in agreement with the findings in related literature.
               
                  Conclusion
                  The proposed method is able to derive suitable non-linear features and the related brain regions for effective computer-aided diagnosis. The fuzzy and rough set based approaches help in handling uncertainty and ambiguity in real data.",health
10.1016/j.jocs.2017.02.009,Journal,Journal of Computational Science,scopus,2018-03-01,sciencedirect,Identification of Gliomas from brain MRI through adaptive segmentation and run length of centralized patterns,https://api.elsevier.com/content/abstract/scopus_id/85016767596,"Brain tumor detection and identification of its severity is a challenging task for radiologists and clinicians. This work aims to develop a novel clinical decision support system to assist radiologists and clinicians efficiently in real-time. The proposed clinical decision support system utilizes fusion of MRI pulse sequences as each of them gives salient information for tumor identification. An adaptive thresholding is proposed for segmentation and centralized patterns are observed from LBP image of so obtained segmented image. Run length matrix extracted from these centralized patterns is used for tumor identification. The developed features successfully identify and classify tumor with Naive Bayes classifier. The proposed decision support system not only detects tumors, but also identifies its grading in terms of severity. As Glioma tumors are the most frequent among brain tumors, the proposed system is tested for the presence of low grade (Astrocytoma and Ependymoma) as well as high grade (Oligodendroglioma and Glioblastoma Multiforme) Glioma tumors on images collected from NSCB Medical College Jabalpur, India and BRATS dataset. The experiments performed on two datasets give more than 96% accuracy. The proposed decision support system is quite sensitive towards the detection and specification of tumors. All the results are verified by domain experts in real time.",health
10.1016/j.jneumeth.2017.12.014,Journal,Journal of Neuroscience Methods,scopus,2018-02-15,sciencedirect,Extracting information from the shape and spatial distribution of evoked potentials,https://api.elsevier.com/content/abstract/scopus_id/85039751518,"Background
                  Over 90 years after its first recording, scalp electroencephalography (EEG) remains one of the most widely used techniques in human neuroscience research, in particular for the study of event-related potentials (ERPs). However, because of its low signal-to-noise ratio, extracting useful information from these signals continues to be a hard-technical challenge. Many studies focus on simple properties of the ERPs such as peaks, latencies, and slopes of signal deflections.
               
                  New method
                  To overcome these limitations, we developed the Wavelet-Information method which uses wavelet decomposition, information theory, and a quantification based on single-trial decoding performance to extract information from evoked responses.
               
                  Results
                  Using simulations and real data from four experiments, we show that the proposed approach outperforms standard supervised analyses based on peak amplitude estimation. Moreover, the method can extract information using the raw data from all recorded channels using no a priori knowledge or pre-processing steps.
               
                  Comparison with existing method(s)
                  We show that traditional approaches often disregard important features of the signal such as the shape of EEG waveforms. Also, other approaches often require some form of a priori knowledge for feature selection and lead to problems of multiple comparisons.
               
                  Conclusions
                  This approach offers a new and complementary framework to design experiments that go beyond the traditional analyses of ERPs. Potentially, it allows a wide usage beyond basic research; such as for clinical diagnosis, brain-machine interfaces, and neurofeedback applications requiring single-trial analyses.",health
10.1016/j.jep.2017.10.017,Journal,Journal of Ethnopharmacology,scopus,2018-02-15,sciencedirect,Effects of Danhong Injection on platelet aggregation in hyperlipidemia rats,https://api.elsevier.com/content/abstract/scopus_id/85032172151,"Ethnopharmacological relevance
                  Danhong Injection (DHI), a Chinese medical product extracted from Radix et Rhizoma Salviae Miltiorrhizae (Salvia miltiorrhiza Bge., Labiatae, Danshen in Chinese) and Flos Carthami (Carthamus tinctorius L., Compositae, Honghua in Chinese), has been reported to have effects on inflammatory, anti-fibrinolytic properties, antithrombotic and decrease blood-lipid. It is extensively used for the clinical treatment of cardiovascular disease. This study aimed to investigate the effects of DHI on blood-lipid levels and platelet aggregation rate in hyperlipidemia rats.
               
                  Materials and methods
                  Rats were randomly divided into 6 groups: normal control (NC), model control (MC), DHI-treated control at doses of 1.0mL/kg, 2.0mL/kg, 4.0mL/kg, respectively, and Simvastatin positive control at dose of 2.0mg/kg. All DHI treated groups were intraperitoneally injected for 7 days. The effects of DHI on serum triglyceride (TG), total cholesterol (TC), low density lipoprotein cholesterol (LDL-C) and high density lipoprotein cholesterol (HDL-C) were evaluated. And platelet activating factor (PAF), platelet membrane glycoprotein IIb/IIIa (GP IIb/IIIa) and 6-keto-prostaglandin F1а (6-K-PGF1а) were determined by enzyme-linked immunosorbent assay (ELISA). Moreover, the expression of prostaglandin I-2 (PGI2), prostaglandin E-2 (PGE2) and thromboxane A2 (TXA2) in liver was determined by real-time PCR.
               
                  Results
                  Compared with the MC group, the rats treated with DHI had significantly reduced TC, TG, LDL-C, FIB, GP IIb/IIIa and platelet aggregation. Meanwhile, the thrombin time (TT), activated partial thrombin time (APTT), prothrombin time (PT), 6-K-PGF1а was significantly increased. Expression of PGI2 and PGE2 mRNA was significantly increased, whereas the TXA2 was significantly reduced.
               
                  Conclusions
                  This study demonstrated that the blood lipid and platelet aggregation has a regulatory effect after DHI treatment. The insights gained from this study will improve understanding of the mechanisms involved in the effect of DHI on hyperlipidemia and the pharmacological rationale for the use of DHI in diseases caused by formation of thrombosis and lipid metabolic disorders.",health
10.1016/j.bja.2017.11.077,Journal,British Journal of Anaesthesia,scopus,2018-02-01,sciencedirect,Could patient-controlled thirst-driven fluid administration lead to more rapid rehydration than clinician-directed fluid management? An early feasibility study,https://api.elsevier.com/content/abstract/scopus_id/85056484648,"Background
                  Fluid management is a major factor determining perioperative outcome, yet in reality, fluid administration practice is variable. Thirst however, is a highly sensitive and reliable indicator of fluid deficits. We explored the use of thirst sensation to trigger i.v. fluid boluses to guide individualized fluid management.
               
                  Methods
                  We performed a randomised double crossover trial on 16 healthy male volunteers, of mean age 31 yr and BMI 24.4 kg m−2. Twice, after administrations of oral furosemide (40 mg) and 12 h of oral fluid restriction, participants received a 4-h i.v. fluid infusion. In the experimental arm, participants pressed a trigger to relieve their thirst, administering a 200 ml bolus. In the control arm, i.v. fluid was infused following National Institute for Health and Clinical Excellence (NICE) guidelines at 1.25 ml kg−1 h−1 with a clinician delivered 500 ml i.v. bolus in response to clinical signs of dehydration. Plasma osmolality and urine specific gravity were measured before and after each infusion.
               
                  Results
                  More fluid was infused in response to thirst than by adherence to NICE guidelines, with a mean difference of 743 ml (P=0.0005). Thirst-driven fluid administration was fitted to an exponential function of time, plateauing after a mean half-life of 98.8 min. In the experimental arm there was a greater reduction in urine specific gravity and thirst score with mean differences 0.0053 g cm−3 (P=0.002) and 3.3 (P=0.003), respectively. Plasma osmolality demonstrated no fluid overload.
               
                  Conclusions
                  A system delivering i.v. fluid in response to subjective thirst corrects fluid deficits in healthy participants. A clinical feasibility study will assess the potential use of this system in the perioperative setting.
               
                  Clinical trial registration
                  NCT 03176043.",health
10.1016/j.mimet.2017.12.007,Journal,Journal of Microbiological Methods,scopus,2018-02-01,sciencedirect,Verification and large scale clinical evaluation of a national standard protocol for Salmonella spp./Shigella spp. screening using real-time PCR combined with guided culture,https://api.elsevier.com/content/abstract/scopus_id/85038259034,"Salmonella spp./Shigella spp. are often associated with food poisoning and fecal-oral transmission of acute gastroenteritis that requires strict monitoring, especially among people who would handle food and water. In 2014, the National Health and Family Planning Commission of the P. R. China issued a national standard protocol (recommendatory) for the screening of Salmonella spp./Shigella spp.. However, its performance has not been fully studied. Whether it was suitable for use in our laboratory was still unknown. In the current study, the new protocol was first verified by various experiments and then its clinical performance was evaluated in about 20,000 stool samples over a three-year period. Verification results showed that the new protocol was highly specific and reproducible. Sensitivity (as defined as the lower limit of detection) of the new protocol at the PCR step was 103
                     CFU/mL and 101
                     CFU/mL for Salmonella spp. and Shigella spp., while that at the guided culture step was 104
                     CFU/mL and 103
                     CFU/mL, respectively. The large scale clinical evaluation indicated that the new protocol could increase the positivity rate by two fold and decrease the workload/median turnaround time significantly. In conclusion, the protocol was verified and evaluated and was proven to be a valuable platform for the rapid, specific, sensitive and high-throughput screening of Salmonella spp./Shigella spp.",health
10.1016/j.media.2017.12.003,Journal,Medical Image Analysis,scopus,2018-02-01,sciencedirect,Multi-hypothesis tracking of the tongue surface in ultrasound video recordings of normal and impaired speech,https://api.elsevier.com/content/abstract/scopus_id/85037537839,"Characterizing tongue shape and motion, as they appear in real-time ultrasound (US) images, is of interest to the study of healthy and impaired speech production. Quantitative anlaysis of tongue shape and motion requires that the tongue surface be extracted in each frame of US speech recordings. While the literature proposes several automated methods for this purpose, these either require large or very well matched training sets, or lack robustness in the presence of rapid tongue motion. This paper presents a new robust method for tongue tracking in US images that combines simple tongue shape and motion models derived from a small training data set with a highly flexible active contour (snake) representation and maintains multiple possible hypotheses as to the correct tongue contour via a particle filtering algorithm. The method was tested on a database of large free speech recordings from healthy and impaired speakers and its accuracy was measured against the manual segmentations obtained for every image in the database. The proposed method achieved mean sum of distances errors of 1.69 ± 1.10 mm, and its accuracy was not highly sensitive to training set composition. Furthermore, the proposed method showed improved accuracy, both in terms of mean sum of distances error and in terms of linguistically meaningful shape indices, compared to the three publicly available tongue tracking software packages Edgetrak, TongueTrack and Autotrace.",health
10.1016/j.asoc.2017.11.047,Journal,Applied Soft Computing Journal,scopus,2018-02-01,sciencedirect,Model forecasting based on two-stage feature selection procedure using orthogonal greedy algorithm,https://api.elsevier.com/content/abstract/scopus_id/85036620078,"Currently, forecasting and feature selection tasks are attracting considerable attention from various scientific fields including global solar radiation forecasting, signal processing, microarray data analysis, finance, medicine and others. However, both selection inconsistency and the intractable computational cost pose critical difficulties when implementing forecasting tasks. Although artificial neural networks (ANNs) are useful for forecasting, a large number of nuisance features are employed. To establish an interpretable forecasting model, feature selection techniques are combined with ANNs to reduce the number of inputs and the complexity of network structures. However, these approaches shrink the estimate, which results in inaccurate forecasting results. To overcome these drawbacks, this paper successfully investigates a novel soft computing approach referred to as a two-stage feature selection procedure using the orthogonal greedy algorithm (TSOGA) to select the important features as inputs of ANNs. A simple-to-implement and efficient computational algorithm is designed, and the theoretical analysis is also provided. Furthermore, the high dimensional Bayesian information criterion (HDBIC) is utilized to select the optimal forecasting model. Real data experiments directly demonstrate the outstanding forecasting performances of the proposed TSOGA approach compared with other state-of-the-art techniques.",health
10.1016/j.neucom.2017.07.048,Journal,Neurocomputing,scopus,2018-01-17,sciencedirect,Robust locally linear embedding algorithm for machinery fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85029764189,"Locally linear embedding (LLE) is a classical nonlinear dimensionality reduction algorithm, and it has been widely used in machinery fault diagnosis. LLE reduces the dimensions of a data set only by exploring the geometry structure, that is, the geometry structure is one of the key factors for the embedding result. In conventional LLE algorithm, the geometry structure is calculated by ordinary least square (OLS) algorithm, which makes the embedding result be sensitive to noise. In order to resolve the problem, a robust LLE (RLLE) is investigated. In RLLE algorithm, the Least Angle Regression and the Elastic Net (LARS-EN) technologies are employed to compute the local structure. Besides, a novel fault diagnosis method based on RLLE and support vector machine (SVM) are proposed for machinery fault diagnosis. Experiments performed on both synthetic and real data sets demonstrate the advantages of the proposed method in the term of fault diagnosis.",health
10.1016/j.chemolab.2017.12.005,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2018-01-15,sciencedirect,A new reconstruction-based auto-associative neural network for fault diagnosis in nonlinear systems,https://api.elsevier.com/content/abstract/scopus_id/85037701407,"Auto-associative neural network (AANN) is a typical nonlinear principal component analysis method, which is widely used in industry for fault diagnosis purposes, especially in nonlinear systems. However, the basic AANN often suffers from “smearing effects” problems that may lead to misdiagnosis, particularly with regards to the complex faults involving multiple variables. In this work, a new reconstruction-based AANN (RBAANN) method is proposed to enhance the capacity of fault diagnosis. In RBAANN, a generic derivative equation is developed to investigate the effects of AANN model inputs on the prediction error between model inputs and outputs. Based on the derivative equation, the reconstruction-based index for single or multiple variables, which is defined as the minimum prediction error, is obtained by tuning the corresponding model inputs iteratively. However, without the prior knowledge of the real faulty variables, all the possible variable sets need to be evaluated by the reconstruction-based index, and this may result in an exhaustive search and cause a huge computational burden. Thus, a branch and bound algorithm is introduced into RBAANN to solve the variable selection problem. Finally, an efficient fault diagnosis strategy by integrating RBAANN and branch and bound algorithm (BAB-RBAANN) is implemented to further pinpoint the source of the detected faults. This BAB-RBAANN method can handle both single and multiple variable(s) faults for nonlinear systems without prior knowledge efficiently. The effectiveness of the proposed methods is evaluated on a validation example and an industrial example. Comparisons with other methods, including principal component analysis techniques, are also presented.",health
10.1016/B978-0-12-813314-9.00011-6,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Unsupervised anomaly detection for high dimensional data-An exploratory analysis,https://api.elsevier.com/content/abstract/scopus_id/85081928867,"Context: Anomaly detection is a crucial area engaging the attention of many researchers. It is a process of finding an unusual point or pattern in a given dataset. It is useful in many real time applications such as industry damage detection, detection of fraudulent usage of credit card, detection of failures in sensor nodes, detection of abnormal health and network intrusion detection. Algorithms proposed for anomaly detection in low dimensional data are not suitable for high dimensional data due to the well-known “dimensionality curses”.
               
                  Motivation: To tackle this issue, a plethora of algorithms dedicated to high dimensional data has been proposed. However, unsupervised algorithms have many problems and challenges, as there is no predefined data label to predict anomaly.
               
                  Objective: We aim at providing a complete view of unsupervised anomaly detection for high dimensional data which gives a clear perception of the concept.
               
                  Contribution: In this paper, existing algorithms and real time applications of unsupervised anomaly detection for high dimensional data have been studied. Evaluation measures, datasets and tools used by different authors have been discussed in detail. In addition, a hybrid framework of unsupervised anomaly detection algorithm called DBN–K means applied two different disease dataset is also proposed.
               
                  Future work: As future work, the proposed framework could be implemented and analyzed in other applications. High dimensional streaming data is another interesting area for further investigation, following this research work.",health
10.1016/j.procir.2018.09.067,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,A Conceptual Design for Smell Based Augmented Reality: Case Study in Maintenance Diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85059916374,"The trend of Industry 4.0 encourages the next generation of manufacturing to be flexible, intelligent, and interoperable. The implementations of the Artificial Intelligence (AI) technology could potentially enhance maintenance in efficiency, and accuracy. However, it will not be a substitution to the human operator’s flexibility, decision-making and information received by the natural five senses. Augmented reality (AR) is commonly understood as a technology that overlays virtual information onto the existing environment to provide users a new and improved experience to assist their daily activities. However, AR can be used to enhance all human five senses rather than just overlay virtual imagery. In this paper, a design and a practical plan of smell augmentation for diagnosis is initialised, via a case study in maintenance. The aim of this paper is to evaluate the feasibilities, identify challenges, and summarise initial results of overlaying information through smell augmentations.",health
10.1016/j.procs.2018.11.080,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Intelligent data processing received from radio frequency identification system,https://api.elsevier.com/content/abstract/scopus_id/85059469763,"The present article is devoted to the issue of improvement of utilization efficiency of modern information technologies in order to enhance the quality and safety of healthcare delivery. The introduction of Real-time Locating Systems (RTLS), in particular Radio Frequency Identification System (RFID), applied in conjunction with intelligent data processing system can reduce the severity of the consequences of event risks implementation, as well as avoidance of a number of such consequences. The authors of the present article suggest using mathematical tools of fuzzy logic theory for event analysis in online mode and recommendation formation on their basis for timely management decision-taking.",health
10.1016/j.procs.2018.10.168,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Towards security on internet of things: Applications and challenges in technology,https://api.elsevier.com/content/abstract/scopus_id/85058281610,"The Internet of Things (IoT) paradigm refers to the network of physical objects or ""things"" embedded with electronics, software, sensors, and connectivity to enable objects to exchange data with servers, centralized systems, and/or other connected devices based on a variety of communication infrastructures. IoT data collected from different sensors, nodes and collectors are transferred to the cloud over the internet. IoT devices are used by consumers, healthcare, businesses as well as by the governments. It is being forecast that 31 billion IoT devices will be deployed all over the world by the year 2020. As the use of IoT devices is increasing every moment several IoT vulnerabilities are introduced. The results and analysis indicate that massive deployment of IoT with an integration of new technologies are introducing new security challenges in IoT paradigm. In this paper, IoT security challenges and open issues are discussed which provides a ground for future research.",health
10.1016/j.procs.2018.10.130,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Efficient enriching of synthesized relational patient data with time series data,https://api.elsevier.com/content/abstract/scopus_id/85058271520,"Analysing data from electronic healthcare records allows for supporting decision making and thereby can improve healthcare. However, obtaining sufficient healthcare data required for machine learning analysis is challenging due to, e.g, privacy aspects of medical data. For machine learning tasks, carefully prepared synthesized medical records can be as good as real records, which is shown in [17]. Existing tools for medical data provision generate either relational records or streams of measurements over time, but not an appropiate combination of both. In this paper, we contribute an approach to enriching synthesized relational data with time series (longitudinal data) of real patients. We use Synthea to synthesize relational data and enrich the records with time series from the anonymized MIMIC III database. In our data integration scenario, we need to find the best match from the relational data to the time series data to obtain a sufficient amount of medical data for machine learning analyses. Our experiments show that we can enrich huge amounts of relational data with real time series data. However, without any processing optimizations, the runtime does not easily scale with the number of synthesized relational records. With several optimizations and using a distributed execution engine, such as Apache Spark SQL, we can efficiently enrich synthesized relational data with time series data.",health
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",health
10.1016/j.bbe.2018.06.005,Journal,Biocybernetics and Biomedical Engineering,scopus,2018-01-01,sciencedirect,Continuous blood glucose level prediction of Type 1 Diabetes based on Artificial Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85052992188,"Recent technological advancements in diabetes technologies, such as Continuous Glucose Monitoring (CGM) systems, provide reliable sources to blood glucose data. Following its development, a new challenging area in the field of artificial intelligence has been opened and an accurate prediction method of blood glucose levels has been targeted by scientific researchers. This article proposes a new method based on Artificial Neural Networks (ANN) for blood glucose level prediction of Type 1 Diabetes (T1D) using only CGM data as inputs. To show the efficiency of our method and to validate our ANN, real CGM data of 13 patients were investigated. The accuracy of the strategy is discussed based on some statistical criteria such as the Root Mean Square Error (RMSE) and the Mean Absolute Percentage Error (MAPE). The obtained averages of RMSE are 6.43 mg/dL, 7.45 mg/dL, 8.13 mg/dL and 9.03 mg/dL for Prediction Horizon (PH) respectively 15 min, 30 min, 45 min and 60 min and the average of MAPE was 3.87% for PH = 15 min, knowing that the smaller is the RMSE and MAPE, the more accurate is the prediction. Experimental results show that the proposed ANN is accurate, adaptive, and very encouraging for a clinical implementation. Furthermore, while other studies have only focused on the prediction accuracy of blood glucose, this work aims to improve the quality of life of T1D patients by using only CGM data as inputs and by limiting human intervention.",health
10.1016/j.bbe.2018.08.002,Journal,Biocybernetics and Biomedical Engineering,scopus,2018-01-01,sciencedirect,Fast statistical model-based classification of epileptic EEG signals,https://api.elsevier.com/content/abstract/scopus_id/85052519495,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4s, performing similarly to the best approaches from the literature.",health
10.1016/j.procs.2018.04.060,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Real-time Driver Drowsiness Detection for Android Application Using Deep Neural Networks Techniques,https://api.elsevier.com/content/abstract/scopus_id/85051265901,"Road crashes and related forms of accidents are a common cause of injury and death among the human population. According to 2015 data from the World Health Organization, road traffic injuries resulted in approximately 1.25 million deaths worldwide, i.e. approximately every 25 seconds an individual will experience a fatal crash. While the cost of traffic accidents in Europe is estimated at around 160 billion Euros, driver drowsiness accounts for approximately 100,000 accidents per year in the United States alone as reported by The American National Highway Traffic Safety Administration (NHTSA). In this paper, a novel approach towards real-time drowsiness detection is proposed. This approach is based on a deep learning method that can be implemented on Android applications with high accuracy. The main contribution of this work is the compression of heavy baseline model to a lightweight model. Moreover, minimal network structure is designed based on facial landmark key point detection to recognize whether the driver is drowsy. The proposed model is able to achieve an accuracy of more than 80%.",health
10.1016/j.procs.2018.04.110,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Fall detection system for elderly people using IoT and Big Data,https://api.elsevier.com/content/abstract/scopus_id/85051262294,"Falls represent a major public health risk worldwide for the elderly people. A fall not assisted in time can cause functional impairment in an elder and a significant decrease in his mobility, independence and life quality. In that sense, the present work proposes an innovative IoT-based system for detecting falls of elderly people in indoor environments, which takes advantages of low-power wireless sensor networks, smart devices, big data and cloud computing. For this purpose, a 3D-axis accelerometer embedded into a 6LowPAN device wearable is used, which is responsible for collecting data from movements of elderly people in real-time. To provide high efficiency in fall detection, the sensor readings are processed and analyzed using a decision trees-based Big Data model running on a Smart IoT Gateway. If a fall is detected, an alert is activated and the system reacts automatically by sending notifications to the groups responsible for the care of the elderly people. Finally, the system provides services built on cloud. From medical perspective, there is a storage service that enables healthcare professional to access to falls data for perform further analysis. On the other hand, the system provides a service leveraging this data to create a new machine learning model each time a fall is detected. The results of experiments have shown high success rates in fall detection in terms of accuracy, precision and gain.",health
10.1016/B978-0-444-64241-7.50368-2,Book Series,Computer Aided Chemical Engineering,scopus,2018-01-01,sciencedirect,States Identification of Complex Chemical Process Based on Unsupervised Learning,https://api.elsevier.com/content/abstract/scopus_id/85050586579,"States identification is an important step of process safety management, and it can be an individual part or a precursor step of fault detection and diagnosis (FDD). Research on FDD have made good progress, but most of them are carried out on labelled data, which is hard to collect in real situation. In this paper, an unsupervised learning based state identification model is proposed to deal with unlabelled data.
                  Feature extraction or dimensionality reduction, and clustering are two main steps of the model. t-SNE is an outstanding tool to visualize high-dimensional data, and a deep auto-encoder network is used to reduce the dimensionality to a reasonable amount before t-SNE is implemented. Different clustering algorithm are tested on features to determine which one is better. The unlabeled data are divided into different clusters by this model. In the final part of this paper, the benchmarked Tennessee Eastman process is utilized to illustrate the performance of this unsupervised learning based model.",health
10.1016/j.procs.2018.05.047,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Analysis of Fuzzification Process in Fuzzy Expert System,https://api.elsevier.com/content/abstract/scopus_id/85049088318,"The fuzzy expert systems are oriented towards handling uncertain or imprecise information. The fuzzy expert system is used in the domains where the input variables do not have fixed values. The success of fuzzy system depends upon the selection of appropriate membership function. The paper presents the analysis of fuzzification process of Fuzzy expert systems implemented in the domains of health care, education, career selection, real estate and finance. The parameters used for analyzing the systems are the input factors, type of membership function used for fuzzification, de-fuzzification of fuzzy sets generated. Based on analysis of the fuzzy expert system, the paper presents recommendations for selecting appropriate membership function. At the end paper presents guidelines for fuzzification process which can be useful in creating Fuzzy Expert System.",health
10.1016/j.procs.2018.05.005,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,An Innovative Approach for Investigation and Diagnosis of Lung Cancer by Utilizing Average Information Parameters,https://api.elsevier.com/content/abstract/scopus_id/85049073855,"In this paper, an Average Information based approach for lung cancer analysis and diagnosis has been proposed. Suggested methodology is established on average information parameters by utilizing image processing tools for lung cancer investigation. The real issue for the lung cancer diagnosis is the time constrictions for physical diagnosis that expands the death possibilities. Henceforth essentially proposed technique is an approach that would help the medical practitioners for precise and superior decision against the lung cancer discovery. Microscopic lung images are taken for analysis and investigation by using digital image processing with MATLAB. The statistical and mathematical parameters under statistical analysis are selected on the basis of the principle working of Average information technique. The input parameters like Entropy, Standard Deviation, Mean, Variance and MSE for average information method are implemented over a large microscopic lung image database. The individual statistical and mathematical parameter analysis with its impact on lung cancer images is successfully carried out and finally the accuracy, selectivity, and sensitivity of the proposed method is calculated by implementing the standard diagnostic test on the proposed method. This method also successfully rejects null hypothesis test by implementing one of the standard statistical methods.",health
10.1016/j.bbe.2018.01.003,Journal,Biocybernetics and Biomedical Engineering,scopus,2018-01-01,sciencedirect,A segment-wise reconstruction method based on bidirectional long short term memory for Power Line Interference suppression,https://api.elsevier.com/content/abstract/scopus_id/85042414724,"The overlap between the signal components of Power Line Interference (PLI) and biomedical signals in the frequency domain makes the filtered results prone to severe distortion. Electrocardiogram (ECG) is a type of biomedical electronic signal used for cardiac diagnosis. The objective of this work is to suppress the PLI components from biomedical signals with minimal distortion, and the object of study is mainly the ECG signals. In this study, we propose a novel segment-wise reconstruction method to suppress the PLI in biomedical signals based on the Bidirectional Recurrent Neural Networks with Long Short Term Memory (Bi-LSTM). Experiments are conducted on both synthetic and real signals, and quantitative comparisons are made with a traditional IIR notch filter and two state-of-the-art methods in the literature. The results show that by our method, the output Signal-to-Noise Ratio (SNR) is improved by more than 7dB and the settling time for step response is reduced to 0.09s on average. The results also demonstrate that our method has enough generalization ability for unforeseen signals without retraining.",health
10.1016/j.ijantimicag.2017.09.001,Journal,International Journal of Antimicrobial Agents,scopus,2018-01-01,sciencedirect,Antiviral activity of arbidol hydrochloride against herpes simplex virus I in vitro and in vivo,https://api.elsevier.com/content/abstract/scopus_id/85039949277,"Herpes simplex virus type 1 (HSV-1) causes significant human diseases ranging from skin lesions to encephalitis, especially in neonates and immunocompromised hosts. The discovery of novel anti-HSV-1 drugs with low toxicity is required for public health. Arbidol hydrochloride (ARB) is an indole derivative molecule with broad-spectrum antiviral activity. In this study, the antiviral effects of ARB against HSV-1 infection were evaluated in vitro and in vivo. The results showed that ARB presents significant inhibitory effect on HSV-1 plaque formation and generation of progeny virus, with EC50 values (50% effective concentration) of 5.39 µg/mL (10.49 µM) and 2.26 µg/mL (4.40 µM), respectively. Moreover, time-of-addition and time-of-removal assays further suggested that ARB has viral inhibitory effects when added up to 12 h post-infection (p.i.), which could be further corroborated by determining the expression of viral immediate-early (ICP4, ICP22 and ICP27), early (ICP8 and UL42) and late (gB, gD, gH, VP1/2 and VP16) genes by real-time quantitative PCR as well as the expression of viral protein ICP4 and ICP8 at 6 h and 12 h p.i. Results of the in vivo study showed that ARB could reduce guinea pig skin lesions caused by HSV-1 infection. Conclusively, this report offers new perspectives in the search for therapeutic measures in the treatment of HSV-1 infection.",health
10.1016/j.ebiom.2017.11.032,Journal,EBioMedicine,scopus,2018-01-01,sciencedirect,Epileptic Seizure Prediction Using Big Data and Deep Learning: Toward a Mobile System,https://api.elsevier.com/content/abstract/scopus_id/85037980011,"Background
                  Seizure prediction can increase independence and allow preventative treatment for patients with epilepsy. We present a proof-of-concept for a seizure prediction system that is accurate, fully automated, patient-specific, and tunable to an individual's needs.
               
                  Methods
                  Intracranial electroencephalography (iEEG) data of ten patients obtained from a seizure advisory system were analyzed as part of a pseudoprospective seizure prediction study. First, a deep learning classifier was trained to distinguish between preictal and interictal signals. Second, classifier performance was tested on held-out iEEG data from all patients and benchmarked against the performance of a random predictor. Third, the prediction system was tuned so sensitivity or time in warning could be prioritized by the patient. Finally, a demonstration of the feasibility of deployment of the prediction system onto an ultra-low power neuromorphic chip for autonomous operation on a wearable device is provided.
               
                  Results
                  The prediction system achieved mean sensitivity of 69% and mean time in warning of 27%, significantly surpassing an equivalent random predictor for all patients by 42%.
               
                  Conclusion
                  This study demonstrates that deep learning in combination with neuromorphic hardware can provide the basis for a wearable, real-time, always-on, patient-specific seizure warning system with low power consumption and reliable long-term performance.",health
10.1016/j.compag.2017.11.032,Journal,Computers and Electronics in Agriculture,scopus,2018-01-01,sciencedirect,Development of an early warning algorithm to detect sick broilers,https://api.elsevier.com/content/abstract/scopus_id/85036463864,"The frequent occurrence of poultry diseases, such as bird flu, not only causes huge economic losses to farmers but also seriously threatens the health of human beings. Providing early warnings of new poultry disease outbreaks is essential in poultry breeding. With the rise of digital image processing technology and machine learning algorithms, real-time monitoring of poultry health status through cameras is an effective way to prevent large-scale outbreaks of disease. To analyze the postures of healthy and sick broilers, bird flu virus was inoculated intranasally into healthy broilers manually. The broilers were then placed in isolator cages for comparative experiments. The methods of observing the posture changes of broilers and extracting the key features are used to realize the automatic classification of healthy and sick broilers. In this research, broiler images are obtained, and two kinds of segmentation algorithms are proposed to separate the broilers from the background to obtain the outlines and skeleton information of the broilers. According to the preset feature extraction algorithm, the posture features of healthy and sick chickens are extracted, the eigenvectors are established, the postures of the broilers are analyzed by machine learning algorithms, and the diseased broilers are predicted. A series of experiments have been done. Data for each feature acquired by the algorithms are analyzed, and the effect of each feature on the recognition accuracy is obtained. Using some of the features proposed in this research, accuracy rates of 84.248%, 60.531% and 91.504% are obtained, but using all the features can yield an accuracy rate of 99.469%. Then, the recognition effects of several commonly used machine learning algorithms are compared. The Support Vector Machine (SVM) model obtains an accuracy rate of 99.469% on the test samples, which is superior to those of the other machine learning algorithms. The experimental results show that the algorithms proposed in this research can effectively separate broilers from the background, extract the posture information of broilers, and accurately and quickly identify the health status of broilers by means of SVM. The algorithms for digital image processing and machine learning are evaluated in the diagnosis of broiler health status and show high accuracy, good stability and good generalization performance, and can give early warning signals. This research can provide a reference for the intelligent identification of broiler health status in the future.",health
10.1016/j.jviromet.2017.10.020,Journal,Journal of Virological Methods,scopus,2018-01-01,sciencedirect,An optimized double-antibody sandwich ELISA for quantitative detection of WSSV in artificially infected crayfish,https://api.elsevier.com/content/abstract/scopus_id/85032584676,"Developing a rapid, accurate and quantitative method for detecting white spot syndrome virus (WSSV) is extremely urgent and critical for reducing the risk of white spot disease outbreaks. In the present work, an optimized double-antibody sandwich enzyme-linked immunosorbent assay (DAS-ELISA) was developed for quantitative detection of WSSV. The method employed rabbit polyclonal antibodies against WSSV as the capture antibody and previously produced anti-WSSV monoclonal antibodies as the detector antibody. A standard curve of the log concentration of WSSV versus OD value was established, which was linear in the concentration range of 120–7680ng/mL, and the linear regression equation was y=0.166x−0.151. Viral proteins in different tissues of crayfish (Procambarus clarkia) post artificial infection with WSSV were quantitatively measured using the DAS-ELISA. WSSV proliferated quickly within 60h post infection and gradually slowed down afterwards. According to the linear regression relationship, the viral proteins in hemolymph, gut and gonad were firstly able to be quantified at 24h post infection with the concentrations of 186, 158 and 128ng/mL, respectively. These three tissues also contained higher viral proteins than the gill, heart, hepatopancreas and muscle during the entire infection period. The viral protein concentration in gut reached the highest level of 6220ng/mL at 72h post infection. Real time quantitative PCR was also used to detect the dynamic change of viral copies in crayfish hemolymph post WSSV infection, with similar results for both assays. The developed DAS-ELISA could detect WSSV propagation from initial to moribund stage in infected crayfish and demonstrated potential application for diagnosis of WSSV.",health
10.1016/j.asoc.2017.09.027,Journal,Applied Soft Computing Journal,scopus,2018-01-01,sciencedirect,Real-time human activity recognition from accelerometer data using Convolutional Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85030840014,"With a widespread of various sensors embedded in mobile devices, the analysis of human daily activities becomes more common and straightforward. This task now arises in a range of applications such as healthcare monitoring, fitness tracking or user-adaptive systems, where a general model capable of instantaneous activity recognition of an arbitrary user is needed. In this paper, we present a user-independent deep learning-based approach for online human activity classification. We propose using Convolutional Neural Networks for local feature extraction together with simple statistical features that preserve information about the global form of time series. Furthermore, we investigate the impact of time series length on the recognition accuracy and limit it up to 1s that makes possible continuous real-time activity classification. The accuracy of the proposed approach is evaluated on two commonly used WISDM and UCI datasets that contain labeled accelerometer data from 36 and 30 users respectively, and in cross-dataset experiment. The results show that the proposed model demonstrates state-of-the-art performance while requiring low computational cost and no manual feature engineering.",health
10.1016/j.jaerosci.2017.08.007,Journal,Journal of Aerosol Science,scopus,2018-01-01,sciencedirect,Comparing the performance of 3 bioaerosol samplers for influenza virus,https://api.elsevier.com/content/abstract/scopus_id/85028451741,"Respiratory viral diseases can be spread when a virus-containing particle (droplet) from one individual is aerosolized and subsequently comes into either direct or indirect contact with another individual. Increasing numbers of studies are examining the occupational risk to healthcare workers due to proximity to patients. Selecting the appropriate air sampling method is a critical factor in assuring the analytical performance characteristics of a clinical study. The objective of this study was to compare the physical collection efficiency and virus collection efficiency of a 5mL compact SKC BioSampler®, a gelatin filter, and a glass fiber filter, in a laboratory setting. The gelatin filter and the glass fiber filter were housed in a home-made filter holder. Submersion (with vortexing and subsequent centrifugation) was used for the gelatin and glass fiber filters. Swabbing method was also tested to retrieve the viruses from the glass fiber filter. Experiments were conducted using the H1N1 influenza A virus A/Puerto Rico/8/1934 (IAV-PR8), and viral recovery was determined using culture and commercial real-time-PCR (BioFire and Xpert). An atomizer was used to aerosolize a solution of influenza virus in PBS for measurement, and two Scanning Mobility Particle Sizers were used to determine particle size distributions. The SKC BioSampler demonstrated a U-shaped physical collection efficiency, lowest for particles around 30–50nm, and highest at 10nm and 300–350nm within the size range examined. The physical collection efficiency of the gelatin filter was strongly influenced by air flow and time: a stable collection across all particle sizes was only observed at 2L/min for the 9min sampling time, otherwise, degradation of the filter was observed. The glass fiber filter demonstrated the highest physical collection efficiency (100% for all sizes) of all tested samplers, however, its overall virus recovery efficiency fared the worst (too low to quantify). The highest viral collection efficiencies for the SKC BioSampler and gelatin filter were 5% and 1.5%, respectively. Overall, the SKC BioSampler outperformed the filters. It is important to consider the total concentration of viruses entering the sampler when interpreting the results.",health
10.1016/j.compeleceng.2017.07.018,Journal,Computers and Electrical Engineering,scopus,2018-01-01,sciencedirect,An intelligent framework for workouts in gymnasium: M-Health perspective,https://api.elsevier.com/content/abstract/scopus_id/85025694176,"The Internet of Things (IoT) Technology has the potential to capture real-time health related parameters everywhere. Henceforth, in this paper, the Cloud Centric IoT (CCIoT) Technology is utilized to assess the health related attributes of a trainee during exercise sessions in a gymnasium. The proposed system have the capabilities to predict the probabilistic vulnerability to health parameters of a trainee during workouts. For this purpose, back-propagation based Artificial Neural Network (ANN) technique is used as a prediction model, layered into three stages, i.e. Monitoring, Learning, and Prediction. Also, the probabilistic vulnerability is represented in real-time using color-coded technique, depicting the health state of the trainee. The proposed system has been validated using an experiment in which five people were monitored for six days at different gymnasiums. Results are compared with different state-of-the-art techniques for determining the overall effectiveness of the proposed system.",health
10.1016/j.compeleceng.2017.03.009,Journal,Computers and Electrical Engineering,scopus,2018-01-01,sciencedirect,Applying spark based machine learning model on streaming big data for health status prediction,https://api.elsevier.com/content/abstract/scopus_id/85015331423,"Machine learning is one of the driving forces of science and commerce, but the proliferation of Big Data demands paradigm shifts from traditional methods in the application of machine learning techniques on this voluminous data having varying velocity. With the availability of large health care datasets and progressions in machine learning techniques, computers are now well equipped in diagnosing many health issues. This work aims at developing a real time remote health status prediction system built around open source Big Data processing engine, the Apache Spark, deployed in the cloud which focus on applying machine learning model on streaming Big Data. In this scalable system, the user tweets his health attributes and the application receives the same in real time, extracts the attributes and applies machine learning model to predict user's health status which is then directly messaged to him/her instantly for taking appropriate action.",health
10.1016/j.asoc.2017.01.055,Journal,Applied Soft Computing Journal,scopus,2017-12-01,sciencedirect,An application of belief merging for the diagnosis of oral cancer,https://api.elsevier.com/content/abstract/scopus_id/85049212663,"Machine learning employs a variety of statistical, probabilistic, fuzzy and optimization techniques that allow computers to “learn” from examples and to detect hard-to-discern patterns from large, noisy or complex datasets. This capability is well-suited to medical applications, and machine learning techniques have been frequently used in cancer diagnosis and prognosis. In general, machine learning techniques usually work in two phases: training and testing. Some parameters, with regards to the underlying machine learning technique, must be tuned in the training phase in order to best “learn” from the dataset. On the other hand, belief merging operators integrate inconsistent information, which may come from different sources, into a unique consistent belief set (base). Implementations of merging operators do not require tuning any parameters apart from the number of sources and the number of topics to be merged. This research introduces a new manner to “learn” from past examples using a non parametrised technique: belief merging. The proposed method has been used for oral cancer diagnosis using a real-world medical dataset. The results allow us to affirm the possibility of training (merging) a dataset without having to tune the parameters. The best results give an accuracy of greater than 75%.",health
10.1016/j.biosystems.2017.10.001,Journal,BioSystems,scopus,2017-12-01,sciencedirect,Towards a first implementation of the WLIMES approach in living system studies advancing the diagnostics and therapy in personalized medicine,https://api.elsevier.com/content/abstract/scopus_id/85033459793,"The goal of this paper is to advance an extensible theory of living systems using an approach to biomathematics and biocomputation that suitably addresses self-organized, self-referential and anticipatory systems with multi-temporal multi-agents. Our first step is to provide foundations for modelling of emergent and evolving dynamic multi-level organic complexes and their sustentative processes in artificial and natural life systems. Main applications are in life sciences, medicine, ecology and astrobiology, as well as robotics, industrial automation, man-machine interface and creative design. Since 2011 over 100 scientists from a number of disciplines have been exploring a substantial set of theoretical frameworks for a comprehensive theory of life known as Integral Biomathics. That effort identified the need for a robust core model of organisms as dynamic wholes, using advanced and adequately computable mathematics. The work described here for that core combines the advantages of a situation and context aware multivalent computational logic for active self-organizing networks, Wandering Logic Intelligence (WLI), and a multi-scale dynamic category theory, Memory Evolutive Systems (MES), hence WLIMES. This is presented to the modeller via a formal augmented reality language as a first step towards practical modelling and simulation of multi-level living systems. Initial work focuses on the design and implementation of this visual language and calculus (VLC) and its graphical user interface. The results will be integrated within the current methodology and practices of theoretical biology and (personalized) medicine to deepen and to enhance the holistic understanding of life.",health
10.1016/j.pmcj.2017.06.013,Journal,Pervasive and Mobile Computing,scopus,2017-12-01,sciencedirect,Using big data analytics to extract disease surveillance information from point of care diagnostic machines,https://api.elsevier.com/content/abstract/scopus_id/85024112744,"This paper explains a novel approach for knowledge discovery from data generated by Point of Care (POC) devices. A very important element of this type of knowledge extraction is that the POC generated data would never be identifiable, thereby protecting the rights and the anonymity of the individual, whilst still allowing for vital population-level evidence to be obtained. This paper also reveals a real-world implementation of the novel approach in a big data analytics system. Using Internet of Things (IoT) enabled POC devices and the big data analytics system, the data can be collected, stored, and analyzed in batch and real-time modes to provide a detailed picture of a healthcare system as well to identify high-risk populations and their locations. In addition, the system offers benefits to national health authorities in forms of optimized resource allocation (from allocating consumables to finding the best location for new labs) thus supports efficient and timely decision-making processes.",health
10.1016/j.lfs.2017.09.011,Journal,Life Sciences,scopus,2017-11-15,sciencedirect,Enzyme-inducing effects of berberine on cytochrome P450 1A2 in vitro and in vivo,https://api.elsevier.com/content/abstract/scopus_id/85029290799,"Aims
                  Berberine (BER) is an important anti-bacterial drug from Chinese herbal medicine and a novel drug candidate for preclinical development in recent years. Here we provide evidence that the effects of berberine on cytochrome P450 (CYP) 1A2 in vitro and in vivo.
               
                  Main methods
                  Real-time polymerase chain reaction and western blotting analysis were employed to evaluate the CYP1A2 mRNA levels and protein expression. The enzyme activity was assessed by the metabolic rate of phenacetin to acetaminophen by LC-MS/MS method.
               
                  Key findings
                  The results indicated that the CYP1A2 mRNA expression and enzyme activity in HepG2 cells after treated with BER (4.5μg/ml) exhibited a significant induction (16.11-fold and 5.0-fold, respectively), which was consistent with those on rat liver microsomes (4.5-fold and 1.98-fold, respectively) by BER induction (10mg/kg/day, i.p.) ex vivo. Beside, BER induced CYP1A2 activity with increases in AUC0−t and Cmax of acetaminophen and the Ke and t1/2 of phenacetin after oral administration of phenacetin (p
                     <0.05) in vivo.
               
                  Significance
                  This study firstly reported the induction effect of BER on rats CYP1A2 by intraperitoneal route. But, BER didn't show significant induction effect on CYP1A2 by high-dose orally administrating to rats for 6 consecutive days due to the extremely low bioavailability. The potential drug-drug interactions were supposed to happen when the liver exposed to high dose of BER in vivo by changing administration route.",health
10.1016/j.eswa.2017.05.073,Journal,Expert Systems with Applications,scopus,2017-11-15,sciencedirect,Medical image analysis using wavelet transform and deep belief networks,https://api.elsevier.com/content/abstract/scopus_id/85019982802,"This paper introduces a three-step framework for classifying multiclass radiography images. The first step utilizes a de-noising technique based on wavelet transform (WT) and the statistical Kolmogorov Smirnov (KS) test to remove noise and insignificant features of the images. An unsupervised deep belief network (DBN) is designed for learning the unlabelled features in the second step. Although small-scale DBNs have demonstrated significant potential, the computational cost of training the restricted Boltzmann machine is a major issue when scaling to large networks. Moreover, noise in radiography images can cause a significant corruption of information that hinders the performance of DBNs. The combination of WT and KS test in the first step helps improve performance of DBNs. Discriminative feature subsets obtained in the first two steps serve as inputs into classifiers in the third step for evaluations. Five frequently used classifiers including naive Bayes, radial basis function network, random forest, sequential minimal optimization, and support vector machine and four different case studies are implemented for experiments using the Image Retrieval in Medical Application data set. The experimental results show that the three-step framework has significantly reduced computational cost and yielded a great performance for multiclass radiography image classification. Along with effective applications in image processing in other fields published in the literature, deep learning network in this paper has again demonstrated its robustness in handling a complex set of medical images. This implies that the proposed approach can be implemented in real practice for analysing noisy radiography images, which have many useful medical applications such as diagnosis of diseases related to lung, breast, musculoskeletal or pediatric studies.",health
10.1016/j.enconman.2017.09.019,Journal,Energy Conversion and Management,scopus,2017-11-01,sciencedirect,An enhanced machine learning based approach for failures detection and diagnosis of PV systems,https://api.elsevier.com/content/abstract/scopus_id/85034076834,"In this paper, a novel procedure for fault detection and diagnosis in the direct current (DC) side of PV system, based on probabilistic neural network (PNN) classifier, is proposed. The suggested procedure consists of four main stages: (i) PV module parameters extraction, (ii) PV array simulation and experimental validation (iii) elaboration of a relevant database of both healthy and faulty operations, and (iv) network construction, training and testing. In the first stage, the unknown electrical parameters of the one diode model (ODM) are accurately identified using the best-so-far ABC algorithm. Then, based on these parameters the PV array is simulated and experimentally validated by using a PSIM™/Matlab™ co-simulation. Finally, efficient fault detection and diagnosis procedure based on PNN classifier is implemented. Four operating cases were tested in a grid connected PV system of 9.54kWp: Healthy system, three modules short-circuited in one string, ten modules short-circuited in one string, and a string disconnected from the array. Moreover, the PNN method was compared, under real operating conditions, with the feed forward back-propagation Artificial Neural Network (ANN) classifiers method, for noiseless and noisy data to evaluate the suggested method’s accuracy and test its aptitude to support noisy data. The obtained results have demonstrated the high efficiency of the proposed method to detect and diagnose DC side anomalies for both noiseless and noisy data cases.",health
10.1016/j.compbiomed.2017.09.019,Journal,Computers in Biology and Medicine,scopus,2017-11-01,sciencedirect,A finite element-based machine learning approach for modeling the mechanical behavior of the breast tissues under compression in real-time,https://api.elsevier.com/content/abstract/scopus_id/85030312260,"This work presents a data-driven method to simulate, in real-time, the biomechanical behavior of the breast tissues in some image-guided interventions such as biopsies or radiotherapy dose delivery as well as to speed up multimodal registration algorithms. Ten real breasts were used for this work. Their deformation due to the displacement of two compression plates was simulated off-line using the finite element (FE) method. Three machine learning models were trained with the data from those simulations. Then, they were used to predict in real-time the deformation of the breast tissues during the compression. The models were a decision tree and two tree-based ensemble methods (extremely randomized trees and random forest). Two different experimental setups were designed to validate and study the performance of these models under different conditions. The mean 3D Euclidean distance between nodes predicted by the models and those extracted from the FE simulations was calculated to assess the performance of the models in the validation set. The experiments proved that extremely randomized trees performed better than the other two models. The mean error committed by the three models in the prediction of the nodal displacements was under 2 mm, a threshold usually set for clinical applications. The time needed for breast compression prediction is sufficiently short to allow its use in real-time (
                        <
                     0.2 s).",health
10.1016/j.compind.2017.06.009,Journal,Computers in Industry,scopus,2017-11-01,sciencedirect,A comprehensive health assessment framework to facilitate IoT-assisted smart workouts: A predictive healthcare perspective,https://api.elsevier.com/content/abstract/scopus_id/85021057118,"Enormous potential of Internet of Things (IoT) Technology has made it feasible to perceive and analyze real time health conditions in ubiquitous manner. Moreover, incorporation of IoT in healthcare industry has led researchers around the world to develop smart applications like mobile healthcare, health-aware recommendations, and intelligent healthcare systems. Inspired from these aspects, this research presents an intelligent healthcare framework based on IoT Technology to provide ubiquitous healthcare to person during his/her workout sessions. The intelligence of the presented framework lies with its ability to analyze real time health conditions during workouts and predict probabilistic health state vulnerability. For predictive purpose, the proposed framework indulges the utilization of Artificial Neural Network (ANN) model, which is comprised of three phases namely, monitor, learn, and predict. In addition to this, the presented framework is supported by a mathematical foundation to predict probabilistic vulnerability, in terms of Probabilistic State of Vulnerability (PSoV). In order to determine the validity and applicability of the proposed framework, experiments were performed where 5 people with different attributes are monitored for 14 days using numerous smart sensors. Results, upon comparison with various state-of-the-art techniques, depict that the proposed system is superior in performance and is highly effective in delivering healthcare services during workouts.",health
10.1016/j.jviromet.2017.05.007,Journal,Journal of Virological Methods,scopus,2017-10-01,sciencedirect,Cost-effective HIV-1 virological monitoring in resource-limited settings using a modified commercially available qPCR RNA assay,https://api.elsevier.com/content/abstract/scopus_id/85021225686,"Virological monitoring through plasma viral load (PVL) quantification is essential for clinical management of HIV patients undergoing antiretroviral treatment (ART), and for detecting treatment failure. Quantitative PCR (qPCR)-based tests are the gold standard for measuring PVL. Largely because of their high cost, however, implementation of these tests in low- and middle-income countries fails to cover the testing demand. In this study, we aimed at reducing the running cost of the commercially available Abbott RealTime™ HIV-1 assay by minimizing the reagent consumption. To this end, a modified version of the assay was obtained by reducing the assay’s reagents volume to about a half, and validated using a panel of 104 plasma samples. Compared to the standard version, the modified Abbott assay allowed for a 50% reduction in running costs. At the same time, it showed a 100% concordance in identifying samples with detectable viral load, strong correlation (Pearson’s r
                     =0.983, P
                     <0.0001), and a high agreement between PVL values (mean percent difference between PVL values±standard deviation=0.76±3.18%). In detecting viral failure (PVL>1000copiesmL−1), the modified assay showed a sensitivity of 94.6%, a specificity of 93.8%, and a negative and positive predictive values of 93.8% and 94.6%, respectively. The modified assay therefore reliably quantifies PVL, predicts viral failure, and allows for a ca. 50% reduction in the assay’s running costs. It may thus be implemented as an ART monitoring tool in resource-limited settings and for research purposes.",health
10.1016/j.jbi.2017.08.006,Journal,Journal of Biomedical Informatics,scopus,2017-09-01,sciencedirect,Monitoring stress with a wrist device using context,https://api.elsevier.com/content/abstract/scopus_id/85028621268,"Being able to detect stress as it occurs can greatly contribute to dealing with its negative health and economic consequences. However, detecting stress in real life with an unobtrusive wrist device is a challenging task. The objective of this study is to develop a method for stress detection that can accurately, continuously and unobtrusively monitor psychological stress in real life. First, we explore the problem of stress detection using machine learning and signal processing techniques in laboratory conditions, and then we apply the extracted laboratory knowledge to real-life data. We propose a novel context-based stress-detection method. The method consists of three machine-learning components: a laboratory stress detector that is trained on laboratory data and detects short-term stress every 2min; an activity recognizer that continuously recognizes the user’s activity and thus provides context information; and a context-based stress detector that uses the outputs of the laboratory stress detector, activity recognizer and other contexts, in order to provide the final decision on 20-min intervals. Experiments on 55days of real-life data showed that the method detects (recalls) 70% of the stress events with a precision of 95%.",health
10.1016/j.jchromb.2017.07.004,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2017-09-01,sciencedirect,Nanofibers mat-based solid-phase extraction method for the pretreatment of urine samples and its application in the primary study on the disposition of nonylphenol after long-term low-level exposure in rats,https://api.elsevier.com/content/abstract/scopus_id/85026474791,"A method was established for the analysis of nonylphenol (NP) in rat urine samples based on a solid-phase extraction (SPE) procedure with an amino functionalized polyacrylonitrile nanofibers mat (NH2-PAN NFSM) as sorbent coupled with high performance liquid chromatography-tandem mass spectrometry (HPLC–MS/MS). The calibration curves prepared in three different days showed good linearity over a wide range of NP concentrations from 0.1 to 100.0ng/mL. It was remarkable that the proposed NH2-PAN NFsM based SPE method showed superior extraction efficiency with the consumption of only 4mg of sorbent and 500μL of eluent. The eluent without any further concentration was directly analyzed by HPLC–MS/MS. As a result, a simple and effective sample preparation was achieved. In addition, the notable lower detection limit (LOD) of 0.03ng/mL revealed the excellent sensitivity of the proposed method in comparison with that in literatures. The recoveries ranged from 85.0% to 114.8% with the relative standard deviations (RSDs) ranging from 7.5% to 13.7%, which were better than or comparable to those from the published methods, suggesting high accuracy of the proposed method. The proposed method was applied in primary study on the disposition of nonylphenol after long-term low-level exposure in rats, providing information for health risk assessment on the real scenarios of NP exposure. NH2-PAN NFsM shows great potential as a novel SPE sorbent for the analysis of biological samples.",health
10.3168/jds.2017-12560,Journal,Journal of Dairy Science,scopus,2017-09-01,sciencedirect,Short communication: Survival of Vaccinia virus in inoculated cheeses during 60-day ripening,https://api.elsevier.com/content/abstract/scopus_id/85024908086,"Bovine vaccinia is a neglected zoonosis caused by Vaccinia virus (VACV) and has a major economic and public health effect in Brazil. Previous studies showed infectious VACV particles in milk from either experimentally or naturally infected cows and in fresh cheeses prepared with experimentally contaminated milk. Ripening is a process that leads to major changes in the physical and chemical characteristics of cheese, reducing contamination by spoilage, pathogenic microorganisms, or both. However, it is not known if VACV infectious particles persist after the ripening process. To investigate this issue, viral infectivity at different ripening times was studied in cheeses manufactured with milk experimentally contaminated with VACV strain Guarani P2 (GP2). Cheeses were analyzed at 1, 7, 14, 21, 45, and 60 d of ripening at 25°C. Viral DNA was quantified by real-time PCR, and VACV isolation and titration were performed in Vero cells. The whole experiment was repeated 4 times. Analysis of the mean viral DNA quantification and infectivity indicated a reduction of approximately 2 logs along the ripening process; however, infectious viral particles (1.7 × 102 pfu/mL) could still be recovered at d 60 of ripening. These findings indicate that the ripening process reduces VACV infectivity, but it was not able to inactivate completely the viral particles after 60 d.",health
10.1016/j.bios.2017.03.047,Journal,Biosensors and Bioelectronics,scopus,2017-08-15,sciencedirect,Multiplexed nanoplasmonic biosensor for one-step simultaneous detection of Chlamydia trachomatis and Neisseria gonorrhoeae in urine,https://api.elsevier.com/content/abstract/scopus_id/85016288582,"Development of rapid and multiplexed diagnostic tools is a top priority to address the current epidemic problem of sexually transmitted diseases. Here we introduce a novel nanoplasmonic biosensor for simultaneous detection of the two most common bacterial infections: Chlamydia trachomatis and Neisseria gonorrhoeae. Our plasmonic microarray is composed of gold nanohole sensor arrays that exhibit the extraordinary optical transmission (EOT), providing highly sensitive analysis in a label-free configuration. The integration in a microfluidic system and the precise immobilization of specific antibodies on the individual sensor arrays allow for selective detection and quantification of the bacteria in real-time. We achieved outstanding sensitivities for direct immunoassay of urine samples, with a limit of detection of 300 colony forming units (CFU)/mL for C. trachomatis and 1500CFU/mL for N. gonorrhoeae. The multiplexing capability of our biosensor was demonstrated by analyzing different urine samples spiked with either C. trachomatis or N. gonorrhoeae, and also containing both bacteria. We could successfully detect, identify and quantify the levels of the two bacteria in a one-step assay, without the need for DNA extraction or amplification techniques. This work opens up new possibilities for the implementation of point-of-care biosensors that enable fast, simple and efficient diagnosis of sexually transmitted infections.",health
10.1016/j.neucom.2016.05.117,Journal,Neurocomputing,scopus,2017-08-02,sciencedirect,Classification of transcranial Doppler signals using individual and ensemble recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/85017224365,"Transcranial Doppler (TCD) is a reliable technique with the advantage of being non-invasive for the diagnosis of cerebrovascular diseases using blood flow velocity measurements pertaining to the cerebral arterial segments. In this study, the recurrent neural network (RNN) is used to classify TCD signals captured from the brain. A total of 35 real, anonymous patient records are collected, and a series of experiments for stenosis diagnosis is conducted. The extracted features from the TCD signals are used for classification using a number of RNN models with recurrent feedbacks. In addition to individual RNN results, an ensemble RNN model is formed in which the majority voting method is used to combine the individual RNN predictions into an integrated prediction. The results, which include the accuracy, sensitivity, and specificity rates as well as the area under the Receiver Operating Characteristic curve, are compared with those from the Random Forest Ensemble model. The outcome positively indicates the usefulness of the RNN ensemble as an effective method for detecting and classifying blood flow velocity changes due to brain diseases.",health
10.1016/j.jbi.2017.06.021,Journal,Journal of Biomedical Informatics,scopus,2017-08-01,sciencedirect,An ontology-based approach to patient follow-up assessment for continuous and personalized chronic disease management,https://api.elsevier.com/content/abstract/scopus_id/85021747974,"Objective
                  Chronic diseases are complex and persistent clinical conditions that require close collaboration among patients and health care providers in the implementation of long-term and integrated care programs. However, current solutions focus partially on intensive interventions at hospitals rather than on continuous and personalized chronic disease management. This study aims to fill this gap by providing computerized clinical decision support during follow-up assessments of chronically ill patients at home.
               
                  Methods
                  We proposed an ontology-based framework to integrate patient data, medical domain knowledge, and patient assessment criteria for chronic disease patient follow-up assessments. A clinical decision support system was developed to implement this framework for automatic selection and adaptation of standard assessment protocols to suit patient personal conditions. We evaluated our method in the case study of type 2 diabetic patient follow-up assessments.
               
                  Results
                  The proposed framework was instantiated using real data from 115,477 follow-up assessment records of 36,162 type 2 diabetic patients. Standard evaluation criteria were automatically selected and adapted to the particularities of each patient. Assessment results were generated as a general typing of patient overall condition and detailed scoring for each criterion, providing important indicators to the case manager about possible inappropriate judgments, in addition to raising patient awareness of their disease control outcomes. Using historical data as the gold standard, our system achieved a rate of accuracy of 99.93% and completeness of 95.00%.
               
                  Conclusions
                  This study contributes to improving the accessibility, efficiency and quality of current patient follow-up services. It also provides a generic approach to knowledge sharing and reuse for patient-centered chronic disease management.",health
10.1016/j.ijmedinf.2017.05.006,Journal,International Journal of Medical Informatics,scopus,2017-08-01,sciencedirect,Dealing with uncertainty when using a surveillance system,https://api.elsevier.com/content/abstract/scopus_id/85019599002,"Introduction
                  Epidemiologists manage outbreak identification and confirmation by means of a “situation diagnosis”, which involves validating (or invalidating) an alarm (signal identified as abnormal) as an alert (a real, characterized outbreak) and proposing the first countermeasures. This work investigates how uncertainty is materialized during this stage, and how experts develop strategies to address this uncertainty with the help of an early warning system.
               
                  Methods
                  We built an experiment using a simulation platform with a scenario involving both a natural and an intentional outbreak. Observations of expert activities were recorded and formalised using a specific task analysis method. These formatted data were then categorized by applying RAWFS (Reduction- Assumption – Weighing − Forestalling- Suppression) heuristics.
               
                  Results
                  We quantified uncertainty and the mechanisms involved. During the situation diagnosis, two sorts of uncertainty were characterized: practice-imposed uncertainty and situation-imposed uncertainty. We did not find either weighing pros and cons or suppression strategies in this area of expertise, but highlight the predominance of coping strategies that relied on reduction (66,4%) and assumption-based reasoning. We observed a predominance of the phone (89%) to cope with uncertainty and among electronic tools, the surveillance system plays a major role (69% of cases) and is mainly used in reduction strategies. We detail tools and systems used to support experts in their coping strategy.
               
                  Conclusion
                  We confirmed that a surveillance system must include different features that provide relevant information to help users reduce uncertainty and thus support their decision making. In that perspective, the flow diagram and proposal presented in this study can help prioritize the necessary changes to surveillance system design.",health
10.1016/j.jmapro.2017.04.012,Journal,Journal of Manufacturing Processes,scopus,2017-08-01,sciencedirect,Particle learning in online tool wear diagnosis and prognosis,https://api.elsevier.com/content/abstract/scopus_id/85018418044,"Automated Tool condition monitoring is critical in intelligent manufacturing to improve both productivity and sustainability of manufacturing operations. Estimation of tool wear in real-time for critical machining operations can improve part quality and reduce scrap rates. This paper proposes a probabilistic method based on a Particle Learning (PL) approach by building a linear system transition function whose parameters are updated through online in-process observations of the machining process. By applying PL, the method helps to avoid developing a complex closed form formulation for a specific tool wear model. It increases the robustness of the algorithm and reduces the time complexity of computation. The application of the PL approach is tested using experiments performed on a milling machine. We have demonstrated one-step and two-step look ahead tool wear state prediction using online indirect measurements obtained from vibration signals. Additionally, the study also estimates remaining useful life (RUL) of the cutting tool inserts.",health
10.1016/j.vaccine.2017.06.055,Journal,Vaccine,scopus,2017-07-24,sciencedirect,Heterologous prime-boost immunization of Newcastle disease virus vectored vaccines protected broiler chickens against highly pathogenic avian influenza and Newcastle disease viruses,https://api.elsevier.com/content/abstract/scopus_id/85021321712,"Avian Influenza virus (AIV) is an important pathogen for both human and animal health. There is a great need to develop a safe and effective vaccine for AI infections in the field. Live-attenuated Newcastle disease virus (NDV) vectored AI vaccines have shown to be effective, but preexisting antibodies to the vaccine vector can affect the protective efficacy of the vaccine in the field. To improve the efficacy of AI vaccine, we generated a novel vectored vaccine by using a chimeric NDV vector that is serologically distant from NDV. In this study, the protective efficacy of our vaccines was evaluated by using H5N1 highly pathogenic avian influenza virus (HPAIV) strain A/Vietnam/1203/2004, a prototype strain for vaccine development. The vaccine viruses were three chimeric NDVs expressing the hemagglutinin (HA) protein in combination with the neuraminidase (NA) protein, matrix 1 protein, or nonstructural 1 protein. Comparison of their protective efficacy between a single and prime-boost immunizations indicated that prime immunization of 1-day-old SPF chicks with our vaccine viruses followed by boosting with the conventional NDV vector strain LaSota expressing the HA protein provided complete protection of chickens against mortality, clinical signs and virus shedding. Further verification of our heterologous prime-boost immunization using commercial broiler chickens suggested that a sequential immunization of chickens with chimeric NDV vector expressing the HA and NA proteins following the boost with NDV vector expressing the HA protein can be a promising strategy for the field vaccination against HPAIVs and against highly virulent NDVs.",health
10.1016/j.jep.2017.05.020,Journal,Journal of Ethnopharmacology,scopus,2017-07-12,sciencedirect,Hepatoprotective activities of Antrodia camphorata and its triterpenoid compounds against CCl<inf>4</inf>-induced liver injury in mice,https://api.elsevier.com/content/abstract/scopus_id/85019259778,"Ethnopharmacology relevance
                  
                     Antrodia camphorata (AC) is a rare and precious fungus indigenous to Taiwan used as a traditional medicine for the treatment of liver injury. Triterpenoids are the major bioactive constituents of A. camphorata and have been reported to possess hepatoprotective activities. To meet the increasing demand, artificial cultivation techniques have been developed.
               
                  Aim of the study
                  This study aims to evaluate the hepatoprotective activities of AC samples derived from different cultivation techniques and to dissect the main active triterpenoid compounds.
               
                  Materials and methods
                  The ethanol extracts of five batches of AC samples, including wild growing fruiting bodies, cutting wood culture fruiting bodies, dish cultures, cutting wood culture mycelia, and submerged fermentation mycelia were orally administered (50mg/kg or 200mg/kg) to ICR mice for 7 days. On the last day, CCl4 (0.2%, 7mL/kg, i.p.) was used to induce liver injury, and the activities of serum alanine aminotransferase (ALT) and aspartate aminotransferase (AST) were determined 24h after the injection. Moreover, a HepG2 cell model treated with CCl4 (0.35%) was used to screen the protective activities of 29 AC triterpenoids. After incubation for 6h, viabilities of the cells were tested using MTS assay. The in vivo hepatoprotective activities of antcin B and antcin K were further studied on the mice model by ALT and AST tests and histopathologic examinations. To elucidate the mechanisms, the mRNA levels of iNOS, COX2, TNF-α and IL-1β, and the protein levels of NF-κB (p65/p-p65), iNOS and COX2 in liver tissues were determined.
               
                  Results
                  The wild growing or cutting wood culture fruiting bodies, and the dish cultures of AC showed more potent activities than the mycelia (P<0.001). At 20μM, 16 of 29 triterpenoids showed significant protective activities, increasing HepG2 cell viability from 46% of the CCl4 group to >90%. Antcin B and antcin K could dose-dependently (10 or 50mg/kg, 7 days, i.g.) decrease the serum levels of ALT and AST, and decrease the incidence of liver necrosis. The effects of 50mg/kg of antcin K or antcin B were almost identical to those of 100mg/kg silymarin. Furthermore, qRT-PCR and Western blotting analyses revealed they could down-regulate IL-1β, TNF-α, iNOS, COX-2 and NF-κB in liver tissues at both transcriptional and translational levels.
               
                  Conclusion
                  The results indicate that cultivation techniques remarkably affect the hepatoprotective activities of AC. Antcin K and antcin B are the major hepatoprotective compounds of A. camphorata, and the mechanism is related with anti-inflammation. Given its high natural abundance and good oral absorption, antcin K could be a promising drug candidate for liver injury.",health
10.1016/j.jchromb.2017.05.004,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2017-07-01,sciencedirect,Comprehensive evaluation of SCFA production in the intestinal bacteria regulated by berberine using gas-chromatography combined with polymerase chain reaction,https://api.elsevier.com/content/abstract/scopus_id/85028508173,"Short-chain fatty acids (SCFAs) of intestine microbial have caught accumulating attention for their beneficial effects on human health. Botanic compounds with low bioavailability such as berberine (BBR) and resveratrol might interact with intestinal microbial ecosystem and promote gut bacteria to produce SCFA, which contribute to their biological effects. In the present study, a comprehensive assay system was built to detect SCFAs production in intestinal bacteria, in which stringent anaerobic culture was applied for in vitro bacterial fermentation, followed by direct-injection GC detection (chemical detection) in combination with real time polymerase chain reaction (RT-PCR, biological detection). BBR was used as positive reference. The direct injection GC method was calibrated and successfully applied to analyze the concentration of SCFAs in gut microbiota and BBR was proved to be effective in the dose- and time-dependent up-regulation of SCFAs production. As compared to the saline group, the concentration of acetic acid, propionate acid and butyric acid (the main SCFAs in gut microbiota) were increased by 17.7%, 11.1% and 30.5%, respectively, after incubating intestinal bacteria with 20μg/mL BBR for 24h. The increase reached to 34.9%, 22.4% and 51.6%, respectively when the BBR was 50μg/mL. Additionally, consensus-degenerate hybrid oligonucleotide primers (CODEHOPs) were designed for the detection of acetate kinase (ACK), Methylmalonyl-CoA decarboxylase (MMD) and butyryl-CoA: acetate-CoA transferase (BUT), as they are the key enzymes in the synthetic pathway for acetic acid, propionate acid and butyric acid, respectively. After 24hr’s incubation, BBR was shown to promote the gene expression of ACK, MMD and BUT significantly (86.5%, 27.2% and 60.4%, respectively, with 20μg/mL BBR; 130.2%, 84.2% and 98.4%, respectively, with 50μg/mL BBR), showing a solid biological support for the chemical detection. This comprehensive assay system might be useful in identifying SCFAs promoting agents with information on their mechanism.",health
10.1016/j.prevetmed.2017.04.011,Journal,Preventive Veterinary Medicine,scopus,2017-07-01,sciencedirect,Estimate of the economic impact of mastitis: A case study in a Holstein dairy herd under tropical conditions,https://api.elsevier.com/content/abstract/scopus_id/85019270385,"The aim of this study was to estimate the economic impact of mastitis at the herd level and the weight (percent) of the components of this impact in a Holstein dairy herd under tropical conditions. Three estimates of the economic impact of mastitis were performed. In estimates 1 and 2 the real production and economic indices from February 2011 to January 2012 were considered. In the estimate 1, indices for mastitis classified as ideal were considered, whereas in the estimate 2, the mastitis indices used were those recorded at the farm and at Holstein Cattle Association of Minas Gerais State database (real indices). Ideal mastitis indices were bulk milk somatic cell counts less than 250,000 cells/mL, incidence of clinical mastitis less than 25 cases/100 cows/year, number of culls due to udder health problems less than 5% and the percentage of cows with somatic cell counts greater than 200,000 cells/mL less than 20%. Considering the ideal indices of mastitis, the economic impact was US$19,132.35. The three main components of the economic impact were culling cows (39.4%) and the reduction in milk production due to subclinical and clinical mastitis (32.3% and 18.2%, respectively). Estimate 2 using real mastitis indices showed an economic impact of US$61,623.13 and the reduction in milk production due to mastitis (77.7%) and milk disposal (14.0%) were the most relevant components. The real impact of culling cows was approximately 16 times less than the weight that was considered ideal, indicating that this procedure could have been more frequently adopted. The reduction in milk production was 27.2% higher than the reduction in Estimate 1, indicating a need to control and prevent mastitis. The estimate 3 considered the same indices as estimate 2, but for the period from February 2012 to January 2013. Its economic impact was US$91,552.69. During this period, 161 treatments of cows with an intramammary antibiotic were performed to eliminate Streptococcus agalactiae, and eight cows chronically infected with Staphylococcus aureus were culled. The reduction in milk production due to mastitis was the main component of the economic impact (54.9%). The culling of cows with chronic infection was associated with an increase in the economic impact of mastitis and a reduction in the average productivity per cow. At the herd level reduction in milk production was the component that presented the largest weight in the economic impact of the disease.",health
10.1016/j.jmsy.2017.04.012,Journal,Journal of Manufacturing Systems,scopus,2017-07-01,sciencedirect,Virtualization and deep recognition for system fault classification,https://api.elsevier.com/content/abstract/scopus_id/85018250053,"Efficient gearbox health monitoring and effective representation of diagnostic results of dynamical systems have remained challenging. In this paper, a new approach to using deep learning for translating diagnostic results of one-dimensional time series analysis into graphical images for fault type and severity illustration is presented, with gearbox as a representative example. Specifically, time sequences are first converted by wavelet analysis to time-frequency images. Next, a deep convolutional neural network (DCNN) learns the underlying features in the time frequency domain from these images and performs fault classification. Experiments on gearbox data demonstrates effectiveness and efficiency of the developed approach with a classification accuracy better than 99.5%.",health
10.1016/j.infsof.2017.03.003,Journal,Information and Software Technology,scopus,2017-07-01,sciencedirect,Uncertainty-wise evolution of test ready models,https://api.elsevier.com/content/abstract/scopus_id/85015382293,"Context
                  Cyber-Physical Systems (CPSs), when deployed for operation, are inherently prone to uncertainty. Considering their applications in critical domains (e.g., healthcare), it is important that such CPSs are tested sufficiently, with the explicit consideration of uncertainty. Model-based testing (MBT) involves creating test ready models capturing the expected behavior of a CPS and its operating environment. These test ready models are then used for generating executable test cases. It is, therefore, necessary to develop methods that can continuously evolve, based on real operational data collected during the operation of CPSs, test ready models and uncertainty captured in them, all together termed as Belief Test Ready Models (BMs)
               
                  Objective
                  Our objective is to propose a model evolution framework that can interactively improve the quality of BMs, based on operational data. Such BMs are developed by one or more test modelers (belief agents) with their assumptions about the expected behavior of a CPS, its expected physical environment, and potential future deployments. Thus, these models explicitly contain subjective uncertainty of the test modelers.
               
                  Method
                  We propose a framework (named as UncerTolve) for interactively evolving BMs (specified with extended UML notations) of CPSs with subjective uncertainty developed by test modelers. The key inputs of UncerTolve include initial BMs of CPSs with known subjective uncertainty and real data collected from the operation of CPSs. UncerTolve has three key features: 1) Validating the syntactic correctness and conformance of BMs against real operational data via model execution, 2) Evolving objective uncertainty measurements of BMs via model execution, and 3) Evolving state invariants (modeling test oracles) and guards of transitions (modeling constraints for test data generation) of BMs with a machine learning technique.
               
                  Results
                  As a proof-of-concept, we evaluated UncerTolve with one industrial CPS case study, i.e., GeoSports from the healthcare domain. Using UncerTolve, we managed to evolve 51% of belief elements, 18% of states, and 21% of transitions as compared to the initial BM developed in an industrial setting.
               
                  Conclusion
                  
                     UncerTolve can successfully evolve model elements of the initial BM, in addition to objective uncertainty measurements using real operational data. The evolved model can be used to generate additional test cases covering evolved model elements and objective uncertainty. These additional test cases can be used to test the current and future deployments of a CPS to ensure that it will handle uncertainty gracefully during its operations.",health
10.1016/j.jocs.2017.01.010,Journal,Journal of Computational Science,scopus,2017-07-01,sciencedirect,Extraction of emotions from multilingual text using intelligent text processing and computational linguistics,https://api.elsevier.com/content/abstract/scopus_id/85012925755,"Extraction of Emotions from Multilingual Text posted on social media by different categories of users is one of the crucial tasks in the field of opining mining and sentiment analysis. Every major event in the world has an online presence and social media. Users use social media platforms to express their sentiments and opinions towards it. In this paper, an advanced framework for detection of emotions of users in Multilanguage text data using emotion theories has been presented, which deals with linguistics and psychology. The emotion extraction system is developed based on multiple features groups for the better understanding of emotion lexicons. Empirical studies of three real-time events in domains like a Political election, healthcare, and sports are performed using proposed framework. The technique used for dynamic keywords collection is based on RSS (Rich Site Summary) feeds of headlines of news articles and trending hashtags from Twitter. An intelligent data collection model has been developed using dynamic keywords. Every word of emotion contained in a tweet is important in decision making and hence to retain the importance of multilingual emotional words, effective pre-processing technique has been used. Naive Bayes algorithm and Support Vector Machine (SVM) are used for fine-grained emotions classification of tweets. Experiments conducted on collected data sets, show that the proposed method performs better in comparison to corpus-driven approach which assign affective orientation or scores to words. The proposed emotion extraction framework performs better on the collected dataset by combining feature sets consisting of words from publicly available lexical resources. Furthermore, the presented work for extraction of emotion from tweets performs better in comparisons of other popular sentiment analysis techniques which are dependent of specific existing affect lexicons.",health
10.1016/j.cbi.2017.05.006,Journal,Chemico-Biological Interactions,scopus,2017-06-25,sciencedirect,Sinigrin attenuates the progression of atherosclerosis in ApoE<sup>−/−</sup> mice fed a high-cholesterol diet potentially by inhibiting VCAM-1 expression,https://api.elsevier.com/content/abstract/scopus_id/85019017511,"Atherosclerosis is a complex inflammatory disease associated with elevated levels of atherogenic molecules for leukocyte recruitment. Sinigrin (2-propenylglucosinolate) is found mainly in broccoli, brussels sprouts, and black mustard seeds. Recently, sinigrin has received attention for its role in disease prevention and health promotion. In this study, we examined the effect of sinigrin on development of atherosclerosis in ApoE−/− mice and the expression of adhesion molecules in vascular smooth muscle cells (VSMCs). The serum concentrations of lactate dehydrogenase (LDH), triglyceride (TG), total cholesterol (TC), low density lipoprotein (LDL), calcium (Ca2+), and pro-inflammatory cytokines were reduced by sinigrin treatment in ApoE−/− mice. In addition, oral administration of sinigrin attenuated the mRNA expression of vascular cell adhesion molecule-1 (VCAM-1), intercellular adhesion molecule-1 (ICAM-1), C-C motif chemokine ligand 2 (CCL2), and CCL5 on aorta tissues and 3-hydroxy-3-methylglutaryl-coenzyme A reductase (HMGR), liver X receptor (LXR), sterol regulatory element-binding protein-2 (SREBP-2), and low density lipoprotein receptor (LDLR) on liver tissues in ApoE−/− mice. To provide a potential mechanism underlying the action of sinigrin, we evaluated the in vitro effect of sinigrin on the expression of the VCAM-1 in TNF-α-induced VSMCs. The increased expression of VCAM-1 by TNF-α stimulation was significantly suppressed by the treatment of sinigrin (1–100 μg/ml) and sinigrin inhibited the nuclear translocation of NF-κB and the phosphorylation of p38 MAPK and JNK pathways, suggesting that sinigrin decreases the TNF-α-stimulated VCAM-1 expression through the suppression of NF-κB and MAP kinases signaling pathways. Overall, sinigrin has the potential to be used in reducing the risks of atherosclerosis.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health
