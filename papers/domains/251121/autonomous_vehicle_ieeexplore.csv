doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database
10.1109/SAM.2018.8448945,EEG-Based Classification of Emotional State Using an Autonomous Vehicle Simulator,IEEE,Conferences,"Societal acceptance of self-driving cars (SDC) is predicated on a level of trust between humans and the autonomous vehicle. Although the performance of SDCs has improved dramatically, the question of mainstream acceptance and requisite trust is still open. We are exploring this question through integration of virtual reality SDC simulator and an electroencephalographic (EEG) recorder. In order for a passenger to build and maintain trust, the SDC will need to operate in a manner that elicits positive emotional response and avoids negative emotional response. In our experiment, a test subject was exposed to scenarios designed to induce positive and negative emotional responses, quantified by the EEG beta wave to alpha wave power ratio. As predicted, an increase in the beta to alpha power ratio was observed when the test subject was exposed to stress inducing situations inside the SDC simulator. Our results are expected to inform the design and operation of an EEG-based supervisory feedback control module or artificial intelligence (AI) that monitors the emotional state of passengers and adjusts the AI control parameters accordingly.",https://ieeexplore.ieee.org/document/8448945/,2018 IEEE 10th Sensor Array and Multichannel Signal Processing Workshop (SAM),8-11 July 2018,ieeexplore
10.1109/AICAS51828.2021.9458488,Evaluation of Machine Learning-based Detection against Side-Channel Attacks on Autonomous Vehicle,IEEE,Conferences,"Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world has introduced new security risks. Recent studies have shown that using Cache-based Side-Channel Attacks (SCAs) could infer sensitive users' information (e.g., which route the user is taking) highlighting significant vulnerability posed to today's computer systems. As a result, it is crucial to propose effective detection mechanisms against emerging microarchitectural SCAs on autonomous driving systems. In response, we first identify the threat model and victim applications of autonomous driving systems in this work. Next, we explore the suitability of various machine learning-based classifiers trained by information collected from built-in hardware performance counter registers available in modern autonomous vehicle systems. To this end, various supervised machine learning models are implemented for cache-based SCAs detection and precisely compared and characterized in terms of detection accuracy, robustness, and latency of the detection. Our experiments conducted on an Intel Xeon, which Waymo autonomous driving vendor uses, demonstrate that J48 achieves 99.5% accuracy with the highest efficiency compared with other investigated models.",https://ieeexplore.ieee.org/document/9458488/,2021 IEEE 3rd International Conference on Artificial Intelligence Circuits and Systems (AICAS),6-9 June 2021,ieeexplore
10.1109/VTCFall.2017.8288318,Impact to Longitude Velocity Control of Autonomous Vehicle from Human Driver's Distraction Behavior,IEEE,Conferences,"Driver distraction behaviors are usually blind to autonomous vehicles (AVs), leading to probable late preparation for AVs to take emergency measures. Hence, this paper aims to build a bridge between AV control and driver behavior detection, to assist AVs to predict the potential risk and avoid abnormal drivers carefully like experienced drivers. Our main contributions of this paper consist: i) put forward a practicable system framework integrating driver distraction monitoring, vehicle-to-vehicle communication and AV velocity control; ii) provide a real-time driver distraction monitoring implementation building on convolutional neural network trained offline; iii) propose a method of longitude velocity control of AV considering the risk of driver distraction behavior based on model predictive control strategy. Simulation results validate the effectiveness of our work.",https://ieeexplore.ieee.org/document/8288318/,2017 IEEE 86th Vehicular Technology Conference (VTC-Fall),24-27 Sept. 2017,ieeexplore
10.1109/ICMLC.2010.71,Microcontroller Based Neural Network Controlled Low Cost Autonomous Vehicle,IEEE,Conferences,"In this paper, design of a low cost autonomous vehicle based on neural network for navigation in unknown environments is presented. The vehicle is equipped with four ultrasonic sensors for hurdle distance measurement, a wheel encoder for measuring distance traveled, a compass for heading information, a GPS receiver for goal position information, a GSM modem for changing destination place on run time and a nonvolatile RAM for storing waypoint data; all interfaced to a low cost AT89C52 microcontroller. The microcontroller processes the information acquired from the sensors and generates robot motion commands accordingly through neural network. The neural network running inside the microcontroller is a multilayer feed-forward network with back-propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that upto twenty neurons can be implemented in hidden layer with this technique. The vehicle is tested with varying destination places in outdoor environments containing stationary as well as moving obstacles and is found to reach the set targets successfully.",https://ieeexplore.ieee.org/document/5460762/,2010 Second International Conference on Machine Learning and Computing,9-11 Feb. 2010,ieeexplore
10.1109/URAI.2016.7734068,Monocular vision-based object recognition for autonomous vehicle driving in a real driving environment,IEEE,Conferences,"Nowadays, many attentions have been devoted to autonomous vehicles because the automation of driving technology has a large number of benefits, such as the minimization of risks, the improvement of mobility and ease of drivers. Among many technologies for autonomous driving, road environmental recognition is one of the key issues. In this paper, we present the test results of various object detection algorithms using single monocular camera for autonomous vehicle in real driving conditions. The vision recognition system tested in this paper has three main recognition parts: pedestrian detection, traffic sign and traffic light recognition. We use Histogram of Gradients (HOG) features and detect the pedestrians by Support Vector Machine (SVM). Also features of traffic signs are extracted by Principal Components Analysis (PCA) and canny edge detection is used for traffic lights. These two signals are classified by Neural Network (NN). Algorithms that we tested are implemented in General-Purpose computing on Graphics Processing Units (GPGPU). We show the effectiveness of these methods in real-time applications for autonomous driving.",https://ieeexplore.ieee.org/document/7734068/,2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),19-22 Aug. 2016,ieeexplore
10.1109/ICICCS51141.2021.9432186,Pothole and Object Detection for an Autonomous Vehicle Using YOLO,IEEE,Conferences,"Object Detection is an key software and a fundamental task for an autonomous driving system that provides remarkable change in computer vision. İn recent years, company's are planning to launch autonomous vehicle in an full swing that's the most important ascpets for object detection and one of most challenging task for locating specific object from from multiple objects in a specific scenario. The computer vision and machine learning algorithm is the important tool for detecting objects in and around the environment. In this paper, which consists of two parts The first part is implemented on object detection in the surrounding with Yolo (You Only Look Once)Algorithm provides exact classification and position which is configured on newly created datasets for classes of object: a car, a person, a truck, a bus, traffic light, motorcycle, pothole, wetland uses the Convolutional Neural Network and max-polling layer for prediction that improves detecting of small target and these deep learning technique provides a high accuracy for detecting real world. Detecting potholes in Indian road help the autonomous vehicle to move smoothly without getting struck in the potholes. In part two of the proposed method is implemented on Raspberry pi4 a popular embedded computer board explores suitability for the running objects. That solves the real world problems and improves the impact on detecting objects. Knowing pothole and wetland detection for self-driving vehicle is needed badly to solve the road lay problems like: accident, slowing down the transport system these are solved by deep learning.",https://ieeexplore.ieee.org/document/9432186/,2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS),6-8 May 2021,ieeexplore
10.1109/ICC42927.2021.9500318,Reinforcement Learning for Autonomous Vehicle Movements in Wireless Sensor Networks,IEEE,Conferences,"In this work we use autonomous vehicles to improve the performance of Wireless Sensor Networks (WSNs). In contrast to other autonomous vehicle applications, WSNs have two metrics for performance evaluation. First, quality of information (QoI) which is used to measure the quality of sensed data (e.g., measurement uncertainties or signal strength). Second, quality of service (QoS) which is used to measure the network’s performance for data forwarding (e.g., delay and packet losses). As a use case, we consider wireless acoustic sensor networks, where a group of speakers move inside a room and there are autonomous vehicles installed with microphones for streaming the audio data. We formulate the problem as a Markov decision problem (MDP) and solve it using Deep-Q-Networks (DQN). Additionally, we compare the performance of DQN solution to two different real-world implementations: speakers holding/passing microphones and microphones being preinstalled in fixed positions.We show using simulations that the performance of autonomous vehicles in terms of QoI and QoS is better than the real-world implementation in some scenarios. Moreover, we study the impact of the vehicles speed on the learning process of the DQN solution and show how low speeds degrade the performance. Finally, we compare the DQN solution to a heuristic one and provide theoretical analysis of the performance with respect to dynamic WSNs.",https://ieeexplore.ieee.org/document/9500318/,ICC 2021 - IEEE International Conference on Communications,14-23 June 2021,ieeexplore
10.1109/ISORC.2018.00025,Representative Safety Assessment of Autonomous Vehicle for Public Transportation,IEEE,Conferences,"The implementations and testing in real conditions of Autonomous Vehicles (AV) for private usage show important advances. However, a lack still exists in addressing the particularities of AVs for Public Transportation. Such particularities range from limited safety mechanisms aboard, risky situations associated to particular users and complex self-driving situations up to the limited passengers-vehicle interactions possible. Since, to our knowledge, no comprehensive safety assessment actually exists and the current automotive related standards do not address identified aspects, in this paper, we propose to conduct a minimal but representative safety assessment based upon a local but real autonomous vehicle implementation. To conduct our study, the Hazard Analysis and Risks Assessment introduced in the ISO 26262 standard is taken as a basis. Initial outcomes suggest that critical autonomy aspects, like machine learning of complex operational situations, the metrics for quantitative assessment of autonomy, and potential conflicts between autonomy principles and external safety fences can have critical safety impacts and demand further discussions.",https://ieeexplore.ieee.org/document/8421156/,2018 IEEE 21st International Symposium on Real-Time Distributed Computing (ISORC),29-31 May 2018,ieeexplore
,Road following for autonomous vehicle navigation using a concurrent neural classifier,IEEE,Conferences,"The paper presents an original approach for visual identification of road direction of an autonomous vehicle using a neural network classifier called Concurrent Self-Organizing Maps (CSOM), representing a winner-takes-all collection of neural modules. We present the experimental results obtained by computer simulation of our model. The path to be identified has been quantized in 5 output directions. For training and testing the neural model, we captured and labeled a road image data set which has been divided in two lots: 30 images for training and other 30 images for test. We have also performed, trained and tested a real time neural path follower based on CSOM model, implemented on a mobile robot (car toy).",https://ieeexplore.ieee.org/document/4699060/,2008 World Automation Congress,28 Sept.-2 Oct. 2008,ieeexplore
10.1109/ACMI53878.2021.9528185,Speed Bump &amp; Pothole Detection with Single Shot MultiBox Detector Algorithm &amp; Speed Control for Autonomous Vehicle,IEEE,Conferences,"The development of self-driving cars has always been an extensive research field for the automobile industry. To make a capable self-driving car, many challenges need to be resolved. Detection of the road condition is one of them. This paper focuses on a particular part-detection of speed bumps and potholes using a camera and analyzing the video feed with the help of artificial intelligence. To solve this problem a popular and lightweight algorithm, SSD (Single Shot Multibox Detector) is used. This is an optimal choice because of being lightweight and also accurate enough to run on mobile devices and to use in real-life situations. For detecting speed bumps and potholes, a dataset has been created based on the road structure of Bangladesh as the main priority of this system is to work on the local environment. Raspberry Pi has been used as the main processing unit because of being small but powerful. A warning system has been implemented so that it can warn the onboard driver about the upcoming pothole or speed bump. This system can also send a signal to the speed controller unit of the car to reduce the speed on detection to avoid accidents or damages to the car. The speed control unit is a microcontroller-based system that uses an ATmega328 microcontroller and L298 motor driver. This paper summarizes the combination of an artificial intelligence-based detection system injunction with a microcontroller-based speed control system in a cost-effective way that can be used in building self-driving cars.",https://ieeexplore.ieee.org/document/9528185/,"2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 (ACMI)",8-9 July 2021,ieeexplore
10.1109/TVT.2018.2819806,Autonomous Vehicle Control Through the Dynamics and Controller Learning,IEEE,Journals,"Parameters tuning of the model and the controller is an essential problem for autonomous vehicles. Traditionally, parameter tuning work is accomplished by manual operation or grid search, which is a tedious and time-consuming work. Recently, thanks to the development of machine learning community, several automatic controller parameter tuning approaches emerged, which usually model the performance function as a Gaussian process, and complete the automatic tuning procedure via Bayesian optimization. However, the existing approaches rarely consider the time-varying feature of the system performance, which is practical in many scenarios, induced by the unmodeled interactions between the system and the environment. In this paper, we take both of the dynamic model uncertainty and the controller parameters uncertainty into account, and tune them to find a global optimal choice for minimizing the time-varying control costs, which is modeled by the time-varying Gaussian process. We provide a novel algorithm, named as time-varying controller optimization. We validate our approach on synthetic simulation and real experiment, respectively. Taking the cumulative regret as the performance metric, we find that our approach has a better performance compared with the stationary algorithm.",https://ieeexplore.ieee.org/document/8325485/,IEEE Transactions on Vehicular Technology,July 2018,ieeexplore
10.1109/ACCESS.2021.3125620,Autonomous Vehicle Evaluation: A Comprehensive Survey on Modeling and Simulation Approaches,IEEE,Journals,"In recent years, autonomous vehicles (AVs), which observe the driving environment and lead a few or all of the driving tasks, have garnered tremendous success. The field of AVs has been rapidly developing and has found many applications. As a safety requirement established by policymakers, these vehicles must be evaluated before their deployment. The evaluation process for AVs is challenging because crashes are rare events, and AVs can escape passing predefined test scenarios. Therefore, capturing crashes and creating real test scenarios should be considered in order to develop an evaluation approach that represents real-world scenarios. One evaluation approach is based on the naturalistic field operational test (N-FOT), in which prototype AVs are driven on roads by volunteers or test engineers. Unfortunately, this approach is time-consuming and costly because thousands of miles need to be driven to experience a police-reported collision and nearly millions of miles for a fatal crash. Another approach is the accelerated evaluation method. The core idea of the accelerated evaluation approach is to modify the statistics of naturalistic driving so that safety-critical events are emphasized. This paper presents a brief survey of the advances that have occurred in the area of the evaluation of partially or fully autonomous vehicles, starting with naturalistic field operational tests (N-FOTs). The review covers the test matrix evaluation, worst-case scenario evaluation (WCSE), Monte Carlo simulations, and accelerated evaluation (AE). We also present all the simulation-based and agent-based modeling approaches that do not follow any evaluation protocol listed above. This study provides a scientific analysis of each evaluation techniques, focusing on their advantages/disadvantages, inherent restrictions, practicability, and optimality. The results reveal that the accelerated evaluation approach outperforms naturalistic field operational tests (N-FOTs), test matrix evaluation, worst-case scenario evaluation (WCSE), and Monte Carlo simulation methods in some of the car-following and lane-change studies when using specific models. Moreover, the agent-based model and augmented and virtual reality approaches show promising results in AV evaluation. Furthermore, integrating machine and deep learning into the available AV evaluation methods can improve their performance and generate encouraging outcomes.",https://ieeexplore.ieee.org/document/9605690/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2021.3054124,Velocity Planning Method Base on Fuzzy Neural Network for Autonomous Vehicle,IEEE,Journals,"In order to improve the comfort performance and reduce the planning algorithm complexity in autonomous vehicle, an intelligent longitudinal velocity planning method based on fuzzy neural network (FNN) is proposed. With the manual driving experience, fuzzy planning model is established. By utilizing the self-learning function of neural network, fuzzy planning model is modified, which is attempted to establish FNN planning model. The planning method is applied to velocity planning. Three kinds of driving scenes are analyzed, and velocity planning models based on FNN are established accordingly. The simulation and experiment results indicate that acceleration generated by FNN planning model has good smooth property, and it is easy to be tracked by the subsequent control module. Compared with traditional method, the proposed method has certain anti-disturbance ability and self-adaptability. Also, the proposed method is convenient for engineering application, which ensures both the real-time performance and stability of the algorithm.",https://ieeexplore.ieee.org/document/9335025/,IEEE Access,2021,ieeexplore
10.1109/ISSCC.2009.4977352,A 201.4GOPS 496mW real-time multi-object recognition processor with bio-inspired neural perception engine,IEEE,Conferences,"The visual attention mechanism, which is the way humans perform object recognition, was applied to the implementation of a high performance object recognition chip. Even though the previous chip achieved 50% gain of computational cost, it could recognize only one object in a frame so that it is not suitable for advanced multi-object recognition applications such as video surveillance, intelligent robots, and autonomous vehicle",https://ieeexplore.ieee.org/document/4977352/,2009 IEEE International Solid-State Circuits Conference - Digest of Technical Papers,8-12 Feb. 2009,ieeexplore
10.1109/ICVES.2016.7548165,A new hopfield-type neural network approach to multi-goal vehicle navigation in unknown environments,IEEE,Conferences,"A Hopfield-type neural networks (HNN) algorithm associated with histogram navigation method is proposed in this paper for real-time map building and path planning for multiple goals applications. In real world applications such as rescue robots, service robots, mining mobile robots, and mine searching robots, etc., an autonomous vehicle needs to reach multiple goals with a shortest path that, in this paper, is capable of being implemented by a HNN method with minimized overall distance. Once a global trajectory is planned, a foraging-enabled trail is created to guide the vehicle to the multiple goals. A histogram-based local navigation algorithm is employed to plan a collision-free path along the trail planned by the global path planner. A re-planning-based algorithm aims to generate trajectory while an autonomous vehicle explores through a terrain with map building in unknown environments. In this paper, simulation and experimental results demonstrate that the real-time concurrent mapping and multi-goal navigation of an autonomous vehicle is successfully performed under unknown environments.",https://ieeexplore.ieee.org/document/7548165/,2016 IEEE International Conference on Vehicular Electronics and Safety (ICVES),10-12 July 2016,ieeexplore
,A robust control of mobile robot based on sonar sensors,IEEE,Conferences,"This paper describes the design and real implementation of wall following and fuzzy perception concept with a non-holonomic mobile robot named KHAN-Robo. The main focus of this paper is obtaining a fuzzy perception of the environment in the design of each reactive behavior and solving the problem of behavior combination to implement a fuzzy behavior based control architecture. It should be remarked that, the proposed technique of the nonholonomic constraints are considered in the design of each behavior. Furthermore, in order to improve the capabilities of the intelligent control system and its practical applicability, teleoperation and planned behaviors, together with their combination with reactive ones, have been considered. Experimental results, of an application to control the KHAN-Robo autonomous vehicle, demonstrate the robustness of the proposed method.",https://ieeexplore.ieee.org/document/6106329/,"2011 11th International Conference on Control, Automation and Systems",26-29 Oct. 2011,ieeexplore
10.1109/ISI49825.2020.9280513,A virtual simulation environment using deep learning for autonomous vehicles obstacle avoidance,IEEE,Conferences,"Autonomous vehicles which are capable of operating independently will be commercially available in the near future. Autonomous driving systems are becoming more complicated and must be successfully checked before implementation. Within this framework, falls our research work. The key purpose of this paper is to implement a simulation environment for autonomous vehicles. We first created this environment which is a novel high fidelity driving simulator that can connect arbitrary interfaces, build simulated worlds consisting of scenarios and incidents experienced by drivers in real-world driving, and incorporate fully autonomous driving. The simulator makes possible to clone the behavior of human driver face as well as some complex situations such as obstacle avoidance maneuvers. The work consists in creating a virtual simulation environment to collect training data used to train vehicles on how to steer themselves. The simulator is, thus, like a video game of car racing. Indeed we used the scenes to make some driving experiences. After collecting the training data, we chose to use deep learning explicitly Convolutional Neural Networks to create a model for autonomous vehicles that avoid obstacles. Clearly, the true challenge for an autonomous vehicle is to navigate without the possibility of collision. This simulator is invested to assess the performance of an autonomous vehicle and to analyze its self-driving activities. In this method, the suggested solution proves to be feasible, efficient and reliable for autonomous vehicle simulation research.",https://ieeexplore.ieee.org/document/9280513/,2020 IEEE International Conference on Intelligence and Security Informatics (ISI),9-10 Nov. 2020,ieeexplore
10.1109/EEEIC/ICPSEurope49358.2020.9160705,ASDVC - A Self-Driving Vehicle Controller using Unsupervised Machine Learning,IEEE,Conferences,"ASDVC is a self-driving vehicle controller that uses unsupervised machine learning methods, namely clustering based k-means, hierarchical, Gaussian Matrix Model and self-organizing mapping to optimize the path the vehicle follows from the source to destination. The real-time optimal selection of the unsupervised machine learning based motion control algorithm could provide fast response times of under one microsecond during the lateral, longitudinal and angular motion control of the autonomous vehicle. However, it is shown that a simple selection of one of the machine learning methods may not guarantee the optimality of the results. The successful implementation of ASDVC controller in self-driving vehicles could have a significant contribution towards making mobility more reliable and sustainable for the future vehicular transportation systems.",https://ieeexplore.ieee.org/document/9160705/,2020 IEEE International Conference on Environment and Electrical Engineering and 2020 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe),9-12 June 2020,ieeexplore
10.1109/DSN-W.2018.00027,AVFI: Fault Injection for Autonomous Vehicles,IEEE,Conferences,"Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S. roads, offering the promise of improvements in traffic management, safety, and the comfort and efficiency of vehicular travel. With this increasing popularity and ubiquitous deployment, resilience has become a critical requirement for public acceptance and adoption. Recent studies into the resilience of AVs have shown that though the AV systems are improving over time, they have not reached human levels of automation. Prior work in this area has studied the safety and resilience of individual components of the AV system (e.g., testing of neural networks powering the perception function). However, methods for holistic end-to-end resilience assessment of AV systems are still non-existent.",https://ieeexplore.ieee.org/document/8416212/,2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),25-28 June 2018,ieeexplore
10.1109/AIPR.2018.8707386,Acquiring Abstract Visual Knowledge of the Real-World Environment for Autonomous Vehicles,IEEE,Conferences,"This paper considers the problem of modeling the surrounding environment of a driven car by using the images captured by a dash cam during the driving process. Inspired from a human driver's interpretation of the car's surrounding environment, an abstract representation of the environment is developed that can facilitate in decision-making to prevent the car's collisions with surrounding objects. The proposed technique for modeling the car's surrounding environment utilizes the dash cam to capture images as the car is driven facing multiple situations and obstacles. By relying on the human driver's interpretation of various driving scenarios, the images of the car's surrounding environment are manually grouped into classes that reflect the driver's abstract knowledge. Grouping the images allows the formulation of knowledge transfer process from the human driver to an autonomous vehicle as a classification problem, producing a meaningful and efficient representation of models arising from real-world scenarios. The framework of convolutional neural networks (CNN) is employed to model the surrounding environment of the driven car, encapsulating the abstract knowledge of the human driver. The proposed modeling approach is applied to determine its efficacy in two experimental scenarios. In the first experiment, a highway driving scenario is considered with three classes. Alternatively, in the second experiment, a scenario of driving in a residential area is addressed with six classes. Excellent modeling performance is reported for both experiments. Comparisons conducted with alternative image classification techniques reveal the superiority of the CNN for modeling the considered driving scenarios.",https://ieeexplore.ieee.org/document/8707386/,2018 IEEE Applied Imagery Pattern Recognition Workshop (AIPR),9-11 Oct. 2018,ieeexplore
10.1109/ICRA40945.2020.9197024,Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving,IEEE,Conferences,In the autonomous driving area synthetic data is crucial for cover specific traffic scenarios which autonomous vehicle must handle. This data commonly introduces domain gap between synthetic and real domains. In this paper we deploy data augmentation to generate custom traffic scenarios with VRUs in order to improve pedestrian recognition. We provide a pipeline for augmentation of the Cityscapes dataset with virtual pedestrians. In order to improve augmentation realism of the pipeline we reveal a novel generative network architecture for adversarial learning of the data-set lighting conditions. We also evaluate our approach on the tasks of semantic and instance segmentation.,https://ieeexplore.ieee.org/document/9197024/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/VTCSpring.2019.8746507,Autonomous Driving without a Burden: View from Outside with Elevated LiDAR,IEEE,Conferences,"The current autonomous driving architecture places a heavy burden in signal processing for the graphics processing units (GPUs) in the car. This directly translates into battery drain and lower energy efficiency, crucial factors in electric vehicles. This is due to the high bit rate of the captured video and other sensing inputs, mainly due to Light Detection and Ranging (LiDAR) sensor at the top of the car which is an essential feature in autonomous vehicles. LiDAR is needed to obtain a high precision map for the vehicle AI to make relevant decisions. However, this is still a quite restricted view from the car. This is the same even in the case of cars without a LiDAR such as Tesla. The existing LiDARs and the cameras have limited horizontal and vertical fields of visions. In all cases it can be argued that precision is lower, given the smaller map generated. This also results in the accumulation of a large amount of data in the order of several TBs in a day, the storage of which becomes challenging. If we are to reduce the effort for the processing units inside the car, we need to uplink the data to edge or an appropriately placed cloud. However, the required data rates in the order of several Gbps are difficult to be met even with the advent of 5G. Therefore, we propose to have a coordinated set of LiDAR's outside at an elevation which can provide an integrated view with a much larger field of vision (FoV) to a centralized decision making body which then sends the required control actions to the vehicles with a lower bit rate in the downlink and with the required latency. The calculations we have based on industry standard equipment from several manufacturers show that this is not just a concept but a feasible system which can be implemented.The proposed system can play a supportive role with existing autonomous vehicle architecture and it is easily applicable in an urban area.",https://ieeexplore.ieee.org/document/8746507/,2019 IEEE 89th Vehicular Technology Conference (VTC2019-Spring),28 April-1 May 2019,ieeexplore
10.1109/UEMCON.2018.8796670,"Building Towards ""Invisible Cloak"": Robust Physical Adversarial Attack on YOLO Object Detector",IEEE,Conferences,"Deep learning based object detection algorithms like R-CNN, SSD, YOLO have been applied to many scenarios, including video surveillance, autonomous vehicle, intelligent robotics et al. With more and more application and autonomy left to deep learning based artificial intelligence, humans want to ensure that the machine does the best for them under their control. However, deep learning algorithms are known to be vulnerable to carefully crafted input known as adversarial examples which makes it possible for an attacker to fool an AI system. In this work, we explored the mechanism behind the YOLO object detector and proposed an optimization method to craft adversarial examples to attack the YOLO model. The experiment shows that this white box attack method is effective and has a success rate of 100% in crafting digital adversarial examples to fool the YOLO model. We also proposed a robust physical adversarial sticker generation method based on an extended Expectation Over Transformation (EOT) method(a method to craft adversarial example in the physical world). We conduct experiments to find the most effective approach to generate adversarial stickers. We tested the stickers both digitally as a watermark and physically showing it on an electronic screen on the front surface of a person. Our result shows that the sticker attack as a watermark has a success rate of 90% and 45% on photos taken indoors and on random 318 pictures from ImageNet. Our physical attack also has a success rate of 72% on photos taken indoors. We shared our project source code on the Github and our work is reproducible.",https://ieeexplore.ieee.org/document/8796670/,"2018 9th IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",8-10 Nov. 2018,ieeexplore
10.1109/ZINC.2019.8769392,Classification of Objects Detected by the Camera based on Convolutional Neural Network,IEEE,Conferences,"Nowadays, we are trying to achieve as much vehicle autonomy as possible by developing Advanced Driver-Assistance Systems (ADAS). For such a system to make decisions, it should have insight into the environment of the vehicle, e.g. the objects surrounding the vehicle. During forward driving, the information about the objects in front of the vehicle is usually obtained by a front view in-vehicle camera. This paper describes the image classification method of the objects in the front of the vehicle based on deep convolutional neural networks (CNN). Such CNN is supposed to be implemented in embedded system of an autonomous vehicle and the inference should satisfy real-time constraints. This means that the CNN should be structured to have fast inference by reducing the number of operations as much as possible, but still having satisfying accuracy. This can be achieved by reducing the number of parameters which also means that the resulting network has lower memory requirements. This paper describes the process of realizing such a network, from image dataset development up to the CNN structuring and training. The proposed CNN is compared to the state-of-the-art deep neural network in terms of classification accuracy, inference speed and memory requirements.",https://ieeexplore.ieee.org/document/8769392/,2019 Zooming Innovation in Consumer Technologies Conference (ZINC),29-30 May 2019,ieeexplore
10.1109/ITSC48978.2021.9564566,Continual Unsupervised Domain Adaptation for Semantic Segmentation by Online Frequency Domain Style Transfer,IEEE,Conferences,"When deep neural networks are deployed in a highly automated vehicle for environment perception tasks in an unseen (target) domain that differs from the training (source) domain, the mismatch will result in decreased performance. Domain adaptation methods aim at overcoming this mismatch. Many recently investigated methods for unsupervised domain adaptation train a model using labeled source data and unlabeled target data at the same time. These methods assume that data from the target domain is available during the source domain training, which is not always the case in real applications. In this paper we present a way to perform an online style transfer for continual domain adaptation which improves performance on (multiple) unseen target domains using a given perception model. The approach is based on an image style transfer in the frequency domain and requires neither an adjustment of the given source-trained model parameters to the target domain, nor does it require any considerable amount of memory for storing its frequency domain representation of the source domain style, which is particularly important considering the hardware limitations in an autonomous vehicle.",https://ieeexplore.ieee.org/document/9564566/,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),19-22 Sept. 2021,ieeexplore
10.1109/ICOSEC51865.2021.9591747,Deep Learning based Object Detection Model for Autonomous Driving Research using CARLA Simulator,IEEE,Conferences,"Autonomous vehicle research has grown exponentially over the years with researchers working on different object detection algorithms to realize safe and competent self-driving systems while legal authorities are simultaneously looking into the ways of mitigating the risks posed by fully autonomous vehicles. These advancements can result in a much safer commuting environment, reduced accidents and also eliminate the necessity for human driving. The creation of data and access to data for autonomous driving research is difficult challenge that research communities are facing. Hence, open source simulators such as the CARLA simulator (CAR Learning to Act) help us train and test models and to gain insights into autonomous driving with ease. This paper proposes the application of object detection algorithm on CARLA simulator to derive useful results for autonomous driving research. Further, the comparison of CARLA simulator with other available simulators, key players in the field of autonomous vehicle technology, state-of-the-art algorithms being used for autonomous driving, real time implementation challenges and future technologies are also discussed.",https://ieeexplore.ieee.org/document/9591747/,2021 2nd International Conference on Smart Electronics and Communication (ICOSEC),7-9 Oct. 2021,ieeexplore
10.1109/ICCC51557.2021.9454613,Deep Learning-Based Automated Vehicle Steering,IEEE,Conferences,"Autonomous Vehicle applications are full of open challenges. Despite the advanced technologies, the lack of robust systems still exists due to the high complexity of the surrounded environments. The automated steering is one of the most complex autonomous driving system's application. Model predictive control is the most common control strategy used to implement the automated steering tasks due to its ability to solve an online quadratic optimization problem in the real-time, in addition to its efficiency in handling the constraints of the system's environments. MPC controller is used to drive the vehicle autonomously along the centerline of the road based on two main factors, the lateral deviation and relative yaw angle. Deep learning technology has been widely used in recent years because of the promising performance achieved in different applications and tasks. In this context, we suggested that the implementation of the Deep Neural Network (DNN) will provide a great improvement and it can be more computationally efficient than solving an online quadratic problem (QP), that will naturally lead to reduce the time, the complexity, and the computational loads of implementations. The main aims of this paper are to design a deep learning-based approach for automated vehicle steering based on the behaviour of the traditional MPC controller. In addition, to study the efficiency of the full replacement of the MPC controller by the suggested DNN model. The study is based on performing a comparison between the implementations of both controllers (MPC and DNN model) in terms of the performance and the execution time. The performance indicator is the ability of the controller to drive the decision variables (lateral deviation and yaw angle) to be close to zero in order to drive the vehicle autonomously along the desired path.",https://ieeexplore.ieee.org/document/9454613/,2021 22nd International Carpathian Control Conference (ICCC),31 May-1 June 2021,ieeexplore
10.1109/ITSC.2018.8569575,Deep Traffic Light Detection for Self-driving Cars from a Large-scale Dataset,IEEE,Conferences,"Traffic lights perception problem is one of the key challenges for autonomous vehicle controllers in urban areas. While a number of approaches for traffic light detection have been proposed, these methods often require a prior knowledge of map and/or show high false positive rates. Recent successes suggest that deep neural networks will be widely used in self-driving cars, but current public datasets do not provide sufficient amount of labels for training such large deep neural networks. In this paper, we developed a two-step computational method that can detect traffic lights from images in a real-time manner. The first step exploits a deep neural object detection architecture to fine true traffic light candidates. In the second step, a point-based reward system is used to eliminate false traffic lights out of the candidates. To evaluate the proposed approach, we collected a human-annotated large-scale traffic lights dataset (over 60 hours). We also designed a real-world experiment with an instrumented self-driving vehicle and observed that the proposed method was able to handle false traffic lights substantially better compared with the baseline considered.",https://ieeexplore.ieee.org/document/8569575/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/SAM.2018.8448945,EEG-Based Classification of Emotional State Using an Autonomous Vehicle Simulator,IEEE,Conferences,"Societal acceptance of self-driving cars (SDC) is predicated on a level of trust between humans and the autonomous vehicle. Although the performance of SDCs has improved dramatically, the question of mainstream acceptance and requisite trust is still open. We are exploring this question through integration of virtual reality SDC simulator and an electroencephalographic (EEG) recorder. In order for a passenger to build and maintain trust, the SDC will need to operate in a manner that elicits positive emotional response and avoids negative emotional response. In our experiment, a test subject was exposed to scenarios designed to induce positive and negative emotional responses, quantified by the EEG beta wave to alpha wave power ratio. As predicted, an increase in the beta to alpha power ratio was observed when the test subject was exposed to stress inducing situations inside the SDC simulator. Our results are expected to inform the design and operation of an EEG-based supervisory feedback control module or artificial intelligence (AI) that monitors the emotional state of passengers and adjusts the AI control parameters accordingly.",https://ieeexplore.ieee.org/document/8448945/,2018 IEEE 10th Sensor Array and Multichannel Signal Processing Workshop (SAM),8-11 July 2018,ieeexplore
10.1109/IV48863.2021.9575135,End-to-End Intersection Handling using Multi-Agent Deep Reinforcement Learning,IEEE,Conferences,"Navigating through intersections is one of the main challenging tasks for an autonomous vehicle. However, for the majority of intersections regulated by traffic lights, the problem could be solved by a simple rule-based method in which the autonomous vehicle behavior is closely related to the traffic light states. In this work, we focus on the implementation of a system able to navigate through intersections where only traffic signs are provided. We propose a multi-agent system using a continuous, model-free Deep Reinforcement Learning algorithm used to train a neural network for predicting both the acceleration and the steering angle at each time step. We demonstrate that agents learn both the basic rules needed to handle intersections by understanding the priorities of other learners inside the environment, and to drive safely along their paths. Moreover, a comparison between our system and a rule-based method proves that our model achieves better results especially with dense traffic conditions. Finally, we test our system on real world scenarios using real recorded traffic data, proving that our module is able to generalize both to unseen environments and to different traffic conditions.",https://ieeexplore.ieee.org/document/9575135/,2021 IEEE Intelligent Vehicles Symposium (IV),11-17 July 2021,ieeexplore
10.1109/CiSt49399.2021.9357196,End-to-End Neural Network for Vehicle Dynamics Modeling,IEEE,Conferences,"Autonomous vehicles have to meet high safety standards in order to be commercially viable. Before real-world testing of an autonomous vehicle, extensive simulation is required to verify software functionality and to detect unexpected behavior. This incites the need for accurate models to match real system behavior as closely as possible. During driving, planing and control algorithms also need an accurate estimation of the vehicle dynamics in order to handle the vehicle safely. Until now, vehicle dynamics estimation has mostly been performed with physics-based models. Whereas these models allow specific effects to be implemented, accurate models need a variety of parameters. Their identification requires costly resources, e.g., expensive test facilities. Machine learning models enable new approaches to perform these modeling tasks without the necessity of identifying parameters. Neural networks can be trained with recorded vehicle data to represent the vehicle's dynamic behavior. We present a neural network architecture that has advantages over a physics-based model in terms of accuracy. We compare both models to real-world test data from an autonomous racing vehicle, which was recorded on different race tracks with high- and low-grip conditions. The developed neural network architecture is able to replace a single-track model for vehicle dynamics modeling.",https://ieeexplore.ieee.org/document/9357196/,2020 6th IEEE Congress on Information Science and Technology (CiSt),5-12 June 2021,ieeexplore
10.1109/AICAS51828.2021.9458488,Evaluation of Machine Learning-based Detection against Side-Channel Attacks on Autonomous Vehicle,IEEE,Conferences,"Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world has introduced new security risks. Recent studies have shown that using Cache-based Side-Channel Attacks (SCAs) could infer sensitive users' information (e.g., which route the user is taking) highlighting significant vulnerability posed to today's computer systems. As a result, it is crucial to propose effective detection mechanisms against emerging microarchitectural SCAs on autonomous driving systems. In response, we first identify the threat model and victim applications of autonomous driving systems in this work. Next, we explore the suitability of various machine learning-based classifiers trained by information collected from built-in hardware performance counter registers available in modern autonomous vehicle systems. To this end, various supervised machine learning models are implemented for cache-based SCAs detection and precisely compared and characterized in terms of detection accuracy, robustness, and latency of the detection. Our experiments conducted on an Intel Xeon, which Waymo autonomous driving vendor uses, demonstrate that J48 achieves 99.5% accuracy with the highest efficiency compared with other investigated models.",https://ieeexplore.ieee.org/document/9458488/,2021 IEEE 3rd International Conference on Artificial Intelligence Circuits and Systems (AICAS),6-9 June 2021,ieeexplore
10.1109/ICAMechS.2016.7813486,Intelligent adaptive precrash control for autonmous vehicle agents (CBR Engine &amp; hybrid A∗ path planner),IEEE,Conferences,"PreCrash problem of Intelligent Control of autonomous vehicles robot is a very complex problem, especially vehicle pre-crash scenariws and at points of intersections in real-time environmenta. This Paper presents a novel architecture of Intelligent adaptive control for autonomous vehicle agent that depends on Artificial Intelligence Techniques that applies case-based reasoning techniques, where Parallel CBR Engines are implemented for different scenarios' of PreCrash problem and sub-problems of intersection safety and collision avoidance, in the higher level of the controller and A* path planner for path planning and at lower-levels it also uses some features of autonomous vehicle dynamics. Moreover, the planner is enhanced by combination of Case-Based Planner. All modules are presented and discussed. Experimental results are conducted in the framework of Webots autonomous vehicle tool and overall results are good for the CBR Engine for Adaptive control and also for the hybrid Case-Based Planner, A* and D* motion planner along with conclusion and future work.",https://ieeexplore.ieee.org/document/7813486/,2016 International Conference on Advanced Mechatronic Systems (ICAMechS),30 Nov.-3 Dec. 2016,ieeexplore
10.1109/ITSC48978.2021.9564899,Learning a Model for Inferring a Spatial Road Lane Network Graph using Self-Supervision,IEEE,Conferences,"Interconnected road lanes are a central concept for navigating urban roads. Currently, most autonomous vehicles rely on preconstructed lane maps as designing an algorithmic model is difficult. However, the generation and maintenance of such maps is costly and hinders large-scale adoption of autonomous vehicle technology. This paper presents the first self-supervised learning method to train a model to infer a spatially grounded lane-level road network graph based on a dense segmented representation of the road scene generated from onboard sensors. A formal road lane network model is presented and proves that any structured road scene can be represented by a directed acyclic graph of at most depth three while retaining the notion of intersection regions, and that this is the most compressed representation. The formal model is implemented by a hybrid neural and search-based model, utilizing a novel barrier function loss formulation for robust learning from partial labels. Experiments are conducted for all common road intersection layouts. Results show that the model can generalize to new road layouts, unlike previous approaches, demonstrating its potential for real-world application as a practical learning-based lane-level map generator.",https://ieeexplore.ieee.org/document/9564899/,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),19-22 Sept. 2021,ieeexplore
10.1109/ICTAI.2019.00220,Learning to Drive via Apprenticeship Learning and Deep Reinforcement Learning,IEEE,Conferences,"With the implementation of reinforcement learning (RL) algorithms, current state-of-art autonomous vehicle technology have the potential to get closer to full automation. However, most of the applications have been limited to game domains or discrete action space which are far from the real world driving. Moreover, it is very tough to tune the parameters of reward mechanism since the driving styles vary a lot among the different users. For instance, an aggressive driver may prefer driving with high acceleration whereas some conservative drivers prefer a safer driving style. Therefore, we propose an apprenticeship learning in combination with deep reinforcement learning approach that allows the agent to learn the driving and stopping behaviors with continuous actions. We use gradient inverse reinforcement learning (GIRL) algorithm to recover the unknown reward function and employ REINFORCE as well as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal policy. The performance of our method is evaluated in simulation-based scenario and the results demonstrate that the agent performs human like driving and even better in some aspects after training.",https://ieeexplore.ieee.org/document/8995417/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.23919/AEITAUTOMOTIVE50086.2020.9307387,LiDAR point-cloud processing based on projection methods: a comparison,IEEE,Conferences,"An accurate and rapid-response perception system is fundamental for autonomous vehicles to operate safely. 3D object detection methods handle point clouds given by LiDAR sensors to provide accurate depth and position information for each detection, together with its dimensions and classification. The information is then used to track vehicles and other obstacles in the surroundings of the autonomous vehicle, and also to feed control units that guarantee collision avoidance and motion planning. Nowadays, object detection systems can be divided into two main categories. The first ones are the geometric based, which retrieve the obstacles using geometric and morphological operations on the 3D points. The seconds are the deep learning-based, which process the 3D points, or an elaboration of the 3D point-cloud, with deep learning techniques to retrieve a set of obstacles. This paper presents a comparison between those two approaches, presenting one implementation of each class on a real autonomous vehicle. Accuracy of the estimates of the algorithms has been evaluated with experimental tests carried in the Monza ENI circuit. The positions of the ego vehicle and the obstacle are given by GPS sensors with real time kinematic (RTK) correction, which guarantees an accurate ground truth for the comparison. Both algorithms have been implemented on ROS and run on a consumer laptop.",https://ieeexplore.ieee.org/document/9307387/,2020 AEIT International Conference of Electrical and Electronic Technologies for Automotive (AEIT AUTOMOTIVE),18-20 Nov. 2020,ieeexplore
10.1109/IV48863.2021.9575925,LiDAR-based Object Detection Failure Tolerated Autonomous Driving Planning System,IEEE,Conferences,"A typical autonomous driving system usually relies on the detected objects from an environment perception module. Current research still cannot guarantee a perfect perception, and failure detections may cause collisions, leading to untrustworthy autonomous vehicles. This work proposes a trajectory planner to tolerate the detection failure of the LiDAR sensors. This method will plan the path relying on the detected objects as well as the raw sensor data. The overlapping and contradiction of both perception routes will be carefully addressed for safe and efficient driving. The object detector in this work uses a deep learning-based method, i.e., CNN-Segmentation neural network. The designed trajectory planner has multi-layers to handle the multi-resolution environment formed by different perception routes. The final system will dynamically adjust its attention to the detected objects or the point cloud to avoid collision due to detection failures. This method is implemented on a real autonomous vehicle to drive in an open urban area. The results show that when the autonomous vehicle fails to detect a surrounding object, e.g., vehicles or some undefined objects, the autonomous vehicles still can plan an efficient and safe trajectory. In the meantime, when the perception system works well, the A V will not be affected by the point clouds. This technology can make the autonomous vehicle trustworthy even with the black-box neural networks. The codes are open-source with our autonomous driving platform to help other researchers for A V development.",https://ieeexplore.ieee.org/document/9575925/,2021 IEEE Intelligent Vehicles Symposium (IV),11-17 July 2021,ieeexplore
10.1109/IntelliSys.2017.8324372,Machine learning and deep neural network — Artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation,IEEE,Conferences,"Autonomous vehicles are now the future of automobile industry. Human drivers can be completely taken out of the loop through the implementation of safe and intelligent autonomous vehicles. Although we can say that HW and SW development continues to play a large role in the automotive industry, test and validation of these systems is a must. The ability to test these vehicles thoroughly and efficiently will ensure their proper and flawless operation. When a large number of people with heterogeneous knowledge and skills try to develop an autonomous vehicle together, it is important to use a sensible engineering process. State of the art techniques for such development include Waterfall, Agile &amp; V-model, where test &amp; validation (T&amp;V) process is an integral part of such a development cycle. This paper will propose a new methodology using machine learning &amp; deep neural network (AI-core) for lab &amp; real-world T&amp;V for ADAS (Advanced driver assistance system) and autonomous vehicles. The methodology will initially connect T&amp;V of individual systems in each level of development and that of complete system efficiently, by using the proposed phase methodology, in which autonomous driving functions are grouped under categories, special T&amp;V processes are carried on simulation as well as in HIL systems. The complete transition towards AI in the field of T&amp;V will be a sequence of steps. Initially the AI-core is fed with available test scenarios, boundary conditions for the test cases and scenarios, and examples, the AI-core will conduct virtual tests on simulation environment using available test scenarios and further generates new test cases and scenarios for efficient and precise tests. These test cases and scenarios are meant to cover all available cases and concentrate on the area where bugs or failures occur. The complete surrounding environment in the simulation is also controlled by the AI-core which means that the system can attain endless/all-possible combinations of the surrounding environment which is necessary. Results of the tests are sorted and stored, critical and important tests are again repeated in the real-world environment using automated cars with other real subsystems to depict the surrounding environment, which are all controlled by the AI-core, and meanwhile the AI-core is always in the loop and learning from each and every executed test case and its results/outcomes. The main goal is to achieve efficient and high quality test and validation of systems for automated driving, which can save precious time in the development process. As a future scope of this methodology, we can step-up to make most parts of test and validation completely autonomous.",https://ieeexplore.ieee.org/document/8324372/,2017 Intelligent Systems Conference (IntelliSys),7-8 Sept. 2017,ieeexplore
10.1109/ITSC.2019.8917085,Machine learning method to ensure robust decision-making of AVs,IEEE,Conferences,"Replacing the human driver to perform the Dynamic Driving Task (DDT)[1] will require perception, complex analysis and assessment of traffic situation. The path leading to success the deployment of fully Autonomous Vehicle (AV) depends on the resolution of a lot of challenges. Both the safety and the security aspects of AV constitute the core of regulatory compliance and technical research. The Autonomous Driving System (ADS) should be designed to ensure a safe manoeuvre and a stable behaviour despite the technological limitations, the uncertainties and hazards which characterize the real traffic conditions. In fully Autonomous Driving situation, detecting all relevant objects and agents should be sufficient to generate a warning, however the ADS requires further complex data analysis steps to quantify and improve the safety of decision making. This paper aims to improve the robustness of decision-making in order to mimic human-like decision ability. The approach is based on machine learning to identify the criticality of the dynamic situation and enabling ADS to make appropriate decision and fulfil safe manoeuvre.",https://ieeexplore.ieee.org/document/8917085/,2019 IEEE Intelligent Transportation Systems Conference (ITSC),27-30 Oct. 2019,ieeexplore
10.1109/ICMLC.2010.71,Microcontroller Based Neural Network Controlled Low Cost Autonomous Vehicle,IEEE,Conferences,"In this paper, design of a low cost autonomous vehicle based on neural network for navigation in unknown environments is presented. The vehicle is equipped with four ultrasonic sensors for hurdle distance measurement, a wheel encoder for measuring distance traveled, a compass for heading information, a GPS receiver for goal position information, a GSM modem for changing destination place on run time and a nonvolatile RAM for storing waypoint data; all interfaced to a low cost AT89C52 microcontroller. The microcontroller processes the information acquired from the sensors and generates robot motion commands accordingly through neural network. The neural network running inside the microcontroller is a multilayer feed-forward network with back-propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that upto twenty neurons can be implemented in hidden layer with this technique. The vehicle is tested with varying destination places in outdoor environments containing stationary as well as moving obstacles and is found to reach the set targets successfully.",https://ieeexplore.ieee.org/document/5460762/,2010 Second International Conference on Machine Learning and Computing,9-11 Feb. 2010,ieeexplore
10.1109/URAI.2016.7734068,Monocular vision-based object recognition for autonomous vehicle driving in a real driving environment,IEEE,Conferences,"Nowadays, many attentions have been devoted to autonomous vehicles because the automation of driving technology has a large number of benefits, such as the minimization of risks, the improvement of mobility and ease of drivers. Among many technologies for autonomous driving, road environmental recognition is one of the key issues. In this paper, we present the test results of various object detection algorithms using single monocular camera for autonomous vehicle in real driving conditions. The vision recognition system tested in this paper has three main recognition parts: pedestrian detection, traffic sign and traffic light recognition. We use Histogram of Gradients (HOG) features and detect the pedestrians by Support Vector Machine (SVM). Also features of traffic signs are extracted by Principal Components Analysis (PCA) and canny edge detection is used for traffic lights. These two signals are classified by Neural Network (NN). Algorithms that we tested are implemented in General-Purpose computing on Graphics Processing Units (GPGPU). We show the effectiveness of these methods in real-time applications for autonomous driving.",https://ieeexplore.ieee.org/document/7734068/,2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),19-22 Aug. 2016,ieeexplore
10.1109/ICCAR.2017.7942721,Object detection on panoramic images based on deep learning,IEEE,Conferences,"Panoramic image can be widely used in many applications, such as virtual reality, visual surveillance and autonomous vehicle, because of its large field of view. However, the inherent distortion for panorama causes object detection to be a challenging task. This paper focuses on the multi-class objects detection in panoramic images using deep learning method. The proposed system uses three fisheye cameras to efficiently create panoramas and build a large dataset. A region based convolutional neutral network (R-CNN) is implemented to train and test on an indoor panoramic image dataset. Experiments show great improvement performance on ten categories of distorted indoor objects with a mean average precision of 68.7%.",https://ieeexplore.ieee.org/document/7942721/,"2017 3rd International Conference on Control, Automation and Robotics (ICCAR)",24-26 April 2017,ieeexplore
10.1109/IVS.2002.1187941,Pattern matching as the nucleus for either autonomous driving or driver assistance systems,IEEE,Conferences,"Concerns autonomous vehicle driving by pattern matching combined with reinforcement learning. In specific, this research focuses on the requirement to steer an autonomous car along a curvy and hilly road course with no intersections and no other vehicle or obstacle but with the strict requirement to self-improve driving behaviour. A camera is used to build quickly an abstract complete description (ACSD) of vehicle's current situation. This combines traditional edge finding operators with a new technique of Bayes prediction for each part of the video image. Those ACSD's are being stored together with the steering commands issued at that time and serve as the pattern database of possible driving behaviour which are being retrieved using an approximate nearest neighbour pattern matching algorithm with a O(n log m) characteristic compared to O(n/spl middot/m) for the conventional nearest neighbour calculation. In addition to this, any feedback on the quality or appropriateness of the driving behaviour has to be self-created (e.g. time measurement for a whole road section) and is therefore delayed and unspecific in relation to single issued steering commands. Consequently, a machine learning algorithm coping with those conditions is being implemented based on Reinforcement Learning.",https://ieeexplore.ieee.org/document/1187941/,"Intelligent Vehicle Symposium, 2002. IEEE",17-21 June 2002,ieeexplore
10.1109/ISCAS45731.2020.9180841,PointNet on FPGA for Real-Time LiDAR Point Cloud Processing,IEEE,Conferences,"LiDAR sensors have been widely used in many autonomous vehicle modalities, such as perception, mapping, and localization. This paper presents an FPGA-based deep learning platform for real-time point cloud processing targeted on autonomous vehicles. The software driver for the Velodyne LiDAR sensor is modified and moved into the on-chip processor system, while the programmable logic is designed as a customized hardware accelerator. As the state-of-art deep learning algorithm for point cloud processing, PointNet is successfully implemented on the proposed FPGA platform. Targeted on a Xilinx Zynq UltraScale+ MPSoC ZCU104 development board, the FPGA implementations of PointNet achieve the computing performance of 182.1 GOPS and 280.0 GOPS for classification and segmentation respectively. The proposed design can support an input up to 4096 points per frame. The processing time is 19.8 ms for classification and 34.6 ms for segmentation, which meets the real-time requirement for most of the existing LiDAR sensors.",https://ieeexplore.ieee.org/document/9180841/,2020 IEEE International Symposium on Circuits and Systems (ISCAS),12-14 Oct 2020,ieeexplore
10.1109/ICICCS51141.2021.9432186,Pothole and Object Detection for an Autonomous Vehicle Using YOLO,IEEE,Conferences,"Object Detection is an key software and a fundamental task for an autonomous driving system that provides remarkable change in computer vision. İn recent years, company's are planning to launch autonomous vehicle in an full swing that's the most important ascpets for object detection and one of most challenging task for locating specific object from from multiple objects in a specific scenario. The computer vision and machine learning algorithm is the important tool for detecting objects in and around the environment. In this paper, which consists of two parts The first part is implemented on object detection in the surrounding with Yolo (You Only Look Once)Algorithm provides exact classification and position which is configured on newly created datasets for classes of object: a car, a person, a truck, a bus, traffic light, motorcycle, pothole, wetland uses the Convolutional Neural Network and max-polling layer for prediction that improves detecting of small target and these deep learning technique provides a high accuracy for detecting real world. Detecting potholes in Indian road help the autonomous vehicle to move smoothly without getting struck in the potholes. In part two of the proposed method is implemented on Raspberry pi4 a popular embedded computer board explores suitability for the running objects. That solves the real world problems and improves the impact on detecting objects. Knowing pothole and wetland detection for self-driving vehicle is needed badly to solve the road lay problems like: accident, slowing down the transport system these are solved by deep learning.",https://ieeexplore.ieee.org/document/9432186/,2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS),6-8 May 2021,ieeexplore
10.1109/CCET52649.2021.9544226,Real- Time Lane Detection Based on a Light-Weight Model in the Wild,IEEE,Conferences,"Lane detection plays an important role in both advanced driver assistance system and autonomous vehicle domains. Benefited from the recent progress of deep learning methods, lane detection becomes more and more powerful. However, these methods usually require a high amount of numerical computation, and the performance of the algorithm always suffer from low speed due to the essential constraint of computing resources. In this paper, we propose a light-weight model which can simultaneously detect lanes in complex environments. Furthermore, a hierarchical feature fusion mechanism is proposed to refine detection module by producing high-level feature representations that are amenable to capture both rich object context and high-resolution details. Experiment results show that our proposed method achieves comparable performance with the state-of-the-art methods, with significantly improved computational efficiency.",https://ieeexplore.ieee.org/document/9544226/,2021 IEEE 4th International Conference on Computer and Communication Engineering Technology (CCET),13-15 Aug. 2021,ieeexplore
10.1109/NAECON46414.2019.9057988,Real-Time 3-D Segmentation on An Autonomous Embedded System: using Point Cloud and Camera,IEEE,Conferences,"Present day autonomous vehicle relies on several sensor technologies for it's autonomous functionality. The sensors based on their type and mounted-location on the vehicle, can be categorized as: line of sight and non-line of sight sensors and are responsible for the different level of autonomy. These line of sight sensors are used for the execution of actions related to localization, object detection and the complete environment understanding. The surrounding or environment understanding for an autonomous vehicle can be achieved by segmentation. Several traditional and deep learning related techniques providing semantic segmentation for an input from camera is already available, however with the advancement in the computing processor, the progression is on developing the deep learning application replacing traditional methods. This paper presents an approach to combine the input of camera and lidar for semantic segmentation purpose. The proposed model for outdoor scene segmentation is based on the frustum pointnet, and ResNet which utilizes the 3d point cloud and camera input for the 3d bounding box prediction across the moving and non-moving object and thus finally recognizing and understanding the scenario at the point-cloud or pixel level. For real time application the model is deployed on the RTMaps framework with Bluebox (an embedded platform for autonomous vehicle). The proposed architecture is trained with the CITYScpaes and the KITTI dataset.",https://ieeexplore.ieee.org/document/9057988/,2019 IEEE National Aerospace and Electronics Conference (NAECON),15-19 July 2019,ieeexplore
10.1109/ASYU50717.2020.9259830,Real-Time Implementation of Mini Autonomous Car Based on MobileNet - Single Shot Detector,IEEE,Conferences,"In this paper, in order to realize a prototype of an autonomous vehicle, we present a framework that consists of convolutional neural networks and image processing methods. The study is comprised of two main parts as software and hardware. In the hardware part, a small-sized smart video car kit is used as the prototype of the autonomous car. This programmable tool consists of Raspberry Pi, servo motors and a USB webcam whose angle of vision is equal to 120°. In the software part, we propose an algorithm in which we use Convolutional Neural Networks to detect the objects (vehicles, pedestrians, and traffic signs) and Hough transformation to detect the road lanes. Based on the outputs of the object and lane detections, the system decides the speed and the direction of the car in real-time. In our results, the vehicle performs autonomous driving in the scaled real-world application.",https://ieeexplore.ieee.org/document/9259830/,2020 Innovations in Intelligent Systems and Applications Conference (ASYU),15-17 Oct. 2020,ieeexplore
10.1109/AIPR.2016.8010547,Real-time detection and classification of traffic light signals,IEEE,Conferences,"Traffic light detection is an important part of Advanced Driver Assist as well as autonomous vehicle systems which ensures timely and appropriate reaction to traffic lights (TLs) in cross sections. In this paper we introduce a robust and realtime approach to detect TLs and recognize its status in complex traffic scenes solely based on image processing techniques. The proposed system uses color properties of the scene to detect TLs in real-time. An innovative technique has been developed to significantly decrease compute requirement for detection of TL color by using one Lookup Table independent of lighting conditions. Each candidate region is further analyzed, using features analysis, to segregate actual TL signals among all candidate regions. As in similar machine learning techniques, an unsupervised classifier using a set of significant features has been developed to accurately segregate circular, semi-circular, and arrow shaped TL signals without using a training dataset. The final C++ code has been implemented and optimized on intelplatform using 1920×1080 frame resolution to recognize the status of TLs during day-time and night-time scenes, achieving 95% precision and 94.7% recall at 30FPS.",https://ieeexplore.ieee.org/document/8010547/,2016 IEEE Applied Imagery Pattern Recognition Workshop (AIPR),18-20 Oct. 2016,ieeexplore
10.1109/ICC42927.2021.9500318,Reinforcement Learning for Autonomous Vehicle Movements in Wireless Sensor Networks,IEEE,Conferences,"In this work we use autonomous vehicles to improve the performance of Wireless Sensor Networks (WSNs). In contrast to other autonomous vehicle applications, WSNs have two metrics for performance evaluation. First, quality of information (QoI) which is used to measure the quality of sensed data (e.g., measurement uncertainties or signal strength). Second, quality of service (QoS) which is used to measure the network’s performance for data forwarding (e.g., delay and packet losses). As a use case, we consider wireless acoustic sensor networks, where a group of speakers move inside a room and there are autonomous vehicles installed with microphones for streaming the audio data. We formulate the problem as a Markov decision problem (MDP) and solve it using Deep-Q-Networks (DQN). Additionally, we compare the performance of DQN solution to two different real-world implementations: speakers holding/passing microphones and microphones being preinstalled in fixed positions.We show using simulations that the performance of autonomous vehicles in terms of QoI and QoS is better than the real-world implementation in some scenarios. Moreover, we study the impact of the vehicles speed on the learning process of the DQN solution and show how low speeds degrade the performance. Finally, we compare the DQN solution to a heuristic one and provide theoretical analysis of the performance with respect to dynamic WSNs.",https://ieeexplore.ieee.org/document/9500318/,ICC 2021 - IEEE International Conference on Communications,14-23 June 2021,ieeexplore
10.1109/ISORC.2018.00025,Representative Safety Assessment of Autonomous Vehicle for Public Transportation,IEEE,Conferences,"The implementations and testing in real conditions of Autonomous Vehicles (AV) for private usage show important advances. However, a lack still exists in addressing the particularities of AVs for Public Transportation. Such particularities range from limited safety mechanisms aboard, risky situations associated to particular users and complex self-driving situations up to the limited passengers-vehicle interactions possible. Since, to our knowledge, no comprehensive safety assessment actually exists and the current automotive related standards do not address identified aspects, in this paper, we propose to conduct a minimal but representative safety assessment based upon a local but real autonomous vehicle implementation. To conduct our study, the Hazard Analysis and Risks Assessment introduced in the ISO 26262 standard is taken as a basis. Initial outcomes suggest that critical autonomy aspects, like machine learning of complex operational situations, the metrics for quantitative assessment of autonomy, and potential conflicts between autonomy principles and external safety fences can have critical safety impacts and demand further discussions.",https://ieeexplore.ieee.org/document/8421156/,2018 IEEE 21st International Symposium on Real-Time Distributed Computing (ISORC),29-31 May 2018,ieeexplore
10.1109/ICAICTA49861.2020.9429073,Road Recognition System with Heuristic Method and Machine Learning,IEEE,Conferences,"Road recognition is one of essential information for determining an Autonomous Vehicle movement. Latest research has shown that machine learning could be used to obtain the information from images. Nevertheless, the system could be improved by effectivity and efficiency. This research proposed finding better feature combinations and using Artificial Neural Network algorithm to build higher accuracy road detection model for better effectivity. Region of Interest module using heuristic method also applied to reduce computation for better efficiency. These three new modules are implemented and combined with road recognition module to become road recognition system. The proposed method performance then tested and compared with the latest research. The experiment results shown that Artificial Neural Network cannot increase the system effectiveness. Nonetheless, with right feature and region of interest module, the proposed system successfully gives better performance. The prototype has accuracy increased from F1-score 0,94 to 0,95 and speed increased from 99 to 112 frames processed per second.",https://ieeexplore.ieee.org/document/9429073/,"2020 7th International Conference on Advance Informatics: Concepts, Theory and Applications (ICAICTA)",8-9 Sept. 2020,ieeexplore
10.1109/IROS.2014.6943162,Spatio-temporal motion features for laser-based moving objects detection and tracking,IEEE,Conferences,"This paper proposes a spatio-temporal motion feature detection and tracking method using range sensors working on a moving platform. The proposed spatio-temporal motion features are similar to optical flow but are extended on a moving platform with fusion of odometry and show much better classification accuracy with consideration of different uncertainties. In the proposal, the ego motion is compensated by odometry sensors and the laser scan points are accumulated and represented as space-time point clouds, from which the velocities and moving directions can be extracted. Based on these spatio-temporal features, a supervised learning technique is applied to classify the points as static or moving and Kalman filters are implemented to track the moving objects. A real experiment is performed during day and night on an autonomous vehicle platform and shows promising results in a crowded and dynamic environment.",https://ieeexplore.ieee.org/document/6943162/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/IVS.1994.639471,The development of a fully autonomous ground vehicle (FAGV),IEEE,Conferences,"As a first step toward the creation of a fully autonomous vehicle that operates in a real world environment, we are currently developing a prototype autonomous ground vehicle (AGV) for use in factories and other industrial/business sites based on behavior-based artificial intelligence (AI) control. This flexible and fully autonomous AGV (FAGV) is expected to operate efficiently in a normal industrial environment without any external guidance. The crucial technique employed is a non-Cartesian way of organizing software agents for the creation of a highly responsive control program. The resulting software is considerably reduced in size. Through numerous experiments using mobile robots we confirmed that these new control programs excel in functionality, efficiency, flexibility and robustness. The second key technique in the planning stage is evolutionary computation, of which genetic algorithms are a principal technique. An online, real-time evolution of the control program will be incorporated in later phases of the project to make FAGVs adaptable to any given operational environment after deployment. The first prototype FAGV has an active vision and behaviour-based control system.",https://ieeexplore.ieee.org/document/639471/,Proceedings of the Intelligent Vehicles '94 Symposium,24-26 Oct. 1994,ieeexplore
10.1109/IVS.2014.6856427,Traversability analysis using terrain mapping and online-trained Terrain type classifier,IEEE,Conferences,"Path estimation is a big challenge for autonomous vehicle navigation, especially in unknown, dynamic environments, when road characteristics change often. 3D terrain information (e.g. stereo cameras) can provide useful hints about the traversability cost of certain regions. However, when the terrain tends to be flat and uniform, it is difficult to identify a better path using 3D map solely. In this scenario the use of a priori knowledge on the expected road's visual characteristics can support detection, but it has the drawback of being not robust to environmental changes. This paper presents a path detection method that mixes together 3D mapping and visual classification, trying to learn, in real time, the actual road characteristics. An on-line learning of visual characteristics is implemented to feedback a terrain classifier, so that the road characteristics are updated as the vehicle moves. The feedback data are taken from a 3D traversability cost map, which provides some hints on traversable and non-traversable regions. After several re-training cycles the algorithm converges on a better separation of the path and non-path regions. The fusion of both 3D traversability cost and visual characteristics of the terrain yields a better estimation when compared with either of these methods solely.",https://ieeexplore.ieee.org/document/6856427/,2014 IEEE Intelligent Vehicles Symposium Proceedings,8-11 June 2014,ieeexplore
10.1109/WACV45572.2020.9093332,Uncertainty-aware Short-term Motion Prediction of Traffic Actors for Autonomous Driving,IEEE,Conferences,"We address one of the crucial aspects necessary for safe and efficient operations of autonomous vehicles, namely predicting future state of traffic actors in the autonomous vehicle's surroundings. We introduce a deep learning-based approach that takes into account a current world state and produces raster images of each actor's vicinity. The rasters are then used as inputs to deep convolutional models to infer future movement of actors while also accounting for and capturing inherent uncertainty of the prediction task. Extensive experiments on real-world data strongly suggest benefits of the proposed approach. Moreover, following successful tests the system was deployed to a fleet of autonomous vehicles.",https://ieeexplore.ieee.org/document/9093332/,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),1-5 March 2020,ieeexplore
10.1109/MICAI.2011.25,Velocity Control of an Electric Vehicle over a CAN Network,IEEE,Conferences,"Distributed control applications require a reliable network for information exchange. The network discussed on this paper uses CAN bus as a means of communication to control the speed of an electric vehicle. National Instruments Programmable Automation Controller, Compact RIO, based on Lab VIEW programming environment is used to execute one of two different speed control algorithms (PID or fuzzy logic) to test the performance of the implemented vehicle network and the control algorithm itself. It also acts as a human-machine interface via a personal computer. The proposed network provides robustness in terms of communication and opens the possibility of expansion to develop complete control architecture in order to successfully build a fully autonomous vehicle.",https://ieeexplore.ieee.org/document/6119003/,2011 10th Mexican International Conference on Artificial Intelligence,26 Nov.-4 Dec. 2011,ieeexplore
10.1109/SCOReD50371.2020.9250937,Visual Computing-based Perception System for Small Autonomous Vehicles: Development on a Lighter Computing Platform,IEEE,Conferences,"Recently, perception system for autonomous vehicle has seen a tremendous growth. Most of the recent works employ sensor fusion with complementary properties to produce a robust and accurate perceptive system for vehicle. However, this comes at a high price, requires high computing power and consumes more energy. In this study a perceptive system is designed to tackle the above issues while maintaining its accuracy and robustness. The proposed perceptive system is using only a pair of vision sensors. A Convolution Neural Network is used to detect and identify objects in the field of vision. A pair of cameras are then used to form a stereovision which is used to measure the distance of the objects detected. A disparity map from stereovision images was constructed first, then from the region of interest, a single disparity value was extracted to calculate the distance. The system is employed on a single board computer system StereoPi with the help of Intel Neural Compute Stick 2 to run deep neural network inference. An experiment was then conducted to test the perceptive system's robustness, accuracy, and runtime. Results show that the proposed system is capable of a detection accuracy of 71.7% with an average error of 0.37% up to a distance of 1.3m.",https://ieeexplore.ieee.org/document/9250937/,2020 IEEE Student Conference on Research and Development (SCOReD),27-29 Sept. 2020,ieeexplore
10.1109/TVT.2020.3027352,A Nash Q-Learning Based Motion Decision Algorithm With Considering Interaction to Traffic Participants,IEEE,Journals,"In order to improve the efficiency and comfort of autonomous vehicles while ensuring safety, the decision algorithm needs to interact with human drivers, infer the most probable behavior and then makes advantageous decision. This paper proposes a Nash-Q learning based motion decision algorithm to consider the interaction. First, the local trajectory of surrounding vehicle is predicted by kinematic constraints, which can reflect the short-term motion trend. Then, the future action space is built based the predicted local trajectory that consists of five basis actions. With that, the Nash-Q learning process can be implemented by the game between these basis actions. By elimination of strictly dominated actions and the Lemke-Howson method, the autonomous vehicle can decide the optimal action and infer the behavior of surrounding vehicle. Finally, the lane merging scenario is built to test the performance contrast to the existing methods. The driver in loop experiment is further designed to verify the interaction performance in multi-vehicle traffic. The results show that the Nash-Q learning based algorithm can improve the efficiency and comfort by 15.75% and 20.71% to the Stackelberg game and the no-interaction method respectively while the safety is ensured. It can also make real-time interaction with human drivers in multi-vehicle traffic.",https://ieeexplore.ieee.org/document/9207975/,IEEE Transactions on Vehicular Technology,Nov. 2020,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/LES.2020.3009910,Designing Neural Networks for Real-Time Systems,IEEE,Journals,"Artificial neural networks (ANNs) are increasingly being used within safety-critical cyber-physical systems (CPSs). It is important to validate both the timing and functional correctness of these systems. However, most approaches in the literature consider guaranteeing only the functionality of the ANN-based controllers. This issue stems largely from the implementation strategies used within common neural network frameworks-their underlying source code is often simply unsuitable for formal techniques such as static timing analysis. As a result, developers of safety-critical CPS must rely on informal techniques, such as measurement-based approaches, to prove correctness, techniques that provide weak guarantees at best. In this letter, we address this challenge. We propose a design pipeline whereby neural networks trained using the popular deep learning framework Keras are compiled to functionally equivalent C code. This C code is restricted to simple constructs that may be analyzed by the existing static timing analysis tools. As a result, if compiled to a suitable time-predictable platform, all execution bounds may be statically derived. To demonstrate the benefits of our approach, we execute an ANN trained to drive an autonomous vehicle around a race track. We compile the ANN to the Patmos time-predictable controller and show that we can derive the worst-case execution timings.",https://ieeexplore.ieee.org/document/9143184/,IEEE Embedded Systems Letters,Sept. 2021,ieeexplore
10.1109/ACCESS.2020.2970728,LoPECS: A Low-Power Edge Computing System for Real-Time Autonomous Driving Services,IEEE,Journals,"To simultaneously enable multiple autonomous driving services on affordable embedded systems, we designed and implemented LoPECS, a Low-Power Edge Computing System for real-time autonomous robots and vehicles services. The contributions of this paper are three-fold: first, we developed a Heterogeneity-Aware Runtime Layer to fully utilize vehicle's heterogeneous computing resources to fulfill the real-time requirement of autonomous driving applications; second, we developed a vehicle-edge Coordinator to dynamically offload vehicle tasks to edge cloudlet to further optimize user experience in the way of prolonged battery life; third, we successfully integrated these components into LoPECS system and implemented it on Nvidia Jetson TX1. To the best of our knowledge, this is the first complete edge computing system in a production autonomous vehicle. Our implementation on Nvidia Jetson demonstrated that it could successfully support multiple autonomous driving services with only 11 W of power consumption, and hence proves the effectiveness of the proposed LoPECS system.",https://ieeexplore.ieee.org/document/8977507/,IEEE Access,2020,ieeexplore
10.1109/41.704895,Modeling of ultrasonic range sensors for localization of autonomous mobile robots,IEEE,Journals,"This paper presents a probabilistic model of ultrasonic range sensors using backpropagation neural networks trained on experimental data. The sensor model provides the probability of detecting mapped obstacles in the environment, given their position and orientation relative to the transducer. The detection probability can be used to compute the location of an autonomous vehicle from those obstacles that are more likely to be detected. The neural network model is more accurate than other existing approaches, since it captures the typical multilobal detection pattern of ultrasonic transducers. Since the network size is kept small, implementation of the model on a mobile robot can be efficient for real-time navigation. An example that demonstrates how the credence could be incorporated into the extended Kalman filter (EKF) and the numerical values of the final neural network weights are provided in the appendices.",https://ieeexplore.ieee.org/document/704895/,IEEE Transactions on Industrial Electronics,Aug. 1998,ieeexplore
10.1109/ACCESS.2021.3054124,Velocity Planning Method Base on Fuzzy Neural Network for Autonomous Vehicle,IEEE,Journals,"In order to improve the comfort performance and reduce the planning algorithm complexity in autonomous vehicle, an intelligent longitudinal velocity planning method based on fuzzy neural network (FNN) is proposed. With the manual driving experience, fuzzy planning model is established. By utilizing the self-learning function of neural network, fuzzy planning model is modified, which is attempted to establish FNN planning model. The planning method is applied to velocity planning. Three kinds of driving scenes are analyzed, and velocity planning models based on FNN are established accordingly. The simulation and experiment results indicate that acceleration generated by FNN planning model has good smooth property, and it is easy to be tracked by the subsequent control module. Compared with traditional method, the proposed method has certain anti-disturbance ability and self-adaptability. Also, the proposed method is convenient for engineering application, which ensures both the real-time performance and stability of the algorithm.",https://ieeexplore.ieee.org/document/9335025/,IEEE Access,2021,ieeexplore
10.1109/EEEIC/ICPSEurope49358.2020.9160705,ASDVC - A Self-Driving Vehicle Controller using Unsupervised Machine Learning,IEEE,Conferences,"ASDVC is a self-driving vehicle controller that uses unsupervised machine learning methods, namely clustering based k-means, hierarchical, Gaussian Matrix Model and self-organizing mapping to optimize the path the vehicle follows from the source to destination. The real-time optimal selection of the unsupervised machine learning based motion control algorithm could provide fast response times of under one microsecond during the lateral, longitudinal and angular motion control of the autonomous vehicle. However, it is shown that a simple selection of one of the machine learning methods may not guarantee the optimality of the results. The successful implementation of ASDVC controller in self-driving vehicles could have a significant contribution towards making mobility more reliable and sustainable for the future vehicular transportation systems.",https://ieeexplore.ieee.org/document/9160705/,2020 IEEE International Conference on Environment and Electrical Engineering and 2020 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe),9-12 June 2020,ieeexplore
10.1109/EEEIC/ICPSEurope49358.2020.9160705,ASDVC - A Self-Driving Vehicle Controller using Unsupervised Machine Learning,IEEE,Conferences,"ASDVC is a self-driving vehicle controller that uses unsupervised machine learning methods, namely clustering based k-means, hierarchical, Gaussian Matrix Model and self-organizing mapping to optimize the path the vehicle follows from the source to destination. The real-time optimal selection of the unsupervised machine learning based motion control algorithm could provide fast response times of under one microsecond during the lateral, longitudinal and angular motion control of the autonomous vehicle. However, it is shown that a simple selection of one of the machine learning methods may not guarantee the optimality of the results. The successful implementation of ASDVC controller in self-driving vehicles could have a significant contribution towards making mobility more reliable and sustainable for the future vehicular transportation systems.",https://ieeexplore.ieee.org/document/9160705/,2020 IEEE International Conference on Environment and Electrical Engineering and 2020 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe),9-12 June 2020,ieeexplore
10.1109/ITSC.2018.8569575,Deep Traffic Light Detection for Self-driving Cars from a Large-scale Dataset,IEEE,Conferences,"Traffic lights perception problem is one of the key challenges for autonomous vehicle controllers in urban areas. While a number of approaches for traffic light detection have been proposed, these methods often require a prior knowledge of map and/or show high false positive rates. Recent successes suggest that deep neural networks will be widely used in self-driving cars, but current public datasets do not provide sufficient amount of labels for training such large deep neural networks. In this paper, we developed a two-step computational method that can detect traffic lights from images in a real-time manner. The first step exploits a deep neural object detection architecture to fine true traffic light candidates. In the second step, a point-based reward system is used to eliminate false traffic lights out of the candidates. To evaluate the proposed approach, we collected a human-annotated large-scale traffic lights dataset (over 60 hours). We also designed a real-world experiment with an instrumented self-driving vehicle and observed that the proposed method was able to handle false traffic lights substantially better compared with the baseline considered.",https://ieeexplore.ieee.org/document/8569575/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/ICICCS51141.2021.9432186,Pothole and Object Detection for an Autonomous Vehicle Using YOLO,IEEE,Conferences,"Object Detection is an key software and a fundamental task for an autonomous driving system that provides remarkable change in computer vision. İn recent years, company's are planning to launch autonomous vehicle in an full swing that's the most important ascpets for object detection and one of most challenging task for locating specific object from from multiple objects in a specific scenario. The computer vision and machine learning algorithm is the important tool for detecting objects in and around the environment. In this paper, which consists of two parts The first part is implemented on object detection in the surrounding with Yolo (You Only Look Once)Algorithm provides exact classification and position which is configured on newly created datasets for classes of object: a car, a person, a truck, a bus, traffic light, motorcycle, pothole, wetland uses the Convolutional Neural Network and max-polling layer for prediction that improves detecting of small target and these deep learning technique provides a high accuracy for detecting real world. Detecting potholes in Indian road help the autonomous vehicle to move smoothly without getting struck in the potholes. In part two of the proposed method is implemented on Raspberry pi4 a popular embedded computer board explores suitability for the running objects. That solves the real world problems and improves the impact on detecting objects. Knowing pothole and wetland detection for self-driving vehicle is needed badly to solve the road lay problems like: accident, slowing down the transport system these are solved by deep learning.",https://ieeexplore.ieee.org/document/9432186/,2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS),6-8 May 2021,ieeexplore
10.1109/ICIP.2019.8803189,Recognizing Chinese Texts with 3D Convolutional Neural Network,IEEE,Conferences,"In this paper, we propose a deep learning system to localize and recognize Chinese texts in scenes with signage and road marks through 3D convolutional neural network. The proposed system adopts YOLO for detecting target location and exploits 3D convolutional neural network for recognizing the contents. The proposed design outperforms the existing designs based on LSTM and achieves real-time processing performance, which is feasible to be implemented on embedded platforms. The proposed system reaches over 90% accuracy in recognizing Chinese texts on bird's-eye viewing road marks in a self-driving vehicle equipped with a fisheye camera. In addition, this system can achieve 20 fps execution speed with NVIDIA DIGITS DevBox with 1080Ti GPU, which is fast enough for autonomous driving applications.",https://ieeexplore.ieee.org/document/8803189/,2019 IEEE International Conference on Image Processing (ICIP),22-25 Sept. 2019,ieeexplore
10.1109/IROS40897.2019.8967875,SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles,IEEE,Conferences,"Place recognition and loop-closure detection are main challenges in the localization, mapping and navigation tasks of self-driving vehicles. In this paper, we solve the loop-closure detection problem by incorporating the deep-learning based point cloud description method and the coarse-to-fine sequence matching strategy. More specifically, we propose a deep neural network to extract a global descriptor from the original large-scale 3D point cloud, then based on which, a typical place analysis approach is presented to investigate the feature space distribution of the global descriptors and select several super keyframes. Finally, a coarse-to-fine strategy, which includes a super keyframe based coarse matching stage and a local sequence matching stage, is presented to ensure the loop-closure detection accuracy and real-time performance simultaneously. Thanks to the sequence matching operation, the proposed approach obtains an improvement against the existing deep-learning based methods. Experiment results on a self-driving vehicle validate the effectiveness of the proposed loop-closure detection algorithm.",https://ieeexplore.ieee.org/document/8967875/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
,Vision Control Unit in Fully Self Driving Vehicles using Xilinx MPSoC and Opensource Stack,IEEE,Conferences,"Fully self-driving (FSD) vehicles are becoming increasing popular over the last few years and companies are investing significantly into its research and development. In the recent years, FSD technology innovators like Tesla, Google etc. have been working on proprietary autonomous driving stacks and have been able to successfully bring the vehicle to the roads. On the other end, organizations like Autoware Foundation and Baidu are fueling the growth of self-driving mobility using open source stacks. These organizations firmly believe in enabling autonomous driving technology for everyone and support developing software stacks through the open source community that is SoC vendor agnostic. In this proposed solution we describe a vision control unit for a fully self-driving vehicle developed on Xilinx MPSoC platform using open source software components.The vision control unit of an FSD vehicle is responsible for camera video capture, image processing and rendering, AI algorithm processing, data and meta-data transfer to next stage of the FSD pipeline. In this proposed solution we have used many open source stacks and frameworks for video and AI processing. The processing of the video pipeline and algorithms take full advantage of the pipelining and parallelism using all the heterogenous cores of the Xilinx MPSoC. In addition, we have developed an extensible, scalable, adaptable and configurable AI backend framework, XTA, for acceleration purposes that is derived from a popular, open source AI backend framework, TVM-VTA. XTA uses all the MPSoC cores for its computation in a parallel and pipelined fashion. XTA also adapts to the compute and memory parameters of the system and can scale to achieve optimal performance for any given AI problem. The FSD system design is based on a distributed system architecture and uses open source components like Autoware for autonomous driving algorithms, ROS and Distributed Data Services as a messaging middleware between the functional nodes and a real-time kernel to coordinate the actions. The details of image capture, rendering and AI processing of the vision perception pipeline will be presented along with the performance measurements of the vision pipeline.In this proposed solution we will demonstrate some of the key use cases of vision perception unit like surround vision and object detection. In addition, we will also show the capability of Xilinx MPSoC technology to handle multiple channels of real time camera and the integration with the Lidar/Radar point cloud data to feed into the decision-making unit of the overall system. The system is also designed with the capability to update the vision control unit through Over the Air Update (OTA). It is also envisioned that the core AI engine will require regular updates with the latest training values; hence a built-in platform level mechanism supporting such capability is essential for real world deployment.",https://ieeexplore.ieee.org/document/9371624/,2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC),18-21 Jan. 2021,ieeexplore
10.1109/IROS40897.2019.8967875,SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles,IEEE,Conferences,"Place recognition and loop-closure detection are main challenges in the localization, mapping and navigation tasks of self-driving vehicles. In this paper, we solve the loop-closure detection problem by incorporating the deep-learning based point cloud description method and the coarse-to-fine sequence matching strategy. More specifically, we propose a deep neural network to extract a global descriptor from the original large-scale 3D point cloud, then based on which, a typical place analysis approach is presented to investigate the feature space distribution of the global descriptors and select several super keyframes. Finally, a coarse-to-fine strategy, which includes a super keyframe based coarse matching stage and a local sequence matching stage, is presented to ensure the loop-closure detection accuracy and real-time performance simultaneously. Thanks to the sequence matching operation, the proposed approach obtains an improvement against the existing deep-learning based methods. Experiment results on a self-driving vehicle validate the effectiveness of the proposed loop-closure detection algorithm.",https://ieeexplore.ieee.org/document/8967875/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
,Vision Control Unit in Fully Self Driving Vehicles using Xilinx MPSoC and Opensource Stack,IEEE,Conferences,"Fully self-driving (FSD) vehicles are becoming increasing popular over the last few years and companies are investing significantly into its research and development. In the recent years, FSD technology innovators like Tesla, Google etc. have been working on proprietary autonomous driving stacks and have been able to successfully bring the vehicle to the roads. On the other end, organizations like Autoware Foundation and Baidu are fueling the growth of self-driving mobility using open source stacks. These organizations firmly believe in enabling autonomous driving technology for everyone and support developing software stacks through the open source community that is SoC vendor agnostic. In this proposed solution we describe a vision control unit for a fully self-driving vehicle developed on Xilinx MPSoC platform using open source software components.The vision control unit of an FSD vehicle is responsible for camera video capture, image processing and rendering, AI algorithm processing, data and meta-data transfer to next stage of the FSD pipeline. In this proposed solution we have used many open source stacks and frameworks for video and AI processing. The processing of the video pipeline and algorithms take full advantage of the pipelining and parallelism using all the heterogenous cores of the Xilinx MPSoC. In addition, we have developed an extensible, scalable, adaptable and configurable AI backend framework, XTA, for acceleration purposes that is derived from a popular, open source AI backend framework, TVM-VTA. XTA uses all the MPSoC cores for its computation in a parallel and pipelined fashion. XTA also adapts to the compute and memory parameters of the system and can scale to achieve optimal performance for any given AI problem. The FSD system design is based on a distributed system architecture and uses open source components like Autoware for autonomous driving algorithms, ROS and Distributed Data Services as a messaging middleware between the functional nodes and a real-time kernel to coordinate the actions. The details of image capture, rendering and AI processing of the vision perception pipeline will be presented along with the performance measurements of the vision pipeline.In this proposed solution we will demonstrate some of the key use cases of vision perception unit like surround vision and object detection. In addition, we will also show the capability of Xilinx MPSoC technology to handle multiple channels of real time camera and the integration with the Lidar/Radar point cloud data to feed into the decision-making unit of the overall system. The system is also designed with the capability to update the vision control unit through Over the Air Update (OTA). It is also envisioned that the core AI engine will require regular updates with the latest training values; hence a built-in platform level mechanism supporting such capability is essential for real world deployment.",https://ieeexplore.ieee.org/document/9371624/,2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC),18-21 Jan. 2021,ieeexplore
10.1109/ACCESS.2020.2990416,Deep SCNN-Based Real-Time Object Detection for Self-Driving Vehicles Using LiDAR Temporal Data,IEEE,Journals,"Real-time accurate detection of three-dimensional (3D) objects is a fundamental necessity for self-driving vehicles. Most existing computer vision approaches are based on convolutional neural networks (CNNs). Although the CNN-based approaches can achieve high detection accuracy, their high energy consumption is a severe drawback. To resolve this problem, novel energy efficient approaches should be explored. Spiking neural network (SNN) is a promising candidate because it has orders-of-magnitude lower energy consumption than CNN. Unfortunately, the studying of SNN has been limited in small networks only. The application of SNN for large 3D object detection networks has remain largely open. In this paper, we integrate spiking convolutional neural network (SCNN) with temporal coding into the YOLOv2 architecture for real-time object detection. To take the advantage of spiking signals, we develop a novel data preprocessing layer that translates 3D point-cloud data into spike time data. We propose an analog circuit to implement the non-leaky integrate and fire neuron used in our SCNN, from which the energy consumption of each spike is estimated. Moreover, we present a method to calculate the network sparsity and the energy consumption of the overall network. Extensive experiments have been conducted based on the KITTI dataset, which show that the proposed network can reach competitive detection accuracy as existing approaches, yet with much lower average energy consumption. If implemented in dedicated hardware, our network could have a mean sparsity of 56.24% and extremely low total energy consumption of 0.247mJ only. Implemented in NVIDIA GTX 1080i GPU, we can achieve 35.7 fps frame rate, high enough for real-time object detection.",https://ieeexplore.ieee.org/document/9078792/,IEEE Access,2020,ieeexplore
10.1109/EEEIC/ICPSEurope49358.2020.9160705,ASDVC - A Self-Driving Vehicle Controller using Unsupervised Machine Learning,IEEE,Conferences,"ASDVC is a self-driving vehicle controller that uses unsupervised machine learning methods, namely clustering based k-means, hierarchical, Gaussian Matrix Model and self-organizing mapping to optimize the path the vehicle follows from the source to destination. The real-time optimal selection of the unsupervised machine learning based motion control algorithm could provide fast response times of under one microsecond during the lateral, longitudinal and angular motion control of the autonomous vehicle. However, it is shown that a simple selection of one of the machine learning methods may not guarantee the optimality of the results. The successful implementation of ASDVC controller in self-driving vehicles could have a significant contribution towards making mobility more reliable and sustainable for the future vehicular transportation systems.",https://ieeexplore.ieee.org/document/9160705/,2020 IEEE International Conference on Environment and Electrical Engineering and 2020 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe),9-12 June 2020,ieeexplore
10.1109/IV47402.2020.9304778,"Autonomous Driving Vehicle Control Auto-Calibration System: An Industry-Level, Data-Driven and Learning-based Vehicle Longitudinal Dynamic Calibrating Algorithm",IEEE,Conferences,"The control module is a crucial part for autonomous driving systems, a typical control algorithm often requires vehicle dynamics (such as longitudinal dynamics) as inputs, which, unfortunately are difficult to calibrate in real time. Further, it is also a challenge to reflect instantaneous changes in longitudinal dynamics (e.g. load changes) using a calibration table. As a result, control performance may deteriorate when load changes considerably (especially for small cargoes). In this paper, we will show how we build a data-driven longitudinal calibration procedure using machine learning techniques to adapt load changes in real time. We first generated offline calibration tables from human driving data. The offline table serves as an initial guess for later uses, and it only requires twenty minutes of data collection and processing. We then used an online learning algorithm to appropriately update the initial table (the offline table) based on real-time performance analysis. Experiments indicated (a) offline auto-calibration leads to a better control accuracy, compared with manual calibration; (b) online auto-calibration is capable to handle load changes and significantly reduce real time control error. This system has been deployed to more than one hundred Baidu self-driving vehicles (both hybrid and electronic vehicles) since April 2018. By January 2019, the system had been tested for more than 2,000 hours and over 10,000 kilometers (6,213 miles) and was still proven to be effective.",https://ieeexplore.ieee.org/document/9304778/,2020 IEEE Intelligent Vehicles Symposium (IV),19 Oct.-13 Nov. 2020,ieeexplore
10.1109/EIT.2018.8500102,Behavioral Cloning for Lateral Motion Control of Autonomous Vehicles Using Deep Learning,IEEE,Conferences,"Current trend of the automotive industry combined with research by the major tech companies has proved that self-driving vehicles are the future. With successful demonstration of neural network based autonomous driving, NVIDIA has introduced a new paradigm for autonomous driving software. The biggest challenge for self-driving cars is autonomous lateral control. An end-to-end model seems very promising in providing a complete software stack for autonomous driving. Although this system is not ready to be provided as a feature in the market today, it is one of the many steps in the right direction to make self-driving cars a reality. The work described in this paper focusses on how an end-to-end model is implemented. The subtleties of training a successful end-to-end model are highlighted with the aim of providing an insight on deep learning and software required for neural network training. Detailed analyses of data acquisition and training systems are provided and installation procedures for all required tools and software discussed. TORCS is used for developing and testing the end-to-end model. Approximately ten hours of driving data was collected from two different tracks. Using four hours of data from a track, we trained a deep neural network to steer a car inside simulation. Even with such a small training set, the end-to-end model developed demonstrated capabilities to maintain lanes and complete laps in different tracks. For a multilane track, like the one used for training, the model demonstrated an autonomy of 96.62%. For single lane unknown tracks, the model steered the vehicle successfully for 89.02% of the time. The results indicate that end-to-end learning and behavioral cloning can be used to drive autonomously in new and unknown scenarios.",https://ieeexplore.ieee.org/document/8500102/,2018 IEEE International Conference on Electro/Information Technology (EIT),3-5 May 2018,ieeexplore
10.23919/ECC51009.2020.9143756,Deep Traffic Light Perception with Spatiotemporal Analysis for Autonomous Driving,IEEE,Conferences,"Traffic light perception is crucial for autonomous driving. In this paper, a three-step method for traffic-light detection, recognition and understanding is developed to guide self-driving vehicles to pass crossroads. The first step adopts a state-of-the-art deep neural object detection architecture to detect traffic lights. The second step designs a novel four-channel convolutional neural network to classify traffic lights. The last step develops a spatiotemporal trajectory analysis method to filter out false positives and to guide self-driving vehicles. The proposed method is evaluated on two datasets, and experiment results show that it can efficiently perceive traffic-light states and perform better than baseline considered. Furthermore, real vehicle testings are conducted, which demonstrate the effectiveness of the proposed method.",https://ieeexplore.ieee.org/document/9143756/,2020 European Control Conference (ECC),12-15 May 2020,ieeexplore
10.1109/ICSPIS48872.2019.9066130,Deep Vision for Navigation of Autonomous Motorcycle in Urban and Semi-Urban Environments,IEEE,Conferences,"Deep neural networks are currently the best solution for road and traffic scene interpretation for autonomous and self-driving vehicles. Compared to the autonomous cars, motorcycles have significant flexibility and advantages in crowded traffic situations and especially in non-urban and off-road areas. Many off-road tracks especially for agriculture and environment management tasks are only traversable with motorcycles. In this paper, a deep neural network is used for design and implementation of the vision system for navigation of an autonomous motorcycle. The proposed framework is evaluated using real world scenarios captured by a real motorcycle in various complex situations. The experimental results show that the proposed framework is capable of highly accurate interpretation of various environments for autonomous navigation of a motorcycle.",https://ieeexplore.ieee.org/document/9066130/,2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS),18-19 Dec. 2019,ieeexplore
10.1109/ICMLA51294.2020.00201,Defending Against Localized Adversarial Attacks on Edge-Deployed Monocular Depth Estimators,IEEE,Conferences,"Estimation of depth from a single image is an important scene understanding task in computer vision. With the advent of Deep Learning and Convolutional Neural Networks, staggeringly high accuracies have been achieved in this task. With advancements in model optimization, it has been possible to deploy these models on edge devices, allowing for efficient depth estimation in safety-critical applications in robots, rovers, drones and even self-driving vehicles. However, these models are susceptible to attacks from malicious adversaries, which aim to distort the output of the model for a seemingly clean image by adding minute perturbations. In the real-world scenario, the most plausible attack is the adversarial patch, which can be printed and used as a physical adversarial attack against Deep Learning models. In the case of Monocular Depth Estimation, we show that small adversarial patches, which range from 0.7% to 5% of the image size, greatly worsen model performance. It is thus essential that these models are made robust using defense mechanisms, to defend against malicious inputs while also not reducing performance on clean images. Moreover, it is essential that the defense mechanism be computationally efficient, for real-time inference on edge devices. In this work, we propose the first defense mechanism against adversarial patches for a regression network, in the context of Monocular Depth Estimation on an edge device. The defense mechanism adds very little overhead time of 38 milliseconds on a Raspberry Pi 3 Model B, maintaining performance on clean images while also achieving near clean image levels of performance on adversarial inputs.",https://ieeexplore.ieee.org/document/9356303/,2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),14-17 Dec. 2020,ieeexplore
10.1109/MECO.2019.8760130,Facilitating Near Real Time Analytics on the Edge,IEEE,Conferences,"Internet of Things (IoT) is revolutionizing the way how information is processed and stored. Due to latency sensitive applications and huge amounts of data produced at the edge of the network, more and more data is processed where it is produced - namely on the edge. This development results in completely new network topologies where besides massive data centers we experience growing amount of so called micro data centers on the edge of the network. However, increasing complexity of multiple data centers necessary to execute an application represents a new challenge for the deployment and runtime operation of large scale applications like those in the area of smart cities, self-driving vehicles and tele medicine. The challenge thereby is to deploy application in a way to satisfy user requirements in form of different Quality of Service parameters (e.g., latency) but at the same time minimize energy consumption necessary to execute the application. In this talk we discuss several research challenges that arise when deploying near real time analytics on the edge of the network.",https://ieeexplore.ieee.org/document/8760130/,2019 8th Mediterranean Conference on Embedded Computing (MECO),10-14 June 2019,ieeexplore
10.1109/CDC40024.2019.9029916,From self-tuning regulators to reinforcement learning and back again,IEEE,Conferences,"Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.",https://ieeexplore.ieee.org/document/9029916/,2019 IEEE 58th Conference on Decision and Control (CDC),11-13 Dec. 2019,ieeexplore
10.1049/icp.2021.0831,Object detection tool for self-driving 3-D printed electrical vehicles,IET,Conferences,"Self-driving electrical vehicles are projected to play an increasingly important role in the urban development of smart cities in the near future. These intelligent vehicles can be rented on demand in a shared economy, reducing both traffic accidents and road congestion, while reducing fuel consumption allowing for a greener footprint. The primary objective of this work is to first introduce the concept of a 3-D printed self-driving electrical vehicle, which can be utilized on the campus grounds of the American University of the Middle East (AUM) in Kuwait for shuttling students between buildings on demand. Secondly, the work will focus on the object detection tool utilized in the self-driving portion of the project. A comprehensive study of the various software algorithms and hardware platforms is performed, while taking computational speed, power consumption and object detection algorithm accuracy into consideration. In particular, the research presented herein will survey recent developments in the field of deep learning algorithms for self-driving vehicles, coupled with high speed graphical processing units (GPUs) for real-time implementation. A representative example of the former in this work is the you only look once (YOLO) algorithm for object detection, while a representative example of the latter is the Jetson AGX Xavier NVIDIA GPU.",https://ieeexplore.ieee.org/document/9545550/,3rd Smart Cities Symposium (SCS 2020),21-23 Sept. 2020,ieeexplore
10.1109/WCNC.2019.8886037,Pedestrian Detection for Autonomous Driving within Cooperative Communication System,IEEE,Conferences,"The ability to perceive and understand surrounding road-users behaviors is crucial for self-driving vehicles to correctly plan reliable reactions. Computer vision that relies mostly on machine learning techniques enables autonomous vehicles to perform several required tasks such as pedestrian detection. Furthermore, within a fully autonomous driving environment, driverless vehicle has to communicate and share perceived data with its neighboring vehicles for more safe navigation. In this context, our paper proposes a warning notification diffusion solution related to real-time pedestrian presence detection, through an inter-vehicle communication system. To achieve this purpose, pedestrian and vehicle recognition is required. Thus, we implemented intended detectors. We used Histogram of Oriented Gradients (HOG) descriptor with the linear Support Vector Machine (SVM) classifier for the pedestrian detector, and Haar feature-based cascade classifier to reach vehicle detection. The performance evaluation of our solution leads to fairly good detection accuracy around 90% for pedestrian and 88% for vehicle.",https://ieeexplore.ieee.org/document/8886037/,2019 IEEE Wireless Communications and Networking Conference (WCNC),15-18 April 2019,ieeexplore
10.1109/IROS40897.2019.8967875,SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles,IEEE,Conferences,"Place recognition and loop-closure detection are main challenges in the localization, mapping and navigation tasks of self-driving vehicles. In this paper, we solve the loop-closure detection problem by incorporating the deep-learning based point cloud description method and the coarse-to-fine sequence matching strategy. More specifically, we propose a deep neural network to extract a global descriptor from the original large-scale 3D point cloud, then based on which, a typical place analysis approach is presented to investigate the feature space distribution of the global descriptors and select several super keyframes. Finally, a coarse-to-fine strategy, which includes a super keyframe based coarse matching stage and a local sequence matching stage, is presented to ensure the loop-closure detection accuracy and real-time performance simultaneously. Thanks to the sequence matching operation, the proposed approach obtains an improvement against the existing deep-learning based methods. Experiment results on a self-driving vehicle validate the effectiveness of the proposed loop-closure detection algorithm.",https://ieeexplore.ieee.org/document/8967875/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/OJITS.2020.3027146,A Plausibility-Based Fault Detection Method for High-Level Fusion Perception Systems,IEEE,Journals,"Trustworthy environment perception is the fundamental basis for the safe deployment of automated agents such as self-driving vehicles or intelligent robots. The problem remains that such trust is notoriously difficult to guarantee in the presence of systematic faults, e.g., non-traceable errors caused by machine learning functions. One way to tackle this issue without making rather specific assumptions about the perception process is plausibility checking. Similar to the reasoning of human intuition, the final outcome of a complex black-box procedure is verified against given expectations of an object's behavior. In this article, we apply and evaluate collaborative, sensor-generic plausibility checking as a mean to detect empirical perception faults from their statistical fingerprints. Our real use case is next-generation automated driving that uses a roadside sensor infrastructure for perception augmentation, represented here by test scenarios at a German highway and a city intersection. The plausibilization analysis is integrated naturally in the object fusion process, and helps to diagnose known and possibly yet unknown faults in distributed sensing systems.",https://ieeexplore.ieee.org/document/9207739/,IEEE Open Journal of Intelligent Transportation Systems,2020,ieeexplore
10.1109/ACCESS.2020.2990416,Deep SCNN-Based Real-Time Object Detection for Self-Driving Vehicles Using LiDAR Temporal Data,IEEE,Journals,"Real-time accurate detection of three-dimensional (3D) objects is a fundamental necessity for self-driving vehicles. Most existing computer vision approaches are based on convolutional neural networks (CNNs). Although the CNN-based approaches can achieve high detection accuracy, their high energy consumption is a severe drawback. To resolve this problem, novel energy efficient approaches should be explored. Spiking neural network (SNN) is a promising candidate because it has orders-of-magnitude lower energy consumption than CNN. Unfortunately, the studying of SNN has been limited in small networks only. The application of SNN for large 3D object detection networks has remain largely open. In this paper, we integrate spiking convolutional neural network (SCNN) with temporal coding into the YOLOv2 architecture for real-time object detection. To take the advantage of spiking signals, we develop a novel data preprocessing layer that translates 3D point-cloud data into spike time data. We propose an analog circuit to implement the non-leaky integrate and fire neuron used in our SCNN, from which the energy consumption of each spike is estimated. Moreover, we present a method to calculate the network sparsity and the energy consumption of the overall network. Extensive experiments have been conducted based on the KITTI dataset, which show that the proposed network can reach competitive detection accuracy as existing approaches, yet with much lower average energy consumption. If implemented in dedicated hardware, our network could have a mean sparsity of 56.24% and extremely low total energy consumption of 0.247mJ only. Implemented in NVIDIA GTX 1080i GPU, we can achieve 35.7 fps frame rate, high enough for real-time object detection.",https://ieeexplore.ieee.org/document/9078792/,IEEE Access,2020,ieeexplore
10.1109/ICSSE52999.2021.9538460,Steering Angle Estimation for Self-driving Car Based on Enhanced Semantic Segmentation,IEEE,Conferences,"Common approaches for semantic segmentation using Convolutional Neural Networks (CNN) based around conventional U-shapes architectures were widely used. However, failures to retrieve global context information and memory issues made such models unable to compete against modern architectures considering accuracy and real-time capability. In this paper, an efficient method maintaining equivalent accuracy of a previous segmentation network and skillfully making a model more light-weighted for real-time inference was proposed. More concretely, we managed to alleviate five out of 17 million trainable parameters, which effectively reduce the amount of computation of the original PSPNet by 30% using the backbone of CSPNet. Our proposed network implementation achieved 73 mIoU scores on our custom dataset and reached 15 fps regarding real-time inference. We deployed the trained model on the multifunctional hardware and then connected it to a golf car to jointly navigate the natural environment and traffic sign detection task. Accordingly, the STM32 board and servo motor were used for controlling the steering wheel through a track-and-wheel drive system. As for the traffic sign detection task, we employed a small-size Yolov5 trained on the TT100K dataset running around 60fps and attained real-time performance with sufficient accuracy.",https://ieeexplore.ieee.org/document/9538460/,2021 International Conference on System Science and Engineering (ICSSE),26-28 Aug. 2021,ieeexplore
10.1109/AIVR.2018.00062,A Combination of Feedback Control and Vision-Based Deep Learning Mechanism for Guiding Self-Driving Cars,IEEE,Conferences,"The purpose of this paper is to develop an agent that can imitate the behavior of humans driving a car. When human beings driving a car, he/she majorly uses vision system to recognize the states of the car, including the position, velocity, and the surrounding environments. In this paper, we implemented a self-driving car which can drive itself on the track of a simulator. The self-driving car uses deep neural network as a computational framework to ""learn"" what is the position of the car related to the road. While the car understands the position of itself related to the track, it can use the information as a basis for feedback control.",https://ieeexplore.ieee.org/document/8613681/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/ICIIP47207.2019.8985977,Comparative Analysis and Implementation of Different Human Detection Techniques,IEEE,Conferences,"Object Detection is used in making several smart surveillance applications which are used in detecting and tracking suspicious activities. Object Detection also plays a very crucial role in several latest inventions like the Google self-driving car. Over the past decade several image processing algorithms have evolved which have been used for human detection after preprocessing of the images. But in several cases these algorithms were found to be less accurate and more time taking. With the advent of the era of Machine Learning, the focus has gradually shifted towards computer vision and deep learning methodologies for human detection. Deep learning algorithms are far more accurate than the traditional methodologies as they employ feature extraction from the images followed by classification according to the dataset provided to them, thus enabling more accurate detection than their ancestors. Nevertheless its also true that some deep learning algorithms like the different versions of R-CNN and YOLO take much more processing time than the traditional methodologies. In our paper we have compared the performance of some traditional and some deep learning algorithms in different scenarios.",https://ieeexplore.ieee.org/document/8985977/,2019 Fifth International Conference on Image Information Processing (ICIIP),15-17 Nov. 2019,ieeexplore
10.1145/3180155.3180220,DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars,IEEE,Conferences,"Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.",https://ieeexplore.ieee.org/document/8453089/,2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE),27 May-3 June 2018,ieeexplore
10.1109/INFOCOM.2019.8737614,Dynamic Adaptive DNN Surgery for Inference Acceleration on the Edge,IEEE,Conferences,"Recent advances in deep neural networks (DNNs) have substantially improved the accuracy and speed of a variety of intelligent applications. Nevertheless, one obstacle is that DNN inference imposes heavy computation burden to end devices, but offloading inference tasks to the cloud causes transmission of a large volume of data. Motivated by the fact that the data size of some intermediate DNN layers is significantly smaller than that of raw input data, we design the DNN surgery, which allows partitioned DNN processed at both the edge and cloud while limiting the data transmission. The challenge is twofold: (1) Network dynamics substantially influence the performance of DNN partition, and (2) State-of-the-art DNNs are characterized by a directed acyclic graph (DAG) rather than a chain so that partition is greatly complicated. In order to solve the issues, we design a Dynamic Adaptive DNN Surgery (DADS) scheme, which optimally partitions the DNN under different network condition. Under the lightly loaded condition, DNN Surgery Light (DSL) is developed, which minimizes the overall delay to process one frame. The minimization problem is equivalent to a min-cut problem so that a globally optimal solution is derived. In the heavily loaded condition, DNN Surgery Heavy (DSH) is developed, with the objective to maximize throughput. However, the problem is NP-hard so that DSH resorts an approximation method to achieve an approximation ratio of 3. Real-world prototype based on self-driving car video dataset is implemented, showing that compared with executing entire the DNN on the edge and cloud, DADS can improve latency up to 6.45 and 8.08 times respectively, and improve throughput up to 8.31 and 14.01 times respectively.",https://ieeexplore.ieee.org/document/8737614/,IEEE INFOCOM 2019 - IEEE Conference on Computer Communications,29 April-2 May 2019,ieeexplore
10.1109/ICCE-Berlin.2018.8576190,End to End Learning based Self-Driving using JacintoNet,IEEE,Conferences,"Automated driving functions, like highway driving and parking assist, are getting increasing deployed in high-end cars with the trend moving towards the self-driving car. With the advent of deep learning, many traditional computer vision techniques have been replaced by deep convolutional neural networks (CNN). End to end learning is one of the paradigm for self-driving, in which user provides a input images from the front facing camera to the given neural network and the network outputs the car control signals such as throttle, steering and braking. The paper proposes an embedded friendly convolutional neural network, `Jacintonet', to demonstrate self-driving using end to end learning paradigm in a virtual simulation environment. Paper discusses key learning during the training methodology and presents the results on embedded platform. Texas Instruments (TI) TDA2x System on Chip (SoC) is used as embedded platform for running `Jacintonet', real-time to demonstrate self-driving car in the virtual simulator.",https://ieeexplore.ieee.org/document/8576190/,2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin),2-5 Sept. 2018,ieeexplore
10.1109/SysCon48628.2021.9447097,Experimental Validation of a Steering Control System using an Adaptive Fuzzy Controller and Computer Vision,IEEE,Conferences,"This paper proposes an adaptive steering control strategy for self-driving cars based on a Fuzzy Expert System and Reinforcement Learning. Our objective consists in deriving an appropriate control law directly from a real vehicle that allows it to navigate on several types of lanes, by controlling the position in relation to the center of the tracks and also the translation speed of the vehicle. Using an on-line Reinforcement Learning approach, the Fuzzy expert controller is derived considering the coupling and non-linearity of the model on straight and winding tracks. To do this, an embedded camera captures the images and sends them to the computer vision algorithm responsible for performing tracks detection and recognition. From that, the control references which indicate the navigation path and direction on the lane are calculated. The main contribution of this work is to apply an online reinforcement learning approach to tune and optimize the fuzzy steering controller while the vehicle navigates through different routes. Using a real vehicle equipped with an embedded computer and also the implemented web user interface, the learning evolution of the adaptive fuzzy controller can be managed remotely during trial in actual environments. Experimental results showed that the learned fuzzy expert controller controls the self-driving car during the path tracking and precisely performs the execution of different maneuvers.",https://ieeexplore.ieee.org/document/9447097/,2021 IEEE International Systems Conference (SysCon),15 April-15 May 2021,ieeexplore
10.1109/ISQED.2018.8357325,Low cost and power CNN/deep learning solution for automated driving,IEEE,Conferences,"Automated driving functions, like highway driving and parking assist, are increasingly getting deployed in high-end cars with the ultimate goal of realizing self-driving car using Deep learning techniques like convolution neural network (CNN). For mass-market deployment, the embedded solution is required to address the right cost and performance envelope along with security and safety. In the case of automated driving, one of the key functionality is “finding drivable free space”, which is addressed using deep learning techniques like CNN. These CNN networks pose huge computing requirements in terms of hundreds of GOPS/TOPS (Giga or Tera operations per second), which seems beyond the capability of today's embedded SoC. This paper covers various techniques consisting of fixed-point conversion, sparse multiplication, fusing of layers and network pruning, for tailoring on the embedded solution. These techniques are implemented on the device by means of optimized Deep learning library for inference. The paper concludes by demonstrating the results of a CNN network running in real time on TI's TDA2X embedded platform producing a high-quality drivable space output for automated driving.",https://ieeexplore.ieee.org/document/8357325/,2018 19th International Symposium on Quality Electronic Design (ISQED),13-14 March 2018,ieeexplore
10.1109/ITSC.2018.8569665,Monocular Fisheye Camera Depth Estimation Using Sparse LiDAR Supervision,IEEE,Conferences,"Near-field depth estimation around a self-driving car is an important function that can be achieved by four wide-angle fisheye cameras having a field of view of over 180°. Depth estimation based on convolutional neural networks (CNNs) produce state of the art results, but progress is hindered because depth annotation cannot be obtained manually. Synthetic datasets are commonly used but they have limitations. For instance, they do not capture the extensive variability in the appearance of objects like vehicles present in real datasets. There is also a domain shift while performing inference on natural images illustrated by many attempts to handle the domain adaptation explicitly. In this work, we explore an alternate approach of training using sparse LiDAR data as ground truth for depth estimation for fisheye camera. We built our own dataset using our self-driving car setup which has a 64-beam Velodyne LiDAR and four wide angle fisheye cameras. To handle the difference in view-points of LiDAR and fisheye camera, an occlusion resolution mechanism was implemented. We started with Eigen's multiscale convolutional network architecture [1] and improved by modifying activation function and optimizer. We obtained promising results on our dataset with RMSE errors comparable to the state-of-the-art results obtained on KITTI.",https://ieeexplore.ieee.org/document/8569665/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/SAMI50585.2021.9378655,Psychophysiological modelling of trust in technology: Comparative analysis of algorithm ensemble methods,IEEE,Conferences,"Measuring user's trust in technology in real-time using psychophysiological signals depends on the availability of stable, accurate, variance sensitive, and non-bias trust classifier model which can be achieved through ensembling several algorithms. Prior efforts resulted to fairly accurate but unstable models. This article investigates what ensemble method is most suitable for developing an ensemble trust classifier model for assessing users trust in technology with psychophysiological signals. Using a self-driving car game, a within subject four condition experiment was implemented. During which 31 participant were involved, and multimodal psychophysiological data (EEG, ECG, EDA, and Facial-EMG) were recorded. An exhaustive 172 features from time and frequency domain were extracted. Six carefully selected algorithms were combined for developing ensemble trust classifier models using each of the four ensemble methods (voting, bagging, stacking, boosting). The result indicated that the Stack ensemble method was more superior, despite voting method dominating prior studies.",https://ieeexplore.ieee.org/document/9378655/,2021 IEEE 19th World Symposium on Applied Machine Intelligence and Informatics (SAMI),21-23 Jan. 2021,ieeexplore
10.1109/ACMI53878.2021.9528185,Speed Bump &amp; Pothole Detection with Single Shot MultiBox Detector Algorithm &amp; Speed Control for Autonomous Vehicle,IEEE,Conferences,"The development of self-driving cars has always been an extensive research field for the automobile industry. To make a capable self-driving car, many challenges need to be resolved. Detection of the road condition is one of them. This paper focuses on a particular part-detection of speed bumps and potholes using a camera and analyzing the video feed with the help of artificial intelligence. To solve this problem a popular and lightweight algorithm, SSD (Single Shot Multibox Detector) is used. This is an optimal choice because of being lightweight and also accurate enough to run on mobile devices and to use in real-life situations. For detecting speed bumps and potholes, a dataset has been created based on the road structure of Bangladesh as the main priority of this system is to work on the local environment. Raspberry Pi has been used as the main processing unit because of being small but powerful. A warning system has been implemented so that it can warn the onboard driver about the upcoming pothole or speed bump. This system can also send a signal to the speed controller unit of the car to reduce the speed on detection to avoid accidents or damages to the car. The speed control unit is a microcontroller-based system that uses an ATmega328 microcontroller and L298 motor driver. This paper summarizes the combination of an artificial intelligence-based detection system injunction with a microcontroller-based speed control system in a cost-effective way that can be used in building self-driving cars.",https://ieeexplore.ieee.org/document/9528185/,"2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 (ACMI)",8-9 July 2021,ieeexplore
10.1109/Ubi-Media.2019.00014,The Matter of Deep Reinforcement Learning Towards Practical AI Applications,IEEE,Conferences,"Reinforcement Learning (RL) is an extraordinarily paradigm that aims to solve a complex problem. This technique leverages the traditional feedforward networks with temporal-difference learning to overcome supervised and unsupervised real-world problems. However, RL is one of state-of-the-art topic due to the opaque aspects in design and implementation. Also, in which situation we will get performance gain from RL is still unclear. Therefore, This study firstly examines the impact of Experience Replay in Deep Q-Learning agent with Self-Driving Car application. Secondly, The impact of Eligibility Trace in RNN A3C agents with Breakout AI game application is studied. Our results indicated that these two techniques enhance RL performance by more than 20 percent as compared with traditional RL methods.",https://ieeexplore.ieee.org/document/9049567/,2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media),5-8 Aug. 2019,ieeexplore
10.1109/IVS.2019.8813870,A Cloud-Based AI Framework for Machine Learning Orchestration: A “Driving or Not-Driving” Case-Study for Self-Driving Cars,IEEE,Conferences,"Self-driving cars rely on a plethora of algorithms in order to perform safe driving manoeuvres. Training those models is expensive (e.g. hardware cost, storage, energy) and requires continuous updates. This paper proposes a cloud-based framework for continuous training of self-driving AI models. In addition to training standalone models, the framework is capable of leveraging pre-trained models in expediting the training on environment changes (e.g. new driver or new car model). As use-case, this paper focuses on a driver's behaviour while the vehicle's control is being transferred between the driver and the self-driving AI. A human driver can hand over the control of a vehicle's driving tasks to an automated system, when that system's confidence level is high enough. Reciprocally, there are situations where that control has to be handed back to the human driver. This paper proposes a novel real-time system for Driving Not-Driving (DND) detection, which is able to capture the ability of the driver to re-take control of a vehicle when the automated driving system transitions from a higher to a lower level of automation (e.g. L3 to L2 vehicle automation). We are using a computer vision-based Driver Monitoring System (DMS) that captures in real-time head and eye movements. These are captured in the car and transferred to the cloud where a DND model is trained for a specific driver. The DND classification model is deployed in the vehicle and predicts if the driver is ready or not to resume control at a given time. The cloud-based framework proposed in this paper shows an end-to-end cycle of collecting, training and deploying self-driving AI technology, with the additional features of continuous and transfer learning.",https://ieeexplore.ieee.org/document/8813870/,2019 IEEE Intelligent Vehicles Symposium (IV),9-12 June 2019,ieeexplore
10.1109/AIVR.2018.00062,A Combination of Feedback Control and Vision-Based Deep Learning Mechanism for Guiding Self-Driving Cars,IEEE,Conferences,"The purpose of this paper is to develop an agent that can imitate the behavior of humans driving a car. When human beings driving a car, he/she majorly uses vision system to recognize the states of the car, including the position, velocity, and the surrounding environments. In this paper, we implemented a self-driving car which can drive itself on the track of a simulator. The self-driving car uses deep neural network as a computational framework to ""learn"" what is the position of the car related to the road. While the car understands the position of itself related to the track, it can use the information as a basis for feedback control.",https://ieeexplore.ieee.org/document/8613681/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/ITSC.2017.8317627,Cognitive map-based model: Toward a developmental framework for self-driving cars,IEEE,Conferences,"End-to-end learning and multi-sensor fusion-based methods are two major frameworks used for self-driving cars. To enable these intelligence vehicles to acquire driving skills at a level comparable to that of human drivers, long short-term memory of previous self-driving processes is necessary, but is difficult to introduce into the above-mentioned frameworks. In this paper, we propose a model for self-driving cars called the cognitive map-based neural network (CMNN). Our framework consists of three parts: a convolutional neural network that can perceive the environment in the manner that the human visual cortex does, a cognitive map to describe the locations of objects in a complex traffic scene and the relationships among them, and a recurrent neural network to process long short-term memory from the cognitive map, which is updated in real time. The proposed model is built to simultaneously handle three tasks: i) detecting free space and lane boundaries, ii) estimating vehicle pose and obstacle distance, and iii) learning to plan and control based on the behaviors of a human driver. More significantly, our approach introduces external instructions during an end-to-end driving process. To test it, we created a large-scale road vehicle dataset (RVD) containing more than 50,000 labeled road images captured by three cameras. We implemented the proposed model on an embedded system.",https://ieeexplore.ieee.org/document/8317627/,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),16-19 Oct. 2017,ieeexplore
10.1109/ITSC.2018.8569575,Deep Traffic Light Detection for Self-driving Cars from a Large-scale Dataset,IEEE,Conferences,"Traffic lights perception problem is one of the key challenges for autonomous vehicle controllers in urban areas. While a number of approaches for traffic light detection have been proposed, these methods often require a prior knowledge of map and/or show high false positive rates. Recent successes suggest that deep neural networks will be widely used in self-driving cars, but current public datasets do not provide sufficient amount of labels for training such large deep neural networks. In this paper, we developed a two-step computational method that can detect traffic lights from images in a real-time manner. The first step exploits a deep neural object detection architecture to fine true traffic light candidates. In the second step, a point-based reward system is used to eliminate false traffic lights out of the candidates. To evaluate the proposed approach, we collected a human-annotated large-scale traffic lights dataset (over 60 hours). We also designed a real-world experiment with an instrumented self-driving vehicle and observed that the proposed method was able to handle false traffic lights substantially better compared with the baseline considered.",https://ieeexplore.ieee.org/document/8569575/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/ICECCE49384.2020.9179457,Limitations of Feature-Classifier Strategies on Pedestrian Detection for Self Driving Cars,IEEE,Conferences,"Evolutionary enhancements are involved by deep learning in computer vision for getting better performance at human-computer interaction. One of the subjects that are known as Pedestrian Detection (PD), is criticized with a lot of problems that are needed to be solved for autonomous cars. Although a significant amount of work has been done for solving these problems, the outcomes have not satisfied the needs of PD. The shortcomings are mainly attributed to datasets, which are believed to be extended significantly to cover real-life scenarios, and utilizing systems, which seem to fail to cover challenging cases due to high dependence on parameters and low generalization capacity. For solving these problems, extensive datasets are collected and existing annotations are updated. More complex and advanced detection/classification systems are developed. Although higher accuracies can be achieved, such datasets and models cause further problems in real-time operation. Accordingly, this study focuses on PD and provides insights from multiple challenging perspectives. First, the main goal is building models for Alpha Development Board, which is constructed for Advanced Driver Assistance Systems. Since the use of deep models is still not easy to be executed on dedicated hardware, as a second step, one of the most used approaches to boost PD performance, well-established hand-crafted feature-classifier combinations, are implemented. Third, the implemented methods are applied to recent datasets to observe the performance as well as inter-dataset dependency. The results show that, albeit being complementary, different feature-classifier pairs can only provide acceptable accuracy for cases that do not include any challenging scenarios.",https://ieeexplore.ieee.org/document/9179457/,"2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE)",12-13 June 2020,ieeexplore
10.1109/ICICICT46008.2019.8993293,Real-time Traffic Light Detection and Recognition based on Deep RetinaNet for Self Driving Cars,IEEE,Conferences,"Self-driving cars are getting more popularized nowadays due to its safe, convenient and congestion free transportability. Most of the real-time challenges for autonomous driving like recognizing traffic lights, traffic signs, pedestrians are being accurately addressed by the newer state-of-the-art algorithms based on Deep Learning. Recent technological advancements in cloud computing and the availability of high-end cloud-based Graphical Processing Units (GPU) accelerated the development of AI algorithms substantially. For real time detection and recognition of traffic lights, we propose RetinaNet (a deep neural network architecture) based model through transfer learning. The deep neural network RetinaNet was used as model and the system was implemented in Keras with TensorFlow backend in Google Colaboratory cloud platform. The RetinaNet model was trained and evaluated on Bosch Small Traffic Light Dataset containing traffic light images of resolution 1280 by 720 pixels, which falls under four type of classes. The model achieved improved accuracy of detection and classification than other deep learning methods for real-time operation.",https://ieeexplore.ieee.org/document/8993293/,"2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)",5-6 July 2019,ieeexplore
10.1109/CSCI51800.2020.00117,Self Driving Cars: All You Need to Know,IEEE,Conferences,"Self-driving cars are coming closer and closer to being fact not fiction, but are we ready for them? In this research we analyze the current status in place for self-driving cars. We address the gaps that need to be filled, and we identify the questions that need to be answered before having self-driving cars on the road becomes a reality. Towards this, we discuss four issues with self-driving: policies, safety, security, and psychological acceptability of users. Our research will help individuals understand different aspects of self-driving cars and their benefits and challenges. Our paper will educate policymakers on the areas that need to be addressed before we deploy self-driving cars on the roads in a larger scale.",https://ieeexplore.ieee.org/document/9458101/,2020 International Conference on Computational Science and Computational Intelligence (CSCI),16-18 Dec. 2020,ieeexplore
10.1109/INMIC.2018.8595684,Self-Driving Cars Using CNN and Q-Learning,IEEE,Conferences,"DrivingMatter is an experiment carried out to understand the deeper side of an autonomous car. In 1900s, idea was to drive car on Moon from Earth. This was initial motivation which grew from there and now expanding to complex system of roads in the real world. A book-sized Raspberry Pi based autonomous car is built to carry out the experiment on hardware. Software side was accomplished by developing a Python based library for controlling and communicating with car over a network or locally within the car. For environment learning two methodologies are practiced; Supervised learning: Drove the car on an environment/road and collected 3, 000+ data-points. Based on this a CNN model was trained which achieved 73 % test 89 % train accuracy. Reinforcement learning: Car is trained for three different road signs; Stop, No left, and Traffic light using DQN with existing CNN model. These road signs are detected in the environment using OpenCV cascade classifiers.",https://ieeexplore.ieee.org/document/8595684/,2018 IEEE 21st International Multi-Topic Conference (INMIC),1-2 Nov. 2018,ieeexplore
10.1109/IVS.2019.8813870,A Cloud-Based AI Framework for Machine Learning Orchestration: A “Driving or Not-Driving” Case-Study for Self-Driving Cars,IEEE,Conferences,"Self-driving cars rely on a plethora of algorithms in order to perform safe driving manoeuvres. Training those models is expensive (e.g. hardware cost, storage, energy) and requires continuous updates. This paper proposes a cloud-based framework for continuous training of self-driving AI models. In addition to training standalone models, the framework is capable of leveraging pre-trained models in expediting the training on environment changes (e.g. new driver or new car model). As use-case, this paper focuses on a driver's behaviour while the vehicle's control is being transferred between the driver and the self-driving AI. A human driver can hand over the control of a vehicle's driving tasks to an automated system, when that system's confidence level is high enough. Reciprocally, there are situations where that control has to be handed back to the human driver. This paper proposes a novel real-time system for Driving Not-Driving (DND) detection, which is able to capture the ability of the driver to re-take control of a vehicle when the automated driving system transitions from a higher to a lower level of automation (e.g. L3 to L2 vehicle automation). We are using a computer vision-based Driver Monitoring System (DMS) that captures in real-time head and eye movements. These are captured in the car and transferred to the cloud where a DND model is trained for a specific driver. The DND classification model is deployed in the vehicle and predicts if the driver is ready or not to resume control at a given time. The cloud-based framework proposed in this paper shows an end-to-end cycle of collecting, training and deploying self-driving AI technology, with the additional features of continuous and transfer learning.",https://ieeexplore.ieee.org/document/8813870/,2019 IEEE Intelligent Vehicles Symposium (IV),9-12 June 2019,ieeexplore
10.1109/IOLTS52814.2021.9486704,A Suitability Analysis of Software Based Testing Strategies for the On-line Testing of Artificial Neural Networks Applications in Embedded Devices,IEEE,Conferences,"Electronic devices based on artificial intelligence solutions are pervading our everyday life. Nowadays, human decision processes are supported by real-time data gathered from intelligent systems. Artificial Neural Networks (ANNs) are one of the most used deep learning predictive models due to their outstanding computational capabilities. However, assessing their reliability is still an open issue faced by both the academic and industrial worlds, especially when ANNs are deployed on safety-critical systems, such as self-driving cars in the automotive world. In these systems, a strategy for identifying hardware faults is required by industry standards (e.g., ISO26262 for automotive, and DO254 for avionics). Among the existing in-field test strategies, the periodic scheduling of on-line Software Test Library (STL) is a wide strategy adopted; STL allows to reach an acceptable fault coverage without the need for additional hardware. However, when dealing with ANN-based applications, the execution of on-line tests interleaving the ANN inferences may jeopardise the strive for performance maximization. The paper presents a comprehensive analysis of six possible scenarios concerning the execution of on-line self-test programs in embedded devices running ANN-based applications. In the proposed scenarios, the impact of the STL execution on the ANN performance is analyzed; in particular, the execution times of an inference and the Fault Detection Time (FDT) of the STL are discussed and compared. Experimental analyses are provided by relying on: an open-source RISC-V platform running two different convolutional neural networks; a STL for RISC-V cores with a maximum achievable fault coverage of 90%.",https://ieeexplore.ieee.org/document/9486704/,2021 IEEE 27th International Symposium on On-Line Testing and Robust System Design (IOLTS),28-30 June 2021,ieeexplore
10.1109/EIT.2018.8500102,Behavioral Cloning for Lateral Motion Control of Autonomous Vehicles Using Deep Learning,IEEE,Conferences,"Current trend of the automotive industry combined with research by the major tech companies has proved that self-driving vehicles are the future. With successful demonstration of neural network based autonomous driving, NVIDIA has introduced a new paradigm for autonomous driving software. The biggest challenge for self-driving cars is autonomous lateral control. An end-to-end model seems very promising in providing a complete software stack for autonomous driving. Although this system is not ready to be provided as a feature in the market today, it is one of the many steps in the right direction to make self-driving cars a reality. The work described in this paper focusses on how an end-to-end model is implemented. The subtleties of training a successful end-to-end model are highlighted with the aim of providing an insight on deep learning and software required for neural network training. Detailed analyses of data acquisition and training systems are provided and installation procedures for all required tools and software discussed. TORCS is used for developing and testing the end-to-end model. Approximately ten hours of driving data was collected from two different tracks. Using four hours of data from a track, we trained a deep neural network to steer a car inside simulation. Even with such a small training set, the end-to-end model developed demonstrated capabilities to maintain lanes and complete laps in different tracks. For a multilane track, like the one used for training, the model demonstrated an autonomy of 96.62%. For single lane unknown tracks, the model steered the vehicle successfully for 89.02% of the time. The results indicate that end-to-end learning and behavioral cloning can be used to drive autonomously in new and unknown scenarios.",https://ieeexplore.ieee.org/document/8500102/,2018 IEEE International Conference on Electro/Information Technology (EIT),3-5 May 2018,ieeexplore
10.1109/RTAS48715.2020.00007,"Co-Optimizing Performance and Memory Footprint Via Integrated CPU/GPU Memory Management, an Implementation on Autonomous Driving Platform",IEEE,Conferences,"Cutting-edge embedded system applications, such as self-driving cars and unmanned drone software, are reliant on integrated CPU/GPU platforms for their DNNs-driven workload, such as perception and other highly parallel components. In this work, we set out to explore the hidden performance implication of GPU memory management methods of integrated CPU/GPU architecture. Through a series of experiments on micro-benchmarks and real-world workloads, we find that the performance under different memory management methods may vary according to application characteristics. Based on this observation, we develop a performance model that can predict system overhead for each memory management method based on application characteristics. Guided by the performance model, we further propose a runtime scheduler. By conducting per-task memory management policy switching and kernel overlapping, the scheduler can significantly relieve the system memory pressure and reduce the multitasking co-run response time. We have implemented and extensively evaluated our system prototype on the NVIDIA Jetson TX2, Drive PX2, and Xavier AGX platforms, using both Rodinia benchmark suite and two real-world case studies of drone software and autonomous driving software.",https://ieeexplore.ieee.org/document/9113098/,2020 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS),21-24 April 2020,ieeexplore
10.1109/ITSC.2017.8317627,Cognitive map-based model: Toward a developmental framework for self-driving cars,IEEE,Conferences,"End-to-end learning and multi-sensor fusion-based methods are two major frameworks used for self-driving cars. To enable these intelligence vehicles to acquire driving skills at a level comparable to that of human drivers, long short-term memory of previous self-driving processes is necessary, but is difficult to introduce into the above-mentioned frameworks. In this paper, we propose a model for self-driving cars called the cognitive map-based neural network (CMNN). Our framework consists of three parts: a convolutional neural network that can perceive the environment in the manner that the human visual cortex does, a cognitive map to describe the locations of objects in a complex traffic scene and the relationships among them, and a recurrent neural network to process long short-term memory from the cognitive map, which is updated in real time. The proposed model is built to simultaneously handle three tasks: i) detecting free space and lane boundaries, ii) estimating vehicle pose and obstacle distance, and iii) learning to plan and control based on the behaviors of a human driver. More significantly, our approach introduces external instructions during an end-to-end driving process. To test it, we created a large-scale road vehicle dataset (RVD) containing more than 50,000 labeled road images captured by three cameras. We implemented the proposed model on an embedded system.",https://ieeexplore.ieee.org/document/8317627/,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),16-19 Oct. 2017,ieeexplore
10.1109/DICTA.2018.8615819,Crack-pot: Autonomous Road Crack and Pothole Detection,IEEE,Conferences,"With the advent of self-driving cars and autonomous robots, it is imperative to detect road impairments like cracks and potholes and to perform necessary evading maneuvers to ensure fluid journey for on-board passengers or equipment. We propose a fully autonomous robust real-time road crack and pothole detection algorithm which can be deployed on any GPU based conventional processing boards with an associated camera. The approach is based on a deep neural net architecture which detects cracks and potholes using texture and spatial features. We also propose pre-processing methods which ensure real-time performance. The novelty of the approach lies in using texture-based features to differentiate between crack surfaces and sound roads. The approach performs well in large viewpoint changes, background noise, shadows, and occlusion. The efficacy of the system is shown on standard road crack datasets.",https://ieeexplore.ieee.org/document/8615819/,2018 Digital Image Computing: Techniques and Applications (DICTA),10-13 Dec. 2018,ieeexplore
10.1109/ITSC.2018.8569575,Deep Traffic Light Detection for Self-driving Cars from a Large-scale Dataset,IEEE,Conferences,"Traffic lights perception problem is one of the key challenges for autonomous vehicle controllers in urban areas. While a number of approaches for traffic light detection have been proposed, these methods often require a prior knowledge of map and/or show high false positive rates. Recent successes suggest that deep neural networks will be widely used in self-driving cars, but current public datasets do not provide sufficient amount of labels for training such large deep neural networks. In this paper, we developed a two-step computational method that can detect traffic lights from images in a real-time manner. The first step exploits a deep neural object detection architecture to fine true traffic light candidates. In the second step, a point-based reward system is used to eliminate false traffic lights out of the candidates. To evaluate the proposed approach, we collected a human-annotated large-scale traffic lights dataset (over 60 hours). We also designed a real-world experiment with an instrumented self-driving vehicle and observed that the proposed method was able to handle false traffic lights substantially better compared with the baseline considered.",https://ieeexplore.ieee.org/document/8569575/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/ITSC.2017.8317901,Deep fully convolutional networks with random data augmentation for enhanced generalization in road detection,IEEE,Conferences,"In this paper, a Deep Learning system for accurate road detection is proposed using the ResNet-101 network with a fully convolutional architecture and multiple upscaling steps for image interpolation. It is demonstrated that significant generalization gains in the learning process are attained by randomly generating augmented training data using several geometric transformations and pixelwise changes, such as affine and perspective transformations, mirroring, image cropping, distortions, blur, noise, and color changes. In addition, this paper shows that the use of a 4-step upscaling strategy provides optimal learning results as compared to other similar techniques that perform data upscaling based on shallow layers with scarce representation of the scene data. The complete system is trained and tested on data from the KITTI benchmark and besides it is also tested on images recorded on the Campus of the University of Alcala (Spain). The improvement attained after performing data augmentation and conducting a number of training variants is really encouraging, showing the path to follow for enhanced learning generalization of road detection systems with a view to real deployment in self-driving cars.",https://ieeexplore.ieee.org/document/8317901/,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),16-19 Oct. 2017,ieeexplore
10.1109/ICPS49255.2021.9468230,Detection of Dataset Shifts in Learning-Enabled Cyber-Physical Systems using Variational Autoencoder for Regression,IEEE,Conferences,"Cyber-physical systems (CPSs) use learning-enabled components (LECs) extensively to cope with various complex tasks under high-uncertainty environments. However, the dataset shifts between the training and testing phase may lead the LECs to become ineffective to make large-error predictions, and further, compromise the safety of the overall system. In our paper, we first provide the formal definitions for different types of dataset shifts in learning-enabled CPS. Then, we propose an approach to detect the dataset shifts effectively for regression problems. Our approach is based on the inductive conformal anomaly detection and utilizes a variational autoencoder for regression model which enables the approach to take into consideration both LEC input and output for detecting dataset shifts. Additionally, in order to improve the robustness of detection, layer-wise relevance propagation (LRP) is incorporated into our approach. We demonstrate our approach by using an advanced emergency braking system implemented in an open-source simulator for self-driving cars. The evaluation results show that our approach can detect different types of dataset shifts with a small number of false alarms while the execution time is smaller than the sampling period of the system.",https://ieeexplore.ieee.org/document/9468230/,2021 4th IEEE International Conference on Industrial Cyber-Physical Systems (ICPS),10-12 May 2021,ieeexplore
10.1109/SAM.2018.8448945,EEG-Based Classification of Emotional State Using an Autonomous Vehicle Simulator,IEEE,Conferences,"Societal acceptance of self-driving cars (SDC) is predicated on a level of trust between humans and the autonomous vehicle. Although the performance of SDCs has improved dramatically, the question of mainstream acceptance and requisite trust is still open. We are exploring this question through integration of virtual reality SDC simulator and an electroencephalographic (EEG) recorder. In order for a passenger to build and maintain trust, the SDC will need to operate in a manner that elicits positive emotional response and avoids negative emotional response. In our experiment, a test subject was exposed to scenarios designed to induce positive and negative emotional responses, quantified by the EEG beta wave to alpha wave power ratio. As predicted, an increase in the beta to alpha power ratio was observed when the test subject was exposed to stress inducing situations inside the SDC simulator. Our results are expected to inform the design and operation of an EEG-based supervisory feedback control module or artificial intelligence (AI) that monitors the emotional state of passengers and adjusts the AI control parameters accordingly.",https://ieeexplore.ieee.org/document/8448945/,2018 IEEE 10th Sensor Array and Multichannel Signal Processing Workshop (SAM),8-11 July 2018,ieeexplore
10.1109/SysCon48628.2021.9447097,Experimental Validation of a Steering Control System using an Adaptive Fuzzy Controller and Computer Vision,IEEE,Conferences,"This paper proposes an adaptive steering control strategy for self-driving cars based on a Fuzzy Expert System and Reinforcement Learning. Our objective consists in deriving an appropriate control law directly from a real vehicle that allows it to navigate on several types of lanes, by controlling the position in relation to the center of the tracks and also the translation speed of the vehicle. Using an on-line Reinforcement Learning approach, the Fuzzy expert controller is derived considering the coupling and non-linearity of the model on straight and winding tracks. To do this, an embedded camera captures the images and sends them to the computer vision algorithm responsible for performing tracks detection and recognition. From that, the control references which indicate the navigation path and direction on the lane are calculated. The main contribution of this work is to apply an online reinforcement learning approach to tune and optimize the fuzzy steering controller while the vehicle navigates through different routes. Using a real vehicle equipped with an embedded computer and also the implemented web user interface, the learning evolution of the adaptive fuzzy controller can be managed remotely during trial in actual environments. Experimental results showed that the learned fuzzy expert controller controls the self-driving car during the path tracking and precisely performs the execution of different maneuvers.",https://ieeexplore.ieee.org/document/9447097/,2021 IEEE International Systems Conference (SysCon),15 April-15 May 2021,ieeexplore
10.1109/ICDE.2017.150,In-Memory Distributed Matrix Computation Processing and Optimization,IEEE,Conferences,"The use of large-scale machine learning and data mining methods is becoming ubiquitous in many application domains ranging from business intelligence and bioinformatics to self-driving cars. These methods heavily rely on matrix computations, and it is hence critical to make these computations scalable and efficient. These matrix computations are often complex and involve multiple steps that need to be optimized and sequenced properly for efficient execution. This paper presents new efficient and scalable matrix processing and optimization techniques for in-memory distributed clusters. The proposed techniques estimate the sparsity of intermediate matrix-computation results and optimize communication costs. An evaluation plan generator for complex matrix computations is introduced as well as a distributed plan optimizer that exploits dynamic cost-based analysis and rule-based heuristics to optimize the cost of matrix computations in an in-memory distributed environment. The result of a matrix operation will often serve as an input to another matrix operation, thus defining the matrix data dependencies within a matrix program. The matrix query plan generator produces query execution plans that minimize memory usage and communication overhead by partitioning the matrix based on the data dependencies in the execution plan. We implemented the proposed matrix processing and optimization techniques in Spark, a distributed in-memory computing platform. Experiments on both real and synthetic data demonstrate that our proposed techniques achieve up to an order-of-magnitude performance improvement over state-of the-art distributed matrix computation systems on a wide range of applications.",https://ieeexplore.ieee.org/document/7930046/,2017 IEEE 33rd International Conference on Data Engineering (ICDE),19-22 April 2017,ieeexplore
10.1109/ICCE-Berlin47944.2019.8966156,Optimizing Deep Learning Based Semantic Video Segmentation on Embedded GPUs,IEEE,Conferences,"Decision making in many industries today is being improved drastically thanks to artificial intelligence and deep learning. New algorithms address challenges such as genome mapping, medical diagnostics, self-driving cars, autonomous robots and more. Deep learning in embedded systems requires high optimization due to the high computational demand, given that power, heat dissipation, size and price constraints are numerous. In this paper we analyze several acceleration methods which include utilization of GPUs for most complex variants of deep learning, such as semantic video segmentation operating in real time. Specifically, we propose mapping of acceleration routines commonly present within deep learning SDKs to different network layers in semantic segmentation. Finally, we evaluate one implementation utilizing the enumerated techniques for semantic segmentation of front camera in autonomous driving front view.",https://ieeexplore.ieee.org/document/8966156/,2019 IEEE 9th International Conference on Consumer Electronics (ICCE-Berlin),8-11 Sept. 2019,ieeexplore
10.1109/FormaliSE.2019.00012,Parallelizable Reachability Analysis Algorithms for Feed-Forward Neural Networks,IEEE,Conferences,"Artificial neural networks (ANN) have displayed considerable utility in a wide range of applications such as image processing, character and pattern recognition, self-driving cars, evolutionary robotics, and non-linear system identification and control. While ANNs are able to carry out complicated tasks efficiently, they are susceptible to unpredictable and errant behavior due to irregularities that emanate from their complex non-linear structure. As a result, there have been reservations about incorporating them into safety-critical systems. In this paper, we present a reachability analysis method for feed-forward neural networks (FNN) that employ rectified linear units (ReLUs) as activation functions. The crux of our approach relies on three reachable-set computation algorithms, namely exact schemes, lazy-approximate schemes, and mixing schemes. The exact scheme computes an exact reachable set for FNN, while the lazy-approximate and mixing schemes generate an over-approximation of the exact reachable set. All schemes are designed efficiently to run on parallel platforms to reduce the computation time and enhance the scalability. Our methods are implemented in a toolbox called, NNV, and is evaluated using a set of benchmarks that consist of realistic neural networks with sizes that range from tens to a thousand neurons. Notably, NNV successfully computes and visualizes the exact reachable sets of the real world ACAS Xu deep neural networks (DNNs), which are a variant of a family of novel airborne collision detection systems known as the ACAS System X, using a representation of tens to hundreds of polyhedra.",https://ieeexplore.ieee.org/document/8807491/,2019 IEEE/ACM 7th International Conference on Formal Methods in Software Engineering (FormaliSE),27-27 May 2019,ieeexplore
10.1109/ICCPS48487.2020.00024,Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems,IEEE,Conferences,"Cyber-physical systems (CPS) greatly benefit by using machine learning components that can handle the uncertainty and variability of the real-world. Typical components such as deep neural networks, however, introduce new types of hazards that may impact system safety. The system behavior depends on data that are available only during runtime and may be different than the data used for training. Out-of-distribution data may lead to a large error and compromise safety. The paper considers the problem of efficiently detecting out-of-distribution data in CPS control systems. Detection must be robust and limit the number of false alarms while being computational efficient for real-time monitoring. The proposed approach leverages inductive conformal prediction and anomaly detection for developing a method that has a well-calibrated false alarm rate. We use variational autoencoders and deep support vector data description to learn models that can be used efficiently compute the nonconformity of new inputs relative to the training set and enable realtime detection of out-of-distribution high-dimensional inputs. We demonstrate the method using an advanced emergency braking system and a self-driving end-to-end controller implemented in an open source simulator for self-driving cars. The simulation results show very small number of false positives and detection delay while the execution time is comparable to the execution time of the original machine learning components.",https://ieeexplore.ieee.org/document/9095995/,2020 ACM/IEEE 11th International Conference on Cyber-Physical Systems (ICCPS),21-25 April 2020,ieeexplore
10.1109/ICICICT46008.2019.8993293,Real-time Traffic Light Detection and Recognition based on Deep RetinaNet for Self Driving Cars,IEEE,Conferences,"Self-driving cars are getting more popularized nowadays due to its safe, convenient and congestion free transportability. Most of the real-time challenges for autonomous driving like recognizing traffic lights, traffic signs, pedestrians are being accurately addressed by the newer state-of-the-art algorithms based on Deep Learning. Recent technological advancements in cloud computing and the availability of high-end cloud-based Graphical Processing Units (GPU) accelerated the development of AI algorithms substantially. For real time detection and recognition of traffic lights, we propose RetinaNet (a deep neural network architecture) based model through transfer learning. The deep neural network RetinaNet was used as model and the system was implemented in Keras with TensorFlow backend in Google Colaboratory cloud platform. The RetinaNet model was trained and evaluated on Bosch Small Traffic Light Dataset containing traffic light images of resolution 1280 by 720 pixels, which falls under four type of classes. The model achieved improved accuracy of detection and classification than other deep learning methods for real-time operation.",https://ieeexplore.ieee.org/document/8993293/,"2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)",5-6 July 2019,ieeexplore
10.1109/THS.2017.7943477,Securing wireless communications of connected vehicles with artificial intelligence,IEEE,Conferences,"This work applies artificial intelligence (AI) to secure wireless communications of Connected Vehicles. Vehicular Ad-hoc Network (VANET) facilitates exchange of safety messages for collision avoidance, leading to self-driving cars. An AI system continuously learns to augment its ability in discerning and recognizing its surroundings. Such ability plays a vital role in evaluating the authenticity and integrity of safety messages for cars driven by computers. Falsification of meter readings, disablement of brake function, and other unauthorized controls by spoofed messages injected into VANET emerge as security threats. Countermeasures must be considered at design stage, as opposed to afterthought patches, effectively against cyber-attacks. However, current standards oversubscribe security measures by validating every message circulating among Connected Vehicles, making VANET subject to denial-of-service (DoS) Attacks. This interdisciplinary research shows promising results by searching the pivot point to balance between message authentication and DoS prevention, making security measures practical for the real-world deployment of Connected Vehicles. Message authentication adopts Context-Adaptive Signature Verification strategy, applying AI filters to reduce both communication and computation overhead. Combining OMNET++, a data network simulator, and SUMO, a road traffic simulator, with Veins, an open source framework for VANET simulation, the study evaluates AI filters comparatively under various attacking scenarios. The results lead to an effective design choice of securing wireless communications for Connected Vehicles.",https://ieeexplore.ieee.org/document/7943477/,2017 IEEE International Symposium on Technologies for Homeland Security (HST),25-26 April 2017,ieeexplore
10.1109/CSCI51800.2020.00117,Self Driving Cars: All You Need to Know,IEEE,Conferences,"Self-driving cars are coming closer and closer to being fact not fiction, but are we ready for them? In this research we analyze the current status in place for self-driving cars. We address the gaps that need to be filled, and we identify the questions that need to be answered before having self-driving cars on the road becomes a reality. Towards this, we discuss four issues with self-driving: policies, safety, security, and psychological acceptability of users. Our research will help individuals understand different aspects of self-driving cars and their benefits and challenges. Our paper will educate policymakers on the areas that need to be addressed before we deploy self-driving cars on the roads in a larger scale.",https://ieeexplore.ieee.org/document/9458101/,2020 International Conference on Computational Science and Computational Intelligence (CSCI),16-18 Dec. 2020,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/ACMI53878.2021.9528185,Speed Bump &amp; Pothole Detection with Single Shot MultiBox Detector Algorithm &amp; Speed Control for Autonomous Vehicle,IEEE,Conferences,"The development of self-driving cars has always been an extensive research field for the automobile industry. To make a capable self-driving car, many challenges need to be resolved. Detection of the road condition is one of them. This paper focuses on a particular part-detection of speed bumps and potholes using a camera and analyzing the video feed with the help of artificial intelligence. To solve this problem a popular and lightweight algorithm, SSD (Single Shot Multibox Detector) is used. This is an optimal choice because of being lightweight and also accurate enough to run on mobile devices and to use in real-life situations. For detecting speed bumps and potholes, a dataset has been created based on the road structure of Bangladesh as the main priority of this system is to work on the local environment. Raspberry Pi has been used as the main processing unit because of being small but powerful. A warning system has been implemented so that it can warn the onboard driver about the upcoming pothole or speed bump. This system can also send a signal to the speed controller unit of the car to reduce the speed on detection to avoid accidents or damages to the car. The speed control unit is a microcontroller-based system that uses an ATmega328 microcontroller and L298 motor driver. This paper summarizes the combination of an artificial intelligence-based detection system injunction with a microcontroller-based speed control system in a cost-effective way that can be used in building self-driving cars.",https://ieeexplore.ieee.org/document/9528185/,"2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 (ACMI)",8-9 July 2021,ieeexplore
10.1109/IDAACS-SWS50031.2020.9297062,Using a COTS Smartphone to Control an Autonomous Self-Driving Platform,IEEE,Conferences,"Recent interest in self-driving cars has boosted related fields like autonomous systems and robotics. This paper describes a simple and inexpensive small-scale self driving platform called ASV, which is based on a lowcost microcontroller and a COTS smartphone connected via WiFi. The camera of the phone, which is fixed to the platform, acquires images which are processed in a Convolutional Neural Network (CNN) inspired by the Nvidia's PilotNet. The network is trained in end-to-end learning to produce steering command to follow highway style lanes with markers on both sides. On the microcontroller, the steering commands are used for motor actuation and control of the physical movement of the platform. This paper presents the structure and implementation of ASV and evaluates its real-time performance and latency. For typical speeds encountered in small-scale systems, the performance is found more than sufficient for lane following with the CNN, leaving plenty of room for extensions. The platform's simplicity allows it to be used in research, education, and to spark interest in self-driving systems and neural networks. It can form the basis for general robot control.",https://ieeexplore.ieee.org/document/9297062/,2020 IEEE 5th International Symposium on Smart and Wireless Systems within the Conferences on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS-SWS),17-18 Sept. 2020,ieeexplore
10.1109/SSCI47803.2020.9308364,Vision-based Vehicle Detection and Distance Estimation,IEEE,Conferences,"Real-time vehicle detection is one of the most important topics under the Autonomous Vehicles (AVs) research paradigm and traffic surveillance. Detecting vehicles and estimating their distances are essential to ensure that the vehicles can keep a safe distance and run safely on the roads. The technology can also be utilized to determine traffic flow and estimate vehicle speed. In this paper, we apply two different deep learning models and compare their performances in detecting vehicles such as cars and trucks for deployment on the self-driving cars to ensure road safety. Our models are based on YOLOv4 and Faster R-CNN which are efficient and accurate in object detection within a given distance. We also propose a vision-based distance estimation algorithm to estimate other vehicles' distances. In detecting vehicles within 100 meters, the two variations of our models, YOLOv4 and Faster R-CNN, achieved 99.16% and 95.47% mean precision, and 79.36% and 85.54% Fl-measure respectively on a two-way road. The detection speed is 68 fps and 14 fps for YOLOv4 and Faster R-CNN respectively.",https://ieeexplore.ieee.org/document/9308364/,2020 IEEE Symposium Series on Computational Intelligence (SSCI),1-4 Dec. 2020,ieeexplore
10.1109/ICSPC51351.2021.9451761,YOLOv4 for Multi-class Artefact Detection in Endoscopic Images,IEEE,Conferences,"State of the art deep learning-based object detectors are deployed in various fields of computer vision such as face recognition, object tracking, self-driving cars and so on. Most of the object detectors are trained on common objects such as person, car, train, truck etc. but not on medical images. Considering specific applications like detecting multi-class artefacts in endoscopic images, a cutting-edge object detector like YOLOv4 which out-performed well in terms of speed and accuracy in general purpose dataset (like MS COCO dataset), is chosen. The aim of the paper is to carefully handpick techniques from Bag of Freebies of YOLOv4 and retrain the detector for detecting commonly occurring artefacts in endoscopic images using EAD2019 dataset. The experimental results proved a good mAP score of 49.82 % with the inference time of 76 milliseconds.",https://ieeexplore.ieee.org/document/9451761/,2021 3rd International Conference on Signal Processing and Communication (ICPSC),13-14 May 2021,ieeexplore
10.1109/TITS.2020.2980855,An Efficient and Scalable Simulation Model for Autonomous Vehicles With Economical Hardware,IEEE,Journals,"Autonomous vehicles rely on sophisticated hardware and software technologies for acquiring holistic awareness of their immediate surroundings. Deep learning methods have effectively equipped modern self-driving cars with high levels of such awareness. However, their application requires high-end computational hardware, which makes utilization infeasible for the legacy vehicles that constitute most of today's automotive industry. Hence, it becomes inherently challenging to achieve high performance while at the same time maintaining adequate computational complexity. In this paper, a monocular vision and scalar sensor-based model car is designed and implemented to accomplish autonomous driving on a specified track by employing a lightweight deep learning model. It can identify various traffic signs based on a vision sensor as well as avoid obstacles by using an ultrasonic sensor. The developed car utilizes a single Raspberry Pi as its computational unit. In addition, our work investigates the behavior of economical hardware used to deploy deep learning models. In particular, we herein propose a novel, computationally efficient, and cost-effective approach. The designed system can serve as a platform to facilitate the development of economical technologies for autonomous vehicles that can be used as part of intelligent transportation or advanced driver assistance systems. The experimental results indicate that this model can achieve real-time response on a resource-constrained device without significant overheads, thus making it a suitable candidate for autonomous driving in current intelligent transportation systems.",https://ieeexplore.ieee.org/document/9094331/,IEEE Transactions on Intelligent Transportation Systems,March 2021,ieeexplore
10.1109/JSAC.2020.3020677,Exploiting Transfer Learning for Emotion Recognition Under Cloud-Edge-Client Collaborations,IEEE,Journals,"Emerging virtual reality/augmented reality games and self-driving cars necessitate accurate/responsive/private emotion recognition. Usually, traditional emotion recognition models are deployed at central servers, which results in the lack of abilities in generalization and covering the individual variation of clients. This paper proposes a responsive, localized, and private transfer learning based emotion recognition framework under the cloud-edge-client collaborations. Additionally, a 3-dimensional channel mapping method is designed to aggregate features extracted from electroencephalogram (EEG) signals for the generic emotion recognition model, which is further localized and personalized using transfer learning. Simulation results validate the performance of the proposed TLER framework in reducing model training time and improving emotion recognition accuracy.",https://ieeexplore.ieee.org/document/9187207/,IEEE Journal on Selected Areas in Communications,Feb. 2021,ieeexplore
10.1109/TDSC.2020.2967703,Leakage-Resilient Authenticated Key Exchange for Edge Artificial Intelligence,IEEE,Journals,"Edge Artificial Intelligence (AI) is a timely complement of cloud-based AI. By introducing intelligence to the edge, it alleviates privacy concerns of streaming and storing data to the cloud, enables real-time operations where milliseconds matter, and brings AI services to remote areas with poor networking infrastructures. Security is a significant problem in Edge AI applications such as self-driving cars and intelligent healthcare. Since the edge devices are empowered to process data and take actions, attacking and compromising them can cause serious damage. However, the wide deployment of computationally limited devices in edge environments and the increasing happening of side-channel (or leakage) attacks pose critical challenges to security. This article thereby aims to enhance the security for Edge AI by designing and developing lightweight and leakage-resilient authenticated key exchange (LRAKE) protocols. Compared with available LRAKE protocols, the proposed protocols in this article can be effortless applied in some mainstreaming security and communication standards. Moreover, this article realizes prototypes and presents implementation details; and a use case of applying the proposed protocol in Bluetooth 5.0 is illustrated. The theoretical design and implementation details will provide a guidance of applying the LRAKE protocols in Edge AI applications.",https://ieeexplore.ieee.org/document/8964439/,IEEE Transactions on Dependable and Secure Computing,1 Nov.-Dec. 2021,ieeexplore
10.1109/ICAMIMIA47173.2019.9223365,Autonomous Car Simulation Using Evolutionary Neural Network Algorithm,IEEE,Conferences,"Automation with artificial intelligence (AI) has widely implemented in robotics, transportation and manufacture. AI has become a powerful technology that change human life and help human more flexible doing something. In this paper, it will show a result of simulation from an autonomous car using the evolutionary neural network algorithm which combines genetic algorithm and neural network. The purpose of the simulation is to test the model that we develop to know the right direction based on the track, so the evolutionary neural network that implemented to the autonomous car be able to deliver the best solution before it implements in the real machine or car technology. Genetic algorithm combines with a neural network to reach an evolution condition. The evolution process is achieved through crossover, mutation and selection process, so the algorithm will give the best result from the iteration of the experiment. The result of our experiment shows that evolutionary neural network algorithm give the best result within 3 layer architecture, with iteration average is 14.5 reach finish point (check point) 3 in the track simulation. Based on the simulation, our car model can find out the right direction.",https://ieeexplore.ieee.org/document/9223365/,"2019 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation (ICAMIMIA)",9-10 Oct. 2019,ieeexplore
10.1109/ASYU50717.2020.9259830,Real-Time Implementation of Mini Autonomous Car Based on MobileNet - Single Shot Detector,IEEE,Conferences,"In this paper, in order to realize a prototype of an autonomous vehicle, we present a framework that consists of convolutional neural networks and image processing methods. The study is comprised of two main parts as software and hardware. In the hardware part, a small-sized smart video car kit is used as the prototype of the autonomous car. This programmable tool consists of Raspberry Pi, servo motors and a USB webcam whose angle of vision is equal to 120°. In the software part, we propose an algorithm in which we use Convolutional Neural Networks to detect the objects (vehicles, pedestrians, and traffic signs) and Hough transformation to detect the road lanes. Based on the outputs of the object and lane detections, the system decides the speed and the direction of the car in real-time. In our results, the vehicle performs autonomous driving in the scaled real-world application.",https://ieeexplore.ieee.org/document/9259830/,2020 Innovations in Intelligent Systems and Applications Conference (ASYU),15-17 Oct. 2020,ieeexplore
10.1109/TNNLS.2019.2892327,A Novel Dual Successive Projection-Based Model-Free Adaptive Control Method and Application to an Autonomous Car,IEEE,Journals,"In this paper, a novel model-free adaptive control (MFAC) algorithm based on a dual successive projection (DuSP)-MFAC method is proposed, and it is analyzed using the introduced DuSP method and the symmetrically similar structures of the controller and its parameter estimator of MFAC. Then, the proposed DuSP-MFAC scheme is successfully implemented in an autonomous car “Ruilong” for the lateral tracking control problem via converting the trajectory tracking problem into a stabilization problem by using the proposed preview-deviation-yaw angle. This MFAC-based lateral tracking control method was tested and demonstrated satisfactory performance on real roads in Fengtai, Beijing, China, and through successful participation in the Chinese Smart Car Future Challenge Competition held in 2015 and 2016.",https://ieeexplore.ieee.org/document/8641438/,IEEE Transactions on Neural Networks and Learning Systems,Nov. 2019,ieeexplore
10.1109/LRA.2021.3097345,Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement Learning,IEEE,Journals,"Autonomous car racing is a challenging task in the robotic control area. Traditional modular methods require accurate mapping, localization and planning, which makes them computationally inefficient and sensitive to environmental changes. Recently, deep-learning-based end-to-end systems have shown promising results for autonomous driving/racing. However, they are commonly implemented by supervised imitation learning (IL), which suffers from the distribution mismatch problem, or by reinforcement learning (RL), which requires a huge amount of risky interaction data. In this work, we present a general deep imitative reinforcement learning approach (DIRL), which successfully achieves agile autonomous racing using visual inputs. The driving knowledge is acquired from both IL and model-based RL, where the agent can learn from human teachers as well as perform self-improvement by safely interacting with an offline world model. We validate our algorithm both in a high-fidelity driving simulation and on a real-world 1/20-scale RC-car with limited onboard computation. The evaluation results demonstrate that our method outperforms previous IL and RL methods in terms of sample efficiency and task performance. Demonstration videos are available at https://caipeide.github.io/autorace-dirl/.",https://ieeexplore.ieee.org/document/9488179/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/CRV.2018.00024,A Hierarchical Deep Architecture and Mini-batch Selection Method for Joint Traffic Sign and Light Detection,IEEE,Conferences,"Traffic light and sign detectors on autonomous cars are integral for road scene perception. The literature is abundant with deep learning networks that detect either lights or signs, not both, which makes them unsuitable for real-life deployment due to the limited graphics processing unit (GPU) memory and power available on embedded systems. The root cause of this issue is that no public dataset contains both traffic light and sign labels, which leads to difficulties in developing a joint detection framework. We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets. Our method solves the overlapping issue where instances from one dataset are not labelled in the other dataset. We are the first to present a network that performs joint detection on traffic lights and signs. We measure our network on the Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small Traffic Lights benchmark for traffic light detection and show it outperforms the existing Bosch Small Traffic light state-of-the-art method. We focus on autonomous car deployment and show our network is more suitable than others because of its low memory footprint and real-time image processing time. Qualitative results can be viewed at https://youtu.be/ YmogPzBXOw.",https://ieeexplore.ieee.org/document/8575742/,2018 15th Conference on Computer and Robot Vision (CRV),8-10 May 2018,ieeexplore
10.1109/I-SMAC.2018.8653736,A Novel Design of Autonomous Cars using IoT and Visual Features,IEEE,Conferences,"Autonomous car is a ground vehicle that is capable of driving without user interference. Traffic congestion and number of collisions are major issues in road traffic control due to rapid increase day-by-day. Autonomous cars provide a solution to this problem in an efficient and economical way. The proposed system utilizes mathematical models like neural networks and image processing techniques to sense the environment. This is implemented as three major components: curved road detection (steering), road sign and signal detection and obstacle detection (collision avoidance). Back Propagation is used for steering control with detection of curved roads; Haar features are used for road signal, sign detection and a distance sensor for collision avoidance. Data collected from the sensors is sent to a server for processing. Based on the result, a command is sent to the car. A GPS module attached to the car identifies the location of the car and with the help of a 3rd party location service, route to destination is identified and directions are sent to the car. Wireless networks are used to transmit data between sensors and the server. Python scripts are used to control and integrate all the units together. The designed system can attain high accuracy with real - time constraints.",https://ieeexplore.ieee.org/document/8653736/,"2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), 2018 2nd International Conference on",30-31 Aug. 2018,ieeexplore
10.1109/ICAMIMIA47173.2019.9223365,Autonomous Car Simulation Using Evolutionary Neural Network Algorithm,IEEE,Conferences,"Automation with artificial intelligence (AI) has widely implemented in robotics, transportation and manufacture. AI has become a powerful technology that change human life and help human more flexible doing something. In this paper, it will show a result of simulation from an autonomous car using the evolutionary neural network algorithm which combines genetic algorithm and neural network. The purpose of the simulation is to test the model that we develop to know the right direction based on the track, so the evolutionary neural network that implemented to the autonomous car be able to deliver the best solution before it implements in the real machine or car technology. Genetic algorithm combines with a neural network to reach an evolution condition. The evolution process is achieved through crossover, mutation and selection process, so the algorithm will give the best result from the iteration of the experiment. The result of our experiment shows that evolutionary neural network algorithm give the best result within 3 layer architecture, with iteration average is 14.5 reach finish point (check point) 3 in the track simulation. Based on the simulation, our car model can find out the right direction.",https://ieeexplore.ieee.org/document/9223365/,"2019 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation (ICAMIMIA)",9-10 Oct. 2019,ieeexplore
10.1109/ROBOT.2009.5152365,Autonomous driving in a multi-level parking structure,IEEE,Conferences,"Recently, the problem of autonomous navigation of automobiles has gained substantial interest in the robotics community. Especially during the two recent DARPA grand challenges, autonomous cars have been shown to robustly navigate over extended periods of time through complex desert courses or through dynamic urban traffic environments. In these tasks, the robots typically relied on GPS traces to follow pre-defined trajectories so that only local planners were required. In this paper, we present an approach for autonomous navigation of cars in indoor structures such as parking garages. Our approach utilizes multi-level surface maps of the corresponding environments to calculate the path of the vehicle and to localize it based on laser data in the absence of sufficiently accurate GPS information. It furthermore utilizes a local path planner for controlling the vehicle. In a practical experiment carried out with an autonomous car in a real parking garage we demonstrate that our approach allows the car to autonomously park itself in a large-scale multi-level structure.",https://ieeexplore.ieee.org/document/5152365/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/IRC.2019.00073,Deep Grid Net (DGN): A Deep Learning System for Real-Time Driving Context Understanding,IEEE,Conferences,"Grid maps obtained from fused sensory information are nowadays among the most popular approaches for motion planning for autonomous driving cars. In this paper, we introduce Deep Grid Net (DGN), a deep learning (DL) system designed for understanding the context in which an autonomous car is driving. DGN incorporates a learned driving environment representation based on Occupancy Grids (OG) obtained from raw Lidar data and constructed on top of the Dempster-Shafer (DS) theory. The predicted driving context is further used for switching between different driving strategies implemented within EB robinos, Elektrobit's Autonomous Driving (AD) software platform. Based on genetic algorithms (GAs), we also propose a neuroevolutionary approach for learning the tuning hyperparameters of DGN. The performance of the proposed deep network has been evaluated against similar competing driving context estimation classifiers.",https://ieeexplore.ieee.org/document/8675636/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/ICCE.2018.8326285,Deep learning in low-power stereo vision accelerator for automotive,IEEE,Conferences,"Various forms of Convolutional Neural Network (CNN) architectures are used as Deep Learning (DL) tools for learning the similarity measure on video patches in order to run the stereo matching algorithm - the most computationally intensive stage of the pipeline for the stereo vision function used in designing an autonomous car. We propose a hybrid system implementation of the algorithm for real-time, low-power and high-temperature environment. The accelerator part of our system is a programmable many-core system with a Map-Reduce Architecture. The paper describes and evaluates the proposed accelerator for different versions of the stereo matching algorithm.",https://ieeexplore.ieee.org/document/8326285/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/IVS.2002.1187941,Pattern matching as the nucleus for either autonomous driving or driver assistance systems,IEEE,Conferences,"Concerns autonomous vehicle driving by pattern matching combined with reinforcement learning. In specific, this research focuses on the requirement to steer an autonomous car along a curvy and hilly road course with no intersections and no other vehicle or obstacle but with the strict requirement to self-improve driving behaviour. A camera is used to build quickly an abstract complete description (ACSD) of vehicle's current situation. This combines traditional edge finding operators with a new technique of Bayes prediction for each part of the video image. Those ACSD's are being stored together with the steering commands issued at that time and serve as the pattern database of possible driving behaviour which are being retrieved using an approximate nearest neighbour pattern matching algorithm with a O(n log m) characteristic compared to O(n/spl middot/m) for the conventional nearest neighbour calculation. In addition to this, any feedback on the quality or appropriateness of the driving behaviour has to be self-created (e.g. time measurement for a whole road section) and is therefore delayed and unspecific in relation to single issued steering commands. Consequently, a machine learning algorithm coping with those conditions is being implemented based on Reinforcement Learning.",https://ieeexplore.ieee.org/document/1187941/,"Intelligent Vehicle Symposium, 2002. IEEE",17-21 June 2002,ieeexplore
10.1109/ASYU50717.2020.9259830,Real-Time Implementation of Mini Autonomous Car Based on MobileNet - Single Shot Detector,IEEE,Conferences,"In this paper, in order to realize a prototype of an autonomous vehicle, we present a framework that consists of convolutional neural networks and image processing methods. The study is comprised of two main parts as software and hardware. In the hardware part, a small-sized smart video car kit is used as the prototype of the autonomous car. This programmable tool consists of Raspberry Pi, servo motors and a USB webcam whose angle of vision is equal to 120°. In the software part, we propose an algorithm in which we use Convolutional Neural Networks to detect the objects (vehicles, pedestrians, and traffic signs) and Hough transformation to detect the road lanes. Based on the outputs of the object and lane detections, the system decides the speed and the direction of the car in real-time. In our results, the vehicle performs autonomous driving in the scaled real-world application.",https://ieeexplore.ieee.org/document/9259830/,2020 Innovations in Intelligent Systems and Applications Conference (ASYU),15-17 Oct. 2020,ieeexplore
10.1109/INMIC.2018.8595684,Self-Driving Cars Using CNN and Q-Learning,IEEE,Conferences,"DrivingMatter is an experiment carried out to understand the deeper side of an autonomous car. In 1900s, idea was to drive car on Moon from Earth. This was initial motivation which grew from there and now expanding to complex system of roads in the real world. A book-sized Raspberry Pi based autonomous car is built to carry out the experiment on hardware. Software side was accomplished by developing a Python based library for controlling and communicating with car over a network or locally within the car. For environment learning two methodologies are practiced; Supervised learning: Drove the car on an environment/road and collected 3, 000+ data-points. Based on this a CNN model was trained which achieved 73 % test 89 % train accuracy. Reinforcement learning: Car is trained for three different road signs; Stop, No left, and Traffic light using DQN with existing CNN model. These road signs are detected in the environment using OpenCV cascade classifiers.",https://ieeexplore.ieee.org/document/8595684/,2018 IEEE 21st International Multi-Topic Conference (INMIC),1-2 Nov. 2018,ieeexplore
10.1109/ITSC.2015.291,Sensor-Based Control with Digital Maps Association for Global Navigation: A Real Application for Autonomous Vehicles,IEEE,Conferences,"This paper presents a sensor-based control strategy applied in the global navigation of autonomous vehicles in urban environments. Typically, sensor-based control performs local navigation tasks regarding some features perceived from the environment. However, when there is more than one possibility to go, like in road intersection, the vehicle control fails to accomplish its global navigation. In order to solve this problem, we propose the vehicle global navigation based on a topological representation of the environment using only digital maps and low cost sensors. The approach was developed for two main tasks: road following and road intersection maneuvers. The final solution was completely implemented in a real autonomous car and tested in a challenge circuit, showing the viability of our solution.",https://ieeexplore.ieee.org/document/7313383/,2015 IEEE 18th International Conference on Intelligent Transportation Systems,15-18 Sept. 2015,ieeexplore
10.1109/UEMCON.2018.8796749,Smart City Software Revolution - Blackboard Systems for Smart City Solutions,IEEE,Conferences,"This paper examines the possibilities and requirements of using the blackboard software system in the context of a smart city. Using Unreal Engine 4, a virtual smart city was developed to test the capabilities and difficulties which would accompany the use of the blackboard. A number of simulations were run to generate insight regarding the viability of implementing the blackboard in a real-world setting. The tasks that the blackboard attempted addressed the following goals: a weather reaction system; a parking space availability system; and a daylight reaction system. An autonomous car running on preset routes was implemented in two separate ways to compare the performance between a blackboard system and blueprints.",https://ieeexplore.ieee.org/document/8796749/,"2018 9th IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",8-10 Nov. 2018,ieeexplore
10.1109/InertialSensors.2018.8577143,Visual lnertial Hybridization Technique based on Beacons identified by Deep Learning,IEEE,Conferences,"Safran has been working for several years on autonomy of vehicles. Whether it is airborne with the UAV Patroller, or on the ground with the military vehicle eRider and with the civilian autonomous car in cooperation with Valeo. This paper focuses on the use of visual information to improve the localization of the car, more precisely, it presents, from a theoretical point of view, the hybridization of the inertial sensors measurement with the line of sight of known position visual beacons: road signs detected on the camera image thanks to deep learning. This fusion algorithm has been implemented in a prototype version of Safran's well know Epsilon 10 navigator and simulation results as well as first real-time results are presented.",https://ieeexplore.ieee.org/document/8577143/,2018 DGON Inertial Sensors and Systems (ISS),11-12 Sept. 2018,ieeexplore
10.1145/3125503.3125568,Work-in-progress: testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks,IEEE,Conferences,Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional filters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator.,https://ieeexplore.ieee.org/document/8094374/,2017 International Conference on Embedded Software (EMSOFT),15-20 Oct. 2017,ieeexplore
10.1109/TNNLS.2019.2892327,A Novel Dual Successive Projection-Based Model-Free Adaptive Control Method and Application to an Autonomous Car,IEEE,Journals,"In this paper, a novel model-free adaptive control (MFAC) algorithm based on a dual successive projection (DuSP)-MFAC method is proposed, and it is analyzed using the introduced DuSP method and the symmetrically similar structures of the controller and its parameter estimator of MFAC. Then, the proposed DuSP-MFAC scheme is successfully implemented in an autonomous car “Ruilong” for the lateral tracking control problem via converting the trajectory tracking problem into a stabilization problem by using the proposed preview-deviation-yaw angle. This MFAC-based lateral tracking control method was tested and demonstrated satisfactory performance on real roads in Fengtai, Beijing, China, and through successful participation in the Chinese Smart Car Future Challenge Competition held in 2015 and 2016.",https://ieeexplore.ieee.org/document/8641438/,IEEE Transactions on Neural Networks and Learning Systems,Nov. 2019,ieeexplore
10.1109/LRA.2021.3097345,Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement Learning,IEEE,Journals,"Autonomous car racing is a challenging task in the robotic control area. Traditional modular methods require accurate mapping, localization and planning, which makes them computationally inefficient and sensitive to environmental changes. Recently, deep-learning-based end-to-end systems have shown promising results for autonomous driving/racing. However, they are commonly implemented by supervised imitation learning (IL), which suffers from the distribution mismatch problem, or by reinforcement learning (RL), which requires a huge amount of risky interaction data. In this work, we present a general deep imitative reinforcement learning approach (DIRL), which successfully achieves agile autonomous racing using visual inputs. The driving knowledge is acquired from both IL and model-based RL, where the agent can learn from human teachers as well as perform self-improvement by safely interacting with an offline world model. We validate our algorithm both in a high-fidelity driving simulation and on a real-world 1/20-scale RC-car with limited onboard computation. The evaluation results demonstrate that our method outperforms previous IL and RL methods in terms of sample efficiency and task performance. Demonstration videos are available at https://caipeide.github.io/autorace-dirl/.",https://ieeexplore.ieee.org/document/9488179/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/I-SMAC.2018.8653736,A Novel Design of Autonomous Cars using IoT and Visual Features,IEEE,Conferences,"Autonomous car is a ground vehicle that is capable of driving without user interference. Traffic congestion and number of collisions are major issues in road traffic control due to rapid increase day-by-day. Autonomous cars provide a solution to this problem in an efficient and economical way. The proposed system utilizes mathematical models like neural networks and image processing techniques to sense the environment. This is implemented as three major components: curved road detection (steering), road sign and signal detection and obstacle detection (collision avoidance). Back Propagation is used for steering control with detection of curved roads; Haar features are used for road signal, sign detection and a distance sensor for collision avoidance. Data collected from the sensors is sent to a server for processing. Based on the result, a command is sent to the car. A GPS module attached to the car identifies the location of the car and with the help of a 3rd party location service, route to destination is identified and directions are sent to the car. Wireless networks are used to transmit data between sensors and the server. Python scripts are used to control and integrate all the units together. The designed system can attain high accuracy with real - time constraints.",https://ieeexplore.ieee.org/document/8653736/,"2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), 2018 2nd International Conference on",30-31 Aug. 2018,ieeexplore
10.1109/WiMOB.2019.8923315,An Anomaly Detector for CAN Bus Networks in Autonomous Cars based on Neural Networks,IEEE,Conferences,"The domain of securing in-vehicle networks has attracted both academic and industrial researchers due to high danger of attacks on drivers and passengers. While securing wired and wireless interfaces is important to defend against these threats, detecting attacks is still the critical phase to construct a robust secure system. There are only a few results on securing communication inside vehicles using anomaly-detection techniques despite their efficiencies in systems that need real-time detection. Therefore, we propose an intrusion detection system (IDS) based on Multi-Layer Perceptron (MLP) neural network for Controller Area Networks (CAN) bus. This IDS divides data according to the ID field of CAN packets using K-means clustering algorithm, then it extracts suitable features and uses them to train and construct the neural network. The proposed IDS works for each ID separately and finally it combines their individual decisions to construct the final score and generates alert in the presence of attack. The strength of our intrusion detection method is that it works simultaneously for two types of attacks which will eliminate the use of several separate IDS and thus reduce the complexity and cost of implementation.",https://ieeexplore.ieee.org/document/8923315/,"2019 International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)",21-23 Oct. 2019,ieeexplore
10.1109/IJCNN52387.2021.9533738,CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,IEEE,Conferences,"Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",https://ieeexplore.ieee.org/document/9533738/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1145/3180155.3180220,DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars,IEEE,Conferences,"Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.",https://ieeexplore.ieee.org/document/8453089/,2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE),27 May-3 June 2018,ieeexplore
10.1109/CRV.2018.00024,A Hierarchical Deep Architecture and Mini-batch Selection Method for Joint Traffic Sign and Light Detection,IEEE,Conferences,"Traffic light and sign detectors on autonomous cars are integral for road scene perception. The literature is abundant with deep learning networks that detect either lights or signs, not both, which makes them unsuitable for real-life deployment due to the limited graphics processing unit (GPU) memory and power available on embedded systems. The root cause of this issue is that no public dataset contains both traffic light and sign labels, which leads to difficulties in developing a joint detection framework. We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets. Our method solves the overlapping issue where instances from one dataset are not labelled in the other dataset. We are the first to present a network that performs joint detection on traffic lights and signs. We measure our network on the Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small Traffic Lights benchmark for traffic light detection and show it outperforms the existing Bosch Small Traffic light state-of-the-art method. We focus on autonomous car deployment and show our network is more suitable than others because of its low memory footprint and real-time image processing time. Qualitative results can be viewed at https://youtu.be/ YmogPzBXOw.",https://ieeexplore.ieee.org/document/8575742/,2018 15th Conference on Computer and Robot Vision (CRV),8-10 May 2018,ieeexplore
10.1109/I-SMAC.2018.8653736,A Novel Design of Autonomous Cars using IoT and Visual Features,IEEE,Conferences,"Autonomous car is a ground vehicle that is capable of driving without user interference. Traffic congestion and number of collisions are major issues in road traffic control due to rapid increase day-by-day. Autonomous cars provide a solution to this problem in an efficient and economical way. The proposed system utilizes mathematical models like neural networks and image processing techniques to sense the environment. This is implemented as three major components: curved road detection (steering), road sign and signal detection and obstacle detection (collision avoidance). Back Propagation is used for steering control with detection of curved roads; Haar features are used for road signal, sign detection and a distance sensor for collision avoidance. Data collected from the sensors is sent to a server for processing. Based on the result, a command is sent to the car. A GPS module attached to the car identifies the location of the car and with the help of a 3rd party location service, route to destination is identified and directions are sent to the car. Wireless networks are used to transmit data between sensors and the server. Python scripts are used to control and integrate all the units together. The designed system can attain high accuracy with real - time constraints.",https://ieeexplore.ieee.org/document/8653736/,"2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), 2018 2nd International Conference on",30-31 Aug. 2018,ieeexplore
10.1109/ICIEVicIVPR52578.2021.9564229,A Vision-Based Lane Detection Approach for Autonomous Vehicles Using a Convolutional Neural Network Architecture,IEEE,Conferences,"Autonomous vehicles no longer belong to the realm of science fiction. They have become a prominent area of research in the last two decades because of the integration of Artificial Intelligence in the automobile industry. Apart from the development of various complex learning algorithms, the advancement of cameras, sensors, and geolocation technology as well as the escalation in the capacity of machines have played a crucial role in bringing this technology into reality. We have had significant breakthroughs in the development of autonomous cars within the last ten years. However, despite the success of multiple prototypes in navigating within the borders of a delimited area, researchers are yet to overcome several drawbacks before embodying them in the transport system; and one of those hurdles lies in the lane detection system of the cars. Therefore, in this article, we present an intelligent lane detection algorithm incorporating fully-connected Neural Networks with a secondary layer protection scheme to detect the borders of a lane. We achieved over 98% classification accuracy using the proposed lane detection model. We also implemented the model in a small prototype to take a look at its performance. Experimental results infer that the algorithm is capable of lane detection and ready for practical use.",https://ieeexplore.ieee.org/document/9564229/,"2021 Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",16-20 Aug. 2021,ieeexplore
10.1109/ROBOT.2009.5152365,Autonomous driving in a multi-level parking structure,IEEE,Conferences,"Recently, the problem of autonomous navigation of automobiles has gained substantial interest in the robotics community. Especially during the two recent DARPA grand challenges, autonomous cars have been shown to robustly navigate over extended periods of time through complex desert courses or through dynamic urban traffic environments. In these tasks, the robots typically relied on GPS traces to follow pre-defined trajectories so that only local planners were required. In this paper, we present an approach for autonomous navigation of cars in indoor structures such as parking garages. Our approach utilizes multi-level surface maps of the corresponding environments to calculate the path of the vehicle and to localize it based on laser data in the absence of sufficiently accurate GPS information. It furthermore utilizes a local path planner for controlling the vehicle. In a practical experiment carried out with an autonomous car in a real parking garage we demonstrate that our approach allows the car to autonomously park itself in a large-scale multi-level structure.",https://ieeexplore.ieee.org/document/5152365/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/IECON43393.2020.9255001,Computation Offloading for Machine Learning in Industrial Environments,IEEE,Conferences,"Industrial applications, such as real-time manufacturing, fault classification and inference, autonomous cars, etc., are data-driven applications that require machine learning with a wealth of data generated from industrial Internet of Things (IoT) devices. However, conventional approaches of transmitting this rich data to a remote data center to learn may be undesired due to the non-negligible network transmission delay and the sensitiveness of data privacy. By deploying a number of computing-capable devices at the network edge, edge computing supports the implementation of machine learning close to the industrial environment. Considering the heterogeneous computing capability as well as network location of edge devices, there are two types of feasible edge computing based machine learning models, including the centralized learning and federated learning models. In centralized learning, a resource-rich edge server aggregates the data from different IoT devices and performs machine learning. In federated learning, distributed edge devices and a federated server collaborate to perform machine learning. The features that data should be offloaded in centralized learning while it is locally trained in federated learning make centralized learning and federated learning quite different. We study the computation offloading problem for edge computing based machine learning in an industrial environment, considering the abovementioned machine learning models. We formulate a machine learning-based offloading problem with the goal of minimizing the training delay. Then, an energy-constrained delay-greedy (ECDG) algorithm is designed to solve the problem. Finally, simulation studies based on the MNIST dataset have been conducted to illustrate the efficiency of the proposal.",https://ieeexplore.ieee.org/document/9255001/,IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society,18-21 Oct. 2020,ieeexplore
10.1109/ICSPIS48872.2019.9066130,Deep Vision for Navigation of Autonomous Motorcycle in Urban and Semi-Urban Environments,IEEE,Conferences,"Deep neural networks are currently the best solution for road and traffic scene interpretation for autonomous and self-driving vehicles. Compared to the autonomous cars, motorcycles have significant flexibility and advantages in crowded traffic situations and especially in non-urban and off-road areas. Many off-road tracks especially for agriculture and environment management tasks are only traversable with motorcycles. In this paper, a deep neural network is used for design and implementation of the vision system for navigation of an autonomous motorcycle. The proposed framework is evaluated using real world scenarios captured by a real motorcycle in various complex situations. The experimental results show that the proposed framework is capable of highly accurate interpretation of various environments for autonomous navigation of a motorcycle.",https://ieeexplore.ieee.org/document/9066130/,2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS),18-19 Dec. 2019,ieeexplore
10.1145/3180155.3180220,DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars,IEEE,Conferences,"Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.",https://ieeexplore.ieee.org/document/8453089/,2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE),27 May-3 June 2018,ieeexplore
10.1109/ISSCC42613.2021.9365804,F1: Striking the Balance Between Energy Efficiency &amp; Flexibility: General-Purpose vs Special-Purpose ML Processors,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The forum provides a comprehensive full-stack (hardware and software) view of ML acceleration from cloud to edge. The first talk focuses on the main design and benchmarking challenges facing large general-purpose accelerators, including multi-die scaling, and describes strategies for conducting relevant research as the complexity gap between research prototype and product continues to widen. The second talk looks at how to leverage and specialize the open-source RISC-V ISA for edge ML, exploring the trade-offs between different forms of acceleration such as lightweight ISA extensions and tightly-coupled memory accelerators. The third talk details an approach based on a practical unified architecture for ML that can be easily “tailored” to fit in different scenarios ranging from smart watches, smartphones, autonomous cars to intelligent cloud. The fourth talk explores the co-design of hardware and DNN models to achieve state-of-the-art performance for real-time, extremely energy/throughput-constrained inference applications. The fifth talk deals with ML on reconfigurable logic, discussing many examples of forms of specializations implemented on FPGAs and their impact on potential applications, flexibility, performance and efficiency. The sixth talk describes the software complexities for enabling ML APIs for various different types of specialized hardware accelerators (GPU, TPUs, including EdgeTPU). The seventh talk look into how to optimize the training process for sparse and low-precision network models for general platforms as well as next-generation memristor-based ML engines.",https://ieeexplore.ieee.org/document/9365804/,2021 IEEE International Solid- State Circuits Conference (ISSCC),13-22 Feb. 2021,ieeexplore
10.1109/ITAIC.2019.8785543,Improving Adversarial Images Using Activation Maps,IEEE,Conferences,"Deep Neural Networks are currently gaining a lot of attention for their near human-level performances in tasks such as image classification, object detection, etc. As a result, they are also being deployed in security critical and real time systems such as face recognition and autonomous cars. This requires models to be robust to changes to the input. However, recent literature has showed that they are easily fooled when human imperceptible noise, also known as adversarial noise, is added to the input. By exploiting this adversarial nature, various adversarial attacks and defences against these attacks have been introduced so far. In this paper, we propose a new approach which can be used alongside any existing adversarial attack to further reduce the L2 distance between the generated adversarial image and the original image. Our approach can also be thought of as a new adversarial attack built on top of an existing attack. We evaluated our approach on the ImageNet dataset. Using our approach, we were able to reduce the L2 distance for around 60-70% of the images sampled from the ImageNet dataset.",https://ieeexplore.ieee.org/document/8785543/,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),24-26 May 2019,ieeexplore
10.1109/ICECCE49384.2020.9179457,Limitations of Feature-Classifier Strategies on Pedestrian Detection for Self Driving Cars,IEEE,Conferences,"Evolutionary enhancements are involved by deep learning in computer vision for getting better performance at human-computer interaction. One of the subjects that are known as Pedestrian Detection (PD), is criticized with a lot of problems that are needed to be solved for autonomous cars. Although a significant amount of work has been done for solving these problems, the outcomes have not satisfied the needs of PD. The shortcomings are mainly attributed to datasets, which are believed to be extended significantly to cover real-life scenarios, and utilizing systems, which seem to fail to cover challenging cases due to high dependence on parameters and low generalization capacity. For solving these problems, extensive datasets are collected and existing annotations are updated. More complex and advanced detection/classification systems are developed. Although higher accuracies can be achieved, such datasets and models cause further problems in real-time operation. Accordingly, this study focuses on PD and provides insights from multiple challenging perspectives. First, the main goal is building models for Alpha Development Board, which is constructed for Advanced Driver Assistance Systems. Since the use of deep models is still not easy to be executed on dedicated hardware, as a second step, one of the most used approaches to boost PD performance, well-established hand-crafted feature-classifier combinations, are implemented. Third, the implemented methods are applied to recent datasets to observe the performance as well as inter-dataset dependency. The results show that, albeit being complementary, different feature-classifier pairs can only provide acceptable accuracy for cases that do not include any challenging scenarios.",https://ieeexplore.ieee.org/document/9179457/,"2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE)",12-13 June 2020,ieeexplore
10.1109/ICM48031.2019.9021904,Low power CNN hardware FPGA implementation,IEEE,Conferences,"A convolution Neural Networks (CNN) goes under the wide umbrella of Deep Neural Networks (DNN) whose applications are widely used. For example, the later are used in robotics and different applications of recognition like speech recognition and facial recognition, also nowadays in autonomous cars. Therefore the aim of implementing the CNN is to be used in real time applications. As a result of that, Graphics processing units (GPUs) are used but their worst disadvantage is it's high power consumption which can't be used in daily used equipments. The target of this paper is to solve the power consumption problem by using Field Programmable Array (FPGA) which has low power consumption, and flexible architecture. The implementation architecture of Alex Network, which consists of three fully connected layers and five convolution layers, on FPGA will depend on two main techniques parallelism of resources, and pipelining inside of some layers.",https://ieeexplore.ieee.org/document/9021904/,2019 31st International Conference on Microelectronics (ICM),15-18 Dec. 2019,ieeexplore
10.1109/ReConFig.2015.7393339,Real-time pedestrian detection on a xilinx zynq using the HOG algorithm,IEEE,Conferences,Advanced driver assistance systems (ADAS) are the key to enable autonomous cars in the near future. One important task for autonomous cars is to detect pedestrians reliably in real-time. The HOG algorithm is one of the best algorithms for this task; however it is very compute intensive. To fulfill the real-time requirements for high resolution images an efficient parallel implementation is necessary. This paper presents an efficient hardware implementation as well as a parallel software implementation of the HOG algorithm for pedestrian detection on a Xilinx Zynq SoC. The hardware implementation achieves a speedup of 2x compared to the parallel software implementation for high resolution images (1920 x 1080). Against state-of-the-art a speedup of 1.32x is achieved. The hardware implementation has a reliable detection rate of 90.2% using a classifier trained by an AdaBoost algorithm and a minor false positive rate of 4 %.,https://ieeexplore.ieee.org/document/7393339/,2015 International Conference on ReConFigurable Computing and FPGAs (ReConFig),7-9 Dec. 2015,ieeexplore
10.1109/FPL.2018.00056,Reconfigurable Acceleration of 3D-CNNs for Human Action Recognition with Block Floating-Point Representation,IEEE,Conferences,"Human action recognition (HAR) has been widely employed in various applications such as autonomous cars and intelligent video surveillance. Among the algorithms proposed for HAR, the 3D-CNNs algorithm can achieve the best accuracy. However, its algorithmic complexity imposes a substantial overhead over the speed of these networks, which limits their deployment in real-life applications. This paper proposes a novel customizable architecture for 3D-CNNs based on block floating-point (BFP) arithmetic, where the utilization of BFP significantly reduces the bitwidth while eliminating the need to retrain the network. Optimizations such as locality exploration and block alignment with 3D blocking are performed to improve performance and accuracy. An analytical model and tool are developed to predict the optimized parameters for hardware customization based on user constraints such as FPGA resources or accuracy requirement. Experiments show that without retraining, a 15-bit mantissa design using single-precision accumulation on a Xilinx ZC706 device can be 8.2 times faster than an Intel i7-950 processor at 3.07 GHz with only 0.4% accuracy loss.",https://ieeexplore.ieee.org/document/8533510/,2018 28th International Conference on Field Programmable Logic and Applications (FPL),27-31 Aug. 2018,ieeexplore
10.1109/QRS.2019.00059,TFCheck : A TensorFlow Library for Detecting Training Issues in Neural Network Programs,IEEE,Conferences,"The increasing inclusion of Machine Learning (ML) models in safety-critical systems like autonomous cars have led to the development of multiple model-based ML testing techniques. One common denominator of these testing techniques is their assumption that training programs are adequate and bug-free. These techniques only focus on assessing the performance of the constructed model using manually labeled data or automatically generated data. However, their assumptions about the training program are not always true as training programs can contain inconsistencies and bugs. In this paper, we examine training issues in ML programs and propose a catalog of verification routines that can be used to detect the identified issues, automatically. We implemented the routines in a Tensorflow-based library named TFCheck. Using TFCheck, practitioners can detect the aforementioned issues automatically. To assess the effectiveness of TFCheck, we conducted a case study with real-world, mutants, and synthetic training programs. Results show that TFCheck can successfully detect training issues in ML code implementations.",https://ieeexplore.ieee.org/document/8854684/,"2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS)",22-26 July 2019,ieeexplore
10.1109/ISORC49007.2020.00018,Time-dependent Decentralized Routing using Federated Learning,IEEE,Conferences,"Recent advancements in cloud computing have driven rapid development in data-intensive smart city applications by providing near real time processing and storage scalability. This has resulted in efficient centralized route planning services such as Google Maps, upon which millions of users rely. Route planning algorithms have progressed in line with the cloud environments in which they run. Current state of the art solutions assume a shared memory model, hence deployment is limited to multiprocessing environments in data centers. By centralizing these services, latency has become the limiting parameter in the technologies of the future, such as autonomous cars. Additionally, these services require access to outside networks, raising availability concerns in disaster scenarios. Therefore, this paper provides a decentralized route planning approach for private fog networks. We leverage recent advances in federated learning to collaboratively learn shared prediction models online and investigate our approach with a simulated case study from a mid-size U.S. city.",https://ieeexplore.ieee.org/document/9112993/,2020 IEEE 23rd International Symposium on Real-Time Distributed Computing (ISORC),19-21 May 2020,ieeexplore
10.1109/M2VIP.2018.8600864,Unsupervised Video Prediction Network with Spatio-temporal Deep Features,IEEE,Conferences,"Predicting the future states of things is an important performance form of intelligence and it is also of vital importance in real-time systems such as autonomous cars and robotics. This paper aims to tackle a video prediction task. Previous methods for future frame prediction are always subject to restrictions from environment, leading to poor accuracy and blurry prediction details. In this work, we present an unsupervised video prediction framework which iteratively anticipates the raw RGB pixel values in future video frames. Extensive experiments are implemented on advanced datasets - KTH and KITTI. The results demonstrate that our method achieves a good performance.",https://ieeexplore.ieee.org/document/8600864/,2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),20-22 Nov. 2018,ieeexplore
10.1109/LRA.2020.2967296,Aerial Single-View Depth Completion With Image-Guided Uncertainty Estimation,IEEE,Journals,"On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.",https://ieeexplore.ieee.org/document/8962227/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/ACCESS.2019.2942390,"Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions",IEEE,Journals,"Driven by the demand to accommodate today's growing mobile traffic, 5G is designed to be a key enabler and a leading infrastructure provider in the information and communication technology industry by supporting a variety of forthcoming services with diverse requirements. Considering the ever-increasing complexity of the network, and the emergence of novel use cases such as autonomous cars, industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML) is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised, unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of ML in the context of mobile and wireless communication, organizing the literature in terms of the types of learning. We then discuss the promising approaches for how ML can contribute to supporting each target 5G network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G), providing future research directions for how ML can contribute to realizing B5G. This article is intended to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of autonomous 5G/B5G mobile and wireless communications.",https://ieeexplore.ieee.org/document/8844682/,IEEE Access,2019,ieeexplore
10.1109/COMST.2021.3095358,Towards Low-Latency Service Delivery in a Continuum of Virtual Resources: State-of-the-Art and Research Directions,IEEE,Journals,"The advent of softwarized networks has enabled the deployment of chains of virtual network and service components on computational resources from the cloud up to the edge, creating a continuum of virtual resources. The next generation of low latency applications (e.g., Virtual Reality (VR), autonomous cars) adds even more stringent requirements to the infrastructure, calling for considerable advancements towards cloud-native micro-service-based architectures. This article presents a comprehensive survey on ongoing research aiming to effectively support low latency services throughout their execution lifetime in next-generation networks. The current state-of-the-art is critically reviewed to identify the most promising trends that will strongly impact the full applicability and high performance of low latency services. This article proposes a taxonomy as well as specific evaluation criteria to classify research across different domains addressing low latency service delivery. Current architectural paradigms such as Multi-access Edge Computing (MEC) and Fog Computing (FC) alongside novel trends on communication networks are discussed. Among these, the integration of Machine Learning (ML) and Artificial intelligence (AI) is introduced as a key research field in current literature towards autonomous network management. A discussion on open challenges and future research directions on low-latency service delivery leads to the conclusion, offering lessons learned and prospects on emerging use cases such as Extended Reality (XR), in which novel trends will play a major role.",https://ieeexplore.ieee.org/document/9476028/,IEEE Communications Surveys & Tutorials,Fourthquarter 2021,ieeexplore
10.1109/SYSOSE.2017.7994953,Autonomous decision making for a driver-less car,IEEE,Conferences,"Autonomous driving has been a hot topic with companies like Google, Uber, and Tesla because of the complexity of the problem, seemingly endless applications, and capital gain. The technology's brain child is DARPA's autonomous urban challenge from over a decade ago. Few companies have had some success in applying algorithms to commercial cars. These algorithms range from classical control approaches to Deep Learning. In this paper, we will use Deep Learning techniques and the Tensor flow framework with the goal of navigating a driverless car through an urban environment. The novelty in this system is the use of Deep Learning vs. traditional methods of real-time autonomous operation as well as the application of the Tensorflow framework itself. This paper provides an implementation of AlexNet's Deep Learning model for identifying driving indicators, how to implement them in a real system, and any unforeseen drawbacks to these techniques and how these are minimized and overcome.",https://ieeexplore.ieee.org/document/7994953/,2017 12th System of Systems Engineering Conference (SoSE),18-21 June 2017,ieeexplore
10.23919/IConAC.2018.8748986,"Improvement of Driverless Cars' Passengers on Board Health and Safety, using Low-Cost Real-Time Heart Rate Monitoring System",IEEE,Conferences,"In this work, a real-time unobtrusive heart rate monitoring system is proposed and implemented. The proposed system aims to monitor the heart rate of the passengers by using a low-cost camera, which can be readily embedded in the car's rear-view mirror. Additionally, we integrate this system with the main system of our test driverless car, and we propose how driverless cars should act in response to serious medical emergency situations. Moreover, we investigate how this system can benefit from the promising features of Google I/O and Google AI. Our approach is based on Remote Photoplethysmography (rPPG), in which the heart rate is extracted from the subtle tiny changes occurring in the skin color of the face during every pulsation. The face is automatically detected and tracked, then the raw signal is calculated from each frame over a 10-seconds sliding window. After that, a series of signal processing techniques are implemented on the raw signals to recover the heart rate frequency. Finally, the resultant heart rate measurements are processed and stored, then we compare it with ground truth measurements values obtained using pulse oximeter.",https://ieeexplore.ieee.org/document/8748986/,2018 24th International Conference on Automation and Computing (ICAC),6-7 Sept. 2018,ieeexplore
10.23919/IConAC.2018.8748986,"Improvement of Driverless Cars' Passengers on Board Health and Safety, using Low-Cost Real-Time Heart Rate Monitoring System",IEEE,Conferences,"In this work, a real-time unobtrusive heart rate monitoring system is proposed and implemented. The proposed system aims to monitor the heart rate of the passengers by using a low-cost camera, which can be readily embedded in the car's rear-view mirror. Additionally, we integrate this system with the main system of our test driverless car, and we propose how driverless cars should act in response to serious medical emergency situations. Moreover, we investigate how this system can benefit from the promising features of Google I/O and Google AI. Our approach is based on Remote Photoplethysmography (rPPG), in which the heart rate is extracted from the subtle tiny changes occurring in the skin color of the face during every pulsation. The face is automatically detected and tracked, then the raw signal is calculated from each frame over a 10-seconds sliding window. After that, a series of signal processing techniques are implemented on the raw signals to recover the heart rate frequency. Finally, the resultant heart rate measurements are processed and stored, then we compare it with ground truth measurements values obtained using pulse oximeter.",https://ieeexplore.ieee.org/document/8748986/,2018 24th International Conference on Automation and Computing (ICAC),6-7 Sept. 2018,ieeexplore
10.23919/IConAC.2018.8748986,"Improvement of Driverless Cars' Passengers on Board Health and Safety, using Low-Cost Real-Time Heart Rate Monitoring System",IEEE,Conferences,"In this work, a real-time unobtrusive heart rate monitoring system is proposed and implemented. The proposed system aims to monitor the heart rate of the passengers by using a low-cost camera, which can be readily embedded in the car's rear-view mirror. Additionally, we integrate this system with the main system of our test driverless car, and we propose how driverless cars should act in response to serious medical emergency situations. Moreover, we investigate how this system can benefit from the promising features of Google I/O and Google AI. Our approach is based on Remote Photoplethysmography (rPPG), in which the heart rate is extracted from the subtle tiny changes occurring in the skin color of the face during every pulsation. The face is automatically detected and tracked, then the raw signal is calculated from each frame over a 10-seconds sliding window. After that, a series of signal processing techniques are implemented on the raw signals to recover the heart rate frequency. Finally, the resultant heart rate measurements are processed and stored, then we compare it with ground truth measurements values obtained using pulse oximeter.",https://ieeexplore.ieee.org/document/8748986/,2018 24th International Conference on Automation and Computing (ICAC),6-7 Sept. 2018,ieeexplore
10.1109/ITSC.2016.7795536,Multivariate modelling for autonomous vehicles: Research trends in perspective,IEEE,Conferences,"Over the last decade, the impressive technological advancement around artificial intelligence have encouraged and stimulated much research on driverless cars. Inevitability, such novelty casts huge speculation on its effective deployment in the urban reality. The viability issue of cybercars demands appropriate research so as to infer and validate upcoming impacts at different levels, especially the mobility level, and address new performance measures intrinsic to this novel transportation paradigm. Therefore, this paper presents a short overview perspective about the definitions around the so-called autonomous vehicles. Additionally, as long as multivariate modelling is concerned, this position paper contributes with insights that span some of the future problematics and research questions regarding the automated vehicles topic.",https://ieeexplore.ieee.org/document/7795536/,2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC),1-4 Nov. 2016,ieeexplore
10.1109/WCNC.2019.8886037,Pedestrian Detection for Autonomous Driving within Cooperative Communication System,IEEE,Conferences,"The ability to perceive and understand surrounding road-users behaviors is crucial for self-driving vehicles to correctly plan reliable reactions. Computer vision that relies mostly on machine learning techniques enables autonomous vehicles to perform several required tasks such as pedestrian detection. Furthermore, within a fully autonomous driving environment, driverless vehicle has to communicate and share perceived data with its neighboring vehicles for more safe navigation. In this context, our paper proposes a warning notification diffusion solution related to real-time pedestrian presence detection, through an inter-vehicle communication system. To achieve this purpose, pedestrian and vehicle recognition is required. Thus, we implemented intended detectors. We used Histogram of Oriented Gradients (HOG) descriptor with the linear Support Vector Machine (SVM) classifier for the pedestrian detector, and Haar feature-based cascade classifier to reach vehicle detection. The performance evaluation of our solution leads to fairly good detection accuracy around 90% for pedestrian and 88% for vehicle.",https://ieeexplore.ieee.org/document/8886037/,2019 IEEE Wireless Communications and Networking Conference (WCNC),15-18 April 2019,ieeexplore
10.1109/IV47402.2020.9304624,Autonomous Driving: Framework for Pedestrian Intention Estimation in a Real World Scenario,IEEE,Conferences,"Rapid advancements in driver assistance technology will lead to the integration of fully autonomous vehicles on our roads that will interact with other road users. To address the problem that driverless vehicles make interaction through eye contact impossible, we describe a framework for estimating the crossing intentions of pedestrians in order to reduce the uncertainty that the lack of eye contact between road users creates. The framework was deployed in a real vehicle and tested with three experimental cases that showed a variety of communication messages to pedestrians in a shared space scenario. Results from the performed field tests showed the feasibility of the presented approach.",https://ieeexplore.ieee.org/document/9304624/,2020 IEEE Intelligent Vehicles Symposium (IV),19 Oct.-13 Nov. 2020,ieeexplore
10.1109/CCAI50917.2021.9447457,Positioning Accuracy Optimization of DSO-SLAM and Its Use for the Localization of Unmanned Vehicle,IEEE,Conferences,"In present work, Direct Sparse Odometry (DSO) of visual SLAM is selected as an auxiliary scheme for unmanned vehicles to solve the problem of poor positioning accuracy or inability to locate caused by multipath refraction. By extracting pixels and feature points jointly in the frontend, it can be ensured that the DSO maintained robustness in weak texture regions, while not omitting the feature corners with repeatability. To improve the positioning accuracy of DSO, the pose-graph optimization and loop closure detection with bag-of-words (BoW) are adopted. The optimized DSO has been compared with the original model in the dataset and verified by experiment in the campus scene. The results show that, the optimized algorithm can accurately detect loop closing, reduce the absolute trajectory error (ATE) of DSO by 61.26%, and greatly improve the positioning accuracy without sacrificing real-time and robustness. It verifies the validity of the DSO with loop closure detection, and provides a new method for the core positioning algorithm of driverless vehicles.",https://ieeexplore.ieee.org/document/9447457/,2021 International Conference on Computer Communication and Artificial Intelligence (CCAI),7-9 May 2021,ieeexplore
10.1109/ACCESS.2020.3001277,"A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals, Technology Integration, and State-of-the-Art",IEEE,Journals,"Driven by the emergence of new compute-intensive applications and the vision of the Internet of Things (IoT), it is foreseen that the emerging 5G network will face an unprecedented increase in traffic volume and computation demands. However, end users mostly have limited storage capacities and finite processing capabilities, thus how to run compute-intensive applications on resource-constrained users has recently become a natural concern. Mobile edge computing (MEC), a key technology in the emerging fifth generation (5G) network, can optimize mobile resources by hosting compute-intensive applications, process large data before sending to the cloud, provide the cloud-computing capabilities within the radio access network (RAN) in close proximity to mobile users, and offer context-aware services with the help of RAN information. Therefore, MEC enables a wide variety of applications, where the real-time response is strictly required, e.g., driverless vehicles, augmented reality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G could become a reality with the advent of new technological concepts. The successful realization of MEC in the 5G network is still in its infancy and demands for constant efforts from both academic and industry communities. In this survey, we first provide a holistic overview of MEC technology and its potential use cases and applications. Then, we outline up-to-date researches on the integration of MEC with the new technologies that will be deployed in 5G and beyond. We also summarize testbeds and experimental evaluations, and open source activities, for edge computing. We further summarize lessons learned from state-of-the-art research works as well as discuss challenges and potential future directions for MEC research.",https://ieeexplore.ieee.org/document/9113305/,IEEE Access,2020,ieeexplore
10.23919/FRUCT52173.2021.9435505,Development of the Detecting System of the Landmark Tags to Increase the Navigation Accuracy of an Unmanned Vehicle in a Known Location,IEEE,Conferences,This paper proposes the landmark detection system for use in unmanned vehicle based on NVIDIA Jetson embedded device. The paper describes the synthetic dataset generation and training YOLOv4 neural network using data augmentation and transfer learning techniques to detect the landmark in incomplete data conditions. The real-time landmark detection module was implemented on the NVIDIA Jetson Xavier. The final mean average precision was resulted as 83.8%.,https://ieeexplore.ieee.org/document/9435505/,2021 29th Conference of Open Innovations Association (FRUCT),12-14 May 2021,ieeexplore
10.1109/CCAI50917.2021.9447457,Positioning Accuracy Optimization of DSO-SLAM and Its Use for the Localization of Unmanned Vehicle,IEEE,Conferences,"In present work, Direct Sparse Odometry (DSO) of visual SLAM is selected as an auxiliary scheme for unmanned vehicles to solve the problem of poor positioning accuracy or inability to locate caused by multipath refraction. By extracting pixels and feature points jointly in the frontend, it can be ensured that the DSO maintained robustness in weak texture regions, while not omitting the feature corners with repeatability. To improve the positioning accuracy of DSO, the pose-graph optimization and loop closure detection with bag-of-words (BoW) are adopted. The optimized DSO has been compared with the original model in the dataset and verified by experiment in the campus scene. The results show that, the optimized algorithm can accurately detect loop closing, reduce the absolute trajectory error (ATE) of DSO by 61.26%, and greatly improve the positioning accuracy without sacrificing real-time and robustness. It verifies the validity of the DSO with loop closure detection, and provides a new method for the core positioning algorithm of driverless vehicles.",https://ieeexplore.ieee.org/document/9447457/,2021 International Conference on Computer Communication and Artificial Intelligence (CCAI),7-9 May 2021,ieeexplore
10.1109/ACC.2016.7525529,A Supervised Adaptive Learning-based Fuzzy Controller for a non-linear vehicle system using Neural Network Identification,IEEE,Conferences,"In this paper, a Supervised Adaptive Learning-based Fuzzy Controller (ALFC) with Neural Network Identification and Convex Parameterization is designed to identify and control the unmanned vehicle in an autonomous parking system. The objective is to achieve robust learning and control while maintaining a low implementation cost. The proposed algorithm design incorporates the following learning and control theorems - non-linear system identification using neural network, fuzzy logic, supervised adaptive learning as well as multiple model based convex parameterization. To demonstrate the algorithm in a more straight forward manner, we are using a real nonlinear unmanned autonomous driving system as an example to apply the algorithm and showing the superior performance of controller. In the autonomous driving system, the proposed method can be used for both estimating and further controlling a desired vehicle speed and steering wheel turning. With a supervised adaptive learning-based method, robustness can be also assured under various operating environments regardless of unpredictable disturbances. The convex parameterization further improves the speed of convergence of the adaptive learning process for the Fuzzy controller by using the multiple models concept. Last but not least, comparative experiments have also demonstrated that systems equipped with the new algorithm are able to achieve faster and smoother convergence.",https://ieeexplore.ieee.org/document/7525529/,2016 American Control Conference (ACC),6-8 July 2016,ieeexplore
10.23919/FRUCT52173.2021.9435505,Development of the Detecting System of the Landmark Tags to Increase the Navigation Accuracy of an Unmanned Vehicle in a Known Location,IEEE,Conferences,This paper proposes the landmark detection system for use in unmanned vehicle based on NVIDIA Jetson embedded device. The paper describes the synthetic dataset generation and training YOLOv4 neural network using data augmentation and transfer learning techniques to detect the landmark in incomplete data conditions. The real-time landmark detection module was implemented on the NVIDIA Jetson Xavier. The final mean average precision was resulted as 83.8%.,https://ieeexplore.ieee.org/document/9435505/,2021 29th Conference of Open Innovations Association (FRUCT),12-14 May 2021,ieeexplore
10.1109/AERO.2018.8396807,Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles,IEEE,Conferences,"Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400-500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.",https://ieeexplore.ieee.org/document/8396807/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/CICA.2009.4982774,Tutorial CICA-T Computing with intelligence for identification and control of nonlinear systems,IEEE,Conferences,"System characterization and identification are fundamental problems in systems theory and play a major role in the design of controllers. System identification and nonlinear control has been proposed and implemented using intelligent systems such as neural networks, fuzzy logic, reinforcement learning, artificial immune system and many others using inverse models, direct/indirect adaptive, or cloning a linear controller. Adaptive Critic Designs (ACDs) are neural networks capable of optimization over time under conditions of noise and uncertainty. The ACD technique develops optimal control laws using two networks - critic and action. There are merits for each approach adopted will be presented. The primary aim of this tutorial is to provide control and system engineers/researchers from industry/academia, new to the field of computational intelligence with the fundamentals required to benefit from and contribute to the rapidly growing field of computational intelligence and its real world applications, including identification and control of power and energy systems, unmanned vehicle navigation, signal and image processing, and evolvable and adaptive hardware systems.",https://ieeexplore.ieee.org/document/4982774/,2009 IEEE Symposium on Computational Intelligence in Control and Automation,30 March-2 April 2009,ieeexplore
10.1109/AERO.2018.8396807,Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles,IEEE,Conferences,"Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400-500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.",https://ieeexplore.ieee.org/document/8396807/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/ANDESCON50619.2020.9272196,Multipurpose unmanned system: an efficient solution to increase the capabilities of the UAVs,IEEE,Conferences,"The results of this research propose the implementation of a system that significantly increases the capacity of unmanned vehicles, turning them into multifunctional vehicles. The system has a logistics dispatch module and a video analytics module. The first module allows the delivery of medical, food, smoke, disinfectant, etc. The module is practical, safe and economical, features that denote the feasibility of immediate implementation in unmanned vehicles of any rank and / or classification. Note that the implementation of the dispatch module does not require additional radio frequency systems. The second module includes a video analysis process in real time, an aspect that constitutes a significant contribution to the proposed solution, since it allows obtaining important information during the flight; it also reduces the risk in air operations and simultaneously increases the efficiency of themselves. Note that video analytics optimizes resources and avoids jeopardizing the lives of aircraft pilots and crews who traditionally should carry out these activities. In times of pandemic, this innovation avoids direct contact with an infected population and can guarantee the sanitary conditions required in certain circumstances. The solution increases the capabilities of unmanned vehicles and makes them useful tools in various scenarios, whether caused by natural or man-made disasters. Our proposal is very flexible, reliable, and scalable and can be adapted to various models and makes of unmanned vehicles. The system has been implemented on fixed-wing and rotary-wing unmanned vehicles, showing satisfactory results.",https://ieeexplore.ieee.org/document/9272196/,2020 IEEE ANDESCON,13-16 Oct. 2020,ieeexplore
10.1109/CCAI50917.2021.9447457,Positioning Accuracy Optimization of DSO-SLAM and Its Use for the Localization of Unmanned Vehicle,IEEE,Conferences,"In present work, Direct Sparse Odometry (DSO) of visual SLAM is selected as an auxiliary scheme for unmanned vehicles to solve the problem of poor positioning accuracy or inability to locate caused by multipath refraction. By extracting pixels and feature points jointly in the frontend, it can be ensured that the DSO maintained robustness in weak texture regions, while not omitting the feature corners with repeatability. To improve the positioning accuracy of DSO, the pose-graph optimization and loop closure detection with bag-of-words (BoW) are adopted. The optimized DSO has been compared with the original model in the dataset and verified by experiment in the campus scene. The results show that, the optimized algorithm can accurately detect loop closing, reduce the absolute trajectory error (ATE) of DSO by 61.26%, and greatly improve the positioning accuracy without sacrificing real-time and robustness. It verifies the validity of the DSO with loop closure detection, and provides a new method for the core positioning algorithm of driverless vehicles.",https://ieeexplore.ieee.org/document/9447457/,2021 International Conference on Computer Communication and Artificial Intelligence (CCAI),7-9 May 2021,ieeexplore
10.1109/TITS.2018.2843815,Real-Time Traffic Sign Recognition Based on Efficient CNNs in the Wild,IEEE,Journals,"Both unmanned vehicles and driver assistance systems require solving the problem of traffic sign recognition. A lot of work has been done in this area, but no approach has been presented to perform the task with high accuracy and high speed under various conditions until now. In this paper, we have designed and implemented a detector by adopting the framework of faster R-convolutional neural networks (CNN) and the structure of MobileNet. Here, color and shape information have been used to refine the localizations of small traffic signs, which are not easy to regress precisely. Finally, an efficient CNN with asymmetric kernels is used to be the classifier of traffic signs. Both the detector and the classifier have been trained on challenging public benchmarks. The results show that the proposed detector can detect all categories of traffic signs. The detector and the classifier proposed here are proved to be superior to the state-of-the-art method. Our code and results are available online.",https://ieeexplore.ieee.org/document/8392744/,IEEE Transactions on Intelligent Transportation Systems,March 2019,ieeexplore
10.1109/ITAIC.2011.6030219,A redeployment strategy based on Unmanned Aerial Vehicle in wireless sensor network,IEEE,Conferences,"In reality, holes in large-scale sensor networks are exist due to various reasons, such as energy depletion and randomness deployment. These holes may degrade the detection performance of the entire sensor networks. Based on the probabilistic detection model with false alarm rate, this paper proposes a new redeployment method. A method of using an Unmanned Aerial Vehicle (UAV) was proposed for boundaries of holes detection. In particular, in this paper, the contour graph was used for redeploy the holes based on depth-first strategy. According to the simulation results, the proposed method can attain better coverage rate.",https://ieeexplore.ieee.org/document/6030219/,2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference,20-22 Aug. 2011,ieeexplore
10.1109/CIMCA.2005.1631523,Autonomous Landing of an Unmanned Aerial Vehicle,IEEE,Conferences,"In this paper, the design and implementation of a real-time landing algorithm for an autonomous helicopter is presented. The helicopter uses an onboard acquisition system to obtain the GPS and the sonar data to update its landing parameters. To control the path during the land step a fuzzy logic controller located in the fixed station is used. This controller is included in a low level module of a hierarchical-based control structure. Experimental results from flight tests in the field are presented, demonstrating that this control algorithm is accurate and robust",https://ieeexplore.ieee.org/document/1631523/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/SSCI.2018.8628656,Brain Emotional Learning-Based Path Planning and Intelligent Control Co-Design for Unmanned Aerial Vehicle in Presence of System Uncertainties and Dynamic Environment,IEEE,Conferences,"This paper proposes a novel intelligent path planning and control co-design for Unmanned Aerial Vehicles (UAVs) in the presence of system uncertainties and dynamic environments. In order to simultaneously handle the uncertainties from both the UAV platform itself and from the environment, a novel biologically-inspired approach based on a computational model of emotional learning in mammalian limbic system is adopted. The methodology, known as Brain Emotional Learning (BEL), is implemented in this application for the first time. Making use of the multi-objective properties and the real-time learning capabilities of BEL, the path planning and control co-design are applied in a synthetic UAV path planning scenario, successfully dealing with the challenges caused by system uncertainties and dynamic environments. A Lyapunov analysis demonstrates the convergence of the co-design, and a set of numerical results illustrate the effectiveness of the proposed approach. Furthermore, it is shown that the low computational complexity of the method guarantees its implementation in real-time applications.",https://ieeexplore.ieee.org/document/8628656/,2018 IEEE Symposium Series on Computational Intelligence (SSCI),18-21 Nov. 2018,ieeexplore
10.1109/ComPE49325.2020.9200107,Inspection of Concrete Structures by a Computer Vision Technique and an Unmanned Aerial Vehicle,IEEE,Conferences,"We have proposed a visual inspection technique for concrete structures using deep learning and a hardware ecosystem, an Unmanned Aerial Vehicle (UAV). The UAV is a quadcopter that can fly to unreachable sections of a site which consists of a camera that captures images of the concrete surfaces via a mobile device and feed the real time images in the CNN model. The images taken from such remote locations may contain different types of surfaces, shadowed regions and surfaces with holes. The cracks are properly detected by the CNN `AlexNet' algorithm and masking with sliding window technique in such conditions due to variation in the image data set. The experimental results were simulated on a standard online data set of 40,000 images of Mendeley Data which is freely available and 3000 images have been chosen from the entire data set for this method. The classes have been divided into 2 categories of `crack' and `no crack' for the proposed method's data set. There are 1050 training images and 450 testing images for each category. Experimental results were achieved on Google Colab cloud service using Python Tensorflow API (Application Programming Interface). The proposed `AlexNet' CNN algorithm achieves 98.4 % accuracy and the model is deployed to a masking technique with sliding window to detect cracks in a 3008×2000 pixel resolution image by breaking the image into 227×227 pixel resolution image patches. The experimental results have proved that the proposed method handles noisy background such as cracks with shadows and stains, cracks on rusty and rough surfaces and minor dimension cracks with good efficiency.",https://ieeexplore.ieee.org/document/9200107/,2020 International Conference on Computational Performance Evaluation (ComPE),2-4 July 2020,ieeexplore
10.1109/ICSTCC50638.2020.9259777,Integrated Fault Detection and Diagnosis of an Unmanned Aerial Vehicle using Time Difference of Arrival,IEEE,Conferences,"An integrated approach to the fault detection and diagnosis (FDD) of an unmanned aerial vehicle is presented. A novel approach using the Time Difference Of Arrival (TDOA) principle has been developed to detect, isolate and identify an incipient fault condition in the rotor dynamics. The requirements of a reconfigurable controller (RC) has been taken into account through the real-time implementation of a continuous forward algorithm (CFA) with a golden section search (GSS) combined with a meta-heuristic global optimization technique. The training and testing data for Radial Basis Function Neural Networks (RBF-NN) learning and prediction were supplied in discrete-time and its integration capacity validated through a Hardware-in-the-loop simulation (HILS) using a Teensy 3.6 microcontroller. The Pseudo real-time desktop simulation showed that the FDD algorithm was able to detect and isolate an incipient rotor fault and supply the RC a post-fault model and associated fault uncertainties. This method showed robustness towards prediction errors (bias and variance) and can be used in an integrated fault-tolerant control framework.",https://ieeexplore.ieee.org/document/9259777/,"2020 24th International Conference on System Theory, Control and Computing (ICSTCC)",8-10 Oct. 2020,ieeexplore
10.1109/MECO.2016.7525773,Neural network implementation of a principal component analysis tasks on board the unmanned aerial vehicle information processing in real time,IEEE,Conferences,"The application of principal component analysis to simplify the classification of pixels of images obtained with the help of unmanned aerial vehicle for the organization received information processing in real time, and simplify the process of orientation of unmanned aerial vehicle on the ground. We consider the neural network of the principal component analysis. The results of experiments showing the effectiveness of such use of principal component analysis.",https://ieeexplore.ieee.org/document/7525773/,2016 5th Mediterranean Conference on Embedded Computing (MECO),12-16 June 2016,ieeexplore
10.1049/cp.2012.1357,Small Unmanned Aerial Vehicle visual system for ground moving target positioning,IET,Conferences,"Recently, Small Unmanned Aerial Vehicles (SUAV) are used in a variety of reconnaissance, surveillance, combat applications and so on. Tracking and positioning ground moving targets using a camera mounted on SUAVs has important applications in military and civilian purposes. Although many approaches for a vision-based target positioning system have been developed, most researches are limited to target recognition algorithm or target state estimation. And hardware implementation schemes which can work well with the whole SUAV system are seldom discussed. In order to achieve an available systematic scheme, a complete visual system which incorporates a vision-based ground moving target positioning algorithm is presented in this paper. Experiment results are finally shown and commented. Experiments indicate that the system performs great real time response and high positioning precision.",https://ieeexplore.ieee.org/document/6492964/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.23919/ACC45564.2020.9147911,Unmanned Aerial Vehicle Angular Velocity Control via Reinforcement Learning in Dimension Reduced Search Spaces,IEEE,Conferences,"Search space dimension reduction strategies are studied for reinforcement learning based angular velocity control of multirotor unmanned aerial vehicles. Reinforcement learning approximates the value function iteratively over the state-action space, which is 6-dimensional in the case of multirotor angular velocity control. An inverse-dynamics approach is applied to reduce the 6-dimensional state-action space to a 3-dimensional state-only search space while estimating the uncertain model parameters. The search space dimension is further reduced when the state variables are only allowed to vary following either a motion camouflage strategy or a hyperbolic tangent path. Simulation results show that the modified reinforcement learning algorithms can be implemented in real time for multirotor angular velocity control.",https://ieeexplore.ieee.org/document/9147911/,2020 American Control Conference (ACC),1-3 July 2020,ieeexplore
10.1109/TIE.2017.2764849,A Vision-Aided Approach to Perching a Bioinspired Unmanned Aerial Vehicle,IEEE,Journals,"This paper presents the implementation of a machine learning approach for replicating highly adaptive avian perching behavior. With full consideration of both the configuration of flying vehicles and perching principles, a bioinspired aerial robot comprising one flight subsystem and one perching subsystem is designed. Based on the real-time landing speed and attitude, a novel type of soft grasping mechanism for dexterous perching is proposed to provide adhesive force and absorb impact force. During the critical perching phase, the dynamics of the perching actuator change with the touchdown conditions and the type of perching target. A hybrid automation of a time-to-contact theory-based attitude controller and a robust self-localization system are utilized to regulate the desired perching maneuvers. The experimental results are provided to attest to the effectiveness of the proposed perching method.",https://ieeexplore.ieee.org/document/8074761/,IEEE Transactions on Industrial Electronics,May 2018,ieeexplore
10.1109/ICRA.2019.8794446,A Reinforcement Learning Approach for Control of a Nature-Inspired Aerial Vehicle,IEEE,Conferences,"In this work, reinforcement learning is used to develop a position controller for an underactuated nature-inspired Unmanned Aerial Vehicle (UAV). This particular configuration of UAVs achieves lift by spinning its entire body contrary to standard multi-rotors or fixed-wing aircraft. Deep Deterministic Policy Gradients (DDPG) with Ape-X Distributed Prioritized Experience Replay was used to train neural network function approximators that were implemented as the final control policy. The reinforcement learning agent was trained in simulations and directly ported over to real-life hardware. Position control tests were performed on the learned control policy and compared to a baseline PID controller. The learned controller was found to exhibit better control over the inherent oscillations that arise from the non-linear dynamics of the platform.",https://ieeexplore.ieee.org/document/8794446/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICUAS.2019.8798329,A Vision-based Unmanned Aircraft System for Autonomous Grasp &amp; Transport,IEEE,Conferences,"The progress in sensor technologies, computer capabilities and artificial intelligence has endowed the unmanned aircraft system (UAS) with more autonomous abilities. Motivated by the 6th International Unmanned Aerial Vehicle Innovation Grand Prix (UAVGP), a UAS with high degree of autonomy was developed to perform the mission of building a simulated tower using prefabricated components. According to the requirement of the competition, the UAS was designed and implemented from the following four parts: 1) navigation and control, 2) recognition and location, 3) grasp and construction, and 4) task planning and scheduling. Different levels of autonomy have been given to the UAS based on these parts. The system hardware was developed on a quadrotor platform by integrating various components, including sensors, computers, power and grasp mechanism. Software which included precise navigation, mission planning, real-time perception and control was implemented and integrated with the developed UAS hardware. The performance in the test environment and actual competition showed that the UAS could perform the mission without human intervention with high autonomy and reliability. This paper addresses the major components and development process of the UAS and describes its application to the practical mission.",https://ieeexplore.ieee.org/document/8798329/,2019 International Conference on Unmanned Aircraft Systems (ICUAS),11-14 June 2019,ieeexplore
10.23919/URSI-AT-RASC.2018.8471616,A Wireless Method for Drone Identification and Monitoring Using AIS Technology,IEEE,Conferences,"The fast growth of UAV (Unmanned Aerial Vehicle) technology in the last years has allowed to extend the use of these devices in many applications. However, the massive use of drones has alerted many governments about an inadequate usage, mainly in terms of security and terrorism. In regards to this problem, some laws about drone usage have been approved by some countries. Among these laws, it is mandatory that all drones are identified and monitored all the time. In this paper, a wireless prototype to identify drones is proposed. To that end, the AIS (Automatic Identification System) is used to transmit parameters as name, ID, speed or the course of drones. This proposed solution can solve the drone identification problem and even, allows to monitor this device in real time. A prototype of this method has been implemented and tested in a real environment, around many locations in the island of Gran Canaria.",https://ieeexplore.ieee.org/document/8471616/,2018 2nd URSI Atlantic Radio Science Meeting (AT-RASC),28 May-1 June 2018,ieeexplore
10.1109/ITAIC.2011.6030219,A redeployment strategy based on Unmanned Aerial Vehicle in wireless sensor network,IEEE,Conferences,"In reality, holes in large-scale sensor networks are exist due to various reasons, such as energy depletion and randomness deployment. These holes may degrade the detection performance of the entire sensor networks. Based on the probabilistic detection model with false alarm rate, this paper proposes a new redeployment method. A method of using an Unmanned Aerial Vehicle (UAV) was proposed for boundaries of holes detection. In particular, in this paper, the contour graph was used for redeploy the holes based on depth-first strategy. According to the simulation results, the proposed method can attain better coverage rate.",https://ieeexplore.ieee.org/document/6030219/,2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference,20-22 Aug. 2011,ieeexplore
10.1109/ICRAE48301.2019.9043821,An Improved Method Based on Deep Reinforcement Learning for Target Searching,IEEE,Conferences,"Unmanned Aerial Vehicle (UAV), due to their high mobility and the ability to cover areas of different heights and locations at relatively low cost, are increasingly used for disaster monitoring and detecting. However, developing and testing UAVs in real world is an expensive task, especially in the domain of search and rescue, most of the previous systems are developed on the basis of greedy or potential-based heuristics without neural network. On the basis of the recent development of deep neural network architecture and deep reinforcement learning (DRL), in this research we improved the probability of success rate of searching target in an unstructured environment by combining image processing algorithms and reinforcement learning methods (RL). This paper aims at the deficiency of target tracking in unstructured environment, trying to propose an algorithm of stationary target positioning of UAV based on computer vision system. Firstly, a new input source is formed by acquiring depth information image of current environment and combining segmentation image. Secondly, the DQN algorithm is used to regulate the reinforcement learning model, and the specific flight response can be independently selected by the UAV through training. This paper utilizes open-source Microsoft UAV simulator AirSim as training and test environment based with Keras a machine learning framework. The main approach investigated in this research is modifying the network of Deep Q-Network, which designs the moving target tracking experiment of UAV in simulation scene. The experimental results demonstrate that this method has better tracking effect.",https://ieeexplore.ieee.org/document/9043821/,2019 4th International Conference on Robotics and Automation Engineering (ICRAE),22-24 Nov. 2019,ieeexplore
10.1049/cp.2012.1044,Attitude stabilization control of a quadrotor helicopter using integral Backstepping,IET,Conferences,"Quadrotor helicopters are emerging as a popular platform for unmanned aerial vehicle (UAV) research. This work included integral action in a Backstepping design for attitude stabilization control of quadrotor helicopter. Firstly, a complete dynamic model of quadrotor was built using blade element and momentum theories. Based on this dynamic model a new controller called ‘Integral Backstepping’ was designed by added tracking error integral term to the normal Backstepping controller. Through various simulations and the real flight experiment, it is proved that the new controller was quite effective and the integral term indeed brought robustness against model uncertainties in the controller.",https://ieeexplore.ieee.org/document/6492651/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/WorldS4.2019.8904014,Autonomous Drone for Defence Machinery Maintenance and Surveillance,IEEE,Conferences,"This proposed research work focuses on the implementation of an autonomous unmanned aerial vehicle (UAV) which is controlled using a pix hawk flight controller. The Quad Copter is capable of navigating autonomously without any real-time input from the user and also programmed to follow a specified path autonomously. The algorithm enables a control technique by which quad copter is empowered to fly autonomously, trajectory tracking, graceful motion and accurate altitude hold performance. Surveillance and Machinery maintenance application are the primary applications designed for the Defense purposes in the Line Of Control and War-zones. This work is aimed to design a quad copter that will follow a command to fly through specified way points. The deep learning algorithm detects human motions and from data acquired camera and ultrasonic sensors to the cloud. On deviations from the standard protocol which is detected using a Sjcam 5000x elite Camera. Also, here a backup auxiliary mini drone is programmed to eject along with the data stored on the primary drone's memory on an unforeseen calamity or an attack that would damage the primary drone's ability to fly.",https://ieeexplore.ieee.org/document/8904014/,2019 Third World Conference on Smart Trends in Systems Security and Sustainablity (WorldS4),30-31 July 2019,ieeexplore
10.1109/GLOBECOM42002.2020.9322556,Caching Placement and Resource Allocation for AR Application in UAV NOMA Networks,IEEE,Conferences,"The cache-enabling unmanned aerial vehicle (UAV) cellular networks with massive access capability supported by non-orthogonal multiple access (NOMA) are investigated in this paper. The delivery of multi-media contents for the mixed augmented reality (AR) and normal multi-media application is assisted by multiple mobile UAV base stations, which cache popular contents for wireless backhaul link traffic offloading. To cope with the dynamic content requests and mobility of users in practical scenarios, the dynamic optimization problem for user association, caching placement of UAVs, real-time deployment of UAVs, and power allocation of NOMA is modeled as a stackelberg game to minimize the long-term content delivery delay. Specifically, the game is decomposed into a leader level problem and a number of follower level problems. A correction mechanism is added in deep reinforcement learning (DRL) to optimize the user association in leader level. A meta actor network is proposed in DRL to jointly optimize the UAVs caching placement, real-time UAVs deployment and power allocation of NOMA in follower level. Then, a dynamic caching placement and resource allocation algorithm based on multi-agent meta deep reinforcement learning is proposed to minimize the long-term content delivery delay. Finally, we demonstrate that the considerable gains are achieved by the proposed algorithm.",https://ieeexplore.ieee.org/document/9322556/,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,7-11 Dec. 2020,ieeexplore
10.23919/ChiCC.2019.8865311,Collaborative Multi-Agent Tracking based on Distributed Learning,IEEE,Conferences,"In order to reasonably allocate the Unmanned Aerial Vehicle (UAV) resources and keep the target tracked, we propose a collaborative multi-agent tracking method based on distributed learning. Considering the interactive fusion of information between multiple UAVs, we use the Information Filter (IF) to transform the target state fusion problem into a simple algebraic superposition. Meanwhile, the UAV's movements can be planned in real time so that the UAV formation can obtain more accurate target measurement as much as possible. The simulation experiment of collaborative multi-UAV tracking proves that the distributed multi-UAV system can make reasonable actions and track targets effectively.",https://ieeexplore.ieee.org/document/8865311/,2019 Chinese Control Conference (CCC),27-30 July 2019,ieeexplore
10.1109/ICAIIC51459.2021.9415209,Controller module implementation to reduce interrupt in CNPC uplink,IEEE,Conferences,"The unmanned aerial vehicle is used in diverse area. In order to make more use of the unmanned aerial vehicle, reliable communication system is required. CNPC has been developed to standardize the communication system for unmanned aerial vehicle over 150kg. CNPC uplink should support diverse UAV in TDD. To implement CNPC in real world, operating system and FPGA should be used with the interface between the two. To reduce the use of interrupts in uplink implementations on FPGA, simple controller is designed to generate signals which act as the interrupts whenever other user message is needed. To implement this controller in FPGA, this paper deals with timing diagram for this module.",https://ieeexplore.ieee.org/document/9415209/,2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),13-16 April 2021,ieeexplore
10.1109/VTC2020-Fall49728.2020.9348616,Deep Q-Network Based Dynamic Movement Strategy in a UAV-Assisted Network,IEEE,Conferences,"Unmanned aerial vehicle (UAV)-assisted communications is a promising solution to improve the performance of future wireless networks, where UAVs are deployed as base stations for enhancing the quality of service (QoS) provided to ground users when traditional terrestrial base stations are unavailable or not sufficient. An effective framework is proposed in this paper to manage the dynamic movement of multiple unmanned aerial vehicles (UAVs) in response to ground user mobility, with the objective to maximize the sum data rate of the ground users. First, we discuss the relationship between the air-to-ground (A2G) path loss (PL) and the location of UAVs. Then a deep Q-network (DQN) based method is proposed to adjust the locations of UAVs to maximize the sum data rate of the user equipment (UE). Finally, simulation results show that the proposed method is capable of adjusting UAV locations in a real-time condition to improve the QoS of the entire network.",https://ieeexplore.ieee.org/document/9348616/,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),18 Nov.-16 Dec. 2020,ieeexplore
10.1109/RAAI52226.2021.9508033,Development of Gasoline-Electric Hybrid Propulsion Surveillance and Reconnaissance VTOL UAV,IEEE,Conferences,"Vertical Take-Off and Landing (VTOL) Unmanned Aerial Vehicles (UAV) have been a high potential topic in the aerospace industry during the last decades due to its multirotor and fixed-wing nature of the aircraft. Besides, having the ability to rapidly deploy from a tight airstrip and gathering Intelligence, Surveillance, and Reconnaissance (ISR) information is the best way to be one step ahead of the enemy. In this paper, we present the implementation and development of gasoline-electric hybrid propulsion VTOL Unmanned Aerial vehicle respectively. The Hybrid propulsion VTOL UAV offers image and real-time video transmission to the ground station with fully autonomous control to get the best view of the enemy from the sky. The gasoline-electric hybrid propulsion system provides long flight endurance with efficient power consumption. The fundamentals of the multirotor and the conventional fixed-wing aircraft present the theoretical background of the aircraft. The accomplished design consists of high-performance multirotor motors with an efficient gasoline engine. Furthermore, the control system architecture, avionics, and power distribution system presented with addressing cost-effective trending design techniques. The performance of the system has been improved using commercially off-the-shelf (COTS) hardware.",https://ieeexplore.ieee.org/document/9508033/,"2021 IEEE International Conference on Robotics, Automation and Artificial Intelligence (RAAI)",21-23 April 2021,ieeexplore
,EXPRESS: An Energy-Efficient and Secure Framework for Mobile Edge Computing and Blockchain based Smart Systems,IEEE,Conferences,"As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.",https://ieeexplore.ieee.org/document/9286009/,2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE),21-25 Sept. 2020,ieeexplore
10.1109/ISAECT50560.2020.9523700,Edge-Cloud Architectures Using UAVs Dedicated To Industrial IoT Monitoring And Control Applications,IEEE,Conferences,"The deployment of new technologies to ease the control and management of a massive data volume and its uncertainty is a very significant challenge in the industry. Under the name ""Smart Factory"", the Industrial Internet of Things (IoT) aims to send data from systems that monitor and control the physical world to data processing systems for which cloud computing has proven to be an important tool to meet processing needs. unmanned aerial vehicles (UAVs) are now being introduced as part of IIoT and can perform important tasks. UAVs are now considered one of the best remote sensing techniques for collecting data over large areas. In the field of fog and edge computing, the IoT gateway connects various objects and sensors to the Internet. It function as a common interface for different networks and support different communication protocols. Edge intelligence is expected to replace Deep Learning (DL) computing in the cloud, providing a variety of distributed, low-latency and reliable intelligent services. In this paper, An unmanned aerial vehicle is automatically integrated into an industrial control system through an IoT gateway platform. Rather than sending photos from the UAV to the cloud for processing, an AI cloud trained model is deployed in the IoT gateway and used to process the taken photos. This model is designed to overcome the latency channels of the cloud computing architecture. The results show that the monitoring and tracking process using advanced computing in the IoT gateway is significantly faster than in the cloud.",https://ieeexplore.ieee.org/document/9523700/,2020 International Symposium on Advanced Electrical and Communication Technologies (ISAECT),25-27 Nov. 2020,ieeexplore
10.1109/AIPR50011.2020.9425341,Enhancing Network-edge Connectivity and Computation Security in Drone Video Analytics,IEEE,Conferences,"Unmanned Aerial Vehicle (UAV) systems with high-resolution video cameras are used for many operations such as aerial imaging, search and rescue, and precision agriculture. Multi-drone systems operating in Flying Ad Hoc Networks (FANETS) are inherently insecure and require efficient security schemes to defend against cyber-attacks such as e.g., Man-in-the-middle, Replay and Denial of Service attacks. In this paper, we propose a cloud-based, end-to-end security framework viz., ""DroneNet-Sec"" that provides secure network-edge connectivity, and computation security for drone video analytics to defend against common attack vectors in UAV systems. The DroneNet-Sec features a dynamic security scheme that uses machine learning to detect anomaly events and adopts countermeasures for computation security of containerized video analytics tasks. The security scheme comprises of a custom secure packet designed with MAVLink protocol for ensuring data privacy and integrity, without high degradation of the performance in a real-time FANET deployment. We evaluate DroneNet-Sec in a hybrid testbed that synergies simulation and emulation via an open-source network simulator (NS-3) and a research platform for mobile wireless networks (POWDER). Our performance evaluation experiments in our holistic hybrid-testbed show that DroneNet-Sec successfully detects learned anomaly events and effectively protects containerized tasks execution as well as communication in drones video analytics in a light-weight manner.",https://ieeexplore.ieee.org/document/9425341/,2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR),13-15 Oct. 2020,ieeexplore
10.1109/TENCON.2019.8929613,Fish Detection and Tracking in Pisciculture Environment using Deep Instance Segmentation,IEEE,Conferences,"This study presents a novel approach in detecting and tracking of fish in pisciculture. Pisciculture in general involves challenging tasks of counting and monitoring fish in natural or nature like, man-made habitats such as inland fisheries for breeding, feeding and sorting purposes. These are presently achieved using conventional methods that are inefficient when implemented in large-scale commercial productions. To overcome such difficulties and improve the efficiency of the processes, images of fish and fish seeds are captured in natural murky water habitats through a vision sensor on board an unmanned aerial vehicle (UAV). In this research paper, a deep instance segmentation algorithm called Mask R-CNN along with GOTURN tracking algorithm is employed for real time fish detection and tracking. A comparison study is also carried out (i) fish detection on high resolution images (ii) fish detection on high resolution image multi-region parallel processing (iii) fish detection on high resolution image multi-region parallel processing with tracking. The results are found to be accurate with image multi-region parallel processing along with tracking, with an F1 score of 0.91 at 16 frames per seconds on in-land fishes environment.",https://ieeexplore.ieee.org/document/8929613/,TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON),17-20 Oct. 2019,ieeexplore
10.1109/IAICT50021.2020.9172031,Human Target Search and Detection using Autonomous UAV and Deep learning,IEEE,Conferences,"An Unmanned Aerial Vehicle (UAV) is an airborne system or pilotless aircraft which is remotely controlled by a human operator on ground or by an onboard computer such that the vehicle moves autonomously. The range of applications in which UAVs are used is very large. This paper describes the application of developing an autonomous surveillance system using an UAV to identify a given target and/or objects of interest in the terrain over which it flies. Such a system can be used in rescue operations, especially in remote areas where physical access is difficult. It can also be used for military operations, farming or any field where surveillance of a given land area is required. The UAV developed in this work is capable of object detection. A mounted camera is used to give visual feedback, and an onboard processing unit runs image recognition software to identify the target in real time. Optimal algorithms are used to search and find the target from the given search area. After recognition of the target, the UAV can either be used to hold its position so as to have a video feed of the target, or return to its base station once the coordinates have been estimated using GPS modules or relay the GPS location to the base station. This paper describes the implementation of the hardware and software components that lead to the realization of the UAV and the application of object detection. The details of a new search algorithm and an example of object detection is presented . The work presented in this paper is the first part in the attempt to develop a cluster of UAVs meant to work in collaboration to be deployed for search and rescue operations.",https://ieeexplore.ieee.org/document/9172031/,"2020 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)",7-8 July 2020,ieeexplore
10.1109/ELECSYM.2018.8615503,Implementation of Victims Detection Framework on Post Disaster Scenario,IEEE,Conferences,"Disasters are prone to occur in Indonesia due to geographical factors, such as tectonic plate movements, which can cause an earthquake. Earthquakes are one of the most frequent disasters, they have broad impacts in a short time and are unpredictable. Thus, an extensive search process in a short time is highly critical to determine the victims location. In this paper, a victims detection framework is developed starting from acquiring images using an unmanned aerial vehicle and further processing using convolutional neural network (CNN) to locate victims robustly on post-disaster. Input images are then sent to victim detector dedicated ground station server for further high processing robustly locating the possibility of victims. A simulation system mimicking a real environment is developed to test our framework in real time. A transmission protocol is also developed for effectively transmitting data between the robot and the server. The treatment on the detection process of the victim is different from the normal human detection, some pre-processing stages are applied to increase the variation of the given dataset. An embedded system is used for taking images and additional sensors data, such as location and time using Global Navigation Satellite System.",https://ieeexplore.ieee.org/document/8615503/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/ComPE49325.2020.9200107,Inspection of Concrete Structures by a Computer Vision Technique and an Unmanned Aerial Vehicle,IEEE,Conferences,"We have proposed a visual inspection technique for concrete structures using deep learning and a hardware ecosystem, an Unmanned Aerial Vehicle (UAV). The UAV is a quadcopter that can fly to unreachable sections of a site which consists of a camera that captures images of the concrete surfaces via a mobile device and feed the real time images in the CNN model. The images taken from such remote locations may contain different types of surfaces, shadowed regions and surfaces with holes. The cracks are properly detected by the CNN `AlexNet' algorithm and masking with sliding window technique in such conditions due to variation in the image data set. The experimental results were simulated on a standard online data set of 40,000 images of Mendeley Data which is freely available and 3000 images have been chosen from the entire data set for this method. The classes have been divided into 2 categories of `crack' and `no crack' for the proposed method's data set. There are 1050 training images and 450 testing images for each category. Experimental results were achieved on Google Colab cloud service using Python Tensorflow API (Application Programming Interface). The proposed `AlexNet' CNN algorithm achieves 98.4 % accuracy and the model is deployed to a masking technique with sliding window to detect cracks in a 3008×2000 pixel resolution image by breaking the image into 227×227 pixel resolution image patches. The experimental results have proved that the proposed method handles noisy background such as cracks with shadows and stains, cracks on rusty and rough surfaces and minor dimension cracks with good efficiency.",https://ieeexplore.ieee.org/document/9200107/,2020 International Conference on Computational Performance Evaluation (ComPE),2-4 July 2020,ieeexplore
10.1109/ICSTCC50638.2020.9259777,Integrated Fault Detection and Diagnosis of an Unmanned Aerial Vehicle using Time Difference of Arrival,IEEE,Conferences,"An integrated approach to the fault detection and diagnosis (FDD) of an unmanned aerial vehicle is presented. A novel approach using the Time Difference Of Arrival (TDOA) principle has been developed to detect, isolate and identify an incipient fault condition in the rotor dynamics. The requirements of a reconfigurable controller (RC) has been taken into account through the real-time implementation of a continuous forward algorithm (CFA) with a golden section search (GSS) combined with a meta-heuristic global optimization technique. The training and testing data for Radial Basis Function Neural Networks (RBF-NN) learning and prediction were supplied in discrete-time and its integration capacity validated through a Hardware-in-the-loop simulation (HILS) using a Teensy 3.6 microcontroller. The Pseudo real-time desktop simulation showed that the FDD algorithm was able to detect and isolate an incipient rotor fault and supply the RC a post-fault model and associated fault uncertainties. This method showed robustness towards prediction errors (bias and variance) and can be used in an integrated fault-tolerant control framework.",https://ieeexplore.ieee.org/document/9259777/,"2020 24th International Conference on System Theory, Control and Computing (ICSTCC)",8-10 Oct. 2020,ieeexplore
10.1109/ASCC.2015.7244614,Joint unscented Kalman filter for dual estimation in a bifilar pendulum for a small UAV,IEEE,Conferences,"It has always been difficult to accurately estimate the moment of inertia of an object, e.g. an unmanned aerial vehicle (UAV). Whilst various offline estimation methods exist to allow accurate parametric estimation by minimizing an error cost function, they require large memory consumption, high computational effort, and a long convergence time. The initial estimate's accuracy is also vital in attaining convergence. In this paper, a new real time solution to the model identification problem is provided with the use of a Joint Unscented Kalman Filter for dual estimation. The identification procedures can be easily implemented using a microcontroller, a gyroscope sensor, and a simple bifilar pendulum setup. Accuracy, robustness, and convergence speed are achieved.",https://ieeexplore.ieee.org/document/7244614/,2015 10th Asian Control Conference (ASCC),31 May-3 June 2015,ieeexplore
10.1109/AERO.2018.8396807,Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles,IEEE,Conferences,"Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400-500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.",https://ieeexplore.ieee.org/document/8396807/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/CCAI50917.2021.9447518,Lightweight Real-time Object Detection Model for UAV Platform,IEEE,Conferences,"Real-time detecting objects on captured images on UAV (Unmanned Aerial Vehicle) platforms, rather than barely transmitting images back to supporting equipment for post-processing, is a core requirement for advanced UAV applications. However, due to limited computing capacity and memory of UAV platforms, it is very challenging to deploy real-time detection models on them. In addition, there are more small objects in aerial images, which makes it more difficult to detect accurately. To solve these problems, this paper brings dense connection to Yolo(You Only Look Once)v3 network, and proposes Yolo-LiteDense model. The backbone of Yolo-LiteDense is densely connected, which improves the performance of feature extraction. Then, we enforce channel pruning to Yolo-LiteDense model by pruning less informative channels with less scaling factors. After pruning, parameters and weight size of the model are compressed significantly, and inference time is also shortened. Evaluation results on VisDrone2018-DET show that parameters and weight size of Yolo-LiteDense are 83% and inference time is 30% less than Yolov3-SPP with comparable average precision. In addition, this paper also proposes the lighter version of Yolo-LiteDense, Yolo-DenseNano. Parameters and weight size of Yolo-LiteDense are 70% less than Yolov3-tiny with 2.68 times greater average precision.",https://ieeexplore.ieee.org/document/9447518/,2021 International Conference on Computer Communication and Artificial Intelligence (CCAI),7-9 May 2021,ieeexplore
10.1109/ICC.2019.8761117,Machine Learning for Position Prediction and Determination in Aerial Base Station System,IEEE,Conferences,"A novel framework for dynamic 3-D deployment of unmanned aerial vehicle (UAV) in the aerial base station system (ABSS) that based on the machine learning algorithms is proposed. In the framework, the UAV is deployed as an aerial base station to serve a group of ground users and is placed based on the prediction of the users' mobility. The joint problem of prediction of users' track and 3-D deployment of the UAV is formulated for maximizing the sum transmit rate. A two-step approach is proposed for predicting the movement of users and for determining the dynamic 3-D placement of the UAV. Firstly, an echo state network (ESN) based prediction algorithm is utilized for predicting the future positions of users based on the real-world datasets collected from Twitter. Secondly, an iterative K-Means based algorithm is proposed for obtaining the optimal placement of UAV at each time slot based on the output of ESN model. Numerical results are illustrated for showing the superiority of the proposed algorithm over the prevalent algorithm on prediction tasks. The accuracy and efficiency of the proposed framework are also investigated. Additionally, compared with static placement of the UAV, the advantage of dynamic 3-D deployment is demonstrated.",https://ieeexplore.ieee.org/document/8761117/,ICC 2019 - 2019 IEEE International Conference on Communications (ICC),20-24 May 2019,ieeexplore
10.1109/QIR.2017.8168502,Modified elman recurrent neural network for attitude and altitude control of heavy-lift hexacopter,IEEE,Conferences,"Hexacopter is a member of rotor-wing Unmanned Aerial Vehicle (UAV) which has 6 six rotors with fixed pitch blades and nonlinear characteristics that cause controlling the attitude of hexacopter is difficult. In this paper, Modified Elman Recurrent Neural Network (MERNN) is used to control attitude and altitude of Heavy-lift Hexacopter to get better performance than Elman Recurrent Neural Network (ERNN). This Modified Elman Recurrent Neural Network has a self-feedback which provides a dynamic trace of the gradients in the parameter space. In the self-feedback, the gain coefficients are trained as connection weight. This connection weight could enhance the adaptability of Elman Recurrent Neural Network to the time-varying system. The flight data are taken from a real flight experiment. Results show that the Modified Elman Recurrent Neural Network can increase performance with small error and generate a better response than Elman Recurrent Neural Network.",https://ieeexplore.ieee.org/document/8168502/,2017 15th International Conference on Quality in Research (QiR) : International Symposium on Electrical and Computer Engineering,24-27 July 2017,ieeexplore
10.1109/MECO.2016.7525773,Neural network implementation of a principal component analysis tasks on board the unmanned aerial vehicle information processing in real time,IEEE,Conferences,"The application of principal component analysis to simplify the classification of pixels of images obtained with the help of unmanned aerial vehicle for the organization received information processing in real time, and simplify the process of orientation of unmanned aerial vehicle on the ground. We consider the neural network of the principal component analysis. The results of experiments showing the effectiveness of such use of principal component analysis.",https://ieeexplore.ieee.org/document/7525773/,2016 5th Mediterranean Conference on Embedded Computing (MECO),12-16 June 2016,ieeexplore
10.1109/SoSE50414.2020.9130475,Real time object detection for aerial search and rescue missions for missing persons,IEEE,Conferences,"This paper introduces a solution to stand-alone system based, real-time object-detection, can efficiently facilitate the search for missing persons with an unmanned aerial vehicle. The challenge is the real-time implementation of the systems and training the given deep neural network for the desired task. The paper describes the methods and procedures currently in use, as well as the possible tools. Subsequently, the autonomous aircraft system, which carries a real-time detection system, is introduced. In the section about real-time detection, we will introduce the TensorFlow lite-based application, building on SSD topology, in detail, which was implemented on mobile phones. We will also introduce the dataset used for training, testing and the results achieved. In summary, the recall achieved is 65.4% and precision is 96.4%, besides the fact that the android-based application, using the phone's camera, performs image analysis at a rate of 11 to 17 FPS in real-time, while continuously providing.",https://ieeexplore.ieee.org/document/9130475/,2020 IEEE 15th International Conference of System of Systems Engineering (SoSE),2-4 June 2020,ieeexplore
10.1109/CCNC46108.2020.9045498,Real-time Crop Classification Using Edge Computing and Deep Learning,IEEE,Conferences,"In recent years, edge computing and deep learning have been successfully performed processing and classification tasks in a variety of fields including agriculture. Therefore, this research aims to use unmanned aerial vehicle (UAV) for agriculture applications with integrating edge computing and deep learning techniques. This research experiment was carried out in the NCHU Experimental Farm. The DJI Matrice 100 drone with ASUS Tinker Board S embedded system, which connects a Logitech C925e webcam to capture images are used in this study. The ASUS Tinker Board S runs a folder monitoring program and sends images over the 4G LTE network to the backend server whenever new images are captured and stored. The backend server runs a pre-trained image semantic segmentation model and provides image inference service. The image inference results with the associated segmented image will be sent to the mobile device of the drone controller, and a dynamic flight control action can be triggered. The image semantic segmentation model adopts SegNet network architecture. For a comparison purpose, another network architecture, FCN-AlexNet, was also trained and validated. The preliminary results show SegNet outperformed FCN-AlexNet in image semantic segmentation tasks in terms of the evaluation between training and validation. The average inference speed of the semantic image segmentation model is 0.7s with segmentation identification accuracy is 89%. The promising results shed light on many agriculture applications, such as crop growth condition assessment, fertilizer management, and yield prediction. Additionally, this research provides possible solutions for the labor shortage issue of agriculture which is a common challenge in an aging community like Taiwan and many countries worldwide.",https://ieeexplore.ieee.org/document/9045498/,2020 IEEE 17th Annual Consumer Communications & Networking Conference (CCNC),10-13 Jan. 2020,ieeexplore
10.1109/ICIT.2009.4939663,Real-time Neural Network based Identification of a Rotary-Wing UAV dynamics for autonomous flight,IEEE,Conferences,"Real time flight implementation of a neural network based black-box identification (NNID) scheme to a rotary wing unmanned aerial vehicle (RUAV) is presented in this paper. The applicability of NNID scheme for real time identification of longitudinal and lateral dynamics of the RUAV is evaluated in flight. To show the efficacy of the method for real time applications, the identification results and error statistics are provided. The challenges involved in terms of hardware implementation, computational time requirements, and real time coding are investigated and reported. Results indicate that NNID is suitable for modeling the dynamics of the RUAV in real time.",https://ieeexplore.ieee.org/document/4939663/,2009 IEEE International Conference on Industrial Technology,10-13 Feb. 2009,ieeexplore
10.1109/ICTC46691.2019.8939564,Real-time UAV Detection based on Deep Learning Network,IEEE,Conferences,"This paper presents deep learning-based YOLO (You only look once), for the detection of an unmanned aerial vehicle (UAV). In common practice, the creation of own data set is an extensive and hectic task, that takes a long time because it requires proper resolution images from different angles. These issues make the data set creation an important task. Implementation of YOLOv2 and YOLOv3 is done on the own created data set for the real-time UAV's detection and to benchmark the performance of both models in terms of mean average precision (MAP) and accuracy. For the specifically created data set made, YOLOv3 is outperforming YOLOv2 both in MAP and accuracy.",https://ieeexplore.ieee.org/document/8939564/,2019 International Conference on Information and Communication Technology Convergence (ICTC),16-18 Oct. 2019,ieeexplore
10.1109/ICSMC.2007.4413945,Real-time multi-network based identification with dynamic selection implemented for a low cost UAV,IEEE,Conferences,This paper describes a system identification technique based on dynamic selection of multiple neural networks for the Unmanned Aerial Vehicle (UAV). The UAV is a multi- input multi-output (MIMO) nonlinear system. The neural network models are based on the autoregressive technique. The multi-network dynamic selection method allows a combination of online and offline neural network models to be used in the architecture where the most suitable output is selected based on the given criteria. The online network uses a novel training scheme with memory retention. Flight test validation results for online and offline models are presented. Real-time hardware in the loop (HIL) simulation results show that the multi-net dynamic selection technique performs better than the individual models.,https://ieeexplore.ieee.org/document/4413945/,"2007 IEEE International Conference on Systems, Man and Cybernetics",7-10 Oct. 2007,ieeexplore
10.1109/GNCC42960.2018.9019103,Research on Drogue Detection Algorithm for Aerial Refueling (IEEE/CSAA GNCC),IEEE,Conferences,"Unmanned aerial vehicle(UAV) has become more and more widely used in military and non-military applications, but endurance has become a major limiting factor in the development of UAV. In order to increase the UAV's endurance, this paper uses a vision guidance method to achieve automatic aerial refueling technology. This paper proposes an automatic refueling technology based on a deep-learning algorithm for detection. The Faster RCNN algorithm can simultaneously recognize the fuel receiver and the Drogue at long-distance and returns the center coordinate value of the receiver. If the pixel area of the identified Drogue is greater than a certain threshold, the central coordinate value of the Drogue is returned. The experiment results show that the average accuracy of the algorithm reaches 67.75%, and the real-time performance is about 5HZ.",https://ieeexplore.ieee.org/document/9019103/,"2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)",10-12 Aug. 2018,ieeexplore
10.1109/ICMA.2019.8816557,Research on V-SLAM Methods,IEEE,Conferences,"With the development of intelligent mobile robots, SLAM, especially V-SLAM, as the basic technology of robot localization and navigation, has the advantages of strong adaptability, high precision and strong intelligence compared with the traditional localization technology. It is widely used in smart devices such as unmanned aerial vehicle, automatic driving and sweeping robots. According to different implementation methods, the visual SLAM is divided into: filter V-SLAM based on probability model, key frame BA-based V-SLAM using nonlinear optimization theory, direct tracking of V-SLAM under the assumption of luminosity invariance, space occupying V-SLAM that focuses on building three-dimensional dense maps. This paper focuses on representative systems of various V-SLAMs and gives their respective applicable scenarios and characteristics. Finally, this article forecasts the development of V-SLAM combining with multi-information fusion technology, semantic deep and learning technology.",https://ieeexplore.ieee.org/document/8816557/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICRA48506.2021.9560756,Siamese Anchor Proposal Network for High-Speed Aerial Tracking,IEEE,Conferences,"In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of ∼200 frames/s.",https://ieeexplore.ieee.org/document/9560756/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICIVC.2018.8492751,Siamese Network for Object Tracking in Aerial Video,IEEE,Conferences,"In Unmanned Aerial Vehicle (UAV) videos, object tracking remains a challenge, due to its low spatial resolution and poor real-time performance. Recently, methods of deep learning have made great progress in object tracking in computer vision, especially fully-convolutional siamese neural networks (SiamFC). Inspired by it, this paper aims to investigate the use of SiamFC for object tracking in UAV videos. The network is trained on part of a UAV123 dataset and Stanford Drone dataset. First, exemplar image is extracted from the first frame and search regions are extracted in the following frames. Then, a Siamese network is used for tracking objects by calculating the similarity between exemplar image and search region. To evaluate our method, we test on a challenge VIVID dataset. The experiment shows that the proposed method has improvements in accuracy and speed in low spatial resolution UAV videos compared to existing methods.",https://ieeexplore.ieee.org/document/8492751/,"2018 IEEE 3rd International Conference on Image, Vision and Computing (ICIVC)",27-29 June 2018,ieeexplore
10.1109/OCEANSKOBE.2018.8559324,Supervised vs Unsupervised Approaches for Real Time Hyperspectral Imaging Maritime Target Detection,IEEE,Conferences,This paper addresses the use of supervised and unsupervised methods for classification of hyperspectral imaging data in maritime border surveillance domain. In this work supervised (SVM) and unsupervised (HYDADE) approaches were implemented. An evaluation benchmark was performed in order to compare methods results using real hyperspectral imaging data taken from an Unmanned Aerial Vehicle in maritime border surveillance scenario.,https://ieeexplore.ieee.org/document/8559324/,2018 OCEANS - MTS/IEEE Kobe Techno-Oceans (OTO),28-31 May 2018,ieeexplore
10.1109/GHTC.2018.8601597,The EDNA Public Safety Drone: Bullet-Stopping Lifesaving,IEEE,Conferences,"Urban gun violence in cities across the world is a serious issue for public safety agencies and disaster management organizations. This led us to the development of the EDNA drone, an aerial robotics solution designed to equip first responders in high-risk settings with lifesaving-edge tools for situational awareness and non-lethal conflict resolution. The EDNA is an unmanned aerial vehicle (UAV) that delivers the patent-pending “Predictive Probable Cause” technology. The EDNA drone is designed to provide automated real-time analysis to assist teams entering high-risk situations where gun violence may occur. By leveraging machine learning, biometric sensors, and advanced materials in the field and routing feedback to an intuitive augmented-reality interface, the EDNA will provide autonomous threat detection and bullet-stopping capabilities wherever those features are needed--to groups such as Police and Sheriff's Departments, Fire Departments, and EMT and emergency rescue teams. Data from the EDNA drone's sensors is fed to machine learning algorithms running on the drone in real-time. Through a neural network trained on past data, the EDNA is able to detect the presence and location of firearms and explosives, even through walls or other obstacles. Through the use of advanced metal foams and composite materials, the armored drone can even stop bullets-functionality which has obvious benefits for humanitarian deployment.",https://ieeexplore.ieee.org/document/8601597/,2018 IEEE Global Humanitarian Technology Conference (GHTC),18-21 Oct. 2018,ieeexplore
10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00060,The Implementation of a Power Efficient BCNN-Based Object Detection Acceleration on a Xilinx FPGA-SoC,IEEE,Conferences,"This paper focuses on the power efficient design on the FPGA SoC for the object detection system based on Binary Convolutional Neural Network (BCNN). Especially, for the small IoT devices, such as an intelligent dash-cam, computer vision system installed on an unmanned aerial vehicle, the power consumption could be a significant factor of the performance and scalability. However, the optimized FPGA design has limitations to reduce the overall power consumption amount. We focus on the design of the FPGA Accelerator as well as the effective design of the peripherals including CPU. In our proposed FPGA-SoC design, it supports not only FPGA but also CPU and the peripheral component can be supported by additional virtual memory system for reducing the processing time. Overall customization including customized BCNN, virtual memories for CPU and FPGA part allows our testbed to achieve low power consumption without speed degradation. Our testbed is based on customized YOLOv2 which consists of applied binary and half precision convolution, and pipeline-based architecture with accelerated hardware design on the target device. The target device used in this paper is the Xilinx ZYNQ-SoC based PYNQ Z-1 board. Our proposed system achieves 15.15 frames per second (FPS) and 1.45 watts of power dissipation. Our result shows that our design technique is effective for real-time object detection and low power system.",https://ieeexplore.ieee.org/document/8875471/,"2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",14-17 July 2019,ieeexplore
10.1109/ECICE50847.2020.9301968,UAV Landmark Detection Based on Convolutional Neural Network,IEEE,Conferences,"The extensive use application of visual perception technology in Unmanned Aerial Vehicle (UAV) has brought great changes to the application of UAV in various fields. It is challenge to detect in landmark images for UAV. During UAV flight in different environments, the performance of landmark detection to deteriorate seriously have been caused by the uncertainty of landmark orientation, the diversity of landmark types and the similarities. This paper presents landmark detection of UAV based on Convolutional Neural Network (CNN). Theoretical analysis and experimental results demonstrate landmark recognition with an accuracy of at least 96% to match deployed in UAV, and the proposed CNN can make a correct classification.",https://ieeexplore.ieee.org/document/9301968/,"2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)",23-25 Oct. 2020,ieeexplore
10.1109/RCAR47638.2019.9043987,UAV Path Planning Based on Biological Excitation Neural Network and Visual Odometer,IEEE,Conferences,"Unmanned aerial vehicle(UAV) have been widely used in military and civil fields due to their compact structure, flexible mobility, low cost and other advantages. With the development of artificial intelligence in recent years, more intelligent and advanced algorithms have appeared, in which machine vision, as an important branch in the field of artificial intelligence, has also been greatly developed. The limitation of space, load, endurance and computing capacity hinders the application of intelligent algorithms on UAV. In the paper a semi-autonomous control platform of the quadrotor UAV was developed and the upper and lower dual control core architecture is implemented. Based on the hardware platform, the improved visual inertia odometer (VIO) and the biological excitation neural network are used to improve the flight performance and the ability of autonomy. To solve the problem of the synchronization for VIO, a cubic spline interpolation function was employed. A biological excitation neural network was extended to solve UAV on-line path planning. It provides an on-board path planning approach for UAV in the 3D world considering the dynamic obstacles. Finally, the feasibility and stability of the designed system were verified by flight experiments.",https://ieeexplore.ieee.org/document/9043987/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.23919/CISTI.2017.7975750,UAV simulator for grown-up people quality of life enhancement,IEEE,Conferences,This paper presents the development of a virtual reality simulator for the management of a UAV (Unmanned Aerial Vehicle) focused on improving the quality of life of grown-up people. The present research has collected characteristics of gestures and physical movements from users made by other related research in order to study the same interaction within a virtual world. Through this research a smaller number of gestures were created improving the user learning curve without affecting the usability. The following implementation uses a client-server architecture composed of 2 Raspberry Pi devices and a Smartphone acting as a server the communication between them was achieved by employing Bluetooth Low Energy technology. The immersive virtual experience is accomplished by using Unity 3D and Google VR tools that allowed the design and display of a playful virtual environment as an approach to promote physical and cognitive skills such as spatial thinking and hand-eye coordination. By performing maneuvers through an aerial circuit filled with obstacles the proposed UAV simulator encourages motor and mental activity while the user is being entertained. The result is the improvement of the user quality of life by avoiding cognitive and physical sedentarism.,https://ieeexplore.ieee.org/document/7975750/,2017 12th Iberian Conference on Information Systems and Technologies (CISTI),21-24 June 2017,ieeexplore
10.1109/ICAIIC48513.2020.9065203,UAV-assisted Real-time Data Processing using Deep Q-Network for Industrial Internet of Things,IEEE,Conferences,"Industrial internet of things (IIoT) enables edge computing technology to provide communication between the machines that produce a large amount of data and locate at the edge network. A task scheduling is implemented in the edge node. Furthermore, the real-time data can achieve with the lowest latency that allowed by the edge node near the edge network. However, a mobile machine such as an autonomous guided vehicle can interfere in this situation. Because the vehicle also needs service by the edge node. Over that, quality of service (QoS) performance can decrease. Therefore, this paper deploys an unmanned aerial vehicle (UAV) as an edge node to provide service to the edge network through optimizing the trajectory of UAV, where the edge network request task using a Deep Q-Network (DQN) Learning. The result shows that using machine learning, notably the DQN algorithm, can increase the number of the machine that can be provided service. Subsequently, the real-time data can achieve either the interrupt occurs at the edge node.",https://ieeexplore.ieee.org/document/9065203/,2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),19-21 Feb. 2020,ieeexplore
10.1109/ROBIO.2018.8665195,Unsupervised Feature Fusion Combined with Neural Network Applied to UAV Attitude Estimation,IEEE,Conferences,"In the field of an unmanned aerial vehicle (UAV), the navigation algorithm with high precision and easy implementation is a hot topic of research, and the key of UAV control is to obtain accurate and real-time attitude information. In this paper, a feature fusion algorithm based on unsupervised deep autoencoder (DAE) is proposed. It is used for data fusion of multiple sensors. The experimental results show that the unsupervised feature fusion algorithm can effectively improve the accuracy and has the potential to be applied to the data fusion of UAV sensors.",https://ieeexplore.ieee.org/document/8665195/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/TIE.2019.2905808,"Design, Implementation, and Evaluation of a Neural-Network-Based Quadcopter UAV System",IEEE,Journals,"In this paper, a quadcopter unmanned aerial vehicle (UAV) system based on neural-network enhanced dynamic inversion control is proposed for multiple real-world application scenarios. A sigma-pi neural network (SPNN) is used as the compensator to reduce the model error and improve the system performance in the presence of the uncertainties of UAV dynamics, payload, and environment. Besides, we present a technical framework for fast and robust implementation of multipurpose UAV systems and develop a testbed for the evaluation of UAV control system by using a high-precision optical motion capture system. Both simulation results and experiment results demonstrate that the SPNN can reduce the inversion errors related to UAV parameter uncertainties as well as tracking errors related to unknown disturbances and unmodeled dynamics. With the help of an online neural network (NN) learning mechanism, the entire system can achieve much higher accuracy in attitude and trajectory control than that achieved by conventional proportional-integral derivative based control systems under varying flight conditions.",https://ieeexplore.ieee.org/document/8676108/,IEEE Transactions on Industrial Electronics,March 2020,ieeexplore
10.1109/TCAD.2019.2957724,Energy-Efficient Real-Time UAV Object Detection on Embedded Platforms,IEEE,Journals,"The recent technology advancement on unmanned aerial vehicle (UAV) has enabled diverse applications in vision-related outdoor tasks. Visual object detection is a crucial task among them. However, it is difficult to actually deploy detectors on embedded devices due to the challenges among energy consumption, accuracy, and speed. In this article, we address a few key challenges from the platform, application to the system, and propose an energy-efficient system for real-time UAV object detection on an embedded platform. The proposed system can achieve speed of 28.5 FPS and 2.7-FPS/W energy efficiency on the data set from 2018 low-power object detection challenges (LPODCs).",https://ieeexplore.ieee.org/document/8924612/,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,Oct. 2020,ieeexplore
10.1109/TMECH.2021.3079935,Geometrical-Based Displacement Measurement With Pseudostereo Monocular Camera on Bidirectional Cascaded Linear Actuator,IEEE,Journals,"This article details the development of a geometrical-based displacement extraction framework capable of automatically extracting critical infrastructure measurements in one sequence. The framework is a novel rail viaduct bearing inspection pipeline implemented on Bearing Inspector for Narrow-space Observation Version 2 (BINOv2). BINOv2 is a tethered custom unmanned aerial vehicle system utilized to supplant labor-intensive pipelines and enhance inspection accuracy of infrastructure conditions in confined remote locations. The algorithm accepts stereoscopic images taken from a single monocular camera on a bidirectional cascaded linear actuator system in a rack-and-pinion configuration. A point cloud model generated from the image sets then runs through a hierarchical neural network for 3-D segmentation to extract targeted regions of interest. Our training pipeline generates and forms the full model's training dataset using only a small sample of real point clouds. The point cloud generated is inadequate to form the full bearing geometry profile. Therefore, the proposed framework projects best-fit circles based on the point cloud curvature to form the full bearing geometry profile so that the required displacement measurement is available for extraction. Several experiments were conducted on a mock-up and actual operational site to validate the proposed framework's accuracy, its robustness and comparison with other state-of-the-art alternatives.",https://ieeexplore.ieee.org/document/9430727/,IEEE/ASME Transactions on Mechatronics,Aug. 2021,ieeexplore
10.1109/ACCESS.2020.3027825,Multi-Modal Data Fusion Using Deep Neural Network for Condition Monitoring of High Voltage Insulator,IEEE,Journals,"A novel Fusion Convolutional Network (FCN) is proposed in this research for potential real-time monitoring of insulators using unmanned aerial vehicle (UAV) edge devices. Precise airborne imaging of outdoor objects, such as high voltage insulators, suffers from varied object resolution, cluttered backgrounds, unclear or contaminated surfaces, and illumination conditions. Accurate information about the insulator surface condition is essential and is of a high priority since insulator breakdown is a leading cause of electrical failure. A multi-modal information fusion (MMIF) system is developed during this research to analyze and classify possible contaminations present on the electrical insulators. A novel system, referred to as FCN, consists of a Convolutional Neural Network (CNN) and a binary Multilayer Neural Network (MNN) sub-classifier. While constructing the MMIF dataset for training and testing the novel FCN, the image classification output of the CNN is combined with the leakage current values (LCV) obtained as the classification output of MNN. Each sample of the MMIF dataset is, therefore, represented as a series of fusions. Later, sub-classifiers, of the FCN, are trained to identify the contamination types in the fusion series by implementing a voting system of sub-classifiers which is trained to identify a given class. As a result of the implementation of the proposed FCN, the classification accuracy increased by 8.4%, i.e., from 92% to 99.76%. To compare and benchmark the performance of proposed FCN, conventional classification algorithms are also implemented on the fusion of features that are extracted employing the wavelet transform and PCA methods. State-of-the-art CNN architectures are also discussed on account of their time consumption and memory usage. The conceptualization of a potential hardware implementation of the proposed FCN, on emerging edge devices, is also provided for completeness of the discussion. Pertinent outcomes of this research can be further extended to other potential applications of airborne imaging.",https://ieeexplore.ieee.org/document/9210065/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2020.3046499,Real-Time Energy Harvesting Aided Scheduling in UAV-Assisted D2D Networks Relying on Deep Reinforcement Learning,IEEE,Journals,"Unmanned aerial vehicle (UAV)-assisted device-to-device (D2D) communications can be deployed flexibly thanks to UAVs' agility. By exploiting the direct D2D interaction supported by UAVs, both the user experience and network performance can be substantially enhanced at public events. However, the continuous moving of D2D users, limited energy and flying time of UAVs are impediments to their applications in real-time. To tackle this issue, we propose a novel model based on deep reinforcement learning in order to find the optimal solution for the energy-harvesting time scheduling in UAV-assisted D2D communications. To make the system model more realistic, we assume that the UAV flies around a central point, the D2D users move continuously with random walk model and the channel state information encountered during each time slot is randomly time-variant. Our numerical results demonstrate that the proposed schemes outperform the existing solutions. The associated energy efficiency game can be solved in less than one millisecond by an off-the-shelf processor using trained neural networks. Hence our deep reinforcement learning techniques are capable of solving real-time resource allocation problems in UAV-assisted wireless networks.",https://ieeexplore.ieee.org/document/9303363/,IEEE Access,2021,ieeexplore
10.1109/TIM.2020.3001659,Real-Time Fault Detection for UAV Based on Model Acceleration Engine,IEEE,Journals,"With the wide applications of the unmanned aerial vehicle (UAV) in the civilian and military fields, its operational safety has drawn much attention. A series of fault detection methods are studied to avoid disasters. Due to the capabilities of strong feature extraction and massive flight data processing, the deep learning-based methods have received extensive attention. However, restricted by UAV airborne size, weight, and power consumption, a significant challenge is posed to deploy these complicated detection methods in the airborne application, which requires to run in real time. In this article, a fault detection model acceleration engine (FDMAE) for UAV real-time fault detection is realized under the airborne constraint. First, a high-performance detection model is designed based on stacked long short-term memory networks, and fault detection is achieved by a statistical threshold in this method. Second, a model pruning method based on principal component analysis is proposed to improve computing efficiency. Finally, the pruned fault detection method is optimized and integrated as a flexible acceleration engine through high-level synthesis and deployed on an airborne embedded computing platform based on a field-programmable gate array. Real UAV flight data are used to verify the proposed FDMAE. By comparing accuracy, the area under the receiver operating characteristic curve, speed, and power consumption, the effectiveness of the FDMAE is proven.",https://ieeexplore.ieee.org/document/9115090/,IEEE Transactions on Instrumentation and Measurement,Dec. 2020,ieeexplore
10.1109/ACCESS.2019.2950053,Research on Recognition Method of Electrical Components Based on YOLO V3,IEEE,Journals,"The reliability of electrical components affects the stable operation of the power system. Electrical components inspection has long been important issues in the intelligent power system. The main problems of traditional recognition methods of electrical components are low detection accuracy and poor real-time performance, which are challenging to extract necessary features from the inspection images. This paper proposes a way to detect the electrical components in the Unmanned Aerial Vehicle (UAV) inspection image based on You Only Look Once (YOLO) V3 algorithm. Due to some of the inspection images are not clear, which result in the reduction of the available dataset. On this basis, we adopt Super-Resolution Convolutional Neural Network (SRCNN) to realize super-resolution reconstruction on the blurred image, which achieves the expansion of the dataset. We compare the performance of the proposed method with other popular recognition methods. The results of experiment verify the effectiveness of the proposed method, and the technique reaches high recognition accuracy, good robustness, and strong real-time performance for UAV power inspection system.",https://ieeexplore.ieee.org/document/8886369/,IEEE Access,2019,ieeexplore
10.1109/TMM.2019.2945167,Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs,IEEE,Journals,"Recent advances in unmanned aerial vehicle (UAV) technology have revolutionized a broad class of civil and military applications. However, the designs of wireless technologies that enable real-time streaming of high-definition video between UAVs and ground clients present a conundrum. Most existing adaptive bitrate (ABR) algorithms are not optimized for the air-to-ground links, which usually fluctuate dramatically due to the dynamic flight states of the UAV. In this paper, we present SA-ABR, a new sensor-augmented system that generates ABR video streaming algorithms with the assistance of various kinds of inherent sensor data that are used to pilot UAVs. By incorporating the inherent sensor data with network observations, SA-ABR trains a deep reinforcement learning (DRL) model to extract salient features from the flight state information and automatically learn an ABR algorithm to adapt to the varying UAV channel capacity through the training process. SA-ABR does not rely on any assumptions or models about UAV's flight states or the environment, but instead, it makes decisions by exploiting temporal properties of past throughput through the long short-term memory (LSTM) to adapt itself to a wide range of highly dynamic environments. We have implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the results show that our system outperforms the best known existing ABR algorithm by 21.4% in terms of the average quality of experience (QoE) reward.",https://ieeexplore.ieee.org/document/8855031/,IEEE Transactions on Multimedia,June 2020,ieeexplore
10.1109/ACCESS.2021.3050522,Spectrum-Sharing UAV-Assisted Mission-Critical Communication: Learning-Aided Real-Time Optimisation,IEEE,Journals,"We propose an unmanned aerial vehicle (UAV) communications scheme with spectrum-sharing mechanism to provide mission-critical services such as disaster recovery and public safety. Specifically, the UAVs can serve as flying base stations to provide extended network coverage for the affected area under spectrum-sharing cognitive radio networks (CRNs). To cope with the effects of network destruction in a disaster, we propose a real-time optimisation framework for resource allocation (e.g., power and number of UAVs) for CRNs assisted by UAV relays. The proposed optimisation scheme aims at optimising the network throughput of primary and secondary networks under the stringent constraint of maximum tolerable interference impinged on the primary users. We also propose a deep neural network (DNN) model to significantly reduce the execution time under real-time solution of mixed-integer UAV deployment problems. For both primary and secondary networks, our real-time optimisation algorithms impose low computational complexity, hence, have a low execution time in solving throughput optimisation problems, which demonstrates the benefit of our approached proposed for spectrum-sharing UAV-assisted mission-critical services.",https://ieeexplore.ieee.org/document/9319135/,IEEE Access,2021,ieeexplore
10.1109/SAMI.2019.8782768,Implementation of Target Tracking Methods on Images Taken from Unmanned Aerial Vehicles,IEEE,Conferences,"Traditional object detection algorithms generate proposals and implement feature extraction. Then, a classification algorithm is implemented to label object classes. This process is slow, and the accuracy may not be adequate for UAV's real-time application tasks due to their movement in the air. We specified and practically implemented an object detection and localization scheme on images taken from a UAV, and provided the UAV with an advanced vision. We used YOLOv2 model. The YOLOv2 is a suitable object detection approach based on deep learning, and it presents a network architecture with accurate results in high speed. The object detection and localization were successfully implemented for people, car, and motorcycle classes within the threshold confidence scores. We pre-trained the model on COCO dataset and tested the model with our test images. The confidence scores were higher in altitudes from 5 to 15 meters and the confidence scores varied between %45 - %79 mAP.",https://ieeexplore.ieee.org/document/8782768/,2019 IEEE 17th World Symposium on Applied Machine Intelligence and Informatics (SAMI),24-26 Jan. 2019,ieeexplore
10.1109/IRCE50905.2020.9199256,Industrial Implementation and Performance Evaluation of LSD-SLAM and Map Filtering Algorithms for Obstacles Avoidance in a Cooperative Fleet of Unmanned Aerial Vehicles,IEEE,Conferences,"In this paper we present an industrial implementation and performance evaluation of the problem of obstacles detection by drones using autonomous navigation systems. The software module that has been developed as well as the tests conducted are part of a large industrial R&amp;D Vitrociset project called SWARM: an AI-Enabled Command and Control (C&amp;C) system, able to execute and review ISR missions for mini/micro cooperative fleets of heterogeneous UAVs. The presented software module, that is currently under test, has been developed to recognize obstacles and drive correctly the drones, using images acquired by low cost RGB video cameras, whose features of lightness and reduced size allow them to be installed on mini/micro UAVs. Moreover, this setup does not require special calibration and preconfiguration processes like the ones necessary for example using stereo video camera systems. The real-time recognition of obstacles in the surrounding environment has been obtained and evaluated through the implementation, performance evaluation and tests of the LSD-SLAM and map filtering algorithms; the core of the study has been realized starting from the integration of these algorithms with a simulated drone in a synthetic environment. The areas of interest have been identified through the filtering of a computer generated map: the module was then integrated into the SWARM project platform, allowing the control of a single drone's movement and making it ready for use in a cooperative fleet environment.",https://ieeexplore.ieee.org/document/9199256/,2020 3rd International Conference on Intelligent Robotic and Control Engineering (IRCE),10-12 Aug. 2020,ieeexplore
10.1109/AERO.2018.8396807,Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles,IEEE,Conferences,"Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400-500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.",https://ieeexplore.ieee.org/document/8396807/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/JSAC.2017.2680898,Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned Aerial Vehicles for Optimized Quality-of-Experience,IEEE,Journals,"In this paper, the problem of proactive deployment of cache-enabled unmanned aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of wireless devices in a cloud radio access network is studied. In the considered model, the network can leverage human-centric information, such as users' visited locations, requested contents, gender, job, and device type to predict the content request distribution, and mobility pattern of each user. Then, given these behavior predictions, the proposed approach seeks to find the user-UAV associations, the optimal UAVs' locations, and the contents to cache at UAVs. This problem is formulated as an optimization problem whose goal is to maximize the users' QoE while minimizing the transmit power used by the UAVs. To solve this problem, a novel algorithm based on the machine learning framework of conceptor-based echo state networks (ESNs) is proposed. Using ESNs, the network can effectively predict each user's content request distribution and its mobility pattern when limited information on the states of users and the network is available. Based on the predictions of the users' content request distribution and their mobility patterns, we derive the optimal locations of UAVs as well as the content to cache at UAVs. Simulation results using real pedestrian mobility patterns from BUPT and actual content transmission data from Youku show that the proposed algorithm can yield 33.3% and 59.6% gains, respectively, in terms of the average transmit power and the percentage of the users with satisfied QoE compared with a benchmark algorithm without caching and a benchmark solution without UAVs.",https://ieeexplore.ieee.org/document/7875131/,IEEE Journal on Selected Areas in Communications,May 2017,ieeexplore
10.1109/ACCESS.2020.3031326,Control Strategies and Novel Techniques for Autonomous Rotorcraft Unmanned Aerial Vehicles: A Review,IEEE,Journals,"This paper presents a review of the various control strategies that have been conducted to address and resolve several challenges for a particular category of unmanned aerial vehicles (UAVs), the emphasis of which is on the rotorcraft or rotary-wing systems. Initially, a brief overview of the important relevant definitions, configurations, components, advantages/disadvantages, and applications of the UAVs is first introduced in general, encompassing a wide spectrum of the flying machines. Subsequently, the focus is more on the two most common and versatile rotorcraft UAVs, namely, the twin-rotor and quadrotor systems. Starting with a brief background on the dual-rotor helicopter and a quadcopter, the full detailed mathematical dynamic model of each system is derived based on the Euler-Lagrange and Newton-Euler methods, considering a number of assumptions and considerations. Then, a state-of-the-art review of the diverse control strategies for controlling the rotorcraft systems with conceivable solutions when the systems are subjected to the different impediments is demonstrated. To counter some of these limitations and adverse operating/loading conditions in the UAVs, several innovative control techniques are particularly highlighted, and their performance are duly analyzed, discussed, and compared. The applied control techniques are deemed to produce a useful contribution to their successful implementation in the wake of varied constraints and demanding environments that result in a degree of robustness and efficacy. Some of the off-the-shelf developments in the rotorcraft systems for research and commercial applications are also presented.",https://ieeexplore.ieee.org/document/9224621/,IEEE Access,2020,ieeexplore
10.1109/TII.2020.3004600,Distributed Artificial Neural Networks-Based Adaptive Strictly Negative Imaginary Formation Controllers for Unmanned Aerial Vehicles in Time-Varying Environments,IEEE,Journals,"Formation control techniques have been widely implemented in networked multirobot systems. In this article, we present a novel framework for swarm multiagent systems based on the relative-position output feedback consensus supported with the new concept of adaptive strictly negative imaginary consensus controllers, leveraging the learning capability of artificial neural networks. For experimental validation, we consider the case of two quadcopters moving together while carrying a dynamic load. We employ Kharitonov's theorem to study the stability of the proposed adaptive control systems. Finally, a rigorous real-time experimental study is conducted to highlight the merits of the proposed formation control algorithms.",https://ieeexplore.ieee.org/document/9124698/,IEEE Transactions on Industrial Informatics,June 2021,ieeexplore
10.1109/TSG.2020.2970156,Intelligent Damage Classification and Estimation in Power Distribution Poles Using Unmanned Aerial Vehicles and Convolutional Neural Networks,IEEE,Journals,"Damage estimation is part of daily operation of power utilities, often requiring a manual process of crew deployment and damage report to quantify and locate damages. Advancement in unmanned aerial vehicles (UAVs) as well as real-time communication and learning technologies could be harnessed towards efficient and accurate automation of this process. This paper develops a model to automate the process of estimating and localizing damages in power distribution poles, which utilizes the images taken by UAVs transferred in real-time to an intelligent damage classification and estimation (IDCE) unit. The IDCE unit integrates four convolutional neural networks to learn the states of poles from images, extract the image characteristics, and train an automated intelligent tool to replace manual fault location and damage estimation. The proposed model first determines the type of pole damages, including falling and burning, and then estimates the percentage of damage in each type. The IDCE unit also localizes damages in the poles by locating possible burning or arcing parts. A data set of 1615 images is utilized to train, validate and test the proposed model, which demonstrates high accuracy of the model in classifying and estimating damages in distribution poles.",https://ieeexplore.ieee.org/document/8972612/,IEEE Transactions on Smart Grid,July 2020,ieeexplore
10.1109/ICIAI.2019.8850815,A Deep Learning Based Forest Fire Detection Approach Using UAV and YOLOv3,IEEE,Conferences,"Unmanned aerial vehicles (UAVs) are increasingly being used in forest fire monitoring and detection thanks to their high mobility and ability to cover areas at different altitudes and locations with relatively lower cost. Traditional fire detection algorithms are mostly based on the RGB color model, but their speed and accuracy need further improvements. This paper proposes a forest fire detection algorithm by exploiting YOLOv3 to UAV-based aerial images. Firstly, a UAV platform for the purpose of forest fire detection is developed. Then according to the available computation power of the onboard hardware, a small-scale of convolution neural network (CNN) is implemented with the help of YOLOv3. The testing results show that the recognition rate of this algorithm is about 83%, and the frame rate of detection can reach more than 3.2 fps. This method has great advantages for real-time forest fire detection application using UAVs.",https://ieeexplore.ieee.org/document/8850815/,2019 1st International Conference on Industrial Artificial Intelligence (IAI),23-27 July 2019,ieeexplore
10.1109/NAECON.2018.8556769,A Rapid Situational Awareness Development Framework for Heterogeneous Manned-Unmanned Teams,IEEE,Conferences,"This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator.",https://ieeexplore.ieee.org/document/8556769/,NAECON 2018 - IEEE National Aerospace and Electronics Conference,23-26 July 2018,ieeexplore
10.1109/VTC2020-Fall49728.2020.9348512,Adaptive Deployment of UAV-Aided Networks Based on Hybrid Deep Reinforcement Learning,IEEE,Conferences,"Unmanned aerial vehicles (UAVs) can be used as air base stations to provide fast wireless connections for ground users. Due to their constraints on both mobility and energy consumption, a key problem is how to deploy UAVs adaptively in a geographic area with changing traffic demand of mobile users, while meeting the aforemetioned constraints. In this paper, we propose an adaptive deployment strategy for UAV-aided networks based on hybrid deep reinforcement learning, where a UAV can adjust its movement direction and distance to serve users who move randomly in the target area. Through hybrid deep reinforcement learning, UAVs can be trained offline to obtain the global state information and learn a completely distributed control strategy, with which each UAV only needs to take actions based on its observed state in the real deployment to be fully adaptive. Moreover, in order to improve the speed and effect of learning, we improve hybrid reinforcement learning, by adding genetic algorithms and TD-error-based resampling optimization mechanism. Simulation results show that the hybrid deep reinforcement learning algorithm has better efficiency and robustness in multi-UAV control, and has better performance in terms of coverage, energy consumption and average throughput, by which average throughput can be increased by 20% to 60%.",https://ieeexplore.ieee.org/document/9348512/,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),18 Nov.-16 Dec. 2020,ieeexplore
10.1109/ECMR50962.2021.9568788,Adaptive Path Planning for UAV-based Multi-Resolution Semantic Segmentation,IEEE,Conferences,"In this paper, we address the problem of adaptive path planning for accurate semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The usage of UAVs for terrain monitoring and remote sensing is rapidly gaining momentum due to their high mobility, low cost, and flexible deployment. However, a key challenge is planning missions to maximize the value of acquired data in large environments given flight time limitations. To address this, we propose an online planning algorithm which adapts the UAV paths to obtain high-resolution semantic segmentations necessary in areas on the terrain with fine details as they are detected in incoming images. This enables us to perform close inspections at low altitudes only where required, without wasting energy on exhaustive mapping at maximum resolution. A key feature of our approach is a new accuracy model for deep learning-based architectures that captures the relationship between UAV altitude and semantic segmentation accuracy. We evaluate our approach on the application of crop/weed segmentation in precision agriculture using real-world field data.",https://ieeexplore.ieee.org/document/9568788/,2021 European Conference on Mobile Robots (ECMR),31 Aug.-3 Sept. 2021,ieeexplore
10.1109/MESA.2016.7587103,Adaptive robust RBFNNs-based model estimator for a small quadrotor aircraft robot,IEEE,Conferences,"This paper presents an on-line estimator that incorporates adaptive MIMO radical basis function neural networks (RBFNNs) for model identification of quadrotor unmanned aerial vehicles (UAVs). The inputs and outputs of quadrotor aircrafts can be obtained from dynamic models or real attitude and position sensors. The adaptive learning rate is employed in the gradient descent method for the update of the weights of RBFNNs, and Lyapunov approach guarantees the stability of the global convergence of the modeling errors. The Welsch functions are also employed as the error functions to get rid of the influence from the noise due to disturbances like wind gusts. Simulation results using Robotics Toolbox for Matlab verify the effectiveness and robustness of the proposed estimator compared with results of traditional RBFNNs. Experiment results from real aircraft platform show that RBFNNs combining adaptive learning rate and Welsch error functions can approximate the overall system with high accuracy and robustness to disturbances.",https://ieeexplore.ieee.org/document/7587103/,2016 12th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA),29-31 Aug. 2016,ieeexplore
10.1109/ICC40277.2020.9148788,An Actor-Critic-Based UAV-BSs Deployment Method for Dynamic Environments,IEEE,Conferences,"In this paper, the real-time deployment of unmanned aerial vehicles (UAVs) as flying base stations (BSs) for optimizing the throughput of mobile users is investigated for UAV networks. This problem is formulated as a time-varying mixed-integer non-convex programming (MINP) problem, which is challenging to find an optimal solution in a short time with conventional optimization techniques. Hence, we propose an actor-critic-based (AC-based) deep reinforcement learning (DRL) method to find near-optimal UAV positions at every moment. In the proposed method, the process searching for the solution iteratively at a particular moment is modeled as a Markov decision process (MDP). To handle infinite state and action spaces and improve the robustness of the decision process, two powerful neural networks (NNs) are configured to evaluate the UAV position adjustments and make decisions, respectively. Compared with heuristic algorithm, sequential least-squares programming and fixed UAVs methods, simulation results have shown that the proposed method outperforms these three benchmarks in terms of the throughput at every moment in UAV networks.",https://ieeexplore.ieee.org/document/9148788/,ICC 2020 - 2020 IEEE International Conference on Communications (ICC),7-11 June 2020,ieeexplore
10.15439/2021F001,An Efficient Connected Swarm Deployment via Deep Learning,IEEE,Conferences,"In this paper, an unmanned aerial vehicles (UAVs) deployment framework based on machine learning is studied. It aims to maximize the sum of the weights of the ground users covered by UAVs while UAVs forming a connected communication graph. We focus on the case where the number of UAVs is not necessarily enough to cover all ground users.We develop an UAV Deployment Deep Neural network (UD-DNNet) as a UAV’s deployment deep network method. Simulation results demonstrate that UDDNNet can serve as a computationally inexpensive replacement for traditionally expensive optimization algorithms in real-time tasks and outperform the state-of-the-art traditional algorithms.",https://ieeexplore.ieee.org/document/9555749/,2021 16th Conference on Computer Science and Intelligence Systems (FedCSIS),2-5 Sept. 2021,ieeexplore
10.1109/IJCNN.2018.8489157,An Embedded Tracking System with Neural Network Accelerator,IEEE,Conferences,"With robots and unmanned aerial vehicles (UAVs) being more and more employed in real-life scenarios for monitoring and surveillance, there is a increasing demand for deploying various video processing applications in mobile systems. However, with limited on-board computational resources and power consumption, the application in this domain requires that the tracking platforms equipped should have outstanding computing power to handle the tasks in real-time with high-accuracy, while at the same time, fit the highly constrained environment of small size, light weight, and low power consumption (SWaP) for the purpose of long-term surveillance. In this paper, we proposed a new autonomous object tracking system based on an embedded platform, leveraging the emerging neural network hardware which is capable of massive parallel pattern recognition processing and demands only a low level power consumption. Further, a prototype of the tracking system that combines a low-power neural network chip, CogniMem, and an embedded development board, BeagleBone, is developed. Our experimental results show that the power consumption for the entire system is only about 2. 25W, which signifies a promising future of applying ultra-low-power neuromorphic hardware as a accelerator in recognition tasks.",https://ieeexplore.ieee.org/document/8489157/,2018 International Joint Conference on Neural Networks (IJCNN),8-13 July 2018,ieeexplore
10.1109/DCOSS.2019.00111,An Open Source and Open Hardware Deep Learning-Powered Visual Navigation Engine for Autonomous Nano-UAVs,IEEE,Conferences,"Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8804776/,2019 15th International Conference on Distributed Computing in Sensor Systems (DCOSS),29-31 May 2019,ieeexplore
10.1109/AERO47225.2020.9172808,Autonomous UAV Navigation for Active Perception of Targets in Uncertain and Cluttered Environments,IEEE,Conferences,"The use of Small Unmanned Aerial Vehicles (sUAVs) has grown exponentially owing to an increasing number of autonomous capabilities. Automated functions include the return to home at critical energy levels, collision avoidance, take-off and landing, and target tracking. However, sUAVs applications in real-world and time-critical scenarios, such as Search and Rescue (SAR) is still limited. In SAR applications, the overarching aim of autonomous sUAV navigation is the quick localisation, identification and quantification of victims to prioritise emergency response in affected zones. Traditionally, sUAV pilots are exposed to prolonged use of visual systems to interact with the environment, which causes fatigue and sensory overloads. Nevertheless, the search for victims onboard a sUAV is challenging because of noise in the data, low image resolution, illumination conditions, and partial (or full) occlusion between the victims and surrounding structures. This paper presents an autonomous Sequential Decision Process (SDP) for sUAV navigation that incorporates target detection uncertainty from vision-based cameras. The SDP is modelled as a Partially Observable Markov Decision Process (POMDP) and solved online using the Adaptive Belief Tree (ABT) algorithm. In particular, a detailed model of target detection uncertainty from deep learning-based models is shown. The presented formulation is tested under Software in the Loop (SITL) through Gazebo, Robot Operating System (ROS), and PX4 firmware. A Hardware in the Loop (HITL) implementation is also presented using an Intel Myriad Vision Processing Unit (VPU) device and ROS. Tests are conducted in a simulated SAR GPS-denied scenario, aimed to find a person at different levels of location and pose uncertainty.",https://ieeexplore.ieee.org/document/9172808/,2020 IEEE Aerospace Conference,7-14 March 2020,ieeexplore
10.1109/SSCI.2018.8628656,Brain Emotional Learning-Based Path Planning and Intelligent Control Co-Design for Unmanned Aerial Vehicle in Presence of System Uncertainties and Dynamic Environment,IEEE,Conferences,"This paper proposes a novel intelligent path planning and control co-design for Unmanned Aerial Vehicles (UAVs) in the presence of system uncertainties and dynamic environments. In order to simultaneously handle the uncertainties from both the UAV platform itself and from the environment, a novel biologically-inspired approach based on a computational model of emotional learning in mammalian limbic system is adopted. The methodology, known as Brain Emotional Learning (BEL), is implemented in this application for the first time. Making use of the multi-objective properties and the real-time learning capabilities of BEL, the path planning and control co-design are applied in a synthetic UAV path planning scenario, successfully dealing with the challenges caused by system uncertainties and dynamic environments. A Lyapunov analysis demonstrates the convergence of the co-design, and a set of numerical results illustrate the effectiveness of the proposed approach. Furthermore, it is shown that the low computational complexity of the method guarantees its implementation in real-time applications.",https://ieeexplore.ieee.org/document/8628656/,2018 IEEE Symposium Series on Computational Intelligence (SSCI),18-21 Nov. 2018,ieeexplore
10.1109/AECT47998.2020.9194188,Clustering Based UAV Base Station Positioning for Enhanced Network Capacity,IEEE,Conferences,"Unmanned aerial vehicles (UAVs) are expected to be deployed in a variety of applications in future mobile networks due to several advantages they bring over the deployment of ground base stations. However, despite the recent interest in UAVs in mobile networks, some issues still remain, such as determining the placement of multiple UAVs in different scenarios. In this paper we propose a solution to determine the optimal 3D position of multiple UAVs in a capacity enhancement use-case, or in other words, when the ground network cannot cope with the user traffic demand. For this scenario, real data from the city of Milan, provided by Telecom Italia is utilized to simulate an event. Based on that, a solution based on k-means, a machine learning technique, to position multiple UAVs is proposed and it is compared with two other baseline methods. Results demonstrate that the proposed solution is able to significantly outperform other methods in terms of users covered and quality of service.",https://ieeexplore.ieee.org/document/9194188/,2019 International Conference on Advances in the Emerging Computing Technologies (AECT),10-10 Feb. 2020,ieeexplore
10.1109/AICAI.2019.8701407,Comparitive Analysis and Implication of UAV and AI in Forensic Investigations,IEEE,Conferences,"Unmanned Aerial Vehicles (UAVs) are having applications in different areas including remote sensing, real-time monitoring, environmental monitoring, agriculture, land use surveys, traffic surveillance, metereology and goods deleivery etc. In this study a comparative analysis is being made on various investigation techniques in forensic science with and without the use of UAVs. The analysis and impact of telecommunication and related aspects of a UAV is being examined in the area of forensic science to investigate the complex crime scenes more sophisticatedly and to help the investigators and forensic professionals in the proper scrutiny and mapping of the scene of crime. The present study is focused on the estimation of the practicality of the use of UAV and AI in crime scene investigation (CSI), feasibility of UAV in forensic science and its logistical implementation.",https://ieeexplore.ieee.org/document/8701407/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore
,Deep Learning based Real Time Object Recognition for Security in Air Defense,IEEE,Conferences,"Internet of Things (IoT) is one of the prominent areas of implementation in assorted domains including corporate, government as well as military applications. Flying Wireless Network (FWN) is one of the IoT based implementation and deployment whereby the flying objects are formed in network environment and remote monitoring is done. Till now, the work in Flying Adhoc Networks (FANET) is used that can be replaced with Flying Deep Learning Integrated Drone (FDLID) that refers to the specific class of wireless network that is integrated with sensor devices, computer vision and the Global Positioning System (GPS) so that the logging and live monitoring of the surround can be done with higher degree of surveillance. From last few years, flying drones are widely used for monitoring of scenarios civil wars and local commotions. FWN makes used of assorted Unmanned Aerial Vehicles (UAV) so that the preprogrammed plans on the flights of such flying objects can be implemented. UAV refers to the pre-programmed flying object or aircraft without need of a dedicated on-board pilot. This research manuscript focuses on the integration of deep learning approach with real time feature descriptor from camera of flying FWN aircraft so that the definite target can be identified accurately. The proposed approach is presented to be effective in military as well as civil defense to recognize the activities of suspicious persons or even to locate the flying objects released by opponent country. In this approach, the integration of TensorFlow, Keras and PyTorch with feature descriptors in the camera of Flying Deep Learning Integrated Drone (FDLID)is proposed and found that the strategic and tactical decisions can be made using this methodology.",https://ieeexplore.ieee.org/document/8991418/,2019 6th International Conference on Computing for Sustainable Global Development (INDIACom),13-15 March 2019,ieeexplore
10.1109/VTC2020-Fall49728.2020.9348616,Deep Q-Network Based Dynamic Movement Strategy in a UAV-Assisted Network,IEEE,Conferences,"Unmanned aerial vehicle (UAV)-assisted communications is a promising solution to improve the performance of future wireless networks, where UAVs are deployed as base stations for enhancing the quality of service (QoS) provided to ground users when traditional terrestrial base stations are unavailable or not sufficient. An effective framework is proposed in this paper to manage the dynamic movement of multiple unmanned aerial vehicles (UAVs) in response to ground user mobility, with the objective to maximize the sum data rate of the ground users. First, we discuss the relationship between the air-to-ground (A2G) path loss (PL) and the location of UAVs. Then a deep Q-network (DQN) based method is proposed to adjust the locations of UAVs to maximize the sum data rate of the user equipment (UE). Finally, simulation results show that the proposed method is capable of adjusting UAV locations in a real-time condition to improve the QoS of the entire network.",https://ieeexplore.ieee.org/document/9348616/,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),18 Nov.-16 Dec. 2020,ieeexplore
10.1109/GLOCOMW.2018.8644345,Deployment and Movement for Multiple Aerial Base Stations by Reinforcement Learning,IEEE,Conferences,"A novel framework for Quality of experience (QoE)-driven deployment and movement of multiple unmanned aerial vehicles (UAVs) is proposed. The problem of joint non-concave 3D deployment and dynamic movement for maximizing the sum mean opinion score (MOS) of users is formulated, which is proved to be NP-hard. In an effort to solve this problem, we proposed a three-step approach to obtain 3D deployment and dynamic movement of multiple UAVs. More specifically, in the first step, GAK-means algorithm is invoked to obtain the cell partitioning of ground users. Secondly, Q-learning based deployment algorithm is proposed, in which each UAV is considered as an agent, making its own decision to obtain 3D position. In contrast to conventional genetic algorithm based learning algorithms, the proposed algorithm is capable of training the policy of making decision offline. Thirdly, Q-learning algorithm is invoked when the ground users roam. Unlike the other trajectory obtaining algorithms, the proposed approach enables each UAV learn its movement gradually through trials and errors, and updates the direction selection strategy until it reaches convergence. Numerical results reveal that the proposed 3D deployment scheme outperforms K-means algorithm and IGK algorithm with low complexity. Additionally, with the aid of proposed approach, 3D real-time dynamic movement of UAVs is obtained.",https://ieeexplore.ieee.org/document/8644345/,2018 IEEE Globecom Workshops (GC Wkshps),9-13 Dec. 2018,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/RAAI52226.2021.9508033,Development of Gasoline-Electric Hybrid Propulsion Surveillance and Reconnaissance VTOL UAV,IEEE,Conferences,"Vertical Take-Off and Landing (VTOL) Unmanned Aerial Vehicles (UAV) have been a high potential topic in the aerospace industry during the last decades due to its multirotor and fixed-wing nature of the aircraft. Besides, having the ability to rapidly deploy from a tight airstrip and gathering Intelligence, Surveillance, and Reconnaissance (ISR) information is the best way to be one step ahead of the enemy. In this paper, we present the implementation and development of gasoline-electric hybrid propulsion VTOL Unmanned Aerial vehicle respectively. The Hybrid propulsion VTOL UAV offers image and real-time video transmission to the ground station with fully autonomous control to get the best view of the enemy from the sky. The gasoline-electric hybrid propulsion system provides long flight endurance with efficient power consumption. The fundamentals of the multirotor and the conventional fixed-wing aircraft present the theoretical background of the aircraft. The accomplished design consists of high-performance multirotor motors with an efficient gasoline engine. Furthermore, the control system architecture, avionics, and power distribution system presented with addressing cost-effective trending design techniques. The performance of the system has been improved using commercially off-the-shelf (COTS) hardware.",https://ieeexplore.ieee.org/document/9508033/,"2021 IEEE International Conference on Robotics, Automation and Artificial Intelligence (RAAI)",21-23 April 2021,ieeexplore
10.23919/DATE.2018.8342149,DroNet: Efficient convolutional neural network detector for real-time UAV applications,IEEE,Conferences,"Unmanned Aerial Vehicles (drones) are emerging as a promising technology for both environmental and infrastructure monitoring, with broad use in a plethora of applications. Many such applications require the use of computer vision algorithms in order to analyse the information captured from an on-board camera. Such applications include detecting vehicles for emergency response and traffic monitoring. This paper therefore, explores the trade-offs involved in the development of a single-shot object detector based on deep convolutional neural networks (CNNs) that can enable UAVs to perform vehicle detection under a resource constrained environment such as in a UAV. The paper presents a holistic approach for designing such systems; the data collection and training stages, the CNN architecture, and the optimizations necessary to efficiently map such a CNN on a lightweight embedded processing platform suitable for deployment on UAVs. Through the analysis we propose a CNN architecture that is capable of detecting vehicles from aerial UAV images and can operate between 5-18 frames-per-second for a variety of platforms with an overall accuracy of ~ 95%. Overall, the proposed architecture is suitable for UAV applications, utilizing low-power embedded processors that can be deployed on commercial UAVs.",https://ieeexplore.ieee.org/document/8342149/,"2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)",19-23 March 2018,ieeexplore
10.1109/MELECON48756.2020.9140588,Drones for Sheep Livestock Monitoring,IEEE,Conferences,"Nowadays, Unmanned Aerial Vehicles (UAV) have been included in many more applications such as package delivery, traffic monitoring, etc; and one of its potential applications is agriculture. This work demonstrates the research and design of a new application for the drones, which is monitoring sheep livestock. We describe the set-up process for the drone and what are the equipment used for it, how the system for the monitoring is designed, what are the system limitations and how the constraints are satisfied within the system design of the system. Image processing and Machine Learning are heavily used along the setup, and therefore, the system is trained and tested in a real field that served the purpose of this paper. Different setups that match a wide spectrum of applications are deployed and their results thoroughly discussed.",https://ieeexplore.ieee.org/document/9140588/,2020 IEEE 20th Mediterranean Electrotechnical Conference ( MELECON),16-18 June 2020,ieeexplore
10.1109/ISAECT50560.2020.9523700,Edge-Cloud Architectures Using UAVs Dedicated To Industrial IoT Monitoring And Control Applications,IEEE,Conferences,"The deployment of new technologies to ease the control and management of a massive data volume and its uncertainty is a very significant challenge in the industry. Under the name ""Smart Factory"", the Industrial Internet of Things (IoT) aims to send data from systems that monitor and control the physical world to data processing systems for which cloud computing has proven to be an important tool to meet processing needs. unmanned aerial vehicles (UAVs) are now being introduced as part of IIoT and can perform important tasks. UAVs are now considered one of the best remote sensing techniques for collecting data over large areas. In the field of fog and edge computing, the IoT gateway connects various objects and sensors to the Internet. It function as a common interface for different networks and support different communication protocols. Edge intelligence is expected to replace Deep Learning (DL) computing in the cloud, providing a variety of distributed, low-latency and reliable intelligent services. In this paper, An unmanned aerial vehicle is automatically integrated into an industrial control system through an IoT gateway platform. Rather than sending photos from the UAV to the cloud for processing, an AI cloud trained model is deployed in the IoT gateway and used to process the taken photos. This model is designed to overcome the latency channels of the cloud computing architecture. The results show that the monitoring and tracking process using advanced computing in the IoT gateway is significantly faster than in the cloud.",https://ieeexplore.ieee.org/document/9523700/,2020 International Symposium on Advanced Electrical and Communication Technologies (ISAECT),25-27 Nov. 2020,ieeexplore
10.1109/AICAS48895.2020.9073885,Efficient Embedded Deep Neural-Network-based Object Detection Via Joint Quantization and Tiling,IEEE,Conferences,"Embedded visual AI is a growing trend in applications requiring low latency, real-time decision support, increased robustness and security. Visual object detection, a key task in visual data analytics, has enjoyed significant improvements in terms of capabilities and accuracy due to the emergence of Convolutional Neural Networks (CNNs). However, such complex paradigms require heavy computational resources that prevent their deployment on resource-constrained devices, and in particular, impose significant constraints in possible hardware accelerators geared towards such applications. In this work therefore, we investigate how a combination of techniques can lead to efficient visual AI pipelines for resource-constrained object detection. In particular we leverage an efficient search strategy based on a combination of pre-processing mechanisms, that reduce the processing demands of deep network as a counter measure for potential accuracy reduction caused by quantization. The proposed approach enables the detection of objects in higher resolution frames using quantized models, while maintaining the accuracy of full-precision CNN-based object detectors. We illustrate the impact on the accuracy and average processing time using quantization techniques and different tiling approaches on efficient object detection architectures; as a case study, we focus on Unmanned-Aerial- Vehicles (UAVs). Through the proposed methodology, hardware accelerator demands are thereby reduced, leading to both performance benefits and associated power savings.",https://ieeexplore.ieee.org/document/9073885/,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),31 Aug.-2 Sept. 2020,ieeexplore
10.1109/SAHCN.2019.8824932,Formation control of a mono-operated UAV fleet through ad-hoc communications: a Q-learning approach,IEEE,Conferences,"In this paper, an innovative approach based on a Q-learning algorithm to allow a single operator to control a fleet of Unmanned Aerial Vehicles (UAVs) is presented. To follow an independently-controlled UAV (the leader), all the other UAVs (the followers) use only the radio signal strength values received during wireless ad-hoc communications among themselves, without the need for any infrastructure, any localization technique or any additional device. By applying the proposed behavior-based control scheme in real-time, the fleet formation can be perfectly maintained. The solution has been implemented through the definition of a new protocol and has been tested using ns-3. Experiments highlight the efficiency and effectiveness of the proposed method.",https://ieeexplore.ieee.org/document/8824932/,"2019 16th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)",10-13 June 2019,ieeexplore
10.1109/GLOBECOM38437.2019.9014310,Gated Recurrent Units Learning for Optimal Deployment of Visible Light Communications Enabled UAVs,IEEE,Conferences,"In this paper, the problem of optimizing the deployment of unmanned aerial vehicles (UAVs) equipped with visible light communication (VLC) capabilities is studied. In the studied model, the UAVs can simultaneously provide communications and illumination to service ground users. Ambient illumination increases the interference over VLC links while reducing the illumination threshold of the UAVs. Therefore, it is necessary to consider the illumination distribution of the target area for UAV deployment optimization. This problem is formulated as an optimization problem whose goal is to minimize the total transmit power while meeting the illumination and communication requirements of users. To solve this problem, an algorithm based on the machine learning framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can model the longterm historical illumination distribution and predict the future illumination distribution. In order to reduce the complexity of the prediction algorithm while accurately predicting the illumination distribution, a Gaussian mixture model (GMM) is used to fit the illumination distribution of the target area at each time slot. Based on the predicted illumination distribution, the optimization problem is proved to be a convex optimization problem that can be solved by using duality. Simulations using real data from the Earth observations group (EOG) at NOAA/NCEI show that the proposed approach can achieve up to 22.1% reduction in transmit power compared to a conventional optimal UAV deployment that does not consider the illumination distribution. The results also show that UAVs must hover at areas having strong illumination, thus providing useful guidelines on the deployment of VLCenabled UAVs.",https://ieeexplore.ieee.org/document/9014310/,2019 IEEE Global Communications Conference (GLOBECOM),9-13 Dec. 2019,ieeexplore
10.1109/MILTECHS.2017.7988808,Genetic neuro-fuzzy approach for unmanned fixed wing attitude control,IEEE,Conferences,"With the imminent growth and the progressive interest in the subject, the unmanned aerial vehicles (UAVs) are already a reality in our daily life. The search for air vehicles, which is ambitious for a future in which the UAVs can act autonomously and safely, continuously drives this sector. The present work aims to apply artificial intelligence techniques to classical control systems, in order to control the attitude of a fixed wing aircraft adaptively. The open source software ArduPlane was used as the basis for this project, which has an enhanced implementation of a PID controller for attitude. It is noteworthy the need to frequent adjustment for gains tied to the attitude control system; either for basic adjustment constants, as well as for parameters whose calibration needs specific technical knowledge of the system. In order to automate this process and ensure the optimization of these parameters throughout the mission, a genetic neuro-fuzzy approach was proposed to make this procedure implicit and transparent to the flight operator. With the use of an Adaptive Neuro-Fuzzy Inference System (ANFIS) capable of predicting the attitude of the aircraft, together with an optimization system (genetic algorithm), it is possible to construct an efficient control architecture, which ensures an improved control that always searches for optimized parameters throughout the mission autonomously.",https://ieeexplore.ieee.org/document/7988808/,2017 International Conference on Military Technologies (ICMT),31 May-2 June 2017,ieeexplore
10.1109/HPCC-SmartCity-DSS50907.2020.00074,High-Performance Object Detection for Optical Remote Sensing Images with Lightweight Convolutional Neural Networks,IEEE,Conferences,"Convolutional neural network (CNN)-based object detection for optical remote sensing images has achieved higher accuracy compared with traditional detection methods with handcrafted features. However, the deep and large CNNs make it hard to be deployed in real-time scenarios with limited computation, storage, power and bandwidth resources, for example, data processing onboard airborne, satellites and unmanned aerial vehicles for search and rescue. Therefore, in this paper we present a high-performance object detection approach for optical remote sensing images. Based on the widely used Faster R-CNN framework, we integrate state-of-the-art lightweight CNNs as backbone to extract features, slim the heavy-head architecture of two-stage detector by reducing dimensions of features, and fine-tune our models with NWPU VHR-10 optical remote sensing dataset. Besides, the multi-threading for CPU and detection in batches for GPU are deployed to enhance the throughput of detectors and utilization of multi-core CPU and many-core GPU. Experiments show that our presented detection approach can significantly reduce the model size, computation complexity and detection time, while maintaining competitive accuracy. Specifically, the one with ShuffleNet-v2 and slimmed features has achieved a highest mean average precision of 94.39%, a lowest computational complexity of 18.97 Giga floating point operations, a highest detection speed of 90.10 frames per second (fps) for GPU and 3.07 fps for CPU, corresponding to speedups of 6.94X and 13.26X compared with the baseline on the benchmarked system, with a model size of 13.6 MB. Moreover, it further improves the efficiency and achieves 4.98 fps on CPU with 4 threads, and 200.24 fps on GPU with a batch size of 32.",https://ieeexplore.ieee.org/document/9407897/,2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),14-16 Dec. 2020,ieeexplore
10.1109/ICRA.2014.6907000,Human aware UAS path planning in urban environments using nonstationary MDPs,IEEE,Conferences,"A growing concern with deploying Unmanned Aerial Vehicles (UAVs) in urban environments is the potential violation of human privacy, and the backlash this could entail. Therefore, there is a need for UAV path planning algorithms that minimize the likelihood of invading human privacy. We formulate the problem of human-aware path planning as a nonstationary Markov Decision Process, and provide a novel model-based reinforcement learning solution that leverages Gaussian process clustering. Our algorithm is flexible enough to accommodate changes in human population densities by employing Bayesian nonparametrics, and is real-time computable. The approach is validated experimentally on a large-scale long duration experiment with both simulated and real UAVs.",https://ieeexplore.ieee.org/document/6907000/,2014 IEEE International Conference on Robotics and Automation (ICRA),31 May-7 June 2014,ieeexplore
10.1109/DASC52595.2021.9594425,Indoor Autonomous Powerline Inspection Model,IEEE,Conferences,"This paper presents the development of an autonomous system that leverages the Quanser Qdrone to perform above-ground indoor autonomous powerline inspections. The powerline infrastructure is exposed to various extreme weather conditions that create an operational concern for utility companies. Frequent inspections ensure the safe operation of a power transmission grid. There are mainly two methods of examination, ground and air [1]. The ground inspections are often slow and challenging due to the rough terrain, utility pole height, and inaccessible remote areas. The aerial inspections are accomplished by deploying helicopters that are expensive to operate, maintain, and repair. As an alternative, Unmanned Aerial Vehicles (UAVs) are being widely adopted for both surveillance and analysis throughout the energy and utility industries. UAVs are being used for inspections of utility towers as well as powerlines as they are energy efficient, user friendly, and convenient. Drone video capturing allows for safer, faster, and more cost-effective solutions to powerline and utility tower inspections as the user does not have to leave the ground aside from repairs. The objective of this project was to develop an autonomous UAV system to detect and track powerlines and utility poles to perform fault inspections of their electrical and material components. The proposed algorithm used a state flow machine paired with an image recognition neural network to make decisions for searching, identifying, and flying along utility poles and powerlines. The proposed system was implemented using MathWorks MATLAB and Simulink with Quarc, a third-party toolbox designed by Quanser, enabling real-time applications with the QDrone. The project yielded an algorithm that would autonomously fly the Quanser QDrone through a scan of the local area, leverage a neural network, PowerNet, to locate an initial tower within the work area, follow attached powerlines if there are any, and locate the secondary tower. Once the inspection was completed, the QDrone would return to the home point and land.",https://ieeexplore.ieee.org/document/9594425/,2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC),3-7 Oct. 2021,ieeexplore
10.1109/IROS40897.2019.8967722,Informed Region Selection for Efficient UAV-based Object Detectors: Altitude-aware Vehicle Detection with CyCAR Dataset,IEEE,Conferences,"Deep Learning-based object detectors enhance the capabilities of remote sensing platforms, such as Unmanned Aerial Vehicles (UAVs), in a wide spectrum of machine vision applications. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such algorithms in scenarios that impose low-latency constraints during inference, in order to make mission-critical decisions in real-time. In this paper, we address the challenge of efficient deployment of region-based object detectors in aerial imagery, by introducing an informed methodology for extracting candidate detection regions (proposals). Our approach considers information from the UAV on-board sensors, such as flying altitude and light-weight computer vision filters, along with prior domain knowledge to intelligently decrease the number of region proposals by eliminating false-positives at an early stage of the computation, reducing significantly the computational workload while sustaining the detection accuracy. We apply and evaluate the proposed approach on the task of vehicle detection. Our experiments demonstrate that state-of-the-art detection models can achieve up to 2.6x faster inference by employing our altitude-aware data-driven methodology. Alongside, we introduce and provide to the community a novel vehicle-annotated and altitude-stamped dataset of real UAV imagery, captured at numerous flying heights under a wide span of traffic scenarios.",https://ieeexplore.ieee.org/document/8967722/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/INFOCOMWKSHPS47286.2019.9093759,Intelli-Eye: An UAV Tracking System with Optimized Machine Learning Tasks Offloading,IEEE,Conferences,"The unmanned aerial vehicles (UAVs) have been extensively used in providing intelligence such as target tracking. In our field experiments, a pre-trained deep neural network (DNN) is deployed on the UAV to identify a target from the captured video frames and enable UAV to keep tracking. However, tracking in real time by the DNN requires a lot of computational resources. This motivates us to consider offloading this type of machine learning (ML) tasks to a mobile edge computing (MEC) server. Specifically, we propose a novel hierarchical ML tasks distribution framework for the UAV tracking system, where the UAV is embedded with lower layers of the pre-trained convolutional neural network (CNN) model due to its limited computing capability, while the MEC server with rich computing resources will handle the higher layers of the CNN model. An optimization problem is formulated to minimize the CNN inference delay while taking into account the communications delay, computing time, and ML error. Insights are provided to understand the tradeoff between communications and ML computing in offloading decisions. Numerical results demonstrate the effectiveness of the proposed ML tasks distribution framework with the optimized offloading strategy.",https://ieeexplore.ieee.org/document/9093759/,IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),29 April-2 May 2019,ieeexplore
10.1109/VLSI-SoC.2017.8203456,Intelligent embedded and real-time ANN-based motor control for multi-rotor unmanned aircraft systems,IEEE,Conferences,"Constant technological advancements in commercial multirotor unmanned aerial vehicles (drones) resulted in their deployment in more and more applications, ranging from entertainment to disaster management and many more domains. However, in contrast to their powerful and diverse entrance into our lifestyle and society, they do not yet provide sufficient intrinsic fail-safe mechanisms to prevent accidents that may occur due to technical problems or unforeseen flight incidents such as turbulent winds, inexperienced pilots, and so on. Therefore, in the current study, we propose the use of an integrated intelligent motor controller, which is trained to recognize incidents directly from the on-board sensors (barometer, gyroscope, compass and accelerometer) and react in real-time, adjusting the drone's motors. The goal is to provide a small, intelligent, low-power, real-time, built-in controller for multirotor UAVs that will be able to understand a dangerous scenario right before it happens, start taking counter measures to keep the drone safe, and provide the pilot with a bigger reaction-time window. We propose the use of an artificial neural network, implemented in a lightweight embedded processing board, that is able to recognize and react in real-time to various turbulent situations. Experimental results suggest that our controller is able to respond properly and timely to wind changes (turbulence) allowing the drone to maintain its expected state and path.",https://ieeexplore.ieee.org/document/8203456/,2017 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC),23-25 Oct. 2017,ieeexplore
10.1109/IROS.2018.8594204,Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation,IEEE,Conferences,"Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.",https://ieeexplore.ieee.org/document/8594204/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/3ICT53449.2021.9581453,Machine Learning techniques implemented in IoT platform for fault detection in photovoltaic panels,IEEE,Conferences,"Novel condition monitoring systems and data analysis methods are required to support and enhance the information obtained with supervisory control and data acquisition systems. The application of advanced conditions monitoring systems based on thermographic cameras embedded in unmanned aerial vehicles is a challenge in maintenance. This paper presents an Internet of Things platform to detect faults by analyzing thermal images acquired by aerial inspections. The combination of two artificial neural networks is applied to detect regions with faults in photovoltaic solar panels, providing high accuracy. A real case study is studied with thermograms from two different photovoltaic solar plants. The analysis is performed in the platform, and the average results obtained shows 93% of accuracy for hot spot detection.",https://ieeexplore.ieee.org/document/9581453/,"2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)",29-30 Sept. 2021,ieeexplore
10.1109/IWCMC51323.2021.9498892,Mobility Prediction For Aerial Base Stations for a Coverage Extension in 5G Networks,IEEE,Conferences,"A promising potential of Unmanned Aerial Vehicles (UAV) in 5G networks is to act as Aerial Base Stations (ABSs) that dynamically extend terrestrial base stations coverage without overloading the infrastructure. However, coverage extension faces crucial challenges such as user mobility and determining the best coordinates for new base station deployment. In this paper, we address this problem based on the prediction of users' spatial distribution that allows Aerial base stations (ABS) to adjust their position accordingly. We first analyze the performance of two machine learning schemes (Long Short Term Memory (LSTM)-based encoder-decoder and self-attention-based Transformer) for user mobility prediction based on a real DataSet. Then, we use these schemes to enhance the ABS deployment algorithm. Numerical results reveal significant gains when applying the proposed mobility prediction models over traditional deployment algorithms. In four hours of the day, both the Transformer and LSTM based models show, respectively, more than 31% and 22% gain in coverage rates compared to regular deployment schemes.",https://ieeexplore.ieee.org/document/9498892/,2021 International Wireless Communications and Mobile Computing (IWCMC),28 June-2 July 2021,ieeexplore
10.1109/UKRICIS.2008.4798952,Neural network based adaptive nonlinear model inversion control of a twin rotor system in real time,IEEE,Conferences,A real time adaptive nonlinear model inversion controller is implemented on a twin rotor multi-input-multi-output system (TRMS) using artificial neural networks. The TRMS is an experimental aerodynamic test bed representing the control challenges of unmanned aerial vehicles. In this study a nonlinear dynamic model of the system is considered and a nonlinear inverse model is used for the pitch channel of the system. The feedback control system and an adaptive neural network element are integrated to compensate the possible model inversion errors. The proposed online learning algorithm updates the weights and biases of the neural network using the error between the setpoint and the real output. Square and sinusoidal reference command signals are used to test the performance of the controller. It is noted that a reasonable tracking response is exhibited in the presence of inversion errors caused by model uncertainty. This paper is the experimental study of the previous work by the same authors in which the proposed method has only been verified by simulation results.,https://ieeexplore.ieee.org/document/4798952/,2008 7th IEEE International Conference on Cybernetic Intelligent Systems,9-10 Sept. 2008,ieeexplore
10.1109/WCNPS.2019.8896308,On the application of SEGAN for the attenuation of the ego-noise in the speech sound source localization problem,IEEE,Conferences,"In this paper, we present some preliminary results using the Speech Enhancement Generative Adversarial Network (SEGAN) for the attenuation of the ego-noise in the speech source localization problem embedded in unmanned aerial vehicles (UAV). This task is of great interest in UAV search and rescue scenarios. The primary motivation of using the SEGAN is that it seems to preserve the waveform of the speech signal, which is essential for time-based direction of arrival (TDOA) algorithms. Although preliminary, the obtained results open an excellent perspective for its usage in this problem and despite its computational burden in the training stage, once the SEGAN is trained, it can be implemented for working in real-time scenarios.",https://ieeexplore.ieee.org/document/8896308/,2019 Workshop on Communication Networks and Power Systems (WCNPS),3-4 Oct. 2019,ieeexplore
10.1109/CYBER53097.2021.9588193,Onboard Real-time Object Detection for UAV with Embedded NPU,IEEE,Conferences,"Unmanned aerial vehicles (UAVs) endowed with the function of computer vision are widely applied. There is an urgent need to implement real-time object detection. However, the limited memory and computing capacity of current embedded devices prevent the deployment of deep learning on UAVs. Therefore, this paper proposes an efficient onboard object detection system based on an embedded NPU device. It can be deployed on a UAV to perform real-time scenario analysis. Firstly, a deep-learning network structure based on YOLOV3-Tiny is designed for object detection. Then it is compressed by a novel pruning strategy to obtain a “slim” object detector. Finally, a detection-reinitialization mechanism is introduced to realize the robust output of detection. The experimental results demonstrate that our model and algorithm achieve efficient performance of detection compared to the unoptimized benchmark. The proposed model achieves up to 0.591 mAP with a 6M parameter size. The complete system is tested in both simulation and real environments of the aerial manipulator grasping task. The effective detection frame ratio reaches 90%, and FPS achieves about 25.",https://ieeexplore.ieee.org/document/9588193/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/PIMRC48278.2020.9217347,Optimal Transmission Control and Learning-Based Trajectory Design for UAV-Assisted Detection and Communication,IEEE,Conferences,"Due to their high mobility, flexible deployment and stable maneuverability, unmanned aerial vehicles (UAVs) have been deemed as a promising and indispensable role for various emerging applications (e.g., dangerous area detection, dynamic target tracking, and map remote sensing). Compared to the static monitoring equipments, UAV-mounted high-definition camera and signal transceiver can be used cost-effectively as an on-demand aerial platform to detect the unknown region and send the real-time data back at the same time. However, these highlighted limitations of battery capacity and communication resource extremely affect the UAV's performance such as flight endurance and data transmission. Motivated by the above conflicts, this paper aims to minimize the total energy consumed by the UAV during the region detection mission through jointly optimizing the collected data size, transmission time, and flying trajectory. Toward this end, we derive the optimal data collection and transmission time in closed forms via convex optimization, and propose a model-free reinforcement learning-based algorithm for training the UAV to plan its trajectory without knowing the environment information in advance. Simulation results validate the performance of our designs in terms of convergence, energy consumption, and energy efficiency.",https://ieeexplore.ieee.org/document/9217347/,"2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications",31 Aug.-3 Sept. 2020,ieeexplore
10.1109/ISCAS45731.2020.9181004,Optimized Random Forest Classifier for Drone Pilot Identification,IEEE,Conferences,"Random forest is a powerful machine learning scheme which finds applications in real-time systems such as unmanned aerial vehicles. In such applications not only the classification performance is relevant but also several non-functional requirements including the classification time, the memory usage and the power consumption. This paper proposes a new approach to improve the real-time behavior of a random forest classifier. This is accomplished by reducing the number of evaluated nodes and branches as well as by reducing the branch length in the underlying binary decision trees with numerical split values. A hardware architecture is presented for the improved tree-based classification method. A proof-of-concept implementation on an FPGA platform and some preliminary results show the advantage of this approach compared to related work.",https://ieeexplore.ieee.org/document/9181004/,2020 IEEE International Symposium on Circuits and Systems (ISCAS),12-14 Oct 2020,ieeexplore
10.1109/ICCE.2018.8326145,Optimized vision-directed deployment of UAVs for rapid traffic monitoring,IEEE,Conferences,"The flexibility and cost efficiency of traffic monitoring using Unmanned Aerial Vehicles (UAVs) has made such a proposition an attractive topic of research. To date, the main focus was placed on the types of sensors used to capture the data, and the alternative data processing options to achieve good monitoring performance. In this work we move a step further, and explore the deployment strategies that can be realized for rapid traffic monitoring over particular regions of the transportation network by considering a monitoring scheme that captures data from a visual sensor on-board the UAV, and subsequently analyzes it through a specific vision processing pipeline to extract network state information. These innovative deployment strategies can be used in real-time to assess traffic conditions, while for longer periods, to validate the underlying mobility models that characterise traffic patterns.",https://ieeexplore.ieee.org/document/8326145/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/IDT52577.2021.9497540,Phishing Detection for Secure Operations of UAVs,IEEE,Conferences,"Unmanned Aerial Vehicles (UAV) or drones are used in various domains more and more, including military operations, monitoring, rescue of victims, and transport. Often, UAV resources are developed as web services so that they can be accessed anywhere on the Internet through the World Wide Web. However, this makes them vulnerable to phishing activities of criminals who may try to access these resources and other sensitive information. Therefore, the development of a phishing detection tool based on data mining is presented in this paper. It consists of a browser extension monitoring visited webpages and a backend communicating with the browser extension for the purposes of executing some specific tasks. The browser extension is implemented in JavaScript and the ReactJS framework, and it contains an implementation of classifications with a Bayesian network, decision tree, nearest neighbor classifier and neural network. The backend uses PHP, Python scripts and the Apache HTTP Server. In addition, a browser extension is implemented so that data about webpages can be collected and this data is used for the creation of data mining models. Experimental validation with 10-fold cross-validation and through the browsing of real-world websites show promising results in phishing detection.",https://ieeexplore.ieee.org/document/9497540/,2021 International Conference on Information and Digital Technologies (IDT),22-24 June 2021,ieeexplore
10.1109/ICNS50378.2020.9223013,RF Fingerprint Measurement For Detecting Multiple Amateur Drones Based on STFT and Feature Reduction,IEEE,Conferences,"Underlying the easy accessibility and popularity of amateur unmanned aerial vehicles (UAVs, or drones), an effective multi-UAV detection method is desired. In this paper, we proposed a novel radio frequency (RF) signal detection method for recognizing multiple UAVs' intrusion. The single transient control and video signal is transformed by Short Time Fourier Transform (STFT) to obtain its time-frequency-energy distribution features. To reduce the dimensionality of the RF feature vector, the principal component analysis (PCA) is applied in the signal characteristic subspace transformation. A remapped UAVs RF signal feature data is used in the training of the support vector machine (SVM) and K-nearest neighbor (KNN) algorithm for classifying the presence and number of intruding UAVs. In addition, a real-time test of UAV attacks on an airport area is implemented. The test results show that the accuracy for detecting the number of intruding UAVs is effective. This method could similarly apply to protect the public from unsafe and unauthorized UAV operations near security sensitive facilities.",https://ieeexplore.ieee.org/document/9223013/,2020 Integrated Communications Navigation and Surveillance Conference (ICNS),8-10 Sept. 2020,ieeexplore
10.1109/ICPHYS.2019.8780266,Real-Time SLFN-Based Node Localization Using UAV,IEEE,Conferences,"In this paper, a novel real-time single hidden layer feedforward neural network (SLFN)-based node localization technique in the wireless sensor network (WSN) is proposed. The localization is performed using mobile unmanned aerial vehicles (UAVs) as the anchor nodes to send the beacon signals every period of time, thus every unknown node can estimate it's current position based on the RSSI values of the received beacon signals by training the SLFN using extreme learning machine (ELM) technique. There are no deployed ground anchor node and require fewer anchor nodes compared to traditional RSSI-based localization technique to yield better accuracy. Simulation results show that this technique is capable of performing real-time unknown nodes localization with less localization error by using ELM compared to other traditional machine learning algorithms.",https://ieeexplore.ieee.org/document/8780266/,2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS),6-9 May 2019,ieeexplore
10.1109/MSN50589.2020.00065,Real-Time Survivor Detection in UAV Thermal Imagery Based on Deep Learning,IEEE,Conferences,"Unmanned Aerial Vehicles (UAVs) uses evolved significantly due to its high durability, lower costs, easy implementation, and flexibility. After a natural disaster occurs, UAVs can quickly search the affected area to save more survivors. Dataset is crucial in developing a round-the-clock rescue system applying deep learning methods. In this paper, we collected a new thermal image dataset captured by UAV for post-disaster search and rescue (SAR) activities. After that, we employed several different deep convolutional neural networks to train the pedestrian detection models on our datasets, including YOLOV3, YOLOV3-MobileNetV1 and YOLOV3-MobileNetV3. Because the onboard microcomputer has limited computing capacity and memory, for balancing the inference time and accuracy, we find optimal points to prune and fine-tune the network based on the sensitivity of convolutional layers. We validate on NVIDIA's Jetson TX2 and achieve 26.60 FPS (Frames per second) real-time performance.",https://ieeexplore.ieee.org/document/9394263/,"2020 16th International Conference on Mobility, Sensing and Networking (MSN)",17-19 Dec. 2020,ieeexplore
10.1109/ICTC49870.2020.9289086,Reinforcement Learning based Real Time Aerial BS Positioning for Dense Urban 5G Mobile Network,IEEE,Conferences,"Due to the recent surge in mobile users and traffic, next-generation mobile communication aims to increase network capacity through large bandwidth and small cell deployment. To respond to this situation, there have been lots of researches on aerial base stations (BSs) using unmanned aerial vehicles (UAVs) for the mobile user. Aerial BS has the advantage of providing flexible communication range by avoiding obstacles such as buildings in urban areas through 3D positioning. However, finding an optimal point for aerial BS considering the variance of user's requirements, movement, and obstacles in real time is difficult problem to solve. Therefore, it is necessary to find an approximate optimal point for applying to the real-time flight path control of aerial BS. This paper aims to find optimal behavior in real time interacting with a given environment, through reinforcement learning. We propose the algorithm based on Q-learning with a new concept called Coarse Search to reduce convergence speed. We evaluate the performance of the algorithm by comparing it with that of other heuristic algorithms.",https://ieeexplore.ieee.org/document/9289086/,2020 International Conference on Information and Communication Technology Convergence (ICTC),21-23 Oct. 2020,ieeexplore
10.1109/ICIP.2019.8803262,SSSDET: Simple Short and Shallow Network for Resource Efficient Vehicle Detection in Aerial Scenes,IEEE,Conferences,"Detection of small-sized targets is of paramount importance in many aerial vision-based applications. The commonly deployed low cost unmanned aerial vehicles (UAVs) for aerial scene analysis are highly resource constrained in nature. In this paper we propose a simple short and shallow network (SSSDet) to robustly detect and classify small-sized vehicles in aerial scenes. The proposed SSSDet is up to 4× faster, requires 4.4× less FLOPs, has 30× less parameters, requires 31× less memory space and provides better accuracy in comparison to existing state-of-the-art detectors. Thus, it is more suitable for hardware implementation in real-time applications. We also created a new airborne image dataset (ABD) by annotating 1396 new objects in 79 aerial images for our experiments. The effectiveness of the proposed method is validated on the existing VEDAI, DLR-3K, DOTA and Combined dataset. The SSSDet outperforms state-of-the-art detectors in term of accuracy, speed, compute and memory efficiency.",https://ieeexplore.ieee.org/document/8803262/,2019 IEEE International Conference on Image Processing (ICIP),22-25 Sept. 2019,ieeexplore
10.1049/cp.2012.1357,Small Unmanned Aerial Vehicle visual system for ground moving target positioning,IET,Conferences,"Recently, Small Unmanned Aerial Vehicles (SUAV) are used in a variety of reconnaissance, surveillance, combat applications and so on. Tracking and positioning ground moving targets using a camera mounted on SUAVs has important applications in military and civilian purposes. Although many approaches for a vision-based target positioning system have been developed, most researches are limited to target recognition algorithm or target state estimation. And hardware implementation schemes which can work well with the whole SUAV system are seldom discussed. In order to achieve an available systematic scheme, a complete visual system which incorporates a vision-based ground moving target positioning algorithm is presented in this paper. Experiment results are finally shown and commented. Experiments indicate that the system performs great real time response and high positioning precision.",https://ieeexplore.ieee.org/document/6492964/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/URTC.2015.7563746,Spectral anomaly detection with machine learning for wilderness search and rescue,IEEE,Conferences,"In wilderness search and rescue missions, unmanned aerial vehicles (UAVs) may be deployed to collect high-resolution imagery which is later reviewed by a first responder. The volume of images and the altitude from which they are taken makes manually identifying potential items of interest, like clothing or other man-made material, a difficult task. For this reason, we created a program that automatically detects unusually-colored objects in aerial imagery in order to assist responders in locating signs of missing persons. The program uses the Reed-Xiaoli (RX) spectral anomaly detection algorithm to determine which pixels in an image are anomalous and then generates an ""anomaly map"" where brighter pixels signify greater abnormality. While the RX algorithm has previously been proposed for search and rescue missions, up until now it has not been evaluated in a high-fidelity setting with real responders and real equipment. We tested the program on 150 aerial images taken over the Blanco River area in Hays County, Texas after the May 2015 flooding and demonstrated the results at a workshop on flooding hosted by Texas A&amp;M's Center for Emergency Informatics. Early feedback from responders suggests that RX spectral anomaly detection is a valuable tool for quickly locating atypically-colored objects in images taken with UAVs for wilderness search and rescue.",https://ieeexplore.ieee.org/document/7563746/,2015 IEEE MIT Undergraduate Research Technology Conference (URTC),7-8 Nov. 2015,ieeexplore
10.1109/ICARCV.2006.345471,Terrain Modeling Using Machine Learning Methods,IEEE,Conferences,"The problem of terrain modeling is basically a type of function approximation problem. This type of problem has been widely studied in the soft computing community. In recent years, neural networks have been successfully applied to surface reconstruction and classification problems involving scattered data. However, due to the iterative nature of training a neural network, the resulting high cost in computational time limits the implementation of machine learning based methods in many real world applications (for example, navigation applications in unmanned aerial vehicles) that require fast generation of terrain models. A recently proposed machine learning method, the extreme learning machine (ELM), is able to train single-layer feed forward neural networks with excellent speed and good generalization. In this paper, we present terrain modeling using various machine learning methods, and we compare the performances of these methods with ELM. We also present a comparison of terrain modeling performances between ELM and the popular choice of terrain and surface modeling technique, the Delaunay triangulation with linear interpolation. Our results show that machine learning using ELM offers a potential solution to terrain modeling problems with good performances",https://ieeexplore.ieee.org/document/4150400/,"2006 9th International Conference on Control, Automation, Robotics and Vision",5-8 Dec. 2006,ieeexplore
10.1109/ICISCAE48440.2019.221655,The Construction of Portrait Identification Tracking System Based on Mask R-CNN,IEEE,Conferences,"A portrait identification and tracking system with strong real-time performance, good flexibility and controllable cost is designed and implemented in the paper. Firstly, Mask R-CNN neural network is used to extract the features of the target, and the COCO dataset is used to train and establish the portrait data model. As a result, accuracy of the portrait recognition is improved. Then, a portrait tracking system including monocular camera, data acquisition module, data processing module, steering gear and control system is built. And the ""Raspberry Pi"" control method is used to control the MG955 steering gear group. Finally, the recognition and tracking of characters can be realized through wired, WIFI, Bluetooth and other ways, which improves the universality of the system. The designed system has simple structure, complete functions and can be used for automatic aiming and tracking of other objects. The modular system can also be used for unmanned aerial vehicles, robots and other platforms.",https://ieeexplore.ieee.org/document/9075573/,2019 2nd International Conference on Information Systems and Computer Aided Education (ICISCAE),28-30 Sept. 2019,ieeexplore
10.1109/RO-MAN46459.2019.8956420,Trust Repair in Human-Swarm Teams+,IEEE,Conferences,"Swarm robots are coordinated via simple control laws to generate emergent behaviors such as flocking, rendezvous, and deployment. Human-swarm teaming has been widely proposed for scenarios, such as human-supervised teams of unmanned aerial vehicles (UAV) for disaster rescue, UAV and ground vehicle cooperation for building security, and soldier-UAV teaming in combat. Effective cooperation requires an appropriate level of trust, between a human and a swarm. When an UAV swarm is deployed in a real-world environment, its performance is subject to real-world factors, such as system reliability and wind disturbances. Degraded performance of a robot can cause undesired swarm behaviors, decreasing human trust. This loss of trust, in turn, can trigger human intervention in UAVs' task executions, decreasing cooperation effectiveness if inappropriate. Therefore, to promote effective cooperation we propose and test a trust-repairing method (Trust-repair) restoring performance and human trust in the swarm to an appropriate level by correcting undesired swarm behaviors. Faulty swarms caused by both external and internal factors were simulated to evaluate the performance of the Trust-repair algorithm in repairing swarm performance and restoring human trust. Results show that Trust-repair is effective in restoring trust to a level intermediate between normal and faulty conditions.",https://ieeexplore.ieee.org/document/8956420/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ETFA.2016.7733537,UAV degradation identification for pilot notification using machine learning techniques,IEEE,Conferences,"Unmanned Aerial Vehicles are currently investigated as an important sub-domain of robotics, a fast growing and truly multidisciplinary research field. UAVs are increasingly deployed in real-world settings for missions in dangerous environments or in environments which are challenging to access. Combined with autonomous flying capabilities, many new possibilities, but also challenges, open up. To overcome the challenge of early identification of degradation, machine learning based on flight features is a promising direction. Existing approaches build classifiers that consider their features to be correlated. This prevents a fine-grained detection of degradation for the different hardware components. This work presents an approach where the data is considered uncorrelated and, using machine learning techniques, allows the precise identification of UAV's damages.",https://ieeexplore.ieee.org/document/7733537/,2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA),6-9 Sept. 2016,ieeexplore
10.1109/ECAI50035.2020.9223154,UAV identification system based on memristor physical unclonable functions,IEEE,Conferences,"The latest decades presented a large development of various size and types of Unmanned Aerial Vehicles (UAVs). Nowadays, there are over 200 million UAVs used in various applications and there it is a large effort to adopt national and international regulation for using them. There it is a real need for the development of a reliable system for UAVs identity verification that can be implemented and used at global level. To this moment the software-based methods such as MAC address, IDs memorized on devices are prone to a large number of cyber-security vulnerabilities and attacks. This paper presents an innovative hardware-based identification solution which could be adapted to UAVs in a non-intrusive manner. The proposed solution is based on physical unclonable functions (PUF), which are implemented by using memristors. The proposed solution is very low cost and high performance. By using memristors, it is possible to generate a very large number of unclonable IDs, using only a few electrical components. This solution could be incorporated in any UAVs systems without major modifications and not affecting their flight parameters.",https://ieeexplore.ieee.org/document/9223154/,"2020 12th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",25-27 June 2020,ieeexplore
10.1109/AERO.2017.7943775,UAV tracking and following a ground target under motion and localisation uncertainty,IEEE,Conferences,"Unmanned Aerial Vehicles (UAVs) are increasingly being used in numerous applications, such as remote sensing, environmental monitoring, ecology and search and rescue missions. Effective use of UAVs depends on the ability of the system to navigate in the mission scenario, especially if the UAV is required to navigate autonomously. There are particular scenarios in which UAV navigation faces challenges and risks. This creates the need for robust motion planning capable of overcoming different sources of uncertainty. One example is a UAV flying to search, track and follow a mobile ground target in GPS-denied space, such as below canopy or in between buildings, while avoiding obstacles. A UAV navigating under these conditions can be affected by uncertainties in its localization and motion due to occlusion of GPS signals and the use of low cost sensors. Additionally, the presence of strong winds in the airspace can disturb the motion of the UAV. In this paper, we describe and flight test a novel formulation of a UAV mission for searching, tracking and following a mobile ground target. This mission is formulated as a Partially Observable Markov Decision Process (POMDP) and implemented in real flight using a modular framework. We modelled the UAV dynamic system, the uncertainties in motion and localization of both the UAV and the target, and the wind disturbances. The framework computes a motion plan online for executing motion commands instead of flying to way-points to accomplish the mission. The system enables the UAV to plan its motion allowing it to execute information gathering actions to reduce uncertainty by detecting landmarks in the scenario, while making predictions of the mobile target trajectory and the wind speed based on observations. Results indicate that the system overcomes uncertainties in localization of both the aircraft and the target, and avoids collisions into obstacles despite the presence of wind. This research has the potential of use particularly for remote monitoring in the fields of biodiversity and ecology.",https://ieeexplore.ieee.org/document/7943775/,2017 IEEE Aerospace Conference,4-11 March 2017,ieeexplore
10.1109/ICoIAS.2018.8494201,UAVNet: An Efficient Obstacel Detection Model for UAV with Autonomous Flight,IEEE,Conferences,"Autonomous navigation for large Unmanned Aerial Vehicles(UAVs) is straight-forward to implement, just employ expensive and sophisticated sensors and monitoring devices. On the contrary, usual small quadrotor UAV still have the challenge on obstacle avoidance since this kind of UAV can only carry very light weight sensors such as cameras. Given the above reason, making autonomous navigation over obstacles on small UAV is much more challenging. In this paper, we focus on proposing a novel and memory efficient deep network architecture named UAVNet for small UAV to achieve obstacle detection in the urban environment. Compared with state-of-the-art DNN architecture, UAVNet has only 2.23M parameters(which is half compared with MobileNet) and 141 MFLOPs complexity. Though the parameters are fewer than usual, the accuracy is acceptable, about 80% validated on ImageNet-2102 dataset. To further justify the utility of UAVNet, we also implement the architecture on Nvidia TX2 in real environment using NCTU campus dataset. The experiment shows the proposed UAVNet can detect obstacles to 15 fps, which is a real-time application.",https://ieeexplore.ieee.org/document/8494201/,2018 International Conference on Intelligent Autonomous Systems (ICoIAS),1-3 March 2018,ieeexplore
10.23919/ACC45564.2020.9147911,Unmanned Aerial Vehicle Angular Velocity Control via Reinforcement Learning in Dimension Reduced Search Spaces,IEEE,Conferences,"Search space dimension reduction strategies are studied for reinforcement learning based angular velocity control of multirotor unmanned aerial vehicles. Reinforcement learning approximates the value function iteratively over the state-action space, which is 6-dimensional in the case of multirotor angular velocity control. An inverse-dynamics approach is applied to reduce the 6-dimensional state-action space to a 3-dimensional state-only search space while estimating the uncertain model parameters. The search space dimension is further reduced when the state variables are only allowed to vary following either a motion camouflage strategy or a hyperbolic tangent path. Simulation results show that the modified reinforcement learning algorithms can be implemented in real time for multirotor angular velocity control.",https://ieeexplore.ieee.org/document/9147911/,2020 American Control Conference (ACC),1-3 July 2020,ieeexplore
10.1109/ICRA.2018.8460692,Visual-Inertial Navigation Algorithm Development Using Photorealistic Camera Simulation in the Loop,IEEE,Conferences,"The development of fast, agile micro Unmanned Aerial Vehicles (UAVs) has been limited by (i) on-board computing hardware restrictions, (ii) the lack of sophisticated vision-based perception and vision-in-the-loop control algorithms, and (iii) the absence of development environments where such systems and algorithms can be rapidly and easily designed, implemented, and validated. Here, we first present a new micro UAV platform that integrates high-rate cameras, inertial sensors, and an NVIDIA Jetson Tegra X1 system-on-chip compute module that boasts 256 GPU cores. The UAV mechanics and electronics were designed and built in house, and are described in detail. Second, we present a novel “virtual reality” development environment, in which photorealistically-rendered synthetic on-board camera images are generated in real time while the UAV is in flight. This development environment allows us to rapidly prototype computing and sensing hardware as well as perception and control algorithms, using real physics, real interoceptive sensor data (e.g., from the on-board inertial measurement unit), and synthetic exteroceptive sensor data (e.g., from synthetic cameras). Third, we demonstrate repeated agile maneuvering with closed-loop vision-based perception and control algorithms, which we have developed using this environment.",https://ieeexplore.ieee.org/document/8460692/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/MFI.2017.8170439,Wearable gesture control of agile micro quadrotors,IEEE,Conferences,"Quadrotor unmanned aerial vehicles (UAVs) have seen a surge of use in various applications due to its structural simplicity and high maneuverability. However, conventional control methods using joysticks prohibit novices from getting used to maneuvering quadrotors in short time. In this paper, we suggest the use of a wearable device, such as a smart watch, as a new remote-controller for a quadrotor. The user's command is recognized as gestures using the 9-DoF inertial measurement unit (IMU) of a wearable device through a recurrent neural network (RNN) with long short-term memory (LSTM) cells. Our implementation also makes it possible to align the heading of a quadrotor with the heading of the user. Our implementation allows nine different gestures and the trained RNN is used for real-time gesture recognition for controlling a micro quadrotor. The proposed system exploits available sensors in a wearable device and a quadrotor as much as possible to make the gesture-based control intuitive. We have experimentally validated the performance of the proposed system by using a Samsung Gear S smart watch and a Crazyflie Nano Quadcopter.",https://ieeexplore.ieee.org/document/8170439/,2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI),16-18 Nov. 2017,ieeexplore
10.1109/OJCOMS.2020.3010270,"6G Wireless Communication Systems: Applications, Requirements, Technologies, Challenges, and Research Directions",IEEE,Journals,"The demand for wireless connectivity has grown exponentially over the last few decades. Fifth-generation (5G) communications, with far more features than fourth-generation communications, will soon be deployed worldwide. A new paradigm of wireless communication, the sixth-generation (6G) system, with the full support of artificial intelligence, is expected to be implemented between 2027 and 2030. Beyond 5G, some fundamental issues that need to be addressed are higher system capacity, higher data rate, lower latency, higher security, and improved quality of service (QoS) compared to the 5G system. This paper presents the vision of future 6G wireless communication and its network architecture. This article describes emerging technologies such as artificial intelligence, terahertz communications, wireless optical technology, free-space optical network, blockchain, three-dimensional networking, quantum communications, unmanned aerial vehicles, cell-free communications, integration of wireless information and energy transfer, integrated sensing and communication, integrated access-backhaul networks, dynamic network slicing, holographic beamforming, backscatter communication, intelligent reflecting surface, proactive caching, and big data analytics that can assist the 6G architecture development in guaranteeing the QoS. Besides, expected applications with 6G communication requirements and possible technologies are presented. We also describe potential challenges and research directions for achieving this goal.",https://ieeexplore.ieee.org/document/9144301/,IEEE Open Journal of the Communications Society,2020,ieeexplore
10.1109/JIOT.2019.2917066,A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones,IEEE,Journals,"Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm<sup>2</sup>. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8715489/,IEEE Internet of Things Journal,Oct. 2019,ieeexplore
10.1109/COMST.2019.2902862,"A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and Open Problems",IEEE,Journals,"The use of flying platforms such as unmanned aerial vehicles (UAVs), popularly known as drones, is rapidly growing. In particular, with their inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs admit several key potential applications in wireless systems. On the one hand, UAVs can be used as aerial base stations to enhance coverage, capacity, reliability, and energy efficiency of wireless networks. On the other hand, UAVs can operate as flying mobile terminals within a cellular network. Such cellular-connected UAVs can enable several applications ranging from real-time video streaming to item delivery. In this paper, a comprehensive tutorial on the potential benefits and applications of UAVs in wireless communications is presented. Moreover, the important challenges and the fundamental tradeoffs in UAV-enabled wireless networks are thoroughly investigated. In particular, the key UAV challenges such as 3D deployment, performance analysis, channel modeling, and energy efficiency are explored along with representative results. Then, open problems and potential research directions pertaining to UAV communications are introduced. Finally, various analytical frameworks and mathematical tools, such as optimization theory, machine learning, stochastic geometry, transport theory, and game theory are described. The use of such tools for addressing unique UAV problems is also presented. In a nutshell, this tutorial provides key guidelines on how to analyze, optimize, and design UAV-based wireless communication systems.",https://ieeexplore.ieee.org/document/8660516/,IEEE Communications Surveys & Tutorials,thirdquarter 2019,ieeexplore
10.1109/TIM.2021.3126398,A Visual Navigation Framework for the Aerial Recovery of UAVs,IEEE,Journals,"This article proposes a visual navigation framework for the aerial recovery of unmanned aerial vehicles (UAVs). The framework is employed for pose estimation between the drogue and the probe to guide the recovery UAV to safely dock with the drogue. First, a deep learning-based detector and the proposed adaptive region of interest (AROI) tracker give the region of interest (ROI) of the drogue at high speed. Second, the centroids of the markers installed on the ring of the drogue can be extracted by image processing of the ROI, which can effectively reduce the computational overhead and the noise impact from other irrelevant areas. To improve the robustness of the framework, a marker compensation method is proposed to address situations of occlusion. After all the centroid coordinates in the image are obtained, stereo vision is employed to measure the drogue pose. Then, a Kalman filter (KF) is applied to accurately estimate the drogue pose. Finally, a ground semiphysical closed-loop experiment of the docking phase of aerial recovery is developed to verify the effectiveness of the proposed framework. The experimental results show that our framework has high accuracy, strong robustness, and good real-time performance.",https://ieeexplore.ieee.org/document/9606501/,IEEE Transactions on Instrumentation and Measurement,2021,ieeexplore
10.1109/ACCESS.2021.3097945,Autonomous Quadrotor Navigation With Vision Based Obstacle Avoidance and Path Planning,IEEE,Journals,"Due to the high demands on military and commercial applications, the development of UAVs (unmanned aerial vehicles) has become increasingly important in recent years. In this paper, we present a vision guided autonomous navigation approach for quadrotor UAVs. A map-based offline path planning technique is developed to generate an initial path, followed by the waypoints of the trajectory for flight guidance. During the navigation, an onboard camera is utilized to acquire a sequence of monocular images for environment perception. A vision-based obstacle detection technique using optical flow is proposed for collision avoidance. The optical flow field constructed from the image sequence is used to provide the depth cues for the incoming obstacle detection. A single-board computer is adopted as a control platform, and the proposed algorithms are implemented for online and real-time processing. Several experiments are carried out in the outdoor environment for obstacles avoidance and visual guidance. The results have demonstrated the feasibility of our proposed method for path planning and autonomous navigation.",https://ieeexplore.ieee.org/document/9490263/,IEEE Access,2021,ieeexplore
10.1109/JSAC.2017.2680898,Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned Aerial Vehicles for Optimized Quality-of-Experience,IEEE,Journals,"In this paper, the problem of proactive deployment of cache-enabled unmanned aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of wireless devices in a cloud radio access network is studied. In the considered model, the network can leverage human-centric information, such as users' visited locations, requested contents, gender, job, and device type to predict the content request distribution, and mobility pattern of each user. Then, given these behavior predictions, the proposed approach seeks to find the user-UAV associations, the optimal UAVs' locations, and the contents to cache at UAVs. This problem is formulated as an optimization problem whose goal is to maximize the users' QoE while minimizing the transmit power used by the UAVs. To solve this problem, a novel algorithm based on the machine learning framework of conceptor-based echo state networks (ESNs) is proposed. Using ESNs, the network can effectively predict each user's content request distribution and its mobility pattern when limited information on the states of users and the network is available. Based on the predictions of the users' content request distribution and their mobility patterns, we derive the optimal locations of UAVs as well as the content to cache at UAVs. Simulation results using real pedestrian mobility patterns from BUPT and actual content transmission data from Youku show that the proposed algorithm can yield 33.3% and 59.6% gains, respectively, in terms of the average transmit power and the percentage of the users with satisfied QoE compared with a benchmark algorithm without caching and a benchmark solution without UAVs.",https://ieeexplore.ieee.org/document/7875131/,IEEE Journal on Selected Areas in Communications,May 2017,ieeexplore
10.1109/ACCESS.2020.3031326,Control Strategies and Novel Techniques for Autonomous Rotorcraft Unmanned Aerial Vehicles: A Review,IEEE,Journals,"This paper presents a review of the various control strategies that have been conducted to address and resolve several challenges for a particular category of unmanned aerial vehicles (UAVs), the emphasis of which is on the rotorcraft or rotary-wing systems. Initially, a brief overview of the important relevant definitions, configurations, components, advantages/disadvantages, and applications of the UAVs is first introduced in general, encompassing a wide spectrum of the flying machines. Subsequently, the focus is more on the two most common and versatile rotorcraft UAVs, namely, the twin-rotor and quadrotor systems. Starting with a brief background on the dual-rotor helicopter and a quadcopter, the full detailed mathematical dynamic model of each system is derived based on the Euler-Lagrange and Newton-Euler methods, considering a number of assumptions and considerations. Then, a state-of-the-art review of the diverse control strategies for controlling the rotorcraft systems with conceivable solutions when the systems are subjected to the different impediments is demonstrated. To counter some of these limitations and adverse operating/loading conditions in the UAVs, several innovative control techniques are particularly highlighted, and their performance are duly analyzed, discussed, and compared. The applied control techniques are deemed to produce a useful contribution to their successful implementation in the wake of varied constraints and demanding environments that result in a degree of robustness and efficacy. Some of the off-the-shelf developments in the rotorcraft systems for research and commercial applications are also presented.",https://ieeexplore.ieee.org/document/9224621/,IEEE Access,2020,ieeexplore
10.1109/TITS.2020.3039617,Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep Reinforcement Learning Approach,IEEE,Journals,"In this paper, we design a navigation policy for multiple unmanned aerial vehicles (UAVs) where mobile base stations (BSs) are deployed to improve the data freshness and connectivity to the Internet of Things (IoT) devices. First, we formulate an energy-efficient trajectory optimization problem in which the objective is to maximize the energy efficiency by optimizing the UAV-BS trajectory policy. We also incorporate different contextual information such as energy and age of information (AoI) constraints to ensure the data freshness at the ground BS. Second, we propose an agile deep reinforcement learning with experience replay model to solve the formulated problem concerning the contextual constraints for the UAV-BS navigation. Moreover, the proposed approach is well-suited for solving the problem, since the state space of the problem is extremely large and finding the best trajectory policy with useful contextual features is too complex for the UAV-BSs. By applying the proposed trained model, an effective real-time trajectory policy for the UAV-BSs captures the observable network states over time. Finally, the simulation results illustrate the proposed approach is 3.6% and 3.13% more energy efficient than those of the greedy and baseline deep Q Network (DQN) approaches.",https://ieeexplore.ieee.org/document/9285214/,IEEE Transactions on Intelligent Transportation Systems,Sept. 2021,ieeexplore
10.1109/TWC.2020.3007804,Deep Learning for Optimal Deployment of UAVs With Visible Light Communications,IEEE,Journals,"In this paper, the problem of dynamical deployment of unmanned aerial vehicles (UAVs) equipped with visible light communication (VLC) capabilities for optimizing the energy efficiency of UAV-enabled networks is studied. In the studied model, the UAVs can simultaneously provide communications and illumination to service ground users. Since ambient illumination increases the interference over VLC links while reducing the illumination threshold of the UAVs, it is necessary to consider the illumination distribution of the target area for UAV deployment optimization. This problem is formulated as an optimization problem which jointly optimizes UAV deployment, user association, and power efficiency while meeting the illumination and communication requirements of users. To solve this problem, an algorithm that combines the machine learning framework of gated recurrent units (GRUs) with convolutional neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the long-term historical illumination distribution and predict the future illumination distribution. Given the prediction of illumination distribution, the original nonconvex optimization problem can be divided into two sub-problems and is then solved using a low-complexity, iterative algorithm. Then, the proposed algorithm enables UAVs to determine the their deployment and user association to minimize the total transmit power. Simulation results using real data from the Earth observations group (EOG) at NOAA/NCEI show that the proposed approach can achieve up to 68.9% reduction in total transmit power compared to a conventional optimal UAV deployment that does not consider the illumination distribution and user association.",https://ieeexplore.ieee.org/document/9140367/,IEEE Transactions on Wireless Communications,Nov. 2020,ieeexplore
10.1109/JSAC.2020.3005495,Deep Reinforcement Learning for Dynamic Uplink/Downlink Resource Allocation in High Mobility 5G HetNet,IEEE,Journals,"Recently, the 5G is widely deployed for supporting communications of high mobility nodes including train, vehicular and unmanned aerial vehicles (UAVs) largely emerged as the main components for constructing the wireless heterogeneous network (HetNet). To further improve the radio utilization, the Time Division Duplex (TDD) is considered to be the potential full-duplex communication technology in the high mobility 5G network. However, the high mobility of users leads to the high dynamic network traffic and unpredicted link state change. A new method to predict the dynamic traffic and channel condition and schedule the TDD configuration in real-time is essential for the high mobility environment. In this paper, we investigate the channel model in the high mobility and heterogeneous network and proposed a novel deep reinforcement learning based intelligent TDD configuration algorithm to dynamically allocate radio resources in an online manner. In the proposal, the deep neural network is employed to extract the features of the complex network information, and the dynamic Q-value iteration based reinforcement learning with experience replay memory mechanism is proposed to adaptively change TDD Up/Down-link ratio by evaluated rewards. The simulation results show that the proposal achieves significant network performance improvement in terms of both network throughput and packet loss rate, comparing with conventional TDD resource allocation algorithms.",https://ieeexplore.ieee.org/document/9127428/,IEEE Journal on Selected Areas in Communications,Dec. 2020,ieeexplore
10.1109/TVT.2019.2947078,Deployment Optimization of UAV Relay for Malfunctioning Base Station: Model-Free Approaches,IEEE,Journals,"Due to the advantages of high mobility, high maneuverability and high probability of line of sight (LoS) transmission, unmanned aerial vehicles (UAVs) have attracted much interest in assisting wireless communication systems. This paper considers a set of ground users cannot receive service from the base station because of a sudden base station malfunction, a UAV is deployed in the air to work as a relay to establish communication links between uncovered users and the neighboring base station. We are going to optimize the UAV relay deployment, aiming to maximize the capacity of the relay network. Considering the channel model and exact positions of ground users are priori unknown, the problem of deployment optimization can't be solved directly because of lacking parameters. Thus, considering multiple detecting UAVs are available and only one is available, model-free online deployment approaches are respectively proposed to solve this challenging problem. The optimal relay deployment is acquired via online learning and iteration without the knowledge of channel model and exact positions of the users but with the real-time measurement of relay capacity, thus the proposed model-free deployment approaches can be adaptive to the practical communication environment compared to the model-based optimization. Simulation results show that with the proposed model-free deployment approaches, relay network capacities are close to the optimum.",https://ieeexplore.ieee.org/document/8867956/,IEEE Transactions on Vehicular Technology,Dec. 2019,ieeexplore
10.1109/COMST.2019.2924143,Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A Comprehensive Survey and Future Directions,IEEE,Journals,"Unmanned aerial vehicles (UAVs) have recently rapidly grown to facilitate a wide range of innovative applications that can fundamentally change the way cyber-physical systems (CPSs) are designed. CPSs are a modern generation of systems with synergic cooperation between computational and physical potentials that can interact with humans through several new mechanisms. The main advantages of using UAVs in CPS application is their exceptional features, including their mobility, dynamism, effortless deployment, adaptive altitude, agility, adjustability, and effective appraisal of real-world functions anytime and anywhere. Furthermore, from the technology perspective, UAVs are predicted to be a vital element of the development of advanced CPSs. Therefore, in this survey, we aim to pinpoint the most fundamental and important design challenges of multi-UAV systems for CPS applications. We highlight key and versatile aspects that span the coverage and tracking of targets and infrastructure objects, energy-efficient navigation, and image analysis using machine learning for fine-grained CPS applications. Key prototypes and testbeds are also investigated to show how these practical technologies can facilitate CPS applications. We present and propose state-of-the-art algorithms to address design challenges with both quantitative and qualitative methods and map these challenges with important CPS applications to draw insightful conclusions on the challenges of each application. Finally, we summarize potential new directions and ideas that could shape future research in these areas.",https://ieeexplore.ieee.org/document/8742658/,IEEE Communications Surveys & Tutorials,Fourthquarter 2019,ieeexplore
10.1109/ACCESS.2021.3076692,Design and Analysis of Lightweight Authentication Protocol for Securing IoD,IEEE,Journals,"The Internet-of-drones (IoD) environment is a layered network control architecture designed to maintain, coordinate, access, and control drones (or Unmanned Aerial vehicles UAVs) and facilitate drones' navigation services. The main entities in IoD are drones, ground station, and external user. Before operationalizing a drone in IoD, a control infrastructure is mandatory for securing its open network channel (Flying Ad Hoc Networks FANETs). An attacker can easily capture data from the available network channel and use it for their own purpose. Its protection is challenging, as it guarantees message integrity, non-repudiation, authenticity, and authorization amongst all the participants. Incredibly, without a robust authentication protocol, the task is sensitive and challenging one to solve. This research focus on the security of the communication path between drone and ground station and solving the noted vulnerabilities like stolen-verifier, privileged-insider attacks, and outdated-data-transmission/design flaws often reported in the current authentication protocols for IoD. We proposed a hash message authentication code/secure hash algorithmic (HMACSHA1) based robust, improved and lightweight authentication protocol for securing IoD. Its security has been verified formally using Random Oracle Model (ROM), ProVerif2.02 and informally using assumptions and pragmatic illustration. The performance evaluation proved that the proposed protocol is lightweight compared to prior protocols and recommended for implementation in the real-world IoD environment.",https://ieeexplore.ieee.org/document/9418994/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2021.3104738,Drone Detection Sensor With Continuous 2.4 GHz ISM Band Coverage Based on Cost-Effective SDR Platform,IEEE,Journals,"The development of Unmanned Aerial Vehicles (UAVs), commonly referred to as drones, has introduced revolutionary changes in many areas over the past few years. However, aside from opening new possibilities, the usage of drones in an irresponsible and dangerous manner leads to many hazardous incidents. This paper presents a drone detection sensor with a continuous 2.400 GHz-2.483 GHz operational frequency range for detection methods based on passive radio frequency imaging techniques. The implementation based on Software Defined Radio (SDR) and Field Programmable Logic Array (FPGA) hardware that overcomes the 40 MHz real-time bandwidth limit of other popular SDRs is presented utilizing low-cost off-the-shelf components. Furthermore, a hardware realization of the signal processing chain for specific detection algorithms is proposed to minimize the throughput between SDR and the companion computer and offload software computations. The device validation is made in a laboratory and real-life scenario and presented in relation to the sensor used in other works. In addition to the increased real-time bandwidth, the measurements show a 9 dB reduction in detection sensitivity compared to the reference receiver, in line with the analog RF front-end specifications. The final analysis demonstrates the proposed device’s relevance as a sensor for obtaining machine learning datasets and as a part of a final anti-drone system.",https://ieeexplore.ieee.org/document/9513316/,IEEE Access,2021,ieeexplore
10.1109/JSTARS.2020.2969809,EmergencyNet: Efficient Aerial Image Classification for Drone-Based Emergency Monitoring Using Atrous Convolutional Feature Fusion,IEEE,Journals,"Deep learning-based algorithms can provide state-of-the-art accuracy for remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones, potentially enhancing their remote sensing capabilities for many emergency response and disaster management applications. In particular, UAVs equipped with camera sensors can operating in remote and difficult to access disaster-stricken areas, analyze the image and alert in the presence of various calamities such as collapsed buildings, flood, or fire in order to faster mitigate their effects on the environment and on human population. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such deep neural networks in many scenarios that impose low-latency constraints on inference, in order to make mission-critical decisions in real time. To this end, this article focuses on the efficient aerial image classification from on-board a UAV for emergency response/monitoring applications. Specifically, a dedicated Aerial Image Database for Emergency Response applications is introduced and a comparative analysis of existing approaches is performed. Through this analysis a lightweight convolutional neural network architecture is proposed, referred to as EmergencyNet, based on atrous convolutions to process multiresolution features and capable of running efficiently on low-power embedded platforms achieving upto 20× higher performance compared to existing models with minimal memory requirements with less than 1% accuracy drop compared to state-of-the-art models.",https://ieeexplore.ieee.org/document/9050881/,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2020,ieeexplore
10.1109/ACCESS.2021.3121905,Evolutionary Coverage Optimization for a Self-Organizing UAV-Based Wireless Communication System,IEEE,Journals,"Self-organized wireless networks based on unmanned aerial vehicles (UAVs) are receiving increasing attention due to their flexible deployment opportunities. Typically, UAVs are used as supplementary access points to existing ground infrastructure to extend network coverage and capacity. Therefore, finding the optimal position for each UAV is a crucial task that can be resolved by multiobjective optimization. In this paper, a self-organizing UAV swarm model is introduced as an evolutionary type of heuristic that can be adjusted in real time based on the network’s key performance indicators (KPIs). The exogenous dynamics of the wireless communication system are reflected by an end-user mobility model based on Ornstein-Uhlenbeck processes. To achieve versatility in the positioning of UAVs, a model of virtual forces is adopted to enable control of the movement of each UAV via a collection of persistent and mutable parameters of the system. Evolution is controlled by eleven strategic versions of parametric mutations, including a neutral benchmark process. The simulation results reveal that the suggested solution allows for a substantial increase in the KPI efficiency metrics relative to those of the nonmutated system. The results also addressed the presence of the Pareto front, where it is not possible to improve the selected KPIs without negatively affecting others. While existing research that focuses on evolutionary methods usually considers offline approaches, this work uses an online evolutionary approach that is able to solve the presented problem by taking the dynamic nature of the environment into account.",https://ieeexplore.ieee.org/document/9583254/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2021.3115711,Implementation of Decentralized Reinforcement Learning-Based Multi-Quadrotor Flocking,IEEE,Journals,"Enabling coordinated motion of multiple quadrotors is an active area of research in the field of small unmanned aerial vehicles (sUAVs). While there are many techniques found in the literature that address the problem, these studies are limited to simulation results and seldom account for wind disturbances. This paper presents the experimental validation of a decentralized planner based on multi-objective reinforcement learning (RL) that achieves waypoint-based flocking (separation, velocity alignment, and cohesion) for multiple quadrotors in the presence of wind gusts. The planner is learned using an object-focused, greatest mass, state-action-reward-state-action (OF-GM-SARSA) approach. The Dryden wind gust model is used to simulate wind gusts during hardware-in-the-loop (HWIL) tests. The hardware and software architecture developed for the multi-quadrotor flocking controller is described in detail. HWIL and outdoor flight tests results show that the trained RL planner can generalize the flocking behaviors learned in training to the real-world flight dynamics of the DJI M100 quadrotor in windy conditions.",https://ieeexplore.ieee.org/document/9548090/,IEEE Access,2021,ieeexplore
10.1109/TSG.2020.2970156,Intelligent Damage Classification and Estimation in Power Distribution Poles Using Unmanned Aerial Vehicles and Convolutional Neural Networks,IEEE,Journals,"Damage estimation is part of daily operation of power utilities, often requiring a manual process of crew deployment and damage report to quantify and locate damages. Advancement in unmanned aerial vehicles (UAVs) as well as real-time communication and learning technologies could be harnessed towards efficient and accurate automation of this process. This paper develops a model to automate the process of estimating and localizing damages in power distribution poles, which utilizes the images taken by UAVs transferred in real-time to an intelligent damage classification and estimation (IDCE) unit. The IDCE unit integrates four convolutional neural networks to learn the states of poles from images, extract the image characteristics, and train an automated intelligent tool to replace manual fault location and damage estimation. The proposed model first determines the type of pole damages, including falling and burning, and then estimates the percentage of damage in each type. The IDCE unit also localizes damages in the poles by locating possible burning or arcing parts. A data set of 1615 images is utilized to train, validate and test the proposed model, which demonstrates high accuracy of the model in classifying and estimating damages in distribution poles.",https://ieeexplore.ieee.org/document/8972612/,IEEE Transactions on Smart Grid,July 2020,ieeexplore
10.1109/TNET.2020.2970744,"Joint Optimization of Relay Deployment, Channel Allocation, and Relay Assignment for UAVs-Aided D2D Networks",IEEE,Journals,"Unmanned aerial vehicles (UAVs) can be deployed in the air to provide high probabilities of line of sight (LoS) transmission, thus UAVs bring much gain for wireless communication systems. In this paper, we study a UAVs-aided self-organized device-to-device (D2D) network. Relay deployment, channel allocation and relay assignment are jointly optimized, aiming to maximize the capacity of the relay network. On account of the coupled relationship between the three optimization variables, an alternating optimization approach is proposed to solve this problem. The original problem is divided into two sub-problems. The first one is that of optimizing the channel allocation and relay assignment with fixed relay deployment. Considering without central controller, a reinforcement learning algorithm is proposed to solve this sub-problem. The second sub-problem is that of optimizing the relay deployment with fixed channel allocation and relay assignment. Assuming no knowledge of channel model and exact positions of the communication nodes, an online learning algorithm based on real-time capacity is proposed to solve this sub-problem. By solving the two sub-problems alternately and iteratively, the original problem is finally solved. Simulation results show that the UAVs-aided D2D network can achieve a high capacity via the joint optimization of relay deployment, channel allocation, and relay assignment.",https://ieeexplore.ieee.org/document/9003500/,IEEE/ACM Transactions on Networking,April 2020,ieeexplore
10.1109/ACCESS.2020.2976686,Large-Scale Synthetic Urban Dataset for Aerial Scene Understanding,IEEE,Journals,"The geometric extraction and semantic understanding in bird's eye view plays an important role in cyber-physical-social systems (CPSS), because it can help human or intelligent agents (IAs) to perceive larger range of environment. Moreover, due to lack of comprehensive dataset from oblique perspective, fog-end deep learning algorithms for this purpose is still in blank. In this paper, we propose a novel method to generate synthetic large-scale dataset for geometric and semantic urban scene understanding from bird's eye view. There are two main steps involved, one is modeling and the other is rendering, which are processed by CityEngine and UnrealEngine4 respectively. In this way, synthetic aligned multi-model data are obtained efficiently, including spectral images, semantic labels, depth and normal maps. Specifically, terrain elevation, street graph, building style and trees distribution are all randomly generated according realistic situation, a few of handcrafted semantic labels annotated by colors spread throughout the scene, virtual cameras moved according to realistic trajectories of unmanned aerial vehicles (UAVs). For evaluation of practicability of our dataset, we manually labeled tens of aerial images downloaded from internet. And the experiment result show that, in both pure and combined mode, the dataset can improve the performance significantly.",https://ieeexplore.ieee.org/document/9015998/,IEEE Access,2020,ieeexplore
10.1109/TVT.2020.2981959,Machine Learning Aided Air Traffic Flow Analysis Based on Aviation Big Data,IEEE,Journals,"Timely and efficient air traffic flow management (ATFM) is a key issue in future dense air traffic. The emerging demands for unmanned aerial vehicles and general aviation aircraft aggravate the burden of the ATFM. Thanks to the advanced automatic dependent surveillance-broadcast (ADS-B) technique, the aerial vehicles can be tracked and monitored in a real-time and accurate manner, providing possibility for establishing a more intelligent ATFM architecture. In this article, we first form an aviation Big Data platform by using the distributed ADS-B ground stations and the obtained ADS-B messages. By exploring the constructed dataset and mapping the extracted information to the routes, the air traffic flow between different cities can be counted and predicted, where the prediction task is implemented on the basis of two machine learning methods, respectively. The experimental results based on real-world data demonstrate that the proposed traffic flow prediction model adopting long short-term memory (LSTM) can achieve better performance, especially when abnormal factors in traffic control are considered.",https://ieeexplore.ieee.org/document/9042360/,IEEE Transactions on Vehicular Technology,May 2020,ieeexplore
10.1109/LRA.2021.3101861,On the Visual-Based Safe Landing of UAVs in Populated Areas: A Crucial Aspect for Urban Deployment,IEEE,Journals,"Autonomous landing of Unmanned Aerial Vehicles (UAVs) in crowded scenarios is crucial for successful deployment of UAVs in populated areas, particularly in emergency landing situations where the highest priority is to avoid hurting people. In this work, a new visual-based algorithm for identifying Safe Landing Zones (SLZ) in crowded scenarios is proposed, considering a camera mounted on a UAV, where the people in the scene move with unknown dynamics. To do so, a density map is generated for each image frame using a Deep Neural Network, from where a binary occupancy map is obtained aiming to overestimate the people's location for security reasons. Then, the occupancy map is projected to the head's plane, and the SLZ candidates are obtained as circular regions with a minimum security radius, within the head's plane. Finally, to keep track of the SLZ candidates, a multiple instance tracking algorithm is implemented using Kalman Filters along with the Hungarian algorithm for data association. Several scenarios were studied to prove the validity of the proposed strategy, including public datasets and real uncontrolled scenarios with people moving in public squares, taken from a UAV in flight. The study showed promising results in the search of preventing the UAV from hurting people during emergency landing.",https://ieeexplore.ieee.org/document/9507275/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TVT.2019.2945037,On-Board Deep Q-Network for UAV-Assisted Online Power Transfer and Data Collection,IEEE,Journals,"Unmanned Aerial Vehicles (UAVs) with Microwave Power Transfer (MPT) capability provide a practical means to deploy a large number of wireless powered sensing devices into areas with no access to persistent power supplies. The UAV can charge the sensing devices remotely and harvest their data. A key challenge is online MPT and data collection in the presence of on-board control of a UAV (e.g., patrolling velocity) for preventing battery drainage and data queue overflow of the devices, while up-to-date knowledge on battery level and data queue of the devices is not available at the UAV. In this paper, an on-board deep Q-network is developed to minimize the overall data packet loss of the sensing devices, by optimally deciding the device to be charged and interrogated for data collection, and the instantaneous patrolling velocity of the UAV. Specifically, we formulate a Markov Decision Process (MDP) with the states of battery level and data queue length of devices, channel conditions, and waypoints given the trajectory of the UAV; and solve it optimally with Q-learning. Furthermore, we propose the on-board deep Q-network that enlarges the state space of the MDP, and a deep reinforcement learning based scheduling algorithm that asymptotically derives the optimal solution online, even when the UAV has only outdated knowledge on the MDP states. Numerical results demonstrate that our deep reinforcement learning algorithm reduces the packet loss by at least 69.2%, as compared to existing non-learning greedy algorithms.",https://ieeexplore.ieee.org/document/8854903/,IEEE Transactions on Vehicular Technology,Dec. 2019,ieeexplore
10.1109/TVT.2020.3047800,Three-Dimension Trajectory Design for Multi-UAV Wireless Network With Deep Reinforcement Learning,IEEE,Journals,"The effective trajectory design of multiple unmanned aerial vehicles (UAVs) is investigated for improving the capacity of the communication system. The aim is for maximizing real-time downlink capacity under the coverage constraint by reaping the mobility benefits of UAVs. The problem of three-dimension (3D) dynamic movement of UAVs under coverage constraint is formulated as a Constrained Markov Decision Process (CMDP) problem, while a constrained Deep Q-Network (cDQN) algorithm is proposed for solving the formulated problem. In the proposed cDQN model, each UAV acts as an agent to explore and learn its 3D deploying policy. The aim of the proposed cDQN model is for obtaining the maximum capacity while attempting to guarantee that all ground terminals (GTs) are covered. In order to satisfy the coverage constraint, a primal-dual method is adopted for training primal variable and dual variable (lagrangian multiplier) in turn. Furthermore, in an effort to reduce the action space of the cDQN algorithm, prior information is utilized for eliminating the invalid actions by the action filter. Experiment results demonstrate that the cDQN algorithm is capable of converging after some training steps. Additionally, the UAVs are capable of adapting the movement of GTs under the coverage constraint according to the 3D deploying policy derived from the proposed cDQN algorithm.",https://ieeexplore.ieee.org/document/9310353/,IEEE Transactions on Vehicular Technology,Jan. 2021,ieeexplore
10.1109/TMECH.2016.2614672,Type-2 Fuzzy Logic Trajectory Tracking Control of Quadrotor VTOL Aircraft With Elliptic Membership Functions,IEEE,Journals,"Emerging applications of quadrotor vertical take-off and landing (VTOL) unmanned aerial vehicles in various fields have created a need for demanding controllers that are able to counter several challenges, inter alia, nonlinearity, underactuated dynamics, lack of modeling, and uncertainties in the working environment. This study compares and contrasts type-1 and type-2 fuzzy neural networks (T2FNNs) for the trajectory tracking problem of quadrotor VTOL aircraft in terms of their tracking accuracy and control efforts. A realistic trajectory consisting of both straight lines and curvatures for a surveillance operation with minimum snap property, which is feasible regarding input constraints of the quadrotor, is generated to evaluate the proposed controllers. In order to imitate the outdoor noisy and time-varying working conditions, realistic uncertainties, such as wind and gust disturbances, are fed to the real-time experiment in the laboratory environment. Furthermore, a cost function based on the integral of the square of the sliding surface, which gives the optimal parameter update rules, is used to train the consequent part parameters of the T2FNN. Thanks to the learning capability of the proposed controllers, experimental results show the efficiency and efficacy of the learning algorithms that the proposed T2FNN-based controller with the optimal tuning algorithm is 50% superior to a conventional proportional-derivative (PD) controller in terms of control accuracy but requires more control effort. T2FNN structures are also shown to possess better noise reduction property as compared to their type-1 counterparts in the presence of unmodeled noise and disturbances.",https://ieeexplore.ieee.org/document/7580570/,IEEE/ASME Transactions on Mechatronics,Feb. 2017,ieeexplore
10.1109/JMASS.2021.3083659,UAV-Based Real-Time Survivor Detection System in Post-Disaster Search and Rescue Operations,IEEE,Journals,"When a natural disaster occurs, the most critical task is to search and rescue trapped people as soon as possible. In recent years, unmanned aerial vehicles (UAVs) have been widely employed because of their high durability, low cost, ease of implementation, and flexibility. In this article, we collected a new thermal image dataset captured by drones. After that, we used several different deep convolutional neural networks to train survivor detection models on our dataset, including YOLOV3, YOLOV3-MobileNetV1, and YOLOV3- MobileNetV3. Due to the limited computing power and memory of the onboard microcomputer, to balance the inference time and accuracy, we found the optimal points to prune and fine-tune the survivor detection network based on the sensitivity of the convolutional layer. We verified it on NVIDIA’s Jetson TX2 and achieved a real-time performance of 26.60 frames/s (FPS). Moreover, we designed a real-time survivor detection system based on DJI Matrice 210 and Manifold 2-G to provide search and rescue services after the disaster.",https://ieeexplore.ieee.org/document/9440534/,IEEE Journal on Miniaturization for Air and Space Systems,Dec. 2021,ieeexplore
