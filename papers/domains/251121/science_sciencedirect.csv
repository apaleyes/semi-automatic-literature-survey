id,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1016/j.resconrec.2021.106022,Journal,"Resources, Conservation and Recycling",scopus,2022-03-01,sciencedirect,Using computer vision to recognize composition of construction waste mixtures: A semantic segmentation approach,https://api.elsevier.com/content/abstract/scopus_id/85118570774,"Timely and accurate recognition of construction waste (CW) composition can provide yardstick information for its subsequent management (e.g., segregation, determining proper disposal destination). Increasingly, smart technologies such as computer vision (CV), robotics, and artificial intelligence (AI) are deployed to automate waste composition recognition. Existing studies focus on individual waste objects in well-controlled environments, but do not consider the complexity of the real-life scenarios. This research takes the challenges of the mixture and clutter nature of CW as a departure point and attempts to automate CW composition recognition by using CV technologies. Firstly, meticulous data collection, cleansing, and annotation efforts are made to create a high-quality CW dataset comprising 5,366 images. Then, a state-of-the-art CV semantic segmentation technique, DeepLabv3+, is introduced to develop a CW segmentation model. Finally, several training hyperparameters are tested via orthogonal experiments to calibrate the model performance. The proposed approach achieved a mean Intersection over Union (mIoU) of 0.56 in segmenting nine types of materials/objects with a time performance of 0.51 s per image. The approach was found to be robust to variation of illumination and vehicle types. The study contributes to the important problem of material composition recognition, formalizing a deep learning-based semantic segmentation approach for CW composition recognition in complex environments. It paves the way for better CW management, particularly in engaging robotics, in the future. The trained models are hosted on GitHub, based on which researchers can further finetune for their specific applications.",science
10.1016/j.ymssp.2021.108284,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-15,sciencedirect,Real-time model calibration with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85112506465,"The real-time, and accurate inference of model parameters is of great importance in many scientific and engineering disciplines that use computational models (such as a digital twin) for the analysis and prediction of complex physical processes. However, fast and accurate inference for processes of complex systems cannot easily be achieved in real-time with state-of-the-art methods under noisy real-world conditions with the requirement of a real-time response. The primary reason is that the inference of model parameters with traditional techniques based on optimization or sampling often suffers from computational and statistical challenges, resulting in a trade-off between accuracy and deployment time. In this paper, we propose a novel framework for inference of model parameters based on reinforcement learning. The proposed methodology is demonstrated and evaluated on two different physics-based models of turbofan engines. The experimental results demonstrate that the proposed methodology outperforms all other tested methods in terms of speed and robustness, with high inference accuracy.",science
10.1016/j.jep.2021.114812,Journal,Journal of Ethnopharmacology,scopus,2022-02-10,sciencedirect,Bai-Hu-Tang regulates endothelin-1 and its signalling pathway in vascular endothelial cells,https://api.elsevier.com/content/abstract/scopus_id/85118924464,"Ethnopharmacological relevance
                  Bai-Hu-Tang (BHT) is traditionally used to treat human and animal fever syndrome with four symptoms: large and vigorous pulse, large thirst, high sweat, and high heat.
               
                  Aim of the study
                  To investigate the mechanism of vasodilation regulation of Bai-Hu-Tang in primary vascular endothelial cells stimulated by lipopolysaccharide (LPS).
               
                  Materials and methods
                  A hydrophilic concentrate of BHT was prepared, and the main components of mangiferin and timosaponin BⅡ were determined by HLPC analysis. The rabbit fever model was constructed by intravenous injection of LPS (15 μg/kg body weight), and BHT was gavaged to treat febrile rabbits. After treatment for 6 h, animal peripheral blood was collected, and serum was isolated for endothelin-1 (ET-1) and nitric oxide (NO) assays. Rabbit vascular endothelial cells (RVECs) were isolated and stimulated with 1 μg/mL LPS, and then inflammatory cells were treated with 125 or 250 μg/mL BHT for 24 h. The supernatant cytokines TNF-ɑ, IL-1β, IL-6, and ET-1 were detected by ELISA kits. Gene expression levels of endothelin receptor type B (ETB receptor) were analysed by real-time polymerase chain reaction (RT-PCR), and protein expression levels of PI3K and Akt were detected by Western blot. A nitrite assay was used to measure intracellular nitric oxide (NO) production, and nitric oxide synthase (NOS) was measured by the T-NOS colorimetric method.
               
                  Results
                  Animal experiments demonstrated that BHT significantly restored ET-1 and NO in animal peripheral blood, which were disordered in LPS-induced fever rabbits. Moreover, a cytotoxicity assay demonstrated that BHT ≤700 μg/mL is innoxious to RVECs. BHT significantly repressed cellular TNF-α, IL-1β, and ET-1, which were originally elevated by LPS in RVECs. Meanwhile, BHT elevated the gene expression level of the ETB receptor and promoted NOS and NO production in RVECs induced by LPS.
               
                  Conclusion
                  BHT can inhibit excessive ET-1 secretion induced by LPS in vascular endothelial cells and activate the classic ET-1 signalling pathway to promote NO production, which may facilitate vasodilation of smooth muscle cells.",science
10.1016/j.ces.2021.117205,Journal,Chemical Engineering Science,scopus,2022-02-02,sciencedirect,"Developments of leak detection, diagnostics, and prediction algorithms in multiphase flows",https://api.elsevier.com/content/abstract/scopus_id/85118896502,"Leak detection, diagnostics, and prediction constitute a crucial phase of the flow assurance risk management process for onshore and offshore pipelines. There are a variety of techniques and algorithms that can be deployed to address each aspect. To date, most review papers have concentrated on steady-state and single-phase flow conditions. The goal of the current review is therefore to carry out a thorough analysis of the available leak detection and diagnosis methods by focusing on (i) multiphase flow and transient flow conditions, (ii) model-based and data-driven techniques, (iii) prediction tools, and (iv) performance measures. Detailed assessment of leak detection methods based on accuracy, complexity, data requirement, and cost of installation are discussed. Data-driven techniques are utterly dependent on qualitative and quantitative data available from pipeline systems. Contrastingly data-driven techniques, model-based techniques require less data to achieve leak detection, provided that a nearly accurate base model is available. Different methodologies and technologies can be combined in order to produce the best detection and diagnosis outputs. In many cases, statistical analysis was combined with the Real Time Transient Method (RTTM), which helped to minimize false alarms. The material in this review can be used as a robust guide for the design of diagnostic systems and further research.",science
10.1016/j.saa.2021.120347,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2022-01-15,sciencedirect,Rapid discrimination of Curcuma longa and Curcuma xanthorrhiza using Direct Analysis in Real Time Mass Spectrometry and Near Infrared Spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85115004546,"This study describes a newly developed method for the fast and straightforward differentiation of two turmeric species using Direct Analysis in Real Time mass spectrometry and miniaturized Near Infrared spectroscopy. Multivariate analyses (PCA and LDA) were performed on the mass spectrometric data, thus creating a powerful model for the discrimination of Curcumalonga and Curcumaxanthorrhiza. Cross-validation of the model revealed correctness-scores of 100% with 20-fold as well as leave-one-out validation techniques. To further estimate the models prediction power, seven retail samples of turmeric powder were analyzed and assorted to a species. Looking for a fast, non-invasive, cost-efficient and laboratory independent method, miniaturized NIR spectrometers offer an alternative for quality control of turmeric species. However, different technologies implemented to compensate for their small size, lead to different applicability of these spectrometers. Therefore, we investigated the three handheld spectrometers microPHAZIR, MicroNIR 2200 and MicroNIR 1700ES for their application in spice analysis in hyphenation to PCA, LDA and ANN methods used for the discriminant analysis. While microPHAZIR proved to be the most valuable device for differentiating C.longa and C.xanthorrhiza, MicroNIR 1700ES offered the worst results. These findings are interpreted on the basis of a quantum chemical simulation of the NIR spectrum of curcumin as the representative constituent. It was found that the information accessible to MicroNIR 1700ES that is relevant to the analyzed constituents is located in the spectral region prone to interferences with the matrix, likely limiting the performance of this spectrometer in this analytical scenario.",science
10.1016/j.cageo.2021.104968,Journal,Computers and Geosciences,scopus,2022-01-01,sciencedirect,Seismic fault detection using convolutional neural networks with focal loss,https://api.elsevier.com/content/abstract/scopus_id/85118727682,"Fault detection is a fundamental and important research topic in automatic seismic interpretation since the geometry of faults usually reveals the accumulation and migration of geological resource. In the communities of machine learning, many methods convert the fault detection task into a patch-based binary classification problem to solve. Because there are only a few faults in seismic data, the related classification task is obviously imbalanced, i.e., non-fault samples heavily outnumber fault samples. On considering that the existing CNN models just transform the problem into a balanced two-class task via undersampling, in this paper we attempt to construct CNNs directly from the imbalanced patch data with the assistance of transfer learning. In particular, we use focal loss to robustly learn fault feature representations for both fault and non-fault patches. With the aim to make full use of available data, we adopt transfer learning to enhance the recognition ability of relatively complex patches. The experiments conducted with both synthetic and real seismic data (some slices of the Netherland offshore F3 block in the North Sea) show that the novel method performs very well in detecting faults in seismic data. In supplemental material, the features extracted by the CNNs are visualized for both fault and non-fault patches to get some insights for their good performance.",science
10.1016/j.neunet.2021.10.002,Journal,Neural Networks,scopus,2022-01-01,sciencedirect,Probabilistic generative modeling and reinforcement learning extract the intrinsic features of animal behavior,https://api.elsevier.com/content/abstract/scopus_id/85118333957,"It is one of the ultimate goals of ethology to understand the generative process of animal behavior, and the ability to reproduce and control behavior is an important step in this field. However, it is not easy to achieve this goal in systems with complex and stochastic dynamics such as animal behavior. In this study, we have shown that MDN–RNN,a type of probabilistic deep generative model, is able to reproduce stochastic animal behavior with high accuracy by modeling the behavior of C. elegans. Furthermore, we found that the model learns different dynamics in a disentangled representation as a time-evolving Gaussian mixture. Finally, by combining the model and reinforcement learning, we were able to extract a behavioral policy of goal-directed behavior in silico, and showed that it can be used for regulating the behavior of real animals. This set of methods will be applicable not only to animal behavior but also to broader areas such as neuroscience and robotics.",science
10.1016/j.commatsci.2021.110883,Journal,Computational Materials Science,scopus,2022-01-01,sciencedirect,Uncertainty bounds for multivariate machine learning predictions on high-strain brittle fracture,https://api.elsevier.com/content/abstract/scopus_id/85116258208,"Simulation of the crack network evolution on high strain rate impact experiments performed in brittle materials is very compute-intensive. The cost increases even more if multiple simulations are needed to account for the randomness in crack length, location, and orientation, which is inherently found in real-world materials. Constructing a machine learning emulator can make the process faster by orders of magnitude. There has been little work, however, on assessing the error associated with their predictions. Estimating these errors is imperative for meaningful overall uncertainty quantification. In this work, we extend the heteroscedastic uncertainty estimates to bound a multiple output machine learning emulator. We find that the response prediction is accurate within its predicted errors, but with a somewhat conservative estimate of uncertainty.",science
10.1016/j.postharvbio.2021.111741,Journal,Postharvest Biology and Technology,scopus,2022-01-01,sciencedirect,Multi-output 1-dimensional convolutional neural networks for simultaneous prediction of different traits of fruit based on near-infrared spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85115232057,"In spectral data predictive modelling of fresh fruit, often the models are calibrated to predict multiple responses. A common method to deal with such a multi-response predictive modelling is the partial least-squares (PLS2) regression. Recently, deep learning (DL) has shown to outperform partial least-squares (PLS) approaches for single fruit traits prediction. The DL can also be adapted to perform multi-response modelling. This study presents an implementation of DL modelling for multi-response prediction for spectral data of fresh fruit. To show this, a real NIR data set related to SSC and MC measurements in pear fruit was used. Since DL models perform better with larger data sets, a data augmentation procedure was performed prior to data modelling. Furthermore, a comparative study was also performed between two of the most used DL architectures for spectral analysis, their multi-output and single-output variants and a classic baseline model using PLS2. A key point to note that all the DL modelling presented in this study is performed using novel automated optimisation tools such as Bayesian optimisation and Hyperband. The results showed that DL models can be easily adapted by changing the output of the fully connected layers to perform multi-response modelling. In comparison to the PLS2, the multi-response DL model showed ∼13 % lower root mean squared error (RMSE), showing the ease and superiority of handling multi-response by DL models for spectral calibration.",science
10.1016/j.chb.2021.106994,Journal,Computers in Human Behavior,scopus,2022-01-01,sciencedirect,Neural and self-reported responses to antisocial news stories: Entertaining versus traditional news introduction,https://api.elsevier.com/content/abstract/scopus_id/85114195266,"Recently, as entertainment programs have become more prevalent in the news media, there is a growing need to understand how entertainment appeal influences viewers' sociomoral evaluation of news content. We investigated neural and self-reported moral evaluation of antisocial news content in college students who viewed real-life news reports featuring moral violations inside a functional magnetic resonance imaging (fMRI) brain scanner. Each news report was preceded by a traditional or entertaining style of introduction. The behavioral results showed that antisocial severity was reduced for antisocial news content that was presented following entertaining news introductions versus traditional news introductions. The fMRI results showed that entertainment news introductions tax more cognitive control resources than traditional news introductions during news processing, as indicated by greater activation in the dorsolateral prefrontal region; however, they diminish moral saliency, as suggested by the reduced activation in the medial prefrontal region. We also found that greater dorsolateral prefrontal activation during the early phase of news reports was associated with more lenient moral acceptability ratings in the entertainment condition. Furthermore, reduced functional connectivity of the mentalizing brain network was observed in the entertainment condition when compared with the traditional condition. These results suggest that entertainment appeal may increase resource depletion, diminish moral sensitivity, and reduce functional integration of relevant social information during news processing, thus hindering viewers' moral scrutiny. This novel study contributes to a better understanding of how entertainment features influence viewers’ sociomoral evaluation of news stories.",science
10.1016/j.chemosphere.2021.131593,Journal,Chemosphere,scopus,2022-01-01,sciencedirect,An in vitro assessment for human skin exposure to parabens using magnetic solid phase extraction coupled with HPLC,https://api.elsevier.com/content/abstract/scopus_id/85110360228,"Skin contact was a significant source of human exposure to parabens during the use of personal care products. In this study, a novel and simple in vitro evaluation method for human skin exposure to parabens was established for the first time. Firstly, magnetic porous carbon (MPC) derived from discarded cigarette butts was prepared as an adsorbent of magnetic solid-phase extraction (MSPE), which provided a fast and efficient sample preparation method with satisfactory extraction performance for parabens in cosmetics and was easy to couple with high performance liquid chromatography. Secondly, the extraction conditions were optimized including the etching ratio of KOH, amount of MPC, extraction time, pH, salt concentration, desorption solvent volume and desorption time. Under the optimized conditions, the limits of detection were between 0.25 and 0.34 ng mL−1 and the spiked recoveries were in the range of 85.8–112.6%. Thirdly, the developed method was successfully employed to determine five typical parabens in real unspiked cosmetic samples, and two parabens were detected at a relatively high level. Then, the developed method was applied to in vitro assays. The absorbable dose of parabens in cream was investigated and in vitro experiments were further designed with agarose-simulated skin to demonstrate the penetration ability of parabens. In conclusion, these results indicated that parabens did have the risk of entering the body through the skin and the exposure was preferably no more than 3 h with skin contact.",science
10.1016/j.is.2021.101771,Journal,Information Systems,scopus,2022-01-01,sciencedirect,Bot2Vec: A general approach of intra-community oriented representation learning for bot detection in different types of social networks,https://api.elsevier.com/content/abstract/scopus_id/85103499630,"Recently, due to the rapid growth of online social networks (OSNs) such as Facebook, Twitter, Weibo, etc. the number of machine accounts/social bots that mimic human users has increased. Along with the development of artificial intelligence (AI), social bots are designed to become smarter and more sophisticated in their efforts at replicating the normal behaviors of human accounts. Constructing reliable and effective bot detection mechanisms is this considered crucial to keep OSNs clean and safe for users. Despite the rapid development of social bot detection platforms, recent state-of-the-art systems still encounter challenges which are related to the model’s generalization (and whether it can be adaptable for multiple types of OSNs) as well as the great efforts needed for feature engineering. In this paper, we propose a novel approach of applying network representation learning (NRL) to bot/spammer detection, called Bot2Vec. Our proposed Bot2Vec model is designed to automatically preserve both local neighborhood relations and the intra-community structure of user nodes while learning the representation of given OSNs, without using any extra features based on the user’s profile. By applying the intra-community random walk strategy, Bot2Vec promises to achieve better user node embedding outputs than recent state-of-the-art network embedding baselines for bot detection tasks. Extensive experiments on two different types of real-word social networks (Twitter and Tagged) demonstrate the effectiveness of our proposed model. The source code for implementing the Bot2Vec model is available at: https://github.com/phamtheanhphu/bot2vec",science
10.1016/j.jclepro.2021.129629,Journal,Journal of Cleaner Production,scopus,2021-12-20,sciencedirect,Performance prediction of suspension freeze crystallization for the treatment of liquid hazardous wastes via machine learning methods,https://api.elsevier.com/content/abstract/scopus_id/85119036691,"The experimental method for determining treatment efficiency of suspension freeze crystallization (SFC) on liquid hazardous wastes (LHWs) is accurate but complex, costly and time-consuming. In the present study, artificial neural works (ANN) and random forest (RF), two machine learning methods, were utilized to develop models that were capable of predicting the treatment performance of SFC based on 8 typical LHWs. The targeted solutes in the chosen LHWs were characterized by COD, TOC, TDS, sulfide, conductivity, etc. The models were induced and tested to predict solute removal efficiency in accordance with freezing conditions and solution characteristics of 328 pieces of data collected from previous publications. Although both models have comparable predictive power, RF model presented better prediction accuracy and power (R
                     2 = 0.9811, RMSE = 0.0323) than ANN model (R
                     2 = 0.9615, RMSE = 0.0481). At the same time, the RF models showed better generalization ability than ANN models regardless different LHWs. The variable importance measurement indicated that ice phase fraction was the most important factor for solute removal efficiency in SFC process. The accurate predictability of developed models could be used before actual experiment to predict the removal efficiency of SFC according to various independent variables, so as to significantly reduce experiment workload of searching for the optimum freezing conditions. The variable importance measurement could provide a right direction for adjust the higher treatment efficiency of SFC on LHWs in the real situation.",science
10.1016/j.oceaneng.2021.110180,Journal,Ocean Engineering,scopus,2021-12-15,sciencedirect,An enhanced intelligent model: To protect marine IoT sensor environment using ensemble machine learning approach,https://api.elsevier.com/content/abstract/scopus_id/85119059082,"The research in marine sensors and the Internet of Things (IoT) has grown exponentially with the ample warehouse of natural materials in the sea. The growing activities in the marine sensor environment increased the threat of anomalies and cyber-attacks. Many Intrusion Detection Systems (IDS) and classical machine learning-based models have been proposed to secure the sensor-based IoT infrastructure. Still, these mechanisms have failed to achieve significant results for securing the marine sensor environment due to the discriminant requirements of the IoT appliances in deep oceans, such as distribution, information complexity, scalability, higher network bandwidth requirements, and low computational capacity. Hence, we propose a lightweight and robust ensemble model to secure the marine IoT environment from cyber-attacks and malicious activities. This paper established an optimized Light Gradient Boosting Machine (Light-GBM) algorithm for ocean IoT attack detection. The experiments were conducted on Distributed Smart Space Orchestration System (DS2OS) dataset. The proposed methodology includes a label encoding technique for best feature selection, hyper-parameter tuning, ensemble function, and a novel algorithm to develop an ocean IoT attack detection model. As an extension of traditional methods, the optimized Light-GBM model can handle the distributed IoT attacks in the deeper marine environments with low computational cost and with 98.52% detection accuracy. The comparative analysis confirms the effectiveness of the proposed model for marine sensor safety. Conclusively, the proposed model mitigates the threat of cyber-attacks in the marine sensor environment and presenting a promising future in real-time ocean-based IoT applications.",science
10.1016/j.cma.2021.114128,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2021-12-15,sciencedirect,Latent map Gaussian processes for mixed variable metamodeling,https://api.elsevier.com/content/abstract/scopus_id/85116044771,"Gaussian processes (GPs) are ubiquitously used in sciences and engineering as metamodels. Standard GPs, however, can only handle numerical or quantitative variables. In this paper, we introduce latent map Gaussian processes (LMGPs) that inherit the attractive properties of GPs and are also applicable to mixed data which have both quantitative and qualitative inputs. The core idea behind LMGPs is to learn a continuous, low-dimensional latent space or manifold which encodes all qualitative inputs. To learn this manifold, we first assign a unique prior vector representation to each combination of qualitative inputs. We then use a low-rank linear map to project these priors on a manifold that characterizes the posterior representations. As the posteriors are quantitative, they can be directly used in any standard correlation function such as the Gaussian or Matern. Hence, the optimal map and the corresponding manifold, along with other hyperparameters of the correlation function, can be systematically learned via maximum likelihood estimation. Through a wide range of analytic and real-world examples, we demonstrate the advantages of LMGPs over state-of-the-art methods in terms of accuracy and versatility. In particular, we show that LMGPs can handle variable-length inputs, have an explainable neural network interpretation, and provide insights into how qualitative inputs affect the response or interact with each other. We also employ LMGPs in Bayesian optimization and illustrate that they can discover optimal compound compositions more efficiently than conventional methods that convert compositions to qualitative variables via manual featurization.",science
10.1016/j.apenergy.2021.117770,Journal,Applied Energy,scopus,2021-12-15,sciencedirect,Cloud and machine learning experiments applied to the energy management in a microgrid cluster,https://api.elsevier.com/content/abstract/scopus_id/85114311209,"The way to organize the generation, storage, and management of renewable energy and energy consumption features has taken relevance in recent years due to demands that define the social welfare of this century. Like demand increases, other factors require grid infrastructure improvement, updates, and opening to other technologies that assuage the final customer needs. Precisely, the interest in renewable energy sources, the constant evolution of energy storage technologies, the continuous research involving microgrid management systems, and the evolution of cloud computing technologies and machine learning strategies motivate the development of this article. Tasks associated with a microgrid cluster like the integration of a considerable number of heterogeneous devices, real-time support, information processing, massive storage capabilities, security considerations, and advanced optimization techniques usage could take place in an autonomous and scalable energy management system architecture under a machine learning perspective running in real-time and using Cloud resources. This paper focuses on identifying the elements considered by different authors to define a cloud-based architecture and ensure the appropriately supervised learning functionality under a microgrids cluster environment. Namely, it was necessary to revise and run microgrid simulations, real-time simulation platforms usage, connection to a virtual server for microgrid control and set the energy management system using cloud computing and machine learning. Based on the review and considering the scenarios mentioned, this article presents a scalable and autonomous cloud-based architecture that allows power generation forecast, energy consumption prediction, a real-time energy management system using machine learning techniques.",science
10.1016/j.jep.2021.114514,Journal,Journal of Ethnopharmacology,scopus,2021-12-05,sciencedirect,Total flavonoids of Taraxacum mongolicum inhibit non-small cell lung cancer by regulating immune function,https://api.elsevier.com/content/abstract/scopus_id/85112690875,"Ethnopharmacological relevance
                  
                     Taraxacum mongolicum Hand.-Mazz. has been used in lung cancer treatment in Chinese medicine. However, its specific mechanism of action has not yet been reported, and developing pharmaceutical anti-cancer resources is important. Here, we aimed to elucidate the anti-tumor effects of dandelion in vitro and in vivo and assess its effects on immune function in lung cancer patients.
               
                  Aim of the study
                  In the present study, we mainly observed the therapeutic effects of total flavonoids from Taraxacum mongolicum Hand.-Mazz. (TFTM) on non-small cell lung cancer and its influence on the body's immune function.
               
                  Materials and methods
                  
                     In vitro experiments on A549 and H1299 cells were performed using the CCK8 method; the proliferation and migration of cells were observed to investigate the wound healing effects of TFTM, and flow cytometry was used to detect the apoptotic rate of TFTM on lung cancer cells. In vivo experiments were preformed to establish a non-small cell lung cancer mouse model using subcutaneously transplanted Lewis cells, and the body weight and tumor growth of the mice were recorded. Hematoxylin and eosin staining was performed for tumor tissue to assess pathological changes. The thymus, spleen, and lungs were isolated for to calculate organ index. The CD4+, CD8+, and CD4+/CD8+ levels were detected in mouse spleen using flow cytometry, and IL-2, IL-3, IFN-γ, and TNF-α levels were determined in serum using enzyme-linked immunosorbent assay. Expressions of IL-2, IL-3, IFN-γ, and TNF-α were detected using quantitative real-time PCR in tumor tissues, and Ki67 expression was observed by immunofluorescence.
               
                  Results
                  At 24 h, TFTM (100 and 200 μg/mL) had the best inhibitory effect on the proliferation of A549 and H1299 cells. The cell migration rate significantly reduced (P < 0.01), and the tumor inhibition rate increased (P < 0.01) and promoted apoptosis (P < 0.01). The mouse thymus index significantly increased (P < 0.05) and mouse spleen index reduced (P < 0.05). The CD4+, CD8+, and CD4+/CD8+ levels in Lewis lung cancer mouse model increased, as did the levels of IL-2, IL-3, IFN-γ, and TNF-α in the serum and tumor of mice; Ki67 expression in tumor tissues significantly reduced (P < 0.01).
               
                  Conclusion
                  TFTM has an inhibitory effect on lung cancer. The mechanism may be that it improves the host's protective immune response by having a milder tumor growth inhibitory effect than cyclophosphamide.",science
10.1016/j.neunet.2021.09.026,Journal,Neural Networks,scopus,2021-12-01,sciencedirect,TACN: A Topical Adversarial Capsule Network for textual network embedding,https://api.elsevier.com/content/abstract/scopus_id/85117410798,"Combining topological information and attributed information of nodes in networks effectively is a valuable task in network embedding. Nevertheless, many prior network embedding methods regarded attributed information of nodes as simple attribute sets or ignored them totally. In some scenarios, the hidden information contained in vertex attributes are essential to network embedding. For instance, networks that contain vertexes with text information play an increasingly important role in our life, including citation networks, social networks, and entry networks. In these textual networks, the latent topic relevance information of different vertexes contained in textual attributes information are valuable in the network analysis process. Shared latent topics of nodes in networks may influence the interaction between them, which is critical to network embedding. However, much prior work for textual network embedding only regarded the text information as simple word sets while ignored the embedded topic information. In this paper, we develop a model named Topical Adversarial Capsule Network (TACN) for textual network embedding, which extracts a low-dimensional latent space of the original network from node structures, vertex attributes, and topic information contained in text of nodes. The proposed TACN contains three parts. The first part is an embedding model, which extracts the embedding representation from the topological structure, vertex attributes, and document-topic distributions. To ensure a consistent training process by back-propagation, we generate document-topic distributions by the neural topic model with Gaussian Softmax constructions. The second part is a prediction model, which is used to exploit labels of vertices. In the third part, an adversarial capsule model is used to help distinguish the latent representations from node structure domain, vertex attribute domain, or document-topic distribution domain. The latent representations, which may come from the three domains, are the output of the embedding model. We incorporate the adversarial idea into the adversarial capsule model to combine the information from these three domains, rather than to distinguish the representations conventionally. Experiments on seven real-world datasets validate the effectiveness of our method.",science
10.1016/j.cie.2021.107733,Journal,Computers and Industrial Engineering,scopus,2021-12-01,sciencedirect,SiteForge: Detecting and localizing forged images on microblogging platforms using deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85117254237,"Microblogging applications are currently used to disseminate information with concise text and images. Nevertheless, they are also the largest platform for circulating forged images. Forged images are digital photographs that have been modified to deceive or distort the information they communicate. These manipulated images posted on microblogging apps like Twitter often create biased user emotions leading to harmful consequences like religious feuds or riots. Microblogging platforms and fact-checking industry are investing in artificial intelligence solutions to detect these forged images on time. Many image forensic techniques are proposed earlier, but their effectiveness falls short on real-world images shared over microblogging sites. As forged images shared over these platforms are typically altered using multiple manipulation techniques, it is hard for forensic techniques to detect them. This paper proposes a customized convolutional neural network with an attention mechanism to spot fake images shared over microblogging platforms. Deep learning convolutional networks learn the intrinsic feature set of images and can detect the forged images. To handle multiple manipulations in an image, the applied attention mechanism focuses on the most relevant image region to learn the inherent feature sets. The model utilizes High-pass filters from the image processing domain to initialize kernel weights of the neural network. This supports the proposed model to converge faster and achieve better accuracy. The pooling layers are designed to specifically handle images from microblogging sites. The solution is universal and can detect complex tampering scenarios like text-editing, face-swapping, copy-move, splicing and mirroring. Local Interpretable Model-agnostic Explanations (LIME) is utilized to localize the manipulated region in a forged image. LIME also adds interpretability and confidence to the proposed model, a common concern in deep learning models. The model is verified against the publicly available CASIA 2.0 dataset. An accuracy score of 94.7% is achieved, which is better than the previous state-of-art papers in fake image detection. In order to test the model on real-world images published on Twitter, a recent dataset is built from an Indian viewpoint. The model achieves a modest accuracy of 83.2% over the real-world Twitter dataset. The experiment proves that the proposed model can accurately detect the forged images over social platforms. It can be utilized in the fact-checking field to improve manual efforts. It will also support manual fact-checkers in swift decision making.",science
10.1016/j.jneumeth.2021.109371,Journal,Journal of Neuroscience Methods,scopus,2021-12-01,sciencedirect,Development of deep learning models for microglia analyses in brain tissue using DeePathology™ STUDIO,https://api.elsevier.com/content/abstract/scopus_id/85116054792,"Background
                  Interest in artificial intelligence-driven analysis of medical images has seen a steep increase in recent years. Thus, our paper aims to promote and facilitate the use of this state-of-the-art technology to fellow researchers and clinicians.
               
                  New method
                  We present custom deep learning models generated in DeePathology™ STUDIO without the need for background knowledge in deep learning and computer science underlined by practical suggestions.
               
                  Results
                  We describe the general workflow in this commercially available software and present three real-world examples how to detect microglia on IBA1-stained mouse brain sections including their differences, validation results and analysis of a sample slide.
               
                  Comparison with existing methods
                  Deep-learning assisted analysis of histological images is faster than classical analysis methods, and offers a wide variety of detection possibilities that are not available using methods based on staining intensity.
               
                  Conclusions
                  Reduced researcher bias, increased speed and extended possibilities make deep-learning assisted analysis of histological images superior to traditional analysis methods for histological images.",science
10.1016/j.ins.2021.09.049,Journal,Information Sciences,scopus,2021-12-01,sciencedirect,Multi-task learning for spatial events prediction from social data,https://api.elsevier.com/content/abstract/scopus_id/85116010017,"Multi-task learning is becoming more popular and is being applied in a variety of applications. It improves the accuracy of prediction by simultaneously learning related tasks and saves cost through shared structures. In particular, the prediction of event type from social data is also an area where multi-task learning can be utilized. In this paper, we present a novel deep learning framework called 
                        S
                     patial 
                        E
                     vents 
                        P
                     rediction (SEP) based on multi-task learning to predict the types of events that happen at a specific location from social data. The proposed model focuses on predicting the attribute types of an event, which is referred to as subtypes. Specifically, an event type-specific attention mechanism is introduced to extract the representations of social data and to identify their important components. The proposed attention mechanism is based on a two-level attention, which measures the importance of words and sentences to the subtypes of an event. We also propose a representation sharing method using semantic and spatial relationships between locations to alleviate the sparsity and incompleteness of data. The proposed representation sharing preserves the spatial heterogeneity between locations and significantly improves the accuracy of the overall framework. Experiments with real-world datasets confirm the effectiveness and efficiency of the proposed method.",science
10.1016/j.cma.2021.114121,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2021-12-01,sciencedirect,A virtual model architecture for engineering structures with Twin Extended Support Vector Regression (T-X-SVR) method,https://api.elsevier.com/content/abstract/scopus_id/85114715295,"A machine learning aided virtual model architecture framework is presented. With great computational stability and preserved convexity features, the Twin Extended Support Vector Regression (T-X-SVR) method is adopted to imitate the underpinned and sophisticated constitutive relationship between the systematic inputs and outcomes in real-world applications. Various numerical simulations can be implemented on the virtual model with greatly reduced computational costs. The multi-type information from heterogeneous sources and multifarious engineering applications are supported by the proposed framework. For the virtual model aided numerical analysis with the multi-type information, fuzzy-valued probabilistic distributional characteristics of the bounds of the concerned structural responses are estimated. The capability of the modularity feature of the virtual model improves the operational flexibility which makes the implementation of such advance technique more user friendly. To demonstrate the applicability and computational efficiency of the proposed framework, three practical engineering stimulated problems (i.e., the mechanical dynamic system, multiphysics with heat transfer and gas flow interaction, and the expansion process of a biomedical stent with both material and geometry nonlinearities), involving multi-type information (i.e., random parameters and fuzzy sets), are fully investigated through the proposed virtual model architecture framework.",science
10.1016/j.jenvman.2021.113594,Journal,Journal of Environmental Management,scopus,2021-12-01,sciencedirect,A hybrid computational intelligence approach for bioremediation of amoxicillin based on fungus activities from soil resources and aflatoxin B1 controls,https://api.elsevier.com/content/abstract/scopus_id/85113717787,"Nowadays, releasing the Emerging Pollutants (EPs) in the nature is one of the main reasons for many health and environmental disasters. Amoxicillin as an antibiotic is one of the EPs and categorized as the Endocrine Disrupting Compounds (EDCs) in hazardous materials. Accumulation of amoxicillin in the soil bulk increases the cancer risk, drug resistances and other epidemiological diseases. Hence, the soil bioremediation of antibiotics can be a solution for this problem which is more environmental-friendly system. This study technically creates a bio-engine setup in soil bulk for remediation of amoxicillin based on Aspergillus Flavus (AF) activities and Removal Percentage (RP) of amoxicillin with Aflatoxin B1 Generation (AG) controls. The main novelty is to propose a hybrid computational intelligence approach to do optimization for mechanical and biological aspects and to predict the behavior of bio-engine's effective mechanical and biological features in an intelligent way. The optimization model is formulated by the Central Composite Design (CCD) which is set by the Response Surface Methodology (RSM). The prediction model is formulated by the Random Forest (RF), Adaptive Neuro Fuzzy Inference System (ANFIS) and Random Tree (RT) algorithms. According to the experimental practices from real soil samples in different times and places, concentration of amoxicillin and Aflatoxin B1 are set equal to 25 mg/L (ppm) and 15 μg/L (ppb). Likewise, the outcomes of experiments in CCD-RSM computations are evaluated by curve fitting comparisons between linear, 2FI, quadratic and cubic polynomial equations with considering to regression coefficient and predicted regression coefficient values, ANOVA and optimization by sequential differentiation. Based on the results of CCD-RSM, the RP performance in the optimum conditions is measured around 86% and in 25 days after runtime, the RP and AG are balanced in the safe mode. The proposed hybrid model achieves the 0.99 accuracy. The applicability of the research is done using real field evaluations from drug industrial park in Mashhad city in Iran. Finally, a broad analysis is done and managerial insights are concluded. The main findings of the present research are: (I) with application of bioremediation from fungus activities, amoxicillin amounts can be control in soil resources with minimum AG, (II) ANFIS model has the best accuracy for smart monitoring of amoxicillin bioremediation in soil environments and (III) based on the statistical assessments Aeration Intensity and AF/Biological Waste ratio are most effective on the amoxicillin removal percentage.",science
10.1016/j.talanta.2021.122780,Journal,Talanta,scopus,2021-12-01,sciencedirect,A real-world approach to identifying animal bones and Lower Pleistocene fossils by laser induced breakdown spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85111807121,"Archaeological sites often contain accumulations of remains derived from different independent events produced by different agents. Thus, in Palaeolithic sites, it is normal to find alternating occupations between humans and carnivores. The faunal assemblages at these sites usually include hundreds or thousands of bone fragments, which are very difficult to associate them to specific individuals since there are no currently available techniques able to do it in a straightforward and cost-effective way. In this work we present a methodology that allows us to characterise the anatomical remains of a bone accumulation and relate them all back to the specific individuals to which they belong. In order to provide a real world application, we have used a selection of animal bones from different individuals belonging to deer and sheep (fed in a controlled way using the same diet). On the other hand, fossilized faunal remains have also been analysed to verify if these fossilized bones keep some of the fingerprinting of the animal from which they come from. For this purpose, we have developed a protocol using Laser Induced Breakdown Spectroscopy (LIBS) together with Neural Networks (NN) implemented here to discriminate and reassemble deer and sheep bones from different individuals, which we subsequently applied for these proposes to fossilized material. To the best of our knowledge, this is the first time that this technique has been applied for individual fingerprinting to actuality and fossil samples. The elemental composition of bones provides enough information to get a correct discrimination of different individuals. The spectral correlation has exceeded 95 %. and all individuals were correctly classified to the individual from which they come from. There have been no instances of false positives or false negatives in our tests or applications.",science
10.1016/j.rcim.2021.102183,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-12-01,sciencedirect,Autonomous nondestructive evaluation of resistance spot welded joints,https://api.elsevier.com/content/abstract/scopus_id/85110261037,"The application of non-destructive evaluation approaches has attracted strong interests in modern automotive industries. This study presents an autonomous deep-computing framework to analyze raw videos from infrared systems and to predict weld nugget shape and size with unprecedented accuracy and speed. In a comprehensive training and testing experiment with 90 videos (seven sets of welding material stack-ups), a new method was developed to assemble sufficient datasets for neural network training. Our framework successfully predicts all the nugget shapes with F1 scores that range from 0.84 to 0.92. The total training time on Nvidia DGX station takes less than 10 min for each set of welding material stack-up. The real inference time of an individual dataset (with 30 video frames) takes about 0.005 s. The procedure and methods developed in the study can be applied to other image-based weld property prediction, as well as other manufacturing processes. Furthermore, our well-trained neural networks take limited memory resources (2.3 MB) and are suitable for embedded microprocessors for in-situ welding quality control as edge computing within an intelligent welding framework.",science
10.1016/j.eswa.2021.115412,Journal,Expert Systems with Applications,scopus,2021-12-01,sciencedirect,AMFB: Attention based multimodal Factorized Bilinear Pooling for multimodal Fake News Detection,https://api.elsevier.com/content/abstract/scopus_id/85109215869,"Fake news is the information or stories that are intentionally created to deceive or mislead the readers. In recent times, Fake news detection has attracted the attention of researchers and practitioners due to its many-fold benefits, including bringing in preventive measures to tackle the dissemination of misinformation that could otherwise disturb the social fabrics. Social media in recent times are heavily loaded with multimedia news and information. People prefer online news reading and find it more informative and convenient if they have access to multimedia content in the forms of text, images, audio, and videos. In early studies, researchers have proposed several fake news detection mechanisms that mostly utilize the textual features and not proper to learn multimodal (textual + visual) shared representation.
                  To overcome these limitations, in this paper, we propose a multimodal fake news detection framework with appropriate multimodal feature fusion that leverages information from text and image and tries to maximize the correlation between them to get the efficient multimodal shared representation. We empirically show that text, when combined with the image, can improve the performance of the model. The model detects the post once it is introduced into the network in an early stage. At the early stage of a news post’s introduction into the network, the model takes the text and image of the post as input and decides whether this is fake or genuine. Since this model only analyzes news contents, It does not require any prior information regarding the user and network details. This framework has four different sub-modules viz. 
                     Attention Based Stacked Bidirectional Long Short Term Memory (ABS-BiLSTM) for textual feature representation, Attention Based Multilevel Convolutional Neural Network–Recurrent Neural Network (ABM-CNN–RNN) for visual feature extraction, multimodal Factorized Bilinear Pooling (MFB) for feature fusion and finally Multi-Layer Perceptron (MLP) for the classification. We perform experiments on two publicly available datasets, viz. Twitter and Weibo. Evaluation results show the efficacy of our proposed approach that performs significantly better compared to the state-of-the-art models. It shows to outperform the current state-of-the-art by approximately 10 points for the Twitter dataset. In contrast, the Weibo dataset achieves an overall better performance with balanced F1-scores between fake and real classes. Furthermore, the complexity of our proposed model is significantly lower than the state-of-the-art.",science
10.1016/j.petrol.2021.109151,Journal,Journal of Petroleum Science and Engineering,scopus,2021-12-01,sciencedirect,3D reconstruction of digital cores based on a model using generative adversarial networks and variational auto-encoders,https://api.elsevier.com/content/abstract/scopus_id/85108868168,"The digitalization of cores, namely the reconstruction of digital cores, is a method to reflect the real internal structures of cores by reconstructing the microstructural information and describing the microstructure of cores on the pore scale, which has become an effective way of quantitatively analyzing the pore structures and other matters in cores for rock physics and petroleum science. The modeling method of digital cores can be divided into the physical experimental methods and numerical simulation methods. Physical experimental methods usually are time-consuming and expensive because the drilling and core sampling for physical experiments are quite costly and the manufacturing of experimental samples sometimes are difficult to implement. Without the complex physical preparation and the demands for expensive equipment, numerical simulation methods are relatively cost-effective but still suffer from a lengthy processing time. Recently, deep learning and its variants can effectively extract characteristics from training images (TIs), casting light on the fast reconstruction of digital cores. In this paper, a reconstruction method is proposed by combining the variational auto-encoder (VAE) and the generative adversarial network (GAN) to achieve the balance of their strengths and weaknesses. Besides, the learning diverse generations using determinantal point processes (GDPP) is added to improve the quality of the generated results. Compared to some numerical simulation methods and GAN, the effectiveness and practicability of the proposed method are demonstrated.",science
10.1016/j.neucom.2021.08.073,Journal,Neurocomputing,scopus,2021-11-13,sciencedirect,Balanced distortion and perception in single-image super-resolution based on optimal transport in wavelet domain,https://api.elsevier.com/content/abstract/scopus_id/85114383530,"Single image super-resolution (SISR) is a classic ill-posed problem in computer vision. In recent years, deep-learning-based (DL-based) models have achieved promising results with the SISR problem. However, most existing methods suffer from an intrinsic trade-off between distortion and perceptual quality. To satisfy the requirements in different real-world situations, the balance of distortion and visual quality for image super-resolution is a critical issue. In DL-based models, the uses of hybrid loss (i.e., the combination of the distortion loss and the perceptual loss) and network interpolation are two common approaches to balancing the distortion and perceptual quality of super-resolved images. However, these two kinds of methods lack flexibility and hold strict constraints on network architectures. In this paper, we propose an image-fusion interpolation method for image super-resolution, which can balance the distortion and visual quality of super-resolved images, based on the optimal transport theory in the wavelet domain. The advantage of our proposed method is that it can be applied to any pretrained DL-based model, without any requirement from the network architecture and parameters. In addition, our proposed method is parameter-free and can run fast without using a GPU. Compared with existing state-of-the-art SISR methods, experiment results show that our proposed method can achieve a better balance between the distortion and visual quality in super-resolved images.",science
10.1016/j.elerap.2021.101105,Journal,Electronic Commerce Research and Applications,scopus,2021-11-01,sciencedirect,∊-k anonymization and adversarial training of graph neural networks for privacy preservation in social networks,https://api.elsevier.com/content/abstract/scopus_id/85118865252,"With the explosive growth of social networks, privacy preservation as a social good has been one common concern. Graph neural networks (GNNs) have been utilized by social network service providers to improve business service. However, traditional anonymization techniques of social networks cannot satisfy the desired privacy preservation of node attribute and graph structure and introduce information disturbance from the anonymization, leading to the performance degradation of GNNs in social network analysis. To protect sensitive user data and persist GNNs’ performance in social network analysis, we propose a two-stage privacy-preserving method of graph neural networks in the social network domain. During the first stage, we design a novel 
                        ∊
                     -
                        k
                      anonymization method that can achieve 
                        ∊
                     -local differential privacy (
                        ∊
                     -LDP) and 
                        k
                     -degree anonymity by incorporating the classical LDP and 
                        k
                     -degree anonymization (
                        k
                     -DA) while retaining as much network community information as possible. At the second stage, we develop an adversarial training mechanism for GNNs to resist the disturbance from 
                        ∊
                     -
                        k
                      anonymization and retain as much task performance as possible on anonymous social network data. Comprehensive experiments on several real-world social network datasets demonstrate the effectiveness of the proposed method for privacy-preserving node classification, link prediction, and graph clustering in social networks. The proposed method represents an interesting and important combination of classical anonymous technologies and recent GNNs and can preserve user privacy while providing business service.",science
10.1016/j.ins.2021.08.086,Journal,Information Sciences,scopus,2021-11-01,sciencedirect,Multi-view group representation learning for location-aware group recommendation,https://api.elsevier.com/content/abstract/scopus_id/85118764349,"With the development of location-based services (LBS), many location-based social sites like Foursquare and Plancast have emerged. People can organize and participate in group activities on those sites. Therefore, recommending venues for group activities is of practical value. However, the group decision making process is complicated, requiring trade-offs among group members. And the data sparsity and cold-start problems make it difficult to make effective group recommendation. In this manuscript, we propose a Multi-view Group Representation Learning (MGPL) framework for location-aware group recommendation. The proposed multi-view group representation learning framework can leverage multiple types of information for deep representation learning of group preferences and incorporate the spatial attributes of locations to further capture the group mobility preferences. Experiments on two real datasets Foursqaure and Plancast show that our method significantly outperforms the-state-of-art approaches.",science
10.1016/j.livsci.2021.104700,Journal,Livestock Science,scopus,2021-11-01,sciencedirect,A review of deep learning algorithms for computer vision systems in livestock,https://api.elsevier.com/content/abstract/scopus_id/85118744270,"In livestock operations, systematically monitoring animal body weight, biometric body measurements, animal behavior, feed bunk, and other difficult-to-measure phenotypes is manually unfeasible due to labor, costs, and animal stress. Applications of computer vision are growing in importance in livestock systems due to their ability to generate real-time, non-invasive, and accurate animal-level information. However, the development of a computer vision system requires sophisticated statistical and computational approaches for efficient data management and appropriate data mining, as it involves massive datasets. This article aims to provide an overview of how deep learning has been implemented in computer vision systems used in livestock, and how such implementation can be an effective tool to predict animal phenotypes and to accelerate the development of predictive modeling for precise management decisions. First, we reviewed the most recent milestones achieved with computer vision systems and the respective deep learning algorithms implemented in Animal Science studies. Then, we reviewed the published research studies in Animal Science which used deep learning algorithms as the primary analytical strategy for image classification, object detection, object segmentation, and feature extraction. The great number of reviewed articles published in the last few years demonstrates the high interest and rapid development of deep learning algorithms in computer vision systems across livestock species. Deep learning algorithms for computer vision systems, such as Mask R-CNN, Faster R-CNN, YOLO (v3 and v4), DeepLab v3, U-Net and others have been used in Animal Science research studies. Additionally, network architectures such as ResNet, Inception, Xception, and VGG16 have been implemented in several studies across livestock species. The great performance of these deep learning algorithms suggests an improved predictive ability in livestock applications and a faster inference. However, only a few articles fully described the deep learning algorithms and their implementation. Thus, information regarding hyperparameter tuning, pre-trained weights, deep learning backbone, and hierarchical data structure were missing. We summarized peer-reviewed articles by computer vision tasks (image classification, object detection, and object segmentation), deep learning algorithms, animal species, and phenotypes including animal identification and behavior, feed intake, animal body weight, and many others. Understanding the principles of computer vision and the algorithms used for each application is crucial to develop efficient systems in livestock operations. Such development will potentially have a major impact on the livestock industry by predicting real-time and accurate phenotypes, which could be used in the future to improve farm management decisions, breeding programs through high-throughput phenotyping, and optimized data-driven interventions.",science
10.1016/j.earscirev.2021.103828,Journal,Earth-Science Reviews,scopus,2021-11-01,sciencedirect,"Spatiotemporal forecasting in earth system science: Methods, uncertainties, predictability and future directions",https://api.elsevier.com/content/abstract/scopus_id/85116626560,"Spatiotemporal forecasting (STF) extends traditional time series forecasting or spatial interpolation problem to space and time dimensions. Here, we review the statistical, physical and artificial intelligence (AI) methods, data and model uncertainties, predictability and future directions for STF problems. Statistical STF methods have limitations in high-level feature extractions and long-term memory modeling. Physical models are computationally intensive and are imperfect in model structure and parameterization. AI models lack the interpretability and require elaborate training but can model complex nonlinear and non-Gaussian problems. Integrating data-driven and physical model-driven methods could facilitate the improvement of interpretability and forecasting accuracy. The predictive uncertainty comes from data and models, which could be measured by probability distribution and Bayesian inference, respectively. The predictive uncertainty is generally missing in AI models and could be resolved by incorporating Bayesian frameworks. The predictability of dynamic earth systems is spatiotemporally heterogeneous and is generally examined by diagnostic and prognostic approaches. Diagnostic methods analyze the predictability empirically from a theoretical perspective, while prognostic methods investigate the predictability through real experiments. Unraveling the predictability in space and time and the predictability sources will greatly improve earth system understanding and operational forecasting development. Current STF systems are largely not user-friendly to provide probabilistic and understandable forecasting services in near real-time. Intelligent STF systems should automatically prepare various data sources, train the models in a self-adaptative way and provide timely predictive information services for users to make decisions. This review provides state-of-the-art advances in forecasting sciences and highlights new directions for new-generation STF systems.",science
10.1016/j.precisioneng.2021.08.010,Journal,Precision Engineering,scopus,2021-11-01,sciencedirect,A method for predicting hobbing tool wear based on CNC real-time monitoring data and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85112751582,"Intelligent monitoring and diagnosis of tool status are of great significance for improving the manufacturing efficiency and accuracy of the workpiece. It is difficult to quickly and accurately predict the wear state of worm gear hob under different working conditions. This paper proposes a novel approach to predict hob wear status based on CNC real-time monitoring data. Based on the open platform communication unified architecture (OPC UA) technology and orthogonal test, the machine data of motor power, current, etc. related to tool wear are collected online in the worm gear machining process. And then, an improved deep belief network (DBN) is used to generate a tool wear model by training data. A growing DBN with transfer learning is introduced to automatically decide its best model structure, which can accelerate its learning process, improve training efficiency and model performance. The experiment results show that the proposed method can effectively predict hob wear status under multi-cutting conditions. To show the advantages of the proposed approach, the performance of the DBN is compared with the traditional back propagation neural network (BP) method in terms of the mean-squared error (MSE). The compared results show that this tool wear prediction method has better prediction accuracy than the traditional BP method during worm gear hobbing.",science
10.1016/j.asoc.2021.107792,Journal,Applied Soft Computing,scopus,2021-11-01,sciencedirect,Sentiment classification using attention mechanism and bidirectional long short-term memory network,https://api.elsevier.com/content/abstract/scopus_id/85112745936,"We propose a sentiment classification method for large scale microblog text based on the attention mechanism and the bidirectional long short-term memory network (SC-ABiLSTM). We use an experimental study to compare our proposed method with baseline methods using real world large-scale microblog data. Comparing the accuracy of the baseline methods to the accuracy of our model, we demonstrate the efficacy of our proposed method. While sentiment classification of social media data has been extensively studied, the main novelty of our study is the implementation of the attention mechanism in a deep learning network for analyzing large scale social media data.",science
10.1016/j.ipm.2021.102712,Journal,Information Processing and Management,scopus,2021-11-01,sciencedirect,Temporally evolving graph neural network for fake news detection,https://api.elsevier.com/content/abstract/scopus_id/85112744798,"The proliferation of fake news on social media has the probability to bring an unfavorable impact on public opinion and social development. Many efforts have been paid to develop effective detection and intervention algorithms in recent years. Most of the existing propagation-based fake news detection methods focus on static networks and assume the whole information propagation network structure is accessible before performing learning algorithms. However, in real-world information diffusion networks, new nodes and edges constantly emerge. Therefore, in this paper, we introduce a novel temporal propagation-based fake news detection framework, which could fuse structure, content semantics, and temporal information. In particular, our model can model temporal evolution patterns of real-world news as the graph evolving under the setting of continuous-time dynamic diffusion networks. We conduct extensive experiments on large-scale real-world datasets and the experimental results demonstrate that our proposed model outperforms state-of-the-art fake news detection methods.",science
10.1016/j.cose.2021.102421,Journal,Computers and Security,scopus,2021-11-01,sciencedirect,An efficient multistage phishing website detection model based on the CASE feature framework: Aiming at the real web environment,https://api.elsevier.com/content/abstract/scopus_id/85112018738,"Phishing has become a favorite method of hackers for committing data theft and continues to evolve. As long as phishing websites continue to operate, many more people and companies will suffer privacy leaks or financial losses. Therefore, the demand for fast and accurate phishing website detection grows stronger. However, the existing phishing detection methods do not fully analyze the features of phishing, and the performance and efficiency of the models only apply to certain limited datasets and need to be improved to be applied to the real web environment. This paper fully considers the social engineering principles of phishing, proposes a comprehensive and interpretable CASE feature framework and designs a multistage phishing detection model to effectively detect phishing sites, especially in the real web environment, where high efficiency and performance and extremely low false alarm rates are required. To fully verify the proposed method, two kinds of data experiments were carried out. One was the comparative experiments among different features and different detection models on CASE, which covers both classic machine learning and deep learning algorithms based on a constructed complex dataset. The other was a one-year phishing discovery experiment in the real web environment. The proposed method achieves better detection results under the premise of significantly shortening the execution time and works well in real phishing discovery, which proves its high practicability in reality.",science
10.1016/j.talanta.2021.122608,Journal,Talanta,scopus,2021-11-01,sciencedirect,"PIXE based, Machine-Learning (PIXEL) supported workflow for glass fragments classification",https://api.elsevier.com/content/abstract/scopus_id/85109431731,"This paper presents a structured workflow for glass fragment analysis based on a combination of Elemental Analysis using PIXE and Machine Learning tools, with the ultimate goal of standardizing and helping forensic efforts. The proposed workflow was implemented on glass fragments received from the Israeli DIFS (Israeli Police Force's Division of Identification and Forensic Sciences) that were collected from various vehicles, including glass fragments from different manufacturers and years of production. We demonstrate that this workflow can produce models with high (>80%) accuracy in identifying glass fragment's origins and provide a test-case demonstrating how the model can be applied in real-life forensic events. We provide a standard, reproducible methodology that can be used in many forensic domains beyond glass fragments, for example, Gun Shot Residue, flammable liquids, illegal substances, and more.",science
10.1016/j.aohep.2021.100339,Journal,Annals of Hepatology,scopus,2021-11-01,sciencedirect,HGF/c-Met regulates p22<sup>phox</sup> subunit of the NADPH oxidase complex in primary mouse hepatocytes by transcriptional and post-translational mechanisms,https://api.elsevier.com/content/abstract/scopus_id/85103360130,"Introduction and objectives
                  It is well-known that signaling mediated by the hepatocyte growth factor (HGF) and its receptor c-Met in the liver is involved in the control of cellular redox status and oxidative stress, particularly through its ability to induce hepatoprotective gene expression by activating survival pathways in hepatocytes. It has been reported that HGF can regulate the expression of some members of the NADPH oxidase family in liver cells, particularly the catalytic subunits and p22phox. In the present work we were focused to characterize the mechanism of regulation of p22phox by HGF and its receptor c-Met in primary mouse hepatocytes as a key determinant for cellular redox regulation.
               
                  Materials and methods
                  Primary mouse hepatocytes were treated with HGF (50 ng/mL) at different times. cyba expression (gene encoding p22phox) or protein content were addressed by real time RT-PCR, Western blot or immunofluorescence. Protein interactions were explored by immunoprecipitation and FRET analysis.
               
                  Results
                  Our results provided mechanistic information supporting the transcriptional repression of cyba induced by HGF in a mechanism dependent of NF-κB activity. We identified a post-translational regulation mechanism directed by p22phox degradation by proteasome 26S, and a second mechanism mediated by p22phox sequestration by c-Met in plasma membrane.
               
                  Conclusion
                  Our data clearly show that HGF/c-Met exerts regulation of the NADPH oxidase by a wide-range of molecular mechanisms. NADPH oxidase-derived reactive oxygen species regulated by HGF/c-Met represents one of the main mechanisms of signal transduction elicited by this growth factor.",science
10.1016/j.dss.2021.113523,Journal,Decision Support Systems,scopus,2021-11-01,sciencedirect,Spline-rule ensemble classifiers with structured sparsity regularization for interpretable customer churn modeling,https://api.elsevier.com/content/abstract/scopus_id/85101404963,"An important business domain that relies heavily on advanced statistical- and machine learning algorithms to support operational decision-making is customer retention management. Customer churn prediction is a crucial tool to support customer retention. It allows an early identification of customers who are at risk to abandon the company and provides the ability to gain insights into why customers are at risk. Hence, customer churn prediction models should complement predictive performance with model insights. Inspired by their ability to reconcile strong predictive performance and interpretability, this study introduces rule ensembles and their extension, spline-rule ensembles, as a promising family of classification algorithms to the customer churn prediction domain. Spline-rule ensembles combine the flexibility of a tree-based ensemble classifier with the simplicity of regression analysis. They do, however, neglect the relatedness between potentially conflicting model components which can introduce unnecessary complexity in the models and compromises model interpretability. To tackle this issue, a novel algorithmic extension, spline-rule ensembles with sparse group lasso regularization (SRE-SGL) is proposed to enhance interpretability through structured regularization. Experiments on fourteen real-world customer churn data sets in different industries (i) demonstrate the superior predictive performance of spline-rule ensembles with sparse group lasso over a set well yet powerful benchmark methods in terms of AUC and top decile lift; (ii) show that spline-rule ensembles with sparse group lasso regularization significantly outperform conventional rule ensembles whilst performing at least as well as conventional spline-rule ensembles; and (iii) illustrate the interpretable nature of a spline-rule ensemble model and the advantage of structured regularization in SRE-SGL by means of a case study on customer churn prediction for a telecommunications company.",science
10.1016/j.jhlste.2020.100275,Journal,"Journal of Hospitality, Leisure, Sport and Tourism Education",scopus,2021-11-01,sciencedirect,Industry 4.0 technologies in tourism education: Nurturing students to think with technology,https://api.elsevier.com/content/abstract/scopus_id/85092173436,"The Industry 4.0 revolution is bringing major transformations in the tourism systems design suitable for technologically oriented consumers. Indeed, methods and technologies introduced by Big Data, Automation, Virtual and augmented reality, Robotics and ICT well fit with the Tourism 4.0 paradigm. However, tourism students are not yet trained on techniques, issues and methods related to the Industry 4.0 framework.
                  Hence, relying on a careful examination of the literature on tourism market trends linked to the offer of innovative technological services, we identified conceptual, methodological, technological and practical skills to be developed in an academic curriculum for Tourism Science students. Learning path were focused on: i) processes of data acquisition from social media, ii) data analysis using Machine Learning techniques and iii) data design into significant elements useful to implement communication systems in the tourism field.
               
                  Results
                  showed that the most of participants achieved a medium-high evaluation for the implementation of the communication systems, applying appropriately techniques and tools learned along the course. Furthermore, the high percentage of students satisfaction registered in relation to the course, revealed that students enjoyed this experience. Outcomes reflects the acquisition and the awareness of those skills that will enable students to be conscious protagonists of their role in tourism 4.0.",science
10.1016/j.neucom.2021.07.063,Journal,Neurocomputing,scopus,2021-10-28,sciencedirect,Leveraging graph neural networks for point-of-interest recommendations,https://api.elsevier.com/content/abstract/scopus_id/85111963513,"Point-of-Interest (POI) recommendation, i.e., suggesting POIs that a user is likely to visit, is a key task to improve user experience in location based social networks (LBSNs). Existing models either focus on geographical influence without considering other factors such as social influence and temporal influence or rely on linear methods to combine different modeling factors, lacking a sophisticated and systematical way to learn representations for users and POIs for recommendation. To remedy these issues, in this work we propose GNN-POI, a generic POI recommendation framework that leverages Graph Neural Networks (GNNs), which demonstrate powerful modeling capacity to learn node representations from node information and topological structure to improve POI recommendation. Specifically, we construct a LBSN graph comprising of two types of nodes, i.e., user node and POI node. For a target user, her preference representation is learned by combining (1) representations of her social connection nodes and (2) representations of the visited POI nodes. For social connection nodes integration, in order to model the complicated and multifaceted social influence, an attention mechanism is applied to learn strengths of heterogeneous social relations; for location nodes integration, we utilize Bi-directional Long Short-Term Memory (Bi-LSTM) to model users’ sequential check-in behavior, taking into account geographical and temporal features. Extensive experiments conducted over three real LBSN datasets show that the proposed GNN based framework significantly outperforms the state-of-the-art POI recommendation models in terms of precision, recall and Normalized Discounted Cumulative Gain (NDCG).",science
10.1016/j.neucom.2021.07.045,Journal,Neurocomputing,scopus,2021-10-21,sciencedirect,Pruning and quantization for deep neural network acceleration: A survey,https://api.elsevier.com/content/abstract/scopus_id/85112651139,"Deep neural networks have been applied in many applications exhibiting extraordinary abilities in the field of computer vision. However, complex network architectures challenge efficient real-time deployment and require significant computation resources and energy costs. These challenges can be overcome through optimizations such as network compression. Network compression can often be realized with little loss of accuracy. In some cases accuracy may even improve. This paper provides a survey on two types of network compression: pruning and quantization. Pruning can be categorized as static if it is performed offline or dynamic if it is performed at run-time. We compare pruning techniques and describe criteria used to remove redundant computations. We discuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise, layer-wise and even network-wise pruning. Quantization reduces computations by reducing the precision of the datatype. Weights, biases, and activations may be quantized typically to 8-bit integers although lower bit width implementations are also discussed including binary neural networks. Both pruning and quantization can be used independently or combined. We compare current techniques, analyze their strengths and weaknesses, present compressed network accuracy results on a number of frameworks, and provide practical guidance for compressing networks.",science
10.1016/j.colsurfa.2021.127171,Journal,Colloids and Surfaces A: Physicochemical and Engineering Aspects,scopus,2021-10-20,sciencedirect,Methylene blue adsorption from an aqueous solution by a magnetic graphene oxide/humic acid composite,https://api.elsevier.com/content/abstract/scopus_id/85111111830,"A novel adsorbent called magnetic humic acid/graphene oxide composite (MHAGO) adsorbent was prepared for treating methylene blue (MB) from wastewater. The structure and morphology of MHAGO were characterized by FTIR, XRD, SEM and XPS. The response surface method was used to optimize the quality feeding ratio for the raw materials, and the best graphene oxide: humic acid: ferroferric oxide feeding ratio was determined to be 0.25:0.50:1.66. Batch adsorption experiments were performed with variation in the initial MB dye concentration, pH of the solution, adsorbent dosage and contact time. The results showed that the adsorption reaction occurred at 45 °C with 30 mg adsorbent to adsorb 5.0 mg/L MB in 100 mL solution, with a maximum MB adsorption capacity of approximately 59.00 mg/g for MHAGO. The adsorption kinetics and adsorption isotherms were found to be in accordance with the Elovich equation and Langmuir model, respectively. Moreover, the thermodynamic parameters showed that the adsorption is spontaneously endothermic. The mechanisms for MB adsorption onto the MHAGO surface was mainly electrostatic attraction, π-π interaction and hydrogen bonding. In addition, the MHAGO shows good feasibility for the removal of pollutants from real factory dyeing wastewater.",science
10.1016/j.engstruct.2021.112877,Journal,Engineering Structures,scopus,2021-10-15,sciencedirect,Prediction of fire resistance of concrete encased steel composite columns using artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85111330781,"Concrete encased steel (CES) columns, also known as steel reinforced concrete (SRC) composite columns, exhibit superior fire resistance due to concrete acting as a protection layer for the embedded steel section. While modern design codes have provided design guides for the fire resistance of CES columns, they are only applicable to those made of normal strength concrete. For high strength CES columns, advanced analysis is needed to capture the brittleness of high strength concrete at elevated temperature. In this paper, two methods, namely the artificial neural network (ANN) and the analytical equations, are proposed to predict the fire resistance of axially-loaded CES columns made of high strength concrete. To train the ANN, a finite difference model is developed to compute the temperature field in CES columns and it is used to establish a database containing 15,200 specimens. The cross-sectional dimensions and materials grades of the specimens are carefully selected to cover a wide range of values including those commonly adopted in real-life applications. The inputs of the ANN are identified through an extensive parametric analysis. The selected ANN consists of 7 inputs, 3 outputs and 2 hidden layers and achieves a high determination coefficient R2 value of 0.999. For practical implementation, analytical equations are also derived and achieve high R2 values above 0.953. The predictive power of the ANN and the analytical equations are examined against the observations obtained from actual fire tests, showing reasonable accuracy of prediction. Both methods are simple, of high accuracy and have implicitly accounted for temperature-dependent material degradation, and hence do not require input of temperature-dependent material properties and advanced analysis software.",science
10.1016/j.jenvman.2021.113199,Journal,Journal of Environmental Management,scopus,2021-10-15,sciencedirect,Microbiologically induced calcite precipitation technology for mineralizing lead and cadmium in landfill leachate,https://api.elsevier.com/content/abstract/scopus_id/85109830278,"As a new bioremediation technology for toxic metals, microbiologically induced calcite precipitation (MICP) is gradually becoming a research focus. This study investigated the application of MICP to mineralize toxic metals (lead and cadmium) in landfill leachate for the first time. In the experiment of remediating synthetic landfill leachate (SLL) contaminated by Pb2+, 100% of the 20 mg/L Pb2+ was removed when the maximum urease activity was only 20.96 U/ml. Scanning electron microscopy and energy dispersive spectroscopy (SEM-EDS) and laser particle size characterizations of the precipitates indicate the formation of agglomerated square particles, 76.9% of which had sizes that ranged from 33.93 to 57.06 μm. Fourier transform infrared spectroscopic and X-ray diffraction analyses confirmed that the precipitates consisted predominantly of calcite crystals, and the unit cell lattice constants of the precipitates (a = b = 4.984 Å, c = 17.171 Å) matched those of calcite, while lead was fixed as hydrocerussite. In addition, the Pb-MICP precipitates were stable under continuous acid degradation (pH = 5.5), and only 1.76% of the lead was released after 15 days. In the verification test of toxic metals remediation in a real landfill leachate (RLL), all of the Pb2+ and Cd2+ (initial concentrations: Pb2+ = 25 mg/L; Cd2+ = 5.6205 mg/L) was mineralized simultaneously, which further confirmed the feasibility of MICP for toxic metal remediation in landfill leachate. However, optimizing the urea dosage and combining the ammonium recovery are necessary strategies required for improving the economic and environmental benefits of the MICP process.",science
10.1016/j.neucom.2021.06.094,Journal,Neurocomputing,scopus,2021-10-07,sciencedirect,Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans,https://api.elsevier.com/content/abstract/scopus_id/85110282298,"Non-destructive testing is a set of techniques for defect detection in materials. While the set of imaging techniques is manifold, ultrasonic imaging is the one used the most. The analysis is mainly performed by human inspectors manually analyzing the acquired images. A low number of defects in real ultrasonic inspections and legal issues concerning data from such inspections make it difficult to obtain proper results from automatic ultrasonic image (B-scan) analysis. The goal of presented research is to obtain an improvement of the detection results by expanding the training data set with realistic synthetic samples. In this paper, we present a novel deep learning Generative Adversarial Network model for generating realistic ultrasonic B-scans with defects in distinct locations. Furthermore, we show that generated B-scans can be used for synthetic data augmentation, and can improve the performances of deep convolutional neural object detection networks. Our novel method was developed on a dataset with almost 4000 images and more than 6000 annotated defects. When trained only on real data, detector can achieve an average precision of 70%. By training only on generated data the results increased to 72%, and by mixing generated and real data we achieve almost 76% average precision. We believe that synthetic data generation can generalize to other tasks with limited data. It could also be used for training human personnel.",science
10.1016/j.neucom.2021.05.098,Journal,Neurocomputing,scopus,2021-10-07,sciencedirect,Improving GAN with inverse cumulative distribution function for tabular data synthesis,https://api.elsevier.com/content/abstract/scopus_id/85107766606,"Designing a generative model to synthesize realistic tabular data is of great significance in data science. Existing tabular data generative models have difficulty in handling complicated and diverse marginal distribution types due to the gradient vanishing problem, and these models pay little attention to the correlation between attributes. We propose a method that improves the generative adversarial network (GAN) with inverse cumulative distribution function for tabular data synthesis. This method first transforms continuous columns into uniform distribution data by using the cumulative distribution function, which can alleviate the gradient vanishing problem in model training. Then the method trains GAN with the transformed data, where the discriminator with label reconstruction function is presented to model the correlation among attributes accurately by introducing an auxiliary supervised task to help the correlations extraction. After that, we train a neural network for each continuous column to perform the inverse transformation of generated data into the target distribution, thereby the synthetic data is obtained. Experiments on simulated and real-world datasets show that our method compares favorably against the state-of-the-art methods in modeling tabular data.",science
10.1016/j.neucom.2021.05.058,Journal,Neurocomputing,scopus,2021-10-07,sciencedirect,Unsupervised learning for community detection in attributed networks based on graph convolutional network,https://api.elsevier.com/content/abstract/scopus_id/85107649006,"Community detection has emerged during the last decade as one of the most challenging problems in network science, which has been revisited with network representation learning recently and has attracted considerable attention. Many approaches have been proposed in recent years, including the latest methods based on graph convolutional network (GCN). Here, we propose a new network representation learning method based on GCN for community detection in attributed networks without prior label information. Inspired by the message pass mechanism of GCN and the local self-organizing property of community structure, we integrate a label sampling model and GCN into an unsupervised learning framework to uncover underlying community structures by fusing topology and attribute information. The label sampling model constructs a balanced training set by structural center location and neighbor node expansion to train the GCN. The experiments on various real-world networks give a comparison view to evaluate the proposed method. The experimental results demonstrate the proposed method performs more efficiently with a comparative performance over current state-of-the-art community detection algorithms.",science
10.1016/j.jmoldx.2021.07.011,Journal,Journal of Molecular Diagnostics,scopus,2021-10-01,sciencedirect,Temporary Regulatory Deviations and the Coronavirus Disease 2019 (COVID-19) PCR Labeling Update Study Indicate What Laboratory-Developed Test Regulation by the US Food and Drug Administration (FDA) Could Look Like,https://api.elsevier.com/content/abstract/scopus_id/85116010045,"The coronavirus disease 2019 (COVID-19) response necessitated innovations and a series of regulatory deviations that also affected laboratory-developed tests (LDTs). To examine real-world consequences and specify regulatory paradigm shifts, legislative proposals were aligned on a common timeline with Emergency Use Authorization (EUA) of LDTs and the US Food and Drug Administration (FDA)-orchestrated severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) labeling update study. The initial EUA adoption by LDT developers shows that the FDA can have oversight over LDTs. We used efficiency-corrected microcosting of our EUA PCR assay to estimate the national cost of the labeling update study to $0.3 to $1.4 million US dollars. Labeling update study performance data showed lower average detection limits in commercial in vitro diagnostic (IVD) assays versus LDTs (32,000 ± 75,000 versus 71,000 ± 147,000 nucleic acid amplification tests/mL; P = 0.04); however, comparison also shows that FDA review of IVD assays and LDTs did not prevent differences between initial and labeling update performance (IVD assay, P < 0.0001; LDT, P = 0.003). The regulatory shifts re-emphasized that both commercial tests and LDTs rely heavily on laboratory competence and procedures; however, lack of performance data on authorized tests, when clinically implemented, precludes assessment of the benefit related to regulatory review. Temporary regulatory deviations during the pandemic and regulatory science tools (ie, reference material) have generated valuable real-world evidence to inform pending legislation regarding LDT regulation.",science
10.1016/j.compbiomed.2021.104820,Journal,Computers in Biology and Medicine,scopus,2021-10-01,sciencedirect,UICPC: Centrality-based clustering for scRNA-seq data analysis without user input,https://api.elsevier.com/content/abstract/scopus_id/85114481229,"scRNA-seq data analysis enables new possibilities for identification of novel cells, specific characterization of known cells and study of cell heterogeneity. The performance of most clustering methods especially developed for scRNA-seq is greatly influenced by user input. We propose a centrality-clustering method named UICPC and compare its performance with 9 state-of-the-art clustering methods on 11 real-world scRNA-seq datasets to demonstrate its effectiveness and usefulness in discovering cell groups. Our method does not require user input. However, it requires settings of threshold, which are benchmarked after performing extensive experiments. We observe that most compared approaches show poor performance due to high heterogeneity and large dataset dimensions. However, UICPC shows excellent performance in terms of NMI, Purity and ARI, respectively. UICPC is available as an R package and can be downloaded by clicking the link https://sites.google.com/view/hussinchowdhury/software.",science
10.1016/j.envsoft.2021.105159,Journal,Environmental Modelling and Software,scopus,2021-10-01,sciencedirect,"Deep learning, explained: Fundamentals, explainability, and bridgeability to process-based modelling",https://api.elsevier.com/content/abstract/scopus_id/85114319353,"Recent breakthroughs in artificial intelligence (AI), and particularly in deep learning (DL), have created tremendous excitement and opportunities in the earth and environmental sciences communities. To leverage these new ‘data-driven’ technologies, however, one needs to understand the fundamental concepts that give rise to DL and how they differ from ‘process-based’, mechanistic modelling. This paper revisits those fundamentals and addresses 10 questions that might be posed by earth and environmental scientists, and with the aid of a real-world modelling experiment, it explains some critical, but often ignored, issues DL may face in practice. The overarching objective is to contribute to a future of AI-assisted earth and environmental sciences where AI models can (1) embrace the typically ignored knowledge base available, (2) function credibly in ‘true’ out-of-sample prediction, and (3) handle non-stationarity in earth and environmental systems. Comparing and contrasting earth and environmental problems with prominent AI applications, such as playing chess and trading in stock markets, provides critical insights for better directing future research in this field.",science
10.1016/j.micpro.2021.104318,Journal,Microprocessors and Microsystems,scopus,2021-10-01,sciencedirect,Investigating data representation for efficient and reliable Convolutional Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85112801148,"Nowadays, Convolutional Neural Networks (CNNs) are widely used as prediction models in different fields, with intensive use in real-time safety-critical systems. Recent studies have demonstrated that hardware faults induced by an external perturbation or aging effects, may significantly impact the CNN inference, leading to prediction failures. Therefore, ensuring the reliability of CNN platforms is crucial, especially when deployed in critical applications. A lot of effort has been made to reduce the memory and energy footprint of CNNs, paving the way to the adoption of approximate computing techniques such as quantization, reduced precision, weight sharing, and pruning. Unfortunately, approximate computing reduces the intrinsic redundancy of CNNs making them more efficient but less resilient to hardware faults. The goal of this work is twofold. First, we assess the reliability of a CNN when reduced bit widths and two different data types (floating- and fixed-point) are used to represent the network parameters (i.e., synaptic weights). Second, we intend to investigate the best compromise between data type, bit-widths reduction, and reliability. The characterization is performed through a fault injection environment built on the darknet open-source framework and targets two CNNs: LeNet-5 and YOLO. Experimental results show that fixed-point data provide the best trade-off between memory footprint reduction and CNN resilience. In particular, for LeNet-5, we achieved a 4X memory footprint reduction at the cost of a slightly reduced reliability (0.45% of critical faults) without retraining the CNN.",science
10.1016/j.aei.2021.101362,Journal,Advanced Engineering Informatics,scopus,2021-10-01,sciencedirect,Teaching and Learning Crystal structures through Virtual Reality based systems,https://api.elsevier.com/content/abstract/scopus_id/85112528485,"Teaching and learning through Virtual Reality(VR) is an emerging technology in the last few years. In this article, the development and use of a VR based teaching–learning system for crystal structures are discussed. The VR system is designed as a lab environment where a user can do experiments related to crystal structures. The VR system is designed in Unity,
                        1
                     
                     
                        1
                        
                           https://www.unity.com/.
                      and Oculus Rift S
                        2
                     
                     
                        2
                        
                           https://www.oculus.com/rift-s/.
                      is used as a VR headset. Currently, the system consists of three phases; in the first phase user can visualize the crystal lattice structures, wherein the second one a user can visualize the light interaction with the crystal lattice structure using a virtual torch ray. The third phase is the X-ray Diffraction (XRD) experiment. In this phase, users can perform the XRD experiment in the lab environment by taking a random crystal from a crystal dispenser machine and placing it in the X-ray machine which identifies the chosen crystalline material and analyses the unit cell. The incident ray colour changes when there is a peak found in the crystal for a better understanding of the user. There is also an interactive display where users can increase/decrease the angles of the radiation and also lock and unlock the experiment to view the diffraction plot for the crystal structure. In many cases, it was found that XRD and the crystal structure is available in the course syllabus but there are no experiments to enhance their learning. Therefore an experiment with 39 participants was performed where the maximum participants are new to crystallography. The study was conducted in two phases; in the first phase, participants are asked to watch video tutorials of the topic followed by questionnaires; in the second phase participants are asked to do the VR based experiment and followed by questionnaires related to overall study and experiment. From the analysis of the study we found that everyone found VR based teaching methods are better than traditional book/video studies. Study results give an average score of 56.74% in comparison to VR based learning approach with an average score of 93.81%. Participants who took part in the experiment found the experience interactive and motivating and found it helpful to learn elusive concepts, which can be learned when simulated. For example, one participant wrote: “The VR experience was surreal and was easy to control. Lucid user experience. Got a view of XRD like never seen before”.",science
10.1016/j.applthermaleng.2021.117375,Journal,Applied Thermal Engineering,scopus,2021-10-01,sciencedirect,A numerical modelling of a multi-layer LaFeCoSi Active magnetic regenerator by using Artificial Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85111976602,"One of the main problems in the framework of magnetic refrigeration regards low adiabatic temperature changes that occur in the magnetocaloric materials, which limits the widespread application of this technology. Therefore, the major effort of researchers is focused on the development of multi-layer Active Magnetic Regenerators, which allows to enlarge the temperature span of a magnetic refrigerator. The use of numerical models can help to understand the feasibility of such application with less effort in comparison with the use of experimental facilities. One of the main challenges in designing a numerical model of a multi-layer Active Magnetic Regenerator is the effective incorporation of the magnetocaloric data of different magnetocaloric materials, which are fundamental to correctly optimize the configuration of such a device with the aim to improve its performance. These data are usually obtained experimentally from different measurements and their integration into the numerical model is challenging. Therefore, this work proposes a modified multi-layer Active Magnetic Regenerator numerical model based on Artificial Neural Networks to integrate the magnetocaloric properties of magnetocaloric materials, allowing an easier and a more reliable implementation of the real properties of magnetocaloric materials. The proposed model was tested simulating a four-layer and a seven-layer LaFeCoSi Active Magnetic Regenerator. The use of Artificial Neural Networks to integrate the magnetocaloric properties of magnetocaloric materials into the multi-layer Active Magnetic Regenerator allowed to improve the accuracy of the model in comparison with the commonly used technique (i.e., Curie temperature shift method) when compared to the experimental data. Indeed, the maximum error of the maximum temperature span with zero thermal load was reduced from about 13 K to 6.6 K, for the seven-layer configuration, and from about 4.1 K to 1.0 K, for the four-layer configuration. Furthermore, the new model allows to obtain more reliable simulated data about the effectiveness of each layer of the Active Magnetic Regenerator, providing a more useful tool to discuss about the optimization of its configuration. The results shows that Artificial Neural Networks can be successfully applied for integrating the magnetocaloric properties of magnetocaloric materials into a multi-layer Active Magnetic Regenerator numerical model, improving its performance. They represent an innovative way to address the problem of including magnetocaloric properties into numerical models, opening the way to other possible Machine Learning techniques as alternatives to the usual Curie temperature shifting method used in the literature to date.",science
10.1016/j.asoc.2021.107720,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,TDMatcher: A topic-based approach to task-developer matching with predictive intelligence for recommendation,https://api.elsevier.com/content/abstract/scopus_id/85111305283,"Artificial Intelligence is currently gripping the business world, which is the next step on the journey from Big Data to full automation. As crowdsourcing has been widely adopted by more enterprises and developers, the software crowdsourcing platform is able to collect enough data. Therefore, we introduce predictive intelligence to solve complex problems. This provides a bridge between software developers and enterprises: developers look for suitable tasks, whose aim is to gain revenues with respect to their interests and abilities; enterprises look for developers that are able to complete crowdsourcing tasks and/or solve hard problems. One main problem is the prediction challenge, i.e., how to perfectly predict the developers for the software crowdsourcing tasks and make appropriate recommendations. To solve the problem, this paper introduces predictive intelligence and proposes TDMatcher, which can effectively perform task-developer pairs prediction and recommendations for software crowdsourcing. First, we builds a unified model for tasks and developers such that they can be matched in the same domain space. Second, we quantitatively measures the matching degree between tasks and developers. Third, we randomly generates potential matchings between developers and crowdsourcing tasks and then employs an MCMC sampling approach to optimize the whole process. Highly matched task-developer pairs can be achieved in the sampling process. In order to solve the cold-start problem, we constructs a social network for each new developer, which indicates that the developer’s interests/abilities to be modeled We implemented TDMatcher and evaluated it against the state-of-the-art approaches on the real-world dataset. The experimental results clearly demonstrate the superiority of TDMatcher. We measured our proposed TDMatcher through the accuracy, diversity and Harmonic Mean of TDMatcher, and found that: (1) TDMatcher outperforms the state-of-the-arts by 15+% in the prediction accuracy and 30% in diversity; and (2) TDMatcher achieves a balance between accuracy and diversity. We believe that TDMatcher provides crowdsourcing platforms with much more capabilities in finding appropriate developers to complete crowdsourcing tasks or vice versa.",science
10.1016/j.chaos.2021.111246,Journal,"Chaos, Solitons and Fractals",scopus,2021-10-01,sciencedirect,To restrict or not to restrict? Use of artificial neural network to evaluate the effectiveness of mitigation policies: A case study of Turkey,https://api.elsevier.com/content/abstract/scopus_id/85111261415,"Outbreaks, epidemics or pandemics have increased over the last years, increasing the morbidity and mortality over large geographical areas, as well as causing financial crises and irreversible social changes. Coping with emerging infectious diseases such as Covid-19, different mitigation policies are developed by countries. However, the benefit of each mitigation policy is still not well-explored due to the considerable difference between implementations of policies in each country. The question is which policies play a significant role in controlling Covid-19 transmission. Developing two models used in Artificial Neural Network, this study investigates the impact of mitigation policies or strategies (a combination of policies) by considering different vaccination and mutation scenarios. The former model requires the prediction of reproduction number based on the number of cases reported in previous days; whereas, the latter model is constructed based on the number of people impacted by a mitigation policy or strategy. Although the first model yields more accurate results, it requires the use of historical data; hence, the passage of time during a critical period of fighting against Covid-19. The benefit of the second model is that it can be implemented more quickly by determining a coefficient for each policy or strategy based on the restricted population and/or limited mobility. Testing different scenarios through a real-world example from Turkey, we find mitigation policies or strategies play a significant role in controlling Covid-19; as well as vaccination and mutation scenarios. Our results suggest continuous and predetermined mitigation policies or strategies should be implemented to control the spread of infectious diseases in addition to a successful vaccination program.",science
10.1016/j.phymed.2021.153643,Journal,Phytomedicine,scopus,2021-10-01,sciencedirect,Atractylodis rhizoma water extract attenuates fructose-induced glomerular injury in rats through anti-oxidation to inhibit TRPC6/p-CaMK4 signaling,https://api.elsevier.com/content/abstract/scopus_id/85111151811,"Background
                  Atractylodis rhizoma, an aromatic herb for resolving dampness, is used to treat Kidney-related edema in traditional Chinese medicine for thousands years. This herb possesses antioxidant effect. However, it is not yet clear how Atractylodis rhizoma prevents glomerular injury through its anti-oxidation.
               
                  Purpose
                  Based the analysis of Atractylodis rhizoma water extract (ARE) components and network pharmacology, this study was to explore whether ARE prevented glomerular injury via its anti-oxidation to inhibit oxidative stress-driven transient receptor potential channel 6 (TRPC6) and its downstream molecule calcium/calmodulin-dependent protein kinase IV (CaMK4) signaling.
               
                  Methods
                  Liquid chromatography-tandem mass spectrometry (LC-MS/MS) was used to analyze ARE components. Network pharmacology analysis was preliminarily performed. Male Sprague-Dawley rats were given 10% fructose drinking water (100 mL/d) for 16 weeks. ARE at 720 and 1090 mg/kg was orally administered to rats for the last 8 weeks. Hydrogen peroxide (H2O2) and malondialdehyde (MDA) level, and superoxide dismutase (SOD) activity in rat kidney cortex were detected, respectively. In rat glomeruli, redox-related factors forkhead box O3 (FoxO3), SOD2 and catalase (CAT), podocyte slit diaphragm proteins podocin and nephrin, cytoskeleton proteins CD2-associated protein (CD2AP) and α-Actinin-4, as well as TRPC6, p-CaMK4 and synaptopodin protein levels were analyzed by Western Blotting. SOD2 and CAT mRNA levels were detected by qRT-PCR.
               
                  Results
                  36 components were identified in ARE. Among them, network pharmacology analysis indicated that ARE might inhibit kidney oxidative stress. Accordingly, ARE up-regulated nuclear FoxO3 expression, and then increased SOD2 and CAT at mRNA and protein levels in glomeruli of fructose-fed rats. It reduced H2O2 and MDA levels, and increased SOD activity in renal cortex of fructose-fed rats. Subsequently, ARE down-regulated TRPC6 and p-CaMK4, and up-regulated synaptopodin in glomeruli of fructose-fed rats. Furthermore, ARE increased podocin and nephrin, as well as CD2AP and α-Actinin-4, being consistent with its reduction of urine albumin-to-creatinine ratio and improvement of glomerular structure injury in this animal model.
               
                  Conclusions
                  These results suggest that ARE may prevent glomerular injury in fructose-fed rats possibly by reducing oxidative stress to inhibit TRPC6/p-CaMK4 signaling and up-regulate synaptopodin expression. Therefore, ARE may be a promising drug for treating high fructose-induced glomerular injury in clinic.",science
10.1016/j.chaos.2021.111236,Journal,"Chaos, Solitons and Fractals",scopus,2021-10-01,sciencedirect,Machine learning-based imputation soft computing approach for large missing scale and non-reference data imputation,https://api.elsevier.com/content/abstract/scopus_id/85109934906,"Missing data is a common problem in real-world data sets and it is amongst the most complex topics in computer science and many other research domains. The common ways to cope with missing values are either by elimination or imputation depending of the volume of the missing data and its distribution nature. It becomes imperative to come up with new imputation approaches along with efficient algorithms. Though most existing imputation methods focus on a moderate amount of missing data, imputation for high missing rates over 80% is still important but challenging. Even with the existence of some works in addressing high missing volume issue, they mostly rely on imputing reference dataset (Complete Datasets for evaluation) after they create artificial missing values and impute it to measure the accuracy of their proposed techniques. So far, the option of imputing high proportions of missing values with no reference comparison dataset (Original Dataset with highly missing values) have been often ignored or overlooked. Therefore, we propose a missing data imputation approach for high volumes of missing values with no reference comparison dataset. The approach makes use of pre-processing measures and breaking the dataset into small continuous non-missing portions then using Multi Criteria Decision-making analysis to select a portion of data which is representative of the entire broken datasets. This portion helps to create reference comparisons and expands the missing dataset through artificial missing-making procedures with different percentages and imputation using different machine learning techniques. This study conducted two experiments using BMI datasets with more than 80% of missing values, derived from the National Child Development Centre (NCDRC) at Sultan Idris Education University (UPSI), Malaysia. The results show that our approach capability in reconstructing datasets with huge missing values.",science
10.1016/j.asoc.2021.107644,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,Production scheduling in industrial mining complexes with incoming new information using tree search and deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85109174667,"Industrial mining complexes have implemented digital technologies and advanced sensors to monitor and gather real-time data about their different operational aspects, starting from the supply of materials from the mineral deposits involved to the products provided to customers. However, technologies are not available to respond in real-time to the incoming new information to adapt the short-term production schedule of a mining complex. A short-term production schedule determines the daily/weekly/monthly sequence of extraction, the destination of materials and utilization of processing streams. This paper presents a novel self-learning artificial intelligence algorithm for mining complexes that learns, from its own experience, to adapt the short-term production scheduling decisions by responding to incoming new information. The algorithm plays the game of short-term production scheduling on its own using a Monte Carlo tree search to train a deep neural network agent that adapts the short-term production schedule with incoming new information. The deep neural network agent evaluates the short-term production scheduling decisions and, in parallel, performs searches using the Monte Carlo tree search to generate experiences. The experiences are then used to train the agent. The agent improves the strength of the tree search, which results in an even stronger self-play to generate better experiences. An application of the proposed algorithm at a real-world copper mining complex shows its exceptional performance to adapt the 13-week short-term production schedule almost in real-time. The adapted production schedule successfully meets the different production requirements and makes better use of the processing capabilities, while also increasing copper concentrate production by 7% and cash flows by 12% compared to the initial production schedule. A video of the proposed algorithm can be found at https://youtu.be/_gSbzxMc_W8.",science
10.1016/j.jobe.2021.102795,Journal,Journal of Building Engineering,scopus,2021-10-01,sciencedirect,A comparative evaluation of semi-active control algorithms for real-time seismic protection of buildings via magnetorheological fluid dampers,https://api.elsevier.com/content/abstract/scopus_id/85107753497,"Semi-active vibration control is considered a powerful method in reducing the dynamic responses of buildings by using additional smart damping devices. In this study, magnetorheological (MR) dampers have been proposed as one of the semi-active control devices to mitigate the structural vibrations and improve the seismic performance of the structures. The performance of the MR dampers strongly depends on implemented controllers. Hence, the main purpose of this paper is to evaluate the efficiency of several semi-active control algorithms related to MR dampers for seismic control of civil building structures. A 5-story test structure is manufactured, and an MR damper is installed between the ground and the first floor. The performance of the semi-active control approach is experimentally evaluated on a shaking table under historical earthquake records. A neural network-based modeling approach is adopted in the inverse MR damper model for the current control. Three different control algorithms, namely Proportional-Integral-Derivative (PID), Sliding Mode (SMC) and Energy-based controller (EBC), are applied to the system in real-time. The shaking tests are also carried out on the structures with different natural frequencies by increasing the number of stories without changing the geometry and material properties of the 5-story building model. The results indicate that the SMC controller is the most effective control algorithm among all controllers in reducing the base shear force by 51%.",science
10.1016/j.compind.2021.103485,Journal,Computers in Industry,scopus,2021-10-01,sciencedirect,Deep learning-based visual control assistant for assembly in Industry 4.0,https://api.elsevier.com/content/abstract/scopus_id/85106362310,"Product assembly is a crucial process in manufacturing plants. In Industry 4.0, the offer of mass-customized products is expanded, thereby increasing the complexity of the assembling phase. This implies that operators should pay close attention to small details, potentially resulting in errors during the manufacturing process owing to its high level of complexity. To mitigate this, we propose a novel architecture that evaluates the activities of an operator during manual assembly in a production cell so that errors in the manufacturing process can be identified, thus avoiding low quality in the final product and reducing rework and waste of raw materials or time. To perform this assessment, it is necessary to use state-of-the-art computer vision techniques, such as deep learning, so that tools, components, and actions may be identified by visual control systems. We develop a deep-learning-based visual control assembly assistant that enables real-time evaluation of the activities in the assembly process so that errors can be identified. A general-use language is developed to describe the actions in assembly processes, which can also be used independently of the proposed architecture. Finally, we generate two datasets with annotated data to be fed to the deep learning methods, the first for the recognition of tools and accessories and the second for the identification of basic actions in manufacturing processes. To validate the proposed method, a set of experiments are conducted, and high accuracy is obtained.",science
10.1016/j.eswa.2021.115081,Journal,Expert Systems with Applications,scopus,2021-10-01,sciencedirect,Utilizing 3D joints data extracted through depth camera to train classifiers for identifying suicide bomber,https://api.elsevier.com/content/abstract/scopus_id/85105277236,"Safety and security of humans is an important concern in every aspect. With the advancement in engineering, sciences, and technology (unfortunately) new methods to harm humans have also been introduced. At the same time, scientists are paying attention to the security aspects by developing new software and hardware gadgets. In comparison to the system level security, the safety/security of human beings is more important. Suicide bombing is one such nuisance that is still an open challenge for the world to detect before it is triggered. This work deals with the identification of a suicide bomber using a 3D depth camera and machine learning techniques. This work utilizes the skeletal data provided by the 3D depth camera to identify a bomber wearing a suicide jacket. The prediction is based on real-time 3D posture data of the body joints obtained through the depth camera. Using a comprehensive experimental design, a dataset is created consisting of 20 joints information obtained from 120 participants. The dataset records this for each of the participants with and without wearing a suicide jacket. Experiments are performed with the suicide jacket bearing 10- to 20-kg weight. Simulations are performed using 3D spatial features of the participants' body in four ways: full body joints (20 joints), upper-half of the body (above the spine base of the skeleton), 20 joints with 15 frames, and 20 joints with 20 frames. It is observed that 15 to 20 frames are sufficient to identify a suspected suicide bomber. The proposed framework utilize four classifiers to identify vulnerability of a subject to be a suicide bomber. Results show that the proposed framework is capable of identifying a suicide bomber with an average accuracy of 92.30%.",science
10.1016/j.cofs.2021.03.014,Journal,Current Opinion in Food Science,scopus,2021-10-01,sciencedirect,Novel digital technologies implemented in sensory science and consumer perception,https://api.elsevier.com/content/abstract/scopus_id/85104656313,"New and emerging digital technologies have been implemented in sensory science, which minimize subjectivity and biases in data acquisition and interpretation compared to traditional methods. These technologies have enabled the incorporation of physiological and emotional responses of panelists elicited by food, beverage, and packaging stimuli through accurate and unbiased information from different sensor technologies. This review focused on recent advances of digital technologies used for sensory science, such as (i) software for sensory science, (ii) integration of biometrics to assess physiological and emotional responses of panelists, (iii) incorporation of virtual, augmented, and mixed reality, and (iv) sensor technology (electronic noses and tongues) for sensory analysis. Rapid data acquisition and results’ interpretation could open the way to automation and implementation of Artificial Intelligence that could revolutionize the food and beverage industries. It also presents a proposed framework for integrating and implementing digital technologies through the food chain from farm/manufacturing facilities to the palate.",science
10.1016/j.ijbiomac.2021.07.138,Journal,International Journal of Biological Macromolecules,scopus,2021-09-30,sciencedirect,The lipid lowering and antioxidative stress potential of polysaccharide from Auricularia auricula prepared by enzymatic method,https://api.elsevier.com/content/abstract/scopus_id/85111709857,"An efficient extraction method of Auricularia auricula polysaccharides (AAPs) by neutral protease was developed and optimized by response surface methodology. AAPs were graded by stepwise ethanol precipitation, the fraction with high recovery rate and strong radical scavenging rate were obtained, then its antioxidant and lipid lowering effect were studied using Caenorhabditis elegans as model organism. The extract yield and ABTS+ scavenging rates of AAPs could reach 14.90% and 86.0% at 50 °C, 75 mL/g of liquid-to-material ratio and pH 9.0. AAP3 obtained by 15% ethanol was a heteropolysaccharide comprised of mannose, glucose, glucuronic acid, xylose, galactose and glucosamine. AAP3 could significantly prolong the lifespan of C. elegans and enhance the activity of antioxidant enzymes including superoxide dismutase (SOD), catalases (CAT) at 0.25 mg/mL (p < 0.05). The qRT-PCR results showed that AAP3 could up regulate mRNA expression levels of daf-16 and skn-1 (>1.6 fold) at 0.25 mg/mL. Besides, AAP3 could significantly reduce the level of body fat and triglyceride in C. elegans (p < 0.05). These studies demonstrated that A. auricula polysaccharides prepared by neutral protease had a prominent protective effect to the damage induced by the intracellular free radical generating agents.",science
10.1016/j.neucom.2021.04.090,Journal,Neurocomputing,scopus,2021-09-30,sciencedirect,Self-supervised video object segmentation using integration-augmented attention,https://api.elsevier.com/content/abstract/scopus_id/85108695156,"While supervised learning approaches show great vitality and effectiveness in video object segmentation, most of them require large amounts of annotations which are expensive and time-consuming. Recently, self-supervised learning has attracted great attention by benefiting from unlabeled video sequences. However, current patch-based self-supervised video object segmentation methods only discriminate the patch from the entire image without distinguishing the object of interest from meaningless backgrounds or even occlusion. These disturbances deteriorate the extracted features and hinder the robustness of tracking when applied to real-world video sequences. In this paper, we propose a novel model named Tracker With Integration-Augmented Attention (TWIAA) to achieve both label-free and prominent performance. Specifically, we integrate both spatial and channel dimensions by introducing a feature spatial enhancement module and a two-stream channel module. With the combination of the two modules, the network can focus on exploring the discriminative object and suppressing the irrelevant part to improve the tracking robustness. Moreover, unlike other methods that calculate features separately on the search branch and template branch, the two designed modules coupled with the Siamese network compute the respective features of the search branch and the template branch jointly to augment the interdependence of the two branches. Such interdependence is injected into both spatial and channel dimensions. So that our approach establishes richer and more discriminative associations to identify the object more accurately. In addition, our method takes full advantage of cycle-consistency information in consecutive frames, which uses coherence as the learning signal to acquire object-oriented relationships. Extensive experiments and ablation studies are conducted on large VOS benchmarks, including DAVIS-2017, YouTube-VOS-2018, and YouTube-VOS-2019. The results verify that our proposed framework has both strong feature representation and competitive performance compared with supervised and self-supervised models.",science
10.1016/j.chroma.2021.462459,Journal,Journal of Chromatography A,scopus,2021-09-27,sciencedirect,Magnet integrated fabric phase sorptive extraction of selected endocrine disrupting chemicals from human urine followed by high-performance liquid chromatography – photodiode array analysis,https://api.elsevier.com/content/abstract/scopus_id/85112491924,"In current paper, a new advanced modification of fabric phase sorptive extraction is introduced for the first time. This advantageous configuration that integrates the stirring and extraction mechanism into a single sample preparation device was originated by equally considering the beneficial role of the increase of extraction kinetics and more specifically of diffusion on the extraction efficiency of the equilibrium based microextraction techniques and the need for integrating and unite processes for better promotion and implementation of the principles of Green Analytical Chemistry.
                  The resulted magnet integrated fabric phase sorptive extraction (MI-FPSE) device was the spearhead to develop a new analytical methodology for the determination of selected very common endocrine disrupting chemicals as model analytes in human urine by high-performance liquid chromatography-photodiode array analysis. More specifically, the sol-gel Carbowax 20 M coated on hydrophilic cellulose fabric substrate, MI-FPSE device was efficiently employed for the establishment of a new extraction protocol before the chromatographic determination. The sample preparation workflow was methodically optimized in terms of the elution solvent mixture, the volume of the sample, the extraction and the elution time, the stirring speed during the extraction, the ionic strength, and the pH of the sample matrix. The chromatographic separation was performed on a Spherisorb C18 column and a gradient elution program within 14 minutes. Mobile phase consisted of 0.05 ammonium acetate aqueous solution and acetonitrile. The method was validated towards linearity, sensitivity, selectivity, precision, accuracy, and stability. LOD and LOQ ranged between 1.05-1.80 and 3.5-6.0 ng/mL, while %RSD values were found lower than 9.0% in all cases. The method was efficiently applied to the bioanalysis of real samples. All the chosen EDCs were measured at high detection levels. The new MI-FPSE device has demonstrated its performance superiority as a magnet integrated stand-alone extraction device and could be considered as a significant improvement in the field of analytical/bioanalytical sample preparation.",science
10.1016/j.knosys.2021.107302,Journal,Knowledge-Based Systems,scopus,2021-09-27,sciencedirect,A novel deep quantile matrix completion model for top-N recommendation[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85111890353,"Matrix completion models have been receiving keen attention due to their wide applications in science and engineering. However, the majority of these models assumes a symmetric noise distribution in their completion processes and uses conditional mean to characterize data distribution in a data set, the assumption of which incurs noticeable bias toward outliers. Recognizing the fact that noise distribution tends to be asymmetric in the real-world, this paper proposes a novel Deep Quantile Matrix Completion model, abbreviated as DQMC, which aims to accurately capture noise distribution in a data set by modeling conditional quantile of the data set instead of its conditional mean as traditionally handled by many state-of-the-art methods. Implemented via a deep computing paradigm, the newly proposed model maps a data set from its input space to the latent spaces through a two-branched deep autoencoder network. Such a mapping can effectively capture complex information latent in the data set. The proposed model is empowered by two key designed elements, including: (1) its two-branched deep autoencoder network that provides a flexible computing pathway to attain completion results with a high quality; (2) the introduction of a quantile loss function in combination with the proposed deep network, leading to a new unsupervised learning algorithm for tackling the matrix completion tasks with a superior capability. Comparative experimental results consistently demonstrate the superiority of the proposed DQMC model in conducting the top-N recommendation tasks involving both explicit and implicit rating data sets with respect to a series of state-of-the-art recommendation algorithms.",science
10.1016/j.xpro.2021.100639,Journal,STAR Protocols,scopus,2021-09-17,sciencedirect,Timesias: A machine learning pipeline for predicting outcomes from time-series clinical records,https://api.elsevier.com/content/abstract/scopus_id/85108953840,"The prediction of outcomes is a critical part of the clinical surveillance for hospitalized patients. Here, we present Timesias, a machine learning pipeline which predicts outcomes from real-time sequential clinical data. The strategy implemented in Timesias is the first-place solution in the crowd-sourcing DII (discover, innovate, impact) National Data Science Challenge involving more than 100,000 patients, achieving 0.85 as evaluated by AUROC (area under receiver operator characteristic curve) in predicting the early onset of sepsis status. Timesias is freely available via PyPI and GitHub.
                  For complete details on the use and execution of this protocol, please refer to Guan et al. (2021).",science
10.1016/j.apgeog.2021.102532,Journal,Applied Geography,scopus,2021-09-01,sciencedirect,Detecting home countries of social media users with machine-learned ranking approach: A case study in Hong Kong,https://api.elsevier.com/content/abstract/scopus_id/85112020941,"Inferring individual's home country from geotagged footprints is widely applied in human mobility research. Previous studies mainly used simple empirical methods that are based on intuitive hypothetical assumptions. Because the exact relationships between users' home countries and geotagged footprints haven't be quantitatively revealed, empirical methods based on human intuitions and past experiences are used for rough approximation. In this study, we propose a machine-learning approach for the task of home country detection, by formulating the task as a query-ranking problem and using a machine-learned ranking model for problem solving. The used model is a Multiple Additive Regression Trees framework that aims to rank regions in specific orders and the region ranked first is designated as the home country. Our approach is data-driven and can adaptively learn the unknown function from input (geotagged footprints) to output (user's home country), thus alleviating the bias introduced by previous empirical methods. We conduct experiments with real-world datasets, and results demonstrate that our approach achieves better performance than previous empirical methods. The model's parameter sensitivity is also investigated, and results show that user's origin may be a factor affecting the approach's performance and that our approach achieves robust good performance with various parameter settings.",science
10.1016/j.phymed.2021.153639,Journal,Phytomedicine,scopus,2021-09-01,sciencedirect,"Anti-angiogenic, apoptotic and matrix metalloproteinase inhibitory activity of Withania somnifera (ashwagandha) on lung adenocarcinoma cells",https://api.elsevier.com/content/abstract/scopus_id/85110554903,"Introduction
                  
                     Withania somnifera belongs to the family Solanaceae, known as Queen of medicinal plants for its enormous use in the medicinal field. Traditionally ashwagandha is used to treat several neurological disorders. This study evaluates the cytotoxic, apoptotic, antiangiogenic and matrix metalloproteinase (MMP) inhibitory activity of W. somnifera on lung adenocarcinoma.
               
                  Methodology
                  Aqueous and ethanolic extracts were prepared from the roots of the W. somnifera. Qualitative and quantitative phytochemical analyses were performed using the standard protocols. Cytotoxicity was assessed using MTT assay. Further experiments were carried out with IC50 concentration of the extract. Apoptosis and DNA damage were evaluated using AO-EB dual staining, Hoechst staining and Comet assay. Effect of the extract on cell migration was evaluated using scratch assay. Angiogenesis inhibition was evaluated using in ovo CAM assay and angiogenic pathway alterations were evaluated using qRT-PCR and western blotting. Autophagy induction was studied via western blotting.
               
                  Results
                  In this study, we found antioxidant activity and the presence of certain secondary metabolites in the ethanolic extracts. The extract showed cytotoxic activity on lung adenocarcinoma cells with an IC50 of 99.7 μg/ml. The extract showed significant anti-angiogenic, apoptotic and autophagy induction activity. W. somnifera extract induced significant decrease in the cell migration at lower concentrations indicating the anti-migratory potential.
               
                  Conclusion
                  Our investigation revealed ethanolic extract of W. somnifera possess significant anti-angiogenic and MMP inhibitory activity and helps in inhibiting the lung adenocarcinoma cells proliferation. Further, our study revealed that the enhanced autophagy induction and apoptotic effects of W. somnifera are responsible for the potential anticancer activity of the extract.",science
10.1016/j.jstrokecerebrovasdis.2021.105962,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-09-01,sciencedirect,StrokeWatch: An Instrument for Objective Standardized Real-Time Measurement of Door-to-Needle Times in Acute Ischemic Stroke Treatment,https://api.elsevier.com/content/abstract/scopus_id/85109982805,"Objectives
                  Monitoring critical time intervals in acute ischemic stroke treatment delivers metrics for quality of performance – the door-to-needle time being well-established. To resolve the conflict of self-reporting bias a “StrokeWatch” was designed – an instrument for objective standardized real-time measurement of procedural times.
               
                  Materials and methods
                  An observational, monocentric analysis of patients receiving intravenous thrombolysis for acute ischemic stroke between January 2018 and September 2019 was performed based on an ongoing investigator-initiated, prospective, and blinded endpoint registry. Patient data and treatment intervals before and after introduction of ""StrokeWatch"" were compared.
               
                  Results
                  “StrokeWatch” was designed as a mobile board equipped with three digital stopwatches tracking door-to-needle, door-to-groin, and door-to-recanalization intervals as well as a form for standardized documentation. 118 patients before introduction of “StrokeWatch” (subgroup A) and 53 patients after introduction of “StrokeWatch” (subgroup B) were compared. There were no significant differences in baseline characteristics, procedural times, or clinical outcome. A non-significant increase in patients with door-to-needle intervals of 60 min or faster (93.2 vs 98.1%, p = 0.243) and good functional outcome (mRS d90 ≤ 2, 47.5 vs 58.5%, p = 0.218) as well as a significant increase in reports of delayed arrival of intra-hospital patient transport service (0.8 vs 13.2%, p = 0.001) were observed in subgroup B.
               
                  Conclusions
                  The implementation of StrokeWatch for objective standardized real-time measurement of door-to-needle times is feasible in a real-life setting without negative impact on procedural times or outcome. It helped to reassure a high-quality treatment standard and reveal factors associated with procedural delays.",science
10.1016/j.ipm.2021.102678,Journal,Information Processing and Management,scopus,2021-09-01,sciencedirect,Catch me if you can: A participant-level rumor detection framework via fine-grained user representation learning,https://api.elsevier.com/content/abstract/scopus_id/85109918946,"Researchers have exerted tremendous effort in designing ways to detect and identify rumors automatically. Traditional approaches focus on feature engineering. They require lots of human actions and are difficult to generalize. Deep learning solutions come to help. However, they usually fail to capture the underlying structure of the rumor propagation and the influence of all participants involved in the spreading chain. In this study, we propose a novel participant-level rumor detection framework. It explicitly models and integrates various fine-grained user representations (i.e., user influence, susceptibility, and temporal information) of all participants from the propagation threads via deep representation learning. Experiments conducted on real-world datasets demonstrate a significant accuracy improvement of our approach. Theoretically, we contribute to the effective usage of data science and analytics for social information diffusion design, particularly rumor detection. Practically, our results can be used to improve the quality of rumor detection services for social platforms.",science
10.1016/j.robot.2021.103830,Journal,Robotics and Autonomous Systems,scopus,2021-09-01,sciencedirect,Visual recognition of gymnastic exercise sequences. Application to supervision and robot learning by demonstration,https://api.elsevier.com/content/abstract/scopus_id/85109177424,"This work presents a novel software architecture to autonomously identify and evaluate the gymnastic activity that people are carrying out. It is composed of three different interconnected layers. The first corresponds to a Multilayer Perceptron (MLP) trained from a set of angular magnitudes derived from the information provided by the OpenPose library. This library works frame by frame, so some postures may be incorrectly detected due to eventual occlusions. The MLP layer makes it possible to accurately identify the posture a person is performing. A second layer, based on a Hidden Markov Model (HMM) and the Viterbi algorithm, filters the incorrect spurious postures. Thus, the accuracy of the algorithm is improved, leading to a precise sequence of postures. A third layer identifies the current exercise and evaluates whether the person is doing it at a correct speed. This layer uses an innovative Modified Levenshtein Distance (MLD), which considers not only the number of operations to transform a given sequence, but also the nature of the elements participating in the comparison. The system works in real time with little delay, thus recognizing sequences of arbitrary length and providing continuous feedback on the exercises being performed. An experiment carried out consisted in reproducing the output of the second layer on an autonomous Pepper robot that can be used in environments where physical exercise is performed, such as a residence for the elderly or others. It has reproduced different exercises previously executed by an instructor so that people can copy the robot. The article analyzes the current situation of the automated gymnastic activities recognition, presents the architecture, the different experiments carried out and the results obtained. The integration of the three components (MLP, HMM and MLD) results in a robust system that has allowed us to improve the results of previous works.",science
10.1016/j.comcom.2021.06.027,Journal,Computer Communications,scopus,2021-09-01,sciencedirect,Optimization of fitness data monitoring system based on Internet of Things and cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85108970321,"In the service dimension, the construction of fitness science data supervision service mode is discussed. Based on the stakeholder theory, through the statistical analysis of the stakeholders of fitness science data supervision, three core stakeholders of the government, users and data service personnel are identified. Based on these three dimensions, we find out the core concepts of government policy model, user demand model and service model. At the same time, each dimension is deeply analyzed. Through the relationship analysis between these three dimensions, the user-oriented collaborative supervision service model of fitness scientific data is expected to guide the specific service practice of fitness scientific data supervision through the establishment of this model. In addition, an unsupervised learning method in machine learning, the isolation forest algorithm, is introduced to detect abnormal data; at the same time, using real fitness data sets, through comparative experiments with local anomaly factor algorithms, it is verified that the isolation forest algorithm has a good effect of anomaly detection; this article also uses redis cache to optimize the performance of the fitness data monitoring system, which solves the access pressure of the main database in a multi-user high-concurrency environment; Finally, the usability and stability of the system are verified by functional tests and stress tests.",science
10.1016/j.asoc.2021.107552,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Contextual recommender system for E-commerce applications,https://api.elsevier.com/content/abstract/scopus_id/85108703897,"Today’s arena of global village organizations, social applications, and commercial websites provides huge information about products, individuals, and activities. This is leading to a plethora of content that requires effective handling to obtain the desired information. A recommendation system (RS) suggests relevant items to the user according to his/her desired preference. It processes various information related to users and items. However, RSs suffer from data sparsity. Generally, deep learning techniques are used in RSs for deep analysis of item contents to create precise recommendations. However, the effective handling of user reviews in parallel with item reviews is still an open research domain that can be further explored. In this paper, a hybrid model that handles both user and item metadata concurrently is proposed with the aim of solving the sparsity problem. To demonstrate the viability of the proposed methodology, a series of experiments was performed on three real-world datasets. The results show that the proposed model outperforms other state-of-the-art approaches to the best of our knowledge.",science
10.1016/j.ins.2021.06.001,Journal,Information Sciences,scopus,2021-09-01,sciencedirect,A development framework of granular prototypes with an allocation of information granularity,https://api.elsevier.com/content/abstract/scopus_id/85107623691,"In this paper, a hybrid model with both clustering mechanism and regression mechanism is built with aid of an allocation of information granularity. Some numeric prototypes constructed by clustering methods are expanded into granular prototypes. The regression module accepts granular prototypes and outcomes information granules. Some advantages of this idea can be concluded: 1). The constructed granular prototypes are best able to represent original data with comparable smaller quantity and high quality. 2). The granular output could be used to predict a new sample’s real number output by giving a rational range. 3). It can be used to solve clustering and regression problems simultaneously. Two different granularity allocation strategies are proposed and experimented while constructing granular prototypes: non-uniformly allocation of information granularity to each cluster and non-uniformly allocation to each feature. A comprehensive objective function is defined considering specificity and generality of the output. The allocation of granularity itself is in fact a multiple-parameters optimization problem which invokes the usage of an evolutionary method. Two popular methods (GA and PSO) are tried and compared with a real data set’s experiment. Three data sets are collected from UCI website to testify the effectiveness of our approach in the experimental part.",science
10.1016/j.image.2021.116329,Journal,Signal Processing: Image Communication,scopus,2021-09-01,sciencedirect,A novel convolutional neural network architecture of multispectral remote sensing images for automatic material classification,https://api.elsevier.com/content/abstract/scopus_id/85107619695,"For real-world simulation, terrain models must combine various types of information on material and texture in terrain reconstruction for the three-dimensional numerical simulation of terrain. However, the construction of such models using the conventional method often involves high costs in both manpower and time. Therefore, this study used a convolutional neural network (CNN) architecture to classify material in multispectral remote sensing images to simplify the construction of future models. Visible light (i.e., RGB), near infrared (NIR), normalized difference vegetation index (NDVI), and digital surface model (DSM) images were examined.
                  This paper proposes the use of the robust U-Net (RUNet) model, which integrates multiple CNN architectures, for material classification. This model, which is based on an improved U-Net architecture combined with the shortcut connections in the ResNet model, preserves the features of shallow network extraction. The architecture is divided into an encoding layer and a decoding layer. The encoding layer comprises 10 convolutional layers and 4 pooling layers. The decoding layer contains four upsampling layers, eight convolutional layers, and one classification convolutional layer. The material classification process in this study involved the training and testing of the RUNet model. Because of the large size of remote sensing images, the training process randomly cuts subimages of the same size from the training set and then inputs them into the RUNet model for training. To consider the spatial information of the material, the test process cuts multiple test subimages from the test set through mirror padding and overlapping cropping; RUNet then classifies the subimages. Finally, it merges the subimage classification results back into the original test image.
                  The aerial image labeling dataset of the National Institute for Research in Digital Science and Technology (Inria, abbreviated from the French Institut national de recherche en sciences et technologies du numérique) was used as well as its configured dataset (called Inria-2) and a dataset from the International Society for Photogrammetry and Remote Sensing (ISPRS). Material classification was performed with RUNet. Moreover, the effects of the mirror padding and overlapping cropping were analyzed, as were the impacts of subimage size on classification performance. The Inria dataset achieved the optimal results; after the morphological optimization of RUNet, the overall intersection over union (IoU) and classification accuracy reached 70.82% and 95.66%, respectively. Regarding the Inria-2 dataset, the IoU and accuracy were 75.5% and 95.71%, respectively, after classification refinement. Although the overall IoU and accuracy were 0.46% and 0.04% lower than those of the improved fully convolutional network, the training time of the RUNet model was approximately 10.6 h shorter. In the ISPRS dataset experiment, the overall accuracy of the combined multispectral, NDVI, and DSM images reached 89.71%, surpassing that of the RGB images. NIR and DSM provide more information on material features, reducing the likelihood of misclassification caused by similar features (e.g., in color, shape, or texture) in RGB images. Overall, RUNet outperformed the other models in the material classification of remote sensing images. The present findings indicate that it has potential for application in land use monitoring and disaster assessment as well as in model construction for simulation systems.",science
10.1016/j.sysarc.2021.102183,Journal,Journal of Systems Architecture,scopus,2021-09-01,sciencedirect,Memory-efficient deep learning inference with incremental weight loading and data layout reorganization on edge systems,https://api.elsevier.com/content/abstract/scopus_id/85107073021,"Pattern recognition applications such as face recognition and agricultural product detection have drawn a rapid interest on Cyber–Physical–Social-Systems (CPSS). These CPSS applications rely on the deep neural networks (DNN) to conduct the image classification. However, traditional DNN inference models in the cloud could suffer from network delay fluctuations and privacy leakage problems. In this regard, current real-time CPSS applications are preferred to be deployed on edge-end embedded devices. Constrained by the computing power and memory limitations of edge devices, improving the memory management efficacy is the key to improving the quality of service for model inference. First, this study explored the incremental loading strategy of model weights for the model inference. Second, the memory space at runtime is optimized through data layout reorganization from the spatial dimension. In particular, the proposed schemes are orthogonal to existing models. Experimental results demonstrate that the proposed approach reduced the memory consumption by 61.05% without additional inference time overhead.",science
10.1016/j.ipm.2021.102641,Journal,Information Processing and Management,scopus,2021-09-01,sciencedirect,Modeling label-wise syntax for fine-grained sentiment analysis of reviews via memory-based neural model,https://api.elsevier.com/content/abstract/scopus_id/85106936740,"Fine-grained sentiment analysis has shown great benefits to real-word applications, such as for social media texts and product reviews. While the current state-of-the-art methods employ external syntactic dependency knowledge and enhance the task performances, most of them make use of merely the dependency edges, leaving the dependency labels unexploited, which the work presented here shows to be also of great helpfulness to the task. In this study we leverage these syntactic features for improving fine-grained sentiment analysis. Compared to previous studies, our method advances following aspects. First, we are the first to propose a novel label-wise syntax memory (LSM) network for simultaneously encoding both the syntactic dependency edges and labels information in a unified manner. Additionally, we take the advantage of the current state-of-the-art contextualized BERT language models to provide rich contexts towards the targeted aspects. We conduct experiments on five benchmark datasets, and the results demonstrate that our model outperforms current best-performing baselines, and achieves new state-of-the-art performances. Further analysis is conducted, proving the necessity to encode sufficient syntactic dependency knowledge for the task, also illustrating the effectiveness of our LSM encoder on modeling these syntax attributes. By exploiting rich syntactic information, our framework outperforms baselines in identifying multiple aspects of sentiment analysis as well as the long-range dependency issues.",science
10.1016/j.ins.2021.04.045,Journal,Information Sciences,scopus,2021-09-01,sciencedirect,HI-GAN: A hierarchical generative adversarial network for blind denoising of real photographs,https://api.elsevier.com/content/abstract/scopus_id/85104913953,"Although deep convolutional neural networks (DCNNs) and generative adversarial networks (GANs) have achieved remarkable success in image denoising, they have been facing a severe problem of the trade-off between removing noise and artifacts on the one hand, and preserving details on the other. In comparison with conventional DCNNs, GANs might be better in balancing between erasing different types of noise and recovering texture details. However, they often generate fake details and unexpected artifacts in the image owing to the instability of their discriminator during training. In this study, we propose a hierarchical generative adversarial network (HI-GAN) that adopts useful solutions for handling these serious problems of image denoising. Unlike the conventional GAN, the proposed HI-GAN comprises three main generators. The first generator tackles the problem of losing high-frequency features such as edges and texture. This generator was trained together with the discriminator to improve its ability to preserve essential details. The second generator focuses on eliminating the effect of instabilities caused by the discriminator and restoring low-frequency features in the noisy image. Both generators use different criteria to evaluate the denoising performance, and none of them outperformed the other. Then, a third generator is employed to help them cooperate more effectively and boost reconstruction performance. Moreover, to improve the effectiveness of the generators, we also propose a novel boosted residual dense UNet, which is designed to maximize information flow to pass through all convolutional layers in the network. In addition, we propose the AdaRaGAN loss function that effectively prevents the instability of the discriminator of the HI-GAN and improves the denoising performance. The experimental results of the experiments involving challenging datasets of real-world noisy images show that our proposed method is superior to other state-of-the-art denoisers in terms of quantitative metrics and visual quality. Our source codes and datasets for HI-GAN are available at https://github.com/ZeroZero19/HI-GAN.git.",science
10.1016/j.neucom.2021.03.076,Journal,Neurocomputing,scopus,2021-08-18,sciencedirect,Enhancing social recommendation via two-level graph attentional networks,https://api.elsevier.com/content/abstract/scopus_id/85104350458,"As an effective deep representation learning technique for graph data, graph convolutional network (GCN) has recently been widely applied to obtain better embedding of vertex. The existing studies have successfully explored user-item interaction via GCN for recommendation task and proved its effectiveness. We argue that a significant limitation of these methods is that social relation, which has been proven to impose positive effects for recommendation in many loss optimization models, has received relatively little scrutiny in GCN. Thus, the resultant embeddings are insufficient to model the potential social propagation effect.
                  In our work, we propose to obtain embeddings by using the neighborhood propagation mechanism on two coupled graphs, i.e. user-item interaction graph and social relation graph, which is capable of capturing the interplay between the user’s item taste and user’s friend relationship to integrate social effect into the embeddings. In particular, to address the challenge that different factors on neighborhood propagation process make different contributions for the embedding, we develop Attentional Social Recommendation system (ASR), a new social recommendation framework with hierarchical attention(i.e., neighbor-level and graph-level attention). This allows much flexibility for adaptively acquiring relative importance for different factors. Extensive experiment on three real-world datasets not only show the superior performance of our proposed model over the baselines, but also demonstrate the effectiveness of simultaneous neighborhood propagation on two graphs.",science
10.1016/j.neuroimage.2021.118207,Journal,NeuroImage,scopus,2021-08-15,sciencedirect,Predictors of real-time fMRI neurofeedback performance and improvement – A machine learning mega-analysis,https://api.elsevier.com/content/abstract/scopus_id/85107090924,"Real-time fMRI neurofeedback is an increasingly popular neuroimaging technique that allows an individual to gain control over his/her own brain signals, which can lead to improvements in behavior in healthy participants as well as to improvements of clinical symptoms in patient populations. However, a considerably large ratio of participants undergoing neurofeedback training do not learn to control their own brain signals and, consequently, do not benefit from neurofeedback interventions, which limits clinical efficacy of neurofeedback interventions. As neurofeedback success varies between studies and participants, it is important to identify factors that might influence neurofeedback success. Here, for the first time, we employed a big data machine learning approach to investigate the influence of 20 different design-specific (e.g. activity vs. connectivity feedback), region of interest-specific (e.g. cortical vs. subcortical) and subject-specific factors (e.g. age) on neurofeedback performance and improvement in 608 participants from 28 independent experiments.
                  With a classification accuracy of 60% (considerably different from chance level), we identified two factors that significantly influenced neurofeedback performance: Both the inclusion of a pre-training no-feedback run before neurofeedback training and neurofeedback training of patients as compared to healthy participants were associated with better neurofeedback performance. The positive effect of pre-training no-feedback runs on neurofeedback performance might be due to the familiarization of participants with the neurofeedback setup and the mental imagery task before neurofeedback training runs. Better performance of patients as compared to healthy participants might be driven by higher motivation of patients, higher ranges for the regulation of dysfunctional brain signals, or a more extensive piloting of clinical experimental paradigms. Due to the large heterogeneity of our dataset, these findings likely generalize across neurofeedback studies, thus providing guidance for designing more efficient neurofeedback studies specifically for improving clinical neurofeedback-based interventions. To facilitate the development of data-driven recommendations for specific design details and subpopulations the field would benefit from stronger engagement in open science research practices and data sharing.",science
10.1016/j.knosys.2021.107069,Journal,Knowledge-Based Systems,scopus,2021-08-05,sciencedirect,Pair-wise ranking based preference learning for points-of-interest recommendation,https://api.elsevier.com/content/abstract/scopus_id/85105426715,"Recommending point-of-interest (POI) to users accurately is a hot topic in business. In the past, many researchers proposed recommendation models based on collaborative filtering or matrix factorization from the perspectives of time, geography, and social relationship. However, only a few studies have focused on user preference which is the key factor influencing user decision. This work focuses on studying the representation and mining of user preference from check-in data for POI recommendation. Pair-wise ranking is the common solution for implementing preference learning. However, traditional ways of constructing pair-wise data cut off the connections between multiple options in the decision process, affecting the effectiveness of preference learning. In this work, we change the ratio of negative to positive instance in pair-wise data from 1:1 to k:1 to ensure the data construction in line with the real decision making process. We propose a new negative sampling method taking the geographical distance and POI categorical distance into consideration jointly for enhancing the quality of training data. For our specialized pair-wise data, we propose a new optimization criterion for implementing effective preference learning. Finally, we conduct extensive experiments on two real-world datasets to validate the effectiveness of our proposed approach. The experiment results show that our approach outperforms the state-of-the-art models by at least 19.7% on F1-Score and 24.4% on nDCG. Additionally, our approach can be easily generalized to other domains, such as commodities, news, and movie recommendation.",science
10.1016/S2589-7500(21)00086-8,Journal,The Lancet Digital Health,scopus,2021-08-01,sciencedirect,Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study,https://api.elsevier.com/content/abstract/scopus_id/85111153013,"Background
                  Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted.
               
                  Methods
                  In this national real-world evidence study, we trained a DLS, the Comprehensive AI Retinal Expert (CARE) system, to identify the 14 most common retinal abnormalities using 207 228 colour fundus photographs derived from 16 clinical settings with different disease distributions. CARE was internally validated using 21 867 photographs and externally tested using 18 136 photographs prospectively collected from 35 real-world settings across China where CARE might be adopted, including eight tertiary hospitals, six community hospitals, and 21 physical examination centres. The performance of CARE was further compared with that of 16 ophthalmologists and tested using datasets with non-Chinese ethnicities and previously unused camera types. This study was registered with ClinicalTrials.gov, NCT04213430, and is currently closed.
               
                  Findings
                  The area under the receiver operating characteristic curve (AUC) in the internal validation set was 0·955 (SD 0·046). AUC values in the external test set were 0·965 (0·035) in tertiary hospitals, 0·983 (0·031) in community hospitals, and 0·953 (0·042) in physical examination centres. The performance of CARE was similar to that of ophthalmologists. Large variations in sensitivity were observed among the ophthalmologists in different regions and with varying experience. The system retained strong identification performance when tested using the non-Chinese dataset (AUC 0·960, 95% CI 0·957–0·964 in referable diabetic retinopathy).
               
                  Interpretation
                  Our DLS (CARE) showed satisfactory performance for screening multiple retinal abnormalities in real-world settings using prospectively collected fundus photographs, and so could allow the system to be implemented and adopted for clinical care.
               
                  Funding
                  This study was funded by the National Key R&D Programme of China, the Science and Technology Planning Projects of Guangdong Province, the National Natural Science Foundation of China, the Natural Science Foundation of Guangdong Province, and the Fundamental Research Funds for the Central Universities.
               
                  Translation
                  For the Chinese translation of the abstract see Supplementary Materials section.",science
10.1016/j.jbi.2021.103848,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,Face mask detection using deep learning: An approach to reduce risk of Coronavirus spread,https://api.elsevier.com/content/abstract/scopus_id/85109043381,"Effective strategies to restrain COVID-19 pandemic need high attention to mitigate negatively impacted communal health and global economy, with the brim-full horizon yet to unfold. In the absence of effective antiviral and limited medical resources, many measures are recommended by WHO to control the infection rate and avoid exhausting the limited medical resources. Wearing a mask is among the non-pharmaceutical intervention measures that can be used to cut the primary source of SARS-CoV2 droplets expelled by an infected individual. Regardless of discourse on medical resources and diversities in masks, all countries are mandating coverings over the nose and mouth in public. To contribute towards communal health, this paper aims to devise a highly accurate and real-time technique that can efficiently detect non-mask faces in public and thus, enforcing to wear mask. The proposed technique is ensemble of one-stage and two-stage detectors to achieve low inference time and high accuracy. We start with ResNet50 as a baseline and applied the concept of transfer learning to fuse high-level semantic information in multiple feature maps. In addition, we also propose a bounding box transformation to improve localization performance during mask detection. The experiment is conducted with three popular baseline models viz. ResNet50, AlexNet and MobileNet. We explored the possibility of these models to plug-in with the proposed model so that highly accurate results can be achieved in less inference time. It is observed that the proposed technique achieves high accuracy (98.2%) when implemented with ResNet50. Besides, the proposed model generates 11.07% and 6.44% higher precision and recall in mask detection when compared to the recent public baseline model published as RetinaFaceMask detector. The outstanding performance of the proposed model is highly suitable for video surveillance devices.",science
10.1016/j.compbiomed.2021.104589,Journal,Computers in Biology and Medicine,scopus,2021-08-01,sciencedirect,Machine learning-based analysis of operator pupillary response to assess cognitive workload in clinical ultrasound imaging,https://api.elsevier.com/content/abstract/scopus_id/85108805307,"Introduction
                  Pupillometry, the measurement of eye pupil diameter, is a well-established and objective modality correlated with cognitive workload. In this paper, we analyse the pupillary response of ultrasound imaging operators to assess their cognitive workload, captured while they undertake routine fetal ultrasound examinations. Our experiments and analysis are performed on real-world datasets obtained using remote eye-tracking under natural clinical environmental conditions.
               
                  Methods
                  Our analysis pipeline involves careful temporal sequence (time-series) extraction by retrospectively matching the pupil diameter data with tasks captured in the corresponding ultrasound scan video in a multi-modal data acquisition setup. This is followed by the pupil diameter pre-processing and the calculation of pupillary response sequences. Exploratory statistical analysis of the operator pupillary responses and comparisons of the distributions between ultrasonographic tasks (fetal heart versus fetal brain) and operator expertise (newly-qualified versus experienced operators) are performed. Machine learning is explored to automatically classify the temporal sequences into the corresponding ultrasonographic tasks and operator experience using temporal, spectral, and time-frequency features with classical (shallow) models, and convolutional neural networks as deep learning models.
               
                  Results
                  Preliminary statistical analysis of the extracted pupillary response shows a significant variation for different ultrasonographic tasks and operator expertise, suggesting different extents of cognitive workload in each case, as measured by pupillometry. The best-performing machine learning models achieve receiver operating characteristic (ROC) area under curve (AUC) values of 0.98 and 0.80, for ultrasonographic task classification and operator experience classification, respectively.
               
                  Conclusion
                  We conclude that we can successfully assess cognitive workload from pupil diameter changes measured while ultrasound operators perform routine scans. The machine learning allows the discrimination of the undertaken ultrasonographic tasks and scanning expertise using the pupillary response sequences as an index of the operators’ cognitive workload. A high cognitive workload can reduce operator efficiency and constrain their decision-making, hence, the ability to objectively assess cognitive workload is a first step towards understanding these effects on operator performance in biomedical applications such as medical imaging.",science
10.1016/j.neuroscience.2021.06.005,Journal,Neuroscience,scopus,2021-08-01,sciencedirect,What Deception Tasks Used in the Lab Really Do: Systematic Review and Meta-analysis of Ecological Validity of fMRI Deception Tasks,https://api.elsevier.com/content/abstract/scopus_id/85108407941,"Interpretation of the neural findings of deception without considering the ecological validity of the experimental tasks could lead to biased conclusions. In this study we classified the experimental tasks according to their inclusion of three essential components required for ecological validity: intention to lie, social interaction and motivation. First, we carried out a systematic review to categorize fMRI deception tasks and to weigh the degree of ecological validity of each one. Second, we performed a meta-analysis to identify if each type of task involves a different neural substrate and to distinguish the neurocognitive contribution of each component of ecological validity essential to deception. We detected six categories of deception tasks. Intention to lie was the component least frequently included, followed by social interaction. Monetary reward was the most frequent motivator. The results of the meta-analysis, including 59 contrasts, revealed that intention to lie is associated with activation in the left lateral occipital cortex (superior division) whereas the left angular gyrus and right inferior frontal gyrus (IFG) are engaged during lying under instructions. Additionally, the right IFG appears to participate in the social aspect of lying including simulated and real interactions. We found no effect of monetary reward in our analysis. Finally, tasks with high ecological validity recruited fewer brain areas (right insular cortex and bilateral anterior cingulate cortex (ACC)) compared to less ecological tasks, perhaps because they are more natural and realistic, and engage a wide network of brain mechanisms, as opposed to specific tasks that demand more centralized processes.",science
10.1016/j.dss.2021.113574,Journal,Decision Support Systems,scopus,2021-08-01,sciencedirect,Prediction of initial coin offering success based on team knowledge and expert evaluation,https://api.elsevier.com/content/abstract/scopus_id/85104123240,"Initial coin offering (ICO) is a new financing method that has been widely used in cryptocurrency projects. However, it has been reported that nearly 30% of cryptocurrency projects fail during ICO, indicating an important gap in research and an opportunity for more advanced research on ICO project assessment. This study reveals that previous studies primarily used project-related factors to predict ICO success while neglecting social factors such as team information and expert evaluation. Inspired by the knowledge-based theory (KBT) of the firm, we set out to examine the impact of heterogeneous team knowledge and expert evaluation on ICO success. One primary contribution of this study is the design of novel knowledge measures based on KBT. In addition, we propose a deep-learning model – an attention-based bidirectional recurrent neural network (A-BiRNN) – to automatically extract features from online comments. We validate the proposed model on a real-world dataset, and experiments show that the accuracy of the proposed prediction model outperforms those of existing models by more than 6%, highlighting the effectiveness of the proposed approach in predicting ICO success. This study's results provide useful ideas for both investors and ICO platforms to assess the quality of cryptocurrency projects, thus improving information symmetry in ICO markets. Also, this study demonstrates the value of applying KBT in assessing firm performance in ICO markets. The generalized value of the proposed approach should be tested in more business contexts, such as crowdfunding and peer-to-peer (P2P) lending.",science
10.1016/j.asoc.2021.107360,Journal,Applied Soft Computing,scopus,2021-08-01,sciencedirect,Detecting malicious activity in Twitter using deep learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85104102374,"Undoubtedly, social media, such as Facebook and Twitter, constitute a major part of our everyday life due to the incredible possibilities they offer to their users. However, Twitter and generally online social networks (OSNs) are increasingly used by automated accounts, widely known as bots, due to their immense popularity across a wide range of user categories. Their main purpose is the dissemination of fake news, the promotion of specific ideas and products, the manipulation of the stock market and even the diffusion of sexually explicit material. Therefore, the early detection of bots in social media is quite essential. In this paper, two methods are introduced targeting this that are mainly based on Natural Language Processing (NLP) to distinguish legitimate users from bots. In the first method, a feature extraction approach is proposed for identifying accounts posting automated messages. After applying feature selection techniques and dealing with imbalanced datasets, the subset of features selected is fed in machine learning algorithms. In the second method, a deep learning architecture is proposed to identify whether tweets have been posted by real users or generated by bots. To the best of the authors’ knowledge, there is no prior work on using an attention mechanism for identifying bots. The introduced approaches have been evaluated over a series of experiments using two large real Twitter datasets and demonstrate valuable advantages over other existing techniques targeting the identification of malicious users in social media.",science
10.1016/j.eswa.2021.114750,Journal,Expert Systems with Applications,scopus,2021-08-01,sciencedirect,A hybrid method with dynamic weighted entropy for handling the problem of class imbalance with overlap in credit card fraud detection,https://api.elsevier.com/content/abstract/scopus_id/85102250887,"Class imbalance with overlap is a very challenging problem in electronic fraud transaction detection. Fraudsters have racked their brains to make a fraud transaction as similar as a genuine one in order to avoid being found. Therefore, lots of data of fraud transactions overlap with genuine transactions so that it is hard to distinguish them. However, most attention has been focused on class imbalance rather than overlapping issues for machine-learning-based methods of fraud transaction detection. This paper proposes a novel hybrid method to handle the problem of class imbalance with overlap based on a divide-and-conquer idea. Firstly, an anomaly detection model is trained on the minority samples for excluding both a few outliers of minority class and lots of majority samples from the original dataset. Then the remaining samples form an overlapping subset that has a low imbalance ratio and a reduced learning interference from both minority class and majority class than the original dataset. After that, this difficult overlapping subset is dealt with a non-linear classifier in order to distinguish them well. To achieve good properties of the overlapping subset, we propose a novel assessment criterion, Dynamic Weighted Entropy (DWE), to evaluate its quality. It is a specially designed trade-off between the number of excluded outliers of minority class and the ratio of class imbalance of overlapping subset. With the help of DWE, time consumption on searching good hyper-parameters is dramatically declined. Extensive experiments on Kaggle fraud detection dataset and a large real electronic transaction dataset demonstrate that our method significantly outperforms state-of-the-art ones.",science
10.1016/j.irbm.2020.07.002,Journal,IRBM,scopus,2021-08-01,sciencedirect,A Computationally Efficient Correlational Neural Network for Automated Prediction of Chronic Kidney Disease,https://api.elsevier.com/content/abstract/scopus_id/85087974451,"Objectives
                  In this paper, we propose a computationally efficient Correlational Neural Network (CorrNN) learning model and an automated diagnosis system for detecting Chronic Kidney Disease (CKD). A Support Vector Machine (SVM) classifier is integrated with the CorrNN model for improving the prediction accuracy.
               
                  Material and methods
                  The proposed hybrid model is trained and tested with a novel sensing module. We have monitored the concentration of urea in the saliva sample to detect the disease. Experiments are carried out to test the model with real-time samples and to compare its performance with conventional Convolutional Neural Network (CNN) and other traditional data classification methods.
               
                  Results
                  The proposed method outperforms the conventional methods in terms of computational speed and prediction accuracy. The CorrNN-SVM combined network achieved a prediction accuracy of 98.67%. The experimental evaluations show a reduction in overall computation time of about 9.85% compared to the conventional CNN algorithm.
               
                  Conclusion
                  The use of the SVM classifier has improved the capability of the network to make predictions more accurately. The proposed framework substantially advances the current methodology, and it provides more precise results compared to other data classification methods.",science
10.1016/j.bbrc.2020.10.077,Journal,Biochemical and Biophysical Research Communications,scopus,2021-07-30,sciencedirect,"Life, death, and self: Fundamental questions of primitive cognition viewed through the lens of body plasticity and synthetic organisms",https://api.elsevier.com/content/abstract/scopus_id/85095615733,"Central to the study of cognition is being able to specify the Subject that is making decisions and owning memories and preferences. However, all real cognitive agents are made of parts (such as brains made of cells). The integration of many active subunits into a coherent Self appearing at a larger scale of organization is one of the fundamental questions of evolutionary cognitive science. Typical biological model systems, whether basal or advanced, have a static anatomical structure which obscures important aspects of the mind-body relationship. Recent advances in bioengineering now make it possible to assemble, disassemble, and recombine biological structures at the cell, organ, and whole organism levels. Regenerative biology and controlled chimerism reveal that studies of cognition in intact, “standard”, evolved animal bodies are just a narrow slice of a much bigger and as-yet largely unexplored reality: the incredible plasticity of dynamic morphogenesis of biological forms that house and support diverse types of cognition. The ability to produce living organisms in novel configurations makes clear that traditional concepts, such as body, organism, genetic lineage, death, and memory are not as well-defined as commonly thought, and need considerable revision to account for the possible spectrum of living entities. Here, I review fascinating examples of experimental biology illustrating that the boundaries demarcating somatic and cognitive Selves are fluid, providing an opportunity to sharpen inquiries about how evolution exploits physical forces for multi-scale cognition. Developmental (pre-neural) bioelectricity contributes a novel perspective on how the dynamic control of growth and form of the body evolved into sophisticated cognitive capabilities. Most importantly, the development of functional biobots – synthetic living machines with behavioral capacity – provides a roadmap for greatly expanding our understanding of the origin and capacities of cognition in all of its possible material implementations, especially those that emerge de novo, with no lengthy evolutionary history of matching behavioral programs to bodyplan. Viewing fundamental questions through the lens of new, constructed living forms will have diverse impacts, not only in basic evolutionary biology and cognitive science, but also in regenerative medicine of the brain and in artificial intelligence.",science
10.1016/j.neucom.2021.02.056,Journal,Neurocomputing,scopus,2021-07-20,sciencedirect,"AttM-CNN: Attention and metric learning based CNN for pornography, age and Child Sexual Abuse (CSA) Detection in images",https://api.elsevier.com/content/abstract/scopus_id/85103630264,"Nowadays, the growing number of cases of possession and distribution of Child Sexual Abuse (CSA) material pose a significant challenge for Law Enforcement Agencies (LEAs). In this paper, we decompose the automatic CSA detection problem into two simpler ones for which it is feasible to create massive labeled datasets, especially to train deep neural networks: (i) pornographic content detection and (ii) age-group classification of a person as a minor or an adult. We propose a deep CNN architecture with a novel attention mechanism and metric learning, denoted as AttM-CNN, for these tasks. Furthermore, the pornography detection and the age-group classification networks are combined for CSA detection using two different strategies: decision level fusion for binary CSA classification and score level fusion for the re-arrangement of the suspicious images. We also introduce two new datasets: (i) Pornographic-2M, which contains two million pornographic images, and (ii) Juvenile-80k, including 80k manually labeled images with apparent facial age. The experiments conducted for age-group and pornographic classification demonstrate that our approach obtained similar or superior results compared to the state-of-the-art systems on various benchmark datasets for both tasks, respectively. For the evaluation of CSA detection, we created a test dataset comprising one million adult porn, one million non-porn images, and 
                        
                           5
                           ,
                           000
                        
                      real CSA images provided to us by Police Forces. For binary CSA classification, our method obtained an accuracy of 
                        
                           92.72
                           %
                        
                     , which increases the recognition rate by more than 
                        
                           21
                           %
                        
                      compared to a well-known forensic tool, i.e. NuDetective. Furthermore, re-arrangement of the CSA test dataset images showed that 
                        
                           80
                           %
                        
                      of CSA images can be found in the top 
                        
                           8.5
                           %
                        
                      of images in the ranked list created using our approach.",science
10.1016/j.chemolab.2021.104329,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-07-15,sciencedirect,A novel approach for water quality classification based on the integration of deep learning and feature extraction techniques,https://api.elsevier.com/content/abstract/scopus_id/85105292476,"Water quality monitoring plays a vital role in the protection of water resources, environmental management, and decision-making. Artificial intelligence (AI) based on machine learning techniques has been widely used to evaluate and classify water quality for the last two decades. However, traditional machine learning techniques face many limitations, the most important of which is the inability to apply these techniques with big data generated by smart water quality monitoring stations to improve the prediction. Real-time water quality monitoring with high accuracy and efficiency for intelligent water quality monitoring stations requires new and sophisticated techniques based on machine and deep learning techniques. For this purpose, we propose a novel approach based on the integration of deep learning and feature extraction techniques to improve water quality classification. In this paper, was chosen the Tilesdit dam in Bouira (Algeria) as a case study. Moreover, we implemented the advanced deep learning method - Long Short Term Memory Recurrent Neural Networks (LSTM RNNs) to construct an intelligent model for drinking water quality classification. Furthermore, principal component analysis (PCA), linear discriminant analysis (LDA) and independent component analysis (ICA) techniques were used for features extraction and data reduction from original features. Additionally, we used three methods of cross-validation and two methods of the out-of-sample test to estimate the performance of LSTM RNNs model. From the results we found that the integration of LSTM RNNs with LDA, and LSTM RNNs with ICA yields an accuracy of 99.72%, using Random-Holdout technique.",science
10.1016/j.wear.2021.203622,Journal,Wear,scopus,2021-07-15,sciencedirect,Acoustic emission and machine learning based classification of wear generated using a pin-on-disc tribometer equipped with a digital holographic microscope,https://api.elsevier.com/content/abstract/scopus_id/85103025626,"The efficiency of processes involving frictional contacts between surfaces is often characterized by wear rates or friction coefficients. However, the classification and forecasting of wear rates in friction related processes is a real industrial challenge that is unsolved today. Hence, an on-line monitoring system able to classify wear rate can be crucial for many industries as it could help in preventing catastrophic failures. Applications include lifetime assessment of various industrial components where a range of wear failures occur such as scuffing (a typical sudden failure mechanism). These tribological processes can now be sensorized, and the corresponding sensor signatures can be modelled and monitored using state-of-the-art Machine learning (ML) algorithms. In this study, we use an Acoustic Emission (AE) sensor and ML frameworks to classify different wear categories simulated with a customized pin-on-disc tribometer. A real-time investigation of the wear track is necessary to find out the origins of the wear scar visible at the surface. To achieve this objective, the experiments were conducted on a pin-on-disc tribometer equipped with a Digital Holographic Microscope (DHM). Experiments were carried out using alumina and steel balls against steel discs at room temperature. Real-time DHM images of the wear track surface were recorded for each lap at the same position. An acoustic emission sensor recorded the AE signals during the complete duration of experiments. The AE signatures, in combination with the real-time DHM images, were correlated as input and ground truth labels for the ML algorithm. Several ML frameworks were compared; they are support vector machine, logistic regression, XGBoost, random forest, neural networks, k-Nearest Neighbor, quadratic discriminant analysis and Naive Bayes. The classifier was trained to differentiate the acoustic emission features of the different wear rates. Most ML algorithms had an average classification accuracy above 80%, and the highest was obtained with support vector machine (84.7%). The classification accuracy can be improved by combining two neighboring categories with limited differences in terms of wear rate. Hence, the proposed method has a significant industrial potential for in-situ and real-time quality monitoring of wear processes since it requires minimum modifications of commercially available industrial machines.",science
10.1016/j.wear.2021.203616,Journal,Wear,scopus,2021-07-15,sciencedirect,Data-driven wear monitoring for sliding bearings using acoustic emission signals and long short-term memory neural networks,https://api.elsevier.com/content/abstract/scopus_id/85099657396,"Driven by the potential applications of sliding bearings in planetary gearboxes for wind turbines, the wear prognosis of heavy loaded sliding bearings under low rotational speeds is an important aspect. The aims of this study are to identify an adequate condition monitoring technique and demonstrate the potential of data-driven wear monitoring for scenarios, where transient wear data for data-driven monitoring is not available.
                  In a first step, Acoustic Emission (AE) technique has been applied to a special test rig for planetary gearbox sliding bearings. It was demonstrated that AE can be used to distinguish between wear-critical mixed friction and hydrodynamic regime. In a second step, a data-driven method for wear monitoring was developed and applied to a component test rig for sliding bearings. For validation and generation of condition monitoring data, sliding bearings from the same bronze material were subjected to steady speed conditions in mixed lubrication regime with different loads as well as runtime. The results from these experiments and results from validated physical wear simulations are the input parameters for the proposed data-driven approach. The wear prognosis is performed with recurrent neural networks, which can predict the transient degradation. With the developed data-driven approach to wear monitoring, a good accuracy can be achieved that is capable of real-time wear monitoring.",science
10.1016/j.chroma.2021.462215,Journal,Journal of Chromatography A,scopus,2021-07-05,sciencedirect,Sensitive determination of Fluoxetine and Citalopram antidepressants in urine and wastewater samples by liquid chromatography coupled with photodiode array detector,https://api.elsevier.com/content/abstract/scopus_id/85105725190,"A new analyte separation and preconcentration method for the trace determination of antidepressant drugs, Fluoxetine (FLU) and Citalopram (CIT) in urine and wastewaters, was developed based on HPLC-DAD analysis after magnetic solid phase extraction (MSPE). In the proposed method, FLU and CIT were retained on the newly synthetized magnetic sorbent (Fe3O4@PPy-GO) in the presence of buffer (pH 10.0) and then were desorbed into a lower volume of acetonitrile prior to the chromatographic determinations. Before HPLC analysis, all samples were filtered through a 0.45 µm PTFE filter. Experimental parameters such as interaction time, desorption solvent and volume, and pH were studied and optimized in order to establish the detection limit, linearity, enrichment factor and other analytical figures of merit under optimum operation conditions. In the developed method, FLU and CIT were analyzed by diode array detector at the corresponding maximum wavelengths of 227 and 238 nm, respectively, by using an isocratic elution of 60% pH 3.0 buffer, 30% acetonitrile, and 10% methanol. By using the optimum conditions, limit of detections for FLU and CIT were 1.58 and 1.43 ng mL−1, respectively, while the limit of quantifications was 4.82 and 4.71 ng mL−1, respectively. Relative standard deviations (RSD%) for triplicate analyses of model solutions containing 100 ng mL−1 target molecules were found to be less than 5.0 %. Finally, the method was successfully applied to urine (both simulated and real healthy human) and wastewater samples, and quantitative results were obtained in recovery experiments.",science
10.1016/j.procs.2021.06.077,Conference Proceeding,Procedia Computer Science,scopus,2021-07-01,sciencedirect,Digital transformation as a new paradigm of economic policy,https://api.elsevier.com/content/abstract/scopus_id/85112599973,"This study analyzes the conceptual provisions related to solving problems related to the introduction of digital technologies and the formation of a digital economy based on them, reveals the dynamics of digital transformation and its impact on business processes and the interaction of states, business and civil society in the context of modern economic policy. We reviewed the policy of the Russian state in terms of overcoming both the existing and potential economic consequences of the COVID-19 pandemic based on published expert assessments. Our results confirmed that overcoming the current turbulent state of the digital economy in Russia requires: firstly, the development of digital entrepreneurship or the digital sector as the “core” of the digital economy, where digital technologies are created; secondly, the removal of restrictions on the movement of resources caused by the COVID-19 pandemic, as a result of the consistent implementation of a coordinated strategy for the digitalization of the economy, based on global cooperation in the field of economic policy; third, the process of reproduction of the social product, where production - distribution – exchange - consumption interact, should take place at the level of world standards; fourth, to introduce the “digital style”in economic policy through building technological chains and diversified connections; fifth, to develop artificial intelligence, the essence of which is to“break” the matrix of habitual life in order to launch a large-scale virtual program of a new being of humanity, spurred by the COVID-19 pandemic.",science
10.1016/j.osnem.2021.100152,Journal,Online Social Networks and Media,scopus,2021-07-01,sciencedirect,Towards a pragmatic detection of unreliable accounts on social networks,https://api.elsevier.com/content/abstract/scopus_id/85110140151,"In recent years, the problem of unreliable content in social networks has become a major threat, with a proven real-world impact in events like elections and pandemics, undermining democracy and trust in science, respectively. Research in this domain has focused not only on the content but also on the accounts that propagate it, with the bot detection task having been thoroughly studied. However, not all bot accounts work as unreliable content spreaders (p.e. bot for news aggregation), and not all human accounts are necessarily reliable. In this study, we try to distinguish unreliable from reliable accounts, independently of how they are operated. In addition, we work towards providing a methodology capable of coping with real-world situations by introducing the content available (restricting it by volume- and time-based batches) as a parameter of the methodology. Experiments conducted on a validation set with a different number of tweets per account provide evidence that our proposed solution produces an increase of up to 20% in performance when compared with traditional (individual) models and with cross-batch models (which perform better with different batches of tweets).",science
10.1016/j.ebiom.2021.103465,Journal,EBioMedicine,scopus,2021-07-01,sciencedirect,A mass spectrometry-based targeted assay for detection of SARS-CoV-2 antigen from clinical specimens,https://api.elsevier.com/content/abstract/scopus_id/85109005451,"Background
                  The COVID-19 pandemic caused by severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) has overwhelmed health systems worldwide and highlighted limitations of diagnostic testing. Several types of diagnostic tests including RT-PCR-based assays and antigen detection by lateral flow assays, each with their own strengths and weaknesses, have been developed and deployed in a short time.
               
                  Methods
                  Here, we describe an immunoaffinity purification approach followed a by high resolution mass spectrometry-based targeted qualitative assay capable of detecting SARS-CoV-2 viral antigen from nasopharyngeal swab samples. Based on our discovery experiments using purified virus, recombinant viral protein and nasopharyngeal swab samples from COVID-19 positive patients, nucleocapsid protein was selected as a target antigen. We then developed an automated antibody capture-based workflow coupled to targeted high-field asymmetric waveform ion mobility spectrometry (FAIMS) - parallel reaction monitoring (PRM) assay on an Orbitrap Exploris 480 mass spectrometer. An ensemble machine learning-based model for determining COVID-19 positive samples was developed using fragment ion intensities from the PRM data.
               
                  Findings
                  The optimized targeted assay, which was used to analyze 88 positive and 88 negative nasopharyngeal swab samples for validation, resulted in 98% (95% CI = 0.922–0.997) (86/88) sensitivity and 100% (95% CI = 0.958–1.000) (88/88) specificity using RT-PCR-based molecular testing as the reference method.
               
                  Interpretation
                  Our results demonstrate that direct detection of infectious agents from clinical samples by tandem mass spectrometry-based assays have potential to be deployed as diagnostic assays in clinical laboratories, which has hitherto been limited to analysis of pure microbial cultures.
               
                  Funding
                  This study was supported by DBT/Wellcome Trust India Alliance Margdarshi Fellowship grant IA/M/15/1/502023 awarded to AP and the generosity of Eric and Wendy Schmidt.",science
10.1016/j.jstrokecerebrovasdis.2021.105826,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-07-01,sciencedirect,Automatic Acute Stroke Symptom Detection and Emergency Medical Systems Alerting by Mobile Health Technologies: A Review,https://api.elsevier.com/content/abstract/scopus_id/85107711467,"Objectives
                  To survey recent advances in acute stroke symptom automatic detection and Emergency Medical Systems (EMS) alerting by mobile health technologies.
               
                  Materials and methods
                  Narrative review
               
                  Results
                  Delayed activation of EMS for stroke symptoms by patients and witnesses deprives patients of rapid access to brain-saving therapies and occurs due to public unawareness of stroke features, cognitive and motor deficits produced by the stroke itself, and sleep onset. A promising emerging approach to overcoming the inherent biologic constraints of patient capacity to self-detect and respond to stroke symptoms is continuous monitoring by mobile health technologies with wireless sensors and artificial intelligence recognition systems. This review surveys 11 sensing technologies - accelerometers, gyroscopes, magnetometers, pressure sensors, touch screen and keyboard input detectors, artificial vision, and artificial hearing; and 10 consumer device form factors in which they are increasingly implemented: smartphones, smart speakers, smart watches and fitness bands, smart speakers/voice assistants, home health robots, smart clothing, smart beds, closed circuit television, smart rings, and desktop/laptop/tablet computers.
               
                  Conclusions
                  The increase in computing power, wearable sensors, and mobile connectivity have ushered in an array of mobile health technologies that can transform stroke detection and EMS activation. By continuously monitoring a diverse range of biometric parameters, commercially available devices provide the technologic capability to detect cardinal language, motor, gait, and sensory signs of stroke onset. Intensified translational research to convert the promise of these technologies to validated, accurate real-world deployments are an important next priority for stroke investigation.",science
10.1016/j.cmpb.2021.106130,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-07-01,sciencedirect,"Chest x-ray automated triage: A semiologic approach designed for clinical implementation, exploiting different types of labels through a combination of four Deep Learning architectures",https://api.elsevier.com/content/abstract/scopus_id/85107617149,"Background and objectives
                  The multiple chest x-ray datasets released in the last years have ground-truth labels intended for different computer vision tasks, suggesting that performance in automated chest x-ray interpretation might improve by using a method that can exploit diverse types of annotations. This work presents a Deep Learning method based on the late fusion of different convolutional architectures, that allows training with heterogeneous data with a simple implementation, and evaluates its performance on independent test data. We focused on obtaining a clinically useful tool that could be successfully integrated into a hospital workflow.
               
                  Materials and methods
                  Based on expert opinion, we selected four target chest x-ray findings, namely lung opacities, fractures, pneumothorax and pleural effusion. For each finding we defined the most suitable type of ground-truth label, and built four training datasets combining images from public chest x-ray datasets and our institutional archive. We trained four different Deep Learning architectures and combined their outputs with a late fusion strategy, obtaining a unified tool. The performance was measured on two test datasets: an external openly-available dataset, and a retrospective institutional dataset, to estimate performance on the local population.
               
                  Results
                  The external and local test sets had 4376 and 1064 images, respectively, for which the model showed an area under the Receiver Operating Characteristics curve of 0.75 (95%CI: 0.74–0.76) and 0.87 (95%CI: 0.86–0.89) in the detection of abnormal chest x-rays. For the local population, a sensitivity of 86% (95%CI: 84–90), and a specificity of 88% (95%CI: 86–90) were obtained, with no significant differences between demographic subgroups. We present examples of heatmaps to show the accomplished level of interpretability, examining true and false positives.
               
                  Conclusion
                  This study presents a new approach for exploiting heterogeneous labels from different chest x-ray datasets, by choosing Deep Learning architectures according to the radiological characteristics of each pathological finding. We estimated the tool's performance on the local population, obtaining results comparable to state-of-the-art metrics. We believe this approach is closer to the actual reading process of chest x-rays by professionals, and therefore more likely to be successful in a real clinical setting.",science
10.1016/j.jchromb.2021.122760,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2021-07-01,sciencedirect,Rapid exposure monitoring of six bisphenols and diethylstilbestrol in human urine using fabric phase sorptive extraction followed by high performance liquid chromatography – photodiode array analysis,https://api.elsevier.com/content/abstract/scopus_id/85106648971,"A novel fabric phase sorptive extraction protocol is developed for rapid exposure monitoring of six bisphenol analogues, including bisphenol A, bisphenol S, bisphenol F, bisphenol E, bisphenol B, bisphenol C, and diethylstilbestrol (DES) from human urine prior to high-performance liquid chromatography-photodiode array analysis.
                  FPSE sample pretreatment protocol ensures the harmonization of the proposed method with the principles of Green Analytical Chemistry (GAC). Among eighteen evaluated FPSE membranes, sol-gel poly (ethylene glycol) (PEG) coated cellulose FPSE membrane resulted in the most efficient extraction. This polar FPSE membrane effectively exploits a number of advantageous features inherent to FPSE including sponge-like porous architecture of the sol-gel sorbent coating, favorable surface chemistry, flexibility and built-in permeability of cellulose fabric substrate, high primary contact surface area for rapid sorbent-analyte interaction, expanded pH, solvent and thermal stability as well as reusability of the FPSE membrane.
                  Optimization was centered on the evaluation of critical parameters, namely the size of the FPSE membrane, the elution solvent mixture, the volume of the sample, the extraction time, the elution time, the kind of the external agitation mechanical stimulus, the ionic strength and the pH of the sample. The chromatographic separation was achieved on a Spherisorb C18 column and a gradient elution program with mobile phase consisted of 0.05 ammonium acetate solution and acetonitrile. The total analysis time was 17.4 min. The developed method was validated in terms of linearity, sensitivity, selectivity, precision, accuracy, stability, and ruggedness. The limits of detection and quantification varied from 0.26–0.62 ng/mL and 0.8–1.9 ng/mL, respectively. The relative recoveries were calculated between 90.6 and 108.8%, while the RSD values were <10% in all cases. The effectiveness of the proposed method was confirmed by its successful implementation in the bioanalysis of real urine samples.",science
10.1016/j.displa.2021.102023,Journal,Displays,scopus,2021-07-01,sciencedirect,T-GAN: A deep learning framework for prediction of temporal complex networks with adaptive graph convolution and attention mechanism,https://api.elsevier.com/content/abstract/scopus_id/85106549218,"Complex network is graph network with non-trivial topological features often occurring in real systems, such as video monitoring networks, social networks and sensor networks. While there is growing research study on complex networks, the main focus has been on the analysis and modeling of large networks with static topology. Predicting and control of temporal complex networks with evolving patterns are urgently needed but have been rarely studied. In view of the research gaps we are motivated to propose a novel end-to-end deep learning based network model, which is called temporal graph convolution and attention (T-GAN) for prediction of temporal complex networks. To joint extract both spatial and temporal features of complex networks, we design new adaptive graph convolution and integrate it with Long Short-Term Memory (LSTM) cells. An encoder-decoder framework is applied to achieve the objectives of predicting properties and trends of complex networks. And we proposed a dual attention block to improve the sensitivity of the model to different time slices. Our proposed T-GAN architecture is general and scalable, which can be used for a wide range of real applications. We demonstrate the applications of T-GAN to three prediction tasks for evolving complex networks, namely, node classification, feature forecasting and topology prediction over 6 open datasets. Our T-GAN based approach significantly outperforms the existing models, achieving improvement of more than 4.7% in recall and 25.1% in precision. Additional experiments are also conducted to show the generalization of the proposed model on learning the characteristic of time-series images. Extensive experiments demonstrate the effectiveness of T-GAN in learning spatial and temporal feature and predicting properties for complex networks.",science
10.1016/j.measurement.2021.109528,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-07-01,sciencedirect,A molecular sensing method integrated with support vector machines to characterize asphalt mixtures,https://api.elsevier.com/content/abstract/scopus_id/85105846445,"Modern and heterogeneous asphalt mixtures are usually produced using various kinds of modifiers such as rubber, polymer, and fiber. These materials are incorporated to improve sustainability and reduce the extent and severity of distresses such as rutting and low-temperature cracking. Currently, there is a lack of a robust real-time method for the identification of these additives in mixtures. In this research, a portable molecular sensing technology is integrated with machine learning (ML) to characterize asphalt binders modified with ground tire rubber (GTR) and asphalt mixtures containing different amounts of recycled materials. A database containing several near-infrared (NIR) spectra for binder and asphalt mixture samples are used to develop the ML-based detection models. The acceptable accuracy reported in this study implies that the proposed integrated NIR and ML approach can be used as a promising tool to differentiate and classify various types of asphalt binders and mixtures. This monitoring and data collection framework can contribute to improved sustainability via accelerating and optimizing the construction material detection and selection process throughout the pavement life. Furthermore, the expensive and cumbersome process of binder extraction and recovery could be avoided using the proposed method.",science
10.1016/j.compbiomed.2021.104450,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,A comprehensive review and analysis of supervised-learning and soft computing techniques for stress diagnosis in humans,https://api.elsevier.com/content/abstract/scopus_id/85105598718,"Stress is the most prevailing and global psychological condition that inevitably disrupts the mood and behavior of individuals. Chronic stress may gravely affect the physical, mental, and social behavior of victims and consequently induce myriad critical human disorders. Herein, a review has been presented where supervised learning (SL) and soft computing (SC) techniques used in stress diagnosis have been meticulously investigated to highlight the contributions, strengths, and challenges faced in the implementation of these methods in stress diagnostic models. A three-tier review strategy comprising of manuscript selection, data synthesis, and data analysis was adopted. The issues in SL strategies and the potential possibility of using hybrid techniques in stress diagnosis have been intensively investigated. The strengths and weaknesses of different SL (Bayesian classifier, random forest, support vector machine, and nearest neighbours) and SC (fuzzy logic, nature-inspired, and deep learning) techniques have been presented to obtain clear insights into these optimization strategies. The effects of social, behavioral, and biological stresses have been highlighted. The psychological, biological, and behavioral responses to stress have also been briefly elucidated. The findings of the study confirmed that different types of data/signals (related to skin temperature, electro-dermal activity, blood circulation, heart rate, facial expressions, etc.) have been used in stress diagnosis. Moreover, there is a potential scope for using distinct nature-inspired computing techniques (Genetic Algorithm, Particle Swarm Optimization, Ant Colony Optimization, Whale Optimization Algorithm, Butterfly Optimization, Harris Hawks Optimizer, and Crow Search Algorithm) and deep learning techniques (Deep-Belief Network, Convolutional-Neural Network, and Recurrent-Neural Network) on multimodal data compiled using behavioral testing, electroencephalogram signals, finger temperature, respiration rate, pupil diameter, galvanic-skin-response, and blood pressure. Likewise, there is a wider scope to investigate the use of SL and SC techniques in stress diagnosis using distinct dimensions such as sentiment analysis, speech recognition, handwriting recognition, and facial expressions. Finally, a hybrid model based on distinct computational methods influenced by both SL and SC techniques, adaption, parameter tuning, and the use of chaos, levy, and Gaussian distribution may address exploration and exploitation issues. However, factors such as real-time data collection, bias, integrity, multi-dimensional data, and data privacy make it challenging to design precise and innovative stress diagnostic systems based on artificial intelligence.",science
10.1016/j.compbiomed.2021.104448,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,High precision in microRNA prediction: A novel genome-wide approach with convolutional deep residual networks,https://api.elsevier.com/content/abstract/scopus_id/85105586824,"MicroRNAs (miRNAs) are small non-coding RNAs that have a key role in the regulation of gene expression. The importance of miRNAs is widely acknowledged by the community nowadays and computational methods are needed for the precise prediction of novel candidates to miRNA. This task can be done by searching homologous with sequence alignment tools, but results are restricted to sequences that are very similar to the known miRNA precursors (pre-miRNAs). Besides, a very important property of pre-miRNAs, their secondary structure, is not taken into account by these methods. To fill this gap, many machine learning approaches were proposed in the last years. However, the methods are generally tested in very controlled conditions. If these methods were used under real conditions, the false positives increase and the precisions fall quite below those published. This work provides a novel approach for dealing with the computational prediction of pre-miRNAs: a convolutional deep residual neural network (mirDNN). This model was tested with several genomes of animals and plants, the full-genomes, achieving a precision up to 5 times larger than other approaches at the same recall rates. Furthermore, a novel validation methodology was used to ensure that the performance reported in this study can be effectively achieved when using mirDNN in novel species. To provide fast an easy access to mirDNN, a web demo is available at http://sinc.unl.edu.ar/web-demo/mirdnn/. The demo can process FASTA files with multiple sequences to calculate the prediction scores and generates the nucleotide importance plots.
               
                  Full source code
                  
                     http://sourceforge.net/projects/sourcesinc/files/mirdnn and https://github.com/cyones/mirDNN.
               
                  Contact
                  
                     gstegmayer@sinc.unl.edu.ar.",science
10.1016/j.rser.2021.110969,Journal,Renewable and Sustainable Energy Reviews,scopus,2021-07-01,sciencedirect,Intelligent building control systems for thermal comfort and energy-efficiency: A systematic review of artificial intelligence-assisted techniques,https://api.elsevier.com/content/abstract/scopus_id/85103719088,"Building operations represent a significant percentage of the total primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for improved thermal comfort. Reducing the associated energy consumption while maintaining comfortable conditions in buildings are conflicting objectives and represent a typical optimization problem that requires intelligent system design. Over the last decade, different methodologies based on the Artificial Intelligence (AI) techniques have been deployed to find the sweet spot between energy use in HVAC systems and suitable indoor comfort levels to the occupants. This paper performs a comprehensive and an in-depth systematic review of AI-based techniques used for building control systems by assessing the outputs of these techniques, and their implementations in the reviewed works, as well as investigating their abilities to improve the energy-efficiency, while maintaining thermal comfort conditions. This enables a holistic view of (1) the complexities of delivering thermal comfort to users inside buildings in an energy-efficient way, and (2) the associated bibliographic material to assist researchers and experts in the field in tackling such a challenge. Among the 20 AI tools developed for both energy consumption and comfort control, functions such as identification and recognition patterns, optimization, predictive control. Based on the findings of this work, the application of AI technology in building control is a promising area of research and still an ongoing, i.e., the performance of AI-based control is not yet completely satisfactory. This is mainly due in part to the fact that these algorithms usually need a large amount of high-quality real-world data, which is lacking in the building or, more precisely, the energy sector. Based on the current study, from 1993 to 2020, the application of AI techniques and personalized comfort models has enabled energy savings on average between 21.81 and 44.36%, and comfort improvement on average between 21.67 and 85.77%. Finally, this paper discusses the challenges faced in the use of AI for energy productivity and comfort improvement, and opens main future directions in relation with AI-based building control systems for human comfort and energy-efficiency management.",science
10.1016/j.ins.2021.01.013,Journal,Information Sciences,scopus,2021-07-01,sciencedirect,Attributed community search based on effective scoring function and elastic greedy method,https://api.elsevier.com/content/abstract/scopus_id/85101624086,"In recent years, with the proliferation of rich attribute information available for entities in real-world networks and the increasing demand for more personalized community searches, attributed community search (ACS), an upgraded version of the community search problem, has attracted great attention from the both academic and industry areas. Some algorithms have been proposed to solve this novel research problem. However, they have a deficiency in evaluating the quality of the attributed community structure, which may mislead them and discover less valuable structures. In this paper, we make up for this defect, and propose the SFEG algorithm to better solve the ACS problem. SFEG designs a more effective scoring function to measure the quality of the discovered attributed community structure, and presents an elastic greedy optimization method to quickly maximize the function value to determine the target community with a specific meaning. The extensive experiments conducted on the attributed graph datasets with ground-truth communities show that our algorithm significantly outperforms the state-of-the-art.",science
10.1016/j.eswa.2021.114708,Journal,Expert Systems with Applications,scopus,2021-07-01,sciencedirect,Classification of hyperspectral imagery using a fully complex-valued wavelet neural network with deep convolutional features,https://api.elsevier.com/content/abstract/scopus_id/85101529343,"The number of spectral bands obtained by hyperspectral sensors improves the ability to distinguish physical objects and materials. But it also brings new challenges to image classification and analysis. In this study, a novel deep learning-based hybrid model called CNN-CVWNN is presented for the hyperspectral images classification (HSIs). The model uses a convolutional neural network (CNN) to extract multilayer image representation and uses the complex valued wavelet neural network (CVWNN) to classify the image using extracted features. The process steps of the proposed method are briefly as follows. First of all, the CNN algorithm has been applied to hyperspectral images. After this stage, efficient features have been obtained. These extracted features were then converted into a complex-valued number format using a novel random based transformation method. Thus, a novel complex-valued attribute set has been obtained for the HSI classification. The obtained features have been presented as input to the CVWNN algorithm. The hybrid method replaces real valued neural network inside CNN with CVWNN to enhance robustness and generalization of CNN. The experiments have been carried out on three data sets consisted of three popular hyperspectral airborne images. The developed method increases classification accuracy compared to other classification approaches.",science
10.1016/j.tele.2021.101583,Journal,Telematics and Informatics,scopus,2021-07-01,sciencedirect,Improving evidence-based assessment of players using serious games,https://api.elsevier.com/content/abstract/scopus_id/85101178082,"Serious games are highly interactive systems which can therefore capture large amounts of player interaction data. This data can be analyzed to provide a deep insight into the effect of the game on its players. However, traditional techniques to assess players of serious games make little use of interaction data, relying instead on costly external questionnaires. We propose an evidence-based process to improve the assessment of players by using their interaction data. The process first combines player interaction data and traditional questionnaires to derive and refine game learning analytics variables, which can then be used to predict the effects of the game on its players. Once the game is validated, and suitable prediction models have been built, the prediction models can be used in large-scale deployments to assess players solely based on their interactions, without the need for external questionnaires. We briefly describe two case studies where this combination of traditional questionnaires and data mining techniques has been successfully applied. The evidence-based assessment process proposed radically simplifies the deployment and application of serious games in real class settings.",science
10.1016/j.chemolab.2021.104314,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-06-15,sciencedirect,A scalable approach for the efficient segmentation of hyperspectral images,https://api.elsevier.com/content/abstract/scopus_id/85105360467,"The number of applications of hyperspectral imaging (HSI) is steadily increasing, as technology evolves and cameras become more affordable. However, the volume of data in a hyperspectral image is large (order of Gigabytes) and standard off-the-shelf algorithms for multi-channel image analysis cannot be readily applied, due to the prohibitive computational time and large memory requirements. Therefore, new scalable approaches are required to perform hyperspectral image analysis. In this article we address an efficient methodology for conducting Unsupervised Image Segmentation – one of the basic and most fundamental image analysis operations. In the methodology proposed, unsupervised segmentation is conducted after transforming the spectral and spatial dimensions of the raw hyperspectral image into a more compact representation using multivariate and multiresolution techniques. The clusters identified in the compact image representation are then used to train a discriminative classifier. The classifier is then adapted and transferred for application to the raw image, where it will efficiently label all the original pixels. With the proposed methodology, the computational expensive operations (unsupervised clustering and classifier learning) are minimized, whereas the efficient implementation of the classifier guarantees the analysis at the native resolution. The effectiveness of the proposed methodology was tested on a real case study considering an industrial hyperspectral image capturing the reflectance spectrum for several objects made of different unknown materials. A significant reduction in the computational cost was achieved without compromising the quality of the unsupervised segmentation, demonstrating the potential of the proposed approach.",science
10.1016/j.chemolab.2021.104325,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-06-15,sciencedirect,Extended Gaussian mixture regression for forward and inverse analysis,https://api.elsevier.com/content/abstract/scopus_id/85104927275,"In molecular, material, and process designs, it is important to perform inverse analysis of the regression models constructed with machine learning using target values of the properties and activities. Although many approaches actually employ a pseudo-inverse analysis, Gaussian mixture regression (GMR) can achieve direct inverse analysis. This paper describes the development and use of extended GMR (EGMR), which offers improved predictive ability over conventional GMR. EGMR includes implementations of both GMR and Bayesian GMR, which is based on a variational Bayesian method. The hyperparameters for each model are optimized, and the choice of model for the specific data is determined, through cross-validation. The effectiveness of the proposed EGMR is verified using numerically simulated datasets, compound datasets, a material dataset, and spectral datasets. These datasets contain real data. The predictive ability of EGMR is found to be greater than or equal to that of GMR in all cases, and the prediction errors can be reduced by more than 30%. Furthermore, it is confirmed that EGMR can perform inverse analysis with high reproducibility, even in the extrapolation region of an objective variable. The Python code for EGMR is available at https://github.com/hkaneko1985/dcekit.",science
10.1016/j.eswa.2021.114563,Journal,Expert Systems with Applications,scopus,2021-06-15,sciencedirect,Two-stage approach to feature set optimization for unsupervised dataset with heterogeneous attributes,https://api.elsevier.com/content/abstract/scopus_id/85100673747,"Unsupervised feature selection (UFS) is utilized in various application domains, such as data mining, pattern recognition, machine learning, etc. UFS follows three basic approaches, namely filter, wrapper, and hybrid (that is, a combination of both filter and wrapper) to select the relevant and non-redundant features. It has been observed that a filter method does not guarantee an optimal solution. However, a wrapper approach is computationally expensive. The hybrid method are known to give a better trade-off between filter and wrapper strategies. But, the practical applicability of schemes mentioned above are preferably restricted only to a numerical dataset and are not so suitable for a mixed dataset. Therefore, there is a need for a UFS scheme which can handle both the numerical and non-numerical features directly. In this paper, a robust and efficient two-phase (i.e., feature ranking (FR) and feature selection (FS)) UFS method is proposed. The proposed FR utilizes entropy and mutual information to produce maximum informative and non-redundant ranked features from a high-dimensional mixed dataset. Further, the proposed FS follows k-prototype clustering algorithm with improved Callinski-Harasbaz criteria-based selection methodology to choose optimal features. Experiments on real-life dataset substantiate that the proposed approach provides a better subset of features compared to the existing state of the art approaches.",science
10.1016/j.dib.2021.107127,Journal,Data in Brief,scopus,2021-06-01,sciencedirect,H2020 project CAPTOR dataset: Raw data collected by low-cost MOX ozone sensors in a real air pollution monitoring network,https://api.elsevier.com/content/abstract/scopus_id/85106384559,"The H2020 CAPTOR project deployed three testbeds in Spain, Italy and Austria with low-cost sensors for the measurement of tropospheric ozone (O3). The aim of the H2020 CAPTOR project was to raise public awareness in a project focused on citizen science. Each testbed was supported by an NGO in charge of deciding how to raise citizen awareness according to the needs of each country. The data presented in this document correspond to the raw data captured by the sensor nodes in the Spanish testbed using SGX Sensortech MICS 2614 metal-oxide sensors. The Spanish testbed consisted of the deployment of twenty-five nodes. Each sensor node included four SGX Sensortech MICS 2614 ozone sensors, one temperature sensor and one relative humidity sensor. Each node underwent a calibration process by co-locating the node at an EU reference air quality monitoring station, followed by a deployment in a sub-urban or rural area in Catalonia, Spain. All nodes spent two to three weeks co-located at a reference station in Barcelona, Spain (urban area), followed by two to three weeks co-located at three sub-urban reference stations near the final deployment site. The nodes were then deployed in volunteers' homes for about two months and, finally, the nodes were co-located again at the sub-urban reference stations for two weeks for final calibration and assessment of potential drifts. All data presented in this paper are raw data taken by the sensors that can be used for scientific purposes such as calibration studies using machine learning algorithms, or once the concentration values of the nodes are obtained, they can be used to create tropospheric ozone pollution maps with heterogeneous data sources (reference stations and low-cost sensors).",science
10.1016/S2589-7500(21)00005-4,Journal,The Lancet Digital Health,scopus,2021-06-01,sciencedirect,Health information technology and digital innovation for national learning health and care systems,https://api.elsevier.com/content/abstract/scopus_id/85106359380,"Health information technology can support the development of national learning health and care systems, which can be defined as health and care systems that continuously use data-enabled infrastructure to support policy and planning, public health, and personalisation of care. The COVID-19 pandemic has offered an opportunity to assess how well equipped the UK is to leverage health information technology and apply the principles of a national learning health and care system in response to a major public health shock. With the experience acquired during the pandemic, each country within the UK should now re-evaluate their digital health and care strategies. After leaving the EU, UK countries now need to decide to what extent they wish to engage with European efforts to promote interoperability between electronic health records. Major priorities for strengthening health information technology in the UK include achieving the optimal balance between top-down and bottom-up implementation, improving usability and interoperability, developing capacity for handling, processing, and analysing data, addressing privacy and security concerns, and encouraging digital inclusivity. Current and future opportunities include integrating electronic health records across health and care providers, investing in health data science research, generating real-world data, developing artificial intelligence and robotics, and facilitating public–private partnerships. Many ethical challenges and unintended consequences of implementation of health information technology exist. To address these, there is a need to develop regulatory frameworks for the development, management, and procurement of artificial intelligence and health information technology systems, create public–private partnerships, and ethically and safely apply artificial intelligence in the National Health Service.",science
10.1016/j.addma.2021.101986,Journal,Additive Manufacturing,scopus,2021-06-01,sciencedirect,Using feedback control of thermal history to improve quality consistency of parts fabricated via large-scale powder bed fusion,https://api.elsevier.com/content/abstract/scopus_id/85105692336,"Process inconsistency in additive manufacturing (AM) leads to irregular quality of the final parts and obstructs its broader adoption in critical structural parts manufacturing. Especially in the manufacture of sizable components, detecting process changes in a real-time and accurate manner for potential corrective operations is crucial. This study aims to develop a feedback control system to reduce inconsistent part quality caused by heat accumulation differences. There are two significant challenges. 1) Thermal images suffer from a low signal-to-noise ratio. 2) Discrete local sintering information should be able to indicate the adjustments to the global temperature field. To tackle these challenges, a feedback model based on a multi-input neural network is proposed to evaluate the sintering status accurately by integrating the thermal history and process features. Subsequently, a layerwise feedback control strategy is proposed to process the discrete sintering status into the variation trend of part quality and ensure that the material has the desired thermal history during sintering. A controlled experiment is used to demonstrate the effectiveness of the proposed approach compared with its traditional counterparts, and the result illustrates the elimination of differences in heat accumulation by the proposed method.",science
10.1016/j.comcom.2021.04.026,Journal,Computer Communications,scopus,2021-06-01,sciencedirect,Adversarial attacks on a lexical sentiment analysis classifier,https://api.elsevier.com/content/abstract/scopus_id/85105035567,"Social media has become a relevant information source for several decision-making processes and for the definition of business strategies. As various sentiment analysis techniques are used to transform collected data into intelligence information, the sentiment classifiers used in these collection environments must be carefully studied and observed before being considered trustful and ready to be installed in decision support systems. An important research area concerns the robustness of sentiment classifiers in view of new adversarial attacks, in which small perturbations may be created by malicious users to deceive the sentiment classifiers, generating a perception different from the one that should be observed in the environment. Thus, it is important to identify and analyze the vulnerabilities of these classifiers under different strategies of adversarial attacks to propose countermeasures that can be used to mitigate such attacks. In this context, this work presents adversarial attacks related to a lexical natural language classifier. Being the target of the attacks, this classifier is used to calculate the sentiment of collected data as posted by users in various social media applications. The results indicate that the found vulnerabilities, if exploited by malicious users in applications that use the same lexical classifier, could invert or cancel the classifiers’ perception, thus generating perceptions that do not correspond to the reality for decision making. This work also proposes some countermeasures that might mitigate the implemented attacks.",science
10.1016/j.scs.2021.102801,Journal,Sustainable Cities and Society,scopus,2021-06-01,sciencedirect,"Smart and sustainable logistics of Port cities: A framework for comprehending enabling factors, domains and goals",https://api.elsevier.com/content/abstract/scopus_id/85104756448,"Digital technologies integrated into port logistics are becoming increasingly decisive among port cities around the world. This growing importance is due to the need for policymakers, urban managers, port authorities, local administrators, shipping companies, couriers, and so on to develop increasingly digitalized and sustainable logistic processes. Therefore, in a global context characterized by intense datafication and globalization of trade, the data-based approach has become a necessary modus operandi to promote smart and sustainable logistics development. This forward-looking model of port logistics uses technologies such as IoT, sensors, cloud computing platforms, Big Data analytics, Artificial Intelligence (AI), GPS tracking systems, radars, drones, real-time monitoring stations, smart grids, and so on in order to collect, process, monitor and analyse data and information concerning the economic, environmental, social and technological sphere of port cities. In this sense, mobile and fixed platforms help logistics operators to optimize the management of flows (e.g., water, waste, emissions, raw materials, people, monetary investments, etc.) in an efficient and digitized manner. The study proposes a systematic literature review of the most recurring themes concerning smart and sustainable logistics initiatives within port cities in order to develop a multidimensional framework capable of holistically integrating the prevailing enabling factors (Ecosystem, Internal Organization, Data and Security, Policy and Regulation, Finance and Funding, and Digital and Technology), domains (Mobility, Environment, Economy, Telecommunications, Safety and Security, Government, and Community) and goals (Sustainable Development and Digitalization) that characterize smart and sustainable logistical development. To this end, the best practices of several pioneering port cities such as Rotterdam, Hamburg, Singapore, Los Angeles, Amsterdam, etc. implemented in partnerships with technology companies such as Cisco, IBM, Huawei and SAP were also analysed. Therefore, the results of this research show that smart and sustainable logistics initiatives in port cities: (a) have the potential to enhance the efficiency of the economic, environmental, social and technological flows; (b) increase the involvement and awareness of stakeholders such as couriers, shippers, shipping companies, citizens, port authorities, municipalities, security officers, gate and terminal personnel, and so on; and (c) provide a detailed overview of the enabling factors, domains and goals that must be activated by port cities to foster a smart and sustainable logistic transition.",science
10.1016/j.psep.2021.04.001,Journal,Process Safety and Environmental Protection,scopus,2021-06-01,sciencedirect,Multi-intelligent connected vehicle longitudinal collision avoidance control and exhaust emission evaluation based on parallel theory,https://api.elsevier.com/content/abstract/scopus_id/85104623018,"With the increasing of vehicle volume and driving speed, traffic accidents and environmental safety have become social concerns. Vehicle traffic accidents, especially multi-vehicle chain accidents, cause damage to property and human lives. Meanwhile, traffic pollution will lead to continuous harm to living environment and health. This is a coupled human-vehicle-environment interaction system, which is difficult to model with traditional mathematical methods. Parallel theory is an effective method to solve such complex problems based on advanced artificial intelligence and computer technology. In this paper, a parallel system is built to analyze and control multi-intelligent connected vehicle based on parallel theory. The parallel system is also used to analyze and assess the exhaust emission of multi-intelligent connected vehicle. The parallel system is carried out with three steps: 1) modeling and representation of multi-intelligent connected vehicle system using artificial societies; 2) analysis and evaluation by computational experiments; 3) control, management and exhaust emission evaluation through parallel execution of real and artificial systems and big data. The parallel control methods, models and conclusions obtained from this paper can be used to enhance the experience of safety in multi-vehicle control under vehicle to everything environment and make the safety intervention measures more efficient.",science
10.1016/j.sysarc.2021.102139,Journal,Journal of Systems Architecture,scopus,2021-06-01,sciencedirect,Tracking and analysing social interactions in dairy cattle with real-time locating system and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85104583225,"There is a need for reliable and efficient methods for monitoring the activity and social behaviour in cows, in order to optimise management in modern dairy farms. This research presents an embedded system that could track individual cows using Ultra-wideband technology. At the same time, social interactions between individuals around the feeding area were analysed with a computer vision module. Detections of the dairy cows’ negative and positive interactions were performed on foreground video stream using a Long-term Recurrent Convolution Networks model. The sensor fusion system was implemented and tested on seven dairy cows during 45 days in an experimental dairy farm. The system performance was evaluated at the feeding area. The real-time locating system based on Ultra-wideband technology reached an accuracy with mean error 0.39 m and standard deviation 0.62 m. The accuracy of detecting the affiliative and agonistic social interactions reached 93.2%. This study demonstrates a potential system for monitoring social interactions between dairy cows.",science
10.1016/j.scp.2021.100415,Journal,Sustainable Chemistry and Pharmacy,scopus,2021-06-01,sciencedirect,Green chemistry and coronavirus,https://api.elsevier.com/content/abstract/scopus_id/85104072773,"The novel coronavirus pandemic has rapidly spread around the world since December 2019. Various techniques have been applied in identification of SARS-CoV-2 or COVID-19 infection including computed tomography imaging, whole genome sequencing, and molecular methods such as reverse transcription polymerase chain reaction (RT-PCR). This review article discusses the diagnostic methods currently being deployed for the SARS-CoV-2 identification including optical biosensors and point-of-care diagnostics that are on the horizon. These innovative technologies may provide a more accurate, sensitive and rapid diagnosis of SARS-CoV-2 to manage the present novel coronavirus outbreak, and could be beneficial in preventing any future epidemics. Furthermore, the use of green synthesized nanomaterials in the optical biosensor devices could leads to sustainable and environmentally-friendly approaches for addressing this crisis.",science
10.1016/S2214-109X(21)00059-0,Journal,The Lancet Global Health,scopus,2021-06-01,sciencedirect,The injustice of unfit clinical practice guidelines in low-resource realities,https://api.elsevier.com/content/abstract/scopus_id/85103953372,"To end the international crisis of preventable deaths in low-income and middle-income countries, evidence-informed and cost-efficient health care is urgently needed, and contextualised clinical practice guidelines are pivotal. However, as exposed by indirect consequences of poorly adapted COVID-19 guidelines, fundamental gaps continue to be reported between international recommendations and realistic best practice. To address this long-standing injustice of leaving health providers without useful guidance, we draw on examples from maternal health and the COVID-19 pandemic. We propose a framework for how global guideline developers can more effectively stratify recommendations for low-resource settings and account for predictable contextual barriers of implementation (eg, human resources) as well as gains and losses (eg, cost-efficiency). Such development of more realistic clinical practice guidelines at the global level will pave the way for simpler and achievable adaptation at local levels. We also urge the development and adaptation of high-quality clinical practice guidelines at national and subnational levels in low-income and middle-income countries through co-creation with end-users, and we encourage global sharing of these experiences.",science
10.1016/j.conengprac.2021.104795,Journal,Control Engineering Practice,scopus,2021-06-01,sciencedirect,Predictive power-split system of hybrid ship propulsion for energy management and emissions reduction,https://api.elsevier.com/content/abstract/scopus_id/85103377640,"In this work, an energy management system to address the optimal power-split problem in hybrid ship propulsion is developed. The torque of the diesel engine and the electric machine is regulated based on a predictive strategy with a weighting factor which determines the trade-off between fuel consumption and NOx emissions minimization. The modeling for the controller design is based on first principles and data gathered from the hybrid plant. In addition a disturbance observer is designed to estimate the propeller load characteristics. A neural network model that predicts rotational speed reference within the prediction horizon complements the control system design. It is used along with the observer to calculate the future load demand. A parametric simulation study is performed for the trade-off evaluation between fuel consumption and NOx emissions reduction of the control scheme. The control scheme is experimentally implemented and tested in real-time operation, where it has to cope with environmental disturbance rejection and follow the desired rotational speed reference, while performing the power-split in respect to the fuel to NOx weighting parameter and operate the plant within the desirable constraints.",science
10.1016/j.scs.2021.102777,Journal,Sustainable Cities and Society,scopus,2021-06-01,sciencedirect,Social distance monitoring framework using deep learning architecture to control infection transmission of COVID-19 pandemic,https://api.elsevier.com/content/abstract/scopus_id/85103273639,"The recent outbreak of the COVID-19 affected millions of people worldwide, yet the rate of infected people is increasing. In order to cope with the global pandemic situation and prevent the spread of the virus, various unprecedented precaution measures are adopted by different countries. One of the crucial practices to prevent the spread of viral infection is social distancing. This paper intends to present a social distance framework based on deep learning architecture as a precautionary step that helps to maintain, monitor, manage, and reduce the physical interaction between individuals in a real-time top view environment. We used Faster-RCNN for human detection in the images. As the human's appearance significantly varies in a top perspective; therefore, the architecture is trained on the top view human data set. Moreover, taking advantage of transfer learning, a new trained layer is fused with a pre-trained architecture. After detection, the pair-wise distance between peoples is estimated in an image using Euclidean distance. The detected bounding box's information is utilized to measure the central point of an individual detected bounding box. A violation threshold is defined that uses distance to pixel information and determines whether two people violate social distance or not. Experiments are conducted using various test images; results demonstrate that the framework effectively monitors the social distance between peoples. The transfer learning technique enhances the overall performance of the framework by achieving an accuracy of 96% with a False Positive Rate of 0.6%.",science
10.1016/j.compchemeng.2021.107290,Journal,Computers and Chemical Engineering,scopus,2021-06-01,sciencedirect,Deeppipe: a customized generative model for estimations of liquid pipeline leakage parameters,https://api.elsevier.com/content/abstract/scopus_id/85103234691,"Considering the tremendous economic losses and human injury caused by pipeline leaks, it is critical to detect and locate the pipeline leakage in time. This work proposes a generative adversarial networks (GANs) framework for leak detection and localization from the perspective of data science instead of physical meaning. The GANs are designed by two powerful neural networks: generative (G) network and discriminative (D) network. Real experiments are performed to verify the effectiveness of the proposed GANs framework, confirming that it can be applied to pipeline leakages for the estimations of the location, coefficient, and the starting time. To qualify the performance of the approach, sensitivity analysis for the structure of the GANs framework is evaluated. Finally, the proposed generative model is validated by two pipeline leakages. The errors of these two examples are 3.9% and 3.5%, respectively, indicating that the proposed method is better than the improved PSO and ANN.",science
10.1016/j.swevo.2021.100868,Journal,Swarm and Evolutionary Computation,scopus,2021-06-01,sciencedirect,"Major Advances in Particle Swarm Optimization: Theory, Analysis, and Application",https://api.elsevier.com/content/abstract/scopus_id/85102857299,"Over the ages, nature has constantly been a rich source of inspiration for science, with much still to discover about and learn from. Swarm Intelligence (SI), a major branch of artificial intelligence, was rendered to model the collective behavior of social swarms in nature. Ultimately, Particle Swarm Optimization algorithm (PSO) is arguably one of the most popular SI paradigms. Over the past two decades, PSO has been applied successfully, with good return as well, in a wide variety of fields of science and technology with a wider range of complex optimization problems, thereby occupying a prominent position in the optimization field. However, through in-depth studies, a number of problems with the algorithm have been detected and identified; e.g., issues regarding convergence, diversity, and stability. Consequently, since its birth in the mid-1990s, PSO has witnessed a myriad of enhancements, extensions, and variants in various aspects of the algorithm, specifically after the twentieth century, and the related research has therefore now reached an impressive state. In this paper, a rigorous yet systematic review is presented to organize and summarize the information on the PSO algorithm and the developments and trends of its most basic as well as of some of the very notable implementations that have been introduced recently, bearing in mind the coverage of paradigm, theory, hybridization, parallelization, complex optimization, and the diverse applications of the algorithm, making it more accessible. Ease for researchers to determine which PSO variant is currently best suited or to be invented for a given optimization problem or application. This up-to-date review also highlights the current pressing issues and intriguing open challenges haunting PSO, prompting scholars and researchers to conduct further research both on the theory and application of the algorithm in the forthcoming years.",science
10.1016/j.biopha.2021.111515,Journal,Biomedicine and Pharmacotherapy,scopus,2021-06-01,sciencedirect,Alterations in neurotransmitter levels and transcription factor expression following intranasal buprenorphine administration,https://api.elsevier.com/content/abstract/scopus_id/85102839676,"Buprenorphine is an opioid drug used in the management of pain and the treatment opioid addiction. Like other opioids, it is believed that it achieves these effects by altering functional neurotransmitter pathways and the expression of important transcription factors; cyclic AMP response element-binding protein (CREB) and brain-derived neurotrophic factor (BDNF) in the brain. However, there is a lack of scientific evidence to support these theories. This study investigated the pharmacodynamic effects of BUP administration by assessing neurotransmitter and molecular changes in the healthy rodent brain. Sprague-Dawley rats (150–200 g) were intranasally administered buprenorphine (0.3 mg/mL) and sacrificed at different time points: 0.25, 0.5, 1, 2, 4, 6, 8 and 24 h post drug administration. LC-MS was used to quantify BUP and neurotransmitters (GABA, GLUT, DA, NE and 5-HT) in the brain, while CREB and BDNF gene expression was determined using qPCR. Results showed that BUP reached a Cmax of 1.21 ± 0.0523 ng/mL after 2 h, with all neurotransmitters showing an increase in their concentration over time, with GABA, GLUT and NE reaching their maximum concentration after 8 h. DA and 5-HT reached their maximum concentrations at 1 h and 24 h, respectively post drug administration. Treatment with BUP resulted in significant upregulation in BDNF expression throughout the treatment period while CREB showed patterns of significant upregulation at 2 and 8 h, and downregulation at 1 and 6 h. This study contributes to the understanding of the pharmacodynamic effects of BUP in opioid addiction by proving that the drug significantly influences NT pathways that are implicated in opioid addiction.",science
10.1016/j.jviromet.2021.114128,Journal,Journal of Virological Methods,scopus,2021-06-01,sciencedirect,Quantitative detection of human adenovirus from river water by monolithic adsorption filtration and quantitative PCR,https://api.elsevier.com/content/abstract/scopus_id/85102586694,"Water contaminated with fecally derived viruses, also known as enteric viruses, represents a particularly high risk for human health. However, they have not been included in water quality regulations yet. The detection of these viruses is often more expensive and time-consuming compared to the analysis of conventional fecal indicator organisms. In addition, most methods are not sensitive enough to detect small viral loads that may already cause serious health issues if present in water. In this study, we established a workflow for the successful and direct enrichment of human adenovirus (HAdV) from artificially contaminated river water based on monolithic adsorption filtration (MAF) and quantitative polymerase reaction (qPCR). With a clear focus on efficiency, we used targeted synthetic DNA fragments as standard for the quantification of HAdV by qPCR, leading to accurate and robust results with a qPCR efficiency of 95 %, a broad working range over 6 orders of magnitude and an LOD of 1 GU/μL. We carried out a cascade of spiking experiments, enhancing the complexity of the spiking matrix with each step to progressively evaluate MAF for the direct concentration of HAdV. We found that negatively charged MAF using monoliths with hydroxyl groups (MAF−OH) showed a better reproducibility and a significantly faster turnaround time than skimmed milk flocculation (SMF) when concentrating HAdV35 from artificially contaminated, acidified mineral water. We then validated positively charged MAF using monoliths with diethyl aminoethyl groups (MAF-DEAE) for the direct concentration of HAdV5 without pre-conditioning of water samples using tap water as spiking matrix with a less defined and controlled water chemistry. Finally, we evaluated MAF-DEAE for the direct concentration of HAdV5 from surface water using river water as representative matrix with an undefined water chemistry. We found, that MAF-DEAE achieved reproducible recoveries of HAdV5, independently of the spiked concentration level or sample volume. Furthermore, we showed, that MAF-DEAE drastically reduced the limit of detection (LOD) of HAdV5 by a factor of 115 from 6.0 ∙ 103 GU/mL before to 5.2 ∙ 101 GU/mL after MAF-DEAE. We identified that recoveries increased for smaller processing volumes with a peak at 0.5 L of 84.0 % and showed that recovery efficiency depends on sample volume and matrix type. The here presented workflow based on MAF-DEAE and qPCR offers an easy-to-implement and highly efficient alternative to existing approaches and allows for a fast detection of HAdV in water.",science
10.1016/j.asoc.2021.107213,Journal,Applied Soft Computing,scopus,2021-06-01,sciencedirect,Cross-platform dynamic goods recommendation system based on reinforcement learning and social networks,https://api.elsevier.com/content/abstract/scopus_id/85102077222,"Aiming at the problems of cold start, gray sheep and sparsity of the traditional collaborative filtering recommendation system, this paper proposes a cross-platform dynamic goods recommendation system based on reinforcement learning and edge computing. First of all, this system models the current friendship relationship networks and potential friendship relationship networks, it also constructs two layers preference prediction models. Then, we consider the frequent change characteristic of social networks and shopping platforms, we design a dynamic reinforcement learning method and edge computing to learn the minimized entropy loss error. Finally, we finish the validation experiments based on the real datasets, the results show the proposed system realizes better link prediction accuracy, and using our proposed system can obtain an obvious increase in the accuracy compared to the existing of collaborative filtering recommendation systems.",science
10.1016/j.asoc.2021.107188,Journal,Applied Soft Computing,scopus,2021-06-01,sciencedirect,Semi-supervised regression using diffusion on graphs,https://api.elsevier.com/content/abstract/scopus_id/85101385263,"In real-world machine learning applications, unlabeled training data are readily available, but labeled data are expensive and hard to obtain. Therefore, semi-supervised learning algorithms have gathered much attention. Previous studies in this area mainly focused on a semi-supervised classification problem, whereas semi-supervised regression has received less attention. In this paper, we proposed a novel semi-supervised regression algorithm using heat diffusion with a boundary-condition that guarantees a closed-form solution. Experiments from artificial and real datasets from business, biomedical, physical, and social domain show that the boundary-based heat diffusion method can effectively outperform the top state of the art methods.",science
10.1016/j.asoc.2021.107175,Journal,Applied Soft Computing,scopus,2021-06-01,sciencedirect,A real-time hostile activities analyses and detection system,https://api.elsevier.com/content/abstract/scopus_id/85101111750,"Over recent years, the development of online social media has dramatically changed the way people connect and share information. It is undeniable that social platform has promoted the quickest type of spread for fake stories. Almost all the current online fact-checking sources and researches are concentrating on the validating political content and context. The proposed system in this paper provides a complete visual data analytics methods to assist users in achieving a comprehensive understanding of malicious activities at multiple levels such as adversary’s behavior, victim’s behavior, content, and context level. In this paper, we investigate a variety of datasets from different aspects such as role, vulnerabilities, influential level, and distribution pattern. The proposed method in this paper focuses on automatic fake/hostile activity detection by utilizing a variety of machine learning (ML) techniques, deep learning models, natural language processes (NLP), and social network analysis (SNA) techniques. Different auxiliary models, such as bot detection, user credibility, and text readability, are deployed to generate additional influential features. The classification performance of ten different machine learning algorithms using a variety of well-known datasets is evaluated by utilizing 10-fold cross-validation.",science
10.1016/j.energy.2021.120109,Journal,Energy,scopus,2021-06-01,sciencedirect,Prediction of solar energy guided by pearson correlation using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85101063162,"Solar energy forecasting represents a key element in increasing the competitiveness of solar power plants in the energy market and reducing the dependence on fossil fuels in economic and social development. This paper presents an approach for predicting solar energy, based on machine and deep learning techniques. The relevance of the studied models was evaluated for real-time and short-term solar energy forecasting to ensure optimized management and security requirements in this field while using an integral solution based on a single tool and an appropriate predictive model. The datasets we used in this study, represent data from 2016 to 2018 and are related to Errachidia which is a semi-desert climate province in Morocco. Pearson correlation coefficient was deployed to identify the most relevant meteorological inputs from which the models should learn. RF and ANN have provided high accuracies against LR and SVR, which have reported very significant errors. ANN has shown good performance for both real-time and short-term predictions. The key findings were compared with Pirapora in Brazil, which is a tropical climate region, to show the quality and reproducibility of the study.",science
10.1016/j.ins.2020.12.080,Journal,Information Sciences,scopus,2021-06-01,sciencedirect,Rumor2vec: A rumor detection framework with joint text and propagation structure representation learning,https://api.elsevier.com/content/abstract/scopus_id/85101056591,"Rumors often yield adverse societal and economic impacts. Therefore, rumor detection has attracted a surge of research interests. Existing methods mainly focus on finding clues from textual contents, which is not quite effective as rumors can be intentionally manipulated. Recent studies have demonstrated that the propagation structure of rumors can significantly improve rumor detection performance. However, propagation-based methods are still limited as the propagation structure is often sparse at an early stage. In this study, we propose Rumor2vec, a novel rumor detection framework with joint text and propagation structure representation learning. First, we present the concept of the union graph to incorporate propagation structures of all tweets to mitigate the sparsity issue. Then, we leverage network embedding to learn representations of nodes in the union graph. Finally, we propose a framework for rumor representation learning and detection. Experimental results on three real-world datasets demonstrate that our proposed framework can achieve better performance than the state-of-the-art approaches. On two Twitter datasets, our method achieves 79.6% and 85.2% accuracies respectively. On the Weibo dataset, our method achieves a 95.1% accuracy. Further experiments on early rumor detection show that our method can identify rumors ahead of other methods by at least 12 h.",science
10.1016/j.eswa.2021.114584,Journal,Expert Systems with Applications,scopus,2021-06-01,sciencedirect,Fusion loss and inter-class data augmentation for deep finger vein feature learning,https://api.elsevier.com/content/abstract/scopus_id/85100382720,"Finger vein recognition (FVR) based on deep learning (DL) has gained rising attention in recent years. However, the performance of FVR is limited by the insufficient amount of finger vein training data and the weak generalization of learned features. To address these limitations and improve the performance, we propose a simple framework by jointly considering intensive data augmentation, loss function design and network architecture selection. Firstly, we propose a simple inter-class data augmentation technique that can double the number of finger vein training classes with new vein patterns via vertical flipping. Then, we combine it with conventional intra-class data augmentation methods to achieve highly diversified expansion, thereby effectively resolving the data shortage problem. In order to enhance the discrimination of deep features, we design a fusion loss by incorporating the classification loss and the metric learning loss. We find that the fusion of these two penalty signals will lead to a good trade-off between the intra-class similarity and inter-class separability, thereby greatly improving the generalization ability of learned features. We also investigate various network architectures for FVR application in terms of performances and model complexities. To examine the reliability and efficiency of our proposed framework, we implement a real-time FVR system to perform end-to-end verification in a near-realworld working condition. In challenging open-set evaluation protocol, extensive experiments conducted on three public finger vein databases and an in-house database confirm the effectiveness of the proposed method.",science
10.1016/j.cja.2020.09.011,Journal,Chinese Journal of Aeronautics,scopus,2021-06-01,sciencedirect,Framework and development of data-driven physics based model with application in dimensional accuracy prediction in pocket milling,https://api.elsevier.com/content/abstract/scopus_id/85097765922,"In the manufacturing of thin wall components for aerospace industry, apart from the side wall contour error, the Remaining Bottom Thickness Error (RBTE) for the thin-wall pocket component (e.g. rocket shell) is of the same importance but overlooked in current research. If the RBTE reduces by 30%, the weight reduction of the entire component will reach up to tens of kilograms while improving the dynamic balance performance of the large component. Current RBTE control requires the off-process measurement of limited discrete points on the component bottom to provide the reference value for compensation. This leads to incompleteness in the remaining bottom thickness control and redundant measurement in manufacturing. In this paper, the framework of data-driven physics based model is proposed and developed for the real-time prediction of critical quality for large components, which enables accurate prediction and compensation of RBTE value for the thin wall components. The physics based model considers the primary root cause, in terms of tool deflection and clamping stiffness induced Axial Material Removal Thickness (AMRT) variation, for the RBTE formation. And to incorporate the dynamic and inherent coupling of the complicated manufacturing system, the multi-feature fusion and machine learning algorithm, i.e. kernel Principal Component Analysis (kPCA) and kernel Support Vector Regression (kSVR), are incorporated with the physics based model. Therefore, the proposed data-driven physics based model combines both process mechanism and the system disturbance to achieve better prediction accuracy. The final verification experiment is implemented to validate the effectiveness of the proposed method for dimensional accuracy prediction in pocket milling, and the prediction accuracy of AMRT achieves 0.014 mm and 0.019 mm for straight and corner milling, respectively.",science
10.1016/j.jep.2021.113943,Journal,Journal of Ethnopharmacology,scopus,2021-05-23,sciencedirect,"Xuesaitong exerts long-term neuroprotection for stroke recovery by inhibiting the ROCKII pathway, in vitro and in vivo",https://api.elsevier.com/content/abstract/scopus_id/85101738050,"Ethnopharmacological relevance
                  Xuesaitong (XST) is a traditional Chinese medicine injection with neuroprotective properties and has been extensively used to treat stroke for many years. The main component of XST is Panax notoginseng saponins (PNS), which is the main extract of the Chinese herbal medicine Panax notoginseng.
               
                  Aim of the study
                  In this study, we investigated whether XST provided long-term neuroprotection by inhibiting neurite outgrowth inhibitor-A (Nogo-A) and the ROCKII pathway in experimental rats after middle cerebral artery occlusion (MCAO) and in SH-SY5Y cells exposed to oxygen-glucose deprivation/reperfusion (OGD/R).
               
                  Materials and methods
                  Rats with permanent MCAO were administered XST, Y27632, XST plus Y27632, and nimodipine for 14 and 28 days. Successful MCAO onset was confirmed by 2,3,5-triphenyl tetrazolium chloride (TTC) staining. Neurological deficit score (NDS) was used to assess neurological impairment. Hematoxylin-eosin (HE) staining and immunohistochemical (IHC) analysis of synaptophysin (SYN) and postsynaptic density protein-95 (PSD-95) were performed to evaluate cerebral ischemic injury and the neuroprotective capability of XST. Nogo-A levels and the ROCKII pathway were detected by IHC analysis, western blotting, and quantitative real-time polymerase chain reaction (qRT-PCR) to explore the protective mechanism of XST. OGD/R model was established in SH-SY5Y cells. Cell counting kit 8 (CCK8) was applied to detect the optimum OGD time and XST concentration. The expression levels Nogo-A and ROCKII pathway were determined using western blotting.
               
                  Results
                  Our results showed that XST reduced neurological dysfunction and pathological damage, promoted weight gain and synaptic regeneration, reduced Nogo-A mRNA and protein levels, and inhibited the ROCKII pathway in MCAO rats. CCK8 assay displayed that the optimal OGD time and optimal XST concentration were 7 h and 20 μg/mL respectively in SH-SY5Y cells. XST could evidently inhibit OGD/R-induced Nogo-A protein expression and ROCKII pathway activation in SH-SY5Y cells.
               
                  Conclusions
                  The present study suggested that XST exerted long-term neuroprotective effects that assisted in stroke recovery, possibly through inhibition of the ROCKII pathway.",science
10.1016/j.jep.2021.113920,Journal,Journal of Ethnopharmacology,scopus,2021-05-23,sciencedirect,Pinoresinol diglucoside (PDG) attenuates cardiac hypertrophy via AKT/mTOR/NF-κB signaling in pressure overload-induced rats,https://api.elsevier.com/content/abstract/scopus_id/85101404055,"Ethnopharmacological relevance
                  Pinoresinol diglucoside (PDG), the active compound extracted from Eucommia ulmoides, Styrax sp. and Forsythia suspensa, plays the roles in regulating hypertension, inflammation and oxidative stress.
               
                  Aims
                  Considering that hypertension and inflammation has been proved to contribute to cardiac remodeling, we tested the effects of PDG on cardiac hypertrophy (CM).
               
                  Methods
                  Male Sprague Dawley (SD) rats were used to construct hypertrophic rats by partial abdominal aortic constriction (AAC)-surgery. PDG solution (2 mg/ml) was used to treat AAC-induced rats by intraperitoneal injection at low dose (L-PDG, 2.5 mg/kg per day), medium dose (M-PDG, 5 mg/kg per day), and high dose (H-PDG, 7.5 mg/kg per day) for 3 weeks post AAC-surgery. CM was evaluated by the ratio of left ventricular weight to body weight ratio (LVW/BW), left ventricular wall thickness by H&E staining, and collagen content deposit by Masson's staining. Further, isoproterenol (ISO) and phenylephrine (PE) were used to produce cellular models of CM in neonatal rat ventricular cardiomyocytes (NRVMs). PDG pre-treated NRVMs 2 h at low dose (L-PDG, 2.5 μg/ml), medium dose (M-PDG, 5 μg/ml), and high dose (H-PDG, 7.5 μg/ml) for 24 h with or without PE- and ISO-stimulation. CM was evaluated by the expressions of hypertrophic biomarkers. Next, the hypertrophic biomarkers and pro-inflammatory cytokines were measured using quantitative real-time PCR (qRT-PCR), the expressions of protein kinase B (AKT)/mammalian target of rapamycin (mTOR)/transcription factor nuclear factor-kappa B (NF-kB) signaling pathway were determined by Western blotting.
               
                  Results
                  PDG treatment prevented cardiac histomorphology damages, decreased upregulations of hypertrophic biomarkers, and prevented fibrosis and inflammation after pressure overload resulting from AAC-surgery. Consistently, PDG remarkably inhibited the changes of cardiomyocyte hypertrophic biomarkers and inflammatory responses in cellular models of CM. Interestingly, PDG administration inhibited the activation of AKT/mTOR/NF-kB signaling pathway both in vivo and in vitro.
               
                  Conclusions
                  PDG prevents AAC-induced CM in vivo, PE- and ISO-induced CM in vitro. The AKT/mTOR/NF-kB signaling pathway could be the potential therapeutic target involved in the protection of PDG. These findings provide novel evidence that PDG might be a promising therapeutic strategy for CM.",science
10.1016/j.bdr.2021.100217,Journal,Big Data Research,scopus,2021-05-15,sciencedirect,CSIP: Enhanced Link Prediction with Context of Social Influence Propagation,https://api.elsevier.com/content/abstract/scopus_id/85102463635,"Data mining in social networks brings an indispensable role for the construction of smart cities from the perspective of social development. Link prediction is an important task of data mining, especially in the knowledge graph, which is also called knowledge graph completion. Link prediction aims to find missing links or predict potential links according to the current social network. The most existing link prediction methods focus on static information in social networks, such as topology and node attributes, which are partly provided by users. When users are unwilling to provide or intentionally hide these static features, traditional link prediction methods cannot achieve ideal performance. The dynamic information of social influence propagation in social networks can avoid the user's subjective impact and better reflect the relationship between users. In addition, users show different degrees of interest and authority on various topics in the real world, leading to different influence propagation patterns. Therefore, we use context of social influence to optimize the topic-aware influence propagation model to improve the performance of link prediction. In this paper, we propose a new multi-output graph neural network framework to capture influence propagation in social networks and model the influence of users in different roles. In this way, the underlying information of influence between users can be used to construct new features to improve the performance of link prediction. Our experiments conduct the method on multiple benchmark datasets. The experimental results show that the modeling of context is effective, and our model outperforms the compared state-of-the-art link prediction methods.",science
10.1016/j.jenvman.2021.112233,Journal,Journal of Environmental Management,scopus,2021-05-15,sciencedirect,“Looking beneath the surface”: A visual-physical feature hybrid approach for unattended gauging of construction waste composition,https://api.elsevier.com/content/abstract/scopus_id/85101970009,"There are various scenarios challenging human experts to judge the interior of something based on limited surface information. Likewise, at waste disposal facilities around the world, human inspectors are often challenged to gauge the composition of waste bulks to determine admissibility and chargeable levy. Manual approaches are laborious, hazardous, and prone to carelessness and fatigue, making unattended gauging of construction waste composition using simple surface information highly desired. This research attempts to contribute to automated waste composition gauging by harnessing a valuable dataset from Hong Kong. Firstly, visual features, called visual inert probability (VIP), characterizing inert and non-inert materials are extracted from 1127 photos of waste bulks using a fine-tuned convolutional neural network (CNN). Then, these visual features together with easy-to-obtain physical features (e.g., weight and depth) are fed to a tailor-made support vector machine (SVM) model to determine waste composition as measured by the proportions of inert and non-inert materials. The visual-physical feature hybrid model achieved a waste composition gauging accuracy of 94% in the experiments. This high performance implies that the model, with proper adaption and integration, could replace human inspectors to smooth the operation of the waste disposal facilities.",science
10.1016/j.eswa.2020.114538,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Parallel versus cascaded logistic regression trained single-hidden feedforward neural network for medical data,https://api.elsevier.com/content/abstract/scopus_id/85098990261,"Objective
                  An important step towards a better healthcare system is fast and accurate diagnosis. In the last decade, the application of intelligent systems in healthcare has led to impressive results. The goal of this paper is to extend the LogSLFN (single-hidden layer feedforward neural network trained using logistic regression) algorithm, which has been deployed successfully in the past for the case of a two-class decision problem, to the case of multiple classes. We have considered and statistically analyzed two approaches: a parallel LogSLFN, and a cascaded LogSLFN.
               
                  Materials and methods
                  According to the universal approximation theorem, a single-hidden layer feedforward neural network has the ability to approximate arbitrarily closely continuous functions of several real variables under certain reasonable assumptions. Essentially, a single hidden layer containing a finite fixed number of neurons is sufficient to provide an arbitrarily well approximation to a given training set of inputs and a desired target output represented by a continuous function. Parallel LogSLFN and cascaded LogSLFN are two novel approaches that can be applied to multiple-class decision problems. Both methods are extensions of the LogSLFN, which uses logistic regression to compute the weights between the input and hidden layer of a single-hidden layer feedforward network. No error correction is needed, the weights between the hidden and the output layer being computed using the Moore-Penrose pseudoinverse matrix. The proposed models have been tested on two medical datasets regarding cancer diagnosis and liver fibrosis staging. Experimental results and the subsequent statistical analysis have proved the robustness of the proposed models with other machine learning techniques reported in literature.
               
                  Main findings
                  The experimental results showed that the Parallel approach surpasses the Cascaded one. Still, both models are competitive to the other state-of-the-art techniques.
               
                  Conclusions
                  The LogSFLN algorithm can be successfully extended to multiple-class decision problems. By embedding knowledge extracted from the data into the architecture, we obtained a raise by 20% in accuracy when applied on the liver fibrosis dataset.",science
10.1016/j.jbi.2021.103787,Journal,Journal of Biomedical Informatics,scopus,2021-05-01,sciencedirect,Can technological advancements help to alleviate COVID-19 pandemic? a review,https://api.elsevier.com/content/abstract/scopus_id/85104674391,"The COVID-19 pandemic is continuing, and the innovative and efficient contributions of the emerging modern technologies to the pandemic responses are too early and cannot be completely quantified at this moment. Digital technologies are not a final solution but are the tools that facilitate a quick and effective pandemic response. In accordance, mobile applications, robots and drones, social media platforms (such as search engines, Twitter, and Facebook), television, and associated technologies deployed in tackling the COVID-19 (SARS-CoV-2) outbreak are discussed adequately, emphasizing the current-state-of-art. A collective discussion on reported literature, press releases, and organizational claims are reviewed. This review addresses and highlights how these effective modern technological solutions can aid in healthcare (involving contact tracing, real-time isolation monitoring/screening, disinfection, quarantine enforcement, syndromic surveillance, and mental health), communication (involving remote assistance, information sharing, and communication support), logistics, tourism, and hospitality. The study discusses the benefits of these digital technologies in curtailing the pandemic and ‘how’ the different sectors adapted to these in a shorter period. Social media and television’s role in ensuring global connectivity and serving as a common platform to share authentic information among the general public were summarized. The World Health Organization and Governments’ role globally in-line with the prevention of propagation of false news, spreading awareness, and diminishing the severity of the COVID-19 was discussed. Furthermore, this collective review is helpful to investigators, health departments, Government organizations, and policymakers alike to facilitate a quick and effective pandemic response.",science
10.1016/j.cjca.2020.12.009,Journal,Canadian Journal of Cardiology,scopus,2021-05-01,sciencedirect,Digital Health Approaches for the Assessment and Optimisation of Hypertension Care Provision,https://api.elsevier.com/content/abstract/scopus_id/85104335482,"Although many aspects of our lives have been transformed by digital innovation, widespread adoption of digital health advancements within the health care sector in general, and for hypertension care specifically, has been limited. However, it is likely that, over the next decade, material increases in the uptake of digital health innovations for hypertension care delivery will be seen. In this narrative review, we summarise those innovations thought to have the greatest chance for impact in the next decade. These include provision of virtual care combined with home blood pressure (BP) telemonitoring, use of digital registries and protocolised care, leveraging continuous BP measurement to collect vast amounts of individual and population-based BP data, and adoption of digital therapeutics to provide low-cost scalable interventions for patients with or at risk for hypertension. Of these, home BP telemonitoring is likely the most ready for implementation, but it needs to be done in a way that enables efficient guideline-concordant care in a cost-effective manner. In addition, efforts must be focused on implementing digital health solutions in a manner that addresses the major challenges to digital adoption. This entails ensuring that innovations are accessible, usable, secure, validated, evidence based, cost-effective, and integrated into the electronic systems that are already used by patients or providers. Increasing the use of broader digital innovations such as artificial/augmented intelligence, data analytics, and interactive voice response is also critically important. The digital revolution holds substantial promise, but success will depend on the ability of collaborative stakeholders to adopt and implement innovative, usable solutions.",science
10.1016/j.evopsy.2021.03.006,Journal,Evolution Psychiatrique,scopus,2021-05-01,sciencedirect,"From Digital Identity to Connected Personality, From Augmented Diagnostician to Virtual Caregiver: What Are the Challenges for the Psychology and the Psychiatry of the Future?",https://api.elsevier.com/content/abstract/scopus_id/85104125089,"Objectifs
                  Qui sommes-nous devenus, citoyens, patients, praticiens ? En quoi les moyens de communications et l’informatisation de notre société modifient-ils, intègrent-ils nos identités ? L’intelligence artificielle comprendrait-elle bientôt plus justement l’être humain dont elle s’émanciperait ?
               
                  Matériel et méthodes
                  Cheminons à partir de la lexicologie pour tenter de saisir, via le point de vue de la philosophie, l’identité contemporaine vers la notion d’« identité numérique » dont les incidents psychologiques normaux ou pathologiques entraînent ce que nous définissons « la personnalité numérique ». Puis, posant les bases d’une psychologie de l’identité contemporaine, nous envisageons comment « la psychologie » et « la psychiatrie » actuelles considèrent « la personnalité » du patient et, en retour, comment elles se définissent du point du vue du « praticien en ligne » ou du « chercheur connecté ».
               
                  Résultats
                  En échange de son utilisation « gratuite », l’action de l’internaute sur le Web 2.0 produit du contenu et alimente des bases de données, déclaratives ou non. En perte d’intimité au fur et à mesure que « ses » données ne lui appartiennent plus, l’identité du citoyen se décompose en fonctions des supports digitaux : site de rencontre amical, plateforme de liens amoureux, blog concernant un loisir ou un voyage, etc. Par le même mouvement, l’identité numérique se compose en autre-soi possédant une part d’intelligence artificielle pourvoyeuse de capacité d’existence propre. Plutôt que deux entités parallèlement différentiables, réelle ou augmentée, naît une identité hybride « réalistiquo-virtuelle ». Quelles conséquences normales ou pathologiques chez l’être humain ? Les tendances sociétales post-modernes issues du digital ou y trouvant expression peuvent entraîner, chez un individu donné, une exacerbation des traits de personnalité préalablement existants, voire des symptômes. Parallèlement, il arrive que les moyens de communication moderne deviennent une aide pour expérimenter le monde, majorer l’estime de soi, rêver favorablement ses phantasmes, se confier plus facilement à des « inconnu(e)s », etc. Mais dans tous les cas, chez le sujet souffrant, ou ne souffrant pas, préalablement à sa surexposition, de maladie neuropsychiatrique ou de trouble psychopathologique, il s’avère aujourd’hui scientifiquement documenté que la confrontation numérique accrue induit des atteintes neuropsychiques massives (affaiblissement de la mémoire de travail, des capacités d’attention et de concentration, des aptitudes à construire des opérations cognitives élaborées, etc.). Sur le plan psychopathologique, plutôt que la terminologie de « trouble de l’identité » ou une notion de « co-identités », le terme d’« identité trouble » nous paraît le mieux rendre compte de cette mutation du « moi » où la frontière entre réalité et virtualités s’amenuise : la dissociation prévaut. L’homme post-moderne et ses objets connectés ne font plus qu’un, mais cet « uniforme » apparaît constitué d’un patchwork de confettis identificatoires plus ou moins accolés, sans réelle harmonisation d’ensemble. La personnalité commune se marque d’hyperexpressivité et d’hyperémotivité, au détriment de la possibilité de contrôle des affects et du développement des capacités d’introspection. Contre le risque du vide, tend à se développer une contra-phobie par l’ordiphone, par l’objet lui-même, par la possibilité de contacter en permanence ses proches si nécessaire, et en retour rester toujours « disponible », ce qui alimente une forme d’égocentrisme addictogène. Résulte de ses évolutions, globalement dans la société, un affaiblissement des capacités langagières, et ainsi de réflexion, y compris pour l’espace clinique et scientifique.
               
                  Discussion
                  Pour les domaines de la psychologie et de la psychiatrie, s’associent actuellement deux évolutions : une velléité d’« objectivité-scientificité » et une numérisation de la relation patient–soignant. Du côté de la « science », la médecine objective « factuelle » s’intéresse de plus en plus à la pathologie aux dépens du sujet en souffrance, confondant signe et symptôme, glissant jusqu’à un niveau moléculaire, très en-deçà du patient, vers une psychiatrie ou une psychologie « post-clinique ». Qu’on veuille la promouvoir ou l’anéantir, du côté du clinicien ou du chercheur, la « subjectivité » est devenue un signifiant à la mode pour le domaine de la santé psychique. Ce retour actuel du « subjectif » prospère sur une sorte de peur de la subjectivité depuis la fin de la seconde guerre mondiale qui avait entraîné la nosographie américaine vers les « objectifs » des DSM (Manuel Diagnostique et Statistique des Troubles Psychiques publié par l’American Psychiatric Association depuis 1952). Mais plutôt qu’une connaissance validable, et/ou invariable concernant tel ou tel trouble psychique, le changement, la relativité des entités nosographiques d’une version à l’autre du manuel traduit, en miroir, la subjectivité d’une époque, ce que nous appelons « subjectivité sociétale ». Autant qu’elle témoigne de notre temps, la révolution bio-numérique s’imposera probablement dans une future édition de la nosographie : la validité diagnostique devrait se majorer par la définition précise de marqueurs biologiques et/ou neuroradiologiques, si ceux-ci participent à construire une théorie étiopathogénique des phénomènes psychiques observés. Cette orientation reste toutefois balbutiante : outre l’infime nombre de biomarqueurs identifiés, et surtout utilisables en pratique quotidienne, leurs liens de causalité ou de conséquentialité avec les symptômes ou le processus morbide restent le plus souvent incertains autant qu’ils sont fort divers et interreliés. Le chercheur en neurosciences vise à mesurer et analyser une multitude de données, intégrant en particulier les mimiques et les émotions authentifiables par caméra thermique, les mouvements des segments des corps et dynamiques des regards enregistrables par des capteurs, la standardisation des voix et des discours pour analyse par logiciel informatique de la prosodie, des signifiants employés, de la syntaxe… le tout s’intégrant dans un phénotypage digital de la souffrance. Pourra-t-on bientôt parler, en remplacement du psychologue ou du psychiatre, de « diagnosticien augmenté » ?
               
                  Conclusion
                  Apparaît-il actuellement hasardeux de faire confiance à un thérapeute entièrement virtuel… expérience déjà lancée il y a plus de 50 ans ! L’être humain est un « être de sens », or, selon le modèle de la clinique traumatique, le surgissement du tout-numérique peut entraîner un « effondrement du sens » générateur d’une tendance à la dissociation de la personnalité. Accordant le rétablissement des liens entre émotions, affects, comportements et cognitions, le langage parlé atténue puis fait disparaître la dissociation. Guidée par le praticien, cette parole thérapeutique est parfois qualifiée de « maïeutique », du nom de la science de l’accouchement : elle construit synchroniquement à son essence la pensée, et une prise de conscience de celle-ci, plutôt qu’elle n’en rendrait compte secondairement. Il s’agit d’une réinterprétation causale d’un sens compris ou plutôt « attribué » singulièrement par le sujet, après-coup, le passé revisité dans l’instant noue une synthèse, le hasard est transformé en destin. Le sujet qui parle réélabore son histoire vers une reconstruction sémantique, une densification de ses réseaux de signification. Reconquérant son être par la création d’un discours, de méandres véridiques comme fictionnels, la narration, voire la poétisation, offre l’illusion ponctuelle d’une meilleure cohérence, toujours relative, illusoire La parole thérapeutique et le discours sur celle-ci restent en devenir, inachevés, incertains autant que vivants, caractérisant une « post-psychothérapie », c’est-à-dire une psychothérapie et non pas une technique rééducative qui se trouverait figée dans des objectifs connus à l’avance. Les notions de faits et de réalité sont ici secondaires, non pas au sens de l’objectif, ni même du subjectif, mais du second degré, puis d’autres degrés successifs ou imbriqués portant l’effort intellectuel. Vers l’apaisement, si nous voulions amener la réflexion à son paroxysme, nous pourrions avancer qu’il suffirait de donner « n’importe quel sens », d’en choisir un quel qu’il soit, du côté du patient ou du praticien, sans qu’il ne soit nécessairement le même, témoignage d’une construction intersubjective formellement invalide.
               
                  Objectives
                  Who have we become, as citizens, patients, practitioners? How do the means of communication and the computerization of our society, its digitization, modify and integrate our identities? Can we assume that artificial intelligence will soon have a more accurate understanding of the human being from whom it will have emancipated itself?
               
                  Materials and methods
                  We move from lexicology to try to grasp, from the point of view of philosophy, a contemporary identity that is moving towards the notion of a “digital identity” whose normal or pathological psychological incidents lead to what we define as “the digital personality.” Then, laying the foundations for a contemporary psychology of identity, we consider how current “psychology” and “psychiatry” view the patient's “personality” and, in turn, how they define themselves from the point of view of “the patient,” or, inversely, from the point of view of the “online practitioner” or “connected researcher.”
               
                  Results
                  In exchange for its “free” use, the Internet user's action on Web 2.0 produces content and feeds databases, whether this is declared or not. Users’ privacy is lost, as “their” data no longer belongs to them; and citizens’ identity is broken down into digital media functions: a site for meeting friends, a dating platform, a blog about hobbies or travel, etc. At the same time, digital identity is made up of an other-self, including a part of artificial intelligence that provides capacity for its own existence. Rather than two parallel, differentiable entities, real or augmented, a “realistic-virtual” hybrid identity is born. What are the normal or pathological consequences for humans? Postmodern societal trends emerging from or finding expression in the digital can lead to an exacerbation of previously existing personality traits, or even symptoms, in a given individual. At the same time, it happens that the modern means of communication become an aid to experience the world, to increase self-esteem, to dream favorably about one's fantasies, to confide more easily in “strangers,” etc. But in all cases, in the subject suffering, or not suffering, prior to his overexposure, from a neuropsychiatric disease or a psychopathological disorder, it now turns out to be scientifically documented that the increased numerical confrontation induces massive neuropsychic damage (weakening working memory, attention and concentration skills, skills in constructing sophisticated cognitive operations, etc.). On the psychopathological level, rather than the terminology of “identity disorder” or a notion of “co-identities,” the term “identity elusive"" seems to us to best account for this mutation of the “me” where the border between reality and virtualities is shrinking: dissociation prevails. The postmodern human and its connected objects become one, but this “uniformity” appears to be made up of a patchwork of identifying confetti more or less joined together, without a real overall harmonization. The common personality is marked by hyperexpressiveness and hyperemotivity, to the detriment of the possibility of controlling affects and the development of introspective capacities. Against the risk of a vacuum, a contra-phobia tends to develop through the smartphone, by the object itself, by the possibility of constantly contacting relatives if necessary, and in return always remaining “available,” which fuels a form of addicting self-centeredness. The result of these developments, for society in general, is a weakening of language skills, and thus of reflection, including in the clinical and scientific space.
               
                  Discussion
                  For the areas of psychology and psychiatry, two developments are currently associated: a desire for “objectivity-scientificity” and a digitization of the patient–caregiver relationship. On the side of “science,” objective “factual” medicine is increasingly interested in pathology at the expense of the suffering subject, confusing sign and symptom, sliding down to a molecular level, far below the patient, towards psychiatry or postclinical psychology. Whether we want to promote it or destroy it, on the side of the clinician or the researcher, “subjectivity” has become a fashionable signifier in the field of mental health. This current return of the “subjective” thrives on a kind of fear of subjectivity present since the end of World War II, which had led American nosography towards the “objectives” of the DSM (Diagnostic and Statistical Manual of Mental Disorders, published by the American Psychiatric Association since 1952). But rather than a verifiable and/or invariable knowledge concerning a particular psychic disorder, the changes and the relativity of nosographic entities from one version of the manual to another provides us with a mirror image of the subjectivity of an era, which we propose to call “societal subjectivity.” As much as it is a product of our time, the bio-digital revolution will probably impose itself in a future edition of nosography: the diagnostic validity should be increased by the precise definition of biological and/or neuroradiological markers, if these participate in building an etiopathogenic theory of observed psychic phenomena. This orientation remains in its infancy, however: in addition to the tiny number of identified biomarkers, and above all, those that are usable in daily practice, their causal or consequential links with symptoms or with the morbid process remain most often uncertain, inasmuch as they are diverse and interrelated. The neuroscience researcher aims to measure and analyze a multitude of data, integrating, in particular, mimicry and emotions authenticated by thermal camera; movements of body segments and gaze dynamics recorded by sensors; the standardization of voices and speeches for computer software analysis of prosody, used signifiers, syntax… all of which is integrated into a digital phenotyping of suffering. Will we soon be able to speak, replacing the psychologist or the psychiatrist, of an “augmented diagnostician?”.
               
                  Conclusion
                  Does it currently appear risky to trust an entirely virtual therapist… an experiment already launched more than 50 years ago! The human being is a “being of meaning,” yet, according to the model of trauma, the emergence of the all-digital can lead to a “collapse of meaning,” generating a tendency to personality dissociation. Granting the reestablishment of the links between emotions, affects, behaviors, and cognitions, spoken language attenuates dissociation, then makes it disappear. Guided by the practitioner, this therapeutic word is sometimes qualified as “maieutics,” from the name of the science of childbirth: it builds thought synchronously to its essence, and an awareness of it, rather than nondisclosure, would account for it secondarily. It is a causal reinterpretation of a meaning understood or rather “attributed” singularly by the subject, after the fact: the past revisited in the present moment creates a synthesis, and chance is transformed into fate. The speaking subject re-elaborates her/his story towards a semantic reconstruction, a densification of her/his networks of signification. Reclaiming one's being by the creation of a discourse, of veridical as well as fictional meanders, narration, even poetization, offers the punctual illusion of a better coherence, always relative, illusory… Therapeutic speech and discourse about such speech–these are still being made, unfinished, uncertain, and alive. These are the characteristics of what we could a “post-psychotherapy,” that is, a psychotherapy and not a re-educational technique whose objectives would be fixed and known in advance. The notions of facts and reality are secondary here, not in the sense of the objective, nor even of the subjective, but of the second degree, then of other successive or overlapping degrees that require intellectual effort. Moving towards appeasement, if we wanted to bring the reflection to its paroxysm, we could advance that it would be enough to give “any meaning,” whatever it may be. This would apply both to the patient and to the practitioner, without each party's meaning necessarily being the same: a testimony to a formally invalid intersubjective construction.",science
10.1016/j.exer.2021.108539,Journal,Experimental Eye Research,scopus,2021-05-01,sciencedirect,PLGA nanoparticles containing Lingzhi extracts rescue corneal epithelial cells from oxidative damage,https://api.elsevier.com/content/abstract/scopus_id/85103317418,"Oxidative stress-related ocular surface epithelial damage can be initiated by ambient oxygen, UV radiation, and chemical burns. The oxidative damage to cornea can lead to inflammation and even vision loss. Lingzhi (Ganoderma lucidum) is a Chinese herbal drug and has been shown to prevent chronic diseases in clinical practices and has been proven to possess anti-oxidative and anti-inflammatory properties. In the study, we prepared poly (lactic-co-glycolic acid) (PLGA) nanoparticles (NPs) as a sustained drug release system of Lingzhi (LZH) to improve bioavailability. The particle size of developed NPs containing LZH (LZH-NPs) was ~184 nm with narrow size distribution. The results of cellular uptake revealed that using NPs as a drug delivery system could significantly increases the intracellular retention time. The results of the cell viability and chemiluminescence assay revealed that 5 μg/ml of LZH-NPs might be the threshold concentration for cultivation of corneal epithelial cells. After treating LZH-NPs in oxidative damaged cells, the results showed that the inflammation-related gene expression and DNA fragmentation level were both significantly decreased. Post-treatment of LZH-NPs in damaged corneal epithelial cells could increase the cell survival rate. In the rabbit corneal alkali burn model, topical instillation of LZH-NPs could promote corneal wound healing and decrease the inflammation. These results suggest that LZH-NPs may have the potential to treat ocular surface diseases caused by oxidative stress.",science
10.1016/j.trc.2021.102967,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-05-01,sciencedirect,Automated eco-driving in urban scenarios using deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85103105894,"Urban settings are challenging environments to implement eco-driving strategies for automated vehicles. It is often assumed that sufficient information on the preceding vehicle pulk is available to accurately predict the traffic situation. Because vehicle-to-vehicle communication was introduced only recently, this assumption will not be valid until a sufficiently high penetration of the vehicle fleet has been reached. Thus, in the present study, we employed Reinforcement Learning (RL) to develop eco-driving strategies for cases where little data on the traffic situation are available.
                  An A-segment electric vehicle was simulated using detailed efficiency models to accurately determine its energy-saving potential. A probabilistic traffic environment featuring signalized urban roads and multiple preceding vehicles was integrated into the simulation model. Only information on the traffic light timing and minimal sensor data were provided to the control algorithm. A twin-delayed deep deterministic policy gradient (TD3) agent was implemented and trained to control the vehicle efficiently and safely in this environment.
                  Energy savings of up to 19% compared with a simulated human driver and up to 11% compared with a fine-tuned Green Light Optimal Speed Advice (GLOSA) algorithm were determined in a probabilistic traffic scenario reflecting real-world conditions. Overall, the RL agents showed a better travel time and energy consumption trade-off than the GLOSA reference.",science
10.1016/j.matdes.2021.109604,Journal,Materials and Design,scopus,2021-05-01,sciencedirect,Machine learning assisted calibration of a ductile fracture locus model,https://api.elsevier.com/content/abstract/scopus_id/85102052960,"While several different specimen geometries are typically required to calibrate a ductile fracture locus model, this article presents for the first time a calibration methodology that uses one single specimen geometry. This is accomplished by a computational framework that combines finite element modelling (FEM) and artificial neural network (ANN). The combinations of the model parameters are used to generate the training database. The local displacement fields and global force-displacement histories are extracted throughout the complete numerical experiment and passed to the ANN. Therefore, the influence of the local stress state on the evolution of the local deformation is implicitly taken into account. The trained ANN is verified by evaluating its predictability of material parameters of FE simulations unseen in the training stage. The experimental data obtained from the shear tensile test using Digital Image Correlation is introduced to the trained ANN to identify the parameter set that predicts the real mechanical response of the shear specimen. Three different ANN architectures with distinguished input representations are studied. It turns out that all of them can acceptably describe the experimental behaviour of not only the calibration specimen but also the specimens not used for training the model.",science
10.1016/j.biosystems.2021.104376,Journal,BioSystems,scopus,2021-05-01,sciencedirect,Category theory and foundations of life science: A structuralist perspective on cognition,https://api.elsevier.com/content/abstract/scopus_id/85101372549,"Category theory has recently been applied successfully beyond mathematics and its foundations, for example, in quantum physics, quantum computing, linguistics, and natural language processing in artificial intelligence. Category theory today is arguably foundations of science as well as foundations of mathematics. Yet applications of category theory to the life sciences are still limited, and there are seemingly no clearly successful paradigmatic cases of them. Here we address foundational aspects of category theory in and across the sciences, and potential structural interconnections between category theory and the life sciences, in particular cognitive science. More specifically, we first address the two aspects of category theory as foundations of science and as foundations of mathematics in particular, and then discuss what category theory could do for foundations of life science, in particular cognitive science. We propose, amongst other things, a categorical structuralist approach to the mind-body problem as an alternative to reductionist approaches, which is arguably of both scientific and metaphysical significance at the same time. Category theory allows us to elucidate structural interconnections between the laws of cognition and the laws of reality, thus paving the way for overcoming the Cartesian dualism separating the cognitive and physical worlds. Put another way, category theory suggests that there may be higher laws governing both worlds at once; the higher structuralist theory of cognition may embody the double aspect theory of information by David Chalmers.",science
10.1016/j.image.2021.116200,Journal,Signal Processing: Image Communication,scopus,2021-05-01,sciencedirect,Modelling spatio-temporal ageing phenomena with deep Generative Adversarial Networks,https://api.elsevier.com/content/abstract/scopus_id/85100999804,"Deterioration modelling of ageing phenomena on materials is an actively researched topic in computer graphics and vision, with a wide range of applications in domains such as cultural heritage, game programming, material science and virtual reality. As a result significant progress has been accomplished and existing methods are able to produce visually pleasing results that appear realistic. However, there is a very limited connection to comprehensive measurements that actually capture the ageing process of a material. This paper focuses on this gap, aiming to provide a link between physical measurements and deterioration modelling. Based on extensive measurements of texture and surface geometry of artificially aged reference materials, a Deep Learning (DL) framework is proposed that models spatio-temporal variations on the 3D surface geometry and the 2D colour–image appearance. Concretely, the problem of material degradation over time is formulated as an 2D/3D material-to-material translation problem, where the goal is, given an input material and a target degradation time, to output the degraded material at that time. At the core of the method lies a modified conditional Generative Adversarial Network (cGAN), which maps input materials to degraded materials over time. In order to train and deploy the proposed cGAN model, proper data parameterization and augmentation steps are introduced. As shown through extensive experimentation on real data coming from materials commonly found in artwork and from actual artworks, the proposed approach produces high quality results.",science
10.1016/j.atmosres.2021.105490,Journal,Atmospheric Research,scopus,2021-05-01,sciencedirect,Changes of ammonia concentrations in wintertime on the North China Plain from 2018 to 2020,https://api.elsevier.com/content/abstract/scopus_id/85100690328,"The reduced economic and social activities during the Chinese Spring Festival provide a unique experiment to evaluate reductions in anthropogenic NH3 emissions in China. However, quantifying this unique scenario is challenging as meteorology may mask the real changes in observed NH3 concentrations. Here, we applied a machine learning technique to decouple the effects of meteorology and confirmed that the real (deweathered) NH3 concentration dropped to a minimum during the Spring Festival in 2019 and 2020 at both urban (Beijing) and rural (Xianghe) sites on the North China Plain. Compared with the scenario without the Spring Festival effect, we predicted that NH3 concentrations in 2020 were 39.8% and 24.6% higher than the observed values at the urban and rural sites, respectively. The significant difference between the two sites indicates a larger reduction in anthropogenic NH3 emissions in urban areas than in rural areas due to the Spring Festival and lockdown measures of COVID-19. Future control strategies should consider the emissions of NH3 from the transportation, industrial and residential sectors, considering that agricultural emissions are minor in cold seasons.",science
10.1016/j.ins.2021.01.004,Journal,Information Sciences,scopus,2021-05-01,sciencedirect,A Blockchain-based approach for matching desired and real privacy settings of social network users,https://api.elsevier.com/content/abstract/scopus_id/85100433895,"Social networks store a considerable amount of personal data, which are also a source of information for business. To comply with users’ privacy rights, all social networks allow users to select the level of privacy they desire. However, what occurs if the privacy choices of a user are modified unilaterally by the social network? The privacy settings chosen by the user are stored by the social network, which acts as a privileged party, which could tamper with the user’s choices at any time. This paper addresses this problem and proposes a decentralized approach to manage the privacy settings of a user. Any change in the privacy settings of a social network user is validated by a smart contract to ensure that it is compliant with users’ expectations. The proposed solution has been implemented as an Ethereum-based decentralized application to validate the effectiveness of the proposed approach.",science
10.1016/j.foodchem.2020.128436,Journal,Food Chemistry,scopus,2021-05-01,sciencedirect,Ultra-sensitive electrochemical aptasensor for label-free detection of Aflatoxin B1 in wheat flour sample using factorial design experiments,https://api.elsevier.com/content/abstract/scopus_id/85094596007,"Considering the significance of mycotoxin detection in food industries, herein, an ultrasensitive aptasensor was developed based on aflatoxin B1 aptamer immobilized on Carbon quantum dots/octahedral Cu2O nanocomposite. Electrochemical measurements were based on Electrochemical Impedance Spectroscopy (EIS) and Differential Pulse Voltammetry (DPV). Since the effective parameters (pH, temperature, incubation time and concentration of aptamers) are interdependent, so their dependent study can be nonideal. Taguchi method has solved this problem and optimized the experimental conditions using a smaller number of experiments. Under optimum conditions, the electrochemical signals declined as AFB1 concentrations increased with a dynamic range of 3 ag.ml−1 −1.9 µg.ml−1 and a low limit of detection (LOD) of 0.9 ± 0.04 ag ml−1. The obtained results proved sufficient repeatability (RSD = 2.4%), reproducibility (RSD = 2.56%), accuracy (97.2–104.4% recovery), and robustness (RSD = 3.25%). Furthermore, considerable selectivity, stability and reliability of the aptasensor confirmed the capability to work in future real assays.",science
10.1016/j.bbr.2021.113156,Journal,Behavioural Brain Research,scopus,2021-04-23,sciencedirect,Maternal antibiotic administration during a critical developmental window has enduring neurobehavioural effects in offspring mice,https://api.elsevier.com/content/abstract/scopus_id/85101391612,"Rates of perinatal maternal antibiotic use have increased in recent years linked to prophylactic antibiotic use following Caesarean section delivery. This antibiotic use is necessary and beneficial in the short-term; however, long-term consequences on brain and behaviour have not been studied in detail. Here, we endeavoured to determine whether maternal administration of antibiotics during a critical window of development in early life has lasting effects on brain and behaviour in offspring mice. To this end we studied two different antibiotic preparations (single administration of Phenoxymethylpenicillin at 31 mg/kg/day; and a cocktail consisting of, ampicillin 1 mg/mL; vancomycin 0.5 mg/mL; metronidazole 1 mg/mL; ciprofloxacin 0.2 mg/mL and imipenem 0.25 mg/mL). It was observed that early life exposure to maternal antibiotics led to persistent alterations in anxiety, sociability and cognitive behaviours. These effects in general were greater in animals treated with the broad-spectrum antibiotic cocktail compared to a single antibiotic with the exception of deficits in social recognition which were more robustly observed in Penicillin V exposed animals. Given the prevalence of maternal antibiotic use, our findings have potentially significant translational relevance, particularly considering the implications on infant health during this critical period and into later life.",science
10.1016/j.comnet.2021.107914,Journal,Computer Networks,scopus,2021-04-22,sciencedirect,A Machine Learning Model for Data Sanitization,https://api.elsevier.com/content/abstract/scopus_id/85100774315,"Discovering important knowledge that may be available from databases while preserving the privacy of sensitive information can be considered a hot research subject of data mining in recent times. With the establishment of strong Internet of Things (IoT) networks globally, several data-intensive applications will be developed. Privacy of information over the network is increasingly relevant, and as edge computing has grown more important, applications running over networks require protection. The privacy of information while utilizing data is a trade-off that needs to be addressed. In the past, many heuristics and meta heuristics-based approaches were revealed to sensitize sensitive information in privacy-preserving data mining (PPDM). They perturb the original database to hide sensitive information using addition or deletion operations. This is a known NP-hard problem. In this paper, we propose data privacy of IoT connected devices over heterogeneous networks. A deep re-enforcement learning-based technique is applied to sensitize sensitive information from a given database while keeping the balance between privacy protection and knowledge discovery during the sanitization process. Furthermore, minimizing known side effects that can be caused in the sanitization process is also be considered. Substantial experiments are conducted on both synthetic and real-world datasets. Results are evaluated based on sanitization side effects which include failing to hide sensitive items as well as choosing not to hide sensitive items. The proposed approach shows significant performance improvement compared to meta-heuristics (Genetic Algorithm, Particle Swarm Optimization) and heuristics (Greedy) approaches by our evaluation.",science
10.1016/j.eswa.2020.114402,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,Unsupervised feature selection for attributed graphs,https://api.elsevier.com/content/abstract/scopus_id/85097572982,"Many real-world applications generate attributed graphs that contain both link structures and content information associated with nodes. Content information in real networks always contains high dimensional feature space. In recent years, unsupervised feature selection has been widely used in handling high dimensional data without label information. Most existing unsupervised feature selection methods assume that instances in datasets are independent and identically distributed. However, instances in attributed graphs are intrinsically correlated. Considering the wide applications of feature selection in attributed graphs, we propose a new unsupervised feature selection method based on regularized sparse learning. We use pseudo class labels to learn the interdependency from both link and content information, and embed the obtained information into a sparse learning based feature selection framework. In particular, a new regularization term is designed to learn link information, which capture group behavior among the connected instances utilizing latent social dimensions. To solve the proposed feature selection model, we consider both convex and nonconvex cases and design the corresponding algorithms based on the Alternating Direction Method of Multipliers (ADMM) combined with ConCave Convex Procedure (CCCP). Numerical studies are implemented on real-world datasets to validate the advantage of our new method.",science
10.1016/j.patter.2021.100225,Journal,Patterns,scopus,2021-04-09,sciencedirect,Machine learning discovery of high-temperature polymers,https://api.elsevier.com/content/abstract/scopus_id/85104127192,"To formulate a machine learning (ML) model to establish the polymer's structure-property correlation for glass transition temperature 
                        
                           
                              T
                              g
                           
                        
                     , we collect a diverse set of nearly 13,000 real homopolymers from the largest polymer database, PoLyInfo. We train the deep neural network (DNN) model with 6,923 experimental 
                        
                           
                              T
                              g
                           
                        
                      values using Morgan fingerprint representations of chemical structures for these polymers. Interestingly, the trained DNN model can reasonably predict the unknown 
                        
                           
                              T
                              g
                           
                        
                      values of polymers with distinct molecular structures, in comparison with molecular dynamics simulations and experimental results. With the validated transferability and generalization ability, the ML model is utilized for high-throughput screening of nearly one million hypothetical polymers. We identify more than 65,000 promising candidates with 
                        
                           
                              T
                              g
                           
                        
                      > 200°C, which is 30 times more than existing known high-temperature polymers (∼2,000 from PoLyInfo). The discovery of this large number of promising candidates will be of significant interest in the development and design of high-temperature polymers.",science
10.1016/j.jep.2020.113768,Journal,Journal of Ethnopharmacology,scopus,2021-04-06,sciencedirect,Astragalus membranaceus and Salvia miltiorrhiza ameliorates cyclosporin A-induced chronic nephrotoxicity through the “gut-kidney axis”,https://api.elsevier.com/content/abstract/scopus_id/85098796907,"Ethnopharmacological relevance
                  The combination of Astragalus membranaceus and Salvia miltiorrhiza (AS) is an effective prescription that is widely used to treat chronic kidney disease (CKD) clinically in traditional Chinese medicine. Our previous studies have shown that AS can alleviate early CKD through the “gut-kidney axis”, but the regulatory role of AS in the “gut-kidney axis” in the middle and late stages of CKD caused by cyclosporin A-induced chronic nephrotoxicity (CICN) has remained unclear.
               
                  Aim of the study
                  To explore the protective effect of AS by regulating the intestinal flora to further control the miRNA-mRNA interaction profiles in CICN.
               
                  Materials and methods
                  Thirty-two mice were divided into four groups: Normal (N) (olive oil), Model (M) (CsA, 30 mg kg−1 d−1), AS (CsA + AS, 30 + 8.4 g kg−1 d−1) and FMT-AS (CsA + Faeces of AS group, 30 mg + 10 mL kg−1 d−1). The mice were treated for 6 weeks. Changes in renal function related metabolites were detected, pathological changes in the colon and kidney were observed, and 16S rDNA sequencing was performed on mouse faeces. In addition, miRNA and mRNA sequencing were performed on the kidney to construct differential expression (DE) profiles of the other 3 groups compared with group M. The target mRNAs among the DE miRNAs were then predicted, and an integrated analysis was performed with the DE mRNAs to annotate gene function by KEGG. DE miRNAs and DE mRNAs related to CICN in the overlapping top 20 KEGG pathways were screened and verified.
               
                  Results
                  Eight metabolites that could worsen renal function were increased in group M, accompanied by thickening of the glomerular basement membrane, vacuolar degeneration of renal tubules, and proliferation of collagen fibres, while AS and FMT-AS intervention amended these changes to varying degrees. Simultaneously, intestinal permeability increased, the abundance and diversity of the flora decreased, and the ratio of Firmicum to Bacteroides (F/B) increased in group M. The AS and FMT-AS treatments reversed the flora disorder and increased probiotics producing butyric acid and lactic acid, especially Akkermansia and Lactobacillus, which might regulate the 12 overlapping top 20 KEGG pathways, such as Butanoate metabolism, Tryptophan metabolism and several RF-related pathways, leading to the remission of renal metabolism. Finally, 15 DE miRNAs and 45 DE mRNAs were screened as the therapeutic targets, and the results coincided with the sequencing results.
               
                  Conclusion
                  AS could alleviate renal fibrosis and metabolism caused by CICN through the “gut-kidney axis”. Probiotics such as Akkermansia and Lactobacillus were the primary driving factors, and the miRNA-mRNA interaction profiles, especially Butanoate metabolism and Tryptophan metabolism, may be an important subsequent response and regulatory mechanism.",science
10.1016/j.jep.2020.113669,Journal,Journal of Ethnopharmacology,scopus,2021-04-06,sciencedirect,Tiao Geng decoction inhibits tributyltin chloride-induced GT1-7 neuronal apoptosis through ASK1/MKK7/JNK signaling pathway,https://api.elsevier.com/content/abstract/scopus_id/85098773002,"Ethnopharmacological relevance
                  Tiao Geng (TG) decoction is a Chinese herbal medicine extract that has been utilized for the treatment of menopausal symptoms for a history of over 30 years. In our previous study, we suggest that TG decoction possibly exerts an anti-apoptotic effect on hypothalamic neurons of ovariectomized rats via the ASK1/MKK7/JNK pathway. Tributyltin chloride (TBTC) causes oxidative damage and induces apoptosis of primary hypothalamic neurons in rats.
               
                  Aim of the study
                  The present work aimed to explore the inhibition of TG decoction on TBTC-induced GT1-7 cell apoptosis and its possible molecular mechanism.
               
                  Materials and methods
                  The GT1-7 cell line was exposed to TG decoction at diverse doses (31.25, 62.5, 125 μg/mL) for 24 h and later with TBTC (1 mg/L) for 1 h, with 17β-E2 (100 nM) treatment being the positive control. Then, CCK8 assay was conducted to evaluate cell viability, while flow cytometric analysis was conducted to examine the apoptosis level. Related pathways and differentially expressed proteins were identified by tandem mass tag (TMT)-based quantitative phosphoproteomics. qRT-PCR was carried out to examine mRNA levels of Bax and B-cell lymphoma-2 (Bcl-2). Western blotting was performed to detect the levels of Bax, Bcl-2, c-Jun, c-Jun N-terminal kinase (JNK), Caspase-3 (Casp3), Mitogen-activated protein kinase kinase 7 (MKK7), and apoptosis signal-regulating kinase 1 (ASK1) .
                  Finally, cells were pretreated with SP600125, an inhibitor of JNK, later the expression of JNK and Casp3 was measured.
               
                  Results
                  Application of TG decoction mitigated the GT1-7 cell apoptosis and injury caused by TBTC; besides, it inhibited the activation of the ASK1/MKK7/JNK pathway. Moreover, Bcl-2/Bax ratio became higher, and the MKK7, ASK1, Casp3 and c-Jun levels were inhibited. Besides, TG decoction combined with SP600125 (the JNK inhibitor) more significantly inhibited GT1-7 cell apoptosis caused by TBTC.
               
                  Conclusion
                  As discovered from the experiment in this study, TG decoction has a neuroprotective effect, which is achieved through inhibiting the ASK1/MKK7/JNK signal transduction pathway to reduce GT1-7 cell apoptosis.",science
10.1016/j.sab.2021.106125,Journal,Spectrochimica Acta - Part B Atomic Spectroscopy,scopus,2021-04-01,sciencedirect,Deep spectral CNN for laser induced breakdown spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85102124336,"This work proposes a spectral convolutional neural network (CNN) operating on laser induced breakdown spectroscopy (LIBS) signals to learn to (1) disentangle spectral signals from the sources of sensor uncertainty (i.e., pre-process) and (2) get qualitative and quantitative measures of chemical content of a sample given a spectral signal (i.e., calibrate). Once the spectral CNN is trained, it can accomplish either task through a single feed-forward pass, with real-time benefits and without any additional side information requirements including dark current, system response, temperature and detector-to-target range. Our experiments demonstrate that the proposed method outperforms the existing approaches used by the Mars Science Lab for pre-processing and calibration for remote sensing observations from the Mars rover, ‘Curiosity’.",science
10.1016/j.engappai.2021.104192,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-04-01,sciencedirect,HK–SEIR model of public opinion evolution based on communication factors,https://api.elsevier.com/content/abstract/scopus_id/85101562600,"Microblog, with its good interaction and convenient dissemination, has become the main platform for public opinion dissemination. How to discover the law of public opinion dissemination, and to identify the public opinion accurately have become the hot researches. In this paper, we define the user influence, topic popularity, topic interest to analysis the process of opinions fusion among the users under the interest and confidence threshold. We propose a new public opinion evolution HK–SEIR model which combines the opinion fusion HK and the epidemic transmission SEIR models. Firstly, the topic interest degree is added to the opinion fusion HK model, and the interaction behavior between the users under the interest and confidence threshold is analyzed. Then, we calculate the probability of topic propagation caused by the interaction of opinions between users under group pressure, and the probability that users change from the infected state to the removed state under topic popularity. Finally, we analyze the changes of the susceptible, exposed, infected and removed states in the process of public opinion communication. The experiment proves that the HK–SEIR model is closer to the work-rest rules of public opinion communication than SEIR, SIR model. The density peak time is closer to the peak of real public opinion communication. We find that the user interest is the main factor influencing the public opinion dissemination after the interaction of user opinions fusion reaches a certain degree. The negative public opinion of the higher proportion can easily reach the peak of public opinion propagation.",science
10.1016/j.isprsjprs.2021.02.007,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2021-04-01,sciencedirect,Automatic atmospheric correction for shortwave hyperspectral remote sensing data using a time-dependent deep neural network,https://api.elsevier.com/content/abstract/scopus_id/85101384194,"Atmospheric correction is an essential step in hyperspectral imaging and target detection from spectrometer remote sensing data. State-of-the-art atmospheric correction approaches either require extensive filed experiments or prior knowledge of atmospheric characteristics to improve the predicted accuracy, which are computational expensive and unsuitable for real time application. To take full advantages of remote sensing observation in quickly and reliably acquiring data for a large area, an automatic and efficient processing tool is required for atmospheric correction. In this paper, we propose a time-dependent neural network for automatic atmospheric correction and target detection using multi-scan hyperspectral data under different elevation angles. In addition to the total radiance, the collection day and time are also incorporated to improve the time-dependency of the network and represent the seasonal and diurnal characteristics of atmosphere and solar radiation. Results show that the proposed network has the capacity to accurately provide atmospheric characteristics and estimate precise reflectivity spectra with 
                        
                           95.72
                           %
                        
                      averaged accuracy for different materials, including vegetation, sea ice, and ocean. Additional experiments are designed to investigate the network’s temporal dependency and performance on missing data. The error analysis confirms that our proposed network is capable of estimating atmospheric characteristics under both seasonally and diurnally varying environments and handling the influence of missing data. Both the predicted results and error analysis are promising and demonstrate that our network has the ability of providing accurate atmospheric correction and target detection in real time.",science
10.1016/j.autcon.2021.103603,Journal,Automation in Construction,scopus,2021-04-01,sciencedirect,A field parameters-based method for real-time wear estimation of disc cutter on TBM cutterhead,https://api.elsevier.com/content/abstract/scopus_id/85100241917,"In hard rock TBM tunneling, the loss caused by disc cutter wear accounts for a large proportion of time and cost for the entire project. However, existing disc cutter wear prediction models mainly focus on predicting cutter consumption before construction and cannot predict the wear of each disc cutter. Moreover, the accurate rock parameters required in these models are challenging to obtain. Hence, these models are not capable of determining which cutter on cutterhead should be replaced during construction. To solve the problems mentioned above, this paper presents a novel field parameters-based method for estimating the wear of each disc cutter in real-time. The proposed method is implemented through the following steps. To begin with, a new health index is constructed and defined as the ratio of the rolling distance of a cutter in a small excavated section to its maximum rolling distance. Then, specific field parameters related to the new health index are analyzed and selected. Thereafter, the mapping model between the new health index and the specific field parameters is established based on a one-dimensional convolutional neural network. Finally, on the basis of the established model, the estimated health indices corresponding to all excavated sections of a disc cutter are accumulated to obtain its health status. The field data obtained from Mumbai metro tunnel was utilized to verify the effectiveness of the proposed method, which demonstrates that the proposed method can estimate the wear of each disc cutter in real-time with average accuracy as high as 87.8% on the test set. Therefore, the proposed method is capable of significantly reducing the time and cost of cutter inspection, replacement, and repair for TBM, thereby improve tunneling efficiency and reduce construction cost.",science
10.1016/j.petrol.2020.108296,Journal,Journal of Petroleum Science and Engineering,scopus,2021-04-01,sciencedirect,Geological structure-guided hybrid MCMC and Bayesian linearized inversion methodology,https://api.elsevier.com/content/abstract/scopus_id/85100209414,"Seismic inversion is a common method for hydrocarbon reservoir characterization, as it consists of a proven and effective approach to derive elastic properties from reflectivity seismic data. Markov Chain Monte Carlo (MCMC) based seismic inversion approach is a suitable choice to numerically evaluate the posterior uncertainties associated with the inverse solution without assuming linear forward operators, Gaussian, or generalized Gaussian prior models. However, the existing MCMC based seismic inversion approaches are mostly performed trace-by-trace, which means that the spatial coupling of model parameters is not considered. When the results of trace-by-trace based inversion are combined to generate a 2D profile, the final results will be laterally discontinuous. Moreover, the large dimension of the model space causes low convergence efficiency of MCMC-based seismic inversion. To overcome these issues, a geological structure-guided hybrid MCMC and Bayesian linearized inversion (BLI) methodology for seismic inversion is implemented. The geological structure information obtained using plane wave destruction (PWD) is incorporated to the MCMC based inversion algorithm in the form of dips yields more geologically meaningful results. The hybrid MCMC and BLI strategy, which takes advantage of BLI's high efficiency to provide initial configuration for MCMC, is used to improve the convergence of MCMC-based inversion. Additionally, the block coordinate descent (BCD) algorithm is introduced to replace the large-scale matrix solution in geological structure-guided, and consequently reduce memory consumption and time cost. This methodology is validated on a synthetic seismic dataset, as well as on a real case. It has proven to be a reliable approach to obtain acoustic impedance (AI) from post-stack seismic data in an efficient way. It also addresses the uncertainty related with the ill-posed characteristics of the inversion methodology itself.",science
10.1016/j.ins.2020.11.042,Journal,Information Sciences,scopus,2021-04-01,sciencedirect,Information spreading with relative attributes on signed networks,https://api.elsevier.com/content/abstract/scopus_id/85098456560,"During the past years, network dynamics has been widely investigated in various disciplines. As a practical and convenient description for social networks, signed networks have also garnered significant attention. In this work, we study information spreading with relative attributes on signed networks, where edges are assigned positive or negative labels, describing friendly or hostile relationships. We define the attribute of information by a degree that can be either ‘good’ or ‘bad’ and assume that the spreading willingness of the information receiver depends on not only its relation with others but also the attribute of information. A pair-wise potential relation identification algorithm is designed based on the shortest path approach and structural balance theory. Both simulations on randomly signed networks and empirical experiments on real datasets show that the proposed information spreading could be approximately investigated within a local 2-order neighborhood. In addition, the ratio of potential friendly nodes with a target node is consist with network content. Finally, the propagation speed of ‘good’ information would unexpectedly slow down when the ratio of positive edges is larger than an estimated threshold. The presented model could be referred to in real social scenarios, such as product promotion, advertisement media, and rumor mongering.",science
10.1016/j.envpol.2020.115900,Journal,Environmental Pollution,scopus,2021-04-01,sciencedirect,Understanding the true effects of the COVID-19 lockdown on air pollution by means of machine learning,https://api.elsevier.com/content/abstract/scopus_id/85097107266,"During March 2020, most European countries implemented lockdowns to restrict the transmission of SARS-CoV-2, the virus which causes COVID-19 through their populations. These restrictions had positive impacts for air quality due to a dramatic reduction of economic activity and atmospheric emissions. In this work, a machine learning approach was designed and implemented to analyze local air quality improvements during the COVID-19 lockdown in Graz, Austria. The machine learning approach was used as a robust alternative to simple, historical measurement comparisons for various individual pollutants. Concentrations of NO2 (nitrogen dioxide), PM10 (particulate matter), O3 (ozone) and Ox (total oxidant) were selected from five measurement sites in Graz and were set as target variables for random forest regression models to predict their expected values during the city’s lockdown period. The true vs. expected difference is presented here as an indicator of true pollution during the lockdown. The machine learning models showed a high level of generalization for predicting the concentrations. Therefore, the approach was suitable for analyzing reductions in pollution concentrations. The analysis indicated that the city’s average concentration reductions for the lockdown period were: -36.9 to −41.6%, and −6.6 to −14.2% for NO2 and PM10, respectively. However, an increase of 11.6–33.8% for O3 was estimated. The reduction in pollutant concentration, especially NO2 can be explained by significant drops in traffic-flows during the lockdown period (−51.6 to −43.9%). The results presented give a real-world example of what pollutant concentration reductions can be achieved by reducing traffic-flows and other economic activities.",science
10.1016/j.jep.2020.113654,Journal,Journal of Ethnopharmacology,scopus,2021-03-25,sciencedirect,Antidiabetic effect of a flavonoid-rich extract from Sophora alopecuroides L. in HFD- and STZ- induced diabetic mice through PKC/GLUT4 pathway and regulating PPARα and PPARγ expression,https://api.elsevier.com/content/abstract/scopus_id/85097798210,"Headings ethnopharmacological relevance
                  
                     Sophora alopecuroides L. is a traditional ethnopharmacological plant, which is widely used in traditional Chinese medicine and Mongolian and Uighur medicine to ameliorate “thirst disease”.
               
                  Aim of the study
                  This study aimed to investigate the antidiabetic activities and mechanisms of a flavonoid-rich extract from Sophora alopecuroides L. (SA-FRE) both in vivo and vitro.
               
                  Materials and methods
                  The main six chemical constituents of SA-FRE were elucidated based on an off-line semi-preparative liquid chromatography nuclear magnetic resonance (LC-NMR) protocol. Myc-GLUT4-mOrange-L6 cell models and mouse model with diabetes induced by high-fat diet combined with STZ injection were respectively adopted to investigate the antidiabetic effects of SA-FRE both in vitro and vivo.
                  
               
                  Results
                  
                     In vivo, 4-week treatment of SA-FRE ameliorated hyperglycemia, dyslipidemia, and insulin resistance in diabetic mice. Mechanically, SA-FRE regulated PPARα and PPARγ expression in white adipose tissue (WAT) and liver, thereby ameliorating dyslipidemia. Moreover, SA-FRE increased the phosphorylation of PKC and further stimulated the GLUT4 expression in WAT and skeletal muscle, thus increasing the glucose utilization in vivo. In vitro, 50 μg/mL SA-FRE increased GLUT4 translocation to about 1.91-fold and glucose uptake to 1.82-fold in L6-myotubes. SA-FRE treatment increased the GLUT4 expression at both gene and protein levels. Furthermore, only Gö6983, a PKC inhibitor, reversed the SA-FRE-induced GLUT4 translocation and expression at the gene and protein levels.
               
                  Conclusions
                  Generally, SA-FRE ameliorated hyperglycemia, dyslipidemia, and insulin resistance partly through activating PKC/GLUT4 pathway and regulating PPARα and PPARγ expression.",science
10.1016/j.jep.2020.113563,Journal,Journal of Ethnopharmacology,scopus,2021-03-25,sciencedirect,Comprehensive evaluation of the combined extracts of Epimedii Folium and Ligustri Lucidi Fructus for PMOP in ovariectomized rats based on MLP-ANN methods,https://api.elsevier.com/content/abstract/scopus_id/85096192504,"Ethnopharmacological relevance
                  Kidney deficiency is the main pathogenesis of osteoporosis based on the theory of “kidney governing bones” in traditional Chinese medicine (TCM). Osteoporosis is a systemic disease; kidney deficiency influences the growth, aging and reproduction of human body, reflecting in endocrine, nerve, immunity, metabolism and other functions. Multi-target drugs composed of natural non-toxic products from kidney-reinforcing herbs, are being investigated for the treatment of osteoporosis. Therefore, it is necessary and imperative to develop an objective and comprehensive method to evaluate and compare the effects of herbs with listed drugs.
               
                  Aim of the study
                  This study was designed to evaluate and compare the therapeutic effects and the underlying molecular mechanism of the combined extracts of Epimedii Folium and Ligustri Lucidi Fructus (EL) with Raloxifene hydrochloride (RH) in ovariectomy (OVX)-induced postmenopausal osteoporosis (PMOP) rats based on the multi-layer perception (MLP)-artificial neural network (ANN) model.
               
                  Materials and methods
                  Female SD rats were subjected to either sham surgery (n = 8) or bilateral OVX (n = 48). One week after recovering from surgery, the OVX-induced rats were randomly divided into three groups: OVX model group (n = 32, every 8 rats were killed at the end of the 5th, 9th, 11th or 13th week after OVX), EL group (treated with EL 0.35 g/kg, n = 8), and RH group (treated with RH 6.25 mg/kg, n = 8). The rats in the treatment groups were administrated once a day for 12 weeks, then sacrificed. We observed bone mass and quality, bone remodeling, the function of estrogen and TGF-β1/Smads pathway in all rats.
               
                  Results
                  Both EL and RH could increase bone mineral density, enhance bone strength, relieve bone micro-structure degeneration, re-balance bone remodeling, regulate estrogen dysfunction, and up-regulate TGF-β1 expression. The evaluation of the MLP-ANN model showed that EL and RH had markedly anti-PMOP effects, and there was no significant difference in the comprehensive evaluation of anti-osteoporosis between the two drugs. However, RH had better effects on bone mass and quality and TGF-β1/Smads pathway than EL; EL had better effects on estrogen function than RH.
               
                  Conclusion
                  Combined extracts of Epimedii Folium and Ligustri Lucidi Fructus (EL) exhibited bone-protective effects on PMOP. The MLP-ANN method evaluated the efficacy of drugs more comprehensively, which provided a new direction for the evaluation and comparison of drugs.",science
10.1016/j.neucom.2020.12.051,Journal,Neurocomputing,scopus,2021-03-21,sciencedirect,Differentially private ensemble learning for classification,https://api.elsevier.com/content/abstract/scopus_id/85098940971,"Training machine learning models requires large amounts of data, which may contain personal sensitive information. Machine learning based on privacy protection has become a research hotspot. In this paper, differential privacy is applied to the ensemble learning, a branch of machine learning, to prevent privacy leakage in the classification process. We propose a differentially private ensemble learning algorithm for classification, which achieves privacy protection while ensures prediction accuracy. Firstly, we adopt the Bag of Little Bootstrap technique and the Jaccard similarity coefficient to generate a set of training data sets, and construct corresponding differentially private base classifiers by adding a carefully chosen amount of perturbation noise with a privacy budget allocation strategy. Furthermore, to reduce the impact of perturbation noise on the accuracy of prediction, an effective ensemble algorithm is proposed. Specifically, the base classifiers are selected based on some criterion functions, and the corresponding weights are assigned simultaneously. Then, the final result of the classification is obtained by a weighted voting scheme. Experiments are executed on 9 real data sets from the UCI Machine Learning Repository to demonstrate that our differentially private ensemble classification algorithm achieves a better trade-off in terms of privacy protection and prediction accuracy.",science
10.1016/j.ijpharm.2021.120338,Journal,International Journal of Pharmaceutics,scopus,2021-03-15,sciencedirect,"Real-time release testing of dissolution based on surrogate models developed by machine learning algorithms using NIR spectra, compression force and particle size distribution as input data",https://api.elsevier.com/content/abstract/scopus_id/85100501165,"In this work spectroscopic measurements, process data and Critical Material Attributes (CMAs) are used to predict the in vitro dissolution profile of sustained-release tablets with three machine learning methods, Artificial Neural Networks (ANN), Support Vector Machines (SVM) and Ensemble of Regression Trees (ERT). Beside the effect of matrix polymer content and compression force, the influence of active pharmaceutical ingredient (API) and matrix polymer particle size distribution (PSD) on the drug release rate of sustained tablets is studied. The matrix polymer PSD was found to be a significant factor, thus this factor was included in the dissolution prediction experiments. In order to evaluate the importance of the inclusion of PSD data, models without PSD data were also prepared and the results were compared. In the developed models, the API and hydroxypropyl-methylcellulose (HPMC) content is predicted from near-infrared (NIR) spectra, the compression force is measured by the tablet press and HPMC particle size is measured off-line. The predictions of ANN, SVM and ERT were compared to the measured dissolution profiles of the validation tablets, ANN yielded the most accurate results. In the presented work, data provided by Process Analytical Technology (PAT) sensors is combined with CMAs for the first time to realize the Real-Time Release Testing (RTRT) of tablet dissolution.",science
10.1016/j.adhoc.2020.102383,Journal,Ad Hoc Networks,scopus,2021-03-15,sciencedirect,Recommending irregular regions using graph attentive networks,https://api.elsevier.com/content/abstract/scopus_id/85099212473,"Due to the prevalence of human activity in urban spaces, recommending ROIs (region-of-interests) to users, especially irregular ROIs, becomes an important task in location-based social networks. A fundamental problem is how to aggregate users’ preferences over POIs (point-of-interests) to infer the users’ region-level mobility patterns. The majority of existing studies ignore the users’ implicit interactions with individual POIs when addressing this issue. For example, a user check-in a region cannot provide any specific information about how the user likes this region (we call this phenomenon “ROI-level” implicitness) and which POI in this region the user is interested in (i.e., “POI-level” implicitness). Furthermore, existing studies adopt predefined strategies for region-level preference aggregation, that is, initializing the importance of different POIs with identical weights, which is insufficient to model the reality of social networks.
                  We emphasize two facts in this paper: 
                        (1)
                      there simultaneously exists ROI-level and POI-level implicitness that blurs the users’ underlying preferences; and 
                        (2)
                      individual POIs should have non-uniform weights and more importantly, the weights should vary across different users. To address these issues, we contribute a novel solution, namely GANR
                        
                           
                           
                              2
                           
                        
                      (Graph Attentive Neural Network for Region Recommendation). Specifically, to learn the user preferences over irregular ROIs, we provide a principled neural network equipped with two attention modules: the POI-level attention module, to select the informative POIs of one ROI, and the ROI-level attention module, to learn the ROI preferences. Moreover, we learn the interactions between users and ROIs under the NGCF (Neural Graph Collaborative Filtering) framework. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework.",science
10.1016/j.adhoc.2020.102360,Journal,Ad Hoc Networks,scopus,2021-03-15,sciencedirect,VOCkit: A low-cost IoT sensing platform for volatile organic compound classification,https://api.elsevier.com/content/abstract/scopus_id/85097468733,"Improvements in small sized sensors allow the easy detection of the presence of Volatile Organic Compounds (VOCs) in the air using easy-to-deploy Internet of Things (IoT) devices. However, classifying what VOC exists in the environment still remains as a complex task. Knowing what VOCs are in the air can help us remove the main cause that vents VOC materials as a way to maintain clean air quality. In this work, we present VOCkit, an IoT sensor kit for non-chemical experts to easily detect and classify different types of VOCs. VOCkit combines miniature chemically-designed fluorometric sensors for recognizing VOCs with an embedded imaging system for classification. Exposing the fluorometric sensors with various VOCs, result in the photophysical property change of fluorescent compounds, which composes the sensors, and the synergistic combination of the changes create unique individual fluorescent color patterns respectively to the VOC material. The fluorescent color change pattern is captured using an embedded camera and the images are processed with machine learning algorithms on the embedded platform for VOC classification. Using 500 fluorometric sensor images collected for five different commonly contactable VOCs, we show the feasibility of VOC classification on small-sized IoT devices. For the VOC types of our interest, our results show a classification accuracy of 97%, implying the potential applicability of VOCkit for real-world usage.",science
10.1016/j.eswa.2020.114070,Journal,Expert Systems with Applications,scopus,2021-03-15,sciencedirect,AnomalP: An approach for detecting anomalous protein conformations using deep autoencoders,https://api.elsevier.com/content/abstract/scopus_id/85092096474,"Proteomics is nowadays one of the most important and relevant fields from computational biology, raising a lot of challenging and provocative questions. Gaining an understanding of protein dynamic and function as well as obtaining additional insights into the protein folding process is still of great interest in bioinformatics and medicine. This paper introduces a new approach 
                        
                           A
                           n
                           o
                           m
                           a
                           l
                           P
                        
                      for detecting anomalous protein conformational transitions using deep autoencoders for encoding information about the structural similarity between proteins belonging to the same superfamily. Experiments are conducted on real protein data and the obtained results emphasize the potential of autoencoders to learn biological relevant patterns, such as proteins’ structural characteristics and that they are useful for detecting conformations or proteins which are likely to be anomalous with respect to a superfamily. The study performed in this paper is aimed to provide better insights of proteins structural similarity, with the broader goal of learning to predict proteins conformational transitions.",science
10.1016/j.patter.2021.100220,Journal,Patterns,scopus,2021-03-12,sciencedirect,Safe Blues: The case for virtual safe virus spread in the long-term fight against epidemics,https://api.elsevier.com/content/abstract/scopus_id/85102307395,"Viral spread is a complicated function of biological properties, the environment, preventative measures such as sanitation and masks, and the rate at which individuals come within physical proximity. It is these last two elements that governments can control through social-distancing directives. However, infection measurements are almost always delayed, making real-time estimation nearly impossible. Safe Blues is one way of addressing the problem caused by this time lag via online measurements combined with machine learning methods that exploit the relationship between counts of multiple forms of the Safe Blues strands and the progress of the actual epidemic. The Safe Blues protocols and techniques have been developed together with an experimental minimal viable product, presented as an app on Android devices with a server backend. Following initial exploration via simulation experiments, we are now preparing for a university-wide experiment of Safe Blues.",science
10.1016/j.neucom.2020.11.049,Journal,Neurocomputing,scopus,2021-03-07,sciencedirect,Aspect-level sentiment analysis using context and aspect memory network,https://api.elsevier.com/content/abstract/scopus_id/85099254604,"With the popularity of social networks, sentiment analysis has become one of the hottest topics in natural language processing (NLP). As the development of research on the fine-grained sentiment analysis, more and more researchers pay attention to aspect-level sentiment analysis. It aims to identify the same or different sentiment polarity in different aspects of the context. In this paper, a context and aspect memory network (CAMN) method is proposed to solve the problem of aspect level sentiment analysis. In this method, deep memory network, bi-directional long short-term memory network and multi-attention mechanism are introduced to better capture the sentiment features in short texts. It includes two strategies: one is to use the self-attention mechanism (i.e., CAMN-SA) to calculate the context relevance; the other is to use the encoder-decoder attention mechanism (i.e., CAMN-ED) to calculate the context and aspect relevance. In order to verify the function of each component in the proposed method, and to test the effect of different hops on the memory network, we conduct many experiments on three real-world datasets to compare the baseline models with our proposed method. Experimental results show that our proposed method can achieve better performance than the baseline models.",science
10.1016/j.neucom.2020.11.066,Journal,Neurocomputing,scopus,2021-03-07,sciencedirect,BayeSuites: An open web framework for massive Bayesian networks focused on neuroscience,https://api.elsevier.com/content/abstract/scopus_id/85098065075,"BayeSuites is the first web framework for learning, visualizing, and interpreting Bayesian networks (BNs) that can scale to tens of thousands of nodes while providing fast and friendly user experience. All the necessary features that enable this are reviewed in this paper; these features include scalability, extensibility, interoperability, ease of use, and interpretability. Scalability is the key factor in learning and processing massive networks within reasonable time; for a maintainable software open to new functionalities, extensibility and interoperability are necessary. Ease of use and interpretability are fundamental aspects of model interpretation, fairly similar to the case of the recent explainable artificial intelligence trend. We present the capabilities of our proposed framework by highlighting a real example of a BN learned from genomic data obtained from Allen Institute for Brain Science. The extensibility properties of the software are also demonstrated with the help of our BN-based probabilistic clustering implementation, together with another genomic-data example.",science
10.1016/j.ecoinf.2021.101231,Journal,Ecological Informatics,scopus,2021-03-01,sciencedirect,Collect and analysis of agro-biodiversity data in a participative context: A business intelligence framework,https://api.elsevier.com/content/abstract/scopus_id/85100383752,"In France and Europe, farmland represents a large fraction of land cover. The study and assessment of biodiversity in farmland is therefore a major challenge. To monitor biodiversity across wide areas, citizen science programs have demonstrated their effectiveness and relevance. The involvement of citizens in data collection offers a great opportunity to deploy extensive networks for biodiversity monitoring. But citizen science programs come with two issues: large amounts of data to manage and large numbers of participants with heterogeneous skills, needs and expectations about these data. In this article, we offer a solution to these issues, concretized by an information system. The study is based on a real life citizen science program tailored for farmers. This information system provides data and tools at several levels of complexity, to fit the needs and the skills of several users, from citizens with basic IT knowledge to scientists with strong statistical background. The proposed system is designed as follows. First, a data warehouse stores the data collected by citizens. This data warehouse is modelled depending on future data analysis. Secondly, associated with the data warehouse, a standard OLAP tool enables citizens and scientists to explore data. To complete the OLAP tool, we implement and compare four feature selection methods, in order to rank explanatory factors according to their relevance. Finally, for users with extended statistical skills, we use Generalized Linear Mixed Models to explore the temporal dynamics of invertebrate diversity in farmland ecosystems. The proposed system, a combination of business intelligence tools, data mining methods and advanced statistics, offers an example of complete exploitation of data by several user profiles. The proposition is supported by a real life citizen science program, and can be used as a guideline to design information systems in the same field.",science
10.1016/j.chemphyslip.2021.105049,Journal,Chemistry and Physics of Lipids,scopus,2021-03-01,sciencedirect,Antiviral activity of stearylamine against chikungunya virus,https://api.elsevier.com/content/abstract/scopus_id/85100148703,"Chikungunya, a mosquito-borne disease that causes high fever and severe joint pain in humans, is a profound global threat because of its high rate of contagion and lack of antiviral interventions or vaccines for controlling the infection. The present study was aimed to investigate the antiviral activity of Stearylamine (SA) against Chikungunya virus (CHIKV) in both in vitro and in vivo. The antiviral activity of SA was determined by foci forming unit (FFU) assay, quantitative RT-PCR and cell-based immune-fluorescence assay (IFA). Further in vivo studies were carried out to see the effect of SA treatment in CHIKV infected C57BL/6 mice. The anti-CHIKV activity was evaluated using qRT-PCR in serum and muscle tissues at different time points and by histopathology. In vitro treatment with SA at a concentration of 50 μM showed a reduction of 1.23 ± 0.19 log10 FFU/mL at 16 h and 1.56 ± 0.12 log10 FFU/mL at 24 h posttreatment by FFU assay. qRT-PCR studies indicated that SA treatment at 50μM concentration showed a singnificant reduction of 1.6 ± 0.1 log10 and 1.27 ± 0.12 log10 RNA copies when compared with that of virus control at 16 and 24 h post incubation. Treatments in the C57BL/6 mice model revealed that SA at 20 mg/kg dose per day up to 3, 5 and 7 days, produced stronger inhibition against CHIKV indicating substantially decrease viral loads and inflammatory cell migration in comparison to a dose of 10 mg/kg. This first in vivo study clearly indicates that SA is effective by significantly reducing virus replication in serum and muscles. As a next-generation antiviral therapeutic, these promising results can be translated for the use of SA to rationalize and develop an ideal delivery system alone or in combination against CHIKV.",science
10.1016/j.berh.2021.101662,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2021-03-01,sciencedirect,Managing patients using telerheumatology: Lessons from a pandemic,https://api.elsevier.com/content/abstract/scopus_id/85100105533,"The coronavirus disease 2019 (COVID-19) pandemic has presented unique challenges to rheumatology provision. Measures to control the pandemic have limited face-to-face contact with rheumatology healthcare professionals. One innovation has been the widespread adoption of telerheumatology to assist in the care of patients with rheumatic and musculoskeletal diseases, building on an existing evidence base in rheumatology. Widespread adoption has only occurred following the COVID-19 pandemic. We discuss the evidence supporting telerheumatology adoption prior to the pandemic, and outline several innovative approaches used to assist in the care of rheumatology patients that have been introduced. Alongside the advantages of these interventions, we discuss the limitations and regulatory challenges. Advances must be balanced, considering wider issues of equity of access, implementation, adoption, and sustainability of telerheumatology post-pandemic. We propose it is not ‘if’, but ‘how’ rheumatologists embrace newer telerheumatology technology, outlining practice points and future research agenda.",science
10.1016/j.micpro.2020.103786,Journal,Microprocessors and Microsystems,scopus,2021-03-01,sciencedirect,Student Psychological Management System Based on FPGA Embedded System and Data Mining,https://api.elsevier.com/content/abstract/scopus_id/85099630662,"People are social beings and rarely live and work in detachment and intentionally and unknowingly create and deal with our relationships. Relationships depend primarily on the outcome of our activities and our ability to deal with our actions. From adolescence, each gains information and involvement in getting others and how to proceed in every single situation in daily life. In the existing method based on Convolution neural network and Image Processing system for the Psychological Management system. The drawback of the previous method is uneven communication in Psychological Management. So in the proposed method is based on FPGA (Field Programmable Gate Arrays) and Data Mining. The practice and understanding in communicating and monitoring relationships in our work environment. The whole arrangement of human resource management revolves around this central issue of overseeing relations in the workplace. Utilizing an individual's deep, social, psychological, and intellectual abilities in the planning and implementation from the focus on activity outcomes and emphasis on efforts made by combining the oriental hypothesis of ritual or activity benefit from complimentary brain research from the inadequate approach of the clinical infection model. The data mining method has an incredible guarantee for significant hypnotic commitment, set in real situations, and solves grave results' administrative problems.",science
10.1016/j.watres.2021.116806,Journal,Water Research,scopus,2021-03-01,sciencedirect,Soft sensor predictor of E. coli concentration based on conventional monitoring parameters for wastewater disinfection control,https://api.elsevier.com/content/abstract/scopus_id/85099446770,"Real-time acquisition of indicator bacteria concentration at the inlet of disinfection unit is a fundamental support to the control of chemical and ultraviolet wastewater disinfection. Culture-based enumeration methods need time-consuming laboratory analyses, which give results after several hours or days, while newest biosensors rarely provide information about specific strains and outputs are not directly comparable with regulatory limits as a consequence of measurement principles.
                  In this work, a novel soft sensor approach for virtual real-time monitoring of E. coli concentration is proposed. Conventional wastewater physical and chemical indicators (chemical oxygen demand, total nitrogen, nitrate, ammonia, total suspended solids, conductivity, pH, turbidity and absorbance at 254 nm) and flowrate were studied as potential predictors of E. coli concentration relying on data collected from three full-scale wastewater treatment plants. Different methods were compared: (i) linear modeling via ordinary least squares; (ii) ridge regression; (iii) principal component regression and partial least squares; (iv) non-linear modeling through artificial neural networks.
                  Linear soft sensors reached some degree of accuracy, but performances of the artificial neural network based models were by far superior. Sensitivity analysis allowed to prioritize the importance of each predictor and to highlight the site-specific nature of the approach, because of the site-specific nature of relationships between predictors and E. coli concentration. In one case study, pH and conductivity worked as good proxy variables when the occurrence of intense rain events caused sharp increases in E. coli concentration. Differently, in other case studies, chemical oxygen demand, total suspended solids, turbidity and absorbance at 254 nm accounted for the positive correlation between low wastewater quality and E. coli concentration. Moreover, sensitivity analysis of artificial neural network models highlighted the importance of interactions among predictors, contributing to 25 to 30% of the model output variance. This evidence, along with performance results, supported the idea that nonlinear families of models should be preferred in the estimation of E. coli concentration.
                  The artificial neural network based soft sensor deployment for control of peracetic acid disinfectant dosage was simulated over a realistic scenario of wastewater quality recorded by on-line sensors over 2 months. The scenario simulations highlighted the significant benefit of an E. coli soft sensor, which provided up to 57% of disinfectant saving.",science
10.1016/j.neuroimage.2020.117697,Journal,NeuroImage,scopus,2021-03-01,sciencedirect,You took the words right out of my mouth: Dual-fMRI reveals intra- and inter-personal neural processes supporting verbal interaction.,https://api.elsevier.com/content/abstract/scopus_id/85098970750,"Verbal communication relies heavily upon mutual understanding, or common ground. Inferring the intentional states of our interaction partners is crucial in achieving this, and social neuroscience has begun elucidating the intra- and inter-personal neural processes supporting such inferences. Typically, however, neuroscientific paradigms lack the reciprocal to-and-fro characteristic of social communication, offering little insight into the way these processes operate online during real-world interaction. In the present study, we overcame this by developing a “hyperscanning” paradigm in which pairs of interactants could communicate verbally with one another in a joint-action task whilst both undergoing functional magnetic resonance imaging simultaneously. Successful performance on this task required both interlocutors to predict their partner's upcoming utterance in order to converge on the same word as each other over recursive exchanges, based only on one another's prior verbal expressions. By applying various levels of analysis to behavioural and neuroimaging data acquired from 20 dyads, three principal findings emerged: First, interlocutors converged frequently within the same semantic space, suggesting that mutual understanding had been established. Second, assessing the brain responses of each interlocutor as they planned their upcoming utterances on the basis of their co-player's previous word revealed the engagement of the temporo-parietal junctional (TPJ), precuneus and dorso-lateral pre-frontal cortex. Moreover, responses in the precuneus were modulated positively by the degree of semantic convergence achieved on each round. Second, effective connectivity among these regions indicates the crucial role of the right TPJ in this process, consistent with the Nexus model. Third, neural signals within certain nodes of this network became aligned between interacting interlocutors. We suggest this reflects an interpersonal neural process through which interactants infer and align to one another's intentional states whilst they establish a common ground.",science
10.1016/j.compbiomed.2020.104197,Journal,Computers in Biology and Medicine,scopus,2021-03-01,sciencedirect,A comprehensive comparison of molecular feature representations for use in predictive modeling,https://api.elsevier.com/content/abstract/scopus_id/85098954842,"Machine learning methods are commonly used for predicting molecular properties to accelerate material and drug design. An important part of this process is deciding how to represent the molecules. Typically, machine learning methods expect examples represented by vectors of values, and many methods for calculating molecular feature representations have been proposed. In this paper, we perform a comprehensive comparison of different molecular features, including traditional methods such as fingerprints and molecular descriptors, and recently proposed learnable representations based on neural networks. Feature representations are evaluated on 11 benchmark datasets, used for predicting properties and measures such as mutagenicity, melting points, activity, solubility, and IC50. Our experiments show that several molecular features work similarly well over all benchmark datasets. The ones that stand out most are Spectrophores, which give significantly worse performance than other features on most datasets. Molecular descriptors from the PaDEL library seem very well suited for predicting physical properties of molecules. Despite their simplicity, MACCS fingerprints performed very well overall. The results show that learnable representations achieve competitive performance compared to expert based representations. However, task-specific representations (graph convolutions and Weave methods) rarely offer any benefits, even though they are computationally more demanding. Lastly, combining different molecular feature representations typically does not give a noticeable improvement in performance compared to individual feature representations.",science
10.1016/j.cbpc.2020.108951,Journal,Comparative Biochemistry and Physiology Part - C: Toxicology and Pharmacology,scopus,2021-03-01,sciencedirect,Genipin induces developmental toxicity through oxidative stress and apoptosis in zebrafish,https://api.elsevier.com/content/abstract/scopus_id/85098178184,"Genipin, an iridoid substance, is mainly derived from Gardenia jasminoides Ellis of the traditional Chinese medicine and is widely used in raw materials for the food additive gardenia blue and biological materials. The developmental toxicity of genipin has not been investigated, and its underlying mechanism is unclear. Therefore, in this study we attempt to investigate the potential developmental toxicity of genipin in zebrafish embryos/larvae. The results showed zebrafish embryos treated with 50 μg/ml dose of genipin display inhibited hatching rates and body length. The pericardial edema was observed. It was also found that genipin could induce cardio-toxicity, hepatotoxicity and nephrotoxicity in zebrafish larvae. After genipin treatment, the suppression of antioxidant capacity and increase of oxidative stress were showed for the triggered generation of ROS and MDA, and decreased activity of SOD. Compared with the 0.5% DMSO group, a number of apoptotic cells in zebrafish were increased after genipin exposure. By measuring marker gene expression with the using of qRT-PCR, we proposed that developmental toxicity after genipin treatment might be associated with oxidative stress and apoptosis increase. Our research offers a better understanding for developmental toxicity of genipin.",science
10.1016/j.radphyschem.2020.109300,Journal,Radiation Physics and Chemistry,scopus,2021-03-01,sciencedirect,Development of a radionuclide identification algorithm based on a convolutional neural network for radiation portal monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85097339486,"At border crossings around the world, plastic scintillator-based radiation portal monitors (RPMs) are employed to detect the presence of illicit radioactive materials in large trailer trucks. However, the RPM system shows a low energy resolution owing to the large size and physical characteristics of plastic scintillators; and thus, the identification of illicit artificial isotopes from naturally occurring radioactive material is difficult. This study aims to develop an advanced algorithm for radionuclide identification with commercial RPMs based on commercial plastic scintillators to reduce the occurrence of frequent nuisance alarms. Subsequently, machine learning models, namely, a convolutional neural network (CNN) was applied. The spectral distributions of energy weighted spectra were used as features of the CNN model. The energy spectra of 137Cs, 60Co, 226Ra, and 40K measured under static and moving conditions were used to implement the identification model. To evaluate the performance of the implemented model, the F-score was used. The trained CNN model correctly identified most of the radionuclides. That is, despite the theoretical Compton edge energies of 60Co and 40K being similar, the spectral distributions of 40K are distinctively different from those of 60Co. The result demonstrates that the CNN model-based identification algorithm performs robust radionuclide identification, thereby reducing the frequency of nuisance alarms at border crossings. Furthermore, considering that the actual cases of cargo passing by the RPMs are becoming more complicated, the algorithm would need to be continuously improved and trained with more complex scenarios in the future.",science
10.1016/j.jep.2020.113538,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,Developmental toxicity of Clerodendrum cyrtophyllum turcz ethanol extract in zebrafish embryo,https://api.elsevier.com/content/abstract/scopus_id/85096104462,"Ethnopharmacological relevance
                  
                     Clerodendrum cyrtophyllum Turcz has been used in traditional medicine for the treatment of various diseases. In spite of its therapeutic applications, research on its toxicity and teratogenicity is still limited.
               
                  Aim of the study
                  The study aimed to investigate the developmental toxicity of the ethanol extract of C. cyrtophyllum (EE) in zebrafish embryo model.
               
                  Material and methods
                  Major compounds from crude ethanol extract of Clerodendron cyrtophyllum Turcz leaves were determined using HPLC-DAD-Orbitrap-MS analysis
                        .
                      The developmental toxicity of EE were investigated using zebrafish embryo model. Zebrafish embryos at 6 h post-fertilization (hpf) were treated with EE at different concentrations. Egg coagulation, mortality, hatching, yolk sac edema, pericardial edema and teratogenicity were recorded each day for during a 5-day exposure. At time point 120 hpf, body length, pericardial area, heartbeat and yolk sac area were assessed. In order to elucidate molecular mechanisms for the developmental toxicity of EE, we further evaluated the effects of the EE on the expression of genes involved on signaling pathways affecting fish embryo’s development such as heart development (gata5, myl7, myh6, has2, hand2, nkx 2.5), oxidative stress (cat, sod1, gpx4, gstp2), wnt pathway (β-catenin, wnt3a, wnt5, wnt8a, wnt11), or cell apoptosis (p53, bax, bcl2, casp3, casp8, casp9, apaf-1, gadd45bb) using qRT-PCR analysis.
               
                  Results
                  Our results demonstrated that three major components including acteoside, cirsilineol and cirsilineol-4'-O-β-D-glucopyranoside were identified from EE. EE exposure during 6–96 h post-fertilization (hpf) at doses ranging from 80 to 200 μg/mL increased embryo mortality and reduced hatching rate. EE exposure at 20 and 40 μg/mL until 72–120 hpf induced a series of malformations, including yolk sac edema, pericardial edema, spine deformation, shorter body length. Based on two prediction models using a teratogenic index (TI), a 25% lethality concentration (LD25) and the no observed-adverse-effect level (NOAEL), EE is considered as teratogenic for zebrafish embryos with TI (LC50/EC50) and LD25/NOAEC values at 96 hpf reaching 3.87 and 15.73 respectively. The mRNA expression levels of p53, casp8, bax/bcl2, gstp2, nkx2.5, wnt3a, wnt11, gadd45bb and gata5 were significantly upregulated by EE exposure at 20 and 40 μg/mL while the expression of wnt5, hand2 and bcl2 were downregulated.
               
                  Conclusions
                  These results provide evidence for toxicity effects of EE to embryo stages and provide an insight into the potential toxicity mechanisms on embryonic development.",science
10.1016/j.jep.2020.113516,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,The anti-inflammatory potential of Cinnamomum camphora (L.) J.Presl essential oil in vitro and in vivo,https://api.elsevier.com/content/abstract/scopus_id/85094843041,"Ethnopharmacological relevance
                  Borneol was widely used in traditional Chinese medicine formulas due to its pharmacological activities, e.g. sedative, anti-inflammatory, and anti-ischemic properties. Cinnamomum camphora (L.) J.Presl essential oil (BEO) is a by-product of natural crystalline borneol (NCB) production obtained by steam distillation of Cinnamomum camphora (L.) J.Presl leaves, and borneol was the main component of BEO. This study aims to investigate the anti-inflammatory effect of BEO and its corresponding mechanisms through in vitro and in vivo studies.
               
                  Materials and methods
                  Human erythrocyte membrane stability assay and the acute inflammation murine model (xylene-induced ear edema) were chosen to evaluate the anti-inflammatory effect of BEO. Expression of inflammatory mediators, including interleukin (IL)-1β, IL-6, and tumor necrosis factor α (TNF-α) was determined by real-time quantitative polymerase chain reaction (RT-PCR) and enzyme-linked immunosorbent assays (ELISA). The functional compounds in the BEO were identified by using gas chromatography-mass spectrometry (GC-MS). The steady-state transdermal diffusion rates of BEO and BEO nano-emulsion with were also determined in this study. Cytotoxicity of BEO was analyzed by cell counting kit-8 (CCK-8) assay.
               
                  Results
                  The BEO showed a high human erythrocyte membrane stabilization by inhibiting heat-induced hemolysis (IC50 = 5.29 mg/mL) and hypotonic solution-induced hemolysis (IC50 = 0.26 mg/mL) in vitro. The BEO was topically applied to mice auricles, both single and repeated administration significantly reduced xylene-induced auricle swelling (p < 0.0001). Expression of inflammatory mediators, including interleukin (IL)-1β, IL-6, and tumor necrosis factor α (TNF-α) in serum and tissue was significantly downregulated (p < 0.05), so as to the mRNA expression of IL-1β (p＜0.05) and TNF-α (p < 0.001). A total of 43 components were identified and quantified by GC-MS. The most abundant was borneol [178.3 mg/mL, 20.9% (m/v)], followed by β-caryophyllene (116.3 mg/mL), camphor (115.2 mg/mL), and limonene (89.4 mg/mL). For determining the skin permeability of BEO, the steady-state transdermal diffusion rates of BEO and BEO nano-emulsion were determined to be 6.7 and 8.9 mg/cm2·h, respectively.
               
                  Conclusion
                  It is suspected that the anti-inflammatory effects in vivo and in vitro were derived from the above-mentioned components in the BEO. These findings will facilitate the development of BEO as a new and natural therapeutic agent for inflammatory skin conditions.",science
10.1016/j.jep.2020.113462,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,Tongmai Yangxin pill reduces myocardial No-reflow via endothelium-dependent NO-cGMP signaling by activation of the cAMP/PKA pathway,https://api.elsevier.com/content/abstract/scopus_id/85093647916,"Ethnopharmacological relevance
                  The Tongmai Yangxin pill (TMYX) is derived from the Zhigancao decoction recorded in Shang han lun by Zhang Zhongjing during the Han dynasty. TMYX is used for the clinical treatment of chest pain, heartache, and qi-yin-deficiency coronary heart disease. Previous studies have confirmed that TMYX can improve vascular endothelial function in patients with coronary heart disease by upregulating nitric oxide activity and then regulating vascular tension. Whether TMYX can further improve myocardial NR by upregulating NO activity and then dilating blood vessels remains unclear.
               
                  Aim of the study
                  This study aimed to reveal whether TMYX can further improve myocardial NR by upregulating NO activity and then dilating blood vessels. The underlying cAMP/PKA and NO-cGMP signaling pathway-dependent mechanism is also explored.
               
                  Materials and methods
                  The left anterior descending coronary arteries of healthy adult male SD rats were ligated to establish the NR model. TMYX (4.0 g/kg) was orally administered throughout the experiment. Cardiac function was measured through echocardiography. Thioflavin S, Evans Blue, and TTC staining were used to evaluate the NR and ischemic areas. Pathological changes in the myocardium were assessed by hematoxylin–eosin staining. An automated biochemical analyzer and kit were used to detect the activities of myocardial enzymes and myocardial oxidants, including CK, CK-MB, LDH, reactive oxygen species, superoxide dismutase, malonaldehyde, and NO. The expression levels of genes and proteins related to the cAMP/PKA and NO/cGMP signaling pathways were detected via real-time fluorescence quantitative PCR and Western blot analysis, respectively. A microvascular tension sensor was used to detect coronary artery diastolic function in vitro.
               
                  Results
                  TMYX elevated the EF, FS, LVOT peak, LVPWd and LVPWs values, decreased the LVIDd, LVIDs, LV-mass, IVSd, and LV Vols values, demonstrating cardio-protective effects, and reduced the NR and ischemic areas. Pathological staining showed that TMYX could significantly reduce inflammatory cell number and interstitial edema. The activities of CK, LDH, and MDA were reduced, NO activity was increased, and oxidative stress was suppressed after treatment with TMYX. TMYX not only enhanced the expression of Gs-α, AC, PKA, and eNOS but also increased the expression of sGC and PKG. Furthermore, TMYX treatment significantly decreased ROCK expression. We further showed that TMYX (25–200 mg/mL) relaxed isolated coronary microvessels.
               
                  Conclusions
                  TMYX attenuates myocardial NR after ischemia and reperfusion by activating the cAMP/PKA and NO/cGMP signaling pathways, further upregulating NO activity and relaxing coronary microvessels.",science
10.1016/j.measurement.2020.108554,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-03-01,sciencedirect,Tool wear mechanism and prediction in milling TC18 titanium alloy using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85092319229,"Rapid tool wear from milling TC18 (Ti-5Al-5Mo-5V-1Cr-1Fe) leads to increased surface deterioration and manufacturing costs. Here, a real-life tool wear experiment was introduced, and the three stages of tool wear were analyzed in detail according to the tool wear micro-topography and chemical elements. In the initial and normal stage, the tool wear was slow because of the protection of the adhesive titanium layer and dense alumina film. Diffusion wear and oxidation wear occurred until the sever wear stage. Based on the above wear mechanism determination, after acquiring the real time cutting force, the tool wear prediction models were established using a convolutional bi-directional long short-term memory networks (CNN + BILSTM) and a convolutional bi-directional gated recurrent unit (CNN + BIGRU). The results show that the errors of the predicted minimum values are all within 8%, demonstrating that the deep learning method offers a new and promising approach for in monitoring tool wear on-line.",science
10.1016/j.patcog.2020.107671,Journal,Pattern Recognition,scopus,2021-03-01,sciencedirect,EKENet: Efficient knowledge enhanced network for real-time scene parsing,https://api.elsevier.com/content/abstract/scopus_id/85091792250,"Scene parsing is essential for many high-level AI applications, such as intelligent vehicles and traffic surveillance. In this work, we propose a highly efficient and powerful deep convolutional neural network, namely Efficient Knowledge Enhanced Network (EKENet), for parsing scenes in real-time. Unlike most existing approaches that compromise efficiency for the sake of high accuracy, EKENet achieves an ideal trade-off between the two. Our EKENet is built upon a novel building block, namely Efficient Dual Abstraction (EDA) block, which employs an efficiently parallel convolution structure for extracting spatial features and modeling cross-channel correlations in a dual fashion. Additionally, a novel light-weight Encoding-Enhancing (EE) module is designed to enhance our EKENet, which can efficiently encode high-level knowledge extracted from top layers to guide the learning of low-level features from bottom layers.
                  Extensive experiments on challenging benchmarks, Cityscapes and CamVid datasets, demonstrate that EKENet achieves the new state-of-the-art performance in terms of speed and accuracy tradeoff.",science
10.1016/j.eswa.2020.113957,Journal,Expert Systems with Applications,scopus,2021-03-01,sciencedirect,Learning ladder neural networks for semi-supervised node classification in social network,https://api.elsevier.com/content/abstract/scopus_id/85090356651,"Graph convolutional networks (GCNs) and network embedding are the two main categories of popular methods for Semi-Supervised Node Classification (SSNC) in social network. However, the former is commonly oriented to attributed networks with efficient auxiliary information in nodes. The latter is usually not geared towards specific graph mining tasks. Therefore, these methods often perform poorly for specific tasks in non-attributed networks. To solve the above problems, in this paper, we propose a novel semi-supervised Node Classification method with Ladder Neural Networks named NCLNN for non-attributed network. We first preprocess the graph for capturing the structural information. Then we present and learn a deep ladder neural network for SSNC. Our trained ladder neural networks could combine supervised learning with unsupervised learning in deep neural networks via simultaneously minimizing the sum of supervised and unsupervised loss functions. Extensive experiments on three real-world network datasets demonstrate that the proposed NCLNN substantially outperforms the state-of-the-art methods on SSNC task.",science
10.1016/j.knosys.2020.106734,Journal,Knowledge-Based Systems,scopus,2021-02-28,sciencedirect,Algorithm for detecting anomalous hosts based on group activity evolution,https://api.elsevier.com/content/abstract/scopus_id/85098969811,"Network behavior analysis is an active and challenging research direction in anomalous network traffic detection. With rapidly-increasing popularity of online applications, network traffic volume has grown exponentially. In the meantime, network communication is becoming more complex. Consequently, new interaction patterns of network behaviors, named group activity, need to be investigated. Group activities can be generated by various hosts over the network and changes in group activities usually cannot be captured by traditional anomaly detection methods. Currently, the primary limitation of traditional flow-based methods for network traffic analysis is the lack of a mechanism that studies the social relationship in the interaction patterns between hosts. Besides, existing approaches fail to detect group activities. To overcome these limitations, the paper aims to detect anomalous hosts based on the profile of group activity evolution. We propose a mathematical method to quantify and detect anomalous group activities based on the stability of group activity evolution, which fully captures both the temporal and structural characteristics of network evolution. This anomaly detection algorithm is called GAP (Group Activity Profile), which is a powerful supplement and extension of the traditional method of network behavior analysis. The main contributions of this paper are: (1) the paper introduces a new perspective of the group activity based on network evolution and network behavior anomaly detection; (2) the algorithm is suitable for measuring the changes in group activity evolution and determining whether the current evolution relatively conforms to or deviates from the normal evolution; and (3) this work defines the baseline of the group activity evolution by applying historical characteristics that can significantly reduce the false positive rate, and detect anomalous hosts accurately. The results of experiments conducted on real datasets demonstrate that GAP is capable of detecting anomalous host more effectively than traditional methods. GAP is free of parameters and achieves high scalability, which can effectively identify group activities as well as accurately detect anomalous hosts over time.",science
10.1016/j.conbuildmat.2020.121928,Journal,Construction and Building Materials,scopus,2021-02-22,sciencedirect,Employing a hybrid GA-ANN method for simulating fracture toughness of RCC mixture containing waste materials,https://api.elsevier.com/content/abstract/scopus_id/85098054250,"The present study is conducted to investigate the efficiency of evolutionary algorithms such as genetic algorithm (GA)-evolved neural network in estimating fracture properties of roller compacted concrete pavement (RCCP) mixtures with different compositions. The effect of waste materials, including reclaimed asphalt pavement (RAP) and crumb rubber on fracture toughness in both pure mode I and pure mod II, were investigated using a real coded GA and an evolution with a back-propagation algorithm. Moreover, the geometry effect of SCB and 4 PB specimens on predicting fracture toughness was evaluated using GA. To evaluate the GA-based neural network's performance, the NSE criterion was applied for fitness function, a different approach for fitting in this area. Many researchers have studied the fracture behavior of RCC in diverse modes. Still, their studies have been restricted to the materials' fracture behavior, which has rarely come to a model. As pure mode II fracture toughness experiment is a complicated procedure with high uncertainties, the introduced model provides a powerful tool for predicting mode II fracture toughness via mix composition and pure mode I fracture toughness of RCC based on GA. The proposed model outperforms the traditional artificial neural network (ANN) models. The geometry effect survey on predicting fracture toughness shows that the 4 PB fracture model has been better fitted to observed data. Also, the MSE results show that prismatic specimens present relatively reliable results than SCB specimens.",science
10.1016/j.quaint.2020.08.018,Journal,Quaternary International,scopus,2021-02-20,sciencedirect,Characterization of geomorphological features of lunar surface using Chandrayaan-1 Mini-SAR and LRO Mini-RF data,https://api.elsevier.com/content/abstract/scopus_id/85090021453,"The lunar surface comprises complex geomorphological features, which have been formed by the conjunction of processes namely impact cratering and volcanism. Geological features on the Lunar surface can be bifurcated into two main areas named Maria region and the Highland region. Taurus-Littrow valley, which was the Apollo-17 mission landing site, consisting of unique geomorphological characteristics by having a sample size of both Lunar Maria and Highland regions. The dielectric constant is a parameter that gives an approximate distribution of the constituent material of the target area. It is a complex quantity, which indicates a periodic variation of the electric field. The real part of dielectric constant indicates stored energy and the imaginary part indicates dielectric loss factor or the loss of the electric field in the medium due to continuous varying electric field. Planetary surfaces for which determining dielectric constant is an important analysis for most of the space missions, ground measurement is not feasible. This work includes the machine learning-based modeling of dielectric constant for the Apollo 17 landing site the Taurus-Littrow valley. Based on the surface roughness of the study area, two models Gaussian and Exponential have been implemented and compared for the modeled output of the dielectric constant values.The modeling approaches for dielectric characterization of the lunar surface were implemented on NASA's LRO Mini-RF SAR data and Mini-SAR hybrid-pol data of ISRO's Chandrayaan-1 mission. The coefficient of determination (r2) and the root mean square error (RMSE) of the theoretical Gaussian model was 0.995, 0.042 and the Exponential model was 0.948, 0.1349 respectively. When compared with the already calculated values of dielectric constant from Apollo 17 return samples and literature survey, the Gaussian model gives a better variation. Gaussian model was further applied to the Lunar north pole crater namely Hermite-A crater, whose distinctive geomorphological characteristics and location being lunar north pole region, makes it one of the coldest places in the Solar System and a prominent location of water ice deposits.",science
10.1016/j.jcp.2020.110069,Journal,Journal of Computational Physics,scopus,2021-02-15,sciencedirect,Active- and transfer-learning applied to microscale-macroscale coupling to simulate viscoelastic flows,https://api.elsevier.com/content/abstract/scopus_id/85098854830,"Active- and transfer-learning are applied to microscale dynamics of polymer flows for the multiscale discovery of effective constitutive approximations required in viscoelastic flow simulation. The result is macroscopic rheology directly connected to a microstructural model. Micro and macroscale simulations are adaptively coupled by means of Gaussian process regression (GPR) to run the expensive microscale computations only as necessary. This multiscale method is demonstrated with flows of a polymer solution as a model system. At the microscale level dissipative particle dynamics (DPD) is employed to model the fluid as a suspension of bead-spring micro-structures subjected to steady shear flow. The results yield the non-Newtonian viscosity and the first normal stress difference at strain rates as training data used in a GPR model. DPD parameters are calibrated with respect to experimental data for a real polymer solution. Compliance with these data requires adjustment of the DPD model's cutoff radius, which then becomes a function of the second invariant of the strain rate tensor. The FENE-P model is chosen for the macroscale description using the spectral element method (SEM) to simulate channel flow and flow past a circular cylinder. The DPD results at the lowest possible shear strain rate yield an estimate of the zero-shear rate viscosity, which allows the initiation of the macroscale flow by SEM as a Newtonian fluid. The resulting strain-rate field is surveyed to determine additional shear strain rate sampling points for the DPD system. This new information allows an initial fitting of parameters of the constitutive equation followed by new SEM simulations at the macroscale. Guided by active-learning GPR to select new sampling points, this process continues until convergence is achieved.
                  The effectiveness of this new simulation paradigm for viscoelastic flows is tested with different macroscale operating conditions. The effective closure learned in the channel simulation is then transferred directly to the flow past a circular cylinder at low Reynolds number, where the results show that only two additional DPD simulations are required to achieve a satisfactory constitutive model. With an increase of the Reynolds number, the active-learning scheme automatically detects the inaccuracy of the learned constitutive model, and initiates additional DPD simulations for the extra data needed to once again close the microscale-macroscale coupled system. This new paradigm of active- and transfer-learning for multiscale modeling is readily applicable to other microscale-macroscale coupled simulations of complex fluids and other materials. Furthermore, the coupling between microscale and macroscale solvers can be seamlessly implemented with our open source multiscale universal interface (MUI) library.",science
10.1016/j.abb.2020.108730,Journal,Archives of Biochemistry and Biophysics,scopus,2021-02-15,sciencedirect,Artificial intelligence in the early stages of drug discovery,https://api.elsevier.com/content/abstract/scopus_id/85098095696,"Although the use of computational methods within the pharmaceutical industry is well established, there is an urgent need for new approaches that can improve and optimize the pipeline of drug discovery and development. In spite of the fact that there is no unique solution for this need for innovation, there has recently been a strong interest in the use of Artificial Intelligence for this purpose. As a matter of fact, not only there have been major contributions from the scientific community in this respect, but there has also been a growing partnership between the pharmaceutical industry and Artificial Intelligence companies. Beyond these contributions and efforts there is an underlying question, which we intend to discuss in this review: can the intrinsic difficulties within the drug discovery process be overcome with the implementation of Artificial Intelligence? While this is an open question, in this work we will focus on the advantages that these algorithms provide over the traditional methods in the context of early drug discovery.",science
10.1016/j.foodchem.2020.128134,Journal,Food Chemistry,scopus,2021-02-15,sciencedirect,Improving the freeze-drying survival rate of Lactobacillus plantarum LIP-1 by increasing biofilm formation based on adjusting the composition of buffer salts in medium,https://api.elsevier.com/content/abstract/scopus_id/85091328210,"Lactic acid bacteria can improve their resistance to adverse environments through the formation of biofilm. This study found that adding different buffer salts in culture medium had a great impact on the freeze-drying survival rate of the Lactobacillus plantarum LIP-1, which could be linked to biofilm formation. Transcriptome data showed that potassium ions in buffer salt increased the expression of the luxS gene in the LuxS/autoinducer-2 (AI-2) quorum sensing system and increase synthesis of the quorum sensing signal AI-2. The AI-2 signal molecules up-regulated the cysE gene, which helps to promote biofilm formation. By adding a biofilm inhibitor, d-galactose, and performing a real-time quantitative polymerase chain reaction experiment, we found that d-galactose could down-regulated the luxS and cysE genes, reduced biofilm formation, and decreased the freeze-drying survival rate. The results of this study showed that promoting biofilm formation using appropriate buffer salts may lead to better freeze-drying survival rates.",science
10.1016/j.patter.2020.100195,Journal,Patterns,scopus,2021-02-12,sciencedirect,Topic classification of electric vehicle consumer experiences with transformer-based deep learning,https://api.elsevier.com/content/abstract/scopus_id/85100638713,"The transportation sector is a major contributor to greenhouse gas (GHG) emissions and is a driver of adverse health effects globally. Increasingly, government policies have promoted the adoption of electric vehicles (EVs) as a solution to mitigate GHG emissions. However, government analysts have failed to fully utilize consumer data in decisions related to charging infrastructure. This is because a large share of EV data is unstructured text, which presents challenges for data discovery. In this article, we deploy advances in transformer-based deep learning to discover topics of attention in a nationally representative sample of user reviews. We report classification accuracies greater than 91% (F1 scores of 0.83), outperforming previously leading algorithms in this domain. We describe applications of these deep learning models for public policy analysis and large-scale implementation. This capability can boost intelligence for the EV charging market, which is expected to grow to US$27.6 billion by 2027.",science
10.1016/j.ins.2020.08.042,Journal,Information Sciences,scopus,2021-02-08,sciencedirect,Network-based evidential three-way theoretic model for large-scale group decision analysis,https://api.elsevier.com/content/abstract/scopus_id/85090357359,"Social relationships are critical to the group decision-making (GDM) process, especially for large-scale scenarios. Conventional GDM models have several drawbacks when applied to large-scale GDM problems. In this paper, we propose an evidential three-way theoretic model for large-scale group decision analysis based on the introduction of ego networks. A similarity matrix of all individuals is obtained after ego network generation via social network feature extraction. Rough and smooth detection are then conducted in the framework of three-way decisions. Specifically, the degree of organizational influence is analyzed based on the generated basic probability assignments (BPAs), and the individuals are divided into several organizations. After an opinion collection process, preference evolution is implemented via a social influence network (SIN) technique and a fuzzy preference relation (FPR) model. Then, the global final scores of all the alternatives are obtained using an aggregation process. Finally, we conduct a simulation experiment to illustrate the entire procedure. Based on a comparison of related methods, we believe that the proposed method can reasonably solve real-world large-scale group decision-making (LSGDM) problems and has good practicability and effectiveness.",science
10.1016/j.ins.2020.08.088,Journal,Information Sciences,scopus,2021-02-08,sciencedirect,Towards real-time demand-aware sequential POI recommendation,https://api.elsevier.com/content/abstract/scopus_id/85090167726,"Next point-of-interest (POI) recommendation has gained growing attention in recent years due to the emergence of location-based social networks (LBSN) services. Most existing approaches focus on learning user’s preferences to POIs from check-in records and recommend a POI to visit next given his/her previously visited POIs. However, the user’s visiting behavior is not only driven by user preferences in real-world scenarios. The real-time demand is another crucial factor to determine the user’s visiting behaviors, which is usually neglected in established approaches. In this paper, we propose a new next point-of-interest (POI) recommendation method, called DSPR, by exploring user’s preferences and real-time demand simultaneously. To model the real-time demand, different kinds of contextual information are exploited, such as absolute time, POI–POI transition time/distance, and the types of POIs. By incorporating user’s preferences, these contextual factors are further modeled and learned automatically with an attention-based recurrent neural network model to support the final next POI recommendation. Experiments on three real-world check-in datasets show that DSPR has better recommendation performance compared with many state-of-the-art methods.",science
10.1016/j.bbr.2020.113027,Journal,Behavioural Brain Research,scopus,2021-02-05,sciencedirect,Increased pSTS activity and decreased pSTS-mPFC connectivity when processing negative social interactions,https://api.elsevier.com/content/abstract/scopus_id/85096988145,"We have previously shown that activity and connectivity within and between the action observation and mentalizing brain systems reflect the degree of positive dimensions expressed by social interactions such as cooperativity and affectivity, respectively. Here we aim to extend this evidence by investigating the neural bases of processing negative dimensions of observed interactions, such as competition and affective conflict, possibly representing a benchmark for different pathological conditions.
                  In this fMRI study 34 healthy participants were shown pictures depicting interactions characterized by two crossed dimensions, i.e. positively- vs. negatively- connotated social intentions mainly expressed in terms of motor acts vs. mental states, i.e. cooperative, competitive, affective and conflicting interactions.
                  We confirmed the involvement of the action observation and mentalizing networks in processing intentions mainly expressed through motor acts (cooperative/competitive) vs. mental states (affective/conflicting), respectively. Results highlighted the selective role of the left pSTS/TPJ in decoding social interactions, even when compared with parallel actions by non-interacting individuals. Its right-hemispheric homologue displayed stronger responses to negative than positive social intentions, regardless of their motor/mental status, and decreased connectivity with the medial prefrontal cortex (mPFC) when processing negative interactions. The resulting mPFC downregulation by negative social scenes might reflect an adaptive response to socio-affective threats, via decreased mentalizing when facing negative social stimuli.
                  This evidence on the brain mechanisms underlying the decoding of real complex interactions represents a baseline for assessing both the neural correlates of impaired social cognition, and the effects of rehabilitative treatments, in neuro-psychiatric diseases or borderline conditions such as loneliness.",science
10.1016/j.micpro.2020.103624,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,FPGA processor and visual keyword matching to optimize feature recognition of tourism resources,https://api.elsevier.com/content/abstract/scopus_id/85102975560,"Confirm information from the web page is a critical issue to support tourism activities. These steps are based on how the analysis and synthesis of a web page article grammatical structure. Semantic structure is a single sentence or a fragment of the marked text. This is a characteristic of developing useful tourist information from a web page to identify the way. Identification, development, and utilization of tourism resources have proved inseparable from the earth sciences. In this case, the literature does not explain Earth's tourism resources' characteristics from a scientific point of almost complete. Still, it is only mentioned in the discussion of the operation of tourism resources and tourism. Machine learning algorithms are used in the proposed architecture, which resembles a field-programmable gate array to achieve. FPGA implementation of a fixed point, comparing classification performance.",science
10.1016/j.ebiom.2021.103213,Journal,EBioMedicine,scopus,2021-02-01,sciencedirect,Interleukin-24 protects against liver injury in mouse models,https://api.elsevier.com/content/abstract/scopus_id/85099987105,"Background
                  Interleukin-24 (IL-24) binds to two kinds of receptor complexes, namely IL-20R1/IL-20R2 and IL-20R2/IL-22R1, which are also bound by IL-20. IL-20 plays a detrimental role in liver fibrosis. Due to the sharing of receptor complexes, we aimed to determine whether IL-24 also participates in liver fibrosis.
               
                  Methods
                  Clinical biopsy specimens from various stages of liver fibrosis were used to analyze IL-24 expression. IL-24 protein was administered to mice with thioacetamide (TAA)-induced liver injury. The direct effects of IL-24 on mouse primary hepatocytes or hepatic stellate cells (HSCs) were analyzed. Wild-type, IL-20R1-, and IL20R2-deficient mice were used to establish a model of acute TAA-induced liver injury.
               
                  Findings
                  Among patients with more severe liver fibrosis, there was a reduced IL-24/IL-20 ratio. Administration of IL-24 protein protected mice from TAA-induced liver injury and reduction of liver inflammation by antioxidant effects. IL-24 protected hepatocytes from TAA-induced apoptosis and prevented liver fibrosis through the inhibition of the HSCs activation. The protective role of IL-24 acted on liver cells were mainly IL-20R1-independent. IL-20R2-deficient mice exhibited more severe liver injury upon TAA treatment, thus confirming the protective role of IL-24.
               
                  Interpretation
                  IL-24 plays a key protective role in the progression of liver injury and has therapeutic potential for treating liver injuries.
               
                  Funding
                  This work was supported by the Ministry of Science and Technology of Taiwan (MOST 106–2320-B-006–024) and Taiwan Liver Disease Prevention & Treatment Research Foundation.",science
10.1016/j.pepi.2021.106653,Journal,Physics of the Earth and Planetary Interiors,scopus,2021-02-01,sciencedirect,Inversion of magnetic data using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85099646383,"As a novel tool, deep learning is used to solve complex problems in the real world and has been successfully applied to invert for seismic and electromagnetic data. In this study, we propose to use deep neural networks (DNNs) to recover the distribution of the physical properties of buried magnetic orebodies from the surface and airborne magnetic anomaly data. This approach is based on data training instead of prior-knowledge assumptions used in traditional inversion methods. Once our generalized network is established, the computing time to predict new magnetic data using this method can be significantly reduced. By implementing the forward modeling of different types of synthetic physical property models, we obtained enough datasets to train a DNN model so that the network can establish a nonlinear mapping directly from magnetic anomaly data to physical properties. The pre-trained network can be used to estimate the distribution of magnetization intensity from new input magnetic data. Two DNN structures were employed to test the feasibility and generalization of the proposed method by implementing Experiments in serval two-dimensional (2D) synthetic examples. Compared with the conventional method, the predicted distribution of magnetization intensity obtained by using our method is more concentrated and has better resolution to determine the boundary of the magnetic body. In a field example of Galinge iron ore deposits in China, the magnetization distribution of concealed iron orebodies inverted by the proposed approach was in good agreement with that detected by borehole data. DNNs have good nonlinear inversion capability and exhibit some excellent merits of strong learning ability, wide coverage and strong adaptability, which is a considerable application prospect in geophysical exploration.",science
10.1016/j.antiviral.2020.104998,Journal,Antiviral Research,scopus,2021-02-01,sciencedirect,Infectious bronchitis virus: Identification of Gallus gallus APN high-affinity ligands with antiviral effects,https://api.elsevier.com/content/abstract/scopus_id/85098587922,"Infectious bronchitis virus (IBV) is a coronavirus, causes infectious bronchitis (IB) with high morbidity and mortality, and gives rise to huge economic losses for the poultry industry. Aminopeptidase N (APN) may be one of the IBV functional receptors. In this study, Gallus gallus APN (gAPN) protein was screened by phage-displayed 12-mer peptide library. Two high-affinity peptides H (HDYLYYTFTGNP) and T (TKFSPPSFWYLH) to gAPN protein were selected for in depth characterization of their anti-IBV effects. In vitro, indirect ELISA showed that these two high-affinity ligands could bind IBV S1 antibodies. Quantitative real-time PCR (qRT-PCR) assay, virus yield reduction assay and indirect immunofluorescence assay results revealed 3.125–50 μg/ml of peptide H and 6.25–50 μg/ml of peptide T reduced IBV proliferation in chicken embryo kidney cells (CEKs). In vivo, high-affinity phage-vaccinated chickens were able to induce specific IBV S1 antibodies and IBV neutralizing antibodies. QRT-PCR results confirmed that high-affinity phages reduced virus proliferation in chicken tracheas, lungs and kidneys, and alleviated IBV-induced lesions. By multiple sequence alignment, motif ‘YxYY’ and ‘FxPPxxWxLH’ of high-affinity peptides were identified in IBV S1-NTD, while another motif ‘YxFxGN’ located in S2. These results indicated that high affinity peptides of gAPN could present an alternative approach to IB prevention or treatment.",science
10.1016/j.wneu.2020.10.171,Journal,World Neurosurgery,scopus,2021-02-01,sciencedirect,Attitudes of the Surgical Team Toward Artificial Intelligence in Neurosurgery: International 2-Stage Cross-Sectional Survey,https://api.elsevier.com/content/abstract/scopus_id/85097780896,"Background
                  Artificial intelligence (AI) has the potential to disrupt how we diagnose and treat patients. Previous work by our group has demonstrated that the majority of patients and their relatives feel comfortable with the application of AI to augment surgical care. The aim of this study was to similarly evaluate the attitudes of surgeons and the wider surgical team toward the role of AI in neurosurgery.
               
                  Methods
                  In a 2-stage cross sectional survey, an initial open-question qualitative survey was created to determine the perspective of the surgical team on AI in neurosurgery including surgeons, anesthetists, nurses, and operating room practitioners. Thematic analysis was performed to develop a second-stage quantitative survey that was distributed via social media. We assessed the extent to which they agreed and were comfortable with real-world AI implementation using a 5-point Likert scale.
               
                  Results
                  In the first-stage survey, 33 participants responded. Six main themes were identified: imaging interpretation and preoperative diagnosis, coordination of the surgical team, operative planning, real-time alert of hazards and complications, autonomous surgery, and postoperative management and follow-up. In the second stage, 100 participants responded. Responders somewhat agreed or strongly agreed about AI being used for imaging interpretation (62%), operative planning (82%), coordination of the surgical team (70%), real-time alert of hazards and complications (85%), and autonomous surgery (66%). The role of AI within postoperative management and follow-up was less agreeable (49%).
               
                  Conclusions
                  This survey highlights that the majority of surgeons and the wider surgical team both agree and are comfortable with the application of AI within neurosurgery.",science
10.1016/j.jmps.2020.104277,Journal,Journal of the Mechanics and Physics of Solids,scopus,2021-02-01,sciencedirect,Thermodynamics-based Artificial Neural Networks for constitutive modeling,https://api.elsevier.com/content/abstract/scopus_id/85097707935,"Machine Learning methods and, in particular, Artificial Neural Networks (ANNs) have demonstrated promising capabilities in material constitutive modeling. One of the main drawbacks of such approaches is the lack of a rigorous frame based on the laws of physics. This may render physically inconsistent the predictions of a trained network, which can be even dangerous for real applications.
                  Here we propose a new class of data-driven, physics-based, neural networks for constitutive modeling of strain rate independent processes at the material point level, which we define as Thermodynamics-based Artificial Neural Networks (TANNs). The two basic principles of thermodynamics are encoded in the network’s architecture by taking advantage of automatic differentiation to compute the numerical derivatives of a network with respect to its inputs. In this way, derivatives of the free-energy, the dissipation rate and their relation with the stress and internal state variables are hardwired in the architecture of TANNs. Consequently, our approach does not have to identify the underlying pattern of thermodynamic laws during training, reducing the need of large data-sets. Moreover the training is more efficient and robust, and the predictions more accurate. Finally and more important, the predictions remain thermodynamically consistent, even for unseen data. Based on these features, TANNs are a starting point for data-driven, physics-based constitutive modeling with neural networks.
                  We demonstrate the wide applicability of TANNs for modeling elasto-plastic materials, using both hyper- and hypo-plasticity models. Strain hardening and softening are also considered for the hyper-plastic scenario. Detailed comparisons show that the predictions of TANNs outperform those of standard ANNs. Finally, we demonstrate that the implementation of the laws of thermodynamics confers to TANNs high robustness in the presence of noise in the training data, compared to standard approaches.
                  TANNs’ architecture is general, enabling applications to materials with different or more complex behavior, without any modification.",science
10.1016/j.mechmat.2020.103673,Journal,Mechanics of Materials,scopus,2021-02-01,sciencedirect,Mechanical design of ring tensile specimen via surrogate modelling for inverse material parameter identification,https://api.elsevier.com/content/abstract/scopus_id/85097343663,"The mechanical characterization of anisotropic thin walled-tubes along hoop direction is not a trivial task. It is necessary to develop experimental techniques, numerical methods and design test samples, which enable to determine the real tube properties along hoop direction without any external influences. In this study, first we propose a surrogate based-model for the mechanical design of the ring hoop tensile test (RHTT) specimen, in order to obtain the effective homogeneous stress and strain distribution of the uniaxial tensile test along hoop direction. Second, the optimized sample is used to carry out RHTT and to obtain the actual flow stress curve and the anisotropy coefficients of AA6063-O extruded tube. However, the experimental curve measured from RHTT (force –displacement) is a degenerate response, since it suffers from intermixture effects of the effective material behaviour with the friction between the sample and the sample-holding tool. Hence, we developed an inverse parameter identification method, which uses design of experiments, finite element analysis and artificial neural network to separate out the tubular material parameters from the friction coefficient. The assessment of the developed method is achieved by comparing the predicted material parameters and the identified flow stress curve obtained by artificial neural network algorithm. The finite element simulation results corroborate the obtained findings.",science
10.1016/j.is.2020.101662,Journal,Information Systems,scopus,2021-02-01,sciencedirect,Topical affinity in short text microblogs,https://api.elsevier.com/content/abstract/scopus_id/85095453438,"Knowledge-based applications like recommender systems in social networks are powered by complex network of social discussions and user connections. Short text microblog platforms like Twitter are powerful in this aspect due to their real-time content dissemination as well as having a complex mesh of user connections. For example, users on Twitter tend to consume certain content to a greater or less extent depending on their interests over time. Quantifying this degree of content consumption in certain topics is an arduous task. This is further compounded by the amount of digital information that such platforms generate at any given time. Formulation of personalized user profiles based on user interests over time and friendship network is thus a problem. Therefore, user profiling based on their interests is important for personalized third-party content recommendations on the platform. In this paper we address this problem by presenting our solution in a two-step process:- (i) Firstly, we compute users’ Degree of Interest (DoI) towards a certain topic based on the overall users’ affinity towards that topic. (ii) Secondly, we affirm this DoI by correlating it to their friendship network. Furthermore, we describe our model for DoI computation and follow-back recommendation system by learning a low-dimensional vector representation of users and their disseminated content. This representation is used to train models for prediction of correct cluster classifications. In our experiments, we use a Twitter dataset to validate our approach by computing degrees of interest for certain test users in three diverse and generic topics. Experimental results show the effectiveness of our approach in the extraction of intra-user interests and better accuracy in follow-back recommendations with diversities in the topics.",science
10.1016/j.watres.2020.116599,Journal,Water Research,scopus,2021-02-01,sciencedirect,Temperature regulated adsorption and desorption of heavy metals to A-MIL-121: Mechanisms and the role of exchangeable protons,https://api.elsevier.com/content/abstract/scopus_id/85095449503,"Adsorption is a viable technology to remove trace heavy metals from wastewater, but regeneration of adsorbents in an economic and environmentally friendly manner often represents a limiting factor of its application. Compared with traditional strong acid desorption, developing a chemical-free method is of great significance to both economic and the environmental welfare. Herein, we synthesized a novel thermoresponsive absorbent, A-MIL-121, which could effectively remove trace Cu(II) (> 95 %) from a high-salinity ([Na+]/[Cu2+] = 20000) water at normal temperature. At elevated temperature, A-MIL-121 could quickly and efficiently desorb Cu(II), with over 90% desorption rate at 80°C within 3 h. Fourier transform infrared spectroscopy (FTIR) analysis revealed that two types of –COOH groups existed in the material. One was in free form and acted as the sites for Cu(II) adsorption; the other was in dimer connected by two H-bonds, which cleaved at elevated temperature. As a result, massive exchangeable protons were released to the solution, which caused the desorption of Cu(II). Similar temperature dependent adsorption-desorption behavior was also found to other heavy metals, such as Cd2+, Pb2+, Ni2+. No significant capacity loss was observed after 10 successive adsorption-desorption cycles. Finally, Column experiments using a real copper electroplating wastewater showed that a total of ~ 1650 mL of clean water was generated before breakthrough (Cu2+ < 0.5 mg/L), while less than 45 mL of 80°C water was used for regeneration. This study indicates the potential of A-MIL-121 as a novel green adsorbent to address trace heavy metals in wastewater.",science
10.1016/j.talanta.2020.121665,Journal,Talanta,scopus,2021-02-01,sciencedirect,Machine learning tools to estimate the severity of matrix effects and predict analyte recovery in inductively coupled plasma optical emission spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85092729485,"Supervised and unsupervised machine learning methods are used to evaluate matrix effects caused by carbon and easily ionizable elements (EIEs) on analytical signals of inductively coupled plasma optical emission spectrometry (ICP OES). A simple experimental approach was used to produce a series of synthetic solutions with varying levels of matrix complexity. Analytical lines (n = 29), with total line energies (E
                     
                        sum
                     ) in the 5.0–15.5 eV range, and non-analyte signals (n = 24) were simultaneously monitored throughout the study. Labeled (supervised learning) and unlabeled (unsupervised learning) data on normalized non-analyte signals (from plasma species) were used to train machine learning models to characterize matrix effect severity and predict analyte recoveries. Dimension reduction techniques, including principal component analysis, uniform manifold approximation and projection and t-distributed stochastic neighborhood embedding, were able to provide visual and quantitative representations that correlated well with observed matrix effects on low-energy atomic and high-energy ionic emission lines. Predictive models, including partial least squares regression and generalized linear models fit with the elastic net penalty, were tuned to estimate analyte recovery error when using the external standard calibration method (EC). The best predictive results were found for high-energy ionic analytical lines, e.g. Zn II 202.548 nm (E
                     
                        sum
                      = 15.5 eV), with accuracy and R2 of 0.970 and 0.856, respectively. Two certified reference materials (CRMs) were used for method validation. The strategy described here may be used for flagging compromising matrix effects, and complement method validation based on addition/recovery experiments and CRMs analyses. Because the data analysis workflows feature signals from plasma-based species, there is potential for developing instrument software capable of alerting users in real time (i.e. before data processing) of inaccurate results when using EC.",science
10.1016/j.future.2020.10.003,Journal,Future Generation Computer Systems,scopus,2021-02-01,sciencedirect,Susceptible user search for defending opinion manipulation,https://api.elsevier.com/content/abstract/scopus_id/85092371363,"The development of cyberspace offers unprecedentedly convenient access to online communication, thus inducing malicious individuals to subtly manipulate user opinions for benefits. Such malicious manipulations usually target those influential and susceptible users to mislead and control public opinion, posing a bunch of threats to public security. Therefore, an intelligent and efficient searching strategy for targeted users is one prominent and critical approach to defend malicious manipulations. However, the major body of current studies either provide solutions under ideal scenarios or offer inefficient solutions without guaranteed performance. As a result, this work adopts the combination of unsupervised learning and heuristic search to discover susceptible and key users for defense. We first propose a greedy algorithm fully considering the susceptibilities of different users, then adopt unsupervised learning and utilize the community property to design an accelerated algorithm. Moreover, the approximation guarantees of both greedy and community-based algorithms are systematically analyzed for some practical circumstances. Extensive experiments on real-world datasets demonstrate that our algorithms significantly outperform the state-of-the-art algorithm.",science
10.1016/j.athoracsur.2020.05.075,Journal,Annals of Thoracic Surgery,scopus,2021-02-01,sciencedirect,Gene-modified Exosomes Protect the Brain Against Prolonged Deep Hypothermic Circulatory Arrest,https://api.elsevier.com/content/abstract/scopus_id/85092135373,"Background
                  Neurologic deficit remains a major complication after cardiovascular surgeries with deep hypothermic circulatory arrest (DHCA). We hypothesized that exosomes derived from bone marrow mesenchymal stem cells (MSCs) may conduct cerebral protection against prolonged DHCA in rats, and overexpressing microRNA-214 (miR-214) may further enhance the neuroprotection.
               
                  Methods
                  Cultured MSCs were transfected with lentivirus vectors containing pre-miR-214 or control vectors. Exosomes were isolated by centrifugation. The DHCA was conducted for 60 minutes when the pericranial temperature was cooled to 18°C. Exosomes from MSCs, MSCs transfected with control vectors, or pre-miR-214 were administered by intracerebroventricular injection 1 day before DHCA.
               
                  Results
                  Transfection of pre-miR-214 significantly enhanced the miR-214 expression in exosomes from MSCs. All exosome-pretreating groups exhibited lower levels of interleukin-1β and tumor necrosis factor-α, higher capillary density, more significant neurogenesis and angiogenesis, and more normal neurons in the hippocampus than those of the control group. Exosome pretreatment markedly improved the spatial learning and memory function and vestibulomotor function. Compared with exosomes from MSCs or MSCs transfected with control vectors, miR-214–enriched exosomes remarkably enhanced the miR-214 level and expressions of phosphor-protein kinase B and Bcl-2, inhibited expressions of phosphate and tension homology, Bcl-2 interacting mediator of cell death, Bcl-2-associated X protein, and cleaved Caspase-3, and increased the number of survival neurons. Significantly better neurologic functions were also detected in rats pretreated with miR-214–enriched exosomes.
               
                  Conclusions
                  Exosomes from MSCs conduct powerful neuroprotection against cerebral injury induced by DHCA, which can be further enhanced by genetic modification of the exosomes to overexpress miR-214.",science
10.1016/j.paid.2020.109969,Journal,Personality and Individual Differences,scopus,2021-02-01,sciencedirect,"Evolution and revolution: Personality research for the coming world of robots, artificial intelligence, and autonomous systems",https://api.elsevier.com/content/abstract/scopus_id/85081938220,"In forty years, human existence will be radically transformed by advances in information technology, including Artificial Intelligence, robots capable of social agency, and other autonomous physical and virtual systems. Future personality research must assess, understand, and apply individual differences in adaptation to these novel challenges. This review article discusses directions for future personality research. Cross-cultural research provides a model, in that both universal traits and those specific to future society are needed. Evolution of major “etic” trait models of today will maintain their relevance. There is also scope for defining a range of new “emic” dimensions for constructs such as trust in autonomy, mental models for robots, anthropomorphism of technology, and preferences for communication with machines. A more revolutionary perspective is that availability of big data on the individual will revive idiographic perspectives. Both nomothetic and idiographic accounts of personality may support applications such as design of intelligent systems and products that adapt to the individual.",science
10.1016/j.cattod.2020.01.047,Journal,Catalysis Today,scopus,2021-02-01,sciencedirect,Sulfamethoxazole degradation by the CuO<inf>x</inf>/persulfate system,https://api.elsevier.com/content/abstract/scopus_id/85078833262,"In the present study, the efficiency of immobilized CuOx catalyst for sodium persulfate (SPS) activation was investigated. The efficiency of the CuOx/SPS system was evaluated for sulfamethoxazole (SMX), an antibiotic agent, degradation. CuOx nanoparticles were grown on TiO2 pellets, serving as supporting material. Information about the morphology and physicochemical characteristics of the catalyst was obtained by means of BET, SEM and XRD. The activity of CuOx/SPS system was first studied in a batch reactor resulting in complete 0.5 mg/L SMX removal in 90 min. SMX degradation followed pseudo-first-order kinetics. The effect of SPS (100−500 mg/L) concentration was also tested. Additional experiments were carried out under simulated solar irradiation showing the existence of synergistic phenomena. The performance of the CuOx/SPS system was further evaluated under real and synthetic water matrices. Apparent rate constant decreased from 0.028 min−1 in ultrapure water to 0.007 min−1 and 0.003 min−1 in the case of bottled water and wastewater, correspondingly. SMX removal was mainly hindered by the presence of bicarbonate. The by-products of SMX degradation were identified by LC–MS-TOF. In order to investigate the long-term performance of the present system, the CuOx/SPS process was operated in a continuous-flow mode at a flow rate of 0.56 mL/min (corresponding to residence time of 40 min); under these conditions, SMX removal remained remarkably stable at ∼80 % for 118 h or operation.",science
10.1016/j.neucom.2020.09.034,Journal,Neurocomputing,scopus,2021-01-21,sciencedirect,A coarse-to-fine user preferences prediction method for point-of-interest recommendation,https://api.elsevier.com/content/abstract/scopus_id/85092902433,"Point-of-interests (POIs) recommendations aim at recommending locations to users on social platforms by analyzing their histories or combining other information. At present, the different granularity of factors (i.e. time, geography and sociability) are not thoroughly studied in existing works. To deal with this problem, we propose a two-stage coarse-to-fine POI recommendation algorithm based on tensor factorization and weighted distance kernel density estimation (KDE). At first stage, we take account of not only long-term preferences with sequential context, but also the crowd’s preferences to estimate the coarse user-category interest. And then a specific-designed weighted KDE with consideration of spatial distance is employed to determine the fine-grained user-location interest. To evaluate the proposed method, experiments are conducted on two real benchmark location-based social network (LBSN) datasets. And the results show that the proposed method outperforms the state-of-the-art methods and produces better POI recommendation.",science
10.1016/j.neuron.2020.10.029,Journal,Neuron,scopus,2021-01-20,sciencedirect,"Behavioral, Physiological, and Neural Signatures of Surprise during Naturalistic Sports Viewing",https://api.elsevier.com/content/abstract/scopus_id/85097452282,"Surprise signals a discrepancy between past and current beliefs. It is theorized to be linked to affective experiences, the creation of particularly resilient memories, and segmentation of the flow of experience into discrete perceived events. However, the ability to precisely measure naturalistic surprise has remained elusive. We used advanced basketball analytics to derive a quantitative measure of surprise and characterized its behavioral, physiological, and neural correlates in human subjects observing basketball games. We found that surprise was associated with segmentation of ongoing experiences, as reflected by subjectively perceived event boundaries and shifts in neocortical patterns underlying belief states. Interestingly, these effects differed by whether surprising moments contradicted or bolstered current predominant beliefs. Surprise also positively correlated with pupil dilation, activation in subcortical regions associated with dopamine, game enjoyment, and long-term memory. These investigations support key predictions from event segmentation theory and extend theoretical conceptualizations of surprise to real-world contexts.",science
10.1016/j.ces.2020.116083,Journal,Chemical Engineering Science,scopus,2021-01-16,sciencedirect,Machine learning assisted measurement of solid mass flow rate in horizontal pneumatic conveying by acoustic emission detection,https://api.elsevier.com/content/abstract/scopus_id/85090220709,"This work proposed a series of generalized strategies to establish a machine learning prediction model for solid mass flow rate in horizontal pneumatic conveying using acoustic emission detection. The strategies included adding flow regime parameters to the inputs for different flow regimes and standardizing the inputs for different conveying setups and different conveying materials. To the most important, the standardization of inputs could be evaluated primarily based on theoretical analyses of the generation and propagation mechanisms of acoustic signals. Finally, the strategies were tested by experiments. Adding flow regime parameters reduced the prediction error under different flow regimes by 8.9%. After the standardization of acoustic signals, the prediction errors under different conveying setups (conveying pipes with different diameters) and different conveying materials (polypropylene and polyethylene particles) were significantly reduced by 159.8% and 198.0%. This work may supply a bridge between the lab-scale experiments and real application in commercial plants.",science
10.1016/j.ecoenv.2020.111609,Journal,Ecotoxicology and Environmental Safety,scopus,2021-01-15,sciencedirect,LncRNA loc105377478 promotes NPs-Nd<inf>2</inf>O<inf>3</inf>-induced inflammation in human bronchial epithelial cells through the ADIPOR1/NF-κB axis,https://api.elsevier.com/content/abstract/scopus_id/85095937114,"With the wide application of neodymium oxide nanoparticles (NPs-Nd2O3) in various fields, their health hazards have aroused public concern in recent years. However, data regarding the cytotoxicity of NPs-Nd2O3 is limited. In this study, we investigated the function and mechanism of long-chain non-coding RNAs (lncRNAs) in NPs-Nd2O3-induced airway inflammation. Treatment with NPs-Nd2O3 induced an inflammatory response in human bronchial epithelial cells (16HBE) by upregulating the expression of interleukin-6 (IL-6) and interleukin-8 (IL-8). The levels of LDH and intracellular ROS in the cells treated by various doses of NPs-Nd2O3 also increased significantly. After treatment with 10 μg/ml NPs-Nd2O3, RNA microarray and real-time quantitative polymerase chain reaction (qRT-PCR) showed a significant upregulation of lncRNA loc105377478. Functional experiments suggested lncRNA loc105377478 enhanced the expression of IL-6, IL-8 and ROS in NPs-Nd2O3-treated 16HBE cells, and it was further demonstrated that lncRNA loc105377478 promoted the activation of NF-κB by negatively regulating ADIPOR1 expression. Moreover, the expression of IL-6 and IL-8 in NPs-Nd2O3-treated 16HBE cells was regulated by lncRNA loc105377478, which was mediated by the NF-κB signaling pathway. In conclusion, lncRNA loc105377478 promotes NF-κB activation by negatively regulating ADIPOR1 expression, thereby upregulating the expression of IL-6 and IL-8 in 16HBE cells treated with NPs-Nd2O3.",science
10.1016/j.jep.2020.113363,Journal,Journal of Ethnopharmacology,scopus,2021-01-10,sciencedirect,Effect of weimaining on apoptosis and Caspase-3 expression in a breast cancer mouse model,https://api.elsevier.com/content/abstract/scopus_id/85091231598,"Ethnopharmacological relevance
                  Weimaining (WMN) is a condensed Tannin compound extracted from Fagopyrum cymosum (Trevir.) Meisn., which comes from the roots of buckwheat, a type of Chinese herbal medicine, was first recorded in “Bencao Shiyi”. WMN has inhibitory effects on multiple cancer types and is widely used in clinical practice; however, the mechanism underlying the anti-tumor effect of WMN is still unclear.
               
                  Aim of the study
                  To investigate the effect of WMN on the cellular activity and apoptosis of mouse breast cancer 4T1-luc2 cells, and caspase-3 and cleaved-caspase-3 expression.
               
                  Materials and methods
                  Luciferase-labeled mouse breast cancer 4T1-luc2 cells were inoculated into the mouse breast pad to establish a luciferase-labeled mouse breast cancer cell model. BALB/C-nu mice were randomly divided into model, WMN, and low-molecular-weight heparin (LMWH) groups (n = 10). Another 10 mice served as the normal control group (no cancer cell injection). The WMN group was administered WMN 250 mg/kg per day for 14 days, the LMWH group was given LMWH (1500 U/kg) daily for 14 days by intraperitoneal injection, and the model and normal control groups were given an equal dose of 0.9% NaCl. The number and distribution of transplanted tumors in 4T1-luc2 breast cancer cells were observed in nude mice by an in vivo imaging system at the time of inoculation after successful modeling, and on days 7 and 14 after drug administration. Tumor cell apoptosis was detected by the terminal deoxynucleotidyl transferase dUTP nick end labeling (TUNEL) method; caspase-3 mRNA expression was detected by RT-PCR and Western blotting was applied to detect the levels of caspase-3 and cleaved-caspase-3 protein expression.
               
                  Results
                  The apoptosis index (AI) of the WMN group was detected by the TUNEL method, and the AI increased with the increase of treatment time. Compared with the model group, the mRNA expression of caspase-3 and the protein levels of caspase-3 and cleaved-caspase-3 were notably elevated in the WMN group. After in vivo bioluminescent imaging, the total photon number of the WMN group was found to be lower than that of the LWMH group on day 14 after administration. Additionally, the AI and expression levels of caspase-3 mRNA, caspase-3, and cleaved-caspase-3 protein of the WMN group were higher than those of the LWMH group.
               
                  Conclusion
                  WMN can effectively suppress the growth of 4T1-luc2 breast cancer xenografts in mice, and promote the apoptosis of breast cancer cells by upregulating the expression of caspase-3.",science
10.1016/j.jep.2020.113075,Journal,Journal of Ethnopharmacology,scopus,2021-01-10,sciencedirect,Commiphora myrrha stimulates insulin secretion from mouse and human islets of Langerhans,https://api.elsevier.com/content/abstract/scopus_id/85089844285,"Ethnopharmacological relevance
                  Traditionally plant-based remedies such as Commiphora myrrha (CM) have been used as an ayurvedic medicine to treat diabetes mellitus in some region of Arabia and Africa. Previous reports have shown that CM reduced blood glucose levels and increased insulin concentrations in animal models of diabetes in vivo. However, the exact mechanisms by which CM improved glycemic control in these animals are not fully understood. We hypothesized that CM may have a direct insulinotropic activity on β-cells to increase insulin secretion.
               
                  Aim of the study
                  The direct effects of CM were investigated using MIN6 β-cells and isolated mouse and human islets in static and perifusion insulin secretion experiments. Isolated mouse and human islets were used to investigate the rate and pattern of CM-induced insulin secretion.
               
                  Materials and methods
                  The effect of CM on insulin secretion was assessed by static and perifusion experiments using MIN6 cells, a mouse-derived β-cell line, and primary mouse and human islets. The effects of CM on cell viability and membrane integrity of MIN6 cells and mouse islets were assessed using an ATP viability assay and a trypan blue exclusion test. The mRNA expression profiles of preproinsulin and Pdx1, a major β-cell transcription factor, were determined by quantitative RT-PCR following chronic exposure to CM.
               
                  Results
                  Exposing MIN6 cells to a CM resin solution (0.5–10 mg/ml) caused a concentration-dependent increase in insulin secretion in a static setting. Similarly, incubating mouse islets to CM (0.1–10 mg/ml) resulted in stimulation of insulin secretion in a concentration-dependent manner. CM concentrations at ≤ 2 mg/ml were not associated with reduction in cell viability nor with reduction in cell membrane integrity. However, higher concentrations of CM were accompanied with marked uptake of trypan blue dye and cell death. In a perifusion setting, CM (2 mg/ml) caused rapid and reversible increases in insulin secretion from both mouse and human islets at both sub-stimulatory and stimulatory glucose levels. The stimulatory effect of CM on insulin secretion did not change the total insulin content of β-cells nor the mRNA expression of preproinsulin and Pdx1.
               
                  Conclusions
                  These data indicate that aqueous CM resin solution has a direct stimulatory effect on β-cells without compromising plasma membrane integrity. CM stimulates insulin secretion from MIN6 cells, a mouse-derived β-cell line, and isolated primary mouse and human islets in vitro at both sub-stimulatory and stimulatory glucose concentrations. The mechanism by which CM may induce insulin secretion is most likely due to a stimulation of insulin granules release rather than insulin synthesis.",science
10.1016/j.neucom.2020.09.041,Journal,Neurocomputing,scopus,2021-01-08,sciencedirect,"MonuMAI: Dataset, deep learning pipeline and citizen science based app for monumental heritage taxonomy and classification",https://api.elsevier.com/content/abstract/scopus_id/85092227308,"An important part of art history can be discovered through the visual information in monument facades. However, the analysis of this visual information, i.e, morphology and architectural elements, requires high expert knowledge. An automatic system for identifying the architectural style or detecting the architectural elements of a monument based on one image will certainly help improving our knowledge in art and history. Building such tool is challenging as some styles share architectural elements, the bad conservation state of some monuments and the noise included in the image itself. The aim of this paper is to introduce MonuMAI (Monument with Mathematics and Artificial Intelligence) framework. In particular, (i) we designed MonuMAI dataset rich with expert knowledge considering the proposed architectural styles taxonomy and key elements relationship, which allows addressing several tasks, e.g., monument style classification and architectural elements detection, (ii) we developed MonuMAI deep learning pipeline based on lightweight MonuNet architecture for monument style classification and MonuMAI Key Elements Detection (MonuMAI-KED) model, and (iii) we built citizen science based MonuMAI mobile app that uses the proposed MonuMAI deep learning pipeline trained on MonuMAI dataset for performing in real life conditions. Our experiments show that both MonuNet architecture and the detection model achieve very good results under real life conditions.",science
10.1016/j.knosys.2020.106623,Journal,Knowledge-Based Systems,scopus,2021-01-05,sciencedirect,A multi-objective linear threshold influence spread model solved by swarm intelligence-based methods,https://api.elsevier.com/content/abstract/scopus_id/85097710919,"The influence maximization problem (IMP) is one of the most important topics in social network analysis. It consists of finding the smallest seed of users that maximizes the influence spread in a social network. The main influence spread models are the linear threshold model (LT-model) and the independent cascade model (IC-model). These models have mainly been treated by using the single-objective paradigm which covers just one perspective: maximize the influence spread starting by given seed size, or minimize the seed set to reach a given number of influenced nodes. Sometimes, this minimization problem has been called the least cost influence problem (LCI). In this work, we propose a new optimization model for both perspectives under conflict, through the LT-model, by applying a binary multi-objective approach. Swarm intelligence methods are implemented to solve our proposal on real networks. Results are promising and suggest that the new multi-objective solution proposed can be properly solved in harder instances.",science
10.1016/j.neucom.2020.08.023,Journal,Neurocomputing,scopus,2021-01-02,sciencedirect,Enhancing session-based social recommendation through item graph embedding and contextual friendship modeling,https://api.elsevier.com/content/abstract/scopus_id/85091215969,"Recommender systems are designed to help users find matching items from plenty of candidates in online platforms. In many online platforms, such as Yelp and Epinions, users’ behaviors are constantly recorded over time, and the users also can build connections with others and share their interests. Previous recommendation methods have either modeled the dynamic interests or the dynamic social influences. A few studies have focused on the modeling of both factors, but they still have several limitations: 1) they fail to consider the complex items transitions among all session sequences, which can be used as a local factor to boost the performance of recommendation methods, and 2) they ignore that a user and their friends only share the same preferences in certain sessions, by keeping the friend vector unchanged for all target users at time t, and 3) they do not consider that a user’s long-term preference may change with the evolution of interests.
                  To overcome the above issues, in this paper, we propose an approach to incorporate item graph embedding and contextual friendship modeling into the recommendation task. Specifically, 1) we construct a directed item graph based on all historical session sequences and utilize a graph neural network to capture the rich local dependency between items, and 2) take a session-level attention mechanism to get each friend’s representation according to the target user’s current interests, and 3) apply max-pooling on the target user’s historical session interests to learn the dynamics of his/her long-term interests. Extensive experiments on two real-world datasets show that our proposed model outperforms state-of-the-art methods consistently on various evaluation metrics.",science
10.1016/j.saa.2021.120534,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2021-01-01,sciencedirect,SERS Detection of Benzoic Acid in Milk by Using Ag-COF SERS Substrate,https://api.elsevier.com/content/abstract/scopus_id/85118982830,"Benzoic acid, which has a pivotal role in food additive, is prohibited to add as a preservative in dairy products. China, Brazil, and other countries have proposed standard methods to detect the addition of benzoic acid in food. Surface-enhanced Raman scattering (SERS) is an upcoming spectral detection technique, which has been widely used in the field of material analysis with the advantages of non-invasive, fast detection speed and complex environment with little interference. To detect the illegal use of benzoic acid in dairy industry, we developed Ag-COF (covalent-organic framework) material as SERS substrate to detect benzoic acid in liquid milk. The great enhancement ability of Ag-COF substrate is controlled by the addition of acetic acid and complex interplay between COF material and benzoic acid. This detection method has high sensitivity and reliability that allows us to achieve limit of detection (LOD) of 0.13 μg/mL in milk and 0.00372 μg/mL in water by applying this method. In experiment on recovery rate of real samples, the detection time is less than 15 minutes and the relative standard deviation (RSD) ranged from 2.82% to 5.69%. Therefore, this method has practical significance of the detection of benzoic acid in dairy products.",science
10.1016/j.eswa.2021.116068,Journal,Expert Systems with Applications,scopus,2021-01-01,sciencedirect,A decision support tool for the student–supervisor allocation problem of postgraduate programs,https://api.elsevier.com/content/abstract/scopus_id/85118755765,"The stable supervisor-student allocation (SSA) is crucial in the success of the research at the postgraduate education. The difference of SSA from the well-known student-project allocation (SPA) problem is that it moves the determination of the research topic to after the allocation, thus allowing the student and the lecturer to discuss the research topic. In the education systems of developing countries where decision support systems are not prevalent, the student–lecturer allocation is performed manually with a greedy approach, which can result in unstable matches. In this study, we propose a multi-objective binary model that allows decision-makers to shift between three main allocation strategies with a trade-off parameter. We test the model with a real dataset of a postgraduate program in Turkey. Experiments show that the model can successfully implement different strategies, and there can also be more than one breaking point between strategies. Also, we transform the model into a decision support tool that provides easy use to the decision-maker and reports the solutions of the trade-off parameter sensitivity analysis. The tool reports the level of satisfaction for each strategy at different breakpoints, allowing the decision-maker to see its options.",science
10.1016/j.dss.2021.113665,Journal,Decision Support Systems,scopus,2021-01-01,sciencedirect,A constraint programming model for making recommendations in personal process management: A design science research approach,https://api.elsevier.com/content/abstract/scopus_id/85115634506,"Decision-making in everyday life has an essential role in effectively completing personal tasks and processes. The complexity of these processes and the resulting cognitive load of managing them may vary significantly. To decrease the cognitive load created by such decision-making efforts and to obtain better outcomes, recommendation systems carry significant potential. In order to investigate the benefits provided by decision support systems (DSS) in personal process management (PPM), we first build a constraint programming (CP) model and a prototype context-aware-mobile application employing this CP model. Then, we evaluate the application and the model via two exemplary real-world scenarios. The scenarios form the core of the experiments conducted with 50 participants. We compare the participants’ planning performances with and without the PPM system with quantitative metrics such as planning times and scenario objective values. In addition, System Usability Scale (SUS) questionnaires and open-ended questions provide qualitative evaluation results. Throughout the study, we apply the Design Science Research methodology to rigorously conduct research activities by proof of concept, proof of use, and proof of value. The empirical results clearly show that our proposed model for PPM is effective, and the developed prototype solution generates positive participant comments as well as a high SUS score. Overall, the prototype PPM system with CP implementation leads to better planning in less time in the planning phase, and it lets the user do fast replanning in the execution phase, which is invaluable in dynamically changing situations such as daily activities.",science
10.1016/j.ejor.2021.08.006,Journal,European Journal of Operational Research,scopus,2021-01-01,sciencedirect,Optimizing revenue while showing relevant assortments at scale,https://api.elsevier.com/content/abstract/scopus_id/85114743541,"Scalable real-time assortment optimization has become essential in e-commerce operations due to the need for personalization and the availability of a large variety of items. While this can be done when there are simplistic assortment choices to be made, the optimization process becomes difficult when imposing constraints on the collection of relevant assortments based on insights by store-managers and historically well-performing assortments. We design fast and flexible algorithms based on variations of binary search that find the (approximately) optimal assortment in this difficult regime. In particular, we revisit the problem of large-scale assortment optimization under the multinomial logit choice model without any assumptions on the structure of the feasible assortments. We speed up the comparison steps using advances in similarity search in the field of information retrieval/machine learning. For an arbitrary collection of assortments, our algorithms can find a solution in time that is sub-linear in the number of assortments, and for the simpler case of cardinality constraints - linear in the number of items (existing methods are quadratic or worse). Empirical validations using a real world dataset (in addition to experiments using semi-synthetic data based on the Billion Prices dataset and several retail transaction datasets) show that our algorithms are competitive (
                        
                           3
                           ×
                           
                           −
                           
                           100
                           ×
                        
                      faster) even when the number of items is 
                        
                           ∼
                           
                              10
                              5
                           
                        
                      (
                        
                           10
                           ×
                        
                      larger instances than previously studied).",science
10.1016/j.dss.2021.113653,Journal,Decision Support Systems,scopus,2021-01-01,sciencedirect,AI-based industrial full-service offerings: A model for payment structure selection considering predictive power,https://api.elsevier.com/content/abstract/scopus_id/85114151068,"Artificial Intelligence and servitization reshape the way that manufacturing companies derive value. Aiming to sustain competitive advantage and intensify customer loyalty, full-service providers offer the use of their products as a service to achieve continuous revenues. For this purpose, companies implement AI classification algorithms to enable high levels of service at controllable costs. However, traditional asset sellers who become service providers require previously atypical payment structures, as classic payment methods involving a one-time fee for production costs and profit margins are unsuitable. In addition, a low predictive power of the implemented classification algorithm can lead to misclassifications, which diminish the achievable level of service and the intended net present value of the resultant service. While previous works focus solely on the costs of such misclassifications, our decision model highlights implications for payment structures, service levels, and – ultimately – the net present value of such data-driven service offerings. Our research suggests that predictive power can be a major factor in selecting a suitable payment structure and the overall design of service level agreements. Therefore, we compare common payment structures for data-driven services and investigate their relationship to predictive power. We develop our model using a design science methodology and iteratively evaluate our results using a four-step approach that includes interviews with industry experts and the application of our model to a real-world use case. In summary, our research extends the existing knowledge of servitization and data-driven services in the manufacturing industry through a quantitative decision model.",science
10.1016/j.procs.2021.05.007,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Subjects Involved in Czech Insolvency Proceedings: An Assessment of Their Future Impact,https://api.elsevier.com/content/abstract/scopus_id/85113586681,"Dynamic social networks follow several specific patterns during their evolution, including preferential attachment, forming of giant components, or densification. Especially preferential attachment impacts the emergence of relatively few influential high-degree nodes that attract most newly added nodes. Previous research on dynamic social networks, in general, assumes the so-called power-law degree to govern the number of nodes with a particular degree. But real social networks might display more complex behavior despite their apparent dependence on the preceding interconnection pattern.
                  This paper contributes to the field by developing a new methodology applicable to assessing a particular node’s actual influence. A significant part of the approach represents a strategy for training and pruning of a neural network used to extract proper knowledge from the data we have at our disposal. Sensitivity analysis applied to the trained neural network further contributes to understanding other nodes’ involvement in the entire process. Supporting experiments performed so far on the data publicly available from the Czech Insolvency Register (which covers more than 300 000 insolvency proceedings) indicate promising results regarding the model’s accuracy and explainability.",science
10.1016/j.cag.2021.08.007,Journal,Computers and Graphics (Pergamon),scopus,2021-01-01,sciencedirect,Spatially and color consistent environment lighting estimation using deep neural networks for mixed reality,https://api.elsevier.com/content/abstract/scopus_id/85113488014,"The representation of consistent mixed reality (XR) environments requires adequate real and virtual illumination composition in real-time. Estimating the lighting of a real scenario is still a challenge. Due to the ill-posed nature of the problem, classical inverse-rendering techniques tackle the problem for simple lighting setups. However, those assumptions do not satisfy the current state-of-art in computer graphics and XR applications. While many recent works solve the problem using machine learning techniques to estimate the environment light and scene’s materials, most of them are limited to geometry or previous knowledge. This paper presents a CNN-based model to estimate complex lighting for mixed reality environments with no previous information about the scene. We model the environment illumination using a set of spherical harmonics (SH) environment lighting, capable of efficiently represent area lighting. We propose a new CNN architecture that inputs an RGB image and recognizes, in real-time, the environment lighting. Unlike previous CNN-based lighting estimation methods, we propose using a highly optimized deep neural network architecture, with a reduced number of parameters, that can learn high complex lighting scenarios from real-world high-dynamic-range (HDR) environment images. We show in the experiments that the CNN architecture can predict the environment lighting with an average mean squared error (MSE) of 7.85
                        ×
                      10−4 when comparing SH lighting coefficients. We validate our model in a variety of mixed reality scenarios. Furthermore, we present qualitative results comparing relights of real-world scenes.",science
10.1016/j.ejor.2021.06.023,Journal,European Journal of Operational Research,scopus,2021-01-01,sciencedirect,"Fairness in credit scoring: Assessment, implementation and profit implications",https://api.elsevier.com/content/abstract/scopus_id/85109424638,"The rise of algorithmic decision-making has spawned much research on fair machine learning (ML). Financial institutions use ML for building risk scorecards that support a range of credit-related decisions. Yet, the literature on fair ML in credit scoring is scarce. The paper makes three contributions. First, we revisit statistical fairness criteria and examine their adequacy for credit scoring. Second, we catalog algorithmic options for incorporating fairness goals in the ML model development pipeline. Last, we empirically compare different fairness processors in a profit-oriented credit scoring context using real-world data. The empirical results substantiate the evaluation of fairness measures, identify suitable options to implement fair credit scoring, and clarify the profit-fairness trade-off in lending decisions. We find that multiple fairness criteria can be approximately satisfied at once and recommend separation as a proper criterion for measuring the fairness of a scorecard. We also find fair in-processors to deliver a good balance between profit and fairness and show that algorithmic discrimination can be reduced to a reasonable level at a relatively low cost. The codes corresponding to the paper are available on GitHub.",science
10.1016/j.jfoodeng.2021.110732,Journal,Journal of Food Engineering,scopus,2021-01-01,sciencedirect,A simplified modelling approach for predicting shrinkage and sensitive material properties during low temperature air drying of porous food materials,https://api.elsevier.com/content/abstract/scopus_id/85108981426,"Many food materials are dried to enhance shelf-life. Drying is an energy-intensive process, and accurate drying models could be used in real time process control of drying equipment to drive cost optimizations. However, most physics-based models suffer from two shortcomings: they require thermo-physical properties of the food materials to be known a priori, and they usually neglect material shrinkage due to moisture loss. In this work, we first develop a simplified physics-based transport model to predict temperatures and moisture content and corresponding spatial and temporal shrinkage during low temperature air drying process, where volumetric shrinkage is dominated by moisture loss. This model agrees well with experiments conducted by us (reported in this paper) as well as with those conducted by others (taken from the literature) on food samples. Further, using the validated modelling framework, we have developed an experimentally validated deep learning-based artificial neural network (ANN) model for properties' estimation. This ANN model is designed to estimate solid density, initial porosity, and initial water saturation of a given food material, using temperature and moisture data from a set of simple experiments with error less than 1%. Using these predicted parameters as input, the physics-based model can predict temperature and moisture for real-time drying to within 5% accuracy. The method proposed in this work could play an important role in industrial drying process optimisation and will find wide applications in the food processing industry.",science
10.1016/j.isatra.2021.06.017,Journal,ISA Transactions,scopus,2021-01-01,sciencedirect,Multi-objective optimization technique for trajectory planning of multi-humanoid robots in cluttered terrain,https://api.elsevier.com/content/abstract/scopus_id/85108514869,"Humanoid robots hold a decent advantage over wheeled robots because of their ability to mimic human exile. The presented paper proposes a novel strategy for trajectory planning in a cluttered terrain using the hybridized controller modeled on the basis of modified MANFIS (multiple adaptive neuro-fuzzy inference system) and MOSFO (multi-objective sunflower optimization) techniques. The controller works in a two-step mechanism. The input parameters, i.e., obstacle distances and target direction, are first fed to the MANFIS controller, which generates a steering angle in both directions of an obstacle to dodge it. The intermediate steering angles are obtained based on the training model. The final steering angle to avoid obstacles is selected based on the direction of the target and additional obstacles in the path. It is further works as input for the MOSFO technique, which provides the ultimate steering angle. Using the proposed technique, various simulations are carried out in the WEBOT simulator, which shows a deviation under 5% when the results are validated in real-time experiments, revealing the technique to be robust. To resolve the complication of providing preference to the robot during deadlock condition in multi-humanoids system, the dining philosopher controller is implemented. The efficiency of the proposed technique is examined through the comparisons with the default controller of NAO based on toques produces at various joints that present an average improvement of 6.12%, 7.05% and 15.04% in ankle, knee and hip, respectively. It is further compared against the existed navigational strategy in multiple robot systems that also displays an acceptable improvement in travel length. In comparison in reference to the existing controller, the proposed technique emerges to be a clear winner by portraying its superiority.",science
10.1016/j.adhoc.2021.102545,Journal,Ad Hoc Networks,scopus,2021-01-01,sciencedirect,Deep convolutional recurrent model for region recommendation with spatial and temporal contexts,https://api.elsevier.com/content/abstract/scopus_id/85107995105,"Spatiotemporal-aware region recommendation satisfies a user by providing an region of POIs (point-of-interests) that he/she may prefer. This recommendation is typically performed by analyzing the region mobility patterns of the user with some spatial and temporal contexts. This kind of recommendation can help, for example, a businessman to enjoy his urban life, or a tourist to travel in an unfamiliar area. In this study, we propose a deep-learning framework to model region-level mobility patterns of users, where personal and global user preferences across regions as well as spatiotemporal dependencies are comprehensively incorporated. To be specific, we model user preferences through a pyramidal Convolutional Long Short-Term Memory (ConvLSTM) component, and induce the dynamic region attributes through a recurrent component. By fusing two components to recommend next time region, our framework can tackle three complex challenges: (1) Modeling users’ distinctive spatio-temporal preferences over regions; (2) tracing diverse region mobility patterns of users over time; and (3) capturing the intrinsic correlations between regions. Extensive experiments on real-world datasets validate the effectiveness of the novel approach.",science
10.1016/j.matpr.2021.01.387,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,The role of artificial intelligence in revealing the results of the interaction of biological materials with each other or with chemicals,https://api.elsevier.com/content/abstract/scopus_id/85107415513,"The binding free energy represented by the residues of the interface are the hot spots and are the main factor in the stability of cells or chemical elements or their interactions and the development of their activities. Proteins, biological cells, and chemicals are distinguished by a structure that can be known about a cell or component, and each of them has its own characteristics and features. The proposed machine learning method to predict the outcome of future activities of biological elements or cells plays on extracting the desired features of the elements or cells according to the ecosystem containing the experiment. The prediction process is based on calculations that can be standardized by the histogram of the saved data set. In this study, we discuss the approach used in predicting future activities of cells by interacting with each other or with chemicals to reveal the results without reference to practical reality.",science
10.1016/j.matpr.2020.11.261,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Analysis and control of the motor vibration using arduino and machine learning model,https://api.elsevier.com/content/abstract/scopus_id/85107352700,"The motor vibrations provide information for diagnosing and predicting errors through signal processing. Motor vibrations provide information for diagnosing and predicting errors through data signal. In this article, we introduce an IoT-based detecting scheme for recording the vibration of an induction motor. A three different sensor such as vibration, Micro-Electro-Mechanical Systems (MEMS) and temperature sensor is used to gather the data from the motor vibration. We conducted an experiment by analysing the motor vibration by using Arduino, when the motor vibration is going to abnormal at that time Arduino send the signal to relay by cutting the supply to the motor. However, the motor running on proper condition with proper temperature, the controller is continuously monitoring and forward the data to storage system. The results can presentation on the mobile phone. The experiments were performed in the steady-state condition and the measured vibration signals were analysed using the Discrete Fourier Transform (DFT). Depend on the outcomes of the proposed model, which greatly monitor and early diagnosis the motor vibration, and performance was analysed by using the Machine Learning model of Decision Tree (DT). The controller can forward the vibration data the cloud with a maximum delay of about 0.9 sec. the stored data is retrieved by using the train the DT model to analysis the performance classification accuracy. This article introduces a new method for implementing real-time vibration measurement and analysis tools based on MATLAB.",science
10.1016/j.procs.2021.03.074,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Requirements towards optimizing analytics in industrial processes,https://api.elsevier.com/content/abstract/scopus_id/85106735396,"Modern production systems are composed of complex manufacturing processes with highly technology specific cause-effect relationships. Developments in sensor technology and computational science allow for data-driven decision making that facilitate effcient and objective production management. However, process data may only be beneficial if it is enriched with meta information and process expertise, reduced to relevant information and modelling results interpreted correctly. The importance of data integration in the heterogeneous industrial environment rises at the same momentum as new metrology techniques are deployed. In this paper, we focus on optimizing analytics, containing data-driven decision making for predictive quality and maintenance. We summarize key requirements for data analytics and machine learning application in industrial processes. With a use case from automotive component manufacturing we characterize industrial production, categorize process data and put requirements in context to a real-world example.",science
10.1016/j.procs.2021.03.066,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Safemobility: An IoT-Based system for safer mobility using machine learning in the age of COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85106733824,"In the face of the COVID-19 pandemic and the absence of a vaccine or an effective treatment against the virus, the available studies show that today, the most effective measure for prevention continues to be social distancing. In this sense, in this article, we focus implementing an IoT-based System for safer mobility in the age of COVID-19 using machine learning called SafeMobility. This system has been designed to monitor in real-time the social distancing between people and control the capacity in common interior spaces via a multilayer architecture that integrates IoT, fog, and cloud solutions. To control the capacity safely, we have detected the location of people using machine learning models. We have trained and evaluated these models from a data set containing the RSSI signals of the different surrounding WiFi networks obtained via a portable IoT device. Besides, this portable device integrated with a high precision laser sensor has also been used to detect the distance between people, thus avoiding potential infections. Also, we have exploited the advantages of fog computing to perform data processing and analysis in a fog node using the machine learning model that presented the highest accuracy in the evaluation. In case of non-compliance with the allowed social distance or the established peak capacity, alert messages are sent via a lightweight and optimal protocol in using IoT applications. A web application hosted on a cloud server receives the information from the fog node in real-time and dynamically displays the congestion sites in the environment. Our experiments demonstrate the effectiveness of the system to determine the position of the people with an accuracy of 91%.",science
10.1016/j.imu.2021.100591,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,The diagnostic accuracy of Artificial Intelligence-Assisted CT imaging in COVID-19 disease: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85105522693,"Artificial intelligence (AI) systems have become critical in support of decision-making. This systematic review summarizes all the data currently available on the AI-assisted CT-Scan prediction accuracy for COVID-19. The ISI Web of Science, Cochrane Library, PubMed, Scopus, CINAHL, Science Direct, PROSPERO, and EMBASE were systematically searched. We used the revised Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool to assess all included studies' quality and potential bias. A hierarchical receiver-operating characteristic summary (HSROC) curve and a summary receiver operating characteristic (SROC) curve have been implemented. The area under the curve (AUC) was computed to determine the diagnostic accuracy. Finally, 36 studies (a total of 39,246 image data) were selected for inclusion into the final meta-analysis. The pooled sensitivity for AI was 0.90 (95% CI, 0.90–0.91), specificity was 0.91 (95% CI, 0.90–0.92) and the AUC was 0.96 (95% CI, 0.91–0.98). For deep learning (DL) method, the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.88 (95% CI, 0.87–0.88) and the AUC was 0.96 (95% CI, 0.93–0.97). In case of machine learning (ML), the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.95 (95% CI, 0.94–0.95) and the AUC was 0.97 (95% CI, 0.96–0.99). AI in COVID-19 patients is useful in identifying symptoms of lung involvement. More prospective real-time trials are required to confirm AI's role for high and quick COVID-19 diagnosis due to the possible selection bias and retrospective existence of currently available studies.",science
10.1016/j.procs.2021.03.075,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Input doubling method based on SVR with RBF kernel in clinical practice: Focus on small data,https://api.elsevier.com/content/abstract/scopus_id/85104314419,"In recent years, machine-learning-based approaches have become of considerable interest to the efficient processing of short or limited data samples. Its so-called small data approach. This is due to the significant growth of new intellectual analysis tasks in various industries, which are characterized by limited historical data. These include Materials Science, Economics, Medicine, and so on. An effective processing of short datasets is especially acute in medicine. Insufficient number of vectors, significant gaps in the data collected during the supervision of patient’s treatment or rehabilitation, reduces the effectiveness or prevents effective intellectual analysis based on them. This paper presents a new approach to processing short medical data samples. The basis of the developed method is SVR with RBF kernel. The algorithmic implementation of the method in both operation modes is described. Experimental modeling on a real short data set (Trabecular bone data) is conducted. It contained only 35 observations. A comparison of the method with a number of existing machine learning methods is conducted. It is experimental established the highest accuracy of the method among those considered. The developed method has potential opportunities for wide application in various fields of medicine.",science
10.1016/j.imu.2021.100566,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,COVID-19 prediction using LSTM algorithm: GCC case study,https://api.elsevier.com/content/abstract/scopus_id/85104093246,"Coronavirus-19 (COVID-19) is the black swan of 2020. Still, the human response to restrain the virus is also creating massive ripples through different systems, such as health, economy, education, and tourism. This paper focuses on research and applying Artificial Intelligence (AI) algorithms to predict COVID-19 propagation using the available time-series data and study the effect of the quality of life, the number of tests performed, and the awareness of citizens on the virus in the Gulf Cooperation Council (GCC) countries at the Gulf area. So we focused on cases in the Kingdom of Saudi Arabia (KSA), United Arab of Emirates (UAE), Kuwait, Bahrain, Oman, and Qatar. For this aim, we accessed the time-series real-datasets collected from Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). The timeline of our data is from January 22, 2020 to January 25, 2021. We have implemented the proposed model based on Long Short-Term Memory (LSTM) with ten hidden units (neurons) to predict COVID-19 confirmed and death cases. From the experimental results, we confirmed that KSA and Qatar would take the most extended period to recover from the COVID-19 virus, and the situation will be controllable in the second half of March 2021 in UAE, Kuwait, Oman, and Bahrain. Also, we calculated the root mean square error (RMSE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and death cases are 320.79 and 1.84, respectively, and both are related to Bahrain. While the worst values are 1768.35 and 21.78, respectively, and both are related to KSA. On the other hand, we also calculated the mean absolute relative errors (MARE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and deaths cases are 37.76 and 0.30, and these are related to Kuwait and Qatar respectively. While the worst values are 71.45 and 1.33, respectively, and both are related to KSA.",science
10.1016/j.matpr.2020.06.084,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Facile synthesis of halloysite-bentonite clay/magnesite nanocomposite and its application for the removal of chromium ions: Adsorption and precipitation process,https://api.elsevier.com/content/abstract/scopus_id/85103031187,"Here we report the synthesis of halloysite-bentonite clay/magnesite nanocomposite, using ball milling and calcination. It was identified that the synthesized nanocomposite enjoys the synergistic properties of both materials, i.e. clays and magnesite, and hence was assessed in terms of chromium ions removal from real tannery wastewater. To identify the optimum conditions for chromium ions removal the one factor-at-a-time (OFAT) method was applied in the design of the batch experiments. The examined parameters include mixing time, dosage, concentration, and pH, while state-of-art analytical techniques were used. Specifically, to identify the morphological properties and the elemental composition of the synthesized nanocomposite, before and after it reacted with the chromium ions, HR-SEM-EDS was used. XRD was used to identify mineralogical compositions, while BET was used to determine surface areas. ICP-MS and multi-parameter probe were employed for water quality analyses. The removal of chromium ions, post the adsorption process, was confirmed using HR-SEM-EDS. The optimum conditions for chromium ions removal were identified as 60 min contract, 0.5 g of dosage at 0.5 g: 500 mL S: L ratio, and 300 mg L−1 chromium ions concentration. The reaction was observed to be independent of pH (1–10). At optimum conditions, the nanocomposite practically removed chromium ions from all examined water matrices, i.e. real tannery wastewater, fortified tap water, groundwater, mine water, and synthetic solution. The adsorption capacity was observed to be 199 mg g−1. Regarding the regression analysis, the adsorption kinetics seem to follow the pseudo-second-order (PSO) than the pseudo-first order (PFO) model. In addition, the adsorption data better fitted the Langmuir than the Freundlich adsorption isotherm. In a nutshell, the synthesized nanocomposite was found to be very promising for chromium ions removal from wastewater and possibly for other contaminants, such as heavy metals, which will be examined in future works of our group.",science
10.1016/j.procir.2021.01.128,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,A Machine Vision-based Cyber-Physical Production System for Energy Efficiency and Enhanced Teaching-Learning Using a Learning Factory,https://api.elsevier.com/content/abstract/scopus_id/85102656008,"Machine vision (MV) can help in achieving real-time data analysis in a manufacturing environment. This can be implemented in any industry to achieve real-time monitoring of workpieces for geometric defects and material irregularities. Identification of defects, sorting of workpieces based on their physical parameters, and analysis of process abnormalities can be achieved by using the real-time data from simple and cost-effective raspberry pi with camera and open source machine learning platform TensorFlow to run convolutional neural network (CNN) model. The proposed cyber-physical production system enables to develop a MV based system for data acquisition integrating physical entities of learning factory (LF) with the cyber world. Nowadays, LFs are widely used to train the workforce for developing competencies for emerging technologies and challenges faced due to technological advancements in Industry 4.0. This paper demonstrates the application of a cost-effective MV system in a learning factory environment to achieve real-time data acquisition and energy efficiency. The proposed low-cost machine vision is found to detect geometric irregularities, colours and surface defects. The simple cost effective MV system has enhanced the energy efficiency and reduced the total carbon footprint by 18.37 % and 78.83 % depending upon the location of MV system along the flow. The teaching-learning experience is also enhanced through action-based learning strategies. This not only ensures less rework, better control, unbiased decisions, 100% quality assurance but also the need of workers/operators can be reduced.",science
10.1016/j.procir.2021.01.115,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Development of a Decision Support System for 3D Printing Processes based on Cyber Physical Production Systems,https://api.elsevier.com/content/abstract/scopus_id/85102637852,"3D printing, an additive manufacturing (AM) technology, potentially provides sustainability advantages such as less waste generation, lightweight geometries, reduced material and energy consumption, lower inventory waste, etc. This paper proposes a decision support system for the 3D printing process based on Cyber Physical Production System (CPPS). The user is enabled to dynamically assess the carbon footprint based on the energy and material usage for their 3D printed object. A CPPS framework for the environmental sustainability of the 3D printing process is presented, which supports the derivation of improved strategies for product design and production. A physical world for 3D printing is used with the internet of things (IoT) devices like sensor node, webcam, smart plugs, and raspberry pi to host printer Management Software (PMS) for real-time monitoring and control of material and energy consumption during the printing process. Experiments have been conducted based on Taguchi L9 orthogonal array with polylactic Acid (PLA) as a filament material to estimate the product-related manufacturing energy consumption with the carbon footprint. The proposed framework can be effectively used by the users to supports the decision-making process for saving resources and energy; and minimizing the effect on the environment.",science
10.1016/j.procir.2021.01.018,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Machine learning based approach for process supervision to predict tool wear during machining,https://api.elsevier.com/content/abstract/scopus_id/85102618379,"Tool wear prediction during machining is a challenging problem. Traditional approaches are available to use the process parameters which influence tool wear but there are certain parameters which are very specific to the machining process and available prediction models fail. Present work discusses a Machine Learning based process supervisory system to predict the tool wear. To illustrate the approach an application for the prediction of tool wear while machining is selected as a case study. The analysis was performed on a machining dataset consisting of certain experiments of different levels of input parameters and for each experiment several sensor logged physical parameters (features). From a chosen training set of experiments the features that best describe the state of tool wear (unworn or worn) along with the input parameters were chosen to build a model. Several models employing logistic regression were built and the best one was chosen. The model obtained had good accuracy and interpretability. The results obtained from the test set show the system’s suitability and potential for industrial application. The presented supervisory model can be utilized to predict tool wear in real time and prior to the tool getting worn before a set number of operations, thus cause a reduction in the delay due to the change over required to an unworn tool.",science
10.1016/j.jksuci.2020.10.023,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2021-01-01,sciencedirect,Improving Sentiment Analysis of Arabic Tweets by One-way ANOVA,https://api.elsevier.com/content/abstract/scopus_id/85099543200,"Social media is an indispensable necessity for modern life. As a result, it is full of people’s opinions, emotions, ideas, and attitudes, whether positive or negative. This abundance of views creates many opportunities for applying sentiment analysis to the education sector, which reflects how countries and cultures develop. In this research, a real-world Twitter dataset was collected, containing approximately 8144 tweets related to Qassim University, Saudi Arabia. The main aim of this experimental study was to explore the possibility of using a one-way analysis of variance (ANOVA) as a feature selection method to considerably reduce the number of features when classifying opinions conveyed through Arabic tweets. The primary motivation for this research was that no previous studies had examined one-way ANOVA comprehensively to tackle the curse of dimensionality and to enhance classification performance in sentiment analysis for Arabic tweets. Therefore, various experiments were conducted to investigate the effects of one-way ANOVA and to select important features concerning the performance of different supervised machine learning classifiers. Support Vector Machine and Naïve Bayes achieved the best results with one-way ANOVA as compared to the baseline experimental results in the collected dataset. Furthermore, the differences between all results have been statistically analyzed in this study. As further evidence, one-way ANOVA with Support Vector Machine represented an excellent combination across different Arabic benchmark datasets, with its results outperforming other studies.",science
10.1016/j.patrec.2020.09.032,Journal,Pattern Recognition Letters,scopus,2021-01-01,sciencedirect,Gradient clustering algorithm based on deep learning aerial image detection,https://api.elsevier.com/content/abstract/scopus_id/85098118591,"In recent years, computer vision, especially deep learning, has been widely used in various fields. Through the deep learning aerial image detection gradient clustering algorithm automatic recognition, it can solve the limitations of manual shooting by humans, can shoot from a high altitude to a panoramic view of a specific area, and provide a more comprehensive solution. The traditional forest resource management and management work is mainly carried out by forestry personnel to carry out a large number of investigations and investigations on the forest. This method not only consumes a lot of manpower and material resources, but also does not have real-time nature. It is difficult to deal with all kinds of forest management. Problems, causing unnecessary losses. In this regard, this paper proposes an aerial image change detection algorithm based on H-KFCM, and designs related experiments to verify and demonstrate the performance of the algorithm. In this paper, we conduct a parallel study based on deep learning on the gradient clustering algorithm of deep learning in aerial image processing. By using CUDA (Compute Unified Device Architecture) to perform large-scale parallel processing of aerial data. Can greatly shorten the time to obtain results, improve the efficiency of relevant personnel. Experiment analysis. It can be seen from the results that the deep learning parallelization program implemented in this paper has a faster calculation speed and uses less time in high-resolution images, and has a good acceleration ratio compared to the CPU.",science
10.1016/j.psychres.2020.113585,Journal,Psychiatry Research,scopus,2021-01-01,sciencedirect,"Digital Gaming Interventions in Psychiatry: Evidence, Applications and Challenges",https://api.elsevier.com/content/abstract/scopus_id/85097734134,"Human evolution has regularly intersected with technology. Digitalization of various services has brought a paradigm shift in consumerism. Treading this path, mental health practice has gradually moved to Digital Mental Health Interventions (DMHI), to improve service access and delivery. Applied games are one such innovation that has gained recent popularity in psychiatry. Based on the principles of gamification, they target psychosocial and cognitive domains, according to the deficits in various psychiatric disorders. They have been used to deliver cognitive behaviour therapy, cognitive training and rehabilitation, behavioural modification, social motivation, attention enhancement, and biofeedback. Research shows their utility in ADHD, autistic spectrum disorders, eating disorders, post-traumatic stress, impulse control disorders, depression, schizophrenia, dementia, and even healthy aging. Virtual reality and artificial intelligence have been used in conjunction with gaming interventions to improvise their scope. Even though these interventions hold promise in engagement, ease of use, reduction of stigma, and bridging the mental-health gap, there are pragmatic challenges, especially in developing countries. These include network quality, infrastructure, feasibility, socio-cultural adaptability, and potential for abuse. Keeping this in the background, this review summarizes the scope, promise, and evidence of digital gaming in psychiatric practice, and highlights the potential caveats in their implementation.",science
10.1016/j.forsciint.2020.110633,Journal,Forensic Science International,scopus,2021-01-01,sciencedirect,Sex classification of first molar teeth in cone beam computed tomography images using data mining,https://api.elsevier.com/content/abstract/scopus_id/85097206562,"Objective
                  The teeth have been used as a supplementary tool for sex differentiation as they are resistant to post-mortem degradation. The present study aimed to develop a new novel informatics framework for predicting sex from linear tooth dimension measurements achieved from cone beam computed tomography (CBCT) images.
               
                  Method and materials
                  A clinical workflow using different machine learning methods was employed to predict the sex in the present study. The CBCT images of 485 subjects (245 men and 240 women) were evaluated for sex differentiation. Nine parameters were measured in both buccolingual and mesiodistal aspects of the teeth. We applied our dataset to Naïve Bayesian (NB), Random Forest (RF), and Support Vector Machine (SVM) as classifiers for prediction. Genetic feature selection was used to discover real features associated with sex classification.
               
                  Results
                  The 10-fold cross-validation results indicated that NB had higher accuracy than SVM and RF for sex classification. The genetic algorithm (GA) indicated that the model could fit the data without using the enamel thickness and pulp height. The average classification accuracy of our clinical workflow was 92.31 %.
               
                  Conclusion
                  The results showed that NB was the best method for sex classification. The application of the first molar teeth in sex prediction indicated an acceptable level of sexual classification. Therefore, these odontometric parameters can be applied as an additional tool for sex determination in forensic anthropology.",science
10.1016/j.ebiom.2020.103153,Journal,EBioMedicine,scopus,2021-01-01,sciencedirect,Prophylactic intranasal administration of a TLR2/6 agonist reduces upper respiratory tract viral shedding in a SARS-CoV-2 challenge ferret model,https://api.elsevier.com/content/abstract/scopus_id/85097183218,"Background
                  The novel human coronavirus SARS-CoV-2 is a major ongoing global threat with huge economic burden. Like all respiratory viruses, SARS-CoV-2 initiates infection in the upper respiratory tract (URT). Infected individuals are often asymptomatic, yet highly infectious and readily transmit virus. A therapy that restricts initial replication in the URT has the potential to prevent progression of severe lower respiratory tract disease as well as limiting person-to-person transmission.
               
                  Methods
                  SARS-CoV-2 Victoria/01/2020 was passaged in Vero/hSLAM cells and virus titre determined by plaque assay. Challenge virus was delivered by intranasal instillation to female ferrets at 5.0 × 106 pfu/ml. Treatment groups received intranasal INNA-051, developed by Ena Respiratory. SARS-CoV-2 RNA was detected using the 2019-nCoV CDC RUO Kit and QuantStudio™ 7 Flex Real-Time PCR System. Histopathological analysis was performed using cut tissues stained with haematoxylin and eosin (H&E).
               
                  Findings
                  We show that prophylactic intra-nasal administration of the TLR2/6 agonist INNA-051 in a SARS-CoV-2 ferret infection model effectively reduces levels of viral RNA in the nose and throat. After 5 days post-exposure to SARS-CoV-2, INNA-051 significantly reduced virus in throat swabs (p=<0.0001) by up to a 24 fold (96% reduction) and in nasal wash (p=0.0107) up to a 15 fold (93% reduction) in comparison to untreated animals.
               
                  Interpretation
                  The results of our study support clinical development of a therapy based on prophylactic TLR2/6 innate immune activation in the URT, to reduce SARS-CoV-2 transmission and provide protection against COVID-19.
               
                  Funding
                  This work was funded by Ena Respiratory, Melbourne, Australia.",science
10.1016/j.rvsc.2020.11.008,Journal,Research in Veterinary Science,scopus,2021-01-01,sciencedirect,Molecular characterization of a novel aspartyl protease-1 from Trichinella spiralis,https://api.elsevier.com/content/abstract/scopus_id/85097107126,"The aim of this study was to characterize the biological properties of a novel aspartic protease-1 from Trichinella spiralis (TsASP1) and evaluate its potential in inducing immune response. TsASP1 gene was cloned and expressed in Escherichia coli BL21 (DE3). On Western blotting analysis with anti-rTsASP1 serum, native TsASP1 was detected in various T. spiralis phases other than newborn larvae (NBL). qPCR results showed that TsASP1 transcription was the highest in intestinal infective larvae (IIL) and the lowest in the NBL stage. Immunofluorescence test result shows that native TsASP1 was principally localized in stichosome, muscle cells of muscle larvae (ML) and IIL, and surrounded intrauterine embryos in female adult worms (AW). After silencing TsASP1 gene of the ML by siRNA, the worm development was significantly inhibited, showed by shorter AW and more wrinkles and longitudinal crack on epicuticle of AW on scanning electron microscopy; the AW and ML burdens were reduced by 41.82 and 56.36% respectively, compared with the control siRNA or PBS group (P < 0.001). Immunization of mice with rTsASP1 elicited an evident antibody response (serum IgG, IgG1/IgG2a and enteral sIgA), and systemic (spleen) and intestinal local mucosal (mesenteric lymph node) cellular immune response, demonstrated by a prominent elevation of IFN-γ and IL-4. The results suggested TsASP1 participated in T. spiralis development and survival in host, and immunization of mice with rTsASP1 induced systemic/intestinal local mucosal humoral and cellular immune response against Trichinella.",science
10.1016/j.cogsys.2020.10.005,Journal,Cognitive Systems Research,scopus,2021-01-01,sciencedirect,Cogmic space for narrative-based world representation,https://api.elsevier.com/content/abstract/scopus_id/85096684889,"Representing a world or a physical/social environment in an agent’s cognitive system is essential for creating human-like artificial intelligence. This study takes a story-centered approach to this issue. In this context, a story refers to an internal representation involving a narrative structure, which is assumed to be a common form of organizing past, present, future, and fictional events and situations. In the artificial intelligence field, a story or narrative is traditionally treated as a symbolic representation. However, a symbolic story representation is limited in its representational power to construct a rich world. For example, a symbolic story representation is unfit to handle the sensory/bodily dimension of a world. In search of a computational theory for narrative-based world representation, this study proposes the conceptual framework of a Cogmic Space for a comic strip-like representation of a world. In the proposed framework, a story is positioned as a mid-level representation, in which the conceptual and sensory/bodily dimensions of a world are unified. The events and their background situations that constitute a story are unified into a sequence of panels. Based on this structure, a representation (i.e., a story) and the represented environment are connected via an isomorphism of their temporal, spatial, and relational structures. Furthermore, the framework of a Cogmic Space is associated with the generative aspect of representations, which is conceptualized in terms of unconscious- and conscious-level processes/representations. Finally, a proof-of-concept implementation is presented to provide a concrete account of the proposed framework.",science
10.1016/j.imbio.2020.152028,Journal,Immunobiology,scopus,2021-01-01,sciencedirect,Study on the additive protective effect of PGLYRP3 and Bifidobacterium adolescentis Reuter 1963 on severity of DSS-induced colitis in Pglyrp3 knockout (Pglyrp3 −/−) and wild-type (WT) mice,https://api.elsevier.com/content/abstract/scopus_id/85096671566,"Background and Aims
                  Pglyrp3 is a bactericidal innate immunity protein known to sustain the habitual gut microbiome and protect against experimental colitis. Intestinal inflammation and metaflammation are commonly associated with a marked reduction of commensal bifidobacteria. Whether Pglyrp3 and bifidobacteria interact synergistically or additively to alleviate metaflammation is unknown. We investigated the extent to which Pglyrp3 and bifidobacteria regulate metaflammation and gut bacterial dysbiosis in DSS-induced mouse models of intestinal inflammation.
               
                  Material & Methods
                  8–10 weeks old male mice were used. In both WT and Pglyrp3 −/− experiments, the mice were randomly divided into three groups of 16 mice per group: (1) a control group receiving sterile tap water, (2) an experimental group receiving sterile tap water supplemented with only 5% DSS, and (3) an experimental group receiving sterile tap water supplemented with 5% DSS and 1 × 109 CFU/ml of Bifidobacterium adolescentis (B.a.) for 7 days. Wild-type (WT) littermates of the respective gene (i.e. Pglyrp3) were used as controls throughout the study. Clinical signs of general health and inflammation were monitored daily. Faecal pellet samples were analysed by qRT-PCR for microbial composition. Histology of relevant organs was carried out on day 8. Metabolic parameters and liver inflammation were determined in serum samples.
               
                  Results
                  Intestinal inflammation in mice of group 2 were significantly increased compared to those of control group 1. There was a significant difference in mean scores for inflammation severity between DSS-treated WT and DSS-treated Pglyrp3 −/− mice. Buildup of key serum metabolic markers (cholesterol, triglyceride and glucose) was set off by colonic inflammation. qRT-PCR quantification showed that DSS significantly decreased the Clostridium coccoides and Bifidobacterium cell counts while increasing those of Bacteroides group in both WT and Pglyrp3 −/− mice. These manifestations of DSS-induced dysbiosis were significantly attenuated by feeding B.a. Both the local and systemic ill-being of the mice alleviated when they received B.a.
                  
               
                  Discussion
                  This study shows that Pglyrp3 facilitates recognition of bifidobacterial cell wall-derived peptidoglycan, thus leading additively to a reduction of metaflammation through an increase in the number of bifidobacteria, which were able to mitigate intestinal immunopathology in the context of Pglyrp3 blockade.",science
10.1016/j.cma.2020.113540,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2021-01-01,sciencedirect,A robust solution of a statistical inverse problem in multiscale computational mechanics using an artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85096216963,"This work addresses the inverse identification of apparent elastic properties of random heterogeneous materials using machine learning based on artificial neural networks. The proposed neural network-based identification method requires the construction of a database from which an artificial neural network can be trained to learn the nonlinear relationship between the hyperparameters of a prior stochastic model of the random compliance field and some relevant quantities of interest of an ad hoc multiscale computational model. An initial database made up with input and target data is first generated from the computational model, from which a processed database is deduced by conditioning the input data with respect to the target data using the nonparametric statistics. Two- and three-layer feedforward artificial neural networks are then trained from each of the initial and processed databases to construct an algebraic representation of the nonlinear mapping between the hyperparameters (network outputs) and the quantities of interest (network inputs). The performances of the trained artificial neural networks are analyzed in terms of mean squared error, linear regression fit and probability distribution between network outputs and targets for both databases. An ad hoc probabilistic model of the input random vector is finally proposed in order to take into account uncertainties on the network input and to perform a robustness analysis of the network output with respect to the input uncertainties level. The capability of the proposed neural network-based identification method to efficiently solve the underlying statistical inverse problem is illustrated through two numerical examples developed within the framework of 2D plane stress linear elasticity, namely a first validation example on synthetic data obtained through computational simulations and a second application example on real experimental data obtained through a physical experiment monitored by digital image correlation on a real heterogeneous biological material (beef cortical bone).",science
10.1016/j.ipm.2020.102437,Journal,Information Processing and Management,scopus,2021-01-01,sciencedirect,A multimodal fake news detection model based on crossmodal attention residual and multichannel convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85096177951,"In recent years, social media has increasingly become one of the popular ways for people to consume news. As proliferation of fake news on social media has the negative impacts on individuals and society, automatic fake news detection has been explored by different research communities for combating fake news. With the development of multimedia technology, there is a phenomenon that cannot be ignored is that more and more social media news contains information with different modalities, e.g., texts, pictures and videos. The multiple information modalities show more evidence of the happening of news events and present new opportunities to detect features in fake news. First, for multimodal fake news detection task, it is a challenge of keeping the unique properties for each modality while fusing the relevant information between different modalities. Second, for some news, the information fusion between different modalities may produce the noise information which affects model’s performance. Unfortunately, existing methods fail to handle these challenges. To address these problems, we propose a multimodal fake news detection framework based on Crossmodal Attention Residual and Multichannel convolutional neural Networks (CARMN). The Crossmodal Attention Residual Network (CARN) can selectively extract the relevant information related to a target modality from another source modality while maintaining the unique information of the target modality. The Multichannel Convolutional neural Network (MCN) can mitigate the influence of noise information which may be generated by crossmodal fusion component by extracting textual feature representation from original and fused textual information simultaneously. We conduct extensive experiments on four real-world datasets and demonstrate that the proposed model outperforms the state-of-the-art methods and learns more discriminable feature representations.",science
10.1016/j.neunet.2020.10.002,Journal,Neural Networks,scopus,2021-01-01,sciencedirect,Gradient-based training and pruning of radial basis function networks with an application in materials physics,https://api.elsevier.com/content/abstract/scopus_id/85096164921,"Many applications, especially in physics and other sciences, call for easily interpretable and robust machine learning techniques. We propose a fully gradient-based technique for training radial basis function networks with an efficient and scalable open-source implementation. We derive novel closed-form optimization criteria for pruning the models for continuous as well as binary data which arise in a challenging real-world material physics problem. The pruned models are optimized to provide compact and interpretable versions of larger models based on informed assumptions about the data distribution. Visualizations of the pruned models provide insight into the atomic configurations that determine atom-level migration processes in solid matter; these results may inform future research on designing more suitable descriptors for use with machine learning algorithms.",science
10.1016/j.scs.2020.102582,Journal,Sustainable Cities and Society,scopus,2021-01-01,sciencedirect,Towards the sustainable development of smart cities through mass video surveillance: A response to the COVID-19 pandemic,https://api.elsevier.com/content/abstract/scopus_id/85096158767,"Sustainable smart city initiatives around the world have recently had great impact on the lives of citizens and brought significant changes to society. More precisely, data-driven smart applications that efficiently manage sparse resources are offering a futuristic vision of smart, efficient, and secure city operations. However, the ongoing COVID-19 pandemic has revealed the limitations of existing smart city deployment; hence; the development of systems and architectures capable of providing fast and effective mechanisms to limit further spread of the virus has become paramount. An active surveillance system capable of monitoring and enforcing social distancing between people can effectively slow the spread of this deadly virus. In this paper, we propose a data-driven deep learning-based framework for the sustainable development of a smart city, offering a timely response to combat the COVID-19 pandemic through mass video surveillance. To implementing social distancing monitoring, we used three deep learning-based real-time object detection models for the detection of people in videos captured with a monocular camera. We validated the performance of our system using a real-world video surveillance dataset for effective deployment.",science
10.1016/j.petrol.2020.107955,Journal,Journal of Petroleum Science and Engineering,scopus,2021-01-01,sciencedirect,A new method for predicting formation lithology while drilling at horizontal well bit,https://api.elsevier.com/content/abstract/scopus_id/85092457002,"The identiﬁcation of lithology while drilling with horizontal well bit is a difficult problem to solve in geosteering. However, due to the existence of “zero length” (the distance between the logging tool and the bit), the lithology at the horizontal well bit cannot be accurately interpreted in real time, which creates a lag in geosteering. Based on logging while drilling (LWD) technology, this paper uses supervised learning in machine learning methods, conventional logging interpretation technology and big data idea in modern computer science, through interdisciplinary theories and methods to research lithology prediction for horizontal well bits in reservoirs. First, a measurement point and vertical reservoir boundary distance (D-MP-VRB) database is built according to different step size categories. Second, based on the D-MP-VRB database, D-MP-VRB prediction models are established using one-versus-one support vector machines (OVO SVMs), random forest (RF), neural networks (NN), and extreme gradient boosting tree (XGBoost) algorithms. To reduce the dimensions of the input data, the feature parameters of the samples are obtained by a correlation analysis of the logging data. The optimal parameter values of each algorithm are determined by grid search and 10-fold cross-validation methods. Finally, the prediction formula of the bit and vertical reservoir boundary distance based on the D-MP-VRB prediction model is established. A case study is performed with data from a sandstone reservoir in Changqing oilfield, Ordos Basin, China. On this basis, the lithology predictions at the bit in real time are carried out by using four models. Considering the principle of model prediction accuracy, through 1320 experiments, only the XGBoost prediction model can be selected, and the step size of the target category is 2 m, however, this model takes the longest time to train. Therefore, the reliable prediction model trained by the sample data of the original training set is used to predict the reservoir information encountered by horizontal well. After the newly drilled reservoir information has accumulated to a certain amount and accurately explained, it is added to the original training set sample data, and the prediction model is retrained to improve the accuracy and adaptability of the model. Based on the prediction results of the XGBoost model and the prediction formula, the distance prediction between the horizontal well bit and the vertical reservoir boundary is realized, real-time lithology correction at the bit is realized, and the adverse effect of the “zero length” on the lithology prediction at the bit is reduced. The research results provide not only a new method for the real-time prediction of lithology in horizontal well bits but also a theoretical basis for the geosteering of oilfield development and valuable information for future research.",science
10.1016/j.jnca.2020.102854,Journal,Journal of Network and Computer Applications,scopus,2021-01-01,sciencedirect,DNC: A Deep Neural Network-based Clustering-oriented Network Embedding Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85092456550,"Deep Neural Networks (DNNs) have achieved impressive success in the domain of Euclidean data such as image. However, designing deep neural network to cluster nodes especially in social networks is still a challenging task. Moreover, recent advanced methods for node clustering have focused on learning node embedding, upon which classic clustering algorithms like K-means are applied. Nevertheless, the resulting node embeddings are customarily task-agnostic. This results in the fact that the performance of clustering is difficult to guarantee. To effectively mitigate the problem, in this paper, we propose a novel clustering-oriented node embedding method named Deep Node Clustering (DNC) for non-attributed network data by resorting to deep neural networks. We first present a preprocessing method via adopting a random surfing model to capture graph structural information directly. Subsequently, we propose to learn a deep clustering network, which could jointly learn node embeddings and cluster assignments. Extensive experiments on three real-world network datasets for node clustering are conducted, which demonstrate that the proposed DNC substantially outperforms the state-of-the-art node clustering methods.",science
10.1016/j.engfailanal.2020.104958,Journal,Engineering Failure Analysis,scopus,2021-01-01,sciencedirect,Wear prediction of a mechanism with multiple joints based on ANFIS,https://api.elsevier.com/content/abstract/scopus_id/85092083385,"Condition monitoring data of joints in a mechanism contains enormous useful information, and can comprehensively improve the wear prediction accuracy. However, condition data of the joints is sometimes hard to obtain due to technical reasons or cost reasons, especially for some complicated mechanical systems. To obtain the real-time wear data of joints in a mechanism with multiple joints, an ANFIS-based (adaptive-network-based fuzzy inference system) joints clearance size prognostic method is developed based on monitored motion outputs of the mechanism. Then, a framework for wear prediction based on multi-body dynamics theory is proposed to predict joints wear more accurately. In the framework, the Archard’s wear model is used. To reduce the uncertainty in the wear coefficient, wear coefficient is treated as a random variable, then a Bayesian updating process is implemented according to the wear data from the ANFIS-based method. The proposed framework is validated using wear experiments of a lock mechanism with three joints in a cabin door. The results show the prediction error is within 3%.",science
10.1016/j.envres.2020.110141,Journal,Environmental Research,scopus,2021-01-01,sciencedirect,Assessing personal exposure using Agent Based Modelling informed by sensors technology,https://api.elsevier.com/content/abstract/scopus_id/85092078286,"Technology innovations create possibilities to capture exposure-related data at a great depth and breadth. Considering, though, the substantial hurdles involved in collecting individual data for whole populations, this study introduces a first approach of simulating human movement and interaction behaviour, using Agent Based Modelling (ABM).
                  A city scale ABM was developed for urban Thessaloniki, Greece that feeds into population-based exposure assessment without imposing prior bias, basing its estimations onto emerging properties of the behaviour of the computerised autonomous decision makers (agents) that compose the city-system. Population statistics, road and buildings networks data were transformed into human, road and building agents, respectively. Survey outputs with time-use patterns were associated with human agent rules, aiming to model representative to real-world behaviours. Moreover, time-geography of exposure data, derived from a local sensors campaign, was used to inform and enhance the model. As a prevalence of an agent-specific decision-making, virtual individuals of different sociodemographic backgrounds express different spatiotemporal behaviours and their trajectories are coupled with spatially resolved pollution levels.
                  Personal exposure was evaluated by assigning PM concentrations to human agents based on coordinates, type of location and intensity of encountered activities. Study results indicated that PM2.5 inhalation adjusted exposure between housemates can differ by 56.5% whereas exposure between two neighbours can vary by as much as 87%, due to the prevalence of different behaviours.
                  This study provides details of a new methodology that permits the cost-effective construction of refined time-activity diaries and daily exposure profiles, taking into account different microenvironments and sociodemographic characteristics. The proposed method leads to a refined exposure assessment model, addressing effectively vulnerable subgroups of population. It can be used for evaluating the probable impacts of different public health policies prior to implementation reducing, therefore, the time and expense required to identify efficient measures.",science
10.1016/j.jneumeth.2020.108927,Journal,Journal of Neuroscience Methods,scopus,2021-01-01,sciencedirect,Automatic classification methods for detecting drowsiness using wavelet packet transform extracted time-domain features from single-channel EEG signal,https://api.elsevier.com/content/abstract/scopus_id/85091767602,"Background
                  Detecting human drowsiness during some critical works like vehicle driving, crane operating, mining blasting, etc. is one of the safeguards to prevent accidents. Among several drowsiness detection (DD) methods, a combination of neuroscience and computer science knowledge has a better ability to differentiate awake and sleep states. Most of the current models are implemented using multi-sensors electroencephalogram (EEG) signals, multi-domain features, predefined features selection algorithms. Therefore, there is great interest in the method of detecting drowsiness on embedded platforms with improved accuracy using generalized best features.
               
                  New-method
                  Single-channel EEG based drowsiness detection (DD) model is proposed in this by utilizing wavelet packet transform (WPT) to extract the time-domain features from considered channel EEG. The dimension of the feature vector is reduced by the proposed novel feature selection method.
               
                  Results
                  The proposed model on freely available real-time sleep analysis EEG and Simulated Virtual Driving Driver (SVDD) EEG achieves 94.45% and 85.3% accuracy, respectively.
               
                  Comparison-with-existing-method
                  The results show that the proposed DD method produces better accuracy compared to the state-of-the-art using the physiological dataset with the proposed time-domain sub-band-based features and feature selection method. This task of detecting drowsiness by analyzing the 5-seconds EEG signal with four features is an improvement to my previous work on detecting drowsiness using a 30-seconds EEG signal with 66 features.
               
                  Conclusions
                  Time-domain features obtained from EEG time-domain sub-bands collected using WPT achieving excellent accuracy rate by selecting unique optimization features for all subjects by the proposed feature selection algorithm.",science
10.1016/j.atmosenv.2020.117917,Journal,Atmospheric Environment,scopus,2021-01-01,sciencedirect,Real-time hourly ozone prediction system for Yangtze River Delta area using attention based on a sequence to sequence model,https://api.elsevier.com/content/abstract/scopus_id/85091562134,"The Yangtze River Delta (YRD) area is becoming increasingly polluted with ground level ozone, making the prediction of ozone particularly important. This study uses a deep learning approach to forecast ozone concentrations over the YRD region of eastern China. We propose an attention-based sequence to sequence model for ozone concentration prediction, which addresses the dynamic, spatial, temporal, and nonlinear characteristics of multivariate time series data by gated recurrent unit based encoder-forecaster architecture. Through multivariate time series forecasting experiments for ozone concentration, we show that the proposed model is easier and performs better than the weather research and forecasting model with chemistry based forecasting system. Furthermore, we show that the predicted ozone concentration can be matched with the ground truth value under single-timestep and multi-timestep forward forecasting conditions. The experiment results show that the seq2seq model is capable of reliably predicting ozone concentration with a high level of accuracy. The root mean square error of 1- h ozone forecast is 12.40 μg/m³ and the mean absolute error of 1- h ozone forecast is 9.27 μg/m³ on the test dataset.",science
10.1016/j.atmosenv.2020.117881,Journal,Atmospheric Environment,scopus,2021-01-01,sciencedirect,Physicochemical properties and cytotoxicity of brown carbon produced under different combustion conditions,https://api.elsevier.com/content/abstract/scopus_id/85090352400,"Light-absorbing organic particulate matter (PM), or brown carbon (BrC), may constitute an important fraction of combustion PM. Here, we investigate the effect of combustion conditions on the molecular sizes of BrC, their light-absorption properties, and their cytotoxicity. We used toluene in a combustion reactor with highly controlled conditions to produce two different types of BrC under two conditions corresponding to smoldering and near-flaming combustion, with temperatures of 670 °C and 1035 °C, respectively. We performed online measurements of the size distributions and light-absorption properties of the BrC. The BrC produced at 1035 °C was more light absorbing, with an imaginary component of the refractive index at 532 nm (k
                     532) an order of magnitude larger than that of the BrC produced at 670 °C. We also collected samples for offline chemical characterization using laser desorption ionization (LDI) mass spectrometry. The LDI mass spectra showed that the BrC produced at 1035 °C was composed of species with significantly larger molecular sizes than the BrC produced at 670 °C. Using human lung epithelial cells, we conducted in vitro cytotoxicity analysis on the two types of BrC with doses ranging from 3.5 to 136.0 μg of BrC/ml. After 24-h exposure, the viability of the cells was assessed using a WST-8 assay. The cytotoxicity analysis showed that, for both BrC samples, the cells exhibited a clear dose-dependent response with significant BrC cytotoxicity that plateaued at the higher doses. However, while the viability of cells exposed to the BrC produced at 1035 °C reached a minimum of around 65% at the highest dose, the BrC produced at 670 °C proved to be significantly more toxic, with the viability dropping asymptotically to 25%. The results presented here suggest that organic PM of smaller molecular sizes produced under lower temperature, smoldering combustion could be significantly more toxic than that of larger molecular sizes produced under higher temperature, flaming conditions. The use of a single-molecule fuel in a highly controlled combustion setup distinguishes this work from experiments that rely on real-life sources and combustion setups, where different combustion conditions could be occurring simultaneously and clouding the conclusions.",science
10.1016/j.prro.2020.07.003,Journal,Practical Radiation Oncology,scopus,2021-01-01,sciencedirect,Time Analysis of Online Adaptive Magnetic Resonance–Guided Radiation Therapy Workflow According to Anatomical Sites,https://api.elsevier.com/content/abstract/scopus_id/85090017005,"Purpose
                  To document time analysis of detailed workflow steps for the online adaptive magnetic resonance–guided radiation therapy treatments (MRgRT) with the ViewRay MRIdian system and to identify the barriers to and solutions for shorter treatment times.
               
                  Methods and Materials
                  A total of 154 patients were treated with the ViewRay MRIdian system between September 2018 and October 2019. The time process of MRgRT workflow steps of 962 fractions for 166 treatment sites was analyzed in terms of patient and online adaptive treatment (ART) characteristics.
               
                  Results
                  Overall, 774 of 962 fractions were treated with online ART, and 83.2% of adaptive fractions were completed in less than 60 minutes. Sixty-three percent, 50.3%, and 4.2% of fractions were completed in less than 50 minutes, 45 minutes, and 30 minutes, respectively. Eight-point-three percent and 3% of fractions were completed in more than 70 minutes and 80 minutes, respectively. The median time (tmed) for ART workflow steps were as follows: (1) setup tmed: 5.0 minutes, (2) low-resolution scanning tmed: 1 minute, (3) high-resolution scanning tmed: 3 minutes, (4) online contouring tmed: 9 minutes, (5) reoptimization with online quality assurance tmed: 5 minutes, (6) real targeting tmed: 3 minutes, (7) beam delivery with gating tmed: 17 minutes, and (8) net total treatment time tmed: 45 minutes. The shortest and longest tmean rates of net total treatment time were 41.59 minutes and 64.43 minutes for upper-lung-lobe-located thoracic tumors and ultracentrally located thoracic tumors, respectively.
               
                  Conclusions
                  To our knowledge, this is the first broad treatment-time analysis for online ART in the literature. Although treatment times are long due to human- and technology-related limitations, benefits offered by MRgRT might be clinically important. In the future, implementation of artificial intelligence segmentation, an increase in dose rate, and faster multileaf collimator and gantry speeds may lead to achieving shorter MRgRT treatments.",science
10.1016/j.bspc.2020.102178,Journal,Biomedical Signal Processing and Control,scopus,2021-01-01,sciencedirect,Towards effective classification of brain hemorrhagic and ischemic stroke using CNN,https://api.elsevier.com/content/abstract/scopus_id/85089894411,"Brain stroke is one of the most leading causes of worldwide death and requires proper medical treatment. Therefore, in this paper, our aim is to classify brain computed tomography (CT) scan images into hemorrhagic stroke, ischemic stroke and normal. Our newly proposed convolutional neural network (CNN) model utilizes image fusion and CNN approaches. Initially, some preprocessing operations have been employed by using multi-focus image fusion in order to improve the quality of CT images. Further, preprocessed images are fed into the newly proposed 13 layers CNN architecture for stroke classification. The robustness of our CNN method has been checked by conducting two experiments on two different datasets. In the first experiment, CT image dataset is partitioned into 20% testing and 80% training sets, while in the second experiment, 10 fold cross-validation of the image dataset has been performed. The classification accuracy obtained by our method on dataset 1 in the first experiment is 98.33% and in the second experiment, it is 98.77%, while in dataset 2 accuracy obtained in experiment 1 and 2 is 92.22% and 93.33% respectively. All the experiments have been conducted on the real CT image dataset which we have been collected from Himalayan Institute of Medical Sciences (HIMS), Dehradun, India. The results obtained by the proposed method have also been compared with AlexNet and ResNet50 where results show improvement over these CNN architectures.",science
10.1016/j.jmsy.2020.06.012,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,"A digital twin to train deep reinforcement learning agent for smart manufacturing plants: Environment, interfaces and intelligence",https://api.elsevier.com/content/abstract/scopus_id/85087690907,"Filling the gaps between virtual and physical systems will open new doors in Smart Manufacturing. This work proposes a data-driven approach to utilize digital transformation methods to automate smart manufacturing systems. This is fundamentally enabled by using a digital twin to represent manufacturing cells, simulate system behaviors, predict process faults, and adaptively control manipulated variables. First, the manufacturing cell is accommodated to environments such as computer-aided applications, industrial Product Lifecycle Management solutions, and control platforms for automation systems. Second, a network of interfaces between the environments is designed and implemented to enable communication between the digital world and physical manufacturing plant, so that near-synchronous controls can be achieved. Third, capabilities of some members in the family of Deep Reinforcement Learning (DRL) are discussed with manufacturing features within the context of Smart Manufacturing. Trained results for Deep Q Learning algorithms are finally presented in this work as a case study to incorporate DRL-based artificial intelligence to the industrial control process. As a result, developed control methodology, named Digital Engine, is expected to acquire process knowledges, schedule manufacturing tasks, identify optimal actions, and demonstrate control robustness. The authors show that integrating a smart agent into the industrial platforms further expands the usage of the system-level digital twin, where intelligent control algorithms are trained and verified upfront before deployed to the physical world for implementation. Moreover, DRL approach to automated manufacturing control problems under facile optimization environments will be a novel combination between data science and manufacturing industries.",science
10.1016/j.jaim.2018.02.139,Journal,Journal of Ayurveda and Integrative Medicine,scopus,2021-01-01,sciencedirect,Scientific validation of anti-arthritic effect of Kashayams – A polyherbal formulation in collagen induced arthritic rats,https://api.elsevier.com/content/abstract/scopus_id/85059941091,"Background
                  Toll-like receptor-4 (TLR-4) mediates activation of nuclear factor kappa-light-chain-enhancer of activated B cells (NF-κB) resulting in induction of proinflammatory genes such as that encoding tumor necrosis factor-α (TNF-α) and interleukin-1β (IL-1β) which played a significant role in cartilage destruction of rheumatoid arthritis (RA). Low risk and better efficacy made herbal drugs more reliable than nonsteroid anti-inflammatory drugs (NSAIDS) in RA treatment. Gugguluthiktam Kashayam (GuK), Punarnavadi Kashayam (PuK) and Balaguluchiadi Kashayam (BgK) are ayurvedic polyherbal formulations prescribed in classical ayurvedic texts Sahasrayogam and Ashtangahridayam as medicines for the treatment of RA.
               
                  Objective
                  The objective of the present study was to elucidate the molecular mechanism of anti-arthritic effect of these Kashayams on TLR-4 signal transduction pathway in collagen induced arthritic rats.
               
                  Material and methods
                  The wistar rats grouped into group I - Normal, group II- Collagen induced arthritis (CIA), group III- CIA + BgK, group IV– CIA + PuK, group V- CIA + GuK, group VI - CIA + Indomethacin (3 mg/kg b.wt.). Treatment with Kashayam (2 ml/kg b.wt) started after 14 days of primary immunization with type II collagen and continued for a period of 45 days.
               
                  Results
                  Arthritis index, C-reactive protein (CRP), rheumatoid factor (RF) and myeloperoxidase (MPO) in serum and protein level of TLR-4, myeloid differentiation factor 88 (MYD88), NF-κB, TNF-α, IL-1β, inducible nitric oxide synthase (iNOS), cyclooxygenase-2 COX-2) and prostaglandin E-2 (PGE-2) in cartilage were significantly elevated in CIA rats. Further, treatment with Kashayams downregulated all these inflammatory mediators hitherto TLR-4-NF-kB signal transduction pathway except IL-10, an anti-inflammatory cytokine which showed a reverse effect.
               
                  Conclusion
                  This molecular mechanism of the investigation confirmed the clinical efficacy of Kashayams in preventing the progression of RA and gave an intuition of the scientific validation of Kashayams, an Ayurvedic classical medicine.",science
10.1016/j.scitotenv.2020.142368,Journal,Science of the Total Environment,scopus,2020-12-20,sciencedirect,A novel dynamic multi-criteria ensemble selection mechanism applied to drinking water quality anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/85091235644,"The provision of clean and safe drinking water is a crucial task for water supply companies from all over the world. To this end, automatic anomaly detection plays a critical role in drinking water quality monitoring. Recent anomaly detection studies use techniques that focus on a single global objective. Yet, companies need solutions that better balance the trade-off between false positives (FPs), which lead to financial losses to water companies, and false negatives (FNs), which severely impact public health and damage the environment. This work proposes a novel dynamic multi-criteria ensemble selection mechanism to cope with both problems simultaneously: the non-dominated local class-specific accuracy (NLCA). Moreover, experiments rely on recent time series related classification metrics to assess the predictive performance. Results on data from a real-world water distribution system show that NLCA outperforms other ensemble learning and dynamic ensemble selection techniques by more than 15% in terms of time series related F
                     1 scores. As a conclusion, NLCA enables the development of stronger anomaly detection systems for drinking water quality monitoring. The proposed technique also offers a new perspective on dynamic ensemble selection, which can be applied to different classification tasks to balance conflicting criteria.",science
10.1016/j.lfs.2020.118549,Journal,Life Sciences,scopus,2020-12-15,sciencedirect,Estrogen-regulated expression of SK3 channel in rat colonic smooth muscle contraction,https://api.elsevier.com/content/abstract/scopus_id/85092697688,"Aims
                  Estrogen can induce inhibition of colonic smooth muscle contraction in male and female mice, which may lead to constipation; however, the mechanisms of inhibition are poorly understood. Hence, this study investigated the effect of estrogen on rat colonic smooth muscle contraction and role of small-conductance Ca2+-activated K+ 3 (SK3) and transcription factors (Sp1 and Sp3) in the underlying mechanisms.
               
                  Main methods
                  The experiment included 24 female Sprague-Dawley (SD) rats divided into 4 groups. The rats were oophorectomized surgically, and a silicone tube containing blank solvent, 0.3 mg/mL estrogen (E2), equal-concentration of estrogen and estrogen receptor antagonist (EI), and bovine serum albumin-E2 (BSA-E2) was implanted. The rats were sacrificed on day 14. The molecular insights were confirmed using real-time quantitative reverse transcription PCR (qRT-PCR) and western blot analyses to determine the effect of estrogenic stimulation on gene and protein expression analyses, respectively.
               
                  Key findings
                  The E2 group showed significantly greater SK3 expression (P < .005) compared with other groups and significantly lowers smooth muscle cell (SMC) contractility (P < .005). Estrogen stimulation and SK3 overexpression resulted in a significant decrease (P < .05) in Ca2+ mobilization in the E2 group versus the control group. Further, the E2 group showed significantly higher Sp1 mRNA (P < .05) but lower Sp3 mRNA expression (P < .05) and protein expression (P < .001) compared with other groups.
               
                  Significance
                  E2 may promote SK3 expression by its genomic effect and inhibit colonic contraction by affecting SK3 expression via an interaction between Sp1 and Sp3.",science
10.1016/j.eswa.2020.113715,Journal,Expert Systems with Applications,scopus,2020-12-15,sciencedirect,Graph classification algorithm based on graph structure embedding,https://api.elsevier.com/content/abstract/scopus_id/85088375744,"With the application of data mining in many fields such as information science, bioinformatics, and network intrusion detection, more and more data are showing new features such as strong structuration and complex relationships between data. As a complex data structure, a graph can be used to describe the relationship between things. Traditional graph classification methods based on graph feature vector construction need to select a feature vector construction criterion in advance, such as graph-based theoretical indicators or graph-based topology occurrences, and then extract features from each graph in the graph set according to the designated criterion. However, the construction method of the graph feature vector is easy to lose the graph structural information and requires strong professional knowledge. Inspired by the Word2Vec and Doc2Vec models in the Natural Language Processing (NLP), this paper first constructs a “word list” of graph data consisting of subgraphs. Then a neural network for training graph embedding is designed with the graph itself as its input, and the “word” in the graph and the attribute features of the graph are used as its output, so that the neural network automatically learns the graph embedding corresponding to each graph. The graph embedding not only reflects the features of the graph itself but also includes the relative relationship among graphs. Finally, on the basis of the well-trained graph embedding, the common classifier can be used to classify graphs. Based on real-world bioinformatics and social data sets, the experiments demonstrate that the proposed graph classification algorithm has advantages over the existing graph classification algorithms based on feature vector construction.",science
10.1016/j.patter.2020.100145,Journal,Patterns,scopus,2020-12-11,sciencedirect,A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread,https://api.elsevier.com/content/abstract/scopus_id/85097386310,"We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform.",science
10.1016/j.patter.2020.100139,Journal,Patterns,scopus,2020-12-11,sciencedirect,scTenifoldNet: A Machine Learning Workflow for Constructing and Comparing Transcriptome-wide Gene Regulatory Networks from Single-Cell Data,https://api.elsevier.com/content/abstract/scopus_id/85096558897,"We present scTenifoldNet—a machine learning workflow built upon principal-component regression, low-rank tensor approximation, and manifold alignment—for constructing and comparing single-cell gene regulatory networks (scGRNs) using data from single-cell RNA sequencing. scTenifoldNet reveals regulatory changes in gene expression between samples by comparing the constructed scGRNs. With real data, scTenifoldNet identifies specific gene expression programs associated with different biological processes, providing critical insights into the underlying mechanism of regulatory networks governing cellular transcriptional activities.",science
10.1016/j.patter.2020.100137,Journal,Patterns,scopus,2020-12-11,sciencedirect,Parallel Factor Analysis Enables Quantification and Identification of Highly Convolved Data-Independent-Acquired Protein Spectra,https://api.elsevier.com/content/abstract/scopus_id/85096522758,"High-throughput data-independent acquisition (DIA) is the method of choice for quantitative proteomics, combining the best practices of targeted and shotgun approaches. The resultant DIA spectra are, however, highly convolved and with no direct precursor-fragment correspondence, complicating biological sample analysis. Here, we present CANDIA (canonical decomposition of data-independent-acquired spectra), a GPU-powered unsupervised multiway factor analysis framework that deconvolves multispectral scans to individual analyte spectra, chromatographic profiles, and sample abundances, using parallel factor analysis. The deconvolved spectra can be annotated with traditional database search engines or used as high-quality input for de novo sequencing methods. We demonstrate that spectral libraries generated with CANDIA substantially reduce the false discovery rate underlying the validation of spectral quantification. CANDIA covers up to 33 times more total ion current than library-based approaches, which typically use less than 5% of total recorded ions, thus allowing quantification and identification of signals from unexplored DIA spectra.",science
10.1016/j.comnet.2020.107573,Journal,Computer Networks,scopus,2020-12-09,sciencedirect,AI-enabled mobile multimedia service instance placement scheme in mobile edge computing,https://api.elsevier.com/content/abstract/scopus_id/85091771160,"Leveraging cloud infrastructure to the mobile edge computing helps the mobile users to get real time multimedia services in Fifth Generation (5G) network system. To ensure higher Quality-of-Experience (QoE), faster migration of mobile multimedia service instances is required to cope up with user mobility. By deploying the mobile multimedia service instances proactively in multiple edge nodes (ENs) helps the users to get higher QoE. However, excessive deployment of service replicas might increase the cost of the overall network. To establish trade-off between these two conflicting objectives, we have formulated the problem as a Multi-objective Integer Linear Programming (MILP) by integrating the users’ path prediction model. This problem is proven to be an NP-hard one for large networks, thus we develop an artificial intelligence (AI) based meta-heuristic Binary Particle Swarm Optimization (BPSO) algorithm to achieve near-optimal solution within polynomial time. The performance analysis results show the significant performance improvement in terms of QoE and user satisfaction as compared to other state-of-the-art works.",science
10.1016/j.enmm.2020.100387,Journal,"Environmental Nanotechnology, Monitoring and Management",scopus,2020-12-01,sciencedirect,"Artificial neural network for prediction of color adsorption from an industrial textile effluent using modified sugarcane bagasse: Characterization, kinetics and isotherm studies",https://api.elsevier.com/content/abstract/scopus_id/85096213404,"The present work aims to study the biosorption process of color removal from real textile effluent using chemically modified sugarcane bagasse (SBM) as a biosorbent material and the prediction of the process by modeling and simulation of an artificial neural network (ANN). The raw sugarcane bagasse and the biosorbent SBM were characterized by scanning electron microscopy analysis (SEM), Fourier-transform infrared spectroscopy (FTIR), and porous structure. Batch experiments were carried out on the effect of the effluent pH, contact time between adsorbent and adsorbate, adsorbent dosage, particle size, and effluent color concentration on the adsorption process. The best-operating conditions found were in an acid medium, using an SBM particle size of 0.7 mm, and a dosage of 0.6 g, which allowed a color removal of 100 % for an initial true color concentration of 149 PtCo.L−1. The multilayer feed-forward neural network, with five inputs and one output, was trained with eight neurons in the hidden layer. A comparison between the experimental data and the predicted by ANN model showed that color removal results fitted very well to the model with a coefficient of determination (R2) of 0.928 and a mean square error (MSE) of 0.013. Nonlinear adjustments were made to the kinetic and adsorption isotherm models. In general, the adsorption process with SBM proved to be a promising method for the treatment of textile effluent, and the developed ANN model can be successfully used to make predictions for the final color of the effluent.",science
10.1016/j.fsi.2020.10.008,Journal,Fish and Shellfish Immunology,scopus,2020-12-01,sciencedirect,Spirulina maxima derived marine pectin promotes the in vitro and in vivo regeneration and wound healing in zebrafish,https://api.elsevier.com/content/abstract/scopus_id/85096187233,"Purified bioactive components of marine algae have shown great pharmaceutical and biomedical potential, including wound healing activity. However, the activity of Spirulina maxima is the least documented with regard to wound healing potential. In the present study, we investigated the regenerative and wound healing activities of a Spirulina (Arthrospira) maxima based pectin (SmP) using in vitro human dermal fibroblasts (HDFs) and in vivo zebrafish model. SmP treated (12.5–50 μg/mL) HDFs showed increased cell proliferation by 20–40% compared to the untreated HDFs. Moreover, in vitro wound healing results in HDFs demonstrated that SmP decreased the open wound area % in concentration-dependent manner at 12.5 (32%) and 25 μg/mL (12%) compared to the control (44%). Further, zebrafish larvae displayed a greater fin regenerated area in the SmP exposed group at 25 (0.48 mm2) and 50 μg/mL (0.51 mm2), whereas the untreated group had the lowest regenerated area (0.40 mm2) at 3 days post amputation. However, fin regeneration was significantly (P < 0.001) higher only in the SmP treated group at 50 μg/mL. Furthermore, the open skin wound healing % in adult zebrafish was significantly higher (P < 0.05) after topical application (600 μg/fish) of SmP (46%) compared to the control (38%). Upregulation of genes such as tgfβ1, timp2b, mmp9, tnf-α, and il-1β, and chemokines such as cxcl18b, ccl34a.4, and ccl34b.4, in the muscle and kidney tissues of SmP treated fish compared to the respective control group was demonstrated using qRT-PCR. Histological analysis results further supported the rapid epidermal growth and tissue remodeling in SmP treated fish, suggesting that SmP exerts positive effects associated with wound healing. Therefore, SmP can be considered a potential regenerative and wound healing agent.",science
10.1016/j.asoc.2020.106754,Journal,Applied Soft Computing Journal,scopus,2020-12-01,sciencedirect,Sentiment Analysis of COVID-19 tweets by Deep Learning Classifiers—A study to show how popularity is affecting accuracy in social media,https://api.elsevier.com/content/abstract/scopus_id/85092457474,"COVID-19 originally known as Corona VIrus Disease of 2019, has been declared as a pandemic by World Health Organization (WHO) on 11th March 2020. Unprecedented pressures have mounted on each country to make compelling requisites for controlling the population by assessing the cases and properly utilizing available resources. The rapid number of exponential cases globally has become the apprehension of panic, fear and anxiety among people. The mental and physical health of the global population is found to be directly proportional to this pandemic disease. The current situation has reported more than twenty four million people being tested positive worldwide as of 27th August, 2020. Therefore, it is the need of the hour to implement different measures to safeguard the countries by demystifying the pertinent facts and information. This paper aims to bring out the fact that tweets containing all handles related to COVID-19 and WHO have been unsuccessful in guiding people around this pandemic outbreak appositely. This study analyzes two types of tweets gathered during the pandemic times. In one case, around twenty three thousand most re-tweeted tweets within the time span from 1st Jan 2019 to 23rd March 2020 have been analyzed and observation says that the maximum number of the tweets portrays neutral or negative sentiments. On the other hand, a dataset containing 226,668 tweets collected within the time span between December 2019 and May 2020 have been analyzed which contrastingly show that there were a maximum number of positive and neutral tweets tweeted by netizens. The research demonstrates that though people have tweeted mostly positive regarding COVID-19, yet netizens were busy engrossed in re-tweeting the negative tweets and that no useful words could be found in WordCloud or computations using word frequency in tweets. The claims have been validated through a proposed model using deep learning classifiers with admissible accuracy up to 81%. Apart from these the authors have proposed the implementation of a Gaussian membership function based fuzzy rule base to correctly identify sentiments from tweets. The accuracy for the said model yields up to a permissible rate of 79%.",science
10.1016/j.arr.2020.101174,Journal,Ageing Research Reviews,scopus,2020-12-01,sciencedirect,"A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",https://api.elsevier.com/content/abstract/scopus_id/85091870837,"One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",science
10.1016/j.biotri.2020.100146,Journal,Biotribology,scopus,2020-12-01,sciencedirect,Effects of Mucin on the dexterity and tactile sensitivity of medical glove users,https://api.elsevier.com/content/abstract/scopus_id/85090742355,"The evaluation of medical glove performance has mostly focused on analysing how good a barrier the glove materials are, as well as their durability. Very few studies aim to determine how these gloves affect the performance of the user. This could lead to a lowered ability to carry out tasks, leading to poor healthcare due to diminished sensitivity and dexterity. Furthermore, none of these studies incorporate contaminants to replicate the real-world environments in which medical gloves are used. The work carried out here aims to look at the effects of the bodily fluid mucin on medical glove user's performance. This was assessed via the use of the Purdue Pegboard and Crawford Small Parts Dexterity Test in conjunction with a tactile bump sensitivity test. These tests were carried each in five conditions; bare hand, donned natural rubber latex (NRL) and donned acrylonitrile butadiene rubber (XNBR) gloves – both with and without a 10 mg/ml concentration of porcine gastric mucin applied. The results show that donning gloves decreased dexterity and sensitivity compared to the bare hand. However, mucin was shown to increase dexterity and sensitivity in XNBR, but not with NRL. This is expected to be due to the different ways in which the materials interact with the mucin, affecting the ability to develop a muco-adhesive film and changing the frictional properties of the glove materials.",science
10.1016/j.cogsys.2020.08.010,Journal,Cognitive Systems Research,scopus,2020-12-01,sciencedirect,Toward ethical cognitive architectures for the development of artificial moral agents,https://api.elsevier.com/content/abstract/scopus_id/85090423654,"New technologies based on artificial agents promise to change the next generation of autonomous systems and therefore our interaction with them. Systems based on artificial agents such as self-driving cars and social robots are examples of this technology that is seeking to improve the quality of people’s life. Cognitive architectures aim to create some of the most challenging artificial agents commonly known as bio-inspired cognitive agents. This type of artificial agent seeks to embody human-like intelligence in order to operate and solve problems in the real world as humans do. Moreover, some cognitive architectures such as Soar, LIDA, ACT-R, and iCub try to be fundamental architectures for the Artificial General Intelligence model of human cognition. Therefore, researchers in the machine ethics field face ethical questions related to what mechanisms an artificial agent must have for making moral decisions in order to ensure that their actions are always ethically right. This paper aims to identify some challenges that researchers need to solve in order to create ethical cognitive architectures. These cognitive architectures are characterized by the capacity to endow artificial agents with appropriate mechanisms to exhibit explicit ethical behavior. Additionally, we offer some reasons to develop ethical cognitive architectures. We hope that this study can be useful to guide future research on ethical cognitive architectures.",science
10.1016/j.colsurfb.2020.111333,Journal,Colloids and Surfaces B: Biointerfaces,scopus,2020-12-01,sciencedirect,Modulating the physicochemical and biological properties of carbon dots synthesised from plastic waste for effective sensing of E. coli,https://api.elsevier.com/content/abstract/scopus_id/85090362352,"The reliable means for the quick recognition of pathogenic bacteria for disease prevention has acquired a considerable significance among researchers for human wellbeing. The purpose of current study is to fabricate highly photo-luminescent and biocompatible carbon dots (CQDs) from single used plastic waste such as poly bags, cups and bottles for selective sensing of E. coli. The formed small sized spherical CQDs have possessed high water solubility with excellent photo stable nature. The detailed fluorescence emission studies of CQDs have illustrated the overview of different types of surface defects and emissive states in formed particles. In addition, the specific role of prepared CQDs with bio-compatible nature has been thoroughly checked on hemolysis of red blood cells by employing in-vitro blood compatibility assay. A combination of anticoagulant and thrombolytic activity of CQDs with anti-oxidative activities from reactive oxygen species (ROS) generation were found to be responsible for the biocompatibility of formed CQDs. The effective in vitro stability toward histidine, cysteine, bovine serum albumin (BSA), human serum albumin (HSA) and saline supported the biocompatibility of formed particles as a function of different concentrations of CQDs. The optimized fluorescence properties with high surface to volume ratio of CQDs have provided a better alternative for “turn-off” fluorescence detection of E. coil in aqueous media with limit of detection down to 108 CFU/mL estimated by using standard colony-counting method. The as prepared nanosensor provided easy fabrication with fast response, high sensitivity and selectivity in real water samples which might be necessary for detecting pathogenic agents. In addition, the current work has provided the large overview in blood compatibility and anti-oxidative potential of prepared CQDs and giving useful information for preparing blood–compatible nanoparticles with enhanced bacterial discrimination ability.",science
10.1016/j.neunet.2020.08.010,Journal,Neural Networks,scopus,2020-12-01,sciencedirect,Unsupervised spectral mapping and feature selection for hyperspectral anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/85090034881,"Exploring techniques that breakthrough the unknown space or material species is of considerable significance to military and civilian fields, and it is a challenging task without any prior information. Nowadays, the use of material-specific spectral information to detect unknowns has received increasing interest. However, affected by noise and interference, high-dimensional hyperspectral anomaly detection is difficult to meet the requirements of high detection accuracy and low false alarm rate. Besides, there is a problem of insufficient and unbalanced samples. To address these problems, we propose a novel hyperspectral anomaly detection framework based on spectral mapping and feature selection (SMFS) in an unsupervised manner. The SMFS introduces the essential properties of hyperspectral data into an unsupervised neural network to construct the nonlinear mapping relationship from high-dimensional spectral space to low-dimensional deep feature space. And it searches the optimal feature subset from the candidate feature space for standing out anomalies. Because of the compelling characterization of the encoder, we develop it specifically for spectral signatures to reveal the hidden data. Quantitative and qualitative experiments on real hyperspectral datasets indicate that the proposed method can provide the compact features overcoming the problems of noise, interference, redundancy and time-consuming caused by high-dimensionality and limited samples. And it has advantages over some state-of-the-art competitors concerning detecting anomalies of different scales.",science
10.1016/j.cma.2020.113371,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-12-01,sciencedirect,Stochastic nonlocal damage analysis by a machine learning approach,https://api.elsevier.com/content/abstract/scopus_id/85089593784,"A machine learning aided stochastic nonlocal damage analysis framework is proposed for quasi-brittle materials. The uncertain system parameters, including the material properties and loading actions, have been incorporated and analysed within a unified safety assessment framework against various working conditions. A three-dimensional integral-type nonlocal damage model through finite element method (FEM) has been adopted. For the purpose of investigating the probabilistic damage analysis problems, a freshly established machine learning approach, namely the capped-extended-support vector regression method (C-X-SVR), is proposed to eliminate the influences of random outliers in the first step, then establish the relationship between the uncertain systemic inputs and structural responses. Such that the training robustness and computational adaptability of the proposed regression model can be reinforced. Moreover, the proposed approach is competent of efficiently predicting the statistical information (i.e., means, standard deviations, probability density functions and cumulative density functions) of structural behaviours under continuous information update of the uncertain working condition from mercurial environment. One real-life experimental validation and two numerical investigations are implemented to further verify the effectiveness and efficiency of the uncertainty quantification framework against probabilistic damage analysis.",science
10.1016/j.aca.2020.09.016,Journal,Analytica Chimica Acta,scopus,2020-11-22,sciencedirect,Copper nanoparticles for SERS-based determination of some cephalosporin antibiotics in spiked human urine,https://api.elsevier.com/content/abstract/scopus_id/85090592335,"Copper nanoparticles (CuNPs) were prepared through a wet chemistry method to be used as substituents for noble-metal-based materials in the determination of cephalosporin antibiotics in urine using surface-enhanced Raman spectroscopy (SERS). The synthesis of the CuNPs was optimized to maximize the analytical signal, and microwave heating was used to increase the reaction rate and improve the homogeneity of the CuNPs. Ceftriaxone (CTR), cefazolin (CZL), and cefoperazone (CPR) were used as the analytes of interest. The determination tests were performed on artificially spiked samples of real human urine with concentrations corresponding to therapeutic drug monitoring (TDM) (50–500 μg mL−1). Urine samples collected in the morning and during the day were used to account for deviations in the urine composition, and the universality of the proposed protocol was ensured by performing sample dilution as a pretreatment. The use of calibration plots in the form of Freundlich adsorption isotherms yielded linear calibration plots. All limits of detection were lower than the minimal concentrations required for TDM, equaling 7.5 (CTR), 8.8 (CZL), and 36 (CPR) μg mL−1. Comparison of CuNPs with Ag and Au nanoparticles (AgNPs and AuNPs, respectively) confirmed that CuNPs offered a competitively high Raman enhancement efficiency (for excitation at 638 nm). Further, although the CuNPs demonstrated poorer temporal stability as compared with the AgNPs and AuNPs, the use of freshly prepared CuNPs resulted in satisfactory accuracy (recovery = 93–107%). Given the short analysis time (<20 min, including the time for the synthesis of the CuNPs and the SERS measurements using a portable Raman spectrometer), low sensitivity to the presence of the primary intrinsic urine components and satisfactory figures of merit of the proposed protocol for the determination of cephalosporin antibiotics in urine, it should be suitable for use in TDM.",science
10.1016/j.xcrp.2020.100247,Journal,Cell Reports Physical Science,scopus,2020-11-18,sciencedirect,Adaptive Optimization of Chemical Reactions with Minimal Experimental Information,https://api.elsevier.com/content/abstract/scopus_id/85100391121,"Optimizing reaction conditions depends on expert chemistry knowledge and laborious exploration of reaction parameters. To automate this task and augment chemical intuition, we here report a computational tool to navigate search spaces. Our approach (LabMate.ML) integrates random sampling of 0.03%–0.04% of all search space as input data with an interpretable, adaptive machine-learning algorithm. LabMate.ML can optimize many real-valued and categorical reaction parameters simultaneously, with minimal computational resources and time. In nine prospective proof-of-concept studies pursuing distinctive objectives, we demonstrate how LabMate.ML can identify optimal goal-oriented conditions for several different chemistries and substrates. Double-blind competitions and the conducted expert surveys reveal that its performance is competitive with that of human experts. LabMate.ML does not require specialized hardware, affords quantitative and interpretable reactivity insights, and autonomously formalizes chemical intuition, thereby providing an innovative framework for informed, automated experiment selection toward the democratization of synthetic chemistry.",science
10.1016/j.jep.2020.113208,Journal,Journal of Ethnopharmacology,scopus,2020-11-15,sciencedirect,Salvia miltiorrhiza bunge exerts anti-oxidative effects through inhibiting KLF10 expression in vascular smooth muscle cells exposed to high glucose,https://api.elsevier.com/content/abstract/scopus_id/85088872308,"Ethnopharmacological relevance
                  Traditional Chinese medicinal herb Salvia miltiorrhiza Bunge(Danshen) and its components have been widely used to treat cardiovascular diseases for hundreds of years in China, including hypertension, diabetes, atherosclerosis, and chronic heart failure. Salvia miltiorrhiza injection (SMI), an aqueous extracts of Salvia miltiorrhiza Bunge, is one of most widely used traditional Chinese medicine injections. SMI is widely used in the treatment of diabetic vascular complications, However, the mechanisms remain to be defined.
               
                  Aim of the study
                  To investigate protective mechanism of Salvia miltiorrhiza Bunge against ROS generation in VSMCs of diabetic mice and patients.
               
                  Materials and methods
                  
                     Salvia miltiorrhiza injection (hereinafter referred to as SMI, 1.5 g mL−1), which was approved by the State Food and Drug Administration (approval number: Z32020161), was obtained from Shenlong Pharmaceutical Co., Ltd. (batch number: 11040314). SMI or vehicle were intraperitoneally administrated to the HFD-fed db/db mice, artery was harvested after 24weeks later. qRT-PCR and Western blot analysis were used to detect the expression of KLF6, KLF5, KLF4, KLF10, KLF12, and HO-1. DCFH-DA staining detected intracellular ROS production. Loss- and gain-of-function experiments of KLF10 were used to investigate the effect of KLF10 on the expression of HO-1. Dual-luciferase reporter assay evaluated the effect of KLF10 on the activity of the HO-1 promoter.
               
                  Results
                  KLF10 expression and ROS generation are significantly increased in the arteries of HFD-fed db/db mice, VSMCs of diabetic patients, as well as in high glucose-treated VSMCs. KLF10 overexpression suppresses, while its knockdown facilitates the expression of heme oxygenase (HO-1) mRNA and protein. Further, Salvia miltiorrhiza injection (SMI) abrogates KLF10 upregulation and reduces ROS generation induced by high glucose in VSMCs. Mechanistically, KLF10 negatively regulates the HO-1 gene transcription via directly binding to its promoter. Accordingly, SMI treatment of VSMCs reduces ROS generation through inhibiting KLF10 expression and thus relieving KLF10 repression of the expression of HO-1 gene, subsequently contributing to upregulation of HO-1.
               
                  Conclusion
                  
                     SMI exerts anti-oxidative effects on VSMCs exposed to high glucose through inhibiting KLF10 expression and thus upregulating HO-1.",science
10.1016/j.eswa.2020.113595,Journal,Expert Systems with Applications,scopus,2020-11-15,sciencedirect,Rumor detection based on propagation graph neural network with attention mechanism,https://api.elsevier.com/content/abstract/scopus_id/85086634178,"Rumors on social media have always been an important issue that seriously endangers social security. Researches on timely and effective detection of rumors have aroused lots of interest in both academia and industry. At present, most existing methods identify rumors based solely on the linguistic information without considering the temporal dynamics and propagation patterns. In this work, we aim to solve rumor detection task under the framework of representation learning. We first propose a novel way to construct the propagation graph by following the propagation structure (who replies to whom) of posts on Twitter. Then we propose a gated graph neural network based algorithm called PGNN, which can generate powerful representations for each node in the propagation graph. The proposed PGNN algorithm repeatedly updates node representations by exchanging information between the neighbor nodes via relation paths within a limited time steps. On this basis, we propose two models, namely GLO-PGNN (rumor detection model based on the global embedding with propagation graph neural network) and ENS-PGNN (rumor detection model based on the ensemble learning with propagation graph neural network). They respectively adopt different classification strategies for rumor detection task, and further improve the performance by including attention mechanism to dynamically adjust the weight of each node in the propagation graph. Experiments on a real-world Twitter dataset demonstrate that our proposed models achieve much better performance than state-of-the-art methods both on the rumor detection task and early detection task.",science
10.1016/j.neucom.2020.07.013,Journal,Neurocomputing,scopus,2020-11-13,sciencedirect,MFRep: Joint user and employer alignment across heterogeneous social networks,https://api.elsevier.com/content/abstract/scopus_id/85088837122,"Nowadays people join multiple social networks simultaneously to enjoy a variety of social services. Apart from common users, social networks also share other information entities such as organizations/companies. Aligning common information entities across heterogeneous social networks is challenging, but will facilitate many applications. Existing approaches for network alignment do not fully leverage indirect relations among users (i.e., friends of friends). This leads to relatively poor performance, especially when there are little overlapping social relations between different networks. Meanwhile, the mutual promotion between two kinds of information entity alignment is often neglected.
                  In this paper, we propose a novel Matrix Factorization based Representation learning (MFRep) framework. MFRep investigates the joint learning for user and employer alignment across different networks. (1). We first compute the cross-network similarities in user attributes to extract seed potential anchor users. Its efficiency can be boosted by considering the similarities in employer properties. (2). Considering social relation differences across networks, we construct user relational matrix to preserve multi-step relational information. This embodies the information propagation from known and seed potential anchor users to other potential anchor users. (3). We extend the user relational matrix to preserve consistent associations between users and employers across networks. (4). We perform semi-supervised user representation learning and unsupervised employer representation learning concurrently via efficient matrix decomposition. The correspondence between users/employers across networks can be inferred based on vector relevance. Extensive experiments on real-world social network datasets justify the utility of MFRep, even with dissimilar social structures across networks. MFRep illustrates the mutual promoted alignments of users and employers with a middle degree of scalability.",science
10.1016/j.mechatronics.2020.102436,Journal,Mechatronics,scopus,2020-11-01,sciencedirect,Modeling the thermo-mechanical deformations of machine tool structures in CFRP material adopting data-driven prediction schemes,https://api.elsevier.com/content/abstract/scopus_id/85092002525,"The thermo-mechanical effects in machine tools (MTs) are represented by complex models since they may produce non-linear distortions overtime, impacting significantly on the machining accuracy. This paper aims to model the deformation of CFRP (Carbon-Fiber-Reinforced-Polymers) structures using data-driven schemes to predict and compensate the structural thermo-mechanical behavior. A novel study is presented to investigate the thermally-induced distortions of CFPR structural materials, selecting and positioning sensors, simulating and validating models to compensate the error in real-time. Anisotropic materials are becoming an effective solution to reduce structure mass and increase damping of a MT, nevertheless their physical complexity and the different thermal-coefficients at the interface with conventional materials may generate undesired effects, limiting the obtained advantages. The proposed strategy is based on the evaluation of a set of data-driven models simultaneously, identifying the most suitable solution and comparing finite element simulations with machine learning approach. The study is developed on a vertical axis frame made of CFRP material. The experimental validation is executed on a commercial 5-axis machine tool by varying the temperature conditions and evaluating the structural thermo-mechanical deformation effect on the Tool-Tip-Point (TTP) displacement. The thermo-mechanical behavior is measured by fiber Bragg grating (FBG) sensing technology embedded in the CFRP structure. Data-driven lab tests are evaluated in operational conditions during 36 h, considering: i) training-deployment periods (875 min interval), ii) typical machining stresses and iii) environmental perturbations. The final selected data-driven model is able to reduce the detected error lower than 10 μm range. In particular, the achieved results indicate a congruence between the TTP displacement measured and predicted with a residual error lower than 7.0 μm (Y-direction) using the ANN- multilayer perceptron algorithm.",science
10.1016/j.mpdhp.2020.08.004,Journal,Diagnostic Histopathology,scopus,2020-11-01,sciencedirect,Artificial intelligence in pathology: an overview,https://api.elsevier.com/content/abstract/scopus_id/85090478810,"Artificial intelligence (AI) is at the forefront of modern technology and emerging uses within the healthcare sector are now being realised. Pathology will be a key area where the impact of AI will be felt. With more and more laboratories making the transition to digital pathology this will provide the key infrastructure in which to deploy these tools and their use will start to become a reality in diagnostic practice. The potential of AI in pathology is to create image analysis tools which could either be used for diagnostic support or to derive novel insights into disease biology, in addition to those achievable with a human observer. Some examples providing diagnostic support currently exist for a limited, but expanding number of applications, such as tumour detection, automated tumour grading, immunohistochemistry scoring, and predicting mutation status. There are a number of challenges to consider, not least the validation and regulatory framework for these tools. In this article, we set out an overview of AI in histopathology, discuss its potential workflow applications, and give key examples of the potential for AI in clinical practice. Considerations for the implementation of AI in practice are also explored.",science
10.1016/j.lfs.2020.118305,Journal,Life Sciences,scopus,2020-11-01,sciencedirect,LncRNA PVT1 regulates ferroptosis through miR-214-mediated TFR1 and p53,https://api.elsevier.com/content/abstract/scopus_id/85089997914,"Aim
                  The study aims to investigate the roles of LncRNA and miRNA in ferroptosis in brain ischemia/reperfusion (I/R) in vivo and in vitro.
               
                  Materials and methods
                  qPCR assay was used to analyze lncRNA PVT1 and miR-214 expressions in acute ischemic stroke (AIS) patients. Then, we established brain I/R mice models and OGD/R PC12 cell models to analyze the mechanism of ferroptosis. I/R mice were treated by lncRNA PVT silencing or miR-214 overexpressing lentivirus via lateral ventricles. Infarct size was analyzed by TTC staining, accompanied by the detection of ferroptosis indicators through Perls'Prussian blue staining, iron kit, MDA kit, glutathione kit, GPx activities kit and Western blotting (WB). Dual luciferase reporter assay was used to assess whether miR-214 bound to PVT1, TP53 or TFR1. Co-IP analyzed the interplay of p53 with SLC7A11.
               
                  Key findings
                  We found that the levels of PVT1 were upregulated and miR-214 levels were downregulated in plasma of AIS patients. NIHSS score was positively correlated with PVT1 levels but was negatively with miR-214 levels. PVT1 silencing or miR-214 overexpression significantly reduced infarct size and suppressed ferroptosis in vivo. miR-214 overexpression markedly decreased PVT1 levels. Specifically, miR-214 could bind to 3'untranslated region (3’UTR) of PVT1, TP53 or TFR1. PVT1 overexpression or miR-214 silencing markedly abolished the effects of Ferrostatin-1 on ferroptosis indicators except for TFR1 expression. Besides, miR-214 silencing counteracted the effects of PVT1 knockdown on the ferroptosis-related proteins.
               
                  Conclusion
                  PVT1 regulated ferroptosis through miR-214-mediated TFR1 and TP53 expression. There was a positive feedback loop of lncRNA PVT1/miR-214/p53 possibly.",science
10.1016/j.fsi.2020.06.061,Journal,Fish and Shellfish Immunology,scopus,2020-11-01,sciencedirect,"Bacillus subtilis H2 modulates immune response, fat metabolism and bacterial flora in the gut of grass carp (Ctenopharyngodon idellus)",https://api.elsevier.com/content/abstract/scopus_id/85088932023,"Functional ingredients such as Bacillus subtilis are used in aquaculture to improve fish condition, modulate microbiota and promote a healthy intestinal system. However, the underlying mechanisms of grass carp treated with B. subtilis are not fully characterized. This study investigated the gut microbes of grass carp after treated with B. subtilis H2 (106 CFU/mL) and Aeromonas hydrophila (106 CFU/mL). The intestinal flora was found that the dominant bacterial phyla identified in all samples were Proteobacteria, Actinobacteria, Fusobacteria, Bacteroidetes and Acidobacteria. Compared with the control group, the relative abundance of Proteobacteria and Bacteroidetes in B. subtilis group were significantly increased. In addition, the relative abundances of Aeromonas and Shewanella in A. hydrophila group were more than the control group. For the intestinal transcriptomic profiling of the grass carp treated with B. subtilis H2, 824 different expressed genes (DEGs) between the B. subtilis H2 treated and non-treated groups were detected, including 365 up-regulated and 459 down-regulated genes. Six DEGs were randomly selected for further validation by quantitative real-time RT-PCR (qRT-PCR) and the results were consistent with the RNA-seq data. Additionally, eight immunomodulatory genes (IL-4, IL-11, IFN-α, CSF, FOSB, MAPK12b, IGHV3-11 and IGHV3-21) were significantly up-regulated after treated with B. subtilis H2. Furthermore, almost all the lipid metabolism-associated genes were significantly up-regulated after treated with B. subtilis H2 according to the lipid metabolism pathways. Eleven lipid metabolism-associated genes were selected by qRT-PCR, which showed that the expressions of almost all the selected genes were increased, especially Apob-48, ABCG8 and DGAT. Taken together, our results support that B. subtilis could modulate the immune response, fat metabolism and bacterial assembly in the gut of grass carp.",science
10.1016/j.ipm.2020.102340,Journal,Information Processing and Management,scopus,2020-11-01,sciencedirect,A topic modeling framework for spatio-temporal information management,https://api.elsevier.com/content/abstract/scopus_id/85087504158,"Real-time processing and learning of conflicting data, especially messages coming from different ideas, locations, and time, in a dynamic environment such as Twitter is a challenging task that recently gained lots of attention. This paper introduces a framework for managing, processing, analyzing, detecting, and tracking topics in streaming data. We propose a model selector procedure with a hybrid indicator to tackle the challenge of online topic detection. In this framework, we built an automatic data processing pipeline with two levels of cleaning. Regular and deep cleaning are applied using multiple sources of meta knowledge to enhance data quality. Deep learning and transfer learning techniques are used to classify health-related tweets, with high accuracy and improved F1-Score. In this system, we used visualization to have a better understanding of trending topics. To demonstrate the validity of this framework, we implemented and applied it to health-related twitter data from users originating in the USA over nine months. The results of this implementation show that this framework was able to detect and track the topics at a level comparable to manual annotation. To better explain the emerging and changing topics in various locations over time the result is graphically displayed on top of the United States map.",science
10.1016/j.jpdc.2020.06.010,Journal,Journal of Parallel and Distributed Computing,scopus,2020-11-01,sciencedirect,Performance enhancement of a dynamic K-means algorithm through a parallel adaptive strategy on multicore CPUs,https://api.elsevier.com/content/abstract/scopus_id/85086986038,"The K-means algorithm is one of the most popular algorithms in Data Science, and it is aimed to discover similarities among the elements belonging to large datasets, partitioning them in 
                        K
                      distinct groups called clusters. The main weakness of this technique is that, in real problems, it is often impossible to define the value of 
                        K
                      as input data. Furthermore, the large amount of data used for useful simulations makes impracticable the execution of the algorithm on traditional architectures. In this paper, we address the previous two issues. On the one hand, we propose a method to dynamically define the value of 
                        K
                      by optimizing a suitable quality index with special care to the computational cost. On the other hand, to improve the performance and the effectiveness of the algorithm, we propose a strategy for parallel implementation on modern multicore CPUs.",science
10.1016/j.jksuci.2018.10.012,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2020-11-01,sciencedirect,Exploring demographic information in online social networks for improving content classification,https://api.elsevier.com/content/abstract/scopus_id/85055732842,"The daily interaction between users within online social networks (OSNs) is an effective way to analyze and interpret its context in real time in order to capture the interests, preferences, and concerns of the OSNs users. These offer a unique information source for several applications in several fields such as trendsetting, future prediction, recommendation systems, community detection, and marketing. Most of the existing studies on text classification in OSNs rely on content based approach, in order to capture users interests through exploiting and categorizing the unstructured textual content shared by those users according to their topics. Moreover, users public profiles available on OSNs often reveal their demographic attributes such as age, gender, education, marital status, etc., which can play an essential role in identifying users interests and preferences. User demographic attributes can provide some preferences for some topics of interests. People with different demographic attributes may be interested in different topics, while people with similar demographic attributes may have the same interests. Usually, young people are more interested in technology than old people, who are more interested in the political news than young people. In this paper, we propose a demographic-content-based approach which uses both users demographic attributes and the textual content to classify OSNs posts using six classifiers ANN, k-NN, Naïve Bayes, Decision Tree, Decision rules and SVM. The experiments are done on a large Facebook dataset in order to analyze the effect of these demographic attributes on the performance of the categorization of the shared textual content in OSNs.",science
10.1016/j.neucom.2020.04.145,Journal,Neurocomputing,scopus,2020-10-28,sciencedirect,Multimodal graph convolutional networks for high quality content recognition,https://api.elsevier.com/content/abstract/scopus_id/85087592194,"With the development of the Internet, more and more creators publish articles on social media. How to automatically filter high quality content from a large number of multimedia articles is one of the core functions of information recommendation, search engine, and other systems. However, existing approaches typically suffer from two limitations: (1) They usually model content as word sequences, which ignores the semantics provided by non-consecutive phrases, long-distance word dependency, and visual information. (2) They rely on a large amount of manually annotated data to train a quality assessment model while users may only provide labels of interest in a single class for a small number of samples in reality. To address these limitations, we propose a Multimodal Graph Convolutional Networks (MGCN) to model the semantic representations in a unified framework for High Quality Content Recognition. Instead of viewing text content as word sequences, we convert them into graphs, which can model non-consecutive phrases and long-distance word dependency for better obtaining the composition of semantics. Besides, visual content is also modeled into the graphs to provide complementary semantics. A well-designed graph convolutional network is proposed to capture the semantic representations based on these graphs. Furthermore, we employ a non-negative risk estimator for high quality content recognition and the loss is back-propagated for model learning. Experiments on real datasets validate the effectiveness of our approach.",science
10.1016/j.knosys.2020.106256,Journal,Knowledge-Based Systems,scopus,2020-10-12,sciencedirect,Community detection based on the Matthew effect,https://api.elsevier.com/content/abstract/scopus_id/85088031223,"Community structure exists in most real-world networks, such as social networks, smart grids, and transportation networks. Established approaches for community detection usually depend on some user-defined criteria (e.g., minimum cut, normalized cut, modularity, etc.). These criteria-based methods usually involve some optimization procedures and need to specify some parameters, which are thus time consuming and sensitive to parameters. In this paper, inspired by the Mathew effect of human society, we view a network as a social system and design a new algorithm called CDME (community detection based on the Matthew effect). Relying on the new concept, CDME has many desirable properties. It allows uncovering high-quality communities driven by dynamic CDME is also parameter free. More importantly, since CDME works in a local way and only needs to calculate the attractiveness of neighboring nodes, which lend itself to handling large-scale networks. Experiments on both synthetic and real-world data sets have demonstrated that CDME has many benefits and outperforms many state-of-the-art algorithms.",science
10.1016/j.patter.2020.100108,Journal,Patterns,scopus,2020-10-09,sciencedirect,Using Machine Learning to Identify Adverse Drug Effects Posing Increased Risk to Women,https://api.elsevier.com/content/abstract/scopus_id/85102228908,"Adverse drug reactions are the fourth leading cause of death in the US. Although women take longer to metabolize medications and experience twice the risk of developing adverse reactions compared with men, these sex differences are not comprehensively understood. Real-world clinical data provide an opportunity to estimate safety effects in otherwise understudied populations, i.e., women. These data, however, are subject to confounding biases and correlated covariates. We present AwareDX, a pharmacovigilance algorithm that leverages advances in machine learning to predict sex risks. Our algorithm mitigates these biases and quantifies the differential risk of a drug causing an adverse event in either men or women. AwareDX demonstrates high precision during validation against clinical literature and pharmacogenetic mechanisms. We present a resource of 20,817 adverse drug effects posing sex-specific risks. AwareDX, and this resource, present an opportunity to minimize adverse events by tailoring drug prescription and dosage to sex.",science
10.1016/j.jece.2020.104302,Journal,Journal of Environmental Chemical Engineering,scopus,2020-10-01,sciencedirect,From waste disposal to valuable material: Sulfonating polystyrene waste for heavy metal removal,https://api.elsevier.com/content/abstract/scopus_id/85094313858,"The conversion of waste into reusable materials has been a focus of many researchers in recent years. Polystyrene waste converted into a cation exchange resin and used as absorbent of cadmium, copper and zinc had been concerned. In this study, the feasibility of sulfonating polystyrene waste was investigated by using sulfuric acid to form sulfonated functional groups on the polystyrene matrix and further used for heavy metal ions removal from wastewater. The modified ion exchange materials were characterized by FTIR, SEM, EDS, XRD and TGA. Batch mode experiments of heavy metal ion exchange were conducted to determine the kinetic parameters. The adsorption of zinc, copper and cadmium by the sulfonated polystyrene fitted with both the Langmuir and the Freundlich isotherm model; the maximum adsorption capacities were 4.09 mg Zn2+/g, 4.58 mg Cu2+/g and 4.04 mg Cd2+/g, respectively. Moreover, fixed-bed adsorption was investigated. When the ﬂow rate decreased, the initial concentration, and the mass of sulfonated polystyrene increased, the adsorption capacity was observed to increase. A maximum adsorption capacity of 10.6 mg Zn2+/g was achieved at the inﬂuent concentration of 70 mg/L, sulfonated polystyrene mass of 30 g, and ﬂow rate of 8.33 mL/min when operating with real zinc electroplating wastewater. The kinetic Thomas and Yoon-Nelson models well described the adsorption of Zn2+, Cu2+, and Cd2+ in continuous mode, with R2 value higher than 90 %. From these results, it can be concluded that this sulfonation process of polystyrene waste can be technically and environmentally feasible method for sustainable development.",science
10.1016/j.heliyon.2020.e05243,Journal,Heliyon,scopus,2020-10-01,sciencedirect,"Fast, easy, cheap, robust and safe method of analysis of Sudan dyes in chilli pepper powder",https://api.elsevier.com/content/abstract/scopus_id/85092504210,"Illicit use of Sudan dyes, a group of harmful and carcinogenic azo dyes, in the food industry has taken a surge in various parts of the world, especially in Africa. Their use in food as additives pose a dire health risk to consumers and have been banned by various food regulatory bodies worldwide. To help increase surveillance, various methods have been proposed for their analysis in literature. This study also sought to experiment and propose an alternative method for quick, easy, cheap, robust and ecologically safe analysis of Sudan dyes in chilli pepper powder and similar matrices. The optimized method used a 6.0 mL mixture of acetone:acetonitrile (1:5 v/v) solvent in a modified QuEChERs method for extraction of Sudan dyes I-IV. The simultaneous analysis of the dyes were achieved on Shimadzu prominence UFLC 20AD coupled with SPD 20AX UV detector operated at dual wavelength of 500 and 480 nm. A total of twenty four (24) chilli pepper powder samples from eight different vendors on the Ghana market were analysed using the optimized method. Quantitation of analytes were done using the external standard calibration method with determination coefficient, R2 > 0.9999. The limit of detection (LOD) and limit of quantitation (LOQ) of the method were 0.02–0.04 mg/kg and 0.05–0.13 mg/kg respectively. A good recovery range between 85.3 – 121.2% were obtained for a spike level of 1.0 mg/kg in real samples. ANOVA analysis at 95% CL showed statistically no significant difference (p > 0.05) in the recoveries between samples and also between the individual compounds. The method experimented and proposed in this study is fast, easy, cheap, robust and ecologically safe, presenting an alternative method for routine analysis for increased rate of surveillance against the illicit use of Sudan dyes as food additives.",science
10.1016/j.trb.2020.08.005,Journal,Transportation Research Part B: Methodological,scopus,2020-10-01,sciencedirect,An actor-critic deep reinforcement learning approach for metro train scheduling with rolling stock circulation under stochastic demand,https://api.elsevier.com/content/abstract/scopus_id/85090424869,"This paper presents a novel actor-critic deep reinforcement learning approach for metro train scheduling with circulation of limited rolling stock. The scheduling problem is modeled as a Markov decision process driven by stochastic passenger demand. As in most dynamic optimization problems, the complexity of the scheduling process grows exponentially with the amount of states, decisions, and uncertainties involved. This study aims to address this ‘curses of dimensionality’ issue by adopting an actor-critic deep reinforcement learning solution framework. The framework simplifies the evaluation and searching process for potential optimal solutions by parameterizing the original state and decision spaces with the use of artificial neural networks. A deep deterministic policy gradient algorithm is developed for training the artificial neural networks via simulated system transitions before the actor-critic agent can be applied for online schedule control. The proposed approach is tested with a real-world scenario configured with data collected from the Victoria Line of London Underground, UK. Experiment results illustrate the advantages of the proposed method over a range of established meta-heuristics in terms of computing time, system efficiency, and robustness under different stochastic environments. This study innovates urban transit operations with state-of-the-art computer science and dynamic optimization techniques.",science
10.1016/j.compbiomed.2020.103976,Journal,Computers in Biology and Medicine,scopus,2020-10-01,sciencedirect,Real-time deep learning-based image recognition for applications in automated positioning and injection of biological cells,https://api.elsevier.com/content/abstract/scopus_id/85090333764,"Biological cell injection is an effective method in which a foreign material is directly introduced into a biological cell. Since human involvement reduces the success rate of the biological microinjection procedure, an extensive research effort has been made towards its automation. The accurate positioning of a randomly placed biological cell in the microscope's field of view is a prerequisite for any automated injection procedure. Vision is the primary source for visual servoing in microinjection applications. For this reason, a visual sensing system is required to recognise, calculate, and manipulate the cell to the desired position. In this study, eight different pretrained neural networks were analysed and used as a backbone for the YOLOv2 object detection method, and the optimal network was evaluated based on mean Intersection over Union (IoU) accuracy, average precision (AP) at different thresholds, and frame rate (fps) in our dataset. YOLOv2 with Resnet-50 model demonstrated superior performance with 89% mean IoU accuracy and 100% detection accuracy at an average of 33 fps. Ten different sets of experiments were conducted to examine the algorithm by verifying the zebrafish embryo gradual presence within the field of view to bring the zebrafish embryo to the predefined position. Experimental results demonstrated that the developed solution performed real-time with high accuracy and illustrates auto-positioning with a 100% success rate regardless of the initial position of the biological cell within the Petri dish. Later, the generalization of the proposed solution was verified in a different dataset from the real microinjection setup.",science
10.1016/j.engappai.2020.103910,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-10-01,sciencedirect,Multi-objective ensembles of echo state networks and extreme learning machines for streamflow series forecasting,https://api.elsevier.com/content/abstract/scopus_id/85089817082,"Streamflow series forecasting composes a fundamental step in planning electric energy production for hydroelectric plants. In Brazil, such plants produce almost 70% of the total energy. Therefore, it is of great importance to improve the quality of streamflow series forecasting by investigating state-of-the-art time series forecasting algorithms. To this end, this work proposes the development of ensembles of unorganized machines, namely Extreme Learning Machines (ELMs) and Echo State Networks (ESNs). Two primary contributions are proposed: (1) a new training logic for ESNs that enables the application of bootstrap aggregation (bagging); and (2) the employment of multi-objective optimization to select and adjust the weights of the ensemble’s base models, taking into account the trade-off between bias and variance. Experiments are conducted on streamflow series data from five real-world Brazilian hydroelectric plants, namely those in Sobradinho, Serra da Mesa, Jiraú, Furnas and Água Vermelha. The statistical results for four different prediction horizons (1, 3, 6, and 12 months ahead) indicate that the ensembles of unorganized machines achieve better results than autoregressive (AR) models in terms of the Nash–Sutcliffe model efficiency coefficient (NSE), root mean squared error (RMSE), coefficient of determination (R
                        
                           
                           
                              2
                           
                        
                     ), and RMSE-observations standard deviation ratio (RSR). In such results, the ensembles with ESNs and the multi-objective optimization design procedure achieve the best scores.",science
10.1016/j.trc.2020.102749,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-10-01,sciencedirect,Analyzing network-wide patterns of rail transit delays using Bayesian network learning,https://api.elsevier.com/content/abstract/scopus_id/85089554926,"Rail transit delays are generally discussed in terms of on-time performance or problems at individual stops. Such stop-scale approaches ignore the fact that delays are also caused and perpetuated by network-wide factors (e.g., bottlenecks caused by shared tracks by multiple transit lines). The objective of this paper is to develop a network model and metrics that can quantify the delay dependencies between transit network stops, and identify local sources of network-wide issues. For this purpose, Bayesian network learning (at the intersection of machine learning and network science) was utilized. Based on the calculated Bayesian networks (BNs), network metrics (inducer and susceptible) were formulated to quantify the network-wide impacts of the delays experienced at the stops. To implement the proposed framework, the delays at Long Island Rail Road (LIRR) were gathered through a crowdsourced real-time transit information app called onTime. The developed BN model was tested through cross-validation, yielded promising accuracy results, successfully identified the problematic stops based on LIRR reports, and provided further insights on network impacts. The BN model and the developed metrics were further tested using a natural experiment, i.e., a before and after study focusing on a recently completed track expansion project at LIRR. The findings imply that BN learning can successfully identify the network dependencies and indicate the rail links/corridors that are the best candidate for subsequent improvement investments. Overall, the developed metrics can quantify the delay dependencies between stops and they can be used by policy makers and practitioners for investment and improvement decisions.",science
10.1016/j.nucengdes.2020.110817,Journal,Nuclear Engineering and Design,scopus,2020-10-01,sciencedirect,Machine learning enabled advanced manufacturing in nuclear engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85089553568,"Advanced manufacturing has gained tremendous interest in both research and industry in the past few years. Over nearly the same period of time, machine learning (ML) has made phenomenal advancements, finding its way into many aspects of manufacturing. For the nuclear engineering field, the adoption of advanced manufacturing is a compelling argument due to the ambitious challenges the field faces. The combination of advanced manufacturing with ML holds great potential in the nuclear engineering field, and even further development is needed to accelerate their deployment towards real-world applications. This review paper seeks to detail several key aspects of ML enabled advanced manufacturing that are used or could prove useful to nuclear applications ranging from radiation detector materials to reactor parts fabrication. The applications covered here include new material extrapolation, manufacturing defect detection, and additive manufacturing parameters’ optimization.",science
10.1016/j.ohx.2020.e00131,Journal,HardwareX,scopus,2020-10-01,sciencedirect,Partially RepRapable automated open source bag valve mask-based ventilator,https://api.elsevier.com/content/abstract/scopus_id/85089470505,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided.",science
10.1016/j.cbpa.2020.06.002,Journal,Current Opinion in Chemical Biology,scopus,2020-10-01,sciencedirect,Sequencing enabling design and learning in synthetic biology,https://api.elsevier.com/content/abstract/scopus_id/85089023322,"The ability to read and quantify nucleic acids such as DNA and RNA using sequencing technologies has revolutionized our understanding of life. With the emergence of synthetic biology, these tools are now being put to work in new ways — enabling de novo biological design. Here, we show how sequencing is supporting the creation of a new wave of biological parts and systems, as well as providing the vast data sets needed for the machine learning of design rules for predictive bioengineering. However, we believe this is only the tip of the iceberg and end by providing an outlook on recent advances that will likely broaden the role of sequencing in synthetic biology and its deployment in real-world environments.",science
10.3168/jds.2020-18652,Journal,Journal of Dairy Science,scopus,2020-10-01,sciencedirect,Effects of lipopolysaccharide exposure in primary bovine ruminal epithelial cells,https://api.elsevier.com/content/abstract/scopus_id/85088978872,"The objective of this study was to investigate whether cultured ruminal epithelial cells (REC) responded to lipopolysaccharide (LPS) stimulation and determine whether LPS induced a proinflammatory response. Primary bovine REC were isolated and grown in culture for 2 studies. In study 1, REC were isolated from Holstein bull calves (n = 8) and grown in culture for 10 to 12 d. Cells were then exposed to 0, 10,000, 50,000, or 200,000 endotoxin (E)U/mL of LPS (Escherichia coli O55:B5) for either 6 or 24 h. The effect of LPS exposure on cell viability was analyzed by flow cytometry using a propidium iodide stain. In study 2, cells were isolated from Holstein bull calves (n = 5) and yearling beef heifers (n = 4). Cells were exposed to either 1,000 or 50,000 EU/mL of LPS using the following conditions: (1) medium alone time-matched controls, (2) 12-h LPS exposure, (3) 24 h of LPS exposure, (4) 36 h of LPS exposure, (5) 12 h of LPS exposure followed by LPS removal for 24 h before restimulating with LPS for an additional 12 h (RPT), and (6) 12 h of LPS exposure followed by LPS removal for 36 (RVY). For both experiments, total RNA was extracted from REC and real-time quantitative PCR was performed to determine relative expression of genes for toll-like receptors (TLR2 and TLR4), proinflammatory cytokines (TNF and IL1B), chemokines (CXCL2 and CXCL8), a lipid mediator (PTGS2), and growth factor-like cytokines (CSF2 and IL7). In study 1, LPS exposure did not negatively affect cell viability. Treatment of cells with LPS resulted in increased transcript abundance for all genes analyzed. The TLR2, IL7, and TLR4 had a greater magnitude of change at 6 h compared with 24 h. Quadratic expression patterns were detected for TNF, IL1B, CXCL2, CXCL8, and CSF2. These results suggested that REC increase expression of proinflammatory genes following exposure to LPS. In study 2, all genes analyzed were upregulated in a quadratic manner following exposure to LPS for different time intervals. The TLR4, TNF, CXCL2, CXCL8, CSF2, and IL7 gene expression was significantly greater after a single 12 h of LPS exposure than after RPT exposure, suggesting repeated exposure of REC to LPS may induce a tolerogenic effect. When LPS was removed from the medium (RVY), transcript abundance for all genes analyzed decreased and expression of TLR2, TLR4, and IL7 returned to baseline levels, suggesting REC recovered following exposure to LPS. Overall, the data suggest cultured REC respond to LPS stimulation by increasing transcription of proinflammatory genes and this transcriptional response was influenced by the dose, duration, and frequency of LPS exposure.",science
10.1016/j.berh.2020.101559,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2020-10-01,sciencedirect,Innovations to improve access to musculoskeletal care,https://api.elsevier.com/content/abstract/scopus_id/85088788188,"Innovation is a form of realising a new way of doing something, often ignoring traditional wisdom, in order to meet new challenges. Globally, particularly in emerging economies, the high burden of musculoskeletal conditions and their contribution to multimorbidity continue to rise, as does the gap for services to deliver essential care. There is a growing need to find solutions to this challenge and deliver person-centred and integrated care, wherein empowering patients with the capacity for self-management is critical. Whilst there is an abundance of information available online to support consumer education, the number of sources for credible medical information is diluted by uninformed anecdotal social media solutions. Even with the provision of high-quality information, behavioural change does not necessarily follow, and more robust educational approaches are required.
                  In this chapter, we examine innovation, its management and the strategic directions required to improve musculoskeletal healthcare at macro (policy), meso (service delivery) and micro (clinical practice) levels. We discuss the critical role of consumer agency (patients and their families/carers) in driving innovation and the need to leverage this through empowerment by education.
                  We provide a snapshot of real-world examples of innovative practices including capacity building in consumer and interprofessional musculoskeletal education and practice; recommendations to transform the access and delivery of integrated, person-centred care; and initiatives in musculoskeletal care and implementation of models of care, enabled by digital health solutions including telehealth, remote monitoring, artificial intelligence, blockchain technology and big data. We provide emerging evidence for how innovation can support systems' strengthening and build capacity to support improved access to ‘right’ musculoskeletal care, and explore some of the ways to best manage innovations.
                  We conclude with recommended systematic steps to establish required leadership, collaboration, research, networking, dissemination, implementation and evaluation of future innovations in musculoskeletal health and care.",science
10.1016/j.compeleceng.2020.106766,Journal,Computers and Electrical Engineering,scopus,2020-10-01,sciencedirect,Imputation of Missing Values Affecting the Software Performance of Component-based Robots,https://api.elsevier.com/content/abstract/scopus_id/85088022516,"Intelligent robots are foreseen as a technology that would be soon present in most public and private environments. In order to increase the trust of humans, robotic systems must be reliable while both response and down times are minimized. In keeping with this idea, present paper proposes the application of machine learning (regression models more precisely) to preprocess data in order to improve the detection of failures. Such failures deeply affect the performance of the software components embedded in human-interacting robots. To address one of the most common problems of real-life datasets (missing values), some traditional (such as linear regression) as well as innovative (decision tree and neural network) models are applied. The aim is to impute missing values with minimum error in order to improve the quality of data and consequently maximize the failure-detection rate. Experiments are run on a public and up-to-date dataset and the obtained results support the viability of the proposed models.",science
10.1016/j.ast.2020.105965,Journal,Aerospace Science and Technology,scopus,2020-10-01,sciencedirect,Towards a PDE-based large-scale decentralized solution for path planning of UAVs in shared airspace,https://api.elsevier.com/content/abstract/scopus_id/85086828428,"Recently, there has been a tremendous increase of interest in utilizing Unmanned Aerial Vehicles (UAVs) for a number of civilian applications. With this increased interest, it is imperative that these UAVs are able to operate in shared airspace for enhanced efficiency. Multi-UAV systems are inherently safety-critical systems, which means that safety guarantees must be made to ensure no undesirable configurations, such as collisions, occur. This paper proposes a decentralized method based on a Partial Differential Equation (PDE) to generate collision-free 3D trajectories for multiple UAVs operating in a shared airspace. This method exploits the dynamical properties of multi-phase fluids flowing through a porous medium by modeling the porosity values as a function of the risk of collision. To highlight the feasibility for on-board implementation, we propose propose a machine learning technique for obtaining computationally efficient solutions of the PDE describing flow movements in porous medium. This method has been compared via a simulation study to two other path planning strategies, centralized and sequential planning, and the advantages of this method are presented. Furthermore, results from an experiment using three UAVs have been presented to demonstrate the applicability of the proposed method to real-world implementation.",science
10.1016/j.petrol.2020.107434,Journal,Journal of Petroleum Science and Engineering,scopus,2020-10-01,sciencedirect,"Probabilistic Neural Network with Bayesian-based, spectral torque imaging and Deep Convolutional Autoencoder for PDC bit wear monitoring",https://api.elsevier.com/content/abstract/scopus_id/85085583360,"Drill bit wear monitoring plays an important role during drilling operations, particularly in drilling challenging environments, such as ultradeep water and hard rock formations. The machine learning algorithms, applied to real-time analysis, has occupied an important role in the oil well industry. We here propose a machine learning system to aid drill bit wear assessment for real-time operations, using a Probabilistic Neural Network (PNN) and Bayes Theorem, combined with Power Spectral Density (PSD) of surface torque image and feature extraction by Deep Convolutional Autoencoder (DCAE). A case study was performed with wells from Brazilian ultradeep water pre-salt fields. The analysis shows that a feature extraction DCAE is more efficient to discriminate the bit wear state when compared with PSD torque image and torque raw data. After that, several numerical experiments were performed to investigate the best machine learning classification model, considering DCAE feature extraction. The cross-validation results considering all the dataset shows the PNN evaluation metrics: 87% accuracy, 83% precision, 91% recall and 86% for F1-score. The field tests validation was performed in real-time simulation, with 3 wells from the original dataset plus 2 offset wells. The simulations show that the proposed system can capture the best moment for the tripping pipe to replace a worn-out drill bit. The field tests experimental results indicate that the system proposed can aid drilling engineers in monitoring Polycrystalline Diamond Compact (PDC) drill bit wear in real-time operations.",science
10.1016/j.cmi.2020.02.006,Journal,Clinical Microbiology and Infection,scopus,2020-10-01,sciencedirect,Machine learning in the clinical microbiology laboratory: has the time come for routine practice?,https://api.elsevier.com/content/abstract/scopus_id/85081582683,"Background
                  Machine learning (ML) allows the analysis of complex and large data sets and has the potential to improve health care. The clinical microbiology laboratory, at the interface of clinical practice and diagnostics, is of special interest for the development of ML systems.
               
                  Aims
                  This narrative review aims to explore the current use of ML In clinical microbiology.
               
                  Sources
                  References for this review were identified through searches of MEDLINE/PubMed, EMBASE, Google Scholar, biorXiv, arXiV, ACM Digital Library and IEEE Xplore Digital Library up to November 2019.
               
                  Content
                  We found 97 ML systems aiming to assist clinical microbiologists. Overall, 82 ML systems (85%) targeted bacterial infections, 11 (11%) parasitic infections, nine (9%) viral infections and three (3%) fungal infections. Forty ML systems (41%) focused on microorganism detection, identification and quantification, 36 (37%) evaluated antimicrobial susceptibility, and 21 (22%) targeted the diagnosis, disease classification and prediction of clinical outcomes. The ML systems used very diverse data sources: 21 (22%) used genomic data of microorganisms, 19 (20%) microbiota data obtained by metagenomic sequencing, 19 (20%) analysed microscopic images, 17 (18%) spectroscopy data, eight (8%) targeted gene sequencing, six (6%) volatile organic compounds, four (4%) photographs of bacterial colonies, four (4%) transcriptome data, three (3%) protein structure, and three (3%) clinical data. Most systems used data from high-income countries (n = 71, 73%) but a significant number used data from low- and middle-income countries (n = 36, 37%). Performance measures were reported for the 97 ML systems, but no article described their use in clinical practice or reported impact on processes or clinical outcomes.
               
                  Implications
                  In clinical microbiology, ML has been used with various data sources and diverse practical applications. The evaluation and implementation processes represent the main gap in existing ML systems, requiring a focus on their interpretability and potential integration into real-world settings.",science
10.1016/j.dt.2019.12.006,Journal,Defence Technology,scopus,2020-10-01,sciencedirect,A novel facial emotion recognition scheme based on graph mining,https://api.elsevier.com/content/abstract/scopus_id/85077698126,"Recent years have seen an explosion in graph data from a variety of scientific, social and technological fields. From these fields, emotion recognition is an interesting research area because it finds many applications in real life such as in effective social robotics to increase the interactivity of the robot with human, driver safety during driving, pain monitoring during surgery etc. A novel facial emotion recognition based on graph mining has been proposed in this paper to make a paradigm shift in the way of representing the face region, where the face region is represented as a graph of nodes and edges and the gSpan frequent sub-graphs mining algorithm is used to find the frequent sub-structures in the graph database of each emotion. To reduce the number of generated sub-graphs, overlap ratio metric is utilized for this purpose. After encoding the final selected sub-graphs, binary classification is then applied to classify the emotion of the queried input facial image using six levels of classification. Binary cat swarm intelligence is applied within each level of classification to select proper sub-graphs that give the highest accuracy in that level. Different experiments have been conducted using Surrey Audio-Visual Expressed Emotion (SAVEE) database and the final system accuracy was 90.00%. The results show significant accuracy improvements (about 2%) by the proposed system in comparison to current published works in SAVEE database.",science
10.1016/j.jaim.2018.02.140,Journal,Journal of Ayurveda and Integrative Medicine,scopus,2020-10-01,sciencedirect,Effect of seeds of Entada phaseoloides on chronic restrain stress in mice,https://api.elsevier.com/content/abstract/scopus_id/85059584549,"Background
                  
                     Entada phaseoloides is a well-known medicinal plant traditionally used in Ayurvedic medicine for centuries.
               
                  Objective
                  To evaluate the anti-stress activity of seeds of E. phaseoloides in endoplasmic reticulum stress during chronic restrain stress in mice, based on our preliminary screening.
               
                  Materials and Methods
                  Mice (n = 6/group) were restrained daily for 6 h in 50 ml polystyrene tubes for 28 days. Methanolic extract of E. phaseoloides (MEEP) (100 and 200 mg/kg, p.o.) and standard drug, imipramine (10 mg/kg i.p.) were administered daily 45 min prior to restrain from day 22–28. Then, forced swim test (FST) was performed to assess despair behavior. Lipid peroxidation (LPO) and antioxidant enzymes Reduced glutathione (GSH), Superoxide dismutase (SOD) were measured in the hippocampus of mice. 78 kDa Glucose-regulated Protein, 94 kDa Glucose-regulated Protein, C/EBP homologous protein, Caspase-12 expression were quantified by Real Time PCR.
               
                  Results
                  MEEP significantly reduced the immobility time in FST (P < 0.001). Significant reduction of LPO (P < 0.05) level and restored antioxidant enzymes viz. GSH (P < 0.001) and SOD towards vehicle control group were observed. Down-regulation of genes GRP 78, GRP 94 (P < 0.001), CHOP and Caspase-12 (P < 0.001) as compared to the chronic restrain stress group was evident, which were upregulated following treatment. Isolation of the active components of the seeds revealed the presence of Oleic acid (1), Entadamide A (2), Entadamide A-beta-d-glucopyranoside (3) and 1-O-protocatechuoyl-β-d-glucose.
               
                  Conclusion
                  MEEP altered endoplasmic reticulum stress in chronic restrain stressed mice; however, as an antidepressant it showed a weaker response.",science
10.1016/j.yexcr.2020.112139,Journal,Experimental Cell Research,scopus,2020-09-15,sciencedirect,A novel 3D printed bioactive scaffolds with enhanced osteogenic inspired by ancient Chinese medicine HYSA for bone repair,https://api.elsevier.com/content/abstract/scopus_id/85086671764,"Some traditional Chinese medicine (TCM) has been applied in bone repair, however, hydroxy-safflower yellow A (HYSA), one composition of safflower of the typical invigorating the circulation of TCM, has little been studied in orthopedics field for osteogenesis and angiogenesis clinically. Herein, we hypothetically speculated that the synthetic bioactive glasses (BG, 1393) scaffolds carried HYSA by a 3D print technique could enhance osteogenic repair properties. Notably, scaffolds coating chitosan/sodium alginate endowed with excellent drug control release ability, and significantly improved the BG mechanical strength. HYSA was loaded into BG scaffolds by coating chitosan/sodium alginate film, and the osteogenesis and angiogenesis of the HYSA/scaffolds were evaluated in vitro and in vivo. In vitro the cell culture results exhibited that the high dose of HYSA (0.5 mg/ml) loaded scaffolds can promote the proliferation of bone marrow stromal cells (rBMSCs) and migration, tubule formation of human umbilical vein endothelial cells (HUVECs). The active alkaline phosphatase (ALP) of rBMSCs can also be improved by the high dose of HYSA/scaffolds. Results of qRT-PCR and Western blot indicated that the high dose of HYSA/scaffolds can up-regulate ALP, OCN, OPN and RUNX-2 expression and relative protein secretion of the HIF-1α and BMP-2. In the animal experiment, the high dose of HYSA/scaffolds has a significantly better capacity to promote new bone formation than the undoped scaffolds at 8 weeks post-surgery. Thus, our results claimed that the novel HYSA/scaffolds hold the substantial potential to be further developed as effective and safe bone tissue engineering biomaterials for bone regeneration by combining enhanced osteogenesis and angiogenesis.",science
10.1016/j.patter.2020.100093,Journal,Patterns,scopus,2020-09-11,sciencedirect,Uncovering Effective Explanations for Interactive Genomic Data Analysis,https://api.elsevier.com/content/abstract/scopus_id/85102976970,"Better tools are needed to enable researchers to quickly identify and explore effective and interpretable feature-based explanations for discriminating multi-class genomic datasets, e.g., healthy versus diseased samples. We develop an interactive exploration tool, GENVISAGE, which rapidly discovers the most discriminative feature pairs that separate two classes of genomic objects and then displays the corresponding visualizations. Since quickly finding top feature pairs is computationally challenging, especially for large numbers of objects and features, we propose a suite of optimizations to make GENVISAGE responsive at scale and demonstrate that our optimizations lead to a 400× speedup over competitive baselines for multiple biological datasets. We apply our rapid and interpretable tool to identify literature-supported pairs of genes whose transcriptomic responses significantly discriminate several chemotherapy drug treatments. With its generalizable optimizations and framework, GENVISAGE opens up real-time feature-based explanation generation to data from massive sequencing efforts, as well as many other scientific domains.",science
10.1016/j.patter.2020.100083,Journal,Patterns,scopus,2020-09-11,sciencedirect,"The Veterans Affairs Precision Oncology Data Repository, a Clinical, Genomic, and Imaging Research Database",https://api.elsevier.com/content/abstract/scopus_id/85102968026,"The Veterans Affairs Precision Oncology Data Repository (VA-PODR) is a large, nationwide repository of de-identified data on patients diagnosed with cancer at the Department of Veterans Affairs (VA). Data include longitudinal clinical data from the VA's nationwide electronic health record system and the VA Central Cancer Registry, targeted tumor sequencing data, and medical imaging data including computed tomography (CT) scans and pathology slides. A subset of the repository is available at the Genomic Data Commons (GDC) and The Cancer Imaging Archive (TCIA), and the full repository is available through the Veterans Precision Oncology Data Commons (VPODC). By releasing this de-identified dataset, we aim to advance Veterans' health care through enabling translational research on the Veteran population by a wide variety of researchers.",science
10.1016/j.patter.2020.100057,Journal,Patterns,scopus,2020-09-11,sciencedirect,Explaining the Genetic Causality for Complex Phenotype via Deep Association Kernel Learning,https://api.elsevier.com/content/abstract/scopus_id/85102966019,"The genetic effect explains the causality from genetic mutations to the development of complex diseases. Existing genome-wide association study (GWAS) approaches are always built under a linear assumption, restricting their generalization in dissecting complicated causality such as the recessive genetic effect. Therefore, a sophisticated and general GWAS model that can work with different types of genetic effects is highly desired. Here, we introduce a deep association kernel learning (DAK) model to enable automatic causal genotype encoding for GWAS at pathway level. DAK can detect both common and rare variants with complicated genetic effects where existing approaches fail. When applied to four real-world GWAS datasets including cancers and schizophrenia, our DAK discovered potential casual pathways, including the association between dilated cardiomyopathy pathway and schizophrenia.",science
10.1016/j.aca.2020.06.075,Journal,Analytica Chimica Acta,scopus,2020-09-01,sciencedirect,Surface molecularly imprinted polymer based on core-shell Fe<inf>3</inf>O<inf>4</inf>@MIL-101(Cr) for selective extraction of phenytoin sodium in plasma,https://api.elsevier.com/content/abstract/scopus_id/85088375026,"Core-shell magnetic Fe3O4@MIL-101(Cr) nanoparticles were synthesized via layer-by-layer self-assembly method. Using Fe3O4@MIL-101(Cr) as support, Fe3O4@MIL-101(Cr)@MIP was prepared with phenytoin as template, acrylamide as functional monomer, ethylene glycol dimethacrylate as cross-linker, methanol and acetonitrile as porogen, azoisobutyronitrile as initiator. The materials were characterized by a serious of characterization experiments. The prepared Fe3O4@MIL-101(Cr)@MIP was demonstrated to possess good separability, large adsorption capability, excellent adsorption selectivity, good durability and reusability via adsorption experiments. Subsequently, a magnetic solid phase extraction method (MSPE) based on Fe3O4@MIL-101(Cr)@MIP combined with high performance liquid chromatography-ultraviolet detector (HPLC-UV) was established for the determination of phenytoin sodium in plasma samples. Experimental parameters including pH, the amount of adsorbent, extraction time, elution conditions, the concentration of NaCl were investigated to optimize extraction process. The method was validated. The linearity was observed in the range of 0.05–40 μg mL−1 with a lower limit of quantification of 0.05 μg mL−1. The calibration equations were y = 0.2514x + 0.0319 (r
                     
                        2
                      = 0.9938), y = 0.2888x + 0.0472 (r
                     
                        2
                      = 0.9943), y = 0.2565x + 0.0418 (r
                     
                        2
                      = 0.9976), respectively. The recoveries ranged from 89.2 to 94.3%, intra- and inter-day precision (RSDs) ranged from 2.1 to 9.7% and 2.9–9.2%, respectively. The established MSPE-HPLC-UV method was time-saving, sensitive, accurate, environmental friendly, and drastically reduced the complex matrix interferences. The established method was successfully applied for phenytoin sodium determination in real plasma samples, providing new directions for therapeutic drug monitoring.",science
10.1016/j.dss.2020.113346,Journal,Decision Support Systems,scopus,2020-09-01,sciencedirect,Geo-semantic-parsing: AI-powered geoparsing by traversing semantic knowledge graphs,https://api.elsevier.com/content/abstract/scopus_id/85087832137,"Online social networks convey rich information about geospatial facets of reality. However in most cases, geographic information is not explicit and structured, thus preventing its exploitation in real-time applications. We address this limitation by introducing a novel geoparsing and geotagging technique called Geo-Semantic-Parsing (GSP). GSP identifies location references in free text and extracts the corresponding geographic coordinates. To reach this goal, we employ a semantic annotator to identify relevant portions of the input text and to link them to the corresponding entity in a knowledge graph. Then, we devise and experiment with several efficient strategies for traversing the knowledge graph, thus expanding the available set of information for the geoparsing task. Finally, we exploit all available information for learning a regression model that selects the best entity with which to geotag the input text. We evaluate GSP on a well-known reference dataset including almost 10 k event-related tweets, achieving F1 = 0.66. We extensively compare our results with those of 2 baselines and 3 state-of-the-art geoparsing techniques, achieving the best performance. On the same dataset, competitors obtain F1 ≤ 0.55. We conclude by providing in-depth analyses of our results, showing that the overall superior performance of GSP is mainly due to a large improvement in recall, with respect to existing techniques.",science
10.1016/j.jchromb.2020.122258,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2020-09-01,sciencedirect,Gel electromembrane extraction using rotating electrode: A new strategy for mass transfer enhancement of basic drugs from real human urine samples,https://api.elsevier.com/content/abstract/scopus_id/85087741350,"This study proposed a new method of EME based on agarose gel named rotating electrode gel electromembrane extraction (RE-G-EME) for extraction and determination of naloxone, naltrexone, and nalbuphine as basic drugs from real human urine samples. In this new method, a rotating electrode connected to the armature was used to agitate the acceptor phase (AP). With this new development, the extraction efficiency enhanced due to increasing analytes mass transfer from gel membrane interface toward the AP. The effective parameters on the extraction efficiency were optimized and the maximum recoveries of the analytes were obtained under the optimal extraction conditions (3.0% (w/v) agarose with pH 5.0 as gel membrane; voltage: 25 V; pH of the donor phase (DP): 6.0; pH of the AP: 4.0; stirring rate of the DP: 750 rpm; electrode rotation speed within AP: 125 rpm; extraction time: 25 min). The method offered limits of detection (LODs) and extraction recoveries in the range of 0.3–1.5 ng mL−1, and 74.3% − 87.0%, respectively. Also, the repeatability of the proposed method was measured for four repeated experiments and was in the acceptable range of 4.3% − 8.1%. To understand the influence of agitation of the AP on the extraction efficiency, a comparative study was carried out between conventional G-EME and RE-G-EME methods. The results showed that, for short the extraction times (t ≤ 10 min), extraction efficiency of G-EME was almost the same as that of RE-G-EME. However, at longer extraction times (25 min), the extraction efficiency of RE-G-EME was significantly higher than that of G-EME. Finally, the proposed method was successfully applied to determine concentrations of model drugs in real urine samples with relative recoveries of 81.1–96.1% indicating good reliability of the proposed method.",science
10.1016/j.cose.2020.101888,Journal,Computers and Security,scopus,2020-09-01,sciencedirect,Forecasting the number of firefighter interventions per region with local-differential-privacy-based data,https://api.elsevier.com/content/abstract/scopus_id/85086466005,"Statistical studies on the number and types of firefighter interventions by region are essential to improve service to the population. It is also a preliminary step if we want to predict these interventions in order to optimize the placement of human and material resources of fire departments, for example. However, this type of data is sensitive and must be treated with the utmost care. In order to avoid any leakage of information, one can think of anonymizing them using Differential Privacy (DP), a safe method by construction. This work focuses on predicting the number of firefighter interventions in certain localities while respecting the strong concept of DP. A local Differential Privacy approach was first used to anonymize location data. Statistical estimators were then applied to reconstruct a synthetic data set that is uncorrelated from the users. Finally, a supervised learning approach using extreme gradient boosting was used to make the predictions. Experiments have shown that the anonymization-prediction method is very accurate: the introduction of noise to sanitize the data does not affect the quality of the predictions, and the predictions faithfully reflect what happened in reality.",science
10.1016/j.mineng.2020.106457,Journal,Minerals Engineering,scopus,2020-09-01,sciencedirect,Effects of process history on the surface morphology of uranium ore concentrates extracted from ore,https://api.elsevier.com/content/abstract/scopus_id/85085988966,"The effects of process history on the particle morphology of uranium ore concentrates (UOC) synthesized from natural uranium ores were investigated. A purified UOC was extracted from a uranium-rich ore by sulfuric acid leaching and purified by two commercial solvent extraction processes: the Dapex process using di-(2-ethylhexyl) phosphoric acid (DEHPA), and the Amex process using Alamine® 336. The UOC from either route was precipitated from its respective strip solution by ammonia and calcined. Powder X-ray diffraction (P-XRD) was used to confirm the crystallography of the UOC; while Rietveld refinement was performed for quantification of U oxide phase composition. Inductively coupled plasma - mass spectrometry (ICP-MS) was used to quantify impurity concentrations of the calcined material. As expected, different impurities were present due to processing via the Dapex and Amex process. To further correlate the impurities to the process history, particle morphology was quantified from scanning electron microscopy (SEM) micrographs using the MAMA segmentation software. In addition, a deep neural network was trained on the SEM images to distinguish between process histories. The results provide a real-world representation of how particle morphology will likely change based on processing at commercial facilities as opposed to high purity material experiments in a laboratory setting.",science
10.1016/j.ijmedinf.2020.104176,Journal,International Journal of Medical Informatics,scopus,2020-09-01,sciencedirect,The development an artificial intelligence algorithm for early sepsis diagnosis in the intensive care unit,https://api.elsevier.com/content/abstract/scopus_id/85085579350,"Background
                  Severe sepsis and septic shock are still the leading causes of death in Intensive Care Units (ICUs), and timely diagnosis is crucial for treatment outcomes. The progression of electronic medical records (EMR) offers the possibility of storing a large quantity of clinical data that can facilitate the development of artificial intelligence (AI) in medicine. However, several difficulties, such as poor structure and heterogenicity of the raw EMR data, are encountered when introducing AI with ICU data. Labor-intensive work, including manual data entry, personal medical records sorting, and laboratory results interpretation may hinder the progress of AI. In this article, we introduce the developing of an AI algorithm designed for sepsis diagnosis using pre-selected features; and compare the performance of the AI algorithm with SOFA score based diagnostic method.
               
                  Materials and methods
                  This is a prospective open-label cohort study. A specialized EMR, named TED_ICU, was implemented for continuous data recording. One hundred six clinical features relevant to sepsis diagnosis were selected prospectively. A labeling work to allocate SEPSIS or NON_SEPSIS status for each ICU patient was performed by the in-charge intensivist according to SEPSIS-3 criteria, along with the automatic recording of selected features every day by TED_ICU. Afterward, we use de-identified data to develop the AI algorithm. Several machine learning methods were evaluated using 5-fold cross-validation, and XGBoost, a decision-tree based algorithm was adopted for our AI algorithm development due to best performance.
               
                  Results
                  The study was conducted between August 2018 and December 2018 for the first stage of analysis. We collected 1588 instances, including 444 SEPSIS and 1144 NON-SEPSIS, from 434 patients. The 434 patients included 259 (59.6%) male patients and 175 female patients. The mean age was 67.6-year-old, and the mean APACHE II score was 13.8. The SEPSIS cohort had a higher SOFA score and increased use of organ support treatment. The AI algorithm was developed with a shuffle method using 80% of the instances for training and 20% for testing. The established AI algorithm achieved the following: accuracy = 82% ± 1%; sensitivity = 65% ± 5%; specificity = 88% ± 2%; precision = 67% ± 3%; and F1 = 0.66 ± 0.02. The area under the receiver operating characteristic curve (AUROC) was approximately 0.89. The SOFA score was used on the same 1588 instances for sepsis diagnosis, and the result was inferior to our AI algorithm (AUROC = 0.596).
               
                  Conclusion
                  Using real-time data, collected by EMR, from the ICU daily practice, our AI algorithm established with pre-selected features and XGBoost can provide a timely diagnosis of sepsis with an accuracy greater than 80%. AI algorithm also outperforms the SOFA score in sepsis diagnosis and exhibits practicality as clinicians can deploy appropriate treatment earlier. The early and precise response of this AI algorithm will result in cost reduction, outcome improvement, and benefit for healthcare systems, medical staff, and patients as well.",science
10.1016/j.compind.2020.103226,Journal,Computers in Industry,scopus,2020-09-01,sciencedirect,Perspective on holonic manufacturing systems: PROSA becomes ARTI,https://api.elsevier.com/content/abstract/scopus_id/85085261123,"Looking back at 30 years of research into holonic manufacturing systems, these explorations made a lasting scientific contribution to the overall architecture of intelligent manufacturing systems. Most notably, holonic architectures are defined in terms of their world-of-interest (Van Brussel et al., 1998). They do not have an information layer, a communication layer, etc. Instead, they have components that relate to real-world assets (e.g. machine tools) and activities (e.g. assembly). And, they mirror and track the structure of their world-of-interest, which allows them to scale and adapt accordingly.
                  This research has wandered around, at times learning from its mistakes, and progressively carved out an invariant structure while it translated and applied scientific insights from complex-adaptive systems theory (e.g. autocatalytic sets) and from bounded rationality (e.g. holons). This paper presents and discusses the outcome of these research efforts.
                  At the top level, the holonic structure distinguishes intelligent beings (or digital twins) from intelligent agents. These digital twins inherit the consistency from reality, which they mirror. They are intelligent beings when they reflect what exists in the world without imposing artificial limitations in this reality. Consequently, a conflict with a digital twin is a conflict with reality.
                  In contrast, intelligent agents typically transform NP-hard challenges into computations with low-polynomial complexity. Unavoidably, this involves arbitrariness (e.g. don’t care choices). Likewise, relying on case-specific properties, to ensure an outcome in polynomial time, usually renders the validity of an agent’s choices both short-lived and situation-dependent. Here, intelligent agents create conflicts by imposing limitations of their own making in their world-of-interest.
                  Real-world smart systems are aggregates comprising both intelligent beings and intelligent agents. They are performers. Inside these performers, digital twins may constitute the foundations, supporting walls, support beams and pillars because these intelligent beings are protected by their real-world counterpart. Further refining the top-level of this architecture, a holonic structure enables these digital twins to shadow their real-world counterpart whenever it changes, adapts and evolves.
                  In contrast, the artificial limitations, imposed by the intelligent agents, cannot be allowed to build up inertia, which would hamper the undoing of arbitrary or case-specific limitations. To this end, performers explicitly manage the rights over their assets. Revoking such rights from a limitation-imposing agent will free the assets. This will be at the cost of reduced services from the agent. When other service providers rely on this agent, their services may be affected as well; that’s how the inertia builds up and how harmful legacy is created. Thus, the services of digital twins are to be preferred over the services of an intelligent agent by developers of holonic manufacturing systems.
                  Finally, digital twins corresponding to the decision making in the world-of-interest (a non-physical asset) allow to mirror the world-of-interest in a predictive mode (in addition to track and trace). It allows to generate short-term forecasts while preserving the benefits of intelligent beings. These twins are the intentions of the decision-making intelligent agents. Evidently, when intentions change, the forecasts needs to be regenerated (i.e. tracking the corresponding reality by the twin). This advanced feature can be deployed in a number of configurations (cf. annex).",science
10.1016/j.microc.2020.104867,Journal,Microchemical Journal,scopus,2020-09-01,sciencedirect,Multi-walled carbon nanotubes modified with iron oxide and manganese dioxide (MWCNTs-Fe<inf>3</inf>O<inf>4</inf>−MnO<inf>2</inf>) as a novel adsorbent for the determination of BPA,https://api.elsevier.com/content/abstract/scopus_id/85084458116,"Multi-walled carbon nanotubes modified with iron oxide and manganese dioxide (MWCNTs-Fe3O4−MnO2) was synthesized by using iron oxide (magnetic agent) and manganese dioxide (surface enhancer agent) to further approach in a magnetic solid-phase extraction (MSPE) coupled with high performance liquid chromatography (HPLC) method for the determination of bisphenol A (BPA) in plastic bottled drink samples. Scanning electron microscopy (SEM), transmission electron microscopy (TEM), energy dispersive X-ray (EDX), Fourier-transform infrared spectroscopy (FTIR), vibrating sample magnetometer (VSM), and BET surface area measurement (BET) were used to characterized the materials. MWCNTs-Fe3O4MnO2 are more effective for BPA adsorption than other materials which compared in this study. The binding performances of sorbent were evaluated by static and kinetic adsorption experiments. The data were well fitted to the Langmuir isotherm model and pseudo-second-order model, which the maximum adsorption capacity (qmax
                     ) and the contact time of initial concentrations to achieve equilibrium were found to be 132.9 mg g−1 and 150 min, respectively. After adsorption, MWCNTs-Fe3O4−MnO2 can be conveniently and quickly separated from the media by an external magnetic field, and adsorption-desorption capacity can remain at least 6 times of usage. Several parameters affecting the extraction efficiency were investigated. Under optimal conditions, the sorbent was successfully applied to MSPE followed by HPLC determination of BPA in real sample. The limit of detection (LOD) and limit of quantification (LOQ) values of MSPE-HPLC was 0.092 ng mL−1 and 0.167 ng mL−1, respectively. Spiked recoveries ranged from 94.9 to 103.4% for four real samples, with relative standard deviations of less than 6.7%. It was concluded that the synthesized MWCNTs-Fe3O4−MnO2 could be used as an efficient adsorbent for the determination of BPA in different plastic bottled drink samples.",science
10.1016/j.ssci.2020.104760,Journal,Safety Science,scopus,2020-09-01,sciencedirect,"Empirical methods in pedestrian, crowd and evacuation dynamics: Part II. Field methods and controversial topics",https://api.elsevier.com/content/abstract/scopus_id/85084055659,"Following the review of the experimental methods and top emerging topics, here, studies using the field data collection methods of pedestrian dynamics (April 2017-July 2019) are reviewed. This includes studies based on post-disaster analysis of real emergencies and past crowd incidents, field pedestrian observations in natural settings, and qualitative interviews with survivors of fire and other emergency incidents. The method of collecting field observations in natural settings is identified to be gaining increasing traction among other field methods (compared to the years preceding 2017) which in part reflects the recent growing attention to the calibration and validation of simulation models. Also, by assembling and analysing the entire body of empirical crowd literature from 1995 to 2019, this review identifies a list of controversial topics and puts a spotlight on recent experiments that have revisited and, in cases, challenged/modified certain long-held assumptions in crowd dynamics. Nine major controversial topics of crowd dynamics are identified for which mixed or contradictory empirical evidence exist. This includes questions related to the flow of pedestrians through bottlenecks (i.e. the faster-is-slower effect, partial obstruction effect, exit location effect, the nature of exit width-capacity relationship), as well as the decision-making aspects of pedestrian evacuations (i.e. the symmetry breaking phenomenon, and the effect of urgency level on various aspects of decision-making) and other topics such as the effect of social groups on evacuation efficiency or the effect of additional exits on blind evacuation efficiency. It is hoped that the discussions on these topics pave the way for further investigating and explaining these inconsistencies and settling the questions surrounding them.",science
10.1016/j.future.2020.04.018,Journal,Future Generation Computer Systems,scopus,2020-09-01,sciencedirect,Software-Defined Network for End-to-end Networked Science at the Exascale,https://api.elsevier.com/content/abstract/scopus_id/85083299223,"Domain science applications and workflow processes are currently forced to view the network as an opaque infrastructure into which they inject data and hope that it emerges at the destination with an acceptable Quality of Experience. There is little ability for applications to interact with the network to exchange information, negotiate performance parameters, discover expected performance metrics, or receive status/troubleshooting information in real time. The work presented here is motivated by a vision for a new smart network and smart application ecosystem that will provide a more deterministic and interactive environment for domain science workflows. The Software-Defined Network for End-to-end Networked Science at Exascale (SENSE) system includes a model-based architecture, implementation, and deployment which enables automated end-to-end network service instantiation across administrative domains. An intent based interface allows applications to express their high-level service requirements, an intelligent orchestrator and resource control systems allow for custom tailoring of scalability and real-time responsiveness based on individual application and infrastructure operator requirements. This allows the science applications to manage the network as a first-class schedulable resource as is the current practice for instruments, compute, and storage systems. Deployment and experiments on production networks and testbeds have validated SENSE functions and performance. Emulation based testing verified the scalability needed to support research and education infrastructures. Key contributions of this work include an architecture definition, reference implementation, and deployment. This provides the basis for further innovation of smart network services to accelerate scientific discovery in the era of big data, cloud computing, machine learning and artificial intelligence.",science
10.1016/j.mattod.2020.03.004,Journal,Materials Today,scopus,2020-09-01,sciencedirect,Genetic algorithm-guided deep learning of grain boundary diagrams: Addressing the challenge of five degrees of freedom,https://api.elsevier.com/content/abstract/scopus_id/85082868440,"Grain boundaries (GBs) often control the processing and properties of polycrystalline materials. Here, potentially transformative research is represented by constructing GB property diagrams as functions of temperature and bulk composition, also called “complexion diagrams,” as a general materials science tool on par with phase diagrams. However, a GB has five macroscopic (crystallographic) degrees of freedom (DOFs). It is essentially a “mission impossible” to construct property diagrams for GBs as a function of five DOFs by either experiments or modeling. Herein, we combine isobaric semi-grand canonical ensemble hybrid Monte Carlo and molecular dynamics (hybrid MC/MD) simulations with a genetic algorithm (GA) and deep neural network (DNN) models to tackle this grand challenge. The DNN prediction is ∼108 faster than atomistic simulations, thereby enabling the construction of the property diagrams for millions of distinctly different GBs of five DOFs. Notably, excellent prediction accuracies have been achieved for not only symmetric-tilt and twist GBs, but also asymmetric-tilt and mixed tilt-twist GBs; the latter are more complex and much less understood, but they are ubiquitous and often limit the performance properties of real polycrystals as the weak links. The data-driven prediction of GB properties as function of temperature, bulk composition, and five crystallographic DOFs (i.e., in a 7D space) opens a new paradigm.",science
10.1016/j.cpc.2020.107275,Journal,Computer Physics Communications,scopus,2020-09-01,sciencedirect,freud: A software suite for high throughput analysis of particle simulation data,https://api.elsevier.com/content/abstract/scopus_id/85082555873,"The freud Python package is a library for analyzing simulation data. Written with modern simulation and data analysis workflows in mind, freud provides a Python interface to fast, parallelized C++ routines that run efficiently on laptops, workstations, and supercomputing clusters. The package provides the core tools for finding particle neighbors in periodic systems, and offers a uniform API to a wide variety of methods implemented using these tools. As such, freud users can access standard methods such as the radial distribution function as well as newer, more specialized methods such as the potential of mean force and torque and local crystal environment analysis with equal ease. Rather than providing its own trajectory data structure, freud operates either directly on NumPy arrays or on trajectory data structures provided by other Python packages. This design allows freud to transparently interface with many trajectory file formats by leveraging the file parsing abilities of other trajectory management tools. By remaining agnostic to its data source, freud is suitable for analyzing any particle simulation, regardless of the original data representation or simulation method. When used for on-the-fly analysis in conjunction with scriptable simulation software such as HOOMD-blue, freud enables smart simulations that adapt to the current state of the system, allowing users to study phenomena such as nucleation and growth.
               
                  Program summary
                  
                     Program Title: 
                     freud
                  
                  
                     Program Files doi: 
                     http://dx.doi.org/10.17632/v7wmv9xcct.1
                  
                  
                     Licensing provisions: BSD 3-Clause
                  
                     Programming language: Python, C++
                  
                     Nature of problem: Simulations of coarse-grained, nano-scale, and colloidal particle systems typically require analyses specialized to a particular system. Certain more standardized techniques – including correlation functions, order parameters, and clustering – are computationally intensive tasks that must be carefully implemented to scale to the larger systems common in modern simulations.
                  
                     Solution method: 
                     freud performs a wide variety of particle system analyses, offering a Python API that interfaces with many other tools in computational molecular sciences via NumPy array inputs and outputs. The algorithms in freud leverage parallelized C++ to scale to large systems and enable real-time analysis. The library’s broad set of features encode few assumptions compared to other analysis packages, enabling analysis of a broader class of data ranging from biomolecular simulations to colloidal experiments.
                  
                     Additional comments including restrictions and unusual features:
                  
                  1. freud provides very fast parallel implementations of standard analysis methods like RDFs and correlation functions.
                  2. freud includes the reference implementation for the potential of mean force and torque (PMFT).
                  3. freud provides various novel methods for characterizing particle environments, including the calculation of descriptors useful for machine learning. The source code is hosted on GitHub (https://github.com/glotzerlab/freud), and documentation is available online (https://freud.readthedocs.io/). The package may be installed via pip install freud-analysis or conda install -c conda-forge freud.",science
10.1016/j.fss.2019.09.017,Journal,Fuzzy Sets and Systems,scopus,2020-09-01,sciencedirect,Centered kernel alignment inspired fuzzy support vector machine,https://api.elsevier.com/content/abstract/scopus_id/85072797442,"Support vector machine (SVM) is a theoretically well motivated algorithm developed from statistical learning theory which has shown impressive performance in many fields. In spite of its success, it still suffers from the noise sensitivity problem originating from the assumption that each training point has equal importance or weight in the training process. To relax this problem, the SVM was extended to the fuzzy SVM (FSVM) by applying a fuzzy membership to each training point such that different training points can make different contributions to the learning of the decision surface. Although well-determined fuzzy memberships can improve classification performance, there are no general guidelines for their construction. In this paper, inspired by the centered kernel alignment (CKA), which measures the degree of similarity between two kernels (or kernel matrices), we propose a new fuzzy membership function calculation method in which a heuristic function derived from the CKA is used to calculate the dependence between a data point and its associated label. Although the CKA induced FSVM is similar to the kernel target alignment (KTA) induced FSVM, there is actually a critical difference. Without that centering, the definition of alignment does not correlate well with the performance of learning machines. Extensive experiments are performed on real-world data sets from the UCI benchmark repository and the application domain of computational biology which validate the superiority of the proposed FSVM model in terms of several classification performance measures.",science
10.1016/j.scitotenv.2020.139158,Journal,Science of the Total Environment,scopus,2020-08-20,sciencedirect,Development of a decision support system for the selection of wastewater treatment technologies,https://api.elsevier.com/content/abstract/scopus_id/85084373810,"Multiple factors including technical, social, economic, regulatory, governmental, and environmental add complexity in the process of selecting a suitable wastewater treatment technology. To overcome this issue, this paper aims to propose a decision support system (DSS) for the selection of wastewater treatment technologies. The proposed system has been developed using a detailed review of the state-of-the-art in wastewater treatment, implemented using Microsoft Visual Studio 2010 and validated through real-time case studies. The system is categorized into four treatment levels based on wastewater complexity and the required degree of treatment. These include preliminary, primary, secondary, and tertiary treatment. Based on the identified treatment levels, the proposed system suggests using any physical, biological, chemical, or hybrid treatment process. The developed DSS will aid the selection of suitable wastewater treatment technology from a set of alternatives while keeping user constraints, conflicting requirements, and prevailing conditions under consideration. Moreover, the system is capable to customize the treatment assembly at the planning stage with minimized costs, eliminate mistakes at the planning and design stage, facilitate decision making by narrowing down the alternative solution as per user requirements and prevailing conditions, incorporate customer demand, and promote sustainable development.",science
10.1016/j.patter.2020.100073,Journal,Patterns,scopus,2020-08-14,sciencedirect,dtoolAI: Reproducibility for Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85102966352,"Deep learning, a set of approaches using artificial neural networks, has generated rapid recent advancements in machine learning. Deep learning does, however, have the potential to reduce the reproducibility of scientific results. Model outputs are critically dependent on the data and processing approach used to initially generate the model, but this provenance information is usually lost during model training. To avoid a future reproducibility crisis, we need to improve our deep-learning model management. The FAIR principles for data stewardship and software/workflow implementation give excellent high-level guidance on ensuring effective reuse of data and software. We suggest some specific guidelines for the generation and use of deep-learning models in science and explain how these relate to the FAIR principles. We then present dtoolAI, a Python package that we have developed to implement these guidelines. The package implements automatic capture of provenance information during model training and simplifies model distribution.",science
10.1016/j.patter.2020.100074,Journal,Patterns,scopus,2020-08-14,sciencedirect,Machine-Learning Approaches in COVID-19 Survival Analysis and Discharge-Time Likelihood Prediction Using Clinical Data,https://api.elsevier.com/content/abstract/scopus_id/85092796371,"As a highly contagious respiratory disease, COVID-19 has yielded high mortality rates since its emergence in December 2019. As the number of COVID-19 cases soars in epicenters, health officials are warning about the possibility of the designated treatment centers being overwhelmed by coronavirus patients. In this study, several computational techniques are implemented to analyze the survival characteristics of 1,182 patients. The computational results agree with the outcome reported in early clinical reports released for a group of patients from China that confirmed a higher mortality rate in men compared with women and in older age groups. The discharge-time prediction of COVID-19 patients was also evaluated using different machine-learning and statistical analysis methods. The results indicate that the Gradient Boosting survival model outperforms other models for patient survival prediction in this study. This research study is aimed to help health officials make more educated decisions during the outbreak.",science
10.1016/j.jclepro.2020.121426,Journal,Journal of Cleaner Production,scopus,2020-08-10,sciencedirect,A sentiment reporting framework for major city events: Case study on the China-United States trade war,https://api.elsevier.com/content/abstract/scopus_id/85084032594,"Smart cities are conceptualized as a vehicle for sustainable urban development and a means to deliver high quality of life for residents. One of the core functions of a smart city consists in the continuous monitoring of events, assets and people and the use of this information and intelligence for the streamlining of the city’s operations. Public opinion represents one type of intelligence of particular importance and value. By monitoring public opinion, governments seek to understand prevalent views about the current events and policies, as well as identify extreme views and trends that may represent problematic situations or precursors to violent actions. Ultimately, maintaining a constant awareness of public opinion means that authorities can better assess and predict public reactions in relation to ongoing events, and thus take appropriate actions to maintain public safety. Due to the popular use of social media to express sentiments and emotions about current events, social media content analysis has been contemplated as a promising solution to capture public opinion. However, existing approaches take a coarse-grained retrospective approach to social media content analysis. Furthermore, those approaches suffer from the lack of scalability and efficiency, as they necessitate the collection and analysis of large volumes of social media content (often millions of posts), to come up with relevant conclusions. In this work, we address those limitations by proposing a novel framework for the real-time monitoring of public opinion. To ensure efficiency and scalability, our framework focuses on the analysis of high impact social media content generated by opinion leaders and their followers as means to offer in-depth insights and sentiment intelligence reports about events, as they are occurring in real time. The proposed framework was implemented and tested on data harvested from 52 economic opinion leaders, with a focus on the China-US trade war as case study. The results show that the convolutional neural network (CNN) classifier used for sentiment analysis yielded a classification accuracy of 86% when differentiating between four sentiment categories: Support, strong support, dissent, and strong dissent. The Support Vector Machine (SVM) classifier employed to perform in-depth emotional analysis attained an accuracy of 82% when differentiating between five emotions: Angry, depressed, excited, happy, and worried. Unlike existing retrospective social media analysis approaches that require the analysis of millions of posts, our approach focuses on the analysis of high-impact social media content in real-time, thus constituting an efficient, sustainable, and timely solution to public opinion monitoring.",science
10.1016/j.neucom.2020.03.023,Journal,Neurocomputing,scopus,2020-08-04,sciencedirect,Attention-based face alignment: A solution to speed/accuracy trade-off,https://api.elsevier.com/content/abstract/scopus_id/85081982806,"Accuracy and speed are two important aspects of face alignment. One of the main concerns is the trade-off between speed and accuracy. To this end, we propose a novel attention-based deep learning framework consisting of a feature extraction module and an attention module. The feature extraction module is based on a two-branch architecture with a trunk branch and a mask branch. The trunk branch extracts shallow features, while mask branch is intermediately supervised to generate coarse masks with rough geometric information. An attention module is designed to select relevant features from trunk features under the guidance of geometric information from the coarse masks. The above attention module helps increase robustness of our framework to unconstrained faces while reducing complexity of our deep network. Extensive experiments are conducted on two public benchmark datasets, 300-W and AFLW. Ablation studies indicate its superior performance on challenging faces. Comparing with the state of the art, our method provides a competent trade-off between speed and accuracy. Our approach achieves 3.35% mean error with 0.29% failure rate on 300-W fullset, and 1.44% mean error with 0.40% failure rate on AFLW-Full datasets. Meanwhile, our method is capable of processing images at real-time speed (13ms) on 300-W with 68 landmarks.",science
10.1016/j.vrih.2020.07.005,Journal,Virtual Reality and Intelligent Hardware,scopus,2020-08-01,sciencedirect,Multimodal interaction design and application in augmented reality for chemical experiment,https://api.elsevier.com/content/abstract/scopus_id/85099018529,"Background
                  Augmented reality classrooms have become an interesting research topic in the field of education, but there are some limitations. Firstly, most researchers use cards to operate experiments, and a large number of cards cause difficulty and inconvenience for users. Secondly, most users conduct experiments only in the visual modal, and such single-modal interaction greatly reduces the users' real sense of interaction. In order to solve these problems, we propose the Multimodal Interaction Algorithm based on Augmented Reality (ARGEV), which is based on visual and tactile feedback in Augmented Reality. In addition, we design a Virtual and Real Fusion Interactive Tool Suite (VRFITS) with gesture recognition and intelligent equipment.
               
                  Methods
                  The ARGVE method fuses gesture, intelligent equipment, and virtual models. We use a gesture recognition model trained by a convolutional neural network to recognize the gestures in AR, and to trigger a vibration feedback after a recognizing a fivefinger grasp gesture. We establish a coordinate mapping relationship between real hands and the virtual model to achieve the fusion of gestures and the virtual model.
               
                  Results
                  The average accuracy rate of gesture recognition was 99.04%. We verify and apply VRFITS in the Augmented Reality Chemistry Lab (ARCL), and the overall operation load of ARCL is thus reduced by 29.42%, in comparison to traditional simulation virtual experiments.
               
                  Conclusions
                  We achieve real-time fusion of the gesture, virtual model, and intelligent equipment in ARCL. Compared with the NOBOOK virtual simulation experiment, ARCL improves the users' real sense of operation and interaction efficiency.",science
10.1016/S2352-3018(20)30190-9,Journal,The Lancet HIV,scopus,2020-08-01,sciencedirect,Modern diagnostic technologies for HIV,https://api.elsevier.com/content/abstract/scopus_id/85088944280,"Novel diagnostic technologies, including nanotechnology, microfluidics, -omics science, next-generation sequencing, genomics big data, and machine learning, could contribute to meeting the UNAIDS 95-95-95 targets to end the HIV epidemic by 2030. Novel technologies include multiplexed technologies (including biomarker-based point-of-care tests and molecular platform technologies), biomarker-based combination antibody and antigen technologies, dried-blood-spot testing, and self-testing. Although biomarker-based rapid tests, in particular antibody-based tests, have dominated HIV diagnostics since the development of the first HIV test in the mid-1980s, targets such as nucleic acids and genes are now used in nanomedicine, biosensors, microfluidics, and -omics to enable early diagnosis of HIV. These novel technologies show promise as they are associated with ease of use, high diagnostic accuracy, rapid detection, and the ability to detect HIV-specific markers. Additional clinical and implementation research is needed to generate evidence for use of novel technologies and a public health approach will be required to address clinical and operational challenges to optimise their global deployment.",science
10.1016/j.compbiomed.2020.103886,Journal,Computers in Biology and Medicine,scopus,2020-08-01,sciencedirect,Skull shape reconstruction using cascaded convolutional networks,https://api.elsevier.com/content/abstract/scopus_id/85086987267,"Designing a cranial implant to restore the protective and aesthetic function of the patient’s skull is a challenging process that requires a substantial amount of manual work, even for an experienced clinician. While computer-assisted approaches with various levels of required user interaction exist to aid this process, they are usually only validated on either a single type of simple synthetic defect or a very limited sample of real defects. The work presented in this paper aims to address two challenges: (i) design a fully automatic 3D shape reconstruction method that can address diverse shapes of real skull defects in various stages of healing and (ii) to provide an open dataset for optimization and validation of anatomical reconstruction methods on a set of synthetically broken skull shapes.
                  We propose an application of the multi-scale cascade architecture of convolutional neural networks to the reconstruction task. Such an architecture is able to tackle the issue of trade-off between the output resolution and the receptive field of the model imposed by GPU memory limitations. Furthermore, we experiment with both generative and discriminative models and study their behavior during the task of anatomical reconstruction.
                  The proposed method achieves an average surface error of 
                        
                           0
                           .
                           59
                           
                           mm
                        
                      for our synthetic test dataset with as low as 
                        
                           0
                           .
                           48
                           
                           mm
                        
                      for unilateral defects of parietal and temporal bone, matching state-of-the-art performance while being completely automatic. We also show that the model trained on our synthetic dataset is able to reconstruct real patient defects.",science
10.1016/j.compag.2020.105526,Journal,Computers and Electronics in Agriculture,scopus,2020-08-01,sciencedirect,Application of random forest classification to predict daily oviposition events in broiler breeders fed by precision feeding system,https://api.elsevier.com/content/abstract/scopus_id/85085736722,"In group-housed poultry, hormone and environment modulated variability in the processes of follicle maturation and egg formation make it difficult to predict a daily egg-laying event (oviposition). Recording daily egg laying events has required individual cages or expensive technology such as RFID equipped nests or labor intensive trap nests. The current study implemented the random forest classification algorithm to predict oviposition events of 202 free run Ross 708 broiler breeder hens fed by a precision feeding system from week 21 to 55, based on a dataset recording information of all visits to the station. The raw dataset from the precision feeding system was processed for 6 classes of features (34 features in total) in relation to feeding activity and real-time body weight of birds. The dataset of the features was then combined with a corresponding daily individual oviposition record. The processed data were shuffled and separated into 2 subsets: 90% for training, and 10% for testing. Important features were selected using random forest-recursive feature elimination with 5-fold cross-validation, and 28 features were selected to build a random forest classification model. Overall accuracy of the model using the testing samples was 0.8482, and out-of-bag score was 0.8510. Precision (a measure of purity in retrieving) of no egg-laying and egg-laying, recall (a measure of completeness in retrieving) of no egg-laying and egg-laying were 0.8814, 0.8090, 0.8520 and 0.8453, respectively. The Kappa coefficient of the model was 0.6931, indicating substantial agreement (substantial agreement range: 0.61–0.80). This model was able to identify whether a free run broiler breeder laid an egg or not on a certain day during the laying period with around 85% accuracy.",science
10.1016/j.ins.2020.04.023,Journal,Information Sciences,scopus,2020-08-01,sciencedirect,Recurrent neural variational model for follower-based influence maximization,https://api.elsevier.com/content/abstract/scopus_id/85083696721,"Influence Maximization, aiming at selecting a small set of seed users in a social network to maximize the spread of influence, has attracted considerable attention recently. Most of the existing influence maximization algorithms focus on the diffusion model of one single-entity, which assumes that only one entity is propagated by users in social network. However, the diffusion situations in real world social networks often involve multiple entities, competitive or complementary, spreading through the whole network, and are more complex than the situations of single independent entity.
                  In this paper, we propose a novel optimization problem, namely, the follower-based influence maximization, which aims to promote a new product into the market by maximizing the influence of a social network where other competitive and complementary products have already been propagating. We tackle this problem by proposing a Recurrent Neural Variational model (RNV) and a follower-based greedy algorithm (RNVGA). The RNV model dynamically tracks entity correlations and cascade correlations through a deep generative model and recurrent neural variational inference, while the RNVGA algorithm applies the greedy approach for submodular maximization and efficiently computes the seed node set for the target product. Extensive experiments have been conducted to evaluate effectiveness and efficiency of our method, and the results show the superiority of our method compared with the state-of-the-art methods.",science
10.1016/j.ins.2020.03.030,Journal,Information Sciences,scopus,2020-08-01,sciencedirect,Efficient approach of recent high utility stream pattern mining with indexed list structure and pruning strategy considering arrival times of transactions,https://api.elsevier.com/content/abstract/scopus_id/85083463056,"One of various pattern mining techniques, the High Utility Pattern Mining (HUPM) is a method for finding meaningful patterns from non-binary databases by considering the characteristics of the items. Recently, new data continues to flow over time in diverse fields such as sales data of market, heartbeat sensor data, and social network service. Since these data have a feature that recently generated data have higher influence than the old data, research has been focused on how to efficiently extract hidden knowledge from time-sensitive databases. In this paper, we propose indexed list-based algorithm that mines recent high utility pattern considering the arrival time of inserted data in an environment where new data is continuously accumulated. In other words, to treat the importance of recent data higher than the that of old data, our algorithms reduces the utility values of old transactions according to the time the data is inserted by applying damped window model concept. Moreover, we carry out various experiments to compare our method with state-of-the-art algorithms using real and synthetic datasets in diverse circumstances. Experimental results show that our algorithm outperforms competitors in terms of execution time, memory usage, and scalability test.",science
10.1016/j.chemosphere.2020.126653,Journal,Chemosphere,scopus,2020-08-01,sciencedirect,Effects of novel brominated flame retardants and metabolites on cytotoxicity in human umbilical vein endothelial cells,https://api.elsevier.com/content/abstract/scopus_id/85083060199,"Novel brominated flame retardants (NBFRs) have been widely used and frequently detected in various environmental matrices. In this study, 2-ethylhexyl-2,3,4,5-tetrabromobenzoate (TBB), bis-(2-ethylhexyl) tetrabromophthalate (TBPH) and their metabolites (namely 2,3,4,5-tetra-bromo benzoic acid (TBBA) and mono(2-ethylhexyl) tetrabromophthalate (TBMEHP)) were exposed to human umbilical vein endothelial cells (HUVECs). Metabolites can induce stronger cytotoxicity than parent compounds with EC50 at 47.3 (TBBA), 8.6 μg/ml (TBMEHP) vs > 200 μg/mL for parent compounds. Gene expression of platelet endothelial cell adhesion molecule-1, the gene associated with blood platelet kinetics, was significantly induced under TBBA and TBMEHP exposure. The in vivo test was consistent with gene expression result that the number of platelets in mouse blood was significantly increased after gavaged with 0.8 μg/mL TBBA and TBMEHP. In addition, TBB or TBPH were exposed to mice via gavage, and higher concentrations of TBBA (4 h, 60.8 ± 12.9 ng/mL, 8 h, 69.4 ± 2.24 ng/mL) in mouse blood were found than those of TBMEHP (4 h, 17.2 ± 4.01 ng/mL, 8 h, 12.8 ± 3.20 ng/mL), indicating that TBB was more readily in vivo metabolized than TBPH. The in vivo metabolism of TBB and TBPH and the stronger toxicity of their metabolites underscore the potential risk through NBFR exposure and the importance of understanding NBFR metabolism process.",science
10.1016/j.isatra.2020.03.031,Journal,ISA Transactions,scopus,2020-08-01,sciencedirect,Virtual metrology of semiconductor PVD process based on combination of tree-based ensemble model,https://api.elsevier.com/content/abstract/scopus_id/85082842250,"In order to improve the accuracy of semiconductor wafer virtual metrology, and overcome the physical metrology delay of wafer acceptance test, a virtual physical vapor deposition metrology method based on combination of tree-based ensemble models is proposed to conduct online virtual metrology on semiconductor wafer electrical parameters, and use hyperparameter optimization technique to perform model optimization and to achieve real-time alarm on process deviation. This combination of tree-based ensemble model combines Bagging, Boosting, and Stacking techniques. First, based on 4 types of base learner, Random Forest, Extra-Trees, XGBoost, and lightGBM, preliminary virtual metrology is performed on wafer PVD process, and then transforms the predict results of the 4 base learners into meta feature vector as the input of meta learner lightGBM to perform further virtual metrology. The Sequential model-based optimization algorithm is used to improve the accuracy of virtual metrology. First, the initial hyperparameter of the sequential model-based optimization is initialized by using random sampling, then the combination model is approximated by the surrogate model of tree-structured Parzen estimator, and the recommended hyperparameters is obtained by using EI (Expected Improvement), and then the optimized combination model is obtained. Finally, the superiority of the method proposed in this paper is verified by studying the results comparing to the common virtual metrology methods on the PVD process. The experiment shows the result of resistivity metrology using the combination of tree-based ensemble models in the PVD process is significantly better than LASSO regression, partial least squares regression(PLSR), support vector machine(SVR), Gaussian process regression(GPR) and artificial neural network regression(ANN).",science
10.1016/j.neuroimage.2019.116492,Journal,NeuroImage,scopus,2020-08-01,sciencedirect,Social network proximity predicts similar trajectories of psychological states: Evidence from multi-voxel spatiotemporal dynamics,https://api.elsevier.com/content/abstract/scopus_id/85077556666,"Homophily is a prevalent characteristic of human social networks: individuals tend to associate and bond with others who are similar to themselves with respect to physical traits and demographic attributes, such as age, gender, and ethnicity. Recent research using functional magnetic resonance imaging has demonstrated a positive relationship between individuals’ real-world social network proximity (i.e., whether they are friends, friends-of-friends, or farther removed in social ties) and inter-subject correlation (ISC) in their time series of neural responses when viewing audiovisual movies. However, conventional ISC methods only capture information about similarity in the temporal evolution of region-averaged neural responses, and ignore information carried in fine-grained, spatially distributed response topographies. Here, we demonstrate that temporal trajectories of multi-voxel response patterns to naturalistic stimuli are exceptionally similar among friends and predictive of social network proximity, over and above the effects of response magnitude fluctuations. Furthermore, inter-subject similarity in the temporal trajectory of multi-voxel response patterns across distant points in time was particularly positively associated with individuals’ proximity in their real-world social network. The fact that exceptional similarities among friends were most pronounced in long-range temporal fluctuations of response patterns located in multimodal cortical regions (e.g., regions of posterior parietal cortex) suggests that aspects of high-level processing during naturalistic stimulation may be particularly similar among friends. Given the localization of results, we speculate that socially close individuals may be particularly similar in endogenously driven shifts in how they distribute their attention (e.g., across the environment, within internal representations) over time. These results suggest that friends may experience exceptionally similar trajectories of psychological states when exposed to a common stimulus, and, more generally, that there are meaningful individual differences in the temporal evolution of multi-voxel response patterns during naturalistic stimulation.",science
10.1016/j.ijbiomac.2019.11.172,Journal,International Journal of Biological Macromolecules,scopus,2020-08-01,sciencedirect,Activation of RAW264.7 macrophages by an acidic polysaccharide derived from Citrus grandis ‘Tomentosa’,https://api.elsevier.com/content/abstract/scopus_id/85075859481,"Citrus grandis ‘Tomentosa’ which is a special Citrus cultivar, has been employed as cough suppressant and expectorant in traditional Chinese medicine for thousands of years. The aim of this study is to investigate the immunomodulatory role of an acidic polysaccharide (designated as CGTP-AP) purified from C. grandis ‘Tomentosa’. CGTP-AP showed effective immune activation in RAW264.7 macrophages at the concentration of 1–100 μg/mL. CGTP-AP could promote the release of NO in dose- and time-dependent manners. Enzyme-Linked Immunosorbent Assay (ELISA) and RT-PCR analysis demonstrated that CGTP-AP could stimulate the secretion of TNF-α and IL-6 in a dosage-dependent way. Western blot analysis and RT-PCR analysis indicated that CGTP-AP treatment could induce the iNOS and COX-2 expression in RAW264.7 macrophages. By conducting the inhibitors experiments, the activation of NF-κB and MAPK signaling pathways by CGTP-AP treatment was confirmed. Therefore, the present results declared that CGTP-AP could be a promising candidate as a potent immunomodulator for the application in future pharmaceutical development.",science
10.1016/j.foodchem.2020.126505,Journal,Food Chemistry,scopus,2020-07-30,sciencedirect,Preparation of monoclonal antibody against penicillic acid (PA) and its application in the immunological detection,https://api.elsevier.com/content/abstract/scopus_id/85081115992,"The high content of Penicillic acid (PA) in the feed pose threat to human health and cause serious losses to economic wealth through the enrichment effect of the food chain. The reliable and rapidly detection of PA is of significant importance to ensure food safety. In this study, indirect competitive enzyme-linked immunosorbent assay (ic-ELISA) and immunochromatographic test strips (ICTS) were established for PA determination based on anti-PA mAb secreted by 4H9 cell line. The linear range of ic-ELISA detection was 0.12–1.95 μg/mL, and the limit of detection (LOD) was 0.03 μg/mL. Then, conventional gold nanospheres (AuNS) with the average diameter of 20 nm were synthetized and AuNS-based strip was developed for rapidly detection of PA. The visual LOD (vLOD) of the AuNS-based strip was 3.9 μg/mL and the assay time of visual evaluation was less than 10 min without any instrument. To enhance the signal sensitivity of the ICTS, the larger size (about 85 nm) of gold nanoflowers (AuNFs) was prepared in our work, and was used as higher signal reporter to establish the AuNF-based strip for PA determination. Fortunately, the vLOD of AuNF-based strip was 0.97 μg/mL, which was approximately 4-fold lower than that of traditional AuNS-based strip. In summary, the rapid and sensitive immunoassays established in this study could be applied to detect and analyze the contamination of PA toxin in real food samples.",science
10.1016/j.neucom.2019.09.111,Journal,Neurocomputing,scopus,2020-07-15,sciencedirect,BeAware: Convolutional neural network(CNN) based user behavior understanding through WiFi channel state information,https://api.elsevier.com/content/abstract/scopus_id/85083833018,"In modern informatics society, human beings are becoming more and more attached to the computer. Therefore, understanding user behavior is critical to various application fields like sedentary analysis, human-computer interaction, and affective computing. Current sensor-based and vision-based user behavior understanding approaches are either contact or obtrusive to user s, jeopardizing their availability and practicality. To this end, we present BeAware, a contactless Radio Frequency (RF) based user behavior understanding system leveraging the WiFi Channel State Information (CSI). The key idea is to visualize the channel data affected by human movements into time -series heat-map images, which are processed by a Convolutional Neural Network (CNN) to understand the corresponding user behaviors. We prototype BeAware on commodity low-cost WiFi devices and evaluate its performance in real-world environments. Experimental results have verified its effectiveness in recognizing user behaviors.",science
10.1016/j.chempr.2020.05.014,Journal,Chem,scopus,2020-07-09,sciencedirect,"Learning to Make Chemical Predictions: The Interplay of Feature Representation, Data, and Machine Learning Methods",https://api.elsevier.com/content/abstract/scopus_id/85087384615,"Recently, supervised machine learning has been ascending in providing new predictive approaches for chemical, biological, and materials sciences applications. In this Perspective, we focus on the interplay of machine learning methods with the chemically motivated descriptors and the size and type of datasets needed for molecular property prediction. Using nuclear magnetic resonance chemical shift prediction as an example, we demonstrate that success is predicated on the choice of feature extracted or real-space representations of chemical structures, whether the molecular property data are abundant and/or experimentally or computationally derived, and how these together will influence the correct choice of popular machine learning methods drawn from deep learning, random forests, or kernel methods.",science
10.1016/j.neucom.2018.09.104,Journal,Neurocomputing,scopus,2020-07-05,sciencedirect,A data-efficient deep learning approach for deployable multimodal social robots,https://api.elsevier.com/content/abstract/scopus_id/85065221778,"The deep supervised and reinforcement learning paradigms (among others) have the potential to endow interactive multimodal social robots with the ability of acquiring skills autonomously. But it is still not very clear yet how they can be best deployed in real world applications. As a step in this direction, we propose a deep learning-based approach for efficiently training a humanoid robot to play multimodal games—and use the game of ‘Noughts and Crosses’ with two variants as a case study. Its minimum requirements for learning to perceive and interact are based on a few hundred example images, a few example multimodal dialogues and physical demonstrations of robot manipulation, and automatic simulations. In addition, we propose novel algorithms for robust visual game tracking and for competitive policy learning with high winning rates, which substantially outperform DQN-based baselines. While an automatic evaluation shows evidence that the proposed approach can be easily extended to new games with competitive robot behaviours, a human evaluation with 130 humans playing with the Pepper robot confirms that highly accurate visual perception is required for successful game play.",science
10.1016/j.nds.2020.07.002,Journal,Nuclear Data Sheets,scopus,2020-07-01,sciencedirect,Enhancing nuclear data validation analysis by using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85089481714,"We demonstrate how machine learning (ML) techniques can be used as an auxiliary tool for nuclear data validation analysis. The output of the ML analysis can inform evaluators and validators on the quality, or lack thereof, of specific nuclear data and benchmark experiments with respect to simulating these experimental benchmark values. To this end, measured and simulated effective neutron multiplication factors, k
                     eff, of 875 selected ICSBEP critical assemblies and the latter's sensitivities with respect to nuclear data as well as benchmarks' features (e.g., material nuclide, core geometry) are used as input for a random forest (RF) regression model. The RF is used to encode the complex inter-dependencies between thousands of nuclear data features (i.e., sensitivity profiles and aspects describing the measurements) and 875 simulated and experimental k
                     eff values in order to understand what nuclear data features are most informative for predicting bias. The complexity of relationships and high-dimensional space is difficult-to-impossible to search fully using simply expert judgment. As a first proof-of-concept—step, it is demonstrated that this technique is able to correctly trace large discrepancies between simulated and experimental k
                     eff back to fabricated shortcomings in nuclear data that were perturbed to simulated k
                     eff values. In a second, real-case scenario, step, the RF algorithm is used to validate the ENDF/B-VIII.0 library in comparison to ENDF/B-VII.1 nuclear data. One case is showcased where the chosen ML algorithms highlighted nuclear data (the 19F(n,inl) cross section from 0.4–0.9 MeV) that are shown to be problematic by comparing them to associated differential experimental data and nuclear data from other libraries. In addition to that, it is shown that the RF results point towards poor benchmark experiments and associated underestimated uncertainties (e.g., the PU-SOL-THERM-028 series). However, using the RF algorithm for validating nuclear data with respect to k
                     eff is currently limited to pinpointing groups of questionable nuclear data due to the inherent correlations between features introduced by the nuclear data themselves and how k
                     eff is simulated. Due to this, we recommend that the ML methods presented be used to augment—rather than replace—the expert knowledge of evaluators and validators.",science
10.1016/j.heliyon.2020.e04289,Journal,Heliyon,scopus,2020-07-01,sciencedirect,Predicting extrusion process parameters in Nigeria cable manufacturing industry using artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85088638910,"The extrusion process is a very complex process due to the number of process parameters that are associated with it which are prone to high fluctuations. The main purpose of this work is to determine the realistic extrusion process parameters in the thermoplastic extrusion process in Nigeria cable manufacturing industries with the use of an artificial neural network. Conventionally, the use of trial and error technique which involves full-size experiments is generally used to determine the process parameters in the thermoplastic extrusion process. This conventional technique is expensive and it is also time-consuming. The use of an artificial neural network to predict extrusion process parameters before plant execution will make extrusion process operations more efficient. This technique also bridges the gap that exists between theoretical analysis and real manufacturing system because real manufacturers' data was used. The neural network was developed in a MATLAB environment and was trained with a supervised learning method based on Levenberg Marquardt Algorithm and the developed ANN model is capable of predicting manufacturing process parameters for different grades of PVC thermoplastic material.",science
10.1016/j.ymeth.2020.05.014,Journal,Methods,scopus,2020-07-01,sciencedirect,GCN-BMP: Investigating graph representation learning for DDI prediction task,https://api.elsevier.com/content/abstract/scopus_id/85087948080,"One drug's pharmacological activity may be changed unexpectedly, owing to the concurrent administration of another drug. It is likely to cause unexpected drug-drug interactions (DDIs). Several machine learning approaches have been proposed to predict the occurrence of DDIs. However, existing approaches are almost dependent heavily on various drug-related features, which may incur noisy inductive bias. To alleviate this problem, we investigate the utilization of the end-to-end graph representation learning for the DDI prediction task. We establish a novel DDI prediction method named GCN-BMP (Graph Convolutional Network with Bond-aware Message Propagation) to conduct an accurate prediction for DDIs. Our experiments on two real-world datasets demonstrate that GCN-BMP can achieve higher performance compared to various baseline approaches. Moreover, in the light of the self-contained attention mechanism in our GCN-BMP, we could find the most vital local atoms that conform to domain knowledge with certain interpretability.",science
10.1016/j.jvcir.2020.102770,Journal,Journal of Visual Communication and Image Representation,scopus,2020-07-01,sciencedirect,Diverse receptive field network with context aggregation for fast object detection,https://api.elsevier.com/content/abstract/scopus_id/85087200862,"Current context-utilizing detectors are all based on two-stage approaches. However, their computational efficiency and context quality extremely depend on the accuracy of proposal-generating methods, which limits their performance and makes them hardly perform real-time detection. In this work, we present a context-exploited method that integrates features in different receptive fields to obtain contextual representation. Based on this idea, we put forward the multi-branch diverse receptive field modules (DRF modules) and their design principles to encode context. To further utilize contextual information for fast object detection, we propose a one-stage diverse receptive field network (DRFNet). In DRFNet, the DRF modules are first applied to capture rich context as the basis, then a parallel structure is constructed to exploit the context at different scales along with DRF modules. Comprehensive experiments indicate that the context introduced by our methods improves the detection performance and DRFNet achieves a good trade-off between speed and accuracy.",science
10.1016/j.comcom.2020.05.042,Journal,Computer Communications,scopus,2020-07-01,sciencedirect,Fastest adaptive estimation algorithms for topological structure errors in smart grid networks,https://api.elsevier.com/content/abstract/scopus_id/85086375513,"Compared with traditional wired networks, wireless sensor networks(WSN) have the characteristics of low cost and rapid deployment, and also guarantee the same level of fault tolerance as wired networks. The WSN can also monitor the operating status of the power grid in real time, collect physical information such as related parameters, and provide more comprehensive and complete power grid operation data as a reference basis for smart grid operation and related management personnel, and complete the diagnosis, monitoring and power statistics of smart grid equipment The rapid construction of the data communication network has become a key technology to effectively solve the problems of difficult optimization management and high cost and economic benefits in the smart grid. This paper discusses the application of WSNs in smart grids from two aspects. Firstly, construct a WSN topology that complies with the smart grid architecture, and establish a real-time routing mechanism that meets the requirements of smart distribution network communication reliability; secondly, propose a fastest adaptive algorithm for the fault of the WSN topology in the smart grid . The proposed adaptive routing mechanism has certain advantages in node energy consumption, which reduces energy consumption by nearly 4% compared to the directional diffusion method and the LEACH algorithm. Therefore, the algorithm is more suitable for the adaptation of WSN topology, and the method can Improve the life cycle of sensor nodes and networks.",science
10.1016/j.joen.2020.04.003,Journal,Journal of Endodontics,scopus,2020-07-01,sciencedirect,"Warm Gutta-Percha Techniques Regulate Cell Viability, Heat Shock, and Mineralized Tissue–associated Proteins of Cementoblasts",https://api.elsevier.com/content/abstract/scopus_id/85085058072,"Introduction
                  The aim of this study was to determine the effect of the continuous wave of condensation technique (CWCT) and the thermoplastic gutta-percha injection (TGI) technique on the messenger RNA (mRNA) expressions of heat shock proteins (HSPs) and mineralized tissue–associated proteins of the immortalized mouse cementoblasts (OCCM.30).
               
                  Methods
                  Crowns of human premolar teeth with single and straight canals were removed. The root canals were prepared up to the ProTaper Next X5 file (Dentsply Maillefer, Ballaigues, Switzerland) in combination with 2 mL 2.5% sodium hypochlorite solution. Roots (12 ± 2 mm height) were sterilized (121°C for 20 minutes) and placed vertically to the cell culture dishes using a tissue culture insert by opening holes according to the root diameter after the removal of 1 mm from the apex for appropriate adaptation to the petri dish surfaces. Six groups were created: control 1 (without teeth), control 2 (with teeth), AH Plus (Dentsply DeTrey, Konstanz, Germany), single-cone obturation (SC), CWCT, and thermoplastic gutta-percha injection technique (TGI). The viability of the OCCM.30 cells was analyzed by 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide cell viability experiments at 24 and 96 hours. The mRNA expression of HSP27, HSP70, and HSP90 and mineralized tissue markers (bone sialoprotein, osteocalcin, runt-related transcription factor 2, type I collagen, and alkaline phosphatase) was evaluated by real-time polymerase chain reaction.
               
                  Results
                  Reduced OCCM.30 cell viability was observed in all groups except the control groups. When the SC technique and CWCT and TGI groups were compared, it was observed that heat had a significant negative effect on cell viability (P < .05). A reduction in the mRNA expressions of HSP27, HSP70, and HSP90 was recognized in all test groups when compared with the control 1 group (P < .01). When the warm gutta-percha techniques were compared with the SC technique, a decrease in mRNA expression of HSP27 and HSP90 was noted (P < .01). The HSP70 transcript was similar in the CWCT group and the SC group. Higher HSP70 mRNA expression was observed in the TGI group compared with the SC group. In all groups except the control 1 group, bone sialoprotein, osteocalcin, runt-related transcription factor 2, type I collagen, and alkaline phosphatase mineralized tissue markers were affected, but this negative effect was higher in the heat-treated groups (P < .05).
               
                  Conclusions
                  Within the limitations of this study, it was concluded that warm gutta-percha techniques reduced the mRNA expressions of the genes for HSPs and mineralized tissue–associated proteins of cementoblasts. Further animal studies are needed to clarify the effect of heat on the behavior of cementoblasts histologically in short- and long-term periods.",science
10.1016/j.sigpro.2020.107567,Journal,Signal Processing,scopus,2020-07-01,sciencedirect,Accurate single image super-resolution using multi-path wide-activated residual network,https://api.elsevier.com/content/abstract/scopus_id/85081999060,"In many recent image super-resolution (SR) methods based on convolutional neural networks (CNNs), the superior performance was achieved by training very large networks, which may not be suitable for real-world applications with limited computing resources. Therefore, it is necessary to develop more compact networks that achieve a better trade-off between the model size and the performance. In this paper, we propose an efficient and effective network called multi-path wide-activated residual network (MWRN). Firstly, as the basic building block of MWRN, the multi-path wide-activated residual block (MWRB) is presented to extract the multi-scale features. MWRB consists of three parallel wide-activated residual paths, where the dilated convolutions with different dilation factors are used to increase the receptive fields. Secondly, the fusional channel attention (FCA) module, which contains a bottleneck layer and a multi-path wide-activated residual channel attention (MWRCA) block, is designed to well exploit the multi-level features in MWRN. In each FCA, the MWRCA block refines the fused features by taking the interdependencies among feature channels into consideration. The experiments demonstrate that, compared with the state-of-the-art methods, the proposed MWRN model is able to provide very competitive performance with a relatively small number of parameters.",science
10.1016/j.ipm.2020.102231,Journal,Information Processing and Management,scopus,2020-07-01,sciencedirect,Discovering web services in social web service repositories using deep variational autoencoders,https://api.elsevier.com/content/abstract/scopus_id/85081050739,"Web Service registries have progressively evolved to social networks-like software repositories. Users cooperate to produce an ever-growing, rich source of Web APIs upon which new value-added Web applications can be built. Such users often interact in order to follow, comment on, consume and compose services published by other users. In this context, Web Service discovery is a core functionality of modern registries as needed Web Services must be discovered before being consumed or composed. Many efforts to provide effective keyword-based service discovery mechanisms are based on Information Retrieval techniques as services are described using structured or unstructured textdocuments that specify the provided functionality. However, traditional techniques suffer from term-mismatch, which means that only the terms that are contained in both user queries and descriptions are exploited to perform service retrieval. Early feature learning techniques such as LSA or LDA tried to solve this problem by finding hidden or latent features in text documents. Recently, alternative feature learning based techniques such as Word Embeddings achieved state of the art results for Web Service discovery. In this paper, we propose to learn features from service descriptions by using Variational Autoencoders, a special kind of autoencoder which restricts the encoded representation to model latent variables. Autoencoders in turn are deep neural networks used for unsupervised learning of efficient codings. We train our autoencoder using a real 17 113-service dataset extracted from the ProgrammableWeb.com API social repository. We measure discovery efficacy by using both Recall and Precision metrics, achieving significant gains compared to both Word Embeddings and classic latent features modelling techniques. Also, performance-oriented experiments show that the proposed approach can be readily exploited in practice.",science
10.1016/j.petrol.2019.106741,Journal,Journal of Petroleum Science and Engineering,scopus,2020-07-01,sciencedirect,Connectionist and mutual information tools to determine water saturation and rank input log variables,https://api.elsevier.com/content/abstract/scopus_id/85081011589,"Characterization of petroleum reservoirs plays an important role to effectively manage and forecast the recovery performance. A number of subset log variables such as gamma-ray, resistivity, density, neutron, and sonic porosity logs are generally used to characterize/predict the reservoir properties. The data attributes selection and ranking in reservoir characterization are vital to determine the output variables with the best performance and cost-effective manner during exploration and production operations. The objectives of this research work are to estimate the water saturation in the reservoir with an acceptable accuracy and to rank the log variables according to their importance. To achieve the objectives, the mutual information (MI) and artificial neural network (ANN) techniques are implemented with the non-linear predictors using log variables. The feed-forward ANN model is employed and optimized to predict the water saturation, where the Levenberg-Marquardt algorithm is used for the network training. There is a good match between the real data and predictions so that the regression coefficient and the maximum error is 99.98% and 5.55%, respectively. In addition, both ANN and MI approaches lead to the same ranking levels of log variables, implying high accuracy and reliability of the introduced strategies. It is found that the primary (or most important) log variables are the true resistivity and bulk density to obtain the pore fluid saturation. The approach suggested in this study (connectionist and MI strategies) can assist engineers/operators to run a few numbers of logging tools for prediction of water saturation, resulting in saving the exploration costs through an efficient manner. In addition, further understanding is attained to conduct proper data selection for determination of reservoir petrophysical properties.",science
10.1016/j.patcog.2020.107314,Journal,Pattern Recognition,scopus,2020-07-01,sciencedirect,Learning to infer human attention in daily activities,https://api.elsevier.com/content/abstract/scopus_id/85080908756,"The first attention model in the computer science community is proposed in 1998. In the following years, human attention has been intensively studied. However, these studies mainly refer human attention as the image regions that draw the attention of a human (outside the image) who is looking at the image. In this paper, we infer the attention of a human inside a third-person view video where the human is doing a task, and define human attention as attentional objects that coincide with the task the human is doing. To infer human attention, we propose a deep neural network model that fuses both low-level human pose cue and high-level task encoding cue. Due to the lack of appropriate public datasets for studying this problem, we newly collect a video dataset in complex Virtual-Reality (VR) scenes. In the experiments, we widely compare our method with three other methods on this VR dataset. In addition, we re-annotate a public real dataset and conduct the extensional experiments on this real dataset. The experiment results validate the effectiveness of our method.",science
10.1016/j.jep.2020.112706,Journal,Journal of Ethnopharmacology,scopus,2020-06-28,sciencedirect,The effects of hydro-ethanolic extract of Capparis spinosa (C. spinosa) on lipopolysaccharide (LPS)-induced inflammation and cognitive impairment: Evidence from in vivo and in vitro studies,https://api.elsevier.com/content/abstract/scopus_id/85083222506,"Ethnopharmacological relevance
                  
                     Capparis spinose (C. spinosa) belonging to Capparaeae, originates from dry areas in the west or central Asia and Mediterranean basin. For thousands of years, C. spinosa has been reported to be used as a therapeutic traditional medicine to relieve various ailments including rheumatism, pain and inflammatory diseases.
               
                  Aim of the study
                  There are several studies mentioning that systemic inflammation results in learning and memory impairments through the activation of microglia. The objective of this study was to investigate the effect of C. spinosa on both in vivo and in vitro models of neuroinflammation and cognitive impairment using lipopolysaccharide (LPS).
               
                  Materials and methods
                  In vivo: 40 male rats were used in the present study. Cognitive impairment was induced using LPS (1 mg/kg/d; i.p.) for 4 weeks. Treatment with C. spinosa (100 and 300 mg/kg/d; p.o.) was performed 1 h before LPS administration. At the end of the experiment, rats were undergone for behavioral and biochemical analysis. In vitro: Primary microglia isolated from mouse was used in the present study. The cells were pretreated with C. spinosa extract (10–300 μg/ml) and then stimulated with LPS (1 μg/ml). The expression levels of inflammatory and anti-inflammatory cytokines were elucidated using Real-Time PCR and ELISA methods.
               
                  Results
                  The escape latency in the Morris water maze test in the LPS group was significantly greater than the control group (p < 0.001), while, in extract-treated groups, it was less than the LPS group (p < 0.001). Additionally, we found that the levels of IL-1β, TNF-α, and iNOS/Arg-1 ratio was also significantly lower in extract-treated groups than the LPS group (p < 0.001). The results revealed that C. spinosa extract significantly reduced the levels of TNF-α, iNOS, COX-2, IL-1β, IL-6, NO and PGE2, and the ratios of iNOS/Arg-1 and NO/urea, following the LPS-induced inflammation in microglia (p < 0.001).
               
                  Conclusions
                  Our finding provides evidence that C. spinosa has a neuroprotective effect, and might be considered as an effective therapeutic agent for the treatment of neurodegenerative diseases that are accompanied by microglial activation, such as AD.",science
10.1016/j.patter.2020.100042,Journal,Patterns,scopus,2020-06-12,sciencedirect,Deep Learning Identifies Digital Biomarkers for Self-Reported Parkinson's Disease,https://api.elsevier.com/content/abstract/scopus_id/85095745471,"Large-scale population screening and in-home monitoring for patients with Parkinson's disease (PD) has so far been mainly carried out by traditional healthcare methods and systems. Development of mobile health may provide an independent, future method to detect PD. Current PD detection algorithms will benefit from better generalizability with data collected in real-world situations. In this paper, we report the top-performing smartphone-based method in the recent DREAM Parkinson's Disease Digital Biomarker Challenge for digital diagnosis of PD. Utilizing real-world accelerometer records, this approach differentiated PD from control subjects with an area under the receiver-operating characteristic curve of 0.87 by 3D augmentation of accelerometer records, a significant improvement over other state-of-the-art methods. This study paves the way for future at-home screening of PD and other neurodegenerative conditions affecting movement.",science
10.1016/j.phymed.2020.153223,Journal,Phytomedicine,scopus,2020-06-01,sciencedirect,"In vitro and in vivo effects of the combination of myricetin and miconazole nitrate incorporated to thermosensitive hydrogels, on C. albicans biofilms",https://api.elsevier.com/content/abstract/scopus_id/85085194143,"Background
                  
                     Candida albicans-related infections are common infections in clinic, among which biofilm-associated infections are most devastating and challenging to overcome. Myricetin (MY) is a plant-derived natural product with various pharmacological activities. Its anti-biofilm effect against C. albicans and its ability to increase the antifungal effect of miconazole nitrate (MN) were unclear and yet need to be explored.
               
                  Hypothesis/Purpose
                  In this study the anti-biofilm effect of MY and its ability to increase the antifungal effect of MN were investigated in vitro and in vivo.
               
                  Study design and methods
                  MY or/and MN were incorporated into a thermosensitive hydrogel (TSH) of poloxamer. The safety of MY or/and MN loaded TSHs towards human umbilical vein endothelial cells (HUVEC) was evaluated by a MTT assay and the in vivo safety towards mice knees was confirmed by histopathological examination. The anti-biofilm effect of MY and its ability to increase the antifungal effect of MN were investigated in vitro with C. albicans ATCC 10231 by broth microdilution method, crystal violet staining and scanning electron microscopy (SEM), as well as in vivo in an established mouse model of periprosthetic joint infection (PJI) by SEM, histological analysis, microorganism culture and detection of the serum levels of interleukin-6 (IL-6). The mechanism of action of MY was analyzed by qRT-PCR assay with C. albicans SC5314.
               
                  Results
                  Our results showed that MY and MN incorporated into TSHs exhibited good stability and safety, excellent temperature sensitivity and controlled drug release property. MY (5-640 µg/ml) exhibited no effect on C. albicans cell viability and MY (≥80 µg/ml) showed a significantly inhibitory effect on biofilm formation. MIC50 (the lowest concentrations of drugs resulting in 50% decrease of C. albicans growth) and MIC80 (the lowest concentrations of drugs resulting in 80% decrease of C. albicans growth) of MN were respectively decreased from 2 µg/ml to 0.5 µg/ml and from 4 µg/ml to 2 µg/ml when used in combination with MY (80 µg/ml). The mouse PJI was effectively prevented by MY and MN incorporated into TSH.
               
                  Conclusions
                  Local application of MY and MN incorporated into TSH might be useful for clinical biofilm-associated infections.",science
10.1016/j.tins.2020.03.013,Journal,Trends in Neurosciences,scopus,2020-06-01,sciencedirect,Social Cognition in the Age of Human–Robot Interaction,https://api.elsevier.com/content/abstract/scopus_id/85084225891,"Artificial intelligence advances have led to robots endowed with increasingly sophisticated social abilities. These machines speak to our innate desire to perceive social cues in the environment, as well as the promise of robots enhancing our daily lives. However, a strong mismatch still exists between our expectations and the reality of social robots. We argue that careful delineation of the neurocognitive mechanisms supporting human–robot interaction will enable us to gather insights critical for optimising social encounters between humans and robots. To achieve this, the field must incorporate human neuroscience tools including mobile neuroimaging to explore long-term, embodied human–robot interaction in situ. New analytical neuroimaging approaches will enable characterisation of social cognition representations on a finer scale using sensitive and appropriate categorical comparisons (human, animal, tool, or object). The future of social robotics is undeniably exciting, and insights from human neuroscience research will bring us closer to interacting and collaborating with socially sophisticated robots.",science
10.1016/j.fitote.2020.104600,Journal,Fitoterapia,scopus,2020-06-01,sciencedirect,Antiviral properties of extracts of Streptomyces sp. SMU 03 isolated from the feces of Elephas maximus,https://api.elsevier.com/content/abstract/scopus_id/85084142195,"Actinobacteria are historically and continued to be an important source for drug discovery. The annual epidemics and periodic pandemics of humans induced by influenza A virus (IAV) prompted us to develop new effective antiviral drugs with different modes of action. An actinobacterium of Streptomyces sp. SMU 03 was identified from the feces of Elephas maximus in Yunnan Province, China. By employing an H5N1 pseudo-typed virus drug screening system, the anti-IAV effect of the dichloromethane extracts (DCME) of this bacterium was investigated. DCME showed broad and potent activities against several influenza viruses, including the H1N1 and H3N2 subtypes and influenza B virus, with IC50 values ranging from 0.37 ± 0.22 to 14.44 ± 0.79 μg/mL. A detailed modes-of-action study indicated that DCME might interact with the HA2 subunit of hemagglutinin (HA) of IAV by interrupting the fusion process between the viral and host cells' membranes thereby inhibiting the entry of the virus into host cells. Furthermore, the in vivo anti-IAV activity test of DCME showed that compared with the no-drug treated group, the survival rates, appearances, weights, lung indices and histopathological changes were all significantly alleviated. Based on these results, the chemical constituent study of DCME was then investigated, from which a number of antiviral compounds with various structural skeletons have been isolated and identified. Overall, these data indicated that the DCME from Streptomyces sp. SMU 03 might represent a good source for antiviral compounds that can be developed as potential antivirus remedies.",science
10.1016/j.compbiomed.2020.103792,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,Automated detection of COVID-19 cases using deep neural networks with X-ray images,https://api.elsevier.com/content/abstract/scopus_id/85083900518,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (https://github.com/muhammedtalo/COVID-19)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.",science
10.1016/j.engappai.2020.103670,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-06-01,sciencedirect,"Detecting, locating and recognising human touches in social robots with contact microphones",https://api.elsevier.com/content/abstract/scopus_id/85083676413,"There are many situations in our daily life where touch gestures during natural human–human interaction take place: meeting people (shaking hands), personal relationships (caresses), moments of celebration or sadness (hugs), etc. Considering that robots are expected to form part of our daily life in the future, they should be endowed with the capacity of recognising these touch gestures and the part of its body that has been touched since the gesture’s meaning may differ. Therefore, this work presents a learning system for both purposes: detect and recognise the type of touch gesture (stroke, tickle, tap and slap) and its localisation. The interpretation of the meaning of the gesture is out of the scope of this paper.
                  Different technologies have been applied to perceive touch by a social robot, commonly using a large number of sensors. Instead, our approach uses 3 contact microphones installed inside some parts of the robot. The audio signals generated when the user touches the robot are sensed by the contact microphones and processed using Machine Learning techniques. We acquired information from sensors installed in two social robots, Maggie and Mini (both developed by the RoboticsLab at the Carlos III University of Madrid), and a real-time version of the whole system has been deployed in the robot Mini. The system allows the robot to sense if it has been touched or not, to recognise the kind of touch gesture, and its approximate location. The main advantage of using contact microphones as touch sensors is that by using just one, it is possible to “cover” a whole solid part of the robot. Besides, the sensors are unaffected by ambient noises, such as human voice, TV, music etc. Nevertheless, the fact of using several contact microphones makes possible that a touch gesture is detected by all of them, and each may recognise a different gesture at the same time. The results show that this system is robust against this phenomenon. Moreover, the accuracy obtained for both robots is about 86%.",science
10.1016/j.dcn.2020.100779,Journal,Developmental Cognitive Neuroscience,scopus,2020-06-01,sciencedirect,Adolescent gender differences in neural reactivity to a friend's positive affect and real-world positive experiences in social contexts,https://api.elsevier.com/content/abstract/scopus_id/85083426638,"Peers become increasingly important during adolescence, with emerging gender differences in peer relationships associated with distinct behavioral and emotional outcomes. Males tend to socialize in larger peer groups with competitive interactions, whereas females engage in longer bouts of dyadic interaction with more intimacy. To examine gender differences in neural response to ecologically valid displays of positive affect and future social interactions, 52 adolescents (14–18 years old; female = 30) completed a social reward functional magnetic resonance imaging (fMRI) task with videos of a same-gender best friend (BF) or unfamiliar peer (UP) expressing positive (versus neutral) affect. Participants completed ecological momentary assessment of social experiences for two 5-day intervals. Compared with females, males more often reported that their happiest experience in the past hour occurred with class/teammates. Females and males displayed greater fusiform gyrus (FG) activation during BF and UP conditions, respectively (p
                     voxel<0.0001, p
                     cluster<0.05, family-wise error). Compared with males, females exhibited greater nucleus accumbens (NAcc)-precuneus functional connectivity to BF Positive> UP Positive. An exploratory analysis indicated that the association of male gender with a greater proportion of positive experiences with class/teammates was statistically mediated by greater NAcc-precuneus functional connectivity. Gender differences in positive social experiences may be associated with reward and social cognition networks.",science
10.1016/j.compag.2020.105434,Journal,Computers and Electronics in Agriculture,scopus,2020-06-01,sciencedirect,Dynamic Simulation Tool of fertigation in drip irrigation subunits,https://api.elsevier.com/content/abstract/scopus_id/85083338592,"Agriculture consumes approximately 95 million tonnes of fertilizers and 97,000 tonnes of active ingredients of pesticides and herbicides. Reducing external input systems can result in significant economic, social and environmental impact. Therefore, establishing an optimal fertigation schedule is essential to achieve efficient drip irrigation management and, therefore, achieve an optimal irrigated agriculture management system that ensures productive, environmental and economic viability. The objective of this study was to develop a decision support system (DSS) to facilitate farmers’ decision-making process and optimize the design and management of farm fertigation scheduling. Implemented in MATLAB®, FERTI-DRIP, was tested in a regular irrigation subunit and in an irregular irrigation subunit of a real water user association. Both irrigation subunits were tested with two irrigation emitter types: pressure-compensating emitters and non-pressure-compensating emitters. Thus, FERTI-DRIP was applied to four scenarios to analyse the effect of the size and shape of the irrigation subunit on the fertigation process. The effect of the pressure head in the irrigation subunit and the effect of the fertilizer dynamics during the fertigation event were also analysed. FERTI-DRIP allows users to compute fertilizer quality parameters to determine how to implement fertigation. FERTI-DRIP also allows users to accurately select pre-fertigation and post-fertigation processes to optimize hydraulic stability at the beginning of the fertigation event and ensure that there is no fertilizer remaining in the irrigation system after the fertigation event. FERTI-DRIP can be very helpful for start-time irrigation events, such in the case of sandy soils where pulse drip irrigation should be performed.",science
10.1016/j.aca.2020.04.007,Journal,Analytica Chimica Acta,scopus,2020-06-01,sciencedirect,Dual-emission CdTe/AgInS<inf>2</inf> photoluminescence probe coupled to neural network data processing for the simultaneous determination of folic acid and iron (II),https://api.elsevier.com/content/abstract/scopus_id/85083073504,"This work focused on the combination of CdTe and AgInS2 quantum dots in a dual-emission nanoprobe for the simultaneous determination of folic acid and Fe(II) in pharmaceutical formulations. The surface chemistry of the used QDs was amended with suitable capping ligands to obtain appropriate reactivity in terms of selectivity and sensitivity towards the target analytes. The implementation of PL-based sensing schemes combining multiple QDs of different nature, excited at the same wavelength and emitting at different ones, allowed to obtain a specific analyte-response profile. The first-order fluorescence data obtained from the whole emission spectra of the CdTe/AgInS2 combined nanoprobe upon interaction with folic acid and Fe(II) were processed by using chemometric tools, namely partial least-squares (PLS) and artificial neural network (ANN). This enabled to circumvent the selectivity issues commonly associated with the use of QDs prone to indiscriminate interaction with multiple species, which impair reliable and accurate quantification in complex matrices samples.
                  ANN demonstrated to be the most efficient chemometric model for the simultaneous determination of both analytes in binary mixtures and pharmaceutical formulations due to the non-linear relationship between analyte concentration and fluorescence data that it could handle. The R2
                     P and SEP% obtained for both analytes quantification in pharmaceutical formulations through ANN modelling ranged from 0.92 to 0.99 and 5.7–9.1%, respectively. The obtained results revealed that the developed approach is able to quantify, with high reliability and accuracy, more than one analyte in complex mixtures and real samples with pharmaceutical interest.",science
10.1016/j.micpath.2020.104109,Journal,Microbial Pathogenesis,scopus,2020-06-01,sciencedirect,Ginsenoside Rb 1: A novel therapeutic agent in Staphylococcus aureus-induced Acute Lung Injury with special reference to Oxidative stress and Apoptosis,https://api.elsevier.com/content/abstract/scopus_id/85082140966,"Acute lung injury (ALI) is considered as an uncontrolled inflammatory response that can leads to acute respiratory distress syndrome (ARDS), which limits the therapeutic strategies. Ginsenosides Rb1 (Rb1), an active ingredient obtained from Panax ginseng, possesses a broad range of pharmacological and medicinal properties, comprising the anti-inflammatory, anti-oxidant, and anti-tumor activities. Therefore, the purpose of the present study was to investigate the protective effects of Rb1 against S. aureus-induced (ALI) through regulation of Nuclear factor erythroid 2-related factor 2 (Nrf2) and mitochondrial-mediated apoptotic pathways in mice (in-vivo), and RAW264.7 cells (in-vitro). For that purpose, forty Kunming mice were randomly assigned into four treatment groups; (1) Control group (phosphate buffer saline (PBS); (2) S. aureus group; (3) S. aureus + Rb1 (20 mg/kg) group; and (4) Rb1 (20 mg/kg) group. The 20 μg/mL dose of Rb1 was used in RAW264.7 cells. In the present study, we found that Rb1 treatment reduced ALI-induced oxidative stress via suppressing the accumulation of malondialdehyde (MDA) and myeloperoxidase (MPO) and increase the antioxidant enzyme activities of superoxidase dismutase 1 (SOD1), Catalase (CAT), and glutathione peroxidase 1 (Gpx1). Similarly, Rb1 markedly increased messenger RNA (mRNA) expression of antioxidant genes (SOD1, CAT and Gpx1) in comparison with ALI group. The histopathological results showed that Rb1 treatment ameliorated ALI-induced hemorrhages, hyperemia, perivascular edema and neutrophilic infiltration in the lungs of mice. Furthermore, Rb1 enhanced the antioxidant defense system through activating the Nrf2 signaling pathway. Our findings showed that Rb1 treated group significantly up-regulated mRNA and protein expression of Nrf2 and its downstream associated genes down-regulated by ALI in vivo and in vitro. Moreover, ALI significantly increased the both mRNA and protein expression of mitochondrial-apoptosis-related genes (Bax, caspase-3, caspase-9, cytochrome c and p53), while decreased the Bcl-2. In addition, Rb1 therapy significantly reversed the mRNA and protein expression of these mitochondrial-apoptosis-related genes, as compared to the ALI group in vivo and in vitro. Taken together, Rb1 alleviates ALI-induced oxidative injury and apoptosis by modulating the Nrf2 and mitochondrial signaling pathways in the lungs of mice.",science
10.1016/j.scitotenv.2020.137459,Journal,Science of the Total Environment,scopus,2020-06-01,sciencedirect,NO<inf>x</inf> removal efficiency of urban photocatalytic pavements at pilot scale,https://api.elsevier.com/content/abstract/scopus_id/85081197829,"Photocatalytic technology implemented in construction materials is a promising solution to contribute to alleviate air quality issues found in big cities. Photocatalysis has been proved able to mineralise most harmful contaminants. However, important problems associated with monitoring the efficiency of these solutions under real conditions still remain, including the lack of affordable analytical tools to measure NOx concentrations with enough accuracy. In this work, two pilot scale demonstration platforms were built at two different locations to assess the photocatalytic NOX removal efficiency of ten selected materials exposed outdoors for AQmesh low-cost sensor PODs were used to measure ground-level to measure NO and NO2 concentrations during nearly one year. The pollutant removal efficiency of the materials was then calculated based on a comparison with simultaneously concentration measurements carried-out on reference, non-active materials. It was found that the NO2 removal efficiency presented large variations across the seasons, with maxima during the warmer months, while NO efficiencies were comparatively steadier. Statistical analysis delivered evidence that the efficiencies significantly depend on different meteorological variables (irradiance and relative humidity) besides NO, NO2 ambient concentrations. Lower efficiencies were observed for higher concentration levels and vice versa. The influence of water vapour could be related to two different effects: a short-term contribution by the instantaneous air humidity and a long-term component associated with the hygroscopic state of the material. The contribution of wind to the pollutant removal efficiencies was principally related to the humidity of air masses moving above the location and to the advection of pollutants from specific emission sources.",science
10.1016/j.mcp.2020.101539,Journal,Molecular and Cellular Probes,scopus,2020-06-01,sciencedirect,Analysis of differentially expressed circular RNAs in endothelial cells under impinging flow,https://api.elsevier.com/content/abstract/scopus_id/85080026758,"Background
                  Circular RNAs (circRNAs) are a special type of non-coding RNA. To elucidate the relationship between hemodynamics and the function of circRNAs in endothelial cells (ECs), a modified T chamber system was designed and produced for the present experiment. This T chamber system can be used to simulate the hemodynamic environment at the bifurcation of the arteries.
               
                  Methods
                  Normal ECs cultured on glass slides were placed in the T chamber, the cell layer was impacted at a flow rate of 500 mL/min, and high-throughput microarrays were used to analyze the expression profiles of circRNAs in ECs. The differential expressions of circRNAs in the ECs treated with impinging flow were compared to those in ECs in conventional culture conditions. The characteristics of the differentially expressed circRNAs were analyzed with bioinformatics and quantitative reverse transcription polymerase chain reaction analyses were conducted to verify results.
               
                  Results
                  Compared to normal samples, there were changes in the expressions of many circRNAs. A total of 974 circRNAs were differentially expressed, and of these, 378 were upregulated and 596 were downregulated (fold change [FC] ≥ 2 and P < 0.05), which suggests that these circRNAs were altered under hemodynamic conditions.
               
                  Conclusions
                  We present the differential expression profiles of circRNAs in ECs after the application of impinging flow; our results indicate that these differentially expressed circRNAs may be involved in inflammatory responses and damage in ECs. The present findings provide valuable information on cRNA profiles as well as clues for future studies that will investigate the roles that circRNAs play in ECs after inflammatory injury.",science
10.1016/j.biopha.2019.109733,Journal,Biomedicine and Pharmacotherapy,scopus,2020-06-01,sciencedirect,Prevent action of magnoflorine with hyaluronic acid gel from cartilage degeneration in anterior cruciate ligament transection induced osteoarthritis,https://api.elsevier.com/content/abstract/scopus_id/85079860048,"According to the Chinese medicine, magnoflorine exerted significant anti-inflammatory effects and potentially promoted synthesis of proteoglycans in chondrocytes to reverse the progression of rheumatoid arthritis. However, the latent beneficial effect of magnoflorine for the treatment of traumatic osteoarthritis (OA) is still unknown. Therefore, we aim to demonstrate the efficacy of magnoflorine combined with HA-gel in attenuating cartilage degeneration in anterior cruciate ligament transection (ACLT) induced OA rat model. We found that the histological results showed the elevated cartilage matrix, chondrogenic signals and chondroprogenitor cells in HA-gel + magnoflorine treatment. HA-gel + magnoflorine treatment resulted in a decreased modified Mankin’s score, and a higher volume ratio of hyaline cartilage (HC)/calcified cartilage (CC) and HC/Sum (whole cartilage), compared to ACLT and HA-gel groups. Furthermore, both the volume ratios of HC/Sum and HC/CC were negatively correlated with modified Mankin’s scores. Finally, HA-gel + magnoflorine could significantly increase the BV/TV, Tb.Th, and decrease the Tb.Pf, Po(tot), Conn.Dn and Tb.Sp. In vitro, 50 μg/ml magnoflorine treatment could significantly increase the viability, S-phase, migration rate and chondrogenesis of chondroprogenitor cells. There were significant downregulations of MAPK/NF-κB signaling, and upregulations of chondrogenic signals in 50 μg/ml magnoflorine treatment. There were significant downregulations of proinflammatory cytokines and upregulation of IL-10 in HA-gel + magnoflorine treated group. Therefore, our study elucidated a protective effect of HA-gel + magnoflorine on attenuating cartilage degradation and maintaining SCB stabilization in ACLT induced OA.",science
10.1016/j.inffus.2019.12.012,Journal,Information Fusion,scopus,2020-06-01,sciencedirect,"Explainable Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",https://api.elsevier.com/content/abstract/scopus_id/85077515399,"In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.",science
10.1016/j.ibror.2019.11.006,Journal,IBRO Reports,scopus,2020-06-01,sciencedirect,Targeted viral vector transduction of relaxin-3 neurons in the rat nucleus incertus using a novel cell-type specific promoter,https://api.elsevier.com/content/abstract/scopus_id/85076463030,"Modern neuroscience utilizes transgenic techniques extensively to study the activity and function of brain neural networks. A key feature of this approach is its compatibility with molecular methods for selective transgene expression in neuronal circuits of interest. Until now, such targeted transgenic approaches have not been applied to the extensive circuitry involving the neuropeptide, relaxin-3. Pharmacological and gene knock-out studies have revealed relaxin-3 signalling modulates interrelated behaviours and cognitive processes, including stress and anxiety, food and alcohol consumption, and spatial and social memory, highlighting the potential of this system as a therapeutic target. In the present study, we aimed to identify a promoter sequence capable of regulating cell-type specific transgene expression from an adeno-associated viral (AAV) vector in relaxin-3 neurons of the rat nucleus incertus (NI). In parallel to relaxin-3 promoter sequences, we also tested an AAV vector containing promoter elements for the tropomyosin receptor kinase A (TrkA) gene, as TrkA is co-expressed with relaxin-3 in rat NI neurons. Stereotaxic injection of an mCherry-expressing AAV vector revealed widespread non-specific TrkA promoter (880 bp) activity in and adjacent to the NI at 8 weeks post-treatment. In contrast, mCherry expression was successfully restricted to relaxin-3 NI neurons with 98% specificity using a 1736 bp relaxin-3 promoter. In addition to detailed anatomical mapping of NI relaxin-3 networks, illustrated here in association with GABAergic medial septum neurons, this method for targeted transgene delivery offers a versatile tool for ongoing preclinical studies of relaxin-3 circuitry.",science
10.1016/j.jep.2020.112670,Journal,Journal of Ethnopharmacology,scopus,2020-05-23,sciencedirect,Effect of Anoectochilus roxburghii flavonoids extract on H<inf>2</inf>O<inf>2</inf> - Induced oxidative stress in LO2 cells and D-gal induced aging mice model,https://api.elsevier.com/content/abstract/scopus_id/85081986322,"Ethnopharmacological relevance
                  Anoectochilus roxburghii (A. roxburghii) is a popular folk medicine in many Asian countries, which has been used traditionally for treatment of some diseases such as diabetes, tumors, hyperlipemia, and hepatitis. The ethanol extract from A. roxburghii was recently shown to exert better ability to scavenge free radicals in vitro and possess antioxidant on natural aging mice in vivo.
               
                  Aim of the study
                  This study is to characterize the chemical composition, and investigate the protective effect of the A. roxburghii flavonoids extract (ARF) against hydrogen peroxide (H2O2)-induced oxidative stress in LO2 cells in vitro and D-galactose (D-gal)-induced aging mice model in vivo, and explore the underlying mechanisms.
               
                  Materials and methods
                  The chemical components of the flavonoids extract from 
                     A. roxburghii were detected by ultraperformance lipid chromatography coupled with quadrupole-time-of-flight mass spectrometry (UPLC-QTOF-MS/MS). H2O2 was used to establish an oxidative stress model in LO2 cells. Cytotoxic and protective effects of ARF on the LO2 cells were determined using 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT) method. Moreover, the levels of superoxide dismutase (SOD), glutathione peroxidase (GSH-PX), and malondialdehyde (MDA) in cell supernatants were measured by commercial reagent kits. Kun-Ming mice were induced to aging with D-gal (400 mg/kg, BW) by subcutaneous injection for 58 days. From the 28th day to the 58th day of D-gal treatment, ARF (122.5, 245 and 490 mg/kg, BW) and vitamin E (100 mg/kg, BW) were orally administrated to aging mice once a day for consecutive 30 days. After 25 days of the treatment with ARF, learning and memory were assessed using Morris Water Maze (MWM). At the end of the test period, the animals were euthanized by cervical dislocation, and the levels of SOD, GSH-PX, and MDA in serum, liver homogenates and brain homogenates were measured. The levels of monoamine oxidase (MAO) and acetylcholinesterase (AchE) were determined in brain homogenates. Skin and liver histopathological morphology were observed by H&E staining. Furthermore, antioxidant-related gene expression levels in the liver were carried out by quantitative real-time polymerase chain reaction (qRT-PCR).
               
                  Results
                  Nine flavonoids were identified in the extracts of A. roxburghii. In vitro assay, a high concentration of ARF (>612.5 μg/ml) reduced the survival rate and had toxic effects on LO2 cells. In addition, ARF (245 μg/ml, 490 μg/ml) and Vitamin C (200 μg/ml) markedly inhibited generations of MDA and increased activities of SOD, GSH-PX in H2O2-induced LO2 cells supernatants. In vivo assay, ARF (122.5 mg/kg, 245 mg/kg and 490 mg/kg) and Vitamin E (100 mg/kg) not only ameliorated learning and memory ability but also improved skin and liver pathological alterations. Strikingly, ARF significantly decreased MDA and MAO levels, markedly enhanced antioxidant enzyme (SOD and GSH-PX) activities. Further, compared to the D-gal group, ARF could obviously up-regulate glutathione peroxidase-1 (GPx-1) and glutathione peroxidase-4 (GPx-4) mRNA levels.
               
                  Conclusions
                  These findings suggested that ARF protects LO2 cells against H2O2-induced oxidative stress and exerts the potent anti-aging effects in D-gal aging mice model, which may be related to the inhibition of oxidative stress. Flavonoid compounds may contribute to the anti-oxidative capability and modulating aging.",science
10.1016/j.jep.2020.112681,Journal,Journal of Ethnopharmacology,scopus,2020-05-23,sciencedirect,Antrodin A from mycelium of Antrodia camphorata alleviates acute alcoholic liver injury and modulates intestinal flora dysbiosis in mice,https://api.elsevier.com/content/abstract/scopus_id/85081368298,"Ethnopharmacological relevance
                  
                     Antrodia camphorata (A. camphorata) is a rare functional fungus in Taiwan and contains a variety of biologically active ingredients. Antrodin A (AdA) is one of the main active ingredients in the solid-state fermented A. camphorata mycelium. It protects the liver from alcohol damage by improving the antioxidant and anti-inflammatory capacity of the liver and maintaining the stability of the intestinal flora.
               
                  Aim of the study
                  The aim of this study was to evaluate the hepatoprotective activities of ethyl acetate layer extract (EALE), AdA, and Antroquinonol (Aq) from mycelium of A. camphorata on alcoholic liver injury.
               
                  Materials and methods
                  Mice were given with intragastrically vehicle (NC, 2% CMC-Na), alcohol (AL, 12 mL/kg bw), or different A. camphorata samples (EALE, AdA, Aq) at low (100 mg/kg bw) or high (200 mg/kg bw) dosages. The positive control (PC) group was given with silymarin (200 mg/kg bw). Except the NC group, each group of mice was fasted for 4 h after the last treatment and was intragastrically administrated with 50% alcohol (12 mL/kg bw). At the end of experiment, mouse serum was collected and the liver was excised. A portion of the liver was fixed in formalin and used for histopathological analysis, whereas the rest was used for biochemical analysis and real-time PCR analysis. The intestinal flora structure of feces was analyzed by determining the v3-v4 region sequence in 16S rDNA.
               
                  Results
                  The high-dose groups of the three samples (EALEH, AdAH, and AqH) significantly alleviated the alcohol-induced increases in liver index, serum ALT, AST, and AKP activities. Serum TG level was significantly reduced in all treatment groups. The increase of HDL-C content indicated that active ingredients of A. camphorata could reduce the lipid content in serum. Furthermore, MDA contents of the AdAH and AqH groups in liver were significantly reduced, accompanying with the levels of SOD, CAT, and GSH elevated to various extents. Antioxidant and anti-inflammatory capabilities in the liver were increased in the AdAH group, as evidenced by the mRNA expression levels of Nrf-2 and HO-1 were significantly increased; while those of CYP2e1, TNF-α, and TLR-4 were significantly decreased. Analysis of intestinal flora of feces showed that alcohol treatment significantly changed the composition of intestinal flora. Supplementation with AdA could mitigate dysbiosis of intestinal flora induced by alcohol. Flora of Faecalibaculum, Lactobacillus, and Coriobacteriaceae_UCG-002 showed significantly negative correlations with ALT, AST, AKP, and MDA levels.
               
                  Conclusion
                  Antrodin A could improve the antioxidant and anti-inflammatory capacities of the liver and maintain the stability of intestinal flora. It is potentially a good candidate compound against acute alcoholic liver injury.",science
10.1016/j.knosys.2020.105786,Journal,Knowledge-Based Systems,scopus,2020-05-21,sciencedirect,On modeling and predicting popularity dynamics via integrating generative model and rich features,https://api.elsevier.com/content/abstract/scopus_id/85082817336,"Understanding the mechanisms governing how an online message acquires more popularity than another, modeling how it gains popularity dynamically, and determining the method for predicting its dynamics popularity are of tremendous interest to related decision support systems. However, one major limitation of existing generative dynamics models is that the learning parameters are difficult to interpret and it is unclear whether it can be generalized for other messages, as they are trained for different messages independently and the feature data-based connections between messages are ignored. To alleviate the defects, we first perform experiments on real-world data from Sina Weibo to identify the general correlation between the dynamics model and rich features of online messages. Consequently, we present a novel feature-regularized dynamics model based on reinforced Poisson process (FRRPP), which regulates the parameter learning of popularity dynamics by integrating a feature regression term to capture the revealed correlation across online posts. Specifically, in addition to the objective of the maximum likelihood function, we assume that the competitiveness parameter of the different posts can be predicted by rich features, to enhance the explicability and generality of the point-process model and learn the dynamics process of different posts together. The proposed model is then evaluated on two real Sina Weibo datasets, and conclusive experimental results indicate that the proposed model achieves a remarkable improvement over baseline methods in terms of MAPE and Accuracy with various settings, which further verifies our findings about how to improve the generality of popularity dynamics modeling and prediction.",science
10.1016/j.cels.2020.04.006,Journal,Cell Systems,scopus,2020-05-20,sciencedirect,Lattice Light-Sheet Microscopy Multi-dimensional Analyses (LaMDA) of T-Cell Receptor Dynamics Predict T-Cell Signaling States,https://api.elsevier.com/content/abstract/scopus_id/85084658613,"Lattice light-sheet microscopy provides large amounts of high-dimensional, high-spatiotemporal resolution imaging data of cell surface receptors across the 3D surface of live cells, but user-friendly analysis pipelines are lacking. Here, we introduce lattice light-sheet microscopy multi-dimensional analyses (LaMDA), an end-to-end pipeline comprised of publicly available software packages that combines machine learning, dimensionality reduction, and diffusion maps to analyze surface receptor dynamics and classify cellular signaling states without the need for complex biochemical measurements or other prior information. We use LaMDA to analyze images of T-cell receptor (TCR) microclusters on the surface of live primary T cells under resting and stimulated conditions. We observe global spatial and temporal changes of TCRs across the 3D cell surface, accurately differentiate stimulated cells from unstimulated cells, precisely predict attenuated T-cell signaling after CD4 and CD28 receptor blockades, and reliably discriminate between structurally similar TCR ligands. All instructions needed to implement LaMDA are included in this paper.",science
10.1016/j.enbuild.2020.109825,Journal,Energy and Buildings,scopus,2020-05-15,sciencedirect,Building temperature regulation in a multi-zone HVAC system using distributed adaptive control,https://api.elsevier.com/content/abstract/scopus_id/85081129562,"During recent years there have been considerable research efforts on improving energy efficiency of buildings. Since Heating, Ventilation and Air-Conditioning (HVAC) systems are responsible for a big part of energy consumption, developing efficient HVAC control systems is crucial. In most of the developed approaches, precise knowledge of system parameters and/or adequate historical data is required. However, these approaches may not perform as well in the presence of dynamic parameter changes due to human activity, material degradation, and wear and tear, or disturbances and other operational uncertainties due to occupancy, solar gains, electrical equipment, and weather conditions. In this paper, we consider buildings with several climate zones and propose a distributed adaptive control scheme for a multi-zone HVAC system which can effectively regulate zone temperature by applying on-line learning and assuming exchange of information between neighboring zones. The controller of each zone achieves the local objective of controlling zone temperature by compensating for the effects of neighboring zones as well as for possible changes in the parameters of the system. Despite the exchange of information, each local controller does not know how the control actions and temperature of a neighboring zone affect the temperature of its own zone. For this reason, each local controller is estimating the parameters of the interconnections in real time and uses them together with the exchanged information to provide a more accurate local zone temperature control. The proposed method is illustrated using an example of temperature control in a six-zone building as well as a large school building, which are implemented in a Building Controls Virtual Test Bed (BCVTB) environment using EnergyPlus and MATLAB/Simulink.",science
10.1016/j.eswa.2020.113199,Journal,Expert Systems with Applications,scopus,2020-05-15,sciencedirect,Towards automatically filtering fake news in Portuguese,https://api.elsevier.com/content/abstract/scopus_id/85078194025,"In the last years, the popularity of smartphones and social networks has been contributing to the spread of fake news. Through these electronic media, this type of news can deceive thousands of people in a short time and cause great harm to individuals, companies, or society. Fake news has the potential to change a political scenario, to contribute to the spread of diseases, and even to cause deaths. Despite the efforts of several studies on fake news detection, most of them only cover English language news. There is a lack of labeled datasets of fake news in other languages and, moreover, important questions still remain open. For example, there is no consensus on what are the best classification strategies and sets of features to be used for automatic fake news detection. To answer this and other important open questions, we present a new public and real dataset of labeled true and fake news in Portuguese, and we perform a comprehensive analysis of machine learning methods for fake news detection. The experiments were performed using different sets of features and employing different types of classification methods. A careful analysis of the results provided sufficient evidence to respond appropriately to the open questions. The various evaluated scenarios and the drawn conclusions from the results shed light on the potentiality of the methods and on the challenges that fake news detection presents.",science
10.1016/j.patter.2020.100013,Journal,Patterns,scopus,2020-05-08,sciencedirect,Random Forest Models for Accurate Identification of Coordination Environments from X-Ray Absorption Near-Edge Structure,https://api.elsevier.com/content/abstract/scopus_id/85088690454,"Analyzing coordination environments using X-ray absorption spectroscopy has broad applications in solid-state physics and material chemistry. Here, we show that random forest models trained on 190,000 K-edge X-ray absorption near-edge structure (XANES) spectra can identify the main atomic coordination environment with a high accuracy of 85.4% and all associated coordination environments with a high Jaccard score of 81.8% for 33 cation elements in oxides, significantly outperforming other machine-learning models. In a departure from prior works, the coordination environment is described as a distribution over 25 distinct coordination motifs with coordination numbers ranging from 1 to 12. More importantly, we show that the random forest models can be used to predict coordination environments from experimental K-edge XANES with minimal loss in accuracy. A drop-variable feature importance analysis highlights the key roles that the pre-edge and main-peak regions play in coordination environment identification.",science
10.1016/j.metabol.2020.154205,Journal,Metabolism: Clinical and Experimental,scopus,2020-05-01,sciencedirect,Cholesterol induced autophagy via IRE1/JNK pathway promotes autophagic cell death in heart tissue,https://api.elsevier.com/content/abstract/scopus_id/85082464082,"Background
                  Cardiovascular diseases (CVDs), with highest mortality and morbidity rates, are the major cause of death in the world. Due to the limited information on heart tissue changes, mediated by hypercholesterolemia, we planned to investigate molecular mechanisms of endoplasmic reticulum (ER) stress and related cell death in high cholesterol fed rabbit model and possible beneficial effects of α-tocopherol.
               
                  Methods
                  Molecular changes in rabbit heart tissue and cultured cardiomyocytes (H9c2 cells) were measured by western blotting, qRT-PCR, immunflouresence and flow cytometry experiments. Histological modifications were assessed by light and electron microscopes, while degradation of mitochondria was quantified through confocal microscope.
               
                  Results
                  Feeding rabbits 2% cholesterol diet for 8 weeks and treatment of cultured cardiomyocytes with 10 μg/mL cholesterol for 3 h induced excessive autophagic activity via IRE1/JNK pathway. While no change in ER-associated degradation (ERAD) and apoptotic cell death were determined, electron and confocal microscopy analyses in cholesterol supplemented rabbits revealed significant parameters of autophagic cell death, including cytoplasmic autophagosomes, autolysosomes and organelle loss in juxtanuclear area as well as mitochondria engulfment by autophagosome. Either inhibition of ER stress or JNK in cultured cardiomyocytes or α-tocopherol supplementation in rabbits could counteract the effects of cholesterol.
               
                  Conclusion
                  Our findings underline the essential role of hypercholesterolemia in stimulating IRE1/JNK branch of ER stress response which then leads to autophagic cell death in heart tissue. Results also showed α-tocopherol as a promising regulator of autophagic cell death in cardiomyocytes.",science
10.1016/j.urolonc.2020.02.021,Journal,Urologic Oncology: Seminars and Original Investigations,scopus,2020-05-01,sciencedirect,The role of cancer stem cells in immunotherapy for bladder cancer: An in vitro study,https://api.elsevier.com/content/abstract/scopus_id/85081732654,"Objective
                  Bladder cancer is characterized by frequent recurrence and progression. CD44+ cancer stem cells (CSCs) might be one of the main reasons for recurrence. Although Bacillus Calmette Guerin (BCG) has become a gold standard immunotherapy, after treatment recurrence frequently occur. Based on this knowledge, the aim of this study was to evaluate the changes in cytokine and chemokine expressions in bladder cancer and CSCs cultures in vitro with BCG only and in combination with IL2 and lymphocyte (MNCs) applications.
               
                  Material and methods
                  In this study, 3 cell lines of human bladder cancer cells with different characteristics (T24, 5637, and JMSU-1) and CD44+ bladder CSCs isolated by magnetic bead isolation (Miltenyl Magtech) were used. Bladder cancer cell lines and bladder CSCs in complete medium were cultured under humidified conditions of 37°C temperature in 5% CO2. BCG only and its combination with IL2 and MNCs were applied to bladder cancer cell lines and bladder CSCs for 24, 48, and 72 hours. Annexin V-PI was used to detect the percentages of apoptotic and necrotic cells in treatment groups and control groups. After treatments, total RNAs were isolated and converted to cDNA for each group and controls. Quantitative fold changes in terms of gene expression were measured by RT2–PCR array and fold changes for expression levels of genes were compared among groups. Eighty-four genes were analyzed in standard array of chemokines and cytokines (Biorad).
               
                  Results
                  BCG treatment with 7.32 µg/ml dose alone and in combination with IL2 (1000 IU/ml) and MNCs (1000 cells/ml) were found to be most effective on bladder cancer cells. When BCG and its combinations were applied to CSCs of the 3 cell lines, BCG treatment showed cytotoxic effect on CSCs as well as cancer cells. CSCs of 3 cell lines over expressed CXCL5, CCL8, CNTF, and CSF2 compared with cancer cells. Cancer cells over expressed IL6, TNSFF11, FASLG, and CXCL9 compared with CSCs. In all 3 cell lines, BCG application increased expression of CXCL5 and LTB and also decreased CCL20 and IL6. When BCG was combined with IL2 and MNCs, CXCL10, CXCL5, and IFNG were increased and CXCL12, IL6, and TNSF11 were decreased. BCG treatment of CSCs caused increases in ADIPOQ, CXCL10, and XCL1 and a decrease in CCL8. When IL2 and MNCs were combined with BCG, the expression of many cytokines and chemokines decreased.
               
                  Conclusion
                  BCG treatment changes the expression of many cytokines and chemokines in bladder cancer. The expression differs in 3 different cell lines and their CSCs. Immune modulation of each case differs from each other. The effectivity of BCG-based immunotherapy in bladder cancer on CSCs might decrease in combination with IL2. Our results indicate that recurrence after BCG treatment for bladder cancer may not occur mainly based on the CSCs hypothesis considering bladder cancer occurs at different loci of surface epithelium.",science
10.1016/j.envres.2020.109367,Journal,Environmental Research,scopus,2020-05-01,sciencedirect,Sonophotocatalytic treatment of AB113 dye and real textile wastewater using ZnO/persulfate: Modeling by response surface methodology and artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85081669370,"The present study investigates the synergistic performance of the sonophotolytic-activated ZnO/persulfate (US/UV/ZnO/PS) process in the decolorization of acid blue 113 (AB113) dye from aqueous solution and its feasibility for the treatment of real textile wastewater. Decolorization of AB113 solution was modeled by central composite design-response surface methodology (CCD-RSM) and artificial neural network (ANN) approaches and optimized by CCD-RSM and genetic algorithm (GA) approaches. Statistical metrics indicated that both CCD-RSM and ANN approaches seemed satisfactory. However, the results of statistical fit measures indicated a relative superiority of CCD-RSM as compared to the ANN approach. The results of optimization of the process parameters by CCD-RSM and GA approaches appeared to be similar as follows: pH = 6.1, reaction time = 25 min, US power density = 300 W/L, ZnO = 0.88 g/L and PS = 2.43 mmol/L. The synergistic effect of the hybrid US/UV/ZnO/PS process in comparison with its individual processes (US, UV, ZnO, and PS) was found to be 54.3%. Quenching experiments discovered that 
                        
                      and HO are the main oxidizing radicals in a mildly acidic condition of the reaction solution. The removal efficiency of AB113 in the presence of some anions decreased in the order of bicarbonate > sulfate > phosphate > nitrate > chloride. Further, the reusability feasibility of ZnO showed that the ZnO material retained its photocatalytic property after five successive cycles of reusability test, while Zn2+ ion concentration in the reaction solution was measured to be 2.81 mg/L. The findings also indicated that the integrated process application suppresses extremely chemical and electrical costs. The study of the feasibility of the US/UV/ZnO/PS process in the treatment of real textile wastewater was done by determining COD, TOC and BOD5/COD ratio. Results demonstrated that the 96.6 and 97.1% reduction of COD and TOC was achieved after 5 and 7 h reaction time, respectively. The obtained BOD5/COD ratio changed from about 0.15 (for non-treated wastewater) to about 0.61 with increasing reaction time from zero to 90 min. In conclusion, the hybrid US/UV/ZnO/PS system can be proposed as a novel and promising approach to be utilized as a pretreatment technique before a biological treatment process to facilitate the biological treatment of recalcitrant textile wastewater.",science
10.1016/j.rse.2020.111717,Journal,Remote Sensing of Environment,scopus,2020-05-01,sciencedirect,Assessing the relationship between macro-faunal burrowing activity and mudflat geomorphology from UAV-based Structure-from-Motion photogrammetry,https://api.elsevier.com/content/abstract/scopus_id/85079899077,"Characterisation of the ecosystem functioning of mudflats requires insight on the morphology and facies of these coastal features, but also on biological processes that influence mudflat geomorphology, such as crab bioturbation and the formation of benthic biofilms, as well as their heterogeneity at cm or less scales. Insight into this fine scale of ecosystem functioning is also important as far as minimizing errors in upscaling are concerned. The realisation of high-resolution ground surveys of these mudflats without perturbing their surface is a real challenge. Here, we address this challenge using UAV-supported photogrammetry based on the Structure-from-Motion (SfM) workflow. We produced a Digital Surface Model (DSM) and an orthophotograph at 1 cm and 0.5 cm pixel resolutions, respectively, of a mudflat in French Guiana, and mapped and classed into different size ranges intricate morphological features, including crab burrow apertures, tidal drainage creeks and depressions. We also determined subtle facies and elevation changes and slopes, and the footprint of different degrees of benthic biofilm development. The results generated at this scale of photogrammetric analysis also enabled us to relate macrofaunal crab burrowing activity to various parameters, including mudflat elevation, spatial distribution and sizes of creeks and depressions, benthic biofilm distribution, and flooding duration. SfM photogrammetry offers interesting new perspectives in fine-scale characterisation of the geomorphology, benthic activity and degree of biofilm development of dynamic muddy intertidal environments that are generally difficult of access. The main shortcomings highlighted in this study are a drift of accuracy of the DSM outside areas of ground control points and the deployment of which perturb the mudflat morphology and biology, the water-logged or very wet surfaces which generate reconstruction artefacts through the sun glint effect, and the time-consuming task of manual interpretation of extraction of features such as crab burrow apertures. On-going developments in UAV positioning integrating RTK/PPK GPS solutions for image-georeferencing and precise orientation with high-quality inertial measurement units will limit the difficulties inherent to ground control points, while conduction of surveys during homogeneous cloudy conditions could reduce the sun-glint effect. Manual extraction of image features could be automated in the future through the use of deep-learning algorithms.",science
10.1016/j.neunet.2020.02.001,Journal,Neural Networks,scopus,2020-05-01,sciencedirect,Preserving differential privacy in deep neural networks with relevance-based adaptive noise imposition,https://api.elsevier.com/content/abstract/scopus_id/85079858482,"In recent years, deep learning achieves remarkable results in the field of artificial intelligence. However, the training process of deep neural networks may cause the leakage of individual privacy. Given the model and some background information of the target individual, the adversary can maliciously infer the sensitive feature of the target individual. Therefore, it is imperative to preserve the sensitive information in the training data. Differential privacy is a state-of-the-art paradigm for providing the privacy guarantee of datasets, which protects the private and sensitive information from the attack of adversaries significantly. However, the existing privacy-preserving models based on differential privacy are less than satisfactory since traditional approaches always inject the same amount of noise into parameters to preserve the sensitive information, which may impact the trade-off between the model utility and the privacy guarantee of training data. In this paper, we present a general differentially private deep neural networks learning framework based on relevance analysis, which aims to bridge the gap between private and non-private models while providing an effective privacy guarantee of sensitive information. The proposed model perturbs gradients according to the relevance between neurons in different layers and the model output. Specifically, during the process of backward propagation, more noise is added to gradients of neurons that have less relevance to the model output, and vice-versa. Experiments on five real datasets demonstrate that our mechanism not only bridges the gap between private and non-private models, but also prevents the disclosure of sensitive information effectively.",science
10.1016/j.ijmultiphaseflow.2019.103194,Journal,International Journal of Multiphase Flow,scopus,2020-05-01,sciencedirect,Bubble patterns recognition using neural networks: Application to the analysis of a two-phase bubbly jet,https://api.elsevier.com/content/abstract/scopus_id/85079560188,"Gas-liquid two-phase bubbly flows are found in different areas of science and technology such as nuclear energy, chemical industry, or piping systems. Optical diagnostics of two-phase bubbly flows with modern panoramic techniques makes it possible to capture simultaneously instantaneous characteristics of both continuous and dispersed phases with a high spatial resolution. In this paper, we introduce a novel approach based on neural networks to recognize bubble patterns in images and identify their geometric parameters. The originality of the proposed method consists in training of a neural network ensemble using synthetic images that resemble real photographs gathered in experiment. The use of neural networks in combination with automatically generated data allowed us to detect overlapping, blurred, and non-spherical bubbles in a broad range of volume gas fractions. Experiments on a turbulent bubbly jet proved that the implemented method increases the identification accuracy, reducing errors of various kinds, and lowers the processing time compared to conventional recognition methods. Furthermore, utilizing the new method of bubbles recognition, the primary physical parameters of a dispersed phase, such as bubble size distribution and local gas content, were calculated in a near-to-nozzle region of the bubbly jet. The obtained results and integral experimental parameters, especially volume gas fraction, are in good agreement with each other.",science
10.1016/j.ijfatigue.2019.105458,Journal,International Journal of Fatigue,scopus,2020-05-01,sciencedirect,Steel railway bridge fatigue damage detection using numerical models and machine learning: Mitigating influence of modeling uncertainty,https://api.elsevier.com/content/abstract/scopus_id/85077500262,"Stringer-to-floor beam connections were reported as one of the most fatigue-prone details in riveted steel railway bridges. To detect stiffness degradation that results from the initiation and growth of fatigue cracks, an automated damage detection framework was proposed by the authors (Eftekhar Azam et al., 2019; Rageh et al., 2018). The proposed method relies on Proper Orthogonal Decomposition (POD) and Artificial Neural Networks (ANNs) to identify damage location and intensity under non-stationary, unknown train loads. Bridge computational models were used to simulate damage scenarios and for training the ANNs. Damage detection method efficiency and accuracy were shown to be significantly influenced by the level of modeling uncertainties (MUs). To investigate the applicability of the proposed framework to in-service bridges, a systematic analysis of the effect of MUs on the proposed POD-ANN framework was necessary. MU influence on the performance of the POD-ANN damage detection method was investigated and a new procedure for generating training data for ANNs was proposed. The procedure was based on synergizing Proper Orthogonal Modes (POMs) extracted from measured structural response and POMs calculated from the numerical model. The current study integrated numerical and field investigations. The main objective of the numerical investigation was to identify a robust damage feature independent of the level and location of assumed MUs. Results showed that Damage Location (DL) and Damage Intensity (DI) were detected with high accuracy for studied uncertainty cases; however, as expected, damage detection accuracy reduced as MU increased. A hybrid experimental-numerical approach was then implemented for the field investigation studies. This approach applied identified damage features from the numerical investigation to measurements from an in-service railway bridge to produce damage scenarios used to train the framework. MATLAB algorithms were developed that preprocessed field data and eliminated POM variations resulted from loading uncertainties. ANNs were trained and tested using the field strain estimated POMs from the hybrid approach and DL and DI results were obtained for the studied railway bridge under non-stationary, unknown train loads. These results show the promise of the POD-ANN method as a robust, real-time fatigue damage identification tool for steel railway bridges.",science
10.1016/j.ygeno.2019.12.005,Journal,Genomics,scopus,2020-05-01,sciencedirect,Discovery and annotation of novel microRNAs in the porcine genome by using a semi-supervised transductive learning approach,https://api.elsevier.com/content/abstract/scopus_id/85076485820,"Despite the broad variety of available microRNA (miRNA) prediction tools, their application to the discovery and annotation of novel miRNA genes in domestic species is still limited. In this study we designed a comprehensive pipeline (eMIRNA) for miRNA identification in the yet poorly annotated porcine genome and demonstrated the usefulness of implementing a motif search positional refinement strategy for the accurate determination of precursor miRNA boundaries. The small RNA fraction from gluteus medius skeletal muscle of 48 Duroc gilts was sequenced and used for the prediction of novel miRNA loci. Additionally, we selected the human miRNA annotation for a homology-based search of porcine miRNAs with orthologous genes in the human genome. A total of 20 novel expressed miRNAs were identified in the porcine muscle transcriptome and 27 additional novel porcine miRNAs were also detected by homology-based search using the human miRNA annotation. The existence of three selected novel miRNAs (ssc-miR-483, ssc-miR484 and ssc-miR-200a) was further confirmed by reverse transcription quantitative real-time PCR analyses in the muscle and liver tissues of Göttingen minipigs. In summary, the eMIRNA pipeline presented in the current work allowed us to expand the catalogue of porcine miRNAs and showed better performance than other commonly used miRNA prediction approaches. More importantly, the flexibility of our pipeline makes possible its application in other yet poorly annotated non-model species.",science
10.1016/j.cmpb.2019.105263,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-05-01,sciencedirect,Parallelized collision detection with applications in virtual bone machining,https://api.elsevier.com/content/abstract/scopus_id/85076248977,"Background and objectives
                  Virtual reality surgery simulators have been proved effective for training in several surgical disciplines. Nevertheless, this technology is presently underutilized in orthopaedics, especially for bone machining procedures, due to the limited realism in haptic simulation of bone interactions. Collision detection is an integral part of surgery simulators and its accuracy and computational efficiency play a determinant role on the fidelity of simulations. To address this, the primary objective of this study was to develop a new algorithm that enables faster and more accurate collision detection within 1 ms (required for stable haptic rendering) in order to facilitate the improvement of the realism of virtual bone machining procedures.
               
                  Methods
                  The core of the developed algorithm is constituted by voxmap point shell method according to which tool and osseous tissue geometries were sampled by points and voxels, respectively. The algorithm projects tool sampling points into the voxmap coordinates and compute an intersection condition for each point-voxel pair. This step is massively parallelized using Graphical Processing Units and it is further accelerated by an early culling of the unnecessary threads as instructed by the rapid estimation of the possible intersection volume. A contiguous array was used for implicit definition of voxmap in order to guarantee a fast access to voxels and thereby enable efficient material removal. A sparse representation of tool points was employed for efficient memory reductions. The effectiveness of the algorithm was evaluated at various bone sampling resolutions and was compared with prior relevant implementations.
               
                  Results
                  The results obtained with an average hardware configuration have indicated that the developed algorithm is capable to reliably maintain < 1 ms running time in severe tool-bone collisions, both sampled at 10243 resolutions. The results also showed the algorithm running time has a low sensitivity to bone sampling resolution. The comparisons performed suggested that the proposed approach is significantly faster than comparable methods while relying on lower or similar memory requirements.
               
                  Conclusions
                  The algorithm proposed through this study enables a higher numerical efficiency and is capable to significantly enlarge the maximum resolution that can be used by high fidelity/high realism haptic simulators targeting surgical orthopaedic procedures.",science
10.1016/j.chroma.2019.460840,Journal,Journal of Chromatography A,scopus,2020-04-26,sciencedirect,Carbon nanotube sponges as an enrichment material for aromatic volatile organic compounds,https://api.elsevier.com/content/abstract/scopus_id/85077755121,"Sensitive methods are required for in situ monitoring of volatile organic compounds (VOCs). Herein, carbon nanotube (CNT) sponges were investigated as a new type of adsorbent for enriching trace aromatic VOCs. A square pillar configuration (3 mm × 3 mm × 45 mm, 5 mg) of a CNT sponge was enclosed in a glass tube (4 mm i.d.). After accumulating the sample vapor, a direct current pulse (26 V, 0.5–3.0 s) through the CNT sponge allowed narrow desorption bandwidths of 0.48−0.84 s (with a photoionization detector) and 1.2 s (with a flame ionization detector) and high desorption efficiency (>96.5%). Gas chromatographic analysis of a nine-component VOC mixture (100 mL adsorption volume) gave enrichment factors of 88 (benzene) to 323 (toluene and m-xylene) with detection limits in the range of 0.9−2.6 ppb (v/v). These results demonstrate that CNT sponges are a promising preconcentrator material for trace detection of VOCs. The adsorption breakthrough experiments exhibited good correlation with the kinetic adsorption and Langmuir isotherm models. The maximum adsorption capacities of the CNT sponge increased in the order benzene (0.13 mg/g) < toluene (2.45 mg/g) < ethylbenzene (13.90 mg/g) < o-xylene (14.31 mg/g), with R
                     2 values of >0.95. The rollup phenomena observed during multicomponent adsorption were explained by the competitive displacement or adsorption affinities of aromatic VOCs. The feasibility of the CNT sponge preconcentrator in a real environment was tested for interfering species (NO2 and NH3), laboratory air, and a human breath sample and demonstrated similar performance as in the controlled nine-component tests.",science
10.1016/j.aca.2020.02.004,Journal,Analytica Chimica Acta,scopus,2020-04-22,sciencedirect,DNA aptamer-based non-faradaic impedance biosensor for detecting E. coli,https://api.elsevier.com/content/abstract/scopus_id/85079432760,"Developing a real-time, portable, and inexpensive sensor for pathogenic bacteria is crucial since the conventional detection approaches such as enzyme-linked immunosorbent assay (ELISA) and polymerase chain reaction (PCR) assays are high cost, time-consuming, and require an expert operator. Here we present a portable, inexpensive, and convenient impedance-based biosensor using Interdigitated Electrode (IDE) arrays to detect Escherichia coli (E. coli) as a model to demonstrate the feasibility of an impedance-based biosensor. We manipulated the affinity of the IDE array towards E. coli (E. coli BL21 series) by functionalizing the IDEs’ surface with an E. coli outer membrane protein (OMP) Ag1 Aptamer. To determine the dominant factors affecting the sensitivity and the performance of the biosensor in detecting E. coli, we investigated the roles of the substrate material used in the fabrication of the IDE, the concentration of the aptamer, and the composition of the carboxy aliphatic thiol mixture used in the pre-treatment of the IDE surface. In the sensing experiments we used an E. coli concentration range of 25–1000 cfu mL−1 and confirmed the binding of the OMP Ag1 Aptamer to the outer membrane protein of the E. coli by Field Emission Scanning Electron Microscopy (FESEM), Optical Microscopy, and Atomic Force Microscopy (AFM). By tuning the surface chemistry, the IDEs’ substrate material, and the concentration of the OMP Ag1 Aptamer, our sensor could detect E. coli with the analytical sensitivity of approximately 1.8 Ohm/cfu and limit of detection of 9 cfu mL−1. We found that the molecular composition of the self-assembled monolayer (SAM) formed on the top of the IDEs before the attachment of the OMP Ag1 Aptamer significantly impacted the sensitivity of the sensor. Notably, with straightforward changes to the molecular recognition elements, this platform device can be used to detect a wide range of other microorganisms and chemicals relevant for environmental monitoring and public health.",science
10.1016/j.knosys.2020.105580,Journal,Knowledge-Based Systems,scopus,2020-04-22,sciencedirect,Finding influential nodes in social networks based on neighborhood correlation coefficient,https://api.elsevier.com/content/abstract/scopus_id/85078759029,"Finding the most influential nodes in social networks has significant applications. A number of methods have been recently proposed to estimate influentiality of nodes based on their structural location in the network. It has been shown that the number of neighbors shared by a node and its neighbors accounts for determining its influence. In this paper, an improved cluster rank approach is presented that takes into account common hierarchy of nodes and their neighborhood set. A number of experiments are conducted on synthetic and real networks to reveal effectiveness of the proposed ranking approach. We also consider ground-truth influence ranking based on Susceptible–Infected–Recovered model, on which performance of the proposed ranking algorithm is verified. The experiments show that the proposed method outperforms state-of-the-art algorithms.",science
10.1016/j.jpowsour.2020.227964,Journal,Journal of Power Sources,scopus,2020-04-15,sciencedirect,Data-driven reinforcement-learning-based hierarchical energy management strategy for fuel cell/battery/ultracapacitor hybrid electric vehicles,https://api.elsevier.com/content/abstract/scopus_id/85080125591,"A reinforcement-learning-based energy management strategy is proposed in this paper for managing energy system of Fuel Cell Hybrid Electric Vehicles (FCHEV) equipped with three power sources. A hierarchical power splitting structure is employed to shrink large state-action space based on an adaptive fuzzy filter. Then, the reinforcement-learning-based algorithm using Equivalent Consumption Minimization Strategy (ECMS) is proposed for tackling high-dimensional state-action space, and finding a trade-off between global learning and real-time implementation. The power splitting policy based on experimental data is obtained by using reinforcement learning algorithm, which allows for many different driving cycles and traffic conditions. The proposed energy management strategy can achieve low computation cost, optimal fuel cell efficiency and energy consumption economy. Simulation results confirm that, compared with existing learning algorithms and optimization methods, the proposed reinforcement-learning-based energy management strategy using ECMS can achieve high computation efficiency, lower power fluctuation of fuel cell and optimal fuel economy of FCHEV.",science
10.1016/j.ijpharm.2020.119137,Journal,International Journal of Pharmaceutics,scopus,2020-04-15,sciencedirect,Topical delivery of niacinamide: Influence of neat solvents,https://api.elsevier.com/content/abstract/scopus_id/85080025811,"Niacinamide (NIA) has been widely used in cosmetic and personal care formulations for several skin conditions. Permeation of topical NIA has been confirmed in a number of studies under infinite dose conditions. However, there is limited information in the literature regarding permeation of NIA following application of topical formulations in amounts that reflect the real-life use of such products by consumers. The aim of the present work was therefore to investigate skin delivery of NIA from single solvent systems in porcine skin under finite dose conditions. A secondary aim was to probe the processes underlying the previously reported low recovery of NIA following in vitro permeation and mass balance studies. The solubility and stability of NIA in various single solvent systems was examined. The solvents investigated included Transcutol® P (TC), propylene glycol (PG), 1–2 hexanediol (HEX), 1–2 pentanediol (1-2P), 1–5 pentanediol (1-5P), 1–3 butanediol (1-3B), glycerol (GLY) and dimethyl isosorbide (DMI). Skin permeation and deposition of the molecule was investigated in full thickness porcine skin in vitro finite dose Franz-type diffusion experiments followed by mass balance studies. Stability of NIA for 72 h in the solvents was confirmed. The solubility of NIA in the solvents ranged from 82.9 ± 0.8 to 311.9 ± 4.5 mg/mL. TC delivered the highest percentage permeation of NIA at 24 h, 32.6 ± 12.1% of the applied dose. Low total recovery of NIA after mass balance studies was observed for some vehicles, with values ranging from 55.2 ± 12.8% to 106.3 ± 2.3%. This reflected the formation of a number of NIA degradation by-products in the receptor phase during the permeation studies. Identification of other vehicles for synergistic enhancement of NIA skin delivery will be the subject of future work.",science
10.1016/j.apenergy.2020.114680,Journal,Applied Energy,scopus,2020-04-15,sciencedirect,Household standards and socio-economic aspects as a factor determining energy consumption in the city,https://api.elsevier.com/content/abstract/scopus_id/85079833073,"Political or economic attempts to mitigate climate change by increasing fossil fuel prices lead to and an increase in energy poverty, i.e., social effects. The ideal solution would be to combine modernisation activities in terms of energy use in cities with sustainable strategies and redevelopment policies. The article's purpose is to estimate the potential for reducing energy consumption depending on socioeconomic factors (household standard and its location in the city) based on built-in scenarios and searching for the optimal way of conducting development policy at the local level. This assumption enables the implementation of the European Union climate policy. To this aim, modelling based on real and estimated data on the diversity of energy consumption in the structure of a medium-sized city in Europe (Zielona Góra) carried out. While creating scenarios, there used a modelling method based on radial artificial neural networks, which map the input set into the output set by matching many individual approximating functions to setpoints. This approach works well for data whose geolocation is in the city quarters. As a result of the simulations, the minimum and maximum achievable energy saving potential for low-intensity buildings in the quarters was estimated, taking into account the possibilities of investing in renewable energy by individual households. The observations included in the article may be relevant to other regions that are interested in reducing the energy consumption of buildings and pollution emissions from the cities. This is particularly important for the regions of Europe that benefit from the financial support of the European Union (including local development programmes based on financing European priority axes for economic development).",science
10.1016/j.jhazmat.2020.122032,Journal,Journal of Hazardous Materials,scopus,2020-04-15,sciencedirect,Reducing residual antibiotic levels in animal feces using intestinal Escherichia coli with surface-displayed erythromycin esterase,https://api.elsevier.com/content/abstract/scopus_id/85077918259,"Antibiotics are widely used in livestock and poultry industries, which results in large quantities of antibiotic residues in manure that influences subsequent treatments. In this study, an Escherichia coli strain was engineered to display erythromycin esterase on its cell surface. The engineered strain (E. coli ereA) efficiently degraded erythromycin by opening the macrocyclic 14-membered lactone ring in solution. Erythromycin (50 mg/L) was completely degraded in a solution by E. coli ereA (1 × 109 CFU/mL) within 24 h. E. coli ereA retained over 86.7 % of the initial enzyme activity after 40 days of storage at 25 °C, and 78.5 % of the initial activity after seven repeated batch reactions in solution at 25 °C. Mice were fed with E. coli ereA and real-time quantitative PCR data showed that E. coli ereA colonized in the mice large intestine. The mice group fed E. coli ereA exhibited 83.13 % decrease in erythromycin levels in their feces compared with the mice group not fed E. coli ereA. E. coli ereA eliminated antibiotics from the source preventing its release into the environment. The surface-engineered strain therefore is an effective alternative agent for treating recalcitrant antibiotics, and has the potential to be applied in livestock and poultry industries.",science
10.1016/j.cma.2019.112790,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-04-15,sciencedirect,"An energy approach to the solution of partial differential equations in computational mechanics via machine learning: Concepts, implementation and applications",https://api.elsevier.com/content/abstract/scopus_id/85077809695,"Partial Differential Equations (PDEs) are fundamental to model different phenomena in science and engineering mathematically. Solving them is a crucial step towards a precise knowledge of the behavior of natural and engineered systems. In general, in order to solve PDEs that represent real systems to an acceptable degree, analytical methods are usually not enough. One has to resort to discretization methods. For engineering problems, probably the best-known option is the finite element method (FEM). However, powerful alternatives such as mesh-free methods and Isogeometric Analysis (IGA) are also available. The fundamental idea is to approximate the solution of the PDE by means of functions specifically built to have some desirable properties. In this contribution, we explore Deep Neural Networks (DNNs) as an option for approximation. They have shown impressive results in areas such as visual recognition. DNNs are regarded here as function approximation machines. There is great flexibility to define their structure and important advances in the architecture and the efficiency of the algorithms to implement them make DNNs a very interesting alternative to approximate the solution of a PDE. We concentrate on applications that have an interest for Computational Mechanics. Most contributions explore this possibility have adopted a collocation strategy. In this work, we concentrate on mechanical problems and analyze the energetic format of the PDE. The energy of a mechanical system seems to be the natural loss function for a machine learning method to approach a mechanical problem. In order to prove the concepts, we deal with several problems and explore the capabilities of the method for applications in engineering.",science
10.1016/j.neucom.2019.11.095,Journal,Neurocomputing,scopus,2020-04-14,sciencedirect,TNAM: A tag-aware neural attention model for Top-N recommendation,https://api.elsevier.com/content/abstract/scopus_id/85077147580,"Recent work shows that incorporating tag information to recommender systems is promising for improving the recommendation accuracy in social systems. However, existing approaches suffer from less reasonable assignment of tag weights when constructing the user profiles and item characteristics in real-world scenarios, resulting in decreased accuracy in making recommendations. The above issue is specifically summarized into two aspects: 1) the weight of a target item is mainly determined by number of one certain type of tags, and 2) users place equal focus on the same tag for different items. To tackle these problems, we propose a novel model named TNAM, a Tag-aware Neural Attention Model, which accurately captures users’ special attention to tags of items. In the proposed model, we design a tag-based neural attention network by extracting potential tag information to overcome the difficulty of assigning tag weights for personalized users. We combine user-item interactions with tag information to map sparse data to dense vectors in higher-order space. In this way, TNAM acquires more interrelations between users and items to make recommendations more accurate. Extensive experiments of our model on three publicly implicit feedback datasets reveal significant improvements on the metrics of HR and NDCG in Top-N recommendation tasks over several state-of-the-art approaches.",science
10.1016/j.patter.2020.100006,Journal,Patterns,scopus,2020-04-10,sciencedirect,Intelligent Electromagnetic Sensing with Learnable Data Acquisition and Processing,https://api.elsevier.com/content/abstract/scopus_id/85089142867,"Electromagnetic (EM) sensing is a widespread contactless examination technique with applications in areas such as health care and the internet of things. Most conventional sensing systems lack intelligence, which not only results in expensive hardware and complicated computational algorithms but also poses important challenges for real-time in situ sensing. To address this shortcoming, we propose the concept of intelligent sensing by designing a programmable metasurface for data-driven learnable data acquisition and integrating it into a data-driven learnable data-processing pipeline. Thereby, a measurement strategy can be learned jointly with a matching data post-processing scheme, optimally tailored to the specific sensing hardware, task, and scene, allowing us to perform high-quality imaging and high-accuracy recognition with a remarkably reduced number of measurements. We report the first experimental demonstration of “learned sensing” applied to microwave imaging and gesture recognition. Our results pave the way for learned EM sensing with low latency and computational burden.",science
10.1016/j.jclepro.2019.119833,Journal,Journal of Cleaner Production,scopus,2020-04-10,sciencedirect,Optimization on cleaner intensification of ozone production using Artificial Neural Network and Response Surface Methodology: Parametric and comparative study,https://api.elsevier.com/content/abstract/scopus_id/85078769911,"Non-thermal microplasma is a promising technology for efficient ozone generation for water sterilization. However, there remains a niche to improve the energy efficiency of the production process. The studies investigating the combined effects of interacting parameters affecting ozone generation are scarce. Studying more than one parameter is a limitation using standard experimental protocols. However, modeling tools such as Response Surface Methodology and Artificial Neural Network provides an opportunity to study the interaction between parameters and propose a mathematical model to predict ozone concentration under various experimental conditions. A robust model providing an insight into parametric interaction and better forecasting can reduce the required power requirement making it cleaner and sustainable. In this study, a Dielectric Barrier Discharge-Corona hybrid plasma microreactor, combining the homogeneity of the former and high energy streamers of the latter, was used to investigate factors affecting ozone generation. Response Surface Methodology was used with Central Composite Design for experimental design. A model was developed for analyzing the correlation of parameters, evaluate complex interactions among independent factors and optimization. Artificial Neural Network model based on Feed-Forward Backpropagation Network was developed to predict the response. The results were compared with the mathematical models developed by Response Surface Methodology. To the best of our knowledge, a study on ozone generation and optimization in a Dielectric Barrier Discharge-Corona hybrid discharge reactor do not exist. Similarly, such a detailed analysis and comparison of Response Surface Methodology and Artificial Neural Network for ozone generation is reported for the first time. Ozone generation was favored at lower values of flow rate and pressure of air, frequency, and higher voltage and electrode length. Response Surface Methodology was found to have a lower value of R2 = 0.9348 as compared to Artificial Neural Network, i.e., R2 = 0.9965. Root Mean Square Error obtained from Response Surface Methodology (5.0737) is approximately four times higher as compared to Artificial Neural Network (1.1779). The results showed the Artificial Neural Network model is more reliable than the Response Surface Methodology to study the interacting parameters and prediction. The model could be related to the real-time experiments to predict the ozone concentration under various experimental conditions and make the sterilization process cleaner.",science
10.1016/j.knosys.2019.105301,Journal,Knowledge-Based Systems,scopus,2020-04-06,sciencedirect,Deep multi-granularity graph embedding for user identity linkage across social networks,https://api.elsevier.com/content/abstract/scopus_id/85076842314,"There have been increasing interests in user identity linkage (UIL) across social networks since it supports many applications such as cross-net recommendation, link prediction, and network fusion. Existing graph embedding based techniques cannot sufficiently model the higher-order structural properties in UIL. Moreover, the very limited supervisory anchor pairs (SAP), which are crucial for the task of UIL across social networks, are not utilized effectively. In this paper, a novel framework named multi-granularity graph embedding (MGGE) is proposed. And as an extension, a deep multi-granularity graph embedding model (DeepMGGE) is further developed. DeepMGGE uses the random walk (RW) to capture the higher-order structural proximities which is ignored by IONE Liu et al. (2016). Besides, DeepMGGE employs a heuristic edge-weighting mechanism given by deep learning to better capture the non-linear SAP-oriented structural properties. Experiments on real social networks demonstrate that the DeepMGGE outperforms state-of-the-art methods.",science
10.1016/j.drudis.2020.03.003,Journal,Drug Discovery Today,scopus,2020-04-01,sciencedirect,Machine learning models for drug–target interactions: current knowledge and future directions,https://api.elsevier.com/content/abstract/scopus_id/85081719171,"Predicting the binding affinity between compounds and proteins with reasonable accuracy is crucial in drug discovery. Computational prediction of binding affinity between compounds and targets greatly enhances the probability of finding lead compounds by reducing the number of wet-lab experiments. Machine-learning and deep-learning techniques using ligand-based and target-based approaches have been used to predict binding affinities, thereby saving time and cost in drug discovery efforts. In this review, we discuss about machine-learning and deep-learning models used in virtual screening to improve drug–target interaction (DTI) prediction. We also highlight current knowledge and future directions to guide further development in this field.",science
10.1016/j.engappai.2020.103539,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-04-01,sciencedirect,Fast and scalable algorithms for mining subgraphs in a single large graph,https://api.elsevier.com/content/abstract/scopus_id/85080078913,"Mining frequent subgraphs is an important issue in graph mining. It is defined as finding all subgraphs whose occurrences in the dataset are greater than or equal to a given frequency threshold. In recent applications, such as social networks, the underlying graphs are very large. Algorithms for mining frequent subgraphs from a single large graph have been developing rapidly lately. Among all such algorithms, GraMi is considered the state-of-the-art. However, GraMi still consumes a lot of time and memory in the mining of a large graph. In this paper, we propose two effective strategies to optimize the GraMi algorithm, which help to increase performance as well as reduce memory consumption during execution. Firstly, GraMi only lists all frequent subgraphs, without computing the support of each mined subgraph. This is disadvantageous in decision support systems, which require information about the support of all subgraphs. Therefore, we optimize GraMi to compute the support values during the mining process. Secondly, we apply the strategy of sorting all edges in graphs by their frequencies, which means that edges with low frequencies will be mined first, and vice versa. This sorting strategy can reduce the number of possibly infrequent subgraph candidates, especially on large subgraphs that are usually derived from those edges with high frequency. Thirdly, we apply a parallel processing technique, in which each frequent edge is executed simultaneously in a separate thread, and improve our parallel strategy by combination with the sorting strategy. Our experiments were performed on three real datasets and the results showed that the performance, as well as memory requirements, are better than those of the original GraMi algorithm",science
10.1016/j.cortex.2019.11.021,Journal,Cortex,scopus,2020-04-01,sciencedirect,Response patterns in the developing social brain are organized by social and emotion features and disrupted in children diagnosed with autism spectrum disorder,https://api.elsevier.com/content/abstract/scopus_id/85077919917,"Adults and children recruit a specific network of brain regions when engaged in “Theory of Mind” (ToM) reasoning. Recently, fMRI studies of adults have used multivariate analyses to provide a deeper characterization of responses in these regions. These analyses characterize representational distinctions within the social domain, rather than comparing responses across preferred (social) and non-preferred stimuli. Here, we conducted opportunistic multivariate analyses in two previously collected datasets (Experiment 1: n = 20 5–11 year old children and n = 37 adults; Experiment 2: n = 76 neurotypical and n = 29 5–12 year old children diagnosed with Autism Spectrum Disorder (ASD)) in order to characterize the structure of representations in the developing social brain, and in order to discover if this structure is disrupted in ASD. Children listened to stories that described characters' mental states (Mental), non-mentalistic social information (Social), and causal events in the environment (Physical), while undergoing fMRI. We measured the extent to which neural responses in ToM brain regions were organized according to two ToM-relevant models: 1) a condition model, which reflected the experimenter-generated condition labels, and 2) a data-driven emotion model, which organized stimuli according to their emotion content. We additionally constructed two control models based on linguistic and narrative features of the stories. In both experiments, the two ToM-relevant models outperformed the control models. The fit of the condition model increased with age in neurotypical children. Moreover, the fit of the condition model to neural response patterns was reduced in the RTPJ in children diagnosed with ASD. These results provide a first glimpse into the conceptual structure of information in ToM brain regions in childhood, and suggest that there are real, stable features that predict responses in these regions in children. Multivariate analyses are a promising approach for sensitively measuring conceptual and neural developmental change and individual differences in ToM.",science
10.1016/j.ins.2019.12.033,Journal,Information Sciences,scopus,2020-04-01,sciencedirect,Relation constrained attributed network embedding,https://api.elsevier.com/content/abstract/scopus_id/85076856635,"Network embedding aims at learning a low-dimensional dense vector for each node in the network. In recent years, it has attracted great research attention due to its wide applications. Most existing studies model the graph structure only and neglect the attribute information. Although several attributed network embedding methods take the node attribute into account, they mainly focus on the basic relations between the nodes and their attributes like a user and his/her interests (attributes). The composite relations between two nodes, and two nodes’ attributes, and the related nodes and their attributes, contain rich information and can enhance the performance of many network analysis tasks. For example, two scholars having the common interests as “nature language processing” and “knowledge graph” may collaborate in the future and there will be a new edge in the network. However, such important information is still under-exploited.
                  To address this limitation, we propose a novel framework to exploit the abundant relation information to enhance attributed network embedding. The main idea is to employ the multiple types of relations in attributed networks as the constraints to improve the network representation. To this end, we first construct the composite relations between two nodes and their attributes in addition to the commonly used basic relations. We then develop a relation constrained attributed network (RCAN) framework to learn the node representations by constraining them with these relations. We conduct extensive experiments on three real-world datasets to show the effectiveness of our proposed RCAN as an attributed network embedding method for modeling various social networks. The results demonstrate that our method achieves significantly better performance than the state-of-the-art baselines in both the link prediction and node clustering tasks.",science
10.1016/j.talanta.2019.120664,Journal,Talanta,scopus,2020-04-01,sciencedirect,Modelling of bioprocess non-linear fluorescence data for at-line prediction of etanercept based on artificial neural networks optimized by response surface methodology,https://api.elsevier.com/content/abstract/scopus_id/85076829838,"In the last years, regulatory agencies in biopharmaceutical industry have promoted the design and implementation of Process Analytical Technology (PAT), which aims to develop rapid and high-throughput strategies for real-time monitoring of bioprocesses key variables, in order to improve their quality control lines. In this context, spectroscopic techniques for data generation in combination with chemometrics represent alternative analytical methods for on-line critical process variables prediction. In this work, a novel multivariate calibration strategy for the at-line prediction of etanercept, a recombinant protein produced in a mammalian cells-based perfusion process, is presented. For data generation, samples from etanercept processes were daily obtained, from which fluorescence excitation-emission matrices were generated in the spectral ranges of 225.0 and 495.0 nm and 250.0 and 599.5 nm for excitation and emission modes, respectively. These data were correlated with etanercept concentration in supernatant (measured by an off-line HPLC-based reference univariate technique) by implementing different chemometric strategies, in order to build predictive models. Partial least squares (PLS) regression evidenced a non-linear relation between signal and concentration when observing actual vs. predicted concentrations. Hence, a non-parametric approach was implemented, based on a multilayer perceptron artificial neural network (MLP). The MLP topology was optimized by means of the response surface methodology. The prediction performance of MLP model was superior to PLS, since the first is able to cope with non-linearity in calibration models, reaching percentage mean relative error in predictions of about 7.0% (against 12.6% for PLS). This strategy represents a fast and inexpensive approach for etanercept monitoring, which conforms the principles of PAT.",science
10.1016/j.patcog.2019.107126,Journal,Pattern Recognition,scopus,2020-04-01,sciencedirect,Clustering social audiences in business information networks,https://api.elsevier.com/content/abstract/scopus_id/85076010225,"Business information networks involve diverse users and rich content and have emerged as important platforms for enabling business intelligence and business decision making. A key step in an organizations business intelligence process is to cluster users with similar interests into social audiences and discover the roles they play within a business network. In this article, we propose a novel machine-learning approach, called CBIN, that co-clusters business information networks to discover and understand these audiences. The CBIN framework is based on co-factorization. The audience clusters are discovered from a combination of network structures and rich contextual information, such as node interactions and node-content correlations. Since what defines an audience cluster is data-driven, plus they often overlap, pre-determining the number of clusters is usually very difficult. Therefore, we have based CBIN on an overlapping clustering paradigm with a hold-out strategy to discover the optimal number of clusters given the underlying data. Experiments validate an outstanding performance by CBIN compared to other state-of-the-art algorithms on 13 real-world enterprise datasets.",science
10.1016/j.eswa.2019.113083,Journal,Expert Systems with Applications,scopus,2020-04-01,sciencedirect,Real-time biomechanical modeling of the liver using Machine Learning models trained on Finite Element Method simulations,https://api.elsevier.com/content/abstract/scopus_id/85074768700,"The development of accurate real-time models of the biomechanical behavior of different organs and tissues still poses a challenge in the field of biomechanical engineering. In the case of the liver, specifically, such a model would constitute a great leap forward in the implementation of complex applications such as surgical simulators, computed-assisted surgery or guided tumor irradiation.
                  In this work, a relatively novel approach for developing such a model is presented. It consists in the use of a machine learning algorithm, which provides real-time inference, trained on tens of thousands of simulations of the biomechanical behavior of the liver carried out by the finite element method on more than 100 different liver geometries.
                  Considering a target accuracy threshold of 3 mm for the Euclidean Error, four different scenarios were modeled and assessed: a single liver with an arbitrary force applied (99.96% of samples within the accepted error range), a single liver with two simultaneous forces applied (99.84% samples in range), a single liver with different material properties and an arbitrary force applied (98.46% samples in range), and a much more general model capable of modeling the behavior of any liver with an arbitrary force applied (99.01% samples in range for the median liver).
                  The results show that the Machine Learning models perform extremely well on all the scenarios, managing to keep the Mean Euclidean Error under 1 mm in all cases. Furthermore, the proposed model achieves working frequencies above 100Hz on modest hardware (with frequencies above 1000Hz being easily achievable on more powerful GPUs) thus fulfilling the real-time requirements. These results constitute a remarkable improvement in this field and may involve a prompt implementation in clinical practice.",science
10.1016/j.cmpb.2019.105019,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic diagnosis of fungal keratitis using data augmentation and image fusion with deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85070552720,"Background and objectives
                  Fungal keratitis is caused by inflammation of the cornea that results from infection by fungal organisms. The lack of an early effective diagnosis often results in serious complications even blindness. Confocal microscopy is one of the most effective methods in the diagnosis of fungal keratitis, but the diagnosis depends on the subjective judgment of medical experts.
               
                  Methods
                  To address this problem, this paper proposes a novel convolutional neural network framework for the automatic diagnosis of fungal keratitis using data augmentation and image fusion. Firstly, a normal image is augmented by flipping to solve the problem of having a limited and imbalanced database. Secondly, a sub-area contrast stretching algorithm is proposed for image preprocessing to highlight the key structures in the images and to filter out irrelevant information. Thirdly, the histogram matching fusion algorithm is implemented, then the preprocessed image is fused with the original image to form a new algorithm framework and a new database. Finally, the traditional convolutional neural network is integrated into the novel algorithm framework to perform the experiments.
               
                  Results
                  Experiments show that the accuracy of traditional AlexNet and VGGNet is 99.35% and 99.14%, that of AlexNet and VGGNet based on MF fusion is 99.80% and 99.83%, and that of AlexNet and VGGNet based on histogram matching fusion (HMF) is 99.95% and 99.89%. The experimental results show that the AlexNet framework using data augmentation and image fusion achieves a perfect trade-off between the diagnostic performance and the computational complexity, with a diagnostic accuracy of 99.95%.
               
                  Conclusions
                  These experimental results demonstrate the novel convolutional neural network framework perfectly balances the diagnostic performance and computational complexity, and can improve the effect and real-time performance in the diagnosis of fungal keratitis.",science
10.1016/j.patrec.2018.07.028,Journal,Pattern Recognition Letters,scopus,2020-04-01,sciencedirect,Rating prediction via generative convolutional neural networks based regression,https://api.elsevier.com/content/abstract/scopus_id/85050988401,"Ratings are an essential criterion for evaluating the quality of movies and a critical indicator of whether a customer would watch a movie. Therefore, an important related research challenge is to predict the rating of a movie before it is released in cinema or even before it is produced. Many existing approaches fail to address this challenge because they predict movie ratings based on post-production factors such as review comments from social media. Consequently, they are generally inapplicable until a movie has been released for a certain period of time when a sufficient number of review comments have become available. In this paper, we propose a regression model based on generative convolutional neural networks for movie rating prediction. Instead of post-production factors widely used by previous work, this model learns from movies’ intrinsic pillars such as genres, budget, cast, director and plot information, which are obtainable before the production of movies. In particular, the model explores the correlations between the rating of a movie and its intrinsic attributes to predict its rating. The results can serve as a reference for investors and movie studios to determine an optimal portfolio for movie production and a guidance to the interested users to choose the movie to watch. Extensive experiments on a real dataset are benchmarked against a set of baselines and state of the art approaches. The results demonstrate the effectiveness of our approach. The proposed model is also general to be extended to handle other prediction tasks.",science
10.1016/j.saa.2019.117731,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2020-03-05,sciencedirect,A signal-on fluorescence based biosensing platform for highly sensitive detection of DNA methyltransferase enzyme activity and inhibition,https://api.elsevier.com/content/abstract/scopus_id/85075380206,"DNA methylation mediated by DNA methyltransferase (MTase) enzyme is internal cell mechanism which regulate the expression or suppression of crucial genes involve in cancer early diagnosis. Herein, highly sensitive fluorescence biosensing platform was developed for monitoring of DNA Dam MTase enzyme activity and inhibition based on fluorescence signal on mechanism. The specific Au NP functionalized oligonucleotide probe with overhang end as a template for the synthesis of fluorescent silver nanoclusters (Ag NCs) was designed to provide the FRET occurrence. Following, methylation and cleavage processes by Dam MTAse and DpnI enzymes respectively at specific probe recognition site could resulted to release of AgNCs synthesizer DNA fragment and returned the platform to fluorescence signal-on state through interrupting in FRET. Subsequently, amplified fluorescence emission signals of Ag NCs showed increasing linear relationship with amount of Dam MTase enzyme at the range of 0.1–20 U/mL and the detection limit was estimated at 0.05 U/mL. Superior selectivity of experiment was illustrated among other tested MTase and restriction enzymes due to the specific recognition of MTase toward its substrate. Furthermore, the inhibition effect of applied Dam MTase drug inhibitors screened and evaluated with satisfactory results which would be helpful for discovery of antimicrobial drugs. The real sample assay also showed the applicability of proposed method in human serum condition. This novel strategy presented an efficient and cost effective platform for sensitive monitoring of DNA MTase activity and inhibition which illustrated its great potential for further application in medical diagnosis and drug discovery.",science
10.1016/j.coal.2020.103418,Journal,International Journal of Coal Geology,scopus,2020-03-01,sciencedirect,The chemical kinetics of the semi-open hydrous pyrolysis system: Time series analysis of lithostatic pressure and fluid pressure,https://api.elsevier.com/content/abstract/scopus_id/85080040271,"As a problem that has plagued geochemists, the perspective of time has long been recognized as an important factor in organic matter evolution and hydrocarbon generation. This article discusses two time series analysis methods based on econometrics, damping trend and autoregressive integrated moving average (ARIMA), to mine the potential value of data and abstract useful information from pyrolysis experiments. The case studies use marine source rocks (depth of 3119–3230 m, in the LH29–2 well) from the Enping Formation in the Baiyun Sag, the deep-water area (depth of >300 m) of the northern South China Sea, which has a geological background of high temperature, high pressure and rapid burial in the late stage. A tubular plug flow microreactor is used to artificially mature the source rock in the laboratory, and the conditions of hydrous pyrolysis are listed as follows: temperatures of 250°C, 300°C, 350°C, 400°C, 450°C, and 500°C; lithostatic pressure of 33~89 MPa; fluid pressure of 16~38 MPa; and time duration of 72 h. The results revealed that as the degree of maturation increased (R
                     
                        o
                      from 0.27 to 2.04), the cumulative yield of hydrocarbon gas increased rapidly (max = 311.64 ml/g⋅TOC), the yield of the expelled oil increased first and then decreased (peak = 350.69 mg/g⋅TOC at 350°C), and the yield of residual oil extracted from residue decreased gradually. Although the kinetic parameters of kerogen can be calculated by conventional pyrolysis experiments, the long-term cumulative effect of episodic-hydrocarbon expulsion in real conditions is often neglected. The major contributions of our statistical approach for geological applications are described as follows: (1) the recognition of qualitative changes within hydrocarbon generation and expulsion; (2) the characterization of episodic-hydrocarbon expulsion that describes the evolution of the lithostatic pressure and fluid pressure; (3) the disclosure of new influencing factors abstracted from time series models to describe the frequency distribution of hydrocarbon expulsion; and (4) an evaluation of the dependency of new variables.",science
10.1016/j.artmed.2020.101817,Journal,Artificial Intelligence in Medicine,scopus,2020-03-01,sciencedirect,Real-world data medical knowledge graph: construction and applications,https://api.elsevier.com/content/abstract/scopus_id/85079325883,"Objective
                  Medical knowledge graph (KG) is attracting attention from both academic and healthcare industry due to its power in intelligent healthcare applications. In this paper, we introduce a systematic approach to build medical KG from electronic medical records (EMRs) with evaluation by both technical experiments and end to end application examples.
               
                  Materials and Methods
                  The original data set contains 16,217,270 de-identified clinical visit data of 3,767,198 patients. The KG construction procedure includes 8 steps, which are data preparation, entity recognition, entity normalization, relation extraction, property calculation, graph cleaning, related-entity ranking, and graph embedding respectively. We propose a novel quadruplet structure to represent medical knowledge instead of the classical triplet in KG. A novel related-entity ranking function considering probability, specificity and reliability (PSR) is proposed. Besides, probabilistic translation on hyperplanes (PrTransH) algorithm is used to learn graph embedding for the generated KG.
               
                  Results
                  A medical KG with 9 entity types including disease, symptom, etc. was established, which contains 22,508 entities and 579,094 quadruplets. Compared with term frequency - inverse document frequency (TF/IDF) method, the normalized discounted cumulative gain (NDCG@10) increased from 0.799 to 0.906 with the proposed ranking function. The embedding representation for all entities and relations were learned, which are proven to be effective using disease clustering.
               
                  Conclusion
                  The established systematic procedure can efficiently construct a high-quality medical KG from large-scale EMRs. The proposed ranking function PSR achieves the best performance under all relations, and the disease clustering result validates the efficacy of the learned embedding vector as entity’s semantic representation. Moreover, the obtained KG finds many successful applications due to its statistics-based quadruplet.
                  where 
                        
                           N
                           
                              c
                              o
                           
                           
                              m
                              i
                              n
                           
                        
                      is a minimum co-occurrence number and R is the basic reliability value. The reliability value can measure how reliable is the relationship between Si
                      and Oij
                     . The reason for the definition is the higher value of N
                     co(Si, Oij
                     ), the relationship is more reliable. However, the reliability values of the two relationships should not have a big difference if both of their co-occurrence numbers are very big. In our study, we finally set 
                        
                           N
                           
                              c
                              o
                           
                           
                              m
                              i
                              n
                           
                        
                      = 10 and R = 1 after some experiments. For instance, if co-occurrence numbers of three relationships are 1, 100 and 10000, their reliability values are 1, 2.96 and 5 respectively.",science
10.1016/j.amar.2020.100113,Journal,Analytic Methods in Accident Research,scopus,2020-03-01,sciencedirect,"Big data, traditional data and the tradeoffs between prediction and causality in highway-safety analysis",https://api.elsevier.com/content/abstract/scopus_id/85078666924,"The analysis of highway accident data is largely dominated by traditional statistical methods (standard regression-based approaches), advanced statistical methods (such as models that account for unobserved heterogeneity), and data-driven methods (artificial intelligence, neural networks, machine learning, and so on). These methods have been applied mostly using data from observed crashes, but this can create a problem in uncovering causality since individuals that are inherently riskier than the population as a whole may be over-represented in the data. In addition, when and where individuals choose to drive could affect data analyses that use real-time data since the population of observed drivers could change over time. This issue, the nature of the data, and the implementation target of the analysis imply that analysts must often tradeoff the predictive capability of the resulting analysis and its ability to uncover the underlying causal nature of crash-contributing factors. The selection of the data-analysis method is often made without full consideration of this tradeoff, even though there are potentially important implications for the development of safety countermeasures and policies. This paper provides a discussion of the issues involved in this tradeoff with regard to specific methodological alternatives and presents researchers with a better understanding of the trade-offs often being inherently made in their analysis.",science
10.1016/j.yrtph.2019.104570,Journal,Regulatory Toxicology and Pharmacology,scopus,2020-03-01,sciencedirect,Safety evaluation and protective effects of ethanolic extract from maca (Lepidium meyenii Walp.) against corticosterone and H<inf>2</inf>O<inf>2</inf> induced neurotoxicity,https://api.elsevier.com/content/abstract/scopus_id/85077357193,"Maca has been traditionally used to enhance sexual behavior and fertility. Recently, maca's neuroprotective effects have been reported. The purpose of this study was to investigate whether the ethanol extract of maca (EEM) (100 mg/kg/bw, 200 mg/kg/bw, 400 mg/kg/bw, p.o.) exerted neuroprotective effects in corticosterone (CORT)-induced (40 mg/kg/bw, s.c.) rats, to determine the neuroprotective effects of EEM (12.5, 25, 50 μg/ml) and macamides in H2O2-induced (50 μM) PC12 cells. The acute toxicity (2000 mg/kg/bw, p.o.) and subacute toxicity (200 mg/kg/bw, 500 mg/kg/bw, 1000 mg/kg/bw, p.o.) of EEM were evaluated by mouse models. EEM reversed CORT-induced abnormal behaviors, reduced the contents of TNF-α, IL-6 in hippocampi, and increased the positive cells of doublecortin (DCX), bromodeoxyuridine (BrdU) and DCX + BrdU in the hippocampus of rats. Moreover, EEM and 4 macamides remarkably increased the cell viability in H2O2-induced PC12 cells. EEM promoted the phosphorylation of IκBα and p65, suppressed the NF-κB activation, and inhibited the levels of pro-inflammatory cytokines such as TNF-α, IL-6 and their mRNA levels in H2O2-induced PC12 cells. In conclusion, EEM could exert neuroprotective effects in CORT-induced rats and in H2O2-induced PC12 cells. Moreover, EEM did not present relevant toxicity after exposure to single and repeated doses.",science
10.1016/j.entcom.2019.100336,Journal,Entertainment Computing,scopus,2020-03-01,sciencedirect,Smart Reckoning: Reducing the traffic of online multiplayer games using machine learning for movement prediction,https://api.elsevier.com/content/abstract/scopus_id/85077019240,"Massively Multiplayer Online Game (MMOG) players maintain consistent views of the positions of each other by periodically exchanging messages. Besides the fact that these messages can suffer delays that cause rendering inconsistencies, they also represent an overhead on the network. This overhead can be significant, as the number of MMOG players is very large, but reducing the number of messages is not trivial. The classic strategy to predict movement avoiding message exchange is based on the Dead Reckoning algorithm, which has several limitations. Other strategies have been proposed more recently that improve the results, but rely on expert knowledge. In this work we propose Smart Reckoning, a movement prediction strategy based on machine learning. The strategy consists of two phases. In the first phase, a learning model classifies whether the classical Dead Reckoning algorithm is able to predict the new avatar position correctly or not. In case the conclusion is negative, another learning model is used to predict the new direction. The proposed strategy was applied to the World of Warcraft game. The learning models were implemented with the Weka tool using real game trace data, and results are presented for the accuracy of multiple algorithms.",science
10.1016/j.envres.2019.109024,Journal,Environmental Research,scopus,2020-03-01,sciencedirect,An efficient tool for the continuous monitoring on adsorption of sub-ppm level gaseous benzene using an automated analytical system based on thermal desorption-gas chromatography/mass spectrometry approach,https://api.elsevier.com/content/abstract/scopus_id/85076492466,"It became an important task to effectively adsorb volatile organic compounds (VOCs) at or near real-world levels for efficient control of airborne pollution in ambient environments. Nonetheless, most studies carried out previously for the control of VOCs are confined to significantly polluted conditions (e.g., >100 ppm) that are far different from real-world or ambient conditions. To help acquire the meaningful data for the adsorptive removal of VOCs at near real-world levels, a new approach was designed and implemented to measure adsorption of gaseous benzene (as a representative or model VOC) at trace-level quantities (as low as 0.14 ng (0.43 ppb) for a 100 mL sample) using activated carbon (sieved to 212 μm mesh size) as a model sorbent. With the aid of a thermal desorption-gas chromatography/mass spectrometry system, the key adsorption performance metrics (such as 10% breakthrough volume (10% BTV) points: 10% as the key reference) were determined: 1018 L atm g−1 at 0.1 ppm benzene with the corresponding partition coefficient of 3.85 mol kg−1 Pa−1. If the adsorption capacity values (at 10% BTV) are compared across the varying concentration levels of benzene, the maximum value of 1.07 mg g−1 was observed at 1 ppm benzene (within the concentration range selected in this work). As such, it was possible to quantitatively assess the sorbate-sorbent interactions at significantly low concentrations of VOCs that actually prevail under the near real-world conditions.",science
10.1016/j.actaastro.2019.11.037,Journal,Acta Astronautica,scopus,2020-03-01,sciencedirect,Pattern recognition in time series for space missions: A rosetta magnetic field case study,https://api.elsevier.com/content/abstract/scopus_id/85076239823,"Time series analysis is a technique widely employed in space science. In unpredictable environments like space, scientific analysis relies on large data sets to enable interpretation of observations. Artificial signal interferences caused by the spacecraft itself further impede this process. The most time consuming part of these studies is the efficient identification of recurrent pattern in observations, both of artificial and natural origin, often forcing researchers to limit their analysis to a reduced set of observations. While pattern recognition techniques for time series are well known, their application is discussed and evaluated primarily on purpose built or heavily preprocessed data sets. The aim of this paper is to evaluate the performance of state of the art pattern recognition techniques in terms of computational efficiency and validity on a real-life testcase. For this purpose the most suitable techniques for different types of pattern are discussed and subsequently evaluated on various hardware in comparison to manual identification. Using magnetic field observations of the ESA Rosetta mission as a representative example, both disturbances and natural patterns are identified. Compared to manual selection a speed-up of a factor up to 100 is achieved, with values for recall and precision above 80%. Moreover, the detection process is fully automated and reproducible. Using the presented method it was possible to detect and correct artificial interference. Finally, the feasibility of onboard deployment is briefly discussed.",science
10.1016/j.cpc.2019.107006,Journal,Computer Physics Communications,scopus,2020-03-01,sciencedirect,Support vector machines on the D-Wave quantum annealer,https://api.elsevier.com/content/abstract/scopus_id/85075444396,"Kernel-based support vector machines (SVMs) are supervised machine learning algorithms for classification and regression problems. We introduce a method to train SVMs on a D-Wave 2000Q quantum annealer and study its performance in comparison to SVMs trained on conventional computers. The method is applied to both synthetic data and real data obtained from biology experiments. We find that the quantum annealer produces an ensemble of different solutions that often generalizes better to unseen data than the single global minimum of an SVM trained on a conventional computer, especially in cases where only limited training data is available. For cases with more training data than currently fits on the quantum annealer, we show that a combination of classifiers for subsets of the data almost always produces stronger joint classifiers than the conventional SVM for the same parameters.",science
10.1016/j.renene.2019.09.092,Journal,Renewable Energy,scopus,2020-03-01,sciencedirect,Wind turbine fatigue reduction based on economic-tracking NMPC with direct ANN fatigue estimation,https://api.elsevier.com/content/abstract/scopus_id/85072713179,"The aim of this work is to deploy an advanced Nonlinear Model Predictive Control (NMPC) approach for reducing the tower fatigue of a wind turbine (WT) tower while guaranteeing efficient energy extraction from the wind. To achieve this, different Artificial Neural Network (ANN) architectures are trained and tested in order to estimate the tower fatigue as a surrogate of the traditional Rainflow Counting (RFC) method. The ANNs receive data stemming from the tower top oscillation velocity and the previous fatigue state to directly estimate the fatigue progression. The results are compared to select the most convenient architecture for control implementation. Once an ANN is selected, an economic-tracking NMPC (etNMPC) solution to reduce the fatigue of the WT tower is deployed in real-time. The closed-loop results are then compared to a baseline controller from a renowned WT simulation tool and a classic etNMPC implementation with indirect fatigue minimisation to demonstrate the improvement achieved with the proposed strategy. Finally, conclusions regarding computational cost and real-time deployment capabilities are discussed, as well as future lines of research.",science
10.1016/j.ipm.2019.02.016,Journal,Information Processing and Management,scopus,2020-03-01,sciencedirect,Detecting breaking news rumors of emerging topics in social media,https://api.elsevier.com/content/abstract/scopus_id/85062093277,"Users of social media websites tend to rapidly spread breaking news and trending stories without considering their truthfulness. This facilitates the spread of rumors through social networks. A rumor is a story or statement for which truthfulness has not been verified. Efficiently detecting and acting upon rumors throughout social networks is of high importance to minimizing their harmful effect. However, detecting them is not a trivial task. They belong to unseen topics or events that are not covered in the training dataset. In this paper, we study the problem of detecting breaking news rumors, instead of long-lasting rumors, that spread in social media. We propose a new approach that jointly learns word embeddings and trains a recurrent neural network with two different objectives to automatically identify rumors. The proposed strategy is simple but effective to mitigate the topic shift issues. Emerging rumors do not have to be false at the time of the detection. They can be deemed later to be true or false. However, most previous studies on rumor detection focus on long-standing rumors and assume that rumors are always false. In contrast, our experiment simulates a cross-topic emerging rumor detection scenario with a real-life rumor dataset. Experimental results suggest that our proposed model outperforms state-of-the-art methods in terms of precision, recall, and F1.",science
10.1016/j.knosys.2019.105308,Journal,Knowledge-Based Systems,scopus,2020-02-29,sciencedirect,An OWA-based hierarchical clustering approach to understanding users’ lifestyles,https://api.elsevier.com/content/abstract/scopus_id/85076253160,"Based on users’ interactions with social networks, a method to understand users’ life-styles is developed. Descriptions of their lifestyles are obtained from previously reported experiences on these sites. Contextual information and contributed reviews lend insight into which elements are important for different lifestyles. In this paper, an ordered weighted averaging operator (OWA) is integrated with hierarchical clustering in order to find the similarity between users and clusters. Specifically, a two step measure is defined to compare and aggregate two clusters. To illustrate the efficiency of the methodology, a real case is implemented for 499 Yelp reviewers associated with 134,102 reviews across 11 variables and 373 Airbnb reviewers associated with 1,826 reviews across 14 variables.",science
10.1016/j.physa.2019.123151,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2020-02-15,sciencedirect,Early warning system: From face recognition by surveillance cameras to social media analysis to detecting suspicious people,https://api.elsevier.com/content/abstract/scopus_id/85074532417,"Surveillance security cameras are increasingly deployed in almost every location for monitoring purposes, including watching people and their actions for security purposes. For criminology, images collected from these cameras are usually used after an incident occurs to analyze who could be the people involved. While this usage of the cameras is important for a post crime action, there exists the need for real time monitoring to act as an early warning to prevent or avoid an incident before it occurs. In this paper, we describe the development and implementation of an early warning system that recognizes people automatically in a surveillance camera environment and then use data from various sources to identify these people and build their profile and network. The current literature is still missing a complete workflow from identifying people/criminals from a video surveillance to building a criminal information extraction framework and identifying those people and their interactions with others We train a feature extraction model for face recognition using convolutional neural networks to get a good recognition rate on the Chokepoint dataset collected using surveillance cameras. The system also provides the function to record people appearance in a location, such that unknown people passing through a scene excessive number of times (above a threshold decided by a security expert) will then be further analyzed to collect information about them. We implemented a queue based system to record people entrance. We try to avoid missing relevant individuals passing through as in some cases it is not possible to add every passing person to the queue which is maintained using some cache handling techniques. We collect and analyze information about unknown people by comparing their images from the cameras to a list of social media profiles collected from Facebook and intelligent services archives. After locating the profile of a person, traditional news and other social media platforms are crawled to collect and analyze more information about the identified person. The analyzed information is then presented to the analyst where a list of keywords and verb phrases are shown. We also construct the person’s network from individuals mentioned with him/her in the text. Further analysis will allow security experts to mark this person as a suspect or safe. This work shows that building a complete early warning system is feasible to tackle and identify criminals so that authorities can take the required actions on the spot.",science
10.1016/j.physa.2019.123174,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2020-02-15,sciencedirect,Fake news detection within online social media using supervised artificial intelligence algorithms,https://api.elsevier.com/content/abstract/scopus_id/85074460484,"Along with the development of the Internet, the emergence and widespread adoption of the social media concept have changed the way news is formed and published. News has become faster, less costly and easily accessible with social media. This change has come along with some disadvantages as well. In particular, beguiling content, such as fake news made by social media users, is becoming increasingly dangerous. The fake news problem, despite being introduced for the first time very recently, has become an important research topic due to the high content of social media. Writing fake comments and news on social media is easy for users. The main challenge is to determine the difference between real and fake news. In this paper, a two-step method for identifying fake news on social media has been proposed, focusing on fake news. In the first step of the method, a number of pre-processing is applied to the data set to convert un-structured data sets into the structured data set. The texts in the data set containing the news are represented by vectors using the obtained TF weighting method and Document-Term Matrix. In the second step, twenty-three supervised artificial intelligence algorithms have been implemented in the data set transformed into the structured format with the text mining methods. In this work, an experimental evaluation of the twenty-three intelligent classification methods has been performed within existing public data sets and these classification models have been compared depending on four evaluation metrics.",science
10.1016/j.jbi.2019.103354,Journal,Journal of Biomedical Informatics,scopus,2020-02-01,sciencedirect,"Task definition, annotated dataset, and supervised natural language processing models for symptom extraction from unstructured clinical notes",https://api.elsevier.com/content/abstract/scopus_id/85077000258,"Introduction
                  Machine learning (ML) and natural language processing have great potential to improve information extraction (IE) within electronic medical records (EMRs) for a wide variety of clinical search and summarization tools. Despite ML advancements, clinical adoption of real time IE tools for patient care remains low. Clinically motivated IE task definitions, publicly available annotated clinical datasets, and inclusion of subtasks such as coreference resolution and named entity normalization are critical for the development of useful clinical tools.
               
                  Materials and methods
                  We provide a task definition and comprehensive annotation requirements for a clinically motivated symptom extraction task. Four annotators labeled symptom mentions within 1108 discharge summaries from two public clinical note datasets for the tasks of named entity recognition, coreference resolution, and named entity normalization; these annotations will be released to the public. Baseline human performance was assessed and two ML models were evaluated on the symptom extraction task.
               
                  Results
                  16,922 symptom mentions were identified within the discharge summaries, with 11,944 symptom instances after coreference resolution and 1255 unique normalized answer forms. Human annotator performance averaged 92.2% F1. Recurrent network model performance was 85.6% F1 (recall 85.8%, precision 85.4%), and Transformer-based model performance was 86.3% F1 (recall 86.6%, precision 86.1%). Our models extracted vague symptoms, acronyms, typographical errors, and grouping statements. The models generalized effectively to a separate clinical note corpus and can run in real time.
               
                  Conclusion
                  To our knowledge, this dataset will be the largest and most comprehensive publicly released, annotated dataset for clinically motivated symptom extraction, as it includes annotations for named entity recognition, coreference, and normalization for more than 1000 clinical documents. Our neural network models extracted symptoms from unstructured clinical free text at near human performance in real time. In this paper, we present a clinically motivated task definition, dataset, and simple supervised natural language processing models to demonstrate the feasibility of building clinically applicable information extraction tools.",science
10.1016/j.cie.2019.106225,Journal,Computers and Industrial Engineering,scopus,2020-02-01,sciencedirect,Fuzzy possibility regression integrated with fuzzy adaptive neural network for predicting and optimizing electrical discharge machining parameters,https://api.elsevier.com/content/abstract/scopus_id/85076689961,"An electrical discharge machining (EDM) is one of the special production methods that are widely used in moldings, repairs and production of specific industrial components. Due to extensive production costs, optimal machining specifications are significant. Machining specifications are effective on output quality and thus attract more customers leading to higher profits. In this study, the impact of EDM parameters on surface roughness, material removal rate and electrode corrosion percentage have been investigated. In order to consider uncertainty of real production environments, the fuzzy theory is employed. Also, using the design of experiment (DOE) parameters calibration is performed and mathematical programming approach is applied for optimization purpose. The relationship between the machining parameters and the output process specification is examined by a fuzzy possibility regression model. Then, the mathematical relation of exact inputs and fuzzy outputs of the EDM process are extracted. The effectiveness of the three outputs is evaluated by interfacing models and fuzzy hypothesis testing. To determine the optimal levels of each output, a fuzzy adaptive neural network is used and appropriate models are prepared to be adapted with a fitted model of fuzzy possibility regression for comparison purposes. Validation tests imply the effectiveness of the proposed method. The integrated model is implemented in real case study. The results show that, fitted models can predict the material removal rate, surface fineness, and corrosion percentage of the electrode. The prediction accuracy of the proposed method is shown in comparison with the optimal fuzzy adaptive neural network outputs considering error value. Also, the proposed method is successful in identifying the optimal process parameters for EDM with reliable accuracy. The proposed integrated prediction and optimization model can be used as a calibration decision support in production systems to handle dynamic data structures and provide real time machining specifications to increase the output quality.",science
10.1016/j.dib.2019.104959,Journal,Data in Brief,scopus,2020-02-01,sciencedirect,Anticancer activity and metabolite profiling data of Penicillium janthinellum KTMT5,https://api.elsevier.com/content/abstract/scopus_id/85076438339,"Fungi are ubiquitous, they proliferate even in environments with toxic pollutants that are otherwise harmful to other eukaryotes. This article presents data of fungi which were isolated from gold mine tailings and identified by DNA sequencing of their inter transcribed spacer regions 1 and 2. Five fungal isolates were identified, among which the crude extract of Penicillium janthinellum KTMT5 was investigated for anticancer activity on A549 (lung carcinoma) and UMG87 (glioblastoma) cell lines. Untargeted metabolite profiling of the crude extract of P. janthinellum KTMT5 was performed using liquid chromatography quadrupole time of flight tandem mass spectrometry (LC-QTOF-MS/MS) and a molecular network generated using the online workflow on the Global Natural Product Social molecular networking (GNPS) website. DNA sequencing showed that all fungal isolates belonged to phylum Ascomycota with the genus Penicillium representing 75% of the fungal isolates. P. janthinellum KTMT5 which was selected for further experiments showed significant anticancer activity against UMG87 cells with a calculated IC50 value of 44.23 μg/mL in the MTS assay, while the real time xCELLigence assay showed dose-dependent anticancer activity at 50 and 100 μg/mL. Metabolite 
                        1
                        
                           https://msbi.ipb-halle.de/MetFragBeta/.
                     profiling revealed the presence of several known metabolites in the crude extract of P. janthinellum KTMT5 and molecular networking showed the relationships among these metabolites.",science
10.1016/j.aca.2019.10.063,Journal,Analytica Chimica Acta,scopus,2020-02-01,sciencedirect,Dual-mode detection of avian influenza virions (H9N2) by ICP-MS and fluorescence after quantum dot labeling with immuno-rolling circle amplification,https://api.elsevier.com/content/abstract/scopus_id/85075378560,"Avian influenza virus (AIVs), hosted in poultry, are the pathogens of many poultry diseases and human infections, which bring huge losses to the poultry breeding industry and huge panic to society. Therefore, it is of great significance to establish accurate and sensitive detection methods for AIVs. In this work, a dual-mode detection method based on immuno-rolling circle amplification (immuno-RCA) and quantum dots (QDs) labeling for inductively coupled plasma mass spectrometry (ICP-MS) and fluorescence detection of H9N2 AIV was developed. The dual-mode detection of the QDs by ICP-MS and fluorescence is used to achieve mutual verification within the analysis results, thus improving the accuracy of the method. With the immuno-RCA, the sensitivity of the method was increased by two orders of magnitude. The limit of detection of the proposed method is 17 ng L−1 and 61 ng L−1, and the linear range of the proposed method is 0.05–5 ng mL−1 and 0.1–5 ng mL−1 with ICP-MS and fluorescence detection, respectively. The relative standard deviation (n = 7) is 4.9% with ICP-MS detection and 3.1% with fluorescence detection. Furthermore, the proposed method was applied to the analysis of chicken serum samples, no significant different was found for two modes detection and the recoveries of the spiking experiments are acceptable, indicating that the method has good practical potential for real sample analysis.",science
10.1016/j.engappai.2019.103380,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-02-01,sciencedirect,Lazy reinforcement learning for real-time generation control of parallel cyber–physical–social energy systems,https://api.elsevier.com/content/abstract/scopus_id/85075002654,"To learn human intelligence, the social system/human system is added to a cyber–physical energy system in this paper. To accelerate the configuration process of the parameters of the cyber–physical energy system, parallel systems based on artificial societies-computational experiments-parallel execution are added to the cyber–physical energy system, i.e., a parallel cyber–physical–social energy system is proposed in this paper. This paper proposes a real-time generation control framework to replace the conventional generation control framework with multiple time scales, which consist of long-term time scale, short-term time scale, and real-time scale. Since a lazy operator employed into reinforcement learning, a lazy reinforcement learning is proposed for the real-time generation control framework. To reduce the real simulation time, multiple virtual parallel cyber–physical–social energy systems and a real parallel cyber–physical–social energy system are built for the real-time generation control of large-scale multi-area interconnected power systems. Compared with a total of 146016 conventional generation control algorithms and a relaxed artificial neural network in the simulation of IEEE 10-generator 39-bus New-England power system, the proposed lazy reinforcement learning based real-time generation control controller can obtain the highest control performance. The active power between two areas and the systemic frequency deviation can be reduced by the lazy reinforcement learning, and the simulation results verify the effectiveness and feasibility of the proposed lazy reinforcement learning based real-time generation control controller for the parallel cyber–physical–social energy systems.",science
10.1016/j.breast.2019.10.001,Journal,Breast,scopus,2020-02-01,sciencedirect,"The ethical, legal and social implications of using artificial intelligence systems in breast cancer care",https://api.elsevier.com/content/abstract/scopus_id/85074099299,"Breast cancer care is a leading area for development of artificial intelligence (AI), with applications including screening and diagnosis, risk calculation, prognostication and clinical decision-support, management planning, and precision medicine. We review the ethical, legal and social implications of these developments. We consider the values encoded in algorithms, the need to evaluate outcomes, and issues of bias and transferability, data ownership, confidentiality and consent, and legal, moral and professional responsibility. We consider potential effects for patients, including on trust in healthcare, and provide some social science explanations for the apparent rush to implement AI solutions. We conclude by anticipating future directions for AI in breast cancer care. Stakeholders in healthcare AI should acknowledge that their enterprise is an ethical, legal and social challenge, not just a technical challenge. Taking these challenges seriously will require broad engagement, imposition of conditions on implementation, and pre-emptive systems of oversight to ensure that development does not run ahead of evaluation and deliberation. Once artificial intelligence becomes institutionalised, it may be difficult to reverse: a proactive role for government, regulators and professional groups will help ensure introduction in robust research contexts, and the development of a sound evidence base regarding real-world effectiveness. Detailed public discussion is required to consider what kind of AI is acceptable rather than simply accepting what is offered, thus optimising outcomes for health systems, professionals, society and those receiving care.",science
10.1016/j.jss.2019.09.011,Journal,Journal of Surgical Research,scopus,2020-02-01,sciencedirect,Quercetin Promotes Diabetic Wound Healing via Switching Macrophages From M1 to M2 Polarization,https://api.elsevier.com/content/abstract/scopus_id/85072911427,"Background
                  For patients with diabetes mellitus, excessive and long-lasting inflammatory reactions at the wound site commonly lead to the delayed refractory wound healing. The polarization of macrophages in terms of M1 and M2 phenotypes is closely related to the production of inflammatory cytokines. Quercetin is traditionally recognized to have anti-inflammatory effect; however, whether quercetin modulates macrophage polarization from M1 to M2 and thus promotes diabetic wound healing remain unknown.
               
                  Materials and methods
                  Wounded male diabetic rats were equally divided into five groups: model group, solvent control group (10% DMSO), and three drug groups treated with quercetin (Q) at concentrations of 10 mg/mL (Q-LD [low dose]), 20 mg/mL (Q-MD [medium dose]), and 40 mg/mL (Q-HD [high dose]), respectively. The anti-inflammatory effect of quercetin on diabetic wounds was observed. Immunohistochemistry and quantificational real-time polymerase chain reaction were applied to test the changes in macrophage polarization and inflammatory responses.
               
                  Results
                  The wound contraction was fastest in Q-HD group. Hematoxylin and eosin (H&E) and Masson's trichrome staining revealed that fibroblast distribution and collagen deposition in quercetin-treated groups were significantly higher than those in the model group. Immunohistochemistry tests showed more CD206-positive cells and less iNOS-positive cells in quercetin-treated groups. Furthermore, the levels of proinflammatory factors in quercetin-treated groups were lower than those in the model group, whereas the levels of the anti-inflammatory factors and angiogenesis-related factors were relatively higher.
               
                  Conclusions
                  In short, quercetin inhibits inflammatory reactions via modulating macrophage polarization switching from M1 to M2 phenotype, thereby accelerating the diabetic wound repair.",science
10.1016/j.chb.2019.09.008,Journal,Computers in Human Behavior,scopus,2020-02-01,sciencedirect,A collaborative working model for enhancing the learning process of science &amp; engineering students,https://api.elsevier.com/content/abstract/scopus_id/85072768570,"Science and engineering education are mostly based on content assimilation and development of skills. However, to adequately prepare students for today's world, it is also necessary to stimulate critical thinking and make them reflect on how to improve current practices using new tools and technologies. In this line, the main motivation of this research consists in exploring ways supported by technology to enhance the learning process of students and to better prepare them to face the challenges of today's world. To this end, the purpose of this work is to design an innovative learning project based on collaborative work among students, and research its impact in achieving better learning outcomes, generating of collective intelligence and further motivation. The proposed collaborative working model is based on peer review assessment methodology implemented through a learning web-platform. Thus, students were encouraged to peer review their classmates' works. They had to make comments, suggest improvements, and assess final assignments. Teaching staff managed and supervised the whole process. Students were selected from computer science engineering at the University of Alicante (Spain). Results suggested greater content assimilation and enhanced learning in several scientific skills. The students' final grade exceeded what any student could produce individually, but we cannot conclude that real collective intelligence was generated. Learning methodologies based on the possibilities of Information and Communication Technologies (ICT) provide new ways to transmit and manage knowledge in higher education. Collaborating in peer assessment enhances the students' motivation and promotes the active learning. In addition, this method can be very helpful and time saving for instructors in the management of large groups.",science
10.1016/j.chemosphere.2019.124937,Journal,Chemosphere,scopus,2020-02-01,sciencedirect,Zebrafish behavioral phenomics employed for characterizing behavioral neurotoxicity caused by silica nanoparticles,https://api.elsevier.com/content/abstract/scopus_id/85072682384,"Nowadays, silica nanoparticles (SiNPs) as one of the most productive nano-powder, has been extensively applied in various filed. The potential harm of SiNPs has previously received severe attention. A bulk of researches have proven the adverse effect of SiNPs on the health of ecological organisms and human. However, neurotoxic impacts of SiNPs, still remain in the stage of exploration. The potential neurotoxic effects of SiNPs need to be further explored. And the toxic mechanism needs comprehensive clarification. Herein, the neurotoxicity of SiNPs of various concentrations (100, 300, 1000 μg/mL) on adult zebrafish was determined by behavioral phenotyping and confirmed by molecular biology techniques such as qPCR. Behavioral phenotype revealed observable effects of SiNPs on disturbing light/dark preference, dampening exploratory behavior, inhibiting memory capability. Furthermore, the relationship between neurotoxic symptom and the transcriptional alteration of autophagy- and parkinsonism-related genes was preliminarily assessed. Importantly, further investigations should be carried out to determine the effects of SiNPs to cause neurodegeneration in the brain as well as to decipher the specific neurotoxic mechanisms. In sum, this work comprehensively evaluated the neurotoxic effect of small-sized SiNPs on overall neurobehavioral profiles and indicated the potential for SiNPs to cause Parkinson’s disease, which will provide a solid reference for the research on the neurotoxicity of SiNPs.",science
10.1016/j.eswa.2019.112905,Journal,Expert Systems with Applications,scopus,2020-02-01,sciencedirect,Influence maximization across heterogeneous interconnected networks based on deep learning,https://api.elsevier.com/content/abstract/scopus_id/85071844672,"With the fast development of online social networks, a large number of their members are involved in more than one social network. Finding most influential users is one of the interesting social network analysis tasks. The influence maximization (IM) problem aims to select a minimum set of users who maximize the influence spread on the underlying network. Most of the previous researches only focus on a single social networks, whereas in real world, users join to multiple social networks. Thus, influence can spread through common users on multiple networks. Besides, the existing works including simulation based, proxy based and sketch based approaches suffer from different issues including scalability, efficiency and feasibility due to the nature of these approaches for exploring networks and computation of their influence diffusion. Moreover, in the previous algorithms, several heuristics are employed to capture network topology for IM. But, these methods have information loss during network exploration because of their pruning strategies.
                  In this paper, a new research direction is presented for studying IM problem on interconnected networks. The proposed approach employs deep learning techniques to learn the feature vectors of network nodes while preserving both local and global structural information. To the best of our knowledge, network embedding has not yet been used to solve IM problem. Indeed, our algorithm leverages deep learning techniques for feature engineering to extract all the appropriate information related to IM problem for single and interconnected networks. Moreover, we prove that the proposed algorithm is monotone and submodular, thus, an optimal solution is guaranteed by the proposed approach. The experimental results on two interconnected networks including DBLP and Twitter-Foursquare illustrate the efficiency of the proposed algorithm in comparison to state of the art IM algorithms. We also conduct some experiments on NetHept dataset to evaluate the performance of the proposed approach on single networks.",science
10.1016/j.neucom.2019.09.084,Journal,Neurocomputing,scopus,2020-01-29,sciencedirect,MPS-Net: Learning to recover surface normal for multispectral photometric stereo,https://api.elsevier.com/content/abstract/scopus_id/85073066291,"Multispectral Photometric Stereo (MPS) estimates per-pixel surface normals from one single image captured under three colored (red, green and blue) light sources. Unlike traditional Photometric Stereo, MPS can therefore be used in dynamic scenes for single frame reconstruction. However, MPS is challenging due to the tangle of the illumination, surface reflectance and camera response, causing inaccurate estimation of surface normal. Existing approaches rely on either extra depth information or materials calibration strategies, thus limiting its usage in practical applications. In this paper, we propose a Multispectral Photometric Stereo Network (MPS-Net) to solve this under-determined system. The MPS-Net takes the single multispectral image and an initial surface normal estimation obtained from this image itself, and outputs an accurate surface normal map, where no extra depth or materials calibration information is required. We show that the MPS-Net is not constrained to Lambertian surfaces and can be applied to surfaces with complex reflectance. We evaluated the MPS-Net using both synthetic and real objects of various materials. Our experiment results show that the MPS-Net outperforms the state-of-the-art approaches.",science
10.1016/j.chroma.2019.460534,Journal,Journal of Chromatography A,scopus,2020-01-11,sciencedirect,Magnetic molecularly imprinted polymers prepared by reversible addition fragmentation chain transfer polymerization for dispersive solid phase extraction of polycyclic aromatic hydrocarbons in water,https://api.elsevier.com/content/abstract/scopus_id/85072157425,"Magnetic molecularly imprinted polymers (MMIPs) combine nanotechnology and molecular imprinting technology to offer selective and tunable enrichment for water analysis. In this paper, a selective sorbent was prepared by surface polymerization onto magnetic Fe3O4@SiO2 nanoparticles through reversible addition fragmentation chain transfer (RAFT) polymerization. The MMIPs were used for dispersive solid phase extraction (DSPE) of 16 PAHs as priority pollutants in aqueous matrices. After preconcentration, the analysis was performed using gas chromatography with an atmospheric pressure chemical ionization-tandem mass spectrometry (APGC–MS/MS). The extraction method is based on the dispersion of MMIPs in an aqueous sample using an ultrasonic bath which provides rapid equilibrium of analytes between the sorbent and sample solution. The enriched analytes were retrieved by collecting MMIP particles and desorbed into an organic solvent before instrumental analysis. A design of experiment (DOE) approach was applied to optimize several extraction parameters including the mass of MMIPs, the sample volume, salt addition, collection time, desorption volume, and desorption time. A fractional factorial design (FFD) (26-2) was performed to assess the influence of the selected factors on the extracted amount of analytes. The most effective factors including the mass of MMIPs, the volume of sample solution, and salt content was further investigated using central composite design (CCD) and yielded quadratic models between dependent and independent variables. The optimum conditions of DSPE obtained by desirability function (DF) were employed for preconcentration of PAHs in water samples. The evaluation showed that the MMIPs provide higher extraction efficiency compared to nanoparticles such as Fe3O4, Fe3O4@SiO2 and non-imprinted polymer, demonstrating the creation of selective recognition binding sites at the surface of magnetic nanoparticles. The LODs and LOQs ranged from 1 to 100 pg mL−1 and 2 to 200 pg mL−1, respectively. Finally, the MMIP-DSPE method was successfully applied for preconcentration and trace quantification of PAHs in real samples such as produced water and river water samples.",science
10.1016/j.jep.2019.112221,Journal,Journal of Ethnopharmacology,scopus,2020-01-10,sciencedirect,Dezhou donkey (Equus asinus) milk a potential treatment strategy for type 2 diabetes,https://api.elsevier.com/content/abstract/scopus_id/85071945083,"Ethnopharmacological relevance
                  Donkey (Equus asinus) milk has become a medical and nutrient product since ancient times. In addition, donkey milk was regarded as a medicinal food and substitute product for infant formula in some ancient western countries. Chinese ancient medical books documented the medicinal value of donkey milk, using donkey milk to treat diabetes, cough and jaundice.
                  
               
                  Aim of the study
                  To investigate the donkey milk’s components and anti-diabetic effect of donkey milk in vitro and in vivo and to study the molecular mechanism of donkey milk was an anti-diabetic medication.
               
                  Materials and methods
                  In this study, the gastrointestinal digested donkey milk was simulated in vitro and its products of protein digestion were analyzed by SDS-PAGE. We then performed cell viability assay, insulin secretion assay, animal experiments and ELISA assays to study the anti-diabetic effect of donkey milk in vitro and in vivo. Donkey milk’s anti-diabetic molecular mechanism and specific targets were detected by using quantitative real time PCR.
               
                  Results
                  Lysozyme (LZ) and α-lactalbumin (α-La) exhibited significantly lower digestibility and higher retention than the other components of donkey milk. In vitro, 500 μg/mL of donkey milk could improve damaged β-cells viability significantly (P < 0.0001). In vivo, the blood glucose and HOMA-IR of diabetic rats treated with donkey milk were 14.23 ± 5.18 mM and 74.94 ± 23.62, respectively, whereas the diabetic group were 22.18 ± 2.23 mM and 112.16 ± 18.44, respectively (P < 0.01). The SOD value of donkey milk group was 265.87 ± 21.29 U/L, while the SOD value of diabetic group was 193.20 ± 52.07 U/L (P < 0.05). These results indicated that the blood glucose was reduced, the ability of the body to eliminate free radicals was enhanced, antioxidant levels in the body was increased, insulin resistance was improved in type 2 diabetic rats after donkey milk powder fed for 4 weeks. Furthermore, donkey milk could treat diabetes through down-regulating phosphoenolpyruvate carboxykinase 1 (Pck1) and glucose-6-phosphatase (G6PC).
               
                  Conclusions
                  Donkey milk has played an important role in the treatment of type 2 diabetes, and contributed to the development of the donkey milk products.",science
10.1016/j.knosys.2019.105039,Journal,Knowledge-Based Systems,scopus,2020-01-05,sciencedirect,Gaussian Mixture Descriptors Learner,https://api.elsevier.com/content/abstract/scopus_id/85072227460,"In recent decades, various machine learning methods have been proposed to address classification problems. However, most of them do not support incremental (or online) learning and therefore are neither scalable nor robust to dynamic problems that change over time. In this study, a classification method was introduced based on the minimum description length principle, which offered a very good trade-off between model complexity and predictive power. The proposed method is lightweight, multiclass, and online. Moreover, despite its probabilistic nature, it can handle continuous features. Experiments conducted on real-world datasets with different characteristics demonstrated that the proposed method outperforms established online classification methods and is robust to overfitting, which is a desired characteristic for large, dynamic, and real-world classification problems.",science
10.1016/j.knosys.2019.07.015,Journal,Knowledge-Based Systems,scopus,2020-01-05,sciencedirect,User intimacy model for question recommendation in community question answering,https://api.elsevier.com/content/abstract/scopus_id/85069593237,"In this paper, we address the problem of automatic recommendation of new questions to suitable users in community question answering (CQA). The major challenge is the accurate selection of suitable users to answer a given question. Most approaches seek suitable users for a question by estimating their capability, interests or a blend of both. However, this ignores intimacy between the user and the asker of a question over different topics. Intimacy between askers and answerers is an important factor in question recommendation. For example, a user is likely to post an answer if interested in a question and intimate with its asker. We propose to model and learn intimacy between users over topics with social interaction in CQA for question recommendation using a novel topic model. We believe this paper is the first to estimate the intimacy between users over different topics and investigate influences on the performance of question recommendation in CQA. We propose a user intimacy model (UIM), an LDA-style model that incorporates social interaction in the generative process of a question-answer (QA) pair to model and learn intimacy between users over topics. Experiments using real-world data from Stack Overflow show that our UIM-based approach consistently and significantly improves the performance of question recommendation, demonstrating that our approach can increase question recommendation accuracy in CQA by utilizing the intimacy between users over topics and that this is an important factor in question recommendation.",science
10.1016/j.neucom.2019.09.004,Journal,Neurocomputing,scopus,2020-01-02,sciencedirect,Digital neuromorphic real-time platform,https://api.elsevier.com/content/abstract/scopus_id/85072526243,"Hardware implementations of spiking neural networks in portable devices can improve many applications of robotics, neurorobotics or prosthetic fields in terms of power consumption, high-speed processing and learning mechanisms. Analog and digital platforms have been previously proposed to run these networks. Analog designs are closer to biology since they implement the original mathematical model. However, digital platforms are, to some extent, abstractions of this model so far. In this paper, a full digital platform to design, implement and run real-time analog-like spiking neural networks is presented. Specifically, we present the design and implementation of digital circuits to run real-time biologically plausible spiking neural networks on a Field Programmable Gate Array (FPGA). The circuit designed for the neuron implements the Leaky Integrate and Fire (LIF) model. The synapsis implemented is a bi-exponential current-based one. The synaptic circuit design consists of one static memory with the baseline current and a dynamic memory which stores the updated contribution over time of each pre-synaptic connection. All the parameters of both the neuron and the synapse are configurable. The results of the circuits are validated by running the same experiments on the Brian simulator. The circuits, which are totally original and independent of the technology, use only 136 slice registers of hardware resources. Thus, these designs allow the scale of the network. These circuits aim to be the basis of the spiking neural networks on digital devices. This platform allows the user to first simulate their network within the Brian simulator and then, confidently, move to the hardware platform replicating the same performance or even replace their analog platform with the digital one.",science
10.1016/j.ifacol.2021.04.197,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Cognitive Artificial Population System: Framework and Application,https://api.elsevier.com/content/abstract/scopus_id/85107879835,"Agent-based social simulation has been comprehensively applied in the research of social and ecological systems. At its core is an artificial population, which endogenously drives the system evolution for particular applications, such as urban transportation, reginal economics, analysis of infectious disease transmission, and military simulation. In contrast with the previous population simulations where simple mathematical models are used to ‘reproduce’ actual demographic features, this paper proposes a self-evolutionary digital population system, named as Cognitive Artificial Population System (CAPS). At a more fine-grained level, CAPS focuses on the agent cognitive, reasoning and learning process in their surrounding environment, thus can exploit most advantages from cognitive computing and Artificial Intelligence. As a case study, Chinese population evolution is implemented using the proposed framework. Computational experiments indicate that CAPS is able to achieve good predicted population structures for real social systems.",science
10.1016/j.promfg.2020.11.012,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Application of machine learning and vision for real-time condition monitoring and acceleration of product development cycles,https://api.elsevier.com/content/abstract/scopus_id/85100766330,"Development work within an experimental environment, in which certain properties are investigated and optimized, requires many test runs and is therefore often associated with long execution times, costs and risks. This can affect product, material and technology development in industry and research. New digital driver technologies offer the possibility to automate complex manual work steps in a cost-effective way, to increase the relevance of the results and to accelerate the processes many times over. In this context, this article presents a low-cost, modular and open-source machine vision system for test execution and evaluates it on the basis of a real industrial application. For this purpose a methodology for the automated execution of the load intervals, the process documentation and for the evaluation of the generated data by means of machine learning to classify wear levels. The software and the mechanical structure are designed to be adaptable to different conditions, components and for a variety of tasks in industry and research. The mechanical structure is required for tracking the test object and represents a motion platform with independent positioning by machine vision operators or machine learning. An evaluation of the state of the test object is performed by the transfer learning after the initial documentation run. The manual procedure for classifying the visually recorded data on the state of the test object is described for the training material. This leads to an increased resource efficiency on the material as well as on the personnel side since on the one hand the significance of the tests performed is increased by the continuous documentation and on the other hand the responsible experts can be assigned time efficiently. The presence and know-how of the experts are therefore only required for defined and decisive events during the execution of the experiments. Furthermore, the generated data are suitable for later use as an additional source of data for predictive maintenance of the developed object.",science
10.1016/j.promfg.2020.05.123,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Integrated tool condition monitoring systems and their applications: A comprehensive review,https://api.elsevier.com/content/abstract/scopus_id/85095576577,"In conventional metal cutting, different tool wear modes, and their individual deterioration rates play vital roles in overall production performance. For a given tool (i.e., geometry or materials), many shop floors still follow a standard rule by pre-setting a tool life, which is conservative but not realistic. Premature failure of a tool can cause unexpected machine downtime and material losses, while another tool could serve beyond that pre-set life. As a result, optimized tool life and productivity cannot be achieved. Moreover, nowadays, there is an increased demand of process monitoring and optimization on the unmanned and the semi-automated shop floors.
                  Tool condition monitoring (TCM) systems for process improvement and optimization have been in research for several decades. Both offline and online TCM systems are invented and discussed. A wide range of original publications are reported focusing on different sub-topics, e.g., specific machining process-based TCM methods, measurement or signal acquisition methods, processing methods, and classifiers. With the recent evolution of smart sensors in the era of Industry 4.0, development of online TCM systems received much attention to the researchers. Accordingly, research on some sub-topics also gets motivated into different directions, such as, feasibility of power or current sensors, machine vision technique, and combination of multi-sensors. Thus, from the industrial viewpoint, the current state of implementation of the proposed TCM systems for (near) real-time process monitoring and control needs to be clear. This paper presents the state-of-the-art of the TCM systems covering three major machining operations, discusses their application feasibility in industry environments, and states some current TCMS implementations. Challenges being faced by the industry are concluded, along with direction and suggestions for future researches.",science
10.1016/j.jksuci.2020.09.013,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2020-01-01,sciencedirect,Affect detection from arabic tweets using ensemble and deep learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85095572698,"Affect detection from text has captured the attention of researchers recently. This is due to the rapid use of social media sites (e.g. Twitter, Facebook), which allows users to express their feelings, emotions, and thoughts in textual format. Analyzing emotion-rich textual data of social networks has many real-life applications. The context of an emotional text can be measured by analyzing certain features of this rich source of emotional information. Classifying text into emotional labels/intensities is considered a difficult problem. This paper resolves one of the state-of-the-art NLP research emotion and intensity detection tasks using Deep Learning and ensemble implementations. In this paper, we developed several innovative approaches; (a) bidirectional GRU_CNN (BiGRU_CNN), (b) conventional neural networks (CNN), and (c) XGBoost regressor (XGB). The ensemble of BiGRU_CNN, CNN, and XGB is used to solve an emotion intensity (EI-reg) task of the SemEval-2018 Task1 (Affect in Tweets). Our proposed ensemble approach was evaluated using a reference dataset of the SemEval-2018 Task1. Results show that our approach is well above the baseline for this task. It also achieved a Pearson of (69.2%), with an enhancement of 0.7% in comparison with previous best performing models.",science
10.1016/j.measurement.2020.108135,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-01-01,sciencedirect,A novel approach based on pattern recognition techniques to evaluate magnetic properties of a non-grain oriented electrical steel in the secondary recrystallization process,https://api.elsevier.com/content/abstract/scopus_id/85089036639,"This paper proposes a new automatic approach based on machine learning strategies to associate the microstructural conditions of Non-Grain Oriented (NGO) steels, during secondary recrystallization, with their magnetic losses, which were determined from hysteresis loops. These hysteresis curves and the states of the secondary recrystallization enabled us to establish the feature extraction and the labels for the classification problem. We also applied a specific methodology to create synthetic samples to overcome the available database, which was too small, and its imbalance among the classes. As far as the authors know, this is the first time that a study has treated this issue in this manner. Normally, magnetic losses of NGO steels are analyzed through expensive and laborious tests. We evaluated our proposal through computer experiments with several state-of-the-art classifiers. The Least Squares Support Vector Machine (LSSVM) achieved the best results with 88.9% accuracy using real samples.",science
10.1016/j.procs.2020.04.220,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Design and Fabrication of SHRALA: Social Humanoid Robot Based on Autonomous Learning Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85086626621,"This paper presents the preliminary research work in the Design, Fabrication of a Social Humanoid Robot based on Autonomous Learning Algorithm (SHRALA). Virtual Model of the humanoid robot was developed using Solidworks environment. This model is then fabricated using Creality Ender-3 3D printer. The electronic control circuit was designed and interfaced to computer using ATMEGA 2650 controller board, based on 8-bit AVR microcontroller. In order to easily and efficiently control the SHRALA a Graphical User Interface (GUI) was created using Unity3D editor, where a simple USB joystick was used to actuate the motions of the SHRALA in the virtual environment. The fabricated SHRALA was controlled in real time using a serial communication interface created between the GUI and Arduino Mega 2650 board. The humanoid robot was successfully controlled using the GUI environment and the preliminary results are satisfactory as it is performing the task as per the desired instructions. This research work is a part of the real time humanoid robot development project “SHRALA”, In near future autonomous learning algorithm will also be implemented in the robot and the same will be published as research article in a modular approach.",science
10.1016/j.procs.2020.03.327,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Music chord inversion shape identification with LSTM-RNN,https://api.elsevier.com/content/abstract/scopus_id/85084484268,"The art of music production has changed slowly over time with the technological advances. Multifarious automated solutions have lent a helping and to the musicians in different ways from practice to production and stage performance. In the context of a musical composition, the background music (BGM) is extremely important as the lead melody. One of the building blocks of BGM is a chord which is composed of two or more musical notes played simultaneously. Each chord can be played in multiple ways which adds to the melodic variety. Each of these ways is termed as inversions whose identification is extremely important for analyzing compositions and transcribing them. It is also extremely important for automated BGM or lead melody generation, where the inversion form or shape of a chord plays a pivotal role in the feeling of a composition. The challenge of chord shape identification further increases for clips of shorter length which is very critical for real time processing. In this paper a system is presented which distinguishes chord shapes from clips of extremely short durations. Experiments were done with as many as 40572 clips recorded in ordinary room environment and a highest accuracy of 99.47% has been obtained with LSF-deltaS deltaG features and LSTM-RNN-based classification.",science
10.1016/j.procs.2020.03.187,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Churn Prediction in Telecommunication using Logistic Regression and Logit Boost,https://api.elsevier.com/content/abstract/scopus_id/85084443717,"Today in every industry weather, it is ISP, IT products, social network or mobile services there is the problem of customer churn (Customers changing their services from one service provider to another). However, in telecommunication the customers churning very frequently. As the market in telecom is fiercely competitive, in that case, companies proactively have to determine the customers churn by analyzing their behavior and try to put effort and money in retaining the customers. In this proposed model, two machine-learning techniques were used for predicting customer churn Logistic regression and Logit Boost. Experiment was carried out in the WEKA Machine-learning tool, along with a real database from an American company Orange. The result were shown in different evaluation measures.",science
10.1016/j.procs.2020.03.348,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Inferring Sentiments from Supervised Classification of Text and Speech cues using Fuzzy Rules,https://api.elsevier.com/content/abstract/scopus_id/85084436618,"In last half decade an increasing number of works published has manifested the tremendous progress in multimodal sentiment analysis. In real-life communication, people are spontaneously modulating their tone to accentuate specific points or to express their sentiments. This research work introduces a supervised fuzzy rule-based system for multimodal sentiment classification, that can identify the sentiment expressed in video reviews on social media platform. It has been demonstrated that multimodal sentiment analysis can be effectively performed by the joint use of linguistic and acoustic modalities. In this paper computation of the sentiment using an ingenious set of fuzzy rules has been applied to label the review into: positive or negative sentiment. The confidence score from supervised Support Vector Machine (SVM) classification of text and speech cues is considered as the input variable for the fuzzy rules. The fusion of fuzzy logic with acoustic and linguistic features for classifying sentiment contributes a new exemplar in multimodal sentiment analysis. Our fuzzy approach has been compared with eight state-of-the-art techniques for supervised machine learning. The experiments on benchmark datasets yield 82.5 % accuracy for our approach which is higher in contrast to the state-of-the-art.",science
10.1016/j.jksuci.2020.03.008,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2020-01-01,sciencedirect,Romanized Tunisian dialect transliteration using sequence labelling techniques,https://api.elsevier.com/content/abstract/scopus_id/85082820171,"In recent years, social web users in Arabic countries have been resorting to the dialects as a written language in their social exchanges. Arabic dialects derive from modern standard Arabic (MSA) and differ significantly from one country to another and one region to another. The use of these dialects has led to an increase of interest in the specificities of such informal languages and their automatic processing within the NLP community. In this work, we deal with the Tunisian dialect (TD) in particular. We address the issue of the automatic Latin to Arabic transliteration of TD language productions on the social web and propose an approach that models the transliteration as a sequence labeling task. At a word level, several techniques, based on machine and deep learning, have been tested for this study, using real word messages extracted from social networks. We experiment and compare three transliteration models: A Conditional Random Fields-based model (CRF), a Bidirectional Long Short-Term Memory based model (BLSTM), and a BLSTM based model with CRF decoding (BLSTM-CRF). The obtained results show that BLSTM-CRF, leads to the best performance, reaching 96.78% of correctly transliterated words. We also evaluate the BLSTM-CRF transliteration approach in context on a set of random TD messages extracted from the social web. We obtained a total error rate of 2.7%. 25% of which are context errors.",science
10.1016/j.ebiom.2019.102609,Journal,EBioMedicine,scopus,2020-01-01,sciencedirect,MELK promotes Endometrial carcinoma progression via activating mTOR signaling pathway,https://api.elsevier.com/content/abstract/scopus_id/85078725163,"Background
                  Endometrial carcinoma (EC) is one of the most common gynecological malignancies among women. Maternal embryonic leucine Zipper Kinase (MELK) is upregulated in a variety of human tumors, where it contributes to malignant phenotype and correlates with a poor prognosis. However, the biological function of MELK in EC progression remains largely unknown.
               
                  Methods
                  We explored the MELK expression in EC using TCGA and GEO databases and verified it using clinical samples by IHC methods. CCK-8 assay, colony formation assay, cell cycle assay, wound healing assay and subcutaneous xenograft mouse model were generated to estimate the functions of MELK and its inhibitor OTSSP167. qRT-PCR, western blotting, co-immunoprecipitation, chromatin immunoprecipitation and luciferase reporter assay were performed to uncover the underlying mechanism concerning MELK during the progression of EC.
               
                  Findings
                  MELK was significantly elevated in patients with EC, and high expression of MELK was associated with serous EC, high histological grade, advanced clinical stage and reduced overall survival and disease-free survival. MELK knockdown decreased the ability of cell proliferation and migration in vitro and subcutaneous tumorigenesis in vivo. In addition, high expression of MELK could be regulated by transcription factor E2F1. Moreover, we found that MELK had a direct interaction with MLST8 and then activated mTORC1 and mTORC2 signaling pathway for EC progression. Furthermore, OTSSP167, an effective inhibitor, could inhibit cell proliferation driven by MELK in vivo and vitro assays.
               
                  Interpretation
                  We have explored the crucial role of the E2F1/MELK/mTORC1/2 axis in the progression of EC, which could be served as potential therapeutic targets for treatment of EC.
               
                  Funding
                  This research was supported by National Natural Science Foundation of China (No:81672565), the Natural Science Foundation of Shanghai (Grant NO:17ZR1421400 to Dr. Zhihong Ai) and the fundamental research funds for central universities (No: 22120180595).",science
10.1016/j.artmed.2019.101767,Journal,Artificial Intelligence in Medicine,scopus,2020-01-01,sciencedirect,SemBioNLQA: A semantic biomedical question answering system for retrieving exact and ideal answers to natural language questions,https://api.elsevier.com/content/abstract/scopus_id/85076035703,"Background and objective
                  Question answering (QA), the identification of short accurate answers to users questions written in natural language expressions, is a longstanding issue widely studied over the last decades in the open-domain. However, it still remains a real challenge in the biomedical domain as the most of the existing systems support a limited amount of question and answer types as well as still require further efforts in order to improve their performance in terms of precision for the supported questions. Here, we present a semantic biomedical QA system named SemBioNLQA which has the ability to handle the kinds of yes/no, factoid, list, and summary natural language questions.
               
                  Methods
                  This paper describes the system architecture and an evaluation of the developed end-to-end biomedical QA system named SemBioNLQA, which consists of question classification, document retrieval, passage retrieval and answer extraction modules. It takes natural language questions as input, and outputs both short precise answers and summaries as results. The SemBioNLQA system, dealing with four types of questions, is based on (1) handcrafted lexico-syntactic patterns and a machine learning algorithm for question classification, (2) PubMed search engine and UMLS similarity for document retrieval, (3) the BM25 model, stemmed words and UMLS concepts for passage retrieval, and (4) UMLS metathesaurus, BioPortal synonyms, sentiment analysis and term frequency metric for answer extraction.
               
                  Results and conclusion
                  Compared with the current state-of-the-art biomedical QA systems, SemBioNLQA, a fully automated system, has the potential to deal with a large amount of question and answer types. SemBioNLQA retrieves quickly users’ information needs by returning exact answers (e.g., “yes”, “no”, a biomedical entity name, etc.) and ideal answers (i.e., paragraph-sized summaries of relevant information) for yes/no, factoid and list questions, whereas it provides only the ideal answers for summary questions. Moreover, experimental evaluations performed on biomedical questions and answers provided by the BioASQ challenge especially in 2015, 2016 and 2017 (as part of our participation), show that SemBioNLQA achieves good performances compared with the most current state-of-the-art systems and allows a practical and competitive alternative to help information seekers find exact and ideal answers to their biomedical questions. The SemBioNLQA source code is publicly available at https://github.com/sarrouti/sembionlqa.",science
10.1016/j.intimp.2019.106066,Journal,International Immunopharmacology,scopus,2020-01-01,sciencedirect,Astragaloside IV attenuates sepsis-induced intestinal barrier dysfunction via suppressing RhoA/NLRP3 inflammasome signaling,https://api.elsevier.com/content/abstract/scopus_id/85075965218,"Intestinal barrier dysfunction is a trigger for sepsis progression. NLRP3 inflammasome and RhoA contribute to sepsis and intestinal inflammation. The current study aimed to explore the effects of Astragaloside IV (AS-IV), a bioactive compound from Astragalus membranaceus, on sepsis-caused intestinal barrier dysfunction and whether NLRP3 inflammasome and RhoA are involved. Septic mice modeled by cecal ligation and puncture (CLP) operation were administered with 3 mg/kg AS-IV intravenously. AS-IV decreased mortality, cytokines release, I-FABP secretion, intestinal histological score and barrier permeability, and increased tight junction (TJ) expression in intestine in CLP model. Also, in Caco-2 cells subjected to lipopolysaccharide (LPS), 200 μg/mL AS-IV co-incubation reduced cytokines levels and enhanced in vitro gut barrier function without cytotoxicity. Subsequently, NLRP3 inflammasome and RhoA were highly activated both in intestinal tissue in vivo and in Caco-2 cells in vitro, both of which were significantly suppressed by AS-IV treatment. In addition, the benefits of AS-IV on Caco-2 monolayer barrier were largely counteracted by RhoA agonist CN03 and NLRP3 gene overexpression, respectively. Furthermore, LPS-induced NLRP3 inflammasome activation was abrogated by RhoA inhibitor C3 exoenzyme. However, NLRP3 knockdown by siRNA hardly affected RhoA activation in Caco-2 cells. These data suggest that AS-IV protects intestinal epithelium from sepsis-induced barrier dysfunction via inhibiting RhoA/NLRP3 inflammasome signal pathway.",science
10.1016/j.xphs.2019.09.026,Journal,Journal of Pharmaceutical Sciences,scopus,2020-01-01,sciencedirect,"Silicone Oil Particles in Prefilled Syringes With Human Monoclonal Antibody, Representative of Real-World Drug Products, Did Not Increase Immunogenicity in In Vivo and In Vitro Model Systems",https://api.elsevier.com/content/abstract/scopus_id/85075396123,"Silicone oil is a lubricant for prefilled syringes (PFS), a common primary container for biotherapeutics. Silicone oil particles (SiOP) shed from PFS are a concern for patients due to their potential for increased immunogenicity and therefore also of regulatory concern. To address the safety concern in a context of manufacturing and distribution of drug product (DP), SiOP was increased (up to ∼25,000 particles/mL) in PFS filled with mAb1, a fully human antibody drug, by simulated handling of DP mimicked by drop shock. These samples are characterized in a companion report (Jiao N et al. J Pharm Sci. 2020). The risk of immunogenicity was then assessed using in vitro and in vivo immune model systems. The impact of a common DP excipient, polysorbate 80, on both the formation and biological consequences of SiOP was also tested. SiOP was found associated with (1) minimal cytokine secretion from human peripheral blood mononuclear cells, (2) no response in cell lines that report NF-κB/AP-1 signaling, and (3) no antidrug antibodies or significant cytokine production in transgenic Xeno-het mice, whether or not mAb1 or polysorbate 80 was present. These results suggest that SiOP in mAb1, representative of real-world DP in PFS, poses no increased risk of immunogenicity.",science
10.1016/j.asoc.2019.105932,Journal,Applied Soft Computing Journal,scopus,2020-01-01,sciencedirect,Training data augmentation: An empirical study using generative adversarial net-based approach with normalizing flow models for materials informatics,https://api.elsevier.com/content/abstract/scopus_id/85075355223,"We address the issue of small data size for training models for regression problems, which is a significant issue in materials science. Many density estimators that use generative models based on deep neural networks have been proposed. With generative models, normalizing flows can provide exact density estimations. Using normalizing flows, we address training data augmentation issue, where we use a real-valued non-volume preserving model (real-NVP) as the normalizing flow. A generative adversarial net (GAN)-based training method is applied to improve real-NVP training using real-NVP as the generator. Using kernel ridge regression trained by generated data, generalization performance was measured for evaluating the models. Experiments were conducted with seven benchmark datasets and a dataset of ionic conductivity of materials to compare the GAN-based real-NVP to state-of-the-art models, such as real-NVP and masked autoregressive flows. The experimental results demonstrated that the GAN-based real-NVP was comparable to state-of-the-art models and implied that the data sampled by the GAN-based real-NVP were available as new training data.",science
10.1016/j.biopha.2019.109581,Journal,Biomedicine and Pharmacotherapy,scopus,2020-01-01,sciencedirect,Microsomal prostaglandin E synthase-1 promotes lung metastasis via SDF-1/CXCR4-mediated recruitment of CD11b<sup>+</sup>Gr1<sup>+</sup>MDSCs from bone marrow,https://api.elsevier.com/content/abstract/scopus_id/85074606468,"Background
                  Accumulation of myeloid-derived suppressor cells (MDSCs) to tumors is related to cancer prognosis. We investigated the contribution of host stromal microsomal prostaglandin E synthase-1 (mPGES-1) to the accumulation of MDSCs in metastasized lungs of prostate cancer in mice.
               
                  Material and methods
                  Eight-week-old male C57Bl/6 wild type (WT) mice and mPGES-1 knock out mice (mPGES-1KO) were injected with RM9 murine prostate cancer cell line (5 × 106 cells/mL). Lung metastasis was evaluated by the number of colonies, the weight of the lung, and the number of MDSCs (CD11b+Gr1+ cells) in the lung.
               
                  Results
                  Intravenous injections of RM9, a murine prostate cancer cell line to WT mice revealed that lung metastasis and accumulation of MDCSs were suppressed with treatments with a Gr1 antibody, a COX-2 inhibitor, and an mPGES-1 inhibitor. Lung metastasis and accumulation of CD11b+Gr1+MDSCs were suppressed in mPGES-1KO mice. The mRNA level of stromal cell-derived factor-1 (SDF-1) in the lung and the number of accumulated SDF-1-expressing CD11b+Gr1+ MDSCs were elevated at an early stage in lung metastasis of C-X-C chemokine receptor type 4 (CXCR4)-expressing RM9 in an mPGES-1-dependent manner. The number of CXCR4-expressing CD11b+Gr1+MDSCs in WT mice was higher than that in mPGES-1KO mice. RM9 lung metastasis and accumulation of CD11b+Gr1+MDSCs were suppressed by CXCR4 antibody in WT mice but not in mPGES-1KO. WT mice transplanted with mPGES-1 KO bone marrow (BM) showed a significant reduction in lung metastasis and accumulation of CD11b+Gr1+MDSCs.
               
                  Conclusion
                  These results suggest that mPGES-1 enhances tumor metastasis by inducing accumulation of BM-derived MDSCs. Selective mPGES-1 inhibitors might, therefore, represent valuable therapeutic tools for the suppression of tumor metastasis.",science
10.1016/j.actbio.2019.10.021,Journal,Acta Biomaterialia,scopus,2020-01-01,sciencedirect,Adaptive in vivo device for theranostics of inflammation: Real-time monitoring of interferon-γ and aspirin,https://api.elsevier.com/content/abstract/scopus_id/85074455944,"Cytokines mediate and control immune and inflammatory responses. Complex interactions exist among cytokines, inflammation, and the innate and adaptive immune responses in maintaining homeostasis, health, and well-being. On-demand, local delivery of anti-inflammatory drugs to target tissues provides an approach for more effective drug dosing while reducing the adverse effects of systemic drug delivery. This work demonstrates a proof-of-concept theranostic approach for inflammation based on analyte-kissing induced signaling, whereby a drug (in this report, aspirin) can be released upon the detection of a target level of a proinflammatory cytokine (i.e., interferon-γ (IFN-γ)) in real time. The structure-switching aptamer-based biosensor described here is capable of quantitatively and dynamically detecting IFN-γ both in vitro and in vivo with a sensitivity of 10 pg mL−1. Moreover, the released aspirin triggered by the immunoregulatory cytokine IFN-γ is able to inhibit inflammation in a rat model, and the release of aspirin can be quantitatively controlled. The data reported here provide a new and promising strategy for the in vivo detection of proinflammatory cytokines and the subsequent therapeutic delivery of anti-inflammatory molecules. This universal theranostic platform is expected to have great potential for patient-specific personalized medicine.
               
                  Statement of Significance
                  We developed an adaptive in vivo sensing device whereby a drug, aspirin, can be released upon the detection of a proinflammatory cytokine, interferon-γ (IFN-γ), in real time with a sensitivity of 10 pg mL−1. Moreover, the aspirin triggered by IFN-γ depressed inflammation in the rat model and was delivered indirectly through blood and cerebrospinal fluid or directly to the inflammation tissue or organ without adverse gastrointestinal effects observed in the liver and kidney. We envision that, for the first time, patients with chronic inflammatory disease can receive the right intervention and treatment at the right time. Additionally, this technology may empower patients to monitor their personalized health and disease management program, allowing real-time diagnostics, disease monitoring, and precise and effective treatments.",science
10.1016/j.envpol.2019.113370,Journal,Environmental Pollution,scopus,2020-01-01,sciencedirect,Development and validation of a UHPLC-MS/MS method for the identification of irinotecan photodegradation products in water samples,https://api.elsevier.com/content/abstract/scopus_id/85074416605,"Irinotecan (CPT-11) is a water-soluble anticancer drug widely used to treat several types of cancer.
                  Even if the metabolites of CPT-11 are well-known and investigated, only limited information is available in the literature about the formation of photo-degradation products that can naturally originate from sunlight irradiation when the drug is released in aqueous systems.
                  CTP-11 solutions at 10.0 mg L−1 were irradiated by simulated sunlight. The intensity of the drug decreased by 90% after 7.5 days of irradiation and no significant reduction of absorbance values was observed after 13 days.
                  A sensitive UHPLC-MS/MS method was developed employing a hybrid triple quadrupole/linear ion trap mass spectrometer, that is able to work in data-dependent acquisition mode and to obtain information about the compounds formed during the photoirradiation. Moreover, a selected reaction monitoring method was built using the MS/MS fragmentation pattern of the compounds previously investigated. The method was validated considering LOD, LOQ, linearity, precision, selectivity, recovery and matrix effect. LOD and LOQ values were 0.02 and 0.05 ng mL−1, respectively, whereas MDL and MQL values in real water samples (river water, groundwater, well water, and wastewater) were lower than 0.05 and 0.2 ng mL−1, respectively.
                  Eight photodegradation products were identified, among which five for the first time. Based on the MS and MS/MS fragmentation, the chemical structures of the degradation products were proposed. Hydrolysis experiments were carried out on the same solutions preserved in the dark, but no formation of other species was highlighted.
                  The method was applied to several real samples: CPT-11 was detected and quantified only in a hospital effluent sample at the concentration of 0.41 ± 0.2 ng mL−1 together with the occurrence of PDP3.
                  The outcomes of this study may be useful for updating the pollutant screening in water samples.",science
10.1016/j.cma.2019.112628,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-01-01,sciencedirect,Deep learning acceleration of Total Lagrangian Explicit Dynamics for soft tissue mechanics,https://api.elsevier.com/content/abstract/scopus_id/85072715847,"Simulating complex soft tissue deformations has been an intense research area in the fields of computer graphics or computational physiology for instance. A desired property is the ability to perform fast, if not real-time, simulations while being physically accurate. Numerical schemes have been explored to speed up finite element methods, like the Total Lagrangian Explicit Dynamics (TLED). However, real-time applications still come at the price of accuracy and fidelity. In this work, we explore the use of neural networks as function approximators to accelerate the time integration of TLED, while being generic enough to handle various geometries, motion and materials without having to retrain the neural network model. The method is evaluated on a set of experiment, showing promising accuracy at time steps up to 20 times larger than the “breaking” time step, as well as in a simple medical application. Such an approach could pave the way to very fast but accurate acceleration strategies for computational biomechanics.",science
10.1016/j.ipm.2019.102122,Journal,Information Processing and Management,scopus,2020-01-01,sciencedirect,Towards a real-time processing framework based on improved distributed recurrent neural network variants with fastText for social big data analytics,https://api.elsevier.com/content/abstract/scopus_id/85072609792,"Big data generated by social media stands for a valuable source of information, which offers an excellent opportunity to mine valuable insights. Particularly, User-generated contents such as reviews, recommendations, and users’ behavior data are useful for supporting several marketing activities of many companies. Knowing what users are saying about the products they bought or the services they used through reviews in social media represents a key factor for making decisions. Sentiment analysis is one of the fundamental tasks in Natural Language Processing. Although deep learning for sentiment analysis has achieved great success and allowed several firms to analyze and extract relevant information from their textual data, but as the volume of data grows, a model that runs in a traditional environment cannot be effective, which implies the importance of efficient distributed deep learning models for social Big Data analytics. Besides, it is known that social media analysis is a complex process, which involves a set of complex tasks. Therefore, it is important to address the challenges and issues of social big data analytics and enhance the performance of deep learning techniques in terms of classification accuracy to obtain better decisions.
                  In this paper, we propose an approach for sentiment analysis, which is devoted to adopting fastText with Recurrent neural network variants to represent textual data efficiently. Then, it employs the new representations to perform the classification task. Its main objective is to enhance the performance of well-known Recurrent Neural Network (RNN) variants in terms of classification accuracy and handle large scale data. In addition, we propose a distributed intelligent system for real-time social big data analytics. It is designed to ingest, store, process, index, and visualize the huge amount of information in real-time. The proposed system adopts distributed machine learning with our proposed method for enhancing decision-making processes. Extensive experiments conducted on two benchmark data sets demonstrate that our proposal for sentiment analysis outperforms well-known distributed recurrent neural network variants (i.e., Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), and Gated Recurrent Unit (GRU)). Specifically, we tested the efficiency of our approach using the three different deep learning models. The results show that our proposed approach is able to enhance the performance of the three models. The current work can provide several benefits for researchers and practitioners who want to collect, handle, analyze and visualize several sources of information in real-time. Also, it can contribute to a better understanding of public opinion and user behaviors using our proposed system with the improved variants of the most powerful distributed deep learning and machine learning algorithms. Furthermore, it is able to increase the classification accuracy of several existing works based on RNN models for sentiment analysis.",science
10.1016/j.neunet.2019.07.020,Journal,Neural Networks,scopus,2020-01-01,sciencedirect,Deep neural network and data augmentation methodology for off-axis iris segmentation in wearable headsets,https://api.elsevier.com/content/abstract/scopus_id/85072296970,"A data augmentation methodology is presented and applied to generate a large dataset of off-axis iris regions and train a low-complexity deep neural network. Although of low complexity the resulting network achieves a high level of accuracy in iris region segmentation for challenging off-axis eye-patches. Interestingly, this network is also shown to achieve high levels of performance for regular, frontal, segmentation of iris regions, comparing favourably with state-of-the-art techniques of significantly higher complexity. Due to its lower complexity this network is well suited for deployment in embedded applications such as augmented and mixed reality headsets.",science
10.1016/j.ins.2019.09.005,Journal,Information Sciences,scopus,2020-01-01,sciencedirect,Two-layer fuzzy multiple random forest for speech emotion recognition in human-robot interaction,https://api.elsevier.com/content/abstract/scopus_id/85071968961,"The two-layer fuzzy multiple random forest (TLFMRF) is proposed for speech emotion recognition. When recognizing speech emotion, there are usually some problems. One is that feature extraction relies on personalized features. The other is that emotion recognition doesn’t consider the differences among different categories of people. In the proposal, personalized and non-personalized features are fused for speech emotion recognition. High dimensional emotional features are divided into different subclasses by adopting the fuzzy C-means clustering algorithm, and multiple random forest is used to recognize different emotional states. Finally, a TLFMRF is established. Moreover, a separate classification of certain emotions which are difficult to recognize to some extent is conducted. The results show that the TLFMRF can identify emotions in a stable manner. To demonstrate the effectiveness of the proposal, experiments on CASIA corpus and Berlin EmoDB are conducted. Experimental results show the recognition accuracies of the proposal are 1.39%–7.64% and 4.06%–4.30% higher than that of back propagation neural network and random forest respectively. Meanwhile, preliminary application experiments are also conducted to investigate the emotional social robot system, and application results indicate that mobile robot can real-time track six basic emotions, including angry, fear, happy, neutral, sad, and surprise.",science
10.1016/j.future.2019.07.074,Journal,Future Generation Computer Systems,scopus,2020-01-01,sciencedirect,GLR: A graph-based latent representation model for successive POI recommendation,https://api.elsevier.com/content/abstract/scopus_id/85070641321,"Point-of-Interest (POI) recommendation is an important service in location-based social networks (LBSNs) since it can help a user to discover new POIs for future visiting. In order to provide better recommendation experience, a novel POI recommendation paradigm, named successive POI recommendation, has been proposed. The difference between traditional POI recommendation and successive POI recommendation is that successive POI recommendation focuses on recommending POIs that the target user may like to visit within a time period (e.g., a few hours). To address this problem, we propose a new graph-based latent representation model called GLR, to obtain the latent vectors of temporal successive transition influence and temporal user preference based on the historical check-in records. We also propose a novel method named GLR_GT to employ these latent vectors and geographical influence of POIs to perform successive POI recommendation. Moreover, we also propose an extended method named GLR_GT_LSTM to employ a long short-term memory (LSTM) neural network to model users’ complex transition behavior. Several experiments are conducted on some real-world LBSN datasets. Experimental results show that our proposed method GLR_GT_LSTM outperforms the other prior successive POI recommendation methods in terms of precision and recall.",science
10.1016/j.spinee.2019.06.025,Journal,Spine Journal,scopus,2020-01-01,sciencedirect,Anti-inflammatory effects of interleukin-4 on intervertebral disc cells,https://api.elsevier.com/content/abstract/scopus_id/85069693779,"BACKGROUND CONTEXT
                  Inflammation has been associated with a number of pathological conditions including intervertebral disc (IVD) degeneration, increased risks of low back pain and other spinal diseases. Downregulating disc inflammation may be a strategy to reduce degeneration and more importantly back pain. Interleukin (IL)-4 was first discovered as a T-cell secreted factor that enhanced the proliferation of anti-IgM stimulated B cells and is now known as a cytokine that can stimulate cell proliferation and differentiation, tissue regeneration and neurological functions. IL-4 has been shown to be effective in inhibiting inflammatory pathways in chondrocytes. Immunohistochemical studies have shown that disc tissues are immunopositive for IL-4 receptor α (IL-4Rα) and IL-4. Yet, the roles of IL-4 and IL-4R in disc biology remain unknown.
               
                  PURPOSE
                  The purpose of this study is to understand the roles of IL-4 and IL-4Rα in IVDs and to determine if IL-4 can function to inhibit inflammation in IVD cells.
               
                  STUDY DESIGN/SETTING
                  In vitro experiment.
               
                  METHODS
                  Deidentified patient IVD tissues were collected after surgery under the Orthopedic Information, Tissue and Implant Repository (ORA L00011021). IVD cells were isolated and cultured in monolayer. IL-4R protein expression was analyzed using immunocytochemistry. To test if the IL-4R was responsive to its ligand, signal transducer and activator of transcription 6 (STAT6) phosphorylation was analyzed on cell lysates of IVD cells treated with recombinant human IL-4 for 30 minutes using enzyme linked immunosorbent assay kit. Gene expression analysis of IL-4 up- and downregulated genes were analyzed using real-time RT-PCR. Anti-inflammatory effects of IL-4 were determined by cotreating disc cells with lipopolysaccharide (LPS) and IL-4 and measuring gene expression and protein release of inflammatory markers, IL-6 and IL-8. The significance of differences among means of data on gene expression and protein analyses were analyzed by one-way analysis of variance or student t test. Differences were considered significant when the p value was below 0.05.
               
                  RESULTS
                  Immunocytochemistry staining for IL-4Rα in primary IVD cells (n=8) showed the majority of immunopositive staining was intracellular. After IVD cells (n=3–7) were treated with different concentrations of recombinant human IL-4 (0.1–100 ng/mL) for 30 minutes, phospho-STAT6 levels significantly increased by two- to four-fold at all concentrations tested compared with untreated cells. Gene expression of IL-4Rα and IL-6 increased significantly in cells undergoing IL-4 treatment for 24 hours compared with control treated IVD cells (n=5–10). LPS stimulated inflammatory gene expression of interferon (IFN)β, IL-12, IL-6, and IL-8 were downregulated significantly in the presence of IL-4 (n=7). Lastly, protein release of IL-6 and IL-8 were reduced significantly in cells treated with IL-4 and LPS compared with those treated with LPS alone (n=7).
               
                  CONCLUSIONS
                  This study was the first to explore the function of IL-4 and IL-4R in IVD cells. Immunocytochemistry studies confirmed that the majority of cells isolated from patient IVDs expressed IL-4Rα at the protein level. Also, IVD cells can respond to IL-4 by up-regulating IL-4Rα and IL-6 genes and inhibiting inflammatory genes and proteins induced by LPS. Further studies to test the anti-inflammatory effects of IL-4 in the IVD would be needed in animal models.
               
                  CLINICAL RELEVANCE
                  Biological therapies which include intradiscal delivery of cells, anti-inflammatories or growth factors are being investigated to treat disc degeneration and back pain in animal models and in the clinic. Based on our findings that IL-4 has anti-inflammatory effects on IVD cells, the results of this study suggest including recombinant IL-4 delivery into the intervertebral disc may be a beneficial therapeutic strategy to treat patients with back pain by reducing disc inflammation.",science
10.1016/j.jviromet.2019.113688,Journal,Journal of Virological Methods,scopus,2020-01-01,sciencedirect,Inhibition of herpes simplex virus type 1 by copper oxide nanoparticles,https://api.elsevier.com/content/abstract/scopus_id/85069464037,"There are accumulating reports of the emergence of drug-resistant strains of HSV-1 that have become a barrier to successful treatment of HSV-1 infection. Therefore, there is a pressing need to identify and evaluate alternative antiherpetic agents. The aim of the present study was to investigate the effect of copper oxide nanoparticles (CuO-NPs) on HSV-1 infection. The MTT assay was applied to examine the cytotoxic effects of CuO-NPs on Vero cells. Antiherpetic potency was determined using the TCID50 and quantitative Real-Time PCR assays. To evaluate the inhibitory impact of CuO-NPs on the expression of viral antigens, an indirect immunofluorescence assay (IFA) was performed. Acyclovir was used as a reference drug in all experiments. Exposure of HSV-1 with CuO-NPs at the highest non-toxic concentration (100 μg/mL) resulted in 2.8 log10 TCID50 reduction in infectious virus titer as compared with virus control (P < 0.0001). This concentration of CuO-NPs was associated with 83.3% inhibition rate, which was estimated based on the HSV-1 viral load compared to virus control. Our findings demonstrated that CuO-NPs are associated with a significant antiviral potency against HSV-1. This feature shows strong potential for CuO-NPs to be used in topical formulations for the treatment of orolabial or genital herpetic lesions.",science
10.1016/j.knosys.2019.07.014,Journal,Knowledge-Based Systems,scopus,2020-01-01,sciencedirect,A new decision support system for knowledge management in archaeological activities”,https://api.elsevier.com/content/abstract/scopus_id/85068965128,"The use of Information Technologies (IT) has today become an added value for appropriate decision making. This has contributed to improving the companies’ strategies in the market. However, the full potential of these technologies in the relevant field of Archaeology has yet to be fully exploited. To contribute to reducing this gap, this paper presents a new and original design of a Process Maturity Framework for archaeological knowledge and data management which may be applied for high-level timely decision making, supported by an ‘IT Governance’ reference frame, in order to improve the quality and efficiency of the services provided by the Diagnostic, Prospecting, Monitoring and Excavation processes of the Preemptive Archaeology Program.
                  This new Process Maturity Model (PMM) takes the processes which are currently established in each phase of archaeological projects as its reference to improve information analysis, reports generation and support decision-making processes, as well as to manage and control the materials and context found in the field. This is achieved by emphasizing the use of the information required for future queries and projections, ensuring its’ quality and integrity in order to generate reports more efficiently, whilst also allowing a more agile and timely decision-making process. Said information has been collected during the field and laboratory processes by analysing the proper application and management of the technology from an ‘IT Governance’ framework in companies which offer archaeological services.
                  The different phases of the implementation of the model designed, based in ITIL, since it is the most holistic of the current benchmarks in Technology Services Management, are shown by means of a hypothetical, yet real, application of the PMM in an Archaeology Consultancy firm. Thus, a set of basic parameters is initially established in order to implement a PMM. Then, a diagnostic on the processes and IT Service Management applied to each archaeological phase is performed. Afterwards, an evaluation of the current maturity level of the processes is carried out and, finally, the continuous improvement plan is described.",science
10.1016/j.eswa.2019.07.006,Journal,Expert Systems with Applications,scopus,2019-12-15,sciencedirect,Learning deep neural networks for node classification,https://api.elsevier.com/content/abstract/scopus_id/85068514427,"Deep Neural Network (DNN) has made great leaps in image classification and speech recognition in recent years. However, employing DNN for node classification such as in social network remains to be a non-trivial problem. Moreover, the current advanced method of implementing node classification tasks usually takes two steps, i.e. firstly, the embedding vector of the node is obtained through network embedding and then the classifier such as SVM is leveraged to do the task. Distinctly, this may only get the suboptimal solution of the problem. To settle the above issues, a novel Deep Neural Network method for node classification named DNNNC is proposed in the framework of Deep Learning. Specifically, we first get the positive pointwise mutual information (PPMI) matrix from the given adjacency matrix. Then, the data is fed to deep neural network composed of deep stacked sparse autoencoders and softmax layer, which could learn the node representation while encoding the rich nonlinear structural and semantic information and could be well trained for node classification under the DNN framework. Extensive experiments are conducted on real-world network datasets for node classification task and have shown that the proposed model DNNNC outperforms the state-of-the-art method in the view of superior performance.",science
10.1016/j.aca.2019.08.019,Journal,Analytica Chimica Acta,scopus,2019-12-04,sciencedirect,An exonuclease-assisted triple-amplified electrochemical aptasensor for mucin 1 detection based on strand displacement reaction and enzyme catalytic strategy,https://api.elsevier.com/content/abstract/scopus_id/85070664893,"The development of some sensitive methods for MUC1 is critical for preclinical diagnosis of tumors. In this experiment, we built a triple-amplified electrochemical aptasensor to achieve sensitive detection of MUC1, which was based on exonuclease III (Exo III)-assisted with strand displacement reaction and enzyme catalytic strategy. Firstly, with the help of Exo III, MUC1 and aptamer could be recycled during the cycle I, the single stranded DNA-1 (S-1) was produced during the process and was introduced to the hybride reaction on the electrode. Secondly, during the cycle II, strand displacement reaction was triggered on the electrode with the adding of hairpin DNA-2 (H-2). Thirdly, after the gold nanoparticles (AuNPs)-DNA-enzyme conjugates hybrided with the H-2 on the electrode, the AuNPs-DNA-enzyme conjugates could act as signal probe to produce electrochemical catalytic signal. We used the fabricated triple-amplified electrochemical aptasensor that could detect MUC1 from 0.1 pg mL−1 to 10 ng mL−1 with the detection limit of 0.04 pg mL−1 under the optimized experimental conditions. The constructed triple-amplified electrochemical aptasensor could be applied in real samples determination. Besides, the strategy can be applied to detect other proteins for health monitoring.",science
10.1016/j.vetmic.2019.108450,Journal,Veterinary Microbiology,scopus,2019-12-01,sciencedirect,UV-C irradiation is able to inactivate pathogens found in commercially collected porcine plasma as demonstrated by swine bioassay,https://api.elsevier.com/content/abstract/scopus_id/85075243758,"Liquid porcine plasma is an animal origin raw material for the manufacturing process of spray-dried porcine plasma that is used in pig nutrition worldwide. In previous studies we found that the application of ultraviolet light C (UV-C) in liquid plasma that was inoculated with a variety of bacteria or viruses of importance in the swine industry can be considered as redundant safety steps because in general achieve around 4 logs reduction for most of these pathogens. However, the final validation of the UV-C light as safety feature should be conducted with commercial liquid plasma and using the pig bioassay model. As a first objective, the potential infectivity of a raw liquid plasma product collected from an abattoir was tested by means of a swine bioassay. We used Porcine circovirus 2 (PCV-2), a ubiquitous virus that has been systematically detected by PCR in porcine plasma at abattoirs as selection criteria for commercial liquid plasma lot. As a second aim of the study, the effects of different doses of UV-C irradiation on the selected raw liquid plasma were assayed in the animal bioassay. Moreover, other swine infecting agents, including Porcine reproductive and respiratory syndrome virus (PRRSV), were also determined in the original plasma and monitored in the inoculated animals. Pigs negative for PCV-2 and PRRSV genome and antibodies were allotted to one of five groups (6 to 8 pigs/ group) and injected intra-peritoneally with 10 mL of their assigned inoculum at 50 d of age. Negative control pigs (group 1) were injected with PBS. Positive control pigs (group 5) were injected with a PCV-2 inoculum. Groups 2, 3 and 4 were injected with liquid porcine plasma that had been subjected to 0 (raw plasma), 3000 or 9000 J/L UV-C irradiation, respectively. Group 2 pigs (0 J/L UV-C) got infection by PRRSV but no PCV-2 infection or seroconversion. However, one pig from group 2 seroconverted to Rotavirus A (RVA) and Hepatitis E virus (HEV) and three group 2 pigs seroconverted to Porcine parvovirus (PPV). Groups 1, 3 and 4 pigs showed no evidence of infection or seroconversion associated with the tested viruses or any other pathogens found in the liquid plasma before UV-C irradiation. Group 5 pigs developed PCV-2 infectivity as expected. UV-C irradiation of liquid plasma at 3000 and 9000 J/L was effective in preventing PRRSV and other pathogens transmission. Moreover, raw liquid plasma was non-infectious for PCV-2 in naïve pigs.",science
10.1016/j.visres.2019.09.005,Journal,Vision Research,scopus,2019-12-01,sciencedirect,One-shot categorization of novel object classes in humans,https://api.elsevier.com/content/abstract/scopus_id/85074616387,"One aspect of human vision unmatched by machines is the capacity to generalize from few samples. Observers tend to know when novel objects are in the same class despite large differences in shape, material or viewpoint. A major challenge in studying such generalization is that participants can see each novel sample only once. To overcome this, we used crowdsourcing to obtain responses from 500 human observers on 20 novel object classes, with each stimulus compared to 1 or 16 related objects. The results reveal that humans generalize from sparse data in highly systematic ways with the number and variance of the samples. We compared human responses to ‘ShapeComp’, an image-computable model based on >100 shape descriptors, and ‘AlexNet’, a convolution neural network that roughly matches humans at recognizing 1000 categories of real-world objects. With 16 samples, the models were consistent with human responses without free parameters. Thus, when there are a sufficient number of samples, observers rely on shallow but efficient processes based on a fixed set of features. With 1 sample, however, the models required different feature weights for each object. This suggests that one-shot categorization involves more sophisticated processes that actively identify the unique characteristics underlying each object class.",science
10.1016/j.swevo.2019.100614,Journal,Swarm and Evolutionary Computation,scopus,2019-12-01,sciencedirect,Identifying influential nodes based on ant colony optimization to maximize profit in social networks,https://api.elsevier.com/content/abstract/scopus_id/85074495178,"One of the most important applications for identification of influential nodes in social networks is viral marketing. In viral marketing, there are valuable users from which companies or smaller businesses benefit most at the lowest cost. Inspired from the behavior of real ants and based on the ant colony optimization algorithm, we propose new methods named PMACO and IMOACO in this paper to find the most valuable users. First, the influence graph is derived from the analysis of users’ interactions and communications in a social network. The negative influence among users is also considered in the process of generating the influence graph. For reduction of computational complexity and removal of unimportant nodes from the influence graph, the nodes the levels of influence of which on their neighbors are less than a specific threshold value are eliminated. Then, the representation of the search space as a weighted graph is constructed by the remaining nodes, where the weight of each edge is the similarity between the two nodes of which that edge is composed. Next, the ants begin their search processes with the goal of maximizing profit and minimizing the similarity among the selected nodes. Assessments have been made on real and synthetic datasets, and compared the proposed algorithm with well-known ones. The results of the experiments demonstrate the efficiency of the proposed algorithm.",science
10.1016/j.jmapro.2019.10.020,Journal,Journal of Manufacturing Processes,scopus,2019-12-01,sciencedirect,Data-driven smart manufacturing: Tool wear monitoring with audio signals and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85074281429,"Tool wear in machining could result in poor surface finish, excessive vibration and energy consumption. Monitoring tool wear in real-time is crucial to improve manufacturing productivity and quality. While numerous sensor-based tool wear monitoring techniques have been demonstrated in laboratory environments, few tool wear monitoring systems have been deployed in factories because it is not realistic to install some of the important sensors such as dynamometers on manufacturing machines. To address this issue, a novel audio signal processing approach is introduced. This technique does not require expensive sensors but audio sensors only. A blind source separation method is used to separate source signals from noise. An extended principal component analysis is used for dimensionality reduction. Real-time multi-channel audio signals are collected during a set of milling tests under varying cutting conditions. The experimental data are used to develop and validate a predictive model. Experimental results have shown that the predictive model is capable of classifying tool wear conditions with high accuracy.",science
10.1016/j.bios.2019.111732,Journal,Biosensors and Bioelectronics,scopus,2019-12-01,sciencedirect,An amplified label-free electrochemical aptasensor of γ-interferon based on target-induced DNA strand transform of hairpin-to-linear conformation enabling simultaneous capture of redox probe and target,https://api.elsevier.com/content/abstract/scopus_id/85072652093,"In this work, a novel and signal-amplified label-free electrochemical aptasensor was developed and enabled efficient determination of γ-interferon (IFN-γ), based on target-induced DNA strand transform of hairpin-to-linear conformation combining with simultaneous capture of redox probe and target. Gold nanoparticles (AuNPs) were electrodeposited in the matrix of poly(amidoamine) dendrimer (PAMAM), followed by drop-casting addition on MoS2 nanosheets to prepare AuNPs- PAMAM/MoS2 composites. HS-terminated hairpin-DNA aptamer of IFN-γ was conjugated with AuNPs to prepare aptamer-AuNPs-PAMAM/MoS2 onto glassy carbon electrode (GCE), by using bovine serum albumin as the cross-linker and stabilizer. Methylene blue (MB) as a redox probe was absorbed on IFN-γ aptamer. In the presence of IFN-γ, MB electrochemical signal increased gradually. The preparation processes, mechanisms and optimal experiment conditions of aptamer- AuNPs-PAMAM/MoS2/MB/GCE sensing platform were studied by electron microscope imaging technologies, spectral curves and electrochemical measurements. There is a well plotting linear relationship between the peak current intensities of MB and IFN-γ contents in the range of 0.01–1000 pg mL−1, showing a low detection limit of 2 fg mL−1. Experimental results testified that the aptasensor had highly sensitive and selective responses toward IFN-γ, over potential interferents. In real biological samples, the aptasensor of IFN-γ had superior detection recoveries, indicating its high detection performance and feasibility for practicability.",science
10.1016/j.cmpb.2019.105056,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-12-01,sciencedirect,An iterative finite element-based method for solving inverse problems in traction force microscopy,https://api.elsevier.com/content/abstract/scopus_id/85072277991,"Background and Objective
                  During the last years different model solutions were proposed for solving cell forces under different conditions. The solution relies on a deformation field that is obtained under cell relaxation with a chemical cocktail. Once the deformation field of the matrix is determined, cell forces can be computed by an inverse algorithm, given the mechanical properties of the matrix. Most of the Traction Force Microscopy (TFM) methods presented so far relied on a linear stress-strain response of the matrix. However, the mechanical response of some biopolymer networks, such as collagen gels is more complex. In this work, we present a numerical method for solving cell forces on non-linear materials.
               
                  Methods
                  The proposed method relies on solving the inverse problem based on an iterative optimization. The objective function is defined by least-square minimization of the difference between the target and the current computed deformed configuration of the cell, and the iterative formulation is based on the solution of several direct mechanical problems. The model presents a well-posed discretized inverse elasticity problem in the absence of regularization. The algorithm can be easily implemented in any kind of Finite Element (FE) code as a sequence of different standard FE analysis.
               
                  Results
                  To illustrate the proposed iterative formulation we apply the theoretical model to some illustrative examples by using real experimental data of Normal Human Dermal Fibroblast cells (NHDF) migrating inside a 2 mg/ml collagen-based gel. Different examples of application have been simulated to test the inverse numerical model proposed and to investigate the effect of introducing the correct cell properties onto the obtained cell forces. The algorithm converges after a small number of iterations, generating errors of around 5% for the tractions field in the cell contour domain. The resulting maximum traction values increased by 11% as a consequence of doubling the mechanical properties of the cell domain.
               
                  Conclusions
                  With the results generated from computations we demonstrate the application of the algorithm and explain how the mechanical properties of both, the cell and the gel, domains are important for arriving to the correct results when using inverse traction force reconstruction algorithms, however, have only a minor effect on the resulting traction values.",science
10.1016/j.petrol.2019.106381,Journal,Journal of Petroleum Science and Engineering,scopus,2019-12-01,sciencedirect,A decision support system for multi-target geosteering,https://api.elsevier.com/content/abstract/scopus_id/85071951311,"Geosteering is a sequential decision process under uncertainty. The goal of geosteering is to maximize the expected value of the well, which should be defined by an objective value-function for each operation.
                  In this paper we present a real-time decision support system (DSS) for geosteering that aims to approximate the uncertainty in the geological interpretation with an ensemble of geomodel realizations. As the drilling operation progresses, the ensemble Kalman filter is used to sequentially update the realizations using the measurements from real-time logging while drilling. At every decision point a discrete dynamic programming algorithm computes all potential well trajectories for the entire drilling operation and the corresponding value of the well for each realization. Then, the DSS considers all immediate alternatives (continue/steer/stop) and chooses the one that gives the best predicted value across the realizations. This approach works for a variety of objectives and constraints and suggests reproducible decisions under uncertainty. Moreover, it has real-time performance.
                  The system is tested on synthetic cases in a layer-cake geological environment where the target layer should be selected dynamically based on the prior (pre-drill) model and the electromagnetic observations received while drilling. The numerical closed-loop simulation experiments demonstrate the ability of the DSS to perform successful geosteering and landing of a well for different geological configurations of drilling targets. Furthermore, the DSS allows to adjust and re-weight the objectives, making the DSS useful before fully-automated geosteering becomes reality.",science
10.1016/j.jtemb.2019.08.014,Journal,Journal of Trace Elements in Medicine and Biology,scopus,2019-12-01,sciencedirect,Availability of arsenic in rice grains by in vitro and in vivo (humans) assays,https://api.elsevier.com/content/abstract/scopus_id/85071662678,"Background
                  Rice grains are consumed by approximately half of the world's population. This cereal has higher arsenic (As) concentrations in grains than wheat or barley. Arsenic determination in food and/or in vitro studies are important for risk assessment; however, it is not enough to assess the real human exposure.
               
                  Method
                  
                     In vitro bioaccessibility was carried out in husked-rice using gastric and intestinal solutions similar to humans. Also, As naturally found in husked-rice was evaluated by in vivo bioavailability in humans. For this purpose, diets from the 1st and 2nd days were free of foods known to be high in As; 3rd and 4th days the diets were composed by rice and water and; 5th and 6th the diet was similar the 1st and 2nd days. During all experimentation, a representative aliquot of each meal, blood and urine were collected for total As (t-As) determination. Arsenic species were determined in the urine.
               
                  Results
                  t-As in husked rice varied from 157.3 ± 30.6 to 240.2 ± 85.2 μg kg−1. The in vitrobioaccessible fractions ranged from 91 to 94%. Inorganic As (i-As) ranged from 99.7 ± 11.2 to 159.5 ± 29.4 μg kg−1. For the in vivo assay, t-As concentrations in the woman and man blood were about 3 μg mL−1 from the 1st to 6th day. Arsenic from the rice ingested was excreted by urine about 72 h after ingestion. The t-As and dimethyl As (DMA) in urine ranged from 3.59 to 47.17 and 1.02 to 2.55 μg g−1 creatinine for the volunteers, indicating a two-fold DMA-increase in urine after ingestion of husked-rice.
               
                  Conclusion
                  After rice ingestion, As was quickly metabolized. The higher As concentrations were found in urine 72 h after rice ingestion. The main As-specie found in urine was DMA, indicating that methylation of As from rice followed by urine excretion is the main biological pathway for As excretion.",science
10.1016/j.lwt.2019.108548,Journal,LWT,scopus,2019-12-01,sciencedirect,Combination of LF-NMR and BP-ANN to monitor water states of typical fruits and vegetables during microwave vacuum drying,https://api.elsevier.com/content/abstract/scopus_id/85071455481,"To set up a rapid real-time nondestructive detection of moisture content, this paper reported the results of a combination of LF-NMR and BP-ANN to monitor the relationship between drying parameters and state of water under different microwave vacuum drying conditions. Three kinds of materials, carrot (fruit), banana (vegetable) and pleurotus eryngii (edible fungus), were tested in the experiment of applicability. The resulted showed that the information of Atotal and T23 can be used to analyze the drying behavior and the information of A20, A21 and A22 can be used as the fingerprint characteristics of material discrimination. Three classic models (PLS, SVM and BP-ANN) were compared to study the prediction ability of moisture content with the inputs of A20, A21, A22, A23 and Atotal. The performance of BP-ANN model was the best. Although the BP-ANN model of mixed species was not as good as the BP-ANN model of single fruit or vegetable, it still had excellent predictive performances with R2 0.9969 and RMSE 0.0184 to meet the needs of current industry and production.",science
10.1016/j.future.2019.07.056,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,Online travel mode detection method using automated machine learning and feature engineering,https://api.elsevier.com/content/abstract/scopus_id/85070075208,"Online travel mode detection provides context information useful for location-based services, in order to deliver a customized user experience. In the last years, many smartphone-based travel mode detection techniques have been proposed, but few explored the usage of dimensionality reduction in conjunction with hyperparameter optimization to improve accuracy with a reduced cost. In this paper, we propose a method to improve the accuracy and computational cost trade-off of travel mode detection, in which use state-of-the-art Feature Engineering and Automated Machine Learning techniques. In addition, we apply the proposed method in a real mobility dataset using different features and parameters. Our experiments showed that the combination of these techniques can greatly improve online detection performance.",science
10.1016/j.future.2019.07.059,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,Predicting supply chain risks using machine learning: The trade-off between performance and interpretability,https://api.elsevier.com/content/abstract/scopus_id/85069864648,"Managing supply chain risks has received increased attention in recent years, aiming to shield supply chains from disruptions by predicting their occurrence and mitigating their adverse effects. At the same time, the resurgence of Artificial Intelligence (AI) has led to the investigation of machine learning techniques and their applicability in supply chain risk management. However, most works focus on prediction performance and neglect the importance of interpretability so that results can be understood by supply chain practitioners, helping them make decisions that can mitigate or prevent risks from occurring. In this work, we first propose a supply chain risk prediction framework using data-driven AI techniques and relying on the synergy between AI and supply chain experts. We then explore the trade-off between prediction performance and interpretability by implementing and applying the framework on the case of predicting delivery delays in a real-world multi-tier manufacturing supply chain. Experiment results show that prioritising interpretability over performance may require a level of compromise, especially with regard to average precision scores.",science
10.1016/j.future.2019.07.020,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,Sensor-based activity recognition: One picture is worth a thousand words,https://api.elsevier.com/content/abstract/scopus_id/85069616209,"In several domains, including healthcare and home automation, it is important to unobtrusively monitor the activities of daily living (ADLs) carried out by people at home. A popular approach consists in the use of sensors attached to everyday objects to capture user interaction, and ADL models to recognize the current activity based on the temporal sequence of used objects. Often, ADL models are automatically extracted from labeled datasets of activities and sensor events, using supervised learning techniques. Unfortunately, acquiring such datasets in smart homes is expensive and violates users’ privacy. Hence, an alternative solution consists in manually defining ADL models based on common sense, exploiting logic languages such as description logics. However, manual specification of ADL ontologies is cumbersome, and rigid ontological definitions fail to capture the variability of activity execution. In this paper, we introduce a radically new approach enabled by the recent proliferation of tagged visual contents available on the Web. Indeed, thanks to the popularity of social network applications, people increasingly share pictures and videos taken during the execution of every kind of activity. Often, shared contents are tagged with metadata, manually specified by their owners, that concisely describe the depicted activity. Those metadata represent an implicit activity label of the picture or video. Moreover, today’s computer vision tools support accurate extraction of tags describing the situation and the objects that appear in the visual content. By reasoning with those tags and their corresponding activity labels, we can reconstruct accurate models of a comprehensive set of human activities executed in the most disparate situations. This approach overcomes the main shortcomings of existing techniques. Compared to supervised learning methods, it does not require the acquisition of training sets of sensor events and activities. Compared to knowledge-based methods, it does not involve any manual modeling effort, and it captures a comprehensive array of execution modalities. Through extensive experiments with large datasets of real-world ADLs, we show that this approach is practical and effective.",science
10.1016/j.chemosphere.2019.07.069,Journal,Chemosphere,scopus,2019-12-01,sciencedirect,Effect of hydraulic retention time on pollutants removal from real ship sewage treatment via a pilot-scale air-lift multilevel circulation membrane bioreactor,https://api.elsevier.com/content/abstract/scopus_id/85068844938,"Developing a real ship sewage treatment system that not only satisfies the requirement of small space onboard but also meets the latest emission standards of International Maritime Organization (IMO) is still a challenging task for ship industry. To overcome these problems, in this study, a novel pilot-scale air-lift multilevel circulation membrane bioreactor (AMCMBR) was used to explore the effect of hydraulic retention time (HRT) on effluent chemical oxygen demand (COD) and total nitrogen (TN) while treating real ship sewage. Results indicated that the satisfactory removal efficiencies of COD and TN was achieved in the former stages (Re(COD) = 91.57% and 87.82%; Re(TN) = 77.17% and 81.19%). When HRT decreased to 4 h, the removal efficiencies of COD and TN was 86.93% and 70.49% respectively, which still met the strict IMO discharge standards. This mainly because the biofilm-assistant membrane filtration lead to the increase of physical removal rate. The high ratio of mixed liquor volatile suspended solids (MLVSS)/mixed liquid suspended solids (MLSS) (i.e. 0.75) indicated a high biomass content in the attached sludge and resulted into perfect pollutants removal effort. The compliance rate of COD and TN was 100% and 89%, respectively, which indicated stable operation of the pilot-scale AMCMBR throughout the whole experiment. Fluorescence in situ Hybridization (FISH) analysis revealed that the abundance of β-Proteobacteria was a key microbial reason for TN removal. In addition, wavelet neural network (WNN) model was proved to be suitable to simulate and predict the COD and TN removal. These conclusions indicated that the pilot-scale AMCMBR technology is an effective way for real ship sewage treatment.",science
10.1016/j.eswa.2019.04.023,Journal,Expert Systems with Applications,scopus,2019-12-01,sciencedirect,Experimental analysis of heuristic solutions for the moving target traveling salesman problem applied to a moving targets monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85068183652,"The Traveling Salesman Problem (TSP) is an important problem in computer science which consists in finding a path linking a set of cities so that each of then can be visited once, before the traveler comes back to the starting point. This is highly relevant because several real world problems can be mapped to it. A special case of TSP is the one in which the cities (the points to be visited) are not static as the cities, but mobile, changing their positions as the time passes. This variation is known as Moving Target TSP (MT-TSP). Emerging systems for crowd monitoring and control based on unmanned aerial vehicles (UAVs) can be mapped to this variation of the TSP problem, as a number of persons (targets) in the crowd can be assigned to be monitored by a given number of UAVs, which by their turn divide the targets among them. These target persons have to be visited from time to time, in a similar way to the cities in the traditional TSP. Aiming at finding a suitable solution for this type of crowd monitoring application, and considering the fact that exact solutions are too complex to perform in a reasonable time, this work explores and compares different heuristic methods for the intended solution. The performed experiments showed that the Genetic Algorithms present the best performance in finding acceptable solutions for the problem in restricted time and processing power situations, performing better compared to Ant Colony Optimization and Simulated Annealing Algorithms.",science
10.1016/j.ssci.2019.06.025,Journal,Safety Science,scopus,2019-12-01,sciencedirect,Securing instant messaging based on blockchain with machine learning,https://api.elsevier.com/content/abstract/scopus_id/85067872085,"Instant Messaging (IM) offers real-time communications between two or more participants on Internet. Nowadays, most IMs take place on mobile applications, such as WhatsApp, WeChat, Viber and Facebook Messenger, which have more users than social networks, such as Twitter and Facebook. Among the applications of IMs, online shopping has become a part of our everyday life, primarily those who are busiest. However, transaction disputes are often occurred online shopping. Since most IMs are centralized and message history is not stored in the center, the messaging between users and owners of online shops are not reliable and traceable. In China, online shopping sales have soared from practically zero in 2003 to nearly 600 hundred million dollars last year, and now top those in the United States. It is very crucial to secure the instant messaging in online shopping in China. We present techniques to exploit blockchain and machine learning algorithms to secure instant messaging. Since the cryptography of Chinese national standard is encouraged to adopt in security applications of China, we propose a blockchain-based IM scheme with the Chinese cryptographic bases. First, we design a message authentication model based on SM2 to avoid the counterfeit attack and replay attack. Second, we design a cryptographic hash mode based on SM3 to verify the integrity of message. Third, we design a message encryption model based on SM4 to protect the privacy of users. Besides, we propose a method based on machine learning algorithms to monitor the activity on blockchain to detect anomaly. To prove and verify the blockchain-based IM scheme, a blockchain-based IM system has been designed on Linux platforms. The implementation result shows that it is a practical and secure IM system, which can be applied to a variety of instant messaging applications directly.",science
10.1016/j.patrec.2018.04.009,Journal,Pattern Recognition Letters,scopus,2019-12-01,sciencedirect,A real-time and unsupervised face re-identification system for human-robot interaction,https://api.elsevier.com/content/abstract/scopus_id/85046146958,"In the context of Human-Robot Interaction (HRI), face Re-Identification (face Re-ID) aims to verify if certain detected faces have already been observed by robots. The ability of distinguishing between different users is crucial in social robots as it will enable the robot to tailor the interaction strategy toward the users’ individual preferences. So far face recognition research has achieved great success, however little attention has been paid to the realistic applications of Face Re-ID in social robots. In this paper, we present an effective and unsupervised face Re-ID system which simultaneously re-identifies multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural Networks to extract features, and an online clustering algorithm to determine the face's ID. Its performance is evaluated on two datasets: the TERESA video dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF Dataset). We demonstrate that the optimised combination of techniques achieves an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on YTF dataset. We have implemented the proposed method into a software module in the HCI^2 Framework [1] for it to be further integrated into the TERESA robot [2], and has achieved real-time performance at 10–26 Frames per second.",science
10.1016/j.eswa.2019.05.052,Journal,Expert Systems with Applications,scopus,2019-11-30,sciencedirect,Unsupervised collective-based framework for dynamic retraining of supervised real-time spam tweets detection model,https://api.elsevier.com/content/abstract/scopus_id/85067174995,"Twitter is one of the most popular social platforms. It has changed the way of communication and information dissemination through its real-time messaging mechanism. Recently, it has been used by researchers and industries as a new source of data for various intelligent systems, such as tweet sentiment analysis and recommendation systems, which require high data quality. However, due to its flexibility and popularity, Twitter has become the main target for spamming activities such as phishing legitimate users or spreading malicious software, which introduces new security issues and waste resources. Therefore, researchers have developed various machine-learning algorithms to reveal Twitter spam. However, as spammers have become smarter and more crafty, the characteristics of the spam tweets are varying over time making these methods inefficient to detect new spammers tricks and strategies. In addition, some of the employed methods (e.g. blacklisting) or spammer features (e.g. graph-based features) are extremely time-consuming, which hinders the ability to detect spammer activities in real-time. In this paper, we introduce a framework to deal with the volatility of the spam contents and new spamming patterns, called the spam drift. The framework combines the strength of unsupervised machine learning approach, which learns from unlabeled tweets, to retrain a real-time supervised tweet-level spam detection model in a batch mode. A set of experiments on a large-scale data set show the effectiveness of the proposed online unsupervised method in adaptively discovers and learns the patterns of new spam activities and achieve stable recall values reaching more than 95%. Although the average spam precision of our method is around 60%, the high spam recall values show the ability of our proposed method in reducing spam drift problems compared to traditional machine learning algorithms.",science
10.1016/j.eswa.2019.05.035,Journal,Expert Systems with Applications,scopus,2019-11-15,sciencedirect,Social mimic optimization algorithm and engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85066806914,"Increase in complexity of real world problems has provided an area to explore efficient methods to solve computer science problems. Meta-heuristic methods based on evolutionary computations and swarm intelligence are instances of techniques inspired by nature. This paper presents a novel social mimic optimization (SMO) algorithm inspired by mimicking behavior to solve optimization problems. The proposed algorithm is evaluated using 23 test functions. Obtained results are compared with 14 known optimization algorithms including Whale optimization algorithm (WOA), Grasshopper optimization algorithm (GOA), Particle Swarm Optimization (PSO), Stochastic fractal search (SFS), Grey Wolf Optimizer (GWO), Optics Inspired Optimization (OIO), League Championship Algorithm (LCA), Wind Driven Optimization (WDO), Harmony search (HS), Firefly Algorithm (FA), Artificial Bee Colony (ABC), Biogeography Based Optimization (BBO), Bat Algorithm (BA), and Teaching Learning Based Optimization (TLBO). Obtained results indicate higher capability of the SMO algorithm in solving high-dimensional decision variables. Furthermore, SMO is used to solve two classic engineering design problems. Three important features of SMO are simple implementation, solving optimization problems with minimum population size and not requiring control parameters. Results of various evaluations show superiority of the proposed method in finding the optimal solution with minimum function evaluations. This superiority is achieved based on reducing number of initial population. The proposed method can be applied to applications like automatic evolution of robotics, automatic control of machines and innovation of machines in finding better solutions with less cost.",science
10.1016/j.nucmedbio.2019.10.005,Journal,Nuclear Medicine and Biology,scopus,2019-11-01,sciencedirect,Synthesis of <sup>11</sup>C-labeled DNA polymerase-β inhibitor 5-methoxyflavone and PET/CT imaging thereof,https://api.elsevier.com/content/abstract/scopus_id/85074137749,"Introduction
                  “Cell-cycle hypothesis” is emerging in recent years to suggest that aberrant cell cycle re-entry of differentiated neurons leads to a remarkable genetic disequilibrium which is likely to be the primary cause of neuronal apoptosis. DNA polymerase-β is involved in neuronal DNA replication during cell cycle re-entry, thus constituting a promising target for Alzheimer's disease treatment. Recently, 5-methoxyflavone was identified as a candidate molecule endowed with good biological activity and selectivity on the DNA pol-β in multiple in vitro AD models. In vivo assays, especially the brain uptake of 5-methoxyflavone, is need to be evaluated for further development for AD treatment. We report herein the synthesis of 11C-labeled 5-methoxyflavone, and the evaluation of in vivo properties of 5-[11C]methoxyflavone in rodents.
               
                  Methods
                  The strategy for synthesis of 5-[11C]methoxyflavone was developed by treating precursor 5-hydroxyflavone with [11C]CH3I and KOH in anhydrous DMF. 5-[11C]Methoxyflavone was purified, then evaluated in mice by using PET/CT imaging.
               
                  Results
                  The 5-[11C]methoxyflavone was synthesized conveniently in an average decay corrected yield of 22% (n = 3) with a radiochemical purity >99%. The average molar radioactivity of 5-[11C]methoxyflavone was 383 GBq/μmol. The average concentration was 0.107 μg/mL. PET/CT imaging in mice showed 5-[11C]methoxyflavone rapidly passed through the blood-brain barrier with 8.36 ± 0.61%ID/g at 2 min post injection, and the radioactivity accumulation in brain was still noticeable with 2.48 ± 0.59%ID/g at 28 min post injection. The clearance rate was 3.37 (brain2 min/brain28 min ratio). The blood and muscle uptakes were low. The lung displayed high initial uptake and subsequent rapid clearance, while the liver and kidney displayed a relatively slow clearance. Real-time imaging showed that 5-[11C]methoxyflavone accumulated immediately in the heart, then transferred to the liver and intestine, and was not observed in lower digestive tract.
               
                  Conclusions
                  5-[11C]Methoxyflavone was synthesized conveniently in one step. The results of PET/CT imaging in C57BL/6 mice suggested 5-[11C]methoxyflavone possesses appropriate pharmacokinetic properties and favorable brain uptake, thus being proved to be suitable for further development for AD treatment.",science
10.1016/j.swevo.2019.01.009,Journal,Swarm and Evolutionary Computation,scopus,2019-11-01,sciencedirect,Speed up differential evolution for computationally expensive protein structure prediction problems,https://api.elsevier.com/content/abstract/scopus_id/85073550088,"Protein structure prediction (PSP) plays an important role in the field of computational molecular biology. Although powerful optimization algorithms have been proven effective to tackle the PSP, researchers are faced with the challenge of time consuming simulations. This paper introduces a new modification of differential evolution (DE) which makes use of the computationally cheap surrogate models and gene expression programming (GEP) in order to address the aforementioned issue. The incorporated GEP is used to generate a diversified set of configurations, while radial basis function (RBF) surrogate model helps DE to find the best set of configurations. In addition to this, covariance matrix adaptation evolution strategy (CMAES) is also adopted to explore the search space more efficiently. The introduced algorithm, called SGDE, is tested on real-world proteins from the Protein data bank (PDB) using both a simplified and an all-atom model. The experiments show that SGDE performs better than the state-of-the-art algorithms on the PSP problems in both terms of the convergence rate and accuracy. In the case of run time complexity, SGDE significantly outperforms the other competitive algorithms for the adopted all-atom model.",science
10.1016/j.jmoldx.2019.07.002,Journal,Journal of Molecular Diagnostics,scopus,2019-11-01,sciencedirect,Analytical Comparison of Methods for Extraction of Short Cell-Free DNA from Urine,https://api.elsevier.com/content/abstract/scopus_id/85073530416,"Urine cell-free DNA (cfDNA) is a valuable noninvasive biomarker for cancer mutation detection, infectious disease diagnosis (eg, tuberculosis), organ transplantation monitoring, and prenatal screening. Conventional silica DNA extraction does not efficiently capture urine cfDNA, which is dilute (ng/mL) and highly fragmented [30 to 100 nucleotides (nt)]. The clinical sensitivity of urine cfDNA detection increases with decreasing target length, motivating use of sample preparation methods designed for short fragments. We compared the analytical performance of two published protocols (Wizard resin/guanidinium thiocyanate and Q Sepharose), three commercial kits (Norgen, QIAamp, and MagMAX), and an in-house sequence-specific hybridization capture technique. Dependence on fragment length (25 to 150 nt), performance at low concentrations (10 copies/mL), tolerance to variable urine conditions, and susceptibility to PCR inhibition were characterized. Hybridization capture and Q Sepharose performed best overall (60% to 90% recovery), although Q Sepharose had reduced recovery (<10%) of the shortest 25-nt fragment. Wizard resin/guanidinium thiocyanate recovery was dependent on pH and background DNA concentration and was limited to <35%, even under optimal conditions. The Norgen kit led to consistent PCR inhibition but had high recovery of short fragments. The QIAamp and MagMAX kits had minimal recovery of fragments <150 and <80 nt, respectively. Urine cfDNA extraction methods differ widely in ability to capture short, dilute cfDNA in urine; using suboptimal methods may profoundly impair clinical results.",science
10.1016/j.fsi.2019.09.054,Journal,Fish and Shellfish Immunology,scopus,2019-11-01,sciencedirect,Novel pectin isolated from Spirulina maxima enhances the disease resistance and immune responses in zebrafish against Edwardsiella piscicida and Aeromonas hydrophila,https://api.elsevier.com/content/abstract/scopus_id/85072562304,"In this study, we demonstrate the enhanced disease resistance and positive immunomodulation of novel pectin isolated from Spirulina maxima (SmP) in zebrafish model. Zebrafish larvae exposed to SmP had significantly (p < 0.05) higher cumulative percent survival (CPS) at 25 (44.0%) and 50 μg/mL (67.0%) against Edwardsiella piscicida compared to the control. However, upon Aeromonas hydrophila challenge, SmP exposed larvae at 50 μg/mL had slightly higher CPS (33.3%) compared to control group (26.7%). SmP supplemented zebrafish exhibited the higher CPS against E. piscicida (93.3%) and A. hydrophila (60.0%) during the early stage of post-infection (<18 hpi). qRT-PCR results demonstrated that exposing (larvae) and feeding (adults) of SmP, drive the modulation of a wide array of immune response genes. In SmP exposed larvae, up-regulation of the antimicrobial enzyme (lyz: 3.5-fold), mucin (muc5.1: 2.84, muc5.2: 2.11 and muc5.3: 2.40-fold), pro-inflammatory cytokines (il1β: 1.79-fold) and anti-oxidants (cat: 2.87 and sod1: 1.82-fold) were identified. In SmP fed adult zebrafish (gut) showed >2-fold induced pro-inflammatory cytokine (il1β) and chemokines (cxcl18b, ccl34a.4 and ccl34b.4). Overall results confirmed the positive modulation of innate immune responses in larval stage and it could be the main reason for developing disease resistance against E. piscicida and A. hydrophila. Thus, non-toxic, natural and biodegradable SmP could be considered as the potential immunomodulatory agent for sustainable aquaculture.",science
10.1016/j.cherd.2019.09.005,Journal,Chemical Engineering Research and Design,scopus,2019-11-01,sciencedirect,Machine learning-based modeling and operation for ALD of SiO<inf>2</inf> thin-films using data from a multiscale CFD simulation,https://api.elsevier.com/content/abstract/scopus_id/85072515659,"Atomic layer deposition (ALD) is a widely utilized deposition technology in the semiconductor industry due to its superior ability to generate highly conformal films and to deposit materials into high aspect-ratio geometric structures. However, ALD experiments remain expensive and time-consuming, and the existing first-principles based models have not yet been able to provide solutions to key process outputs that are computationally efficient, which is necessary for on-line optimization and real-time control. In this work, a multiscale data-driven model is proposed and developed to capture the macroscopic process domain dynamics with a linear parameter varying model, and to characterize the microscopic domain film growth dynamics with a feed-forward artificial neural network (ANN) model. The multiscale data-driven model predicts the transient deposition rate from the following four key process operating parameters that can be manipulated, measured or estimated by process engineers: precursor feed flow rate, operating pressure, surface heating, and transient film coverage. Our results demonstrate that the multiscale data-driven model can efficiently characterize the transient input-output relationship for the SiO2 thermal ALD process using bis(tertiary-butylamino)silane (BTBAS) as the Si precursor. The multiscale data-driven model successfully reduces the computational time from 0.6 to 1.2h for each time step, which is required for the first-principles based multiscale computational fluid dynamics (CFD) model, to less than 0.1s, making its real-time usage feasible. The developed data-driven modeling methodology can be further generalized and used for other thermal ALD or similar deposition systems, which will greatly enhance the feasibility of industrial manufacturing processes.",science
10.1016/j.enbuild.2019.109440,Journal,Energy and Buildings,scopus,2019-11-01,sciencedirect,A deep reinforcement learning-based autonomous ventilation control system for smart indoor air quality management in a subway station,https://api.elsevier.com/content/abstract/scopus_id/85072289855,"Mechanical ventilation has been widely implemented to alleviate poor indoor air quality (IAQ) in confined underground public facilities. However, due to time-varying IAQ properties that are influenced by unpredictable factors, including outdoor air quality, subway schedules, and passenger volumes, real-time control that incorporates a trade-off between energy saving and IAQ is limited in conventional rule-based and model-based approaches. We propose a data-driven and intelligent approach for a smart ventilation control system based on a deep reinforcement learning (DeepRL) algorithm. This study utilized a deep Q-network (DQN) algorithm of DeepRL to design the ventilation system. The DQN agent was trained in a virtual environment defined by a gray-box model to simulate an IAQ system in a subway station. Performance of the proposed method over three weeks was evaluated by a comprehensive indoor air-quality index (CIAI) and energy consumption under different outdoor air quality scenarios. The results show that the proposed DeepRL-based ventilation control system reduced energy consumption by up to 14.4% for the validation dataset time interval and improved IAQ from unhealthy to acceptable.",science
10.1016/j.cie.2019.106031,Journal,Computers and Industrial Engineering,scopus,2019-11-01,sciencedirect,Machine learning based concept drift detection for predictive maintenance,https://api.elsevier.com/content/abstract/scopus_id/85071975175,"In this work we present a machine learning based approach for detecting drifting behavior – so-called concept drifts – in continuous data streams. The motivation for this contribution originates from the currently intensively investigated topic Predictive Maintenance (PdM), which refers to a proactive way of triggering servicing actions for industrial machinery. The aim of this maintenance strategy is to identify wear and tear, and consequent malfunctioning by analyzing condition monitoring data, recorded by sensor equipped machinery, in real-time. Recent developments in this area have shown potential to save time and material by preventing breakdowns and improving the overall predictability of industrial processes. However, due to the lack of high quality monitoring data and only little experience concerning the applicability of analysis methods, real-world implementations of Predictive Maintenance are still rare. Within this contribution, we present a method, to detect concept drift in data streams as potential indication for defective system behavior and depict initial tests on synthetic data sets. Further on, we present a real-world case study with industrial radial fans and discuss promising results gained from applying the detailed approach in this scope.",science
10.1016/j.ins.2019.07.019,Journal,Information Sciences,scopus,2019-11-01,sciencedirect,Labeled graph sketches: Keeping up with real-time graph streams,https://api.elsevier.com/content/abstract/scopus_id/85068588796,"Currently, graphs serve as fundamental data structures for many applications, such as road networks, social and communication networks, and web requests. In many applications, graph edges stream in and users are only interested in the recent data. In data exploration, the storage and processing of such massive amounts of graph stream data has become a significant problem. As the categorical attributes of vertices and edges are often referred to as labels, we propose a labeled graph sketch that stores real-time graph structural information using only sublinear space and that supports graph queries of diverse types. This sketch also works for sliding-window queries. We conduct extensive experiments on real-world datasets in six different domains and compare the results with a state-of-the-art method to show the accuracy, efficiency, and practicability of our proposed approach.",science
10.1016/j.msec.2019.109869,Journal,Materials Science and Engineering C,scopus,2019-11-01,sciencedirect,Selective detection of Escherichia coli caused UTIs with surface imprinted plasmonic nanoscale sensor,https://api.elsevier.com/content/abstract/scopus_id/85067361200,"The aim of the present study was developing a surface plasmon resonance (SPR) nanosensor to detect Escherichia coli (E. coli) for the diagnosis of urinary tract infections by using surface imprinted Au nanoparticles (AuNPs) as a recognition element. In order to realize imprinting, Cu(II) ions were used to provide interaction between E. coli cell wall and amine functionalized AuNPs forming cavities on the surface of nanosensor. E. coli surface imprinted AuNPs nanosensor was characterized by using ellipsometry, contact angle measurement, scanning electron microscopy (SEM) and atomic force microscopy (AFM). The real time detection of E. coli was evaluated by using E. coli suspensions in the concentration range of 1 × 103–0.5 × 101 CFU/mL. Combination of the signal enhancing properties of AuNPs and surface imprinting technique provided ultrasensitive detection with a comparatively low limit of detection value (1 CFU/mL) to the SPR nanosensor system. Selectivity experiments were performed by using Staphylococcus aureus, Klebsiella pneumoniae and Pseudomonas aeruginosa. The highest response was recorded for E. coli, as expected. Additionally, the recognition of E. coli even in a complex medium such as artificial urine sample was achieved by the developed nanosensing system. Also, this chip can be used repeatedly without seen signal reducing for four-time consecutive. In the view of these results, it was emphasized that this novel sensing system has a potency for the selective, very sensitive, rapid and real time detection of causative agent in order to diagnose E. coli caused infections.",science
10.1016/j.ecoenv.2019.109447,Journal,Ecotoxicology and Environmental Safety,scopus,2019-10-30,sciencedirect,Selenium decreases methylmercury and increases nutritional elements in rice growing in mercury-contaminated farmland,https://api.elsevier.com/content/abstract/scopus_id/85069005684,"Methylmercury (MeHg) in rice grains grown in Hg-contaminated areas has raised environmental health concerns. Pot experiments found that selenium (Se) could reduce MeHg levels in rice grains. However, relatively high levels of Se (up to 6 mg/kg) were applied in these pot experiments, which may have adverse effects on the soil ecology due to the toxicity of Se. The aims of this work were thus to study 1) the effect of low levels of Se on the accumulation and distribution of Hg, especially MeHg, in rice plants grown in a real Hg-contaminated paddy field and 2) the effect of Se treatment on Se and other nutritional elements (e.g., Cu, Fe, Zn) in grains. A field study amended with different levels of Se was carried out in Hg-contaminated paddy soil in Qingzhen, Guizhou, China. The levels of MeHg and total Hg were studied using cold vapor atomic fluorescence spectrometry (CVAFS) and inductively coupled plasma mass spectrometry (ICP-MS). The distribution and relative quantification of elements in grains were examined by synchrotron radiation X-ray fluorescence analysis (SR-XRF). This field study showed that low levels of Se (0.5 μg/mL, corresponding to 0.15 mg Se/kg soils) could significantly reduce total Hg and MeHg in rice tissues. Se treatment also reduced Hg distribution in the embryo and endosperm and increased the levels of Fe, Cu, Zn and Se in grains and especially embryos. This field study implied that treatment with an appropriate level of Se is an effective approach to not only decrease the level of MeHg but to also increase the levels of nutritional elements such as Fe, Cu, Zn and Se in rice grains, which could bring beneficial effects for rice-dependent residents living in Hg-contaminated areas.",science
10.1016/j.jhazmat.2019.03.129,Journal,Journal of Hazardous Materials,scopus,2019-10-15,sciencedirect,Development of an ic-ELISA and immunochromatographic strip based on IgG antibody for detection of Ω-conotoxin MVIIA,https://api.elsevier.com/content/abstract/scopus_id/85067348797,"ω-conotoxin MVIIA(ω-CTX MVIIA) is a peptide consisting of 25 amino acid residues secreted mainly by Conus magus. In view of the toxin threat to humans and animals and defined application in analgesic therapy, it is necessary to develop a rapid, effective and accuracy method for the quantification and analysis of ω-CTX MVIIA in real samples. In the present study, a hybridoma cell named 2E5 stable secreting IgG antibody against ω-CTX MVIIA was selected successfully, and the subtype of Mab 2E5 was IgG1. The purified monoclonal antibody(Mab) 2E5 has high affinity (about 2.79 × 109 L/mol), and shows high specificity to ω-CTX MVIIA antigen. The linear range of ic-ELISA to detect ω-CTX MVIIA was 0.20˜7.22 μg/mL, with a lower detection limit (LOD) of 0.14 ng/mL. The average recovery of intra- and inter-assay were (85.45 ± 2.28)% and (88.03 ± 4.80)% respectively, with a coefficient of variation from 2.59% to 5.42%. The LOD of colloidal strip by naked eye was 1 μg/mL, and the detection time was less than 10 min without any equipment. The developed ELISA and colloidal test strips based on this IgG antibody could be used to detect ω-CTX MVIIA residue in real Conus samples.",science
10.1016/j.jhazmat.2019.06.004,Journal,Journal of Hazardous Materials,scopus,2019-10-15,sciencedirect,The application of machine learning methods for prediction of metal sorption onto biochars,https://api.elsevier.com/content/abstract/scopus_id/85066994123,"The adsorption of six heavy metals (lead, cadmium, nickel, arsenic, copper, and zinc) on 44 biochars were modeled using artificial neural network (ANN) and random forest (RF) based on 353 dataset of adsorption experiments from literatures. The regression models were trained and optimized to predict the adsorption capacity according to biochar characteristics, metal sources, environmental conditions (e.g. temperature and pH), and the initial concentration ratio of metals to biochars. The RF model showed better accuracy and predictive performance for adsorption efficiency (R2 = 0.973) than ANN model (R2 = 0.948). The biochar characteristics were most significant for adsorption efficiency, in which the contribution of cation exchange capacity (CEC) and pHH2O of biochars accounted for 66% in the biochar characteristics. However, surface area of the biochars provided only 2% of adsorption efficiency. Meanwhile, the models developed by RF had better generalization ability than ANN model. The accurate predicted ability of developed models could significantly reduce experiment workload such as predicting the removal efficiency of biochars for target metal according to biochar characteristics, so as to select more efficient biochar without increasing experimental times. The relative importance of variables could provide a right direction for better treatments of heavy metals in the real water and wastewater.",science
10.1016/j.neucom.2019.07.015,Journal,Neurocomputing,scopus,2019-10-14,sciencedirect,Merging visual features and temporal dynamics in sequential recommendation,https://api.elsevier.com/content/abstract/scopus_id/85069687170,"With the development of social networking and mobile computing technologies, data analysis in the fashion field has increasingly focused on visual features. The main features currently used in the recommendation methods include non-visual user attributes, item attributes, explicit ratings, and implicit feedbacks. How to understand visual features and integrate them with non-visual features becomes the key to building a good recommender system. In this paper, we consider both non-visual text data and visual image data and their time dynamics to build a large-scale recommender system. An advanced visual Bayesian personalized ranking (aVBPR) model is proposed, which integrates three models. Factorized personalized Markov chains (FPMC) model is used to simulate users’ sequence behaviors, intelligent field-aware factorization machine (iFFM) model also put forward by us is used to predict users’ preferences based on non-visual features, and visual Bayesian personalized ranking (VBPR) model is used to analyze users’ visual preferences. We design a learning algorithm based on AdaGrad method to optimize model aVBPR. The high complexity of the model does not affect the performance of the system by adopting multi-thread technology in the implementation of the learning algorithm. Experimental results of two real-world datasets Women's and Men's Clothing & Accessories from Amazon demonstrate that our model can obtain better recommendation results than the recent popular models for Amazon datasets. Although the model is complicated, multi-thread technique can be used to greatly improve the speed of the implementation.",science
10.1016/j.asoc.2019.105664,Journal,Applied Soft Computing Journal,scopus,2019-10-01,sciencedirect,A holistic multi-objective optimization design procedure for ensemble member generation and selection,https://api.elsevier.com/content/abstract/scopus_id/85073644903,"In the last few years, machine learning techniques have been successfully applied to solve engineering problems. However, owing to certain complexities found in real-world problems, such as class imbalance, classical learning algorithms may not reach a prescribed performance. There can be situations where a good result on different conflicting objectives is desirable, such as true positive and true negative ratios, or it is important to balance model’s complexity and prediction score. To solve such issues, the application of multi-objective optimization design procedures can be used to analyze various trade-offs and build more robust machine learning models. Thus, the creation of ensembles of predictive models using such procedures is addressed in this work. First, a set of diverse predictive models is built by employing a multi-objective evolutionary algorithm. Next, a second multi-objective optimization step selects the previous models as ensemble members, resulting on several non-dominated solutions. A final multi-criteria decision making stage is applied to rank and visualize the resulting ensembles. To analyze the proposed methodology, two different experiments are conducted for binary classification. The first case study is a famous classification problem through which the proposed procedure is illustrated. The second one is a challenging real-world problem related to water quality monitoring, where the proposed procedure is compared to four classical ensemble learning algorithms. Results on this second experiment show that the proposed technique is able to create robust ensembles that can outperform other ensemble methods. Overall, the authors conclude that the proposed methodology for ensemble generation creates competitive models for real-world engineering problems.",science
10.1016/j.bios.2019.111549,Journal,Biosensors and Bioelectronics,scopus,2019-10-01,sciencedirect,Efficient electron-mediated electrochemical biosensor of gold wire for the rapid detection of C-reactive protein: A predictive strategy for heart failure,https://api.elsevier.com/content/abstract/scopus_id/85071785022,"C-reactive protein (CRP) is considered a promising biomarker for the rapid and high-throughput real-time monitoring of cardiovascular disease and inflammation in unprocessed clinical samples. Implementation of this monitoring would enable various transformative biomedical applications. We have fabricated a highly specific sensor chip to detect CRP with a detection limit of 2.25 fg/mL. The protein was immobilized on top of a gold (Au) wire/polycarbonate (PC) substrate using 1-ethyl-3-(3-dimethylamino-propyl) carbodiimide hydrochloride/N-hydroxy succinimide-activated 3-mercaptoproponic acid (MPA) as a self-assembled monolayer agent and bovine serum albumin (BSA) as a blocking agent. In contrast to the bare PC substrate, the CRP/BSA/anti-CRP/MPA/Au substrate exhibited a considerably high electrochemical signal toward CRP. The influence of the experimental parameters on CRP detection was assessed via various analysis methods, and these parameters were then optimized. The linear dynamic range of the CRP was 5–220 fg/mL for voltammetric and impedance analysis. Morever, the strategy exhibited high selectivity against various potential interfering species and was capable of directly probing trace amounts of the target CRP in human serum with excellent selectivity. The analytical assay based on the CRP/BSA/anti-CRP/MPA/Au substrate could be exploited as a potentially useful tool for detecting CRP in clinical samples.",science
10.1016/j.engfracmech.2019.106642,Journal,Engineering Fracture Mechanics,scopus,2019-10-01,sciencedirect,Necking-induced fracture prediction using an artificial neural network trained on virtual test data,https://api.elsevier.com/content/abstract/scopus_id/85071523401,"The imperfection-based necking model by Marciniak and Kuczyński (MK) is frequently used for predicting the onset of localized necking under proportional and non-proportional loading, which can be considered a lower limit for the occurrence of fracture in a vehicle body structure subjected to crash loading. A large number of virtual imperfection lines at different orientation angles have to be analysed simultaneously in order to find the critical imperfection causing necking under arbitrary loading. This, and the continuous computation of a “distance to necking” quantity, representing a crucial output quantity for the simulation engineer, makes the model computationally expensive and limits industrial use in full-scale vehicle crash simulations.
                  In this work, an extended MK model is used for creating a virtual test data base under proportional and non-proportional loading for training of a computationally more efficient simple feed-forward neural network (NN). Both models are implemented in a User Material routine of an explicit crash code, where the predictions of the NN are in good agreement with the predictions of the MK reference model, however at a significantly reduced computational cost. Besides a pure numerical validation study, an experimental validation study has been performed, imposing biaxial tension loading followed by plane strain tension loading until necking using a special punch test apparatus. Whereas MK and NN are in good agreement with the experimental observations, the agreement of classical necking models, applied in conjunction with a linear damage accumulation (forming severity) concept was less accurate.",science
10.1016/j.jacr.2019.06.009,Journal,Journal of the American College of Radiology,scopus,2019-10-01,sciencedirect,Bending the Artificial Intelligence Curve for Radiology: Informatics Tools From ACR and RSNA,https://api.elsevier.com/content/abstract/scopus_id/85071398084,"Artificial intelligence (AI) will reshape radiology over the coming years. The radiology community has a strong history of embracing new technology for positive change, and AI is no exception. As with any new technology, rapid, successful implementation faces several challenges that will require creation and adoption of new integration technology. Use cases important to real-world application of AI are described, including clinical registries, AI research, AI product validation, and computer assistance for radiology reporting. Furthermore, the informatics technologies required for successful implementation of the use cases are described, including open Computer-Assisted Radiologist Decision Support, ACR Assist, ACR Data Science Institute use cases, common data elements (radelement.org), RadLex (radlex.org), LOINC/RSNA RadLex Playbook (loinc.org), and Radiology Report Templates (radreport.org).",science
10.1016/j.sna.2019.111561,Journal,"Sensors and Actuators, A: Physical",scopus,2019-10-01,sciencedirect,High-precision smart calibration system for temperature sensors,https://api.elsevier.com/content/abstract/scopus_id/85071100929,"High precision and smart sensors make up an indispensable data entry for the Internet of Things technology. Nonetheless, conventional calibration algorithms mainly implemented on the software, such as least squares, polynomial fitting, and interpolation, exhibit limited calibration accuracy that does not reflect a real-time measurement of the sensors. The problem can be resolved with an MCU-based sensor calibration system proposed herein, which mainly employs particle swarm optimization (PSO)-back propagation (BP) neural network. The system firstly reads sensor data through I2C bus and then uses the BP neural network and PSO algorithm to automatically calibrate these data in real time. Sigmoid activation function was implemented via a piecewise polynomial fitting to create a trade-off between hardware resource and precision. A performance test conducted on temperature sensors showed a maximum error of 0.16 °C within the measurement range of −40–100 °C with three times the standard deviation (3
                        σ
                     ) error of ±0.23 °C and overall linearity of 0.1143% after the calibration system was added as compared to the significantly higher error of ±0.63 °C without the calibration.",science
10.1016/j.engappai.2019.07.008,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-10-01,sciencedirect,A semisupervised autoencoder-based approach for anomaly detection in high performance computing systems,https://api.elsevier.com/content/abstract/scopus_id/85069910646,"High Performance Computing (HPC) systems are complex machines with heterogeneous components that can break or malfunction. Automated anomaly detection in these systems is a challenging and critical task, as HPC systems are expected to work 24/7. The majority of the current state-of-the-art methods dealing with this problem are Machine Learning techniques or statistical models that rely on a supervised approach, namely the detection mechanism is trained to recognize a fixed number of different states (i.e. normal and anomalous conditions).
                  In this paper a novel semi-supervised approach for anomaly detection in supercomputers is proposed, based on a type of neural network called autoencoder. The approach learns the normal state of the supercomputer nodes and after the training phase can be used to discern anomalous conditions from normal behavior; in doing so it relies only on the availability of data characterizing only the normal state of the system. This is different from supervised methods that require data sets with many examples of anomalous states, which are in general very rare and/or hard to obtain.
                  The approach was tested on a real-life High Performance Computing system equipped with a monitoring infrastructure capable to generate large amount of data describing the system state. The proposed approach definitely outperforms the best current techniques for semi-supervised anomaly detection, with an increase in accuracy detection of around 12%. Two different implementations are discussed: one where each supercomputer node has a specific model and one with a single, generalized model for all nodes, in order to explore the trade-off between accuracy and ease of deployment.",science
10.1016/j.jpowsour.2019.226832,Journal,Journal of Power Sources,scopus,2019-10-01,sciencedirect,Artificial neural network simulating microbial fuel cells with different membrane materials and electrode configurations,https://api.elsevier.com/content/abstract/scopus_id/85068523208,"Microbial fuel cells (MFCs) are gaining interest due to higher power production achieved by deep analysis of their characteristics and their effect on the overall efficiency. To date, investigations on MFC efficiency, can only be based on laboratory experiments or mathematical modelling. However, there is only a handful of rule-based mathematical modelling due to the difficulties imposed by the high sensitivity of the MFC system to environmental parameters and the highly complex bacterial consortia that dictate its behavior. Thus, an application of an artificial neural network (ANN) is proposed to simulate the polarisation of cylindrical MFCs with different materials as the separation membranes. ANNs are ideal candidates for investigating these systems, as there is no need for explicit knowledge of the detailed rules that govern the system. The ANN developed here is a feed-forward back-propagation network with a topology of 4-10-1 neurons that approximates the voltage of each MFC at a given state. Two different membrane materials with two different electrode configurations were assembled and utilized in laboratory experiments to produce the data set on which the ANN was trained upon. For the whole data set the correlation coefficient (R) between real values and outputs of the network was 0.99662.",science
10.1016/j.scs.2019.101615,Journal,Sustainable Cities and Society,scopus,2019-10-01,sciencedirect,"Thai sentiment analysis with deep learning techniques: A comparative study based on word embedding, POS-tag, and sentic features",https://api.elsevier.com/content/abstract/scopus_id/85067187685,"A smart city connects physical, information technology, social, and business infrastructures together to leverage their collective intelligence. Feedback drives improvements in service, city development, and quality of life in the city. Therefore, sentiment analysis in real-time of opinions expressed in text form by residents in the city is absolutely necessary. Nowadays, machine learning is widely applied to sentiment analysis of decisions in business, especially deep learning. In this experiment, we evaluated and compared the performances of several conventional deep learning models: Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Bidirectional LSTM (Bi-LSTM), in sentiment analysis of Thai children tales. In several previous studies, many features have been used in all of the models mentioned, features such as word embedding that helps a model to understand the semantics of each word, POS-tag that helps a model to understand the grammatical function of words, and sentic that helps a model to understand the emotion of words. Some combinations of these features have also been used. The results of this experiment show that the CNN model that used all three features gave the best result of 0.817 F1-score at p < 0.01, which was significantly better than all other models.",science
10.1016/j.talanta.2019.05.089,Journal,Talanta,scopus,2019-10-01,sciencedirect,Combination of LEDs and cognitive modeling to quantify sheep cheese whey in watercourses,https://api.elsevier.com/content/abstract/scopus_id/85066257571,"The concentration of sheep cheese whey (CW) in water obtained from two Spanish reservoirs, two Spanish rivers, and distilled water has been estimated by combining spectroscopic measurements, obtained with light-emitting diodes (LEDs), and linear or non-linear algorithms. The concentration range of CW that has been studied covers from 0 to 25% in weight. Every sample was measured by six different types of LEDs possessing different emission wavelengths (blue, orange, green, pink, white, and UV). 1,800 fluorescence measurements were carried out and used to design different types of models to estimate the concentration of CW in water. The fluorescence spectra provided by the pink LED originated the most accurate mathematical models, with mean square errors lower than 3.3% and 2.5% for the linear and non-linear approaches, respectively. The pink LED combined with the non-linear model, which was an artificial neural network, was further validated through a k-fold cross-validation and an internal validation. It should be noted that the sensor used here has been designed and produced by a 3D printer and has the potential of being implemented in situ for real-time and cost-effective analysis of natural watercourses.",science
10.1016/j.neucom.2019.05.023,Journal,Neurocomputing,scopus,2019-09-30,sciencedirect,Multiple convolutional neural networks for multivariate time series prediction,https://api.elsevier.com/content/abstract/scopus_id/85067343649,"Multivariate time series prediction, with a profound impact on human social life, has been attracting growing interest in machine learning research. However, the task of time series forecasting is very challenging because it is affected by many complex factors. For example, in predicting traffic and solar power generation, weather can bring great trouble. In particular, for strictly periodic time series, if the periodic information can be extracted from the historical sequence data to the maximum, the accuracy of the prediction will be greatly improved. At present, for time series prediction tasks, the sequence models based on RNN have made great progress. However, the sequence models has difficulty in capturing global information, failing to well highlight the periodic characteristics of the time series. But the this problem can be solved by CNN models. So in this paper, we propose a model called Multiple CNNs to solve the problem of periodic multivariate time series prediction. The working process of Multiple CNNs is analyzing the periodicity of time series, extracting the closeness and the long and short periodic information of the predicted target respectively, and finally integrating the characteristics of the three parts to make the prediction. Moreover, the model is highly flexible, which allows users to freely adjust the cycle span set in the model according to their own data characteristics. Tests on two large real-world datasets, show that our model has a strong advantage over other time series prediction methods.",science
10.1016/j.neucom.2019.05.064,Journal,Neurocomputing,scopus,2019-09-17,sciencedirect,Improving novelty detection with generative adversarial networks on hand gesture data,https://api.elsevier.com/content/abstract/scopus_id/85066314268,"We propose a novel way of solving the issue of classification of out-of-vocabulary gestures using Artificial Neural Networks (ANNs) trained in the Generative Adversarial Network (GAN) framework. A generative model augments the data set in an online fashion with new samples and stochastic target vectors, while a discriminative model determines the class of the samples. The approach was evaluated on the UC2017 SG and UC2018 DualMyo data sets. The generative models’ performance was measured with a distance metric between generated and real samples. The discriminative models were evaluated by their accuracy on trained and novel classes. In terms of sample generation quality, the GAN is significantly better than a random distribution (noise) in mean distance, for all classes. In the classification tests, the baseline neural network was not capable of identifying untrained gestures. When the proposed methodology was implemented, we found that there is a trade-off between the detection of trained and untrained gestures, with some trained samples being mistaken as novelty. Nevertheless, a novelty detection accuracy of 95.4% or 90.2% (depending on the data set) was achieved with just 5% loss of accuracy on trained classes.",science
10.1016/j.jep.2019.111975,Journal,Journal of Ethnopharmacology,scopus,2019-09-15,sciencedirect,Danhong Huayu Koufuye prevents venous thrombosis through antiinflammation via Sirtuin 1/NF-κB signaling pathway,https://api.elsevier.com/content/abstract/scopus_id/85066272741,"Ethnopharmacological relevance
                  Danhong Huayu Koufuye (DHK), a compound traditional Chinese medicine, is composed of Salvia miltiorrhiza radix (Salvia miltiorrhiza Bge.), Angelicae Sinensis radix (Angelicae Sinensis (Oliv.) Diels.), Chuanxiong rhizoma (Ligusticum chuanxiong Hort.), Persicae semen (Prunus persica (L.) Batsch), Carthami flos (Carthamus tinctorius L.), Bupleuri radix (Bupleurum chinense DC.) and Aurantii fructus (Citrus aurantium L.). DHK prevents deep vein thrombosis (DVT) through antiinflammation. However, the antiinflammatory mechanism of DHK is still unknown.
               
                  Objective
                  The aim of this study was to evaluate whether DHK prevented venous thrombosis through antiinflammation via Sirtuin 1 (SIRT1)/NF-κB signaling pathway.
               
                  Methods
                  Inferior vena cava (IVC) stenosis-induced DVT rat model was established. Rats were administered with DHK (1.6, 3.2 or 6.4 mL/kg/d, p.o.), heparin (200 U/kg/d, i.v.), clopidogrel (25 mg/kg/d, p.o.), resveratrol (50 mg/kg/d, p.o.) or vehicle (p.o.) once daily for two days. Blood coagulation, blood fibrinolysis, blood viscosity, blood cell counts and platelet activity were evaluated. Serum levels of inflammatory cytokines were analyzed by enzyme-linked immunosorbent assay. Pathological changes were observed by hematoxylin-eosin (HE) staining. Protein expressions in thrombosed IVCs were evaluated by Western blot and/or immunofluorescence analyses. SIRT1 mRNA expression was analyzed by real-time quantitative polymerase chain reaction. Besides, SIRT1-specific inhibitor EX527 was pretreated to confirm the role of SIRT1/NF-κB signaling pathway in the antithrombotic effect of DHK.
               
                  Results
                  DHK remarkably prevented DVT. DHK had no effects on blood coagulation, blood fibrinolysis, blood viscosity, blood cell counts or platelet activity. But DHK significantly up-regulated protein and mRNA expressions of SIRT1, and reduced leukocytes infiltration into thrombus and vein wall, serum levels of inflammatory cytokines, and protein expressions of acetylated p65 (Ace-p65), phosphorylated p65 (p-p65) and tissue factor (TF). Moreover, the antithrombotic effect of DHK was significantly abolished by EX527.
               
                  Conclusion
                  DHK may prevent DVT by inhibiting inflammation via SIRT1/NF-κB signaling pathway.",science
10.1016/B978-0-12-814725-2.00015-7,Book,Riemannian Geometric Statistics in Medical Image Analysis,scopus,2019-09-04,sciencedirect,Efficient recursive estimation of the Riemannian barycenter on the hypersphere and the special orthogonal group with applications,https://api.elsevier.com/content/abstract/scopus_id/85080840239,"Finding the Riemannian barycenter (center of mass) or the Fréchet mean (FM) of manifold-valued data sets is a commonly encountered problem in a variety of fields of science and engineering, including, but not limited to, medical image computing, machine learning, and computer vision. For example, it is encountered in tasks such as atlas construction, clustering, principal geodesic analysis, and so on. Traditionally, algorithms for computing the FM of the manifold-valued data require that the entire data pool be available a priori and not incrementally. Thus, when encountered with new data, the FM needs to be recomputed over the entire pool, which can be computationally and storage inefficient. A computational and storage efficient alternative is to consider a recursive algorithm for computing the FM, which simply updates the previously computed FM when presented with a new data sample. In this chapter we present such an alternative called the inductive/incremental Fréchet mean estimator (iFME) for data residing on two well-known Riemannian manifolds, namely the hypersphere 
                     S
                     (
                     d
                     )
                   and the special orthogonal group 
                     
                        SO
                     
                     (
                     d
                     )
                  . We prove the asymptotic convergence of iFME to the true FM of the underlying distribution from which the data samples were drawn. Further we present several experiments demonstrating the performance iFME on synthetic and real data sets.",science
10.1016/j.ifacol.2019.11.102,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Sustainable operations management for industry 4.0 and its social return,https://api.elsevier.com/content/abstract/scopus_id/85078948022,"In today’s industrial environment, where concepts of smart factories are consolidating their application in companies, it is still necessary to approach management decision making from a perspective that encompasses all aspects of sustainability without losing sight of the social return to which they must contribute. In order to obtain a reliable prediction, of the operation of a Sustainable Manufacturing System (SMS) and its Social Return (SR), this paper develops a methodology and procedures that allow predicting the system performance as a whole. This will allow us to assist management decision making in industries 4.0, supported by multi-criteria methods in knowledge management, simulation, value analysis and operational research by means of:
                  a) Study the economic, social and environmental impacts in the organization and management of the efficient operation of an SMS with the selection of strategies and alternatives in production chains to minimize and / or mitigate environmental and labor risks.
                  b) Encourage of industrial symbiosis or eco-industries networks that create opportunities increasing eco-efficiency and the positive social return of production systems.
                  This proposed methodology will facilitate changes in the structure of production systems in order to implement industry 4.0 paradigms through facilitator technologies such as simulation and virtual reality. This framework will allow Small and Medium Enterprises (SMEs) and other companies to address the decision-making activities that improve the economic-functional efficiency, which will lead to reduce the environmental impact and increase the positive social return of certain production strategies, considering working conditions.
                  The proposed approach went validated, in the area of the Euroregion Galicia North of Portugal, to favour the implementation of the decision-making through the Industry 4.0 Technologies.",science
10.1016/j.ifacol.2019.11.172,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Machine learning framework for predictive maintenance in milling,https://api.elsevier.com/content/abstract/scopus_id/85078904429,"In the Industry 4.0 era, artificial intelligence is transforming the manufacturing industry. With the advent of Internet of Things (IoT) and machine learning methods, manufacturing systems are able to monitor physical processes and make smart decisions through realtime communication and cooperation with humans, machines, sensors, and so forth. Artificial intelligence enables manufacturers to reduce equipment downtime, spot production defects, improve the supply chain, and shorten design times by using machine learning technologies which learn from experiences. One of the last application of these technologies is the development of Predictive Maintenance systems. Predictive maintenance combines Industrial IoT technologies with machine learning to forecast the exact time in which manufacturing equipment will need maintenance, allowing problems to be solved and adaptive decisions to be made in a timely fashion. This study will discuss the implementation of a milling Cutting-tool Predictive Maintenance solution (including Wear Monitoring), applied to a real milling data set as validation of the framework. More generally, this work provides a basic framework for creating a tool to monitor the wear level, preventing the breakdown, of a generic manufacturing tool, in order to improve human-machine interaction and optimize the production process.",science
10.1016/j.ifacol.2019.11.385,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Towards a data-driven predictive-reactive production scheduling approach based on inventory availability,https://api.elsevier.com/content/abstract/scopus_id/85078884096,"To survive in a competitive business environment, manufacturing systems require the proper deployment of advanced technologies coming from Industry 4.0. These technologies allow access to quasi-real-time data that provide a continuously updated picture of the production system, including the state of available inventory. Data-driven predictive-reactive production scheduling has the potential to support the anticipation and prompt reaction to overcome different kinds of disruptions that occur in production execution nowadays. This research paper aims to propose a conceptual model for a data-driven predictive-reactive production scheduling approach combining machine learning and simulation-based optimization, considering current inventory of raw material, work in process and final products inventory to characterize a job-shop production execution state. The approach supports decision-making in dynamic situations related to inventory availability that can affect production schedules.",science
10.1016/j.clineuro.2019.105442,Journal,Clinical Neurology and Neurosurgery,scopus,2019-09-01,sciencedirect,Artificial intelligence for assisting diagnostics and assessment of Parkinson's disease—A review,https://api.elsevier.com/content/abstract/scopus_id/85069629950,"Artificial intelligence, specifically machine learning, has found numerous applications in computer-aided diagnostics, monitoring and management of neurodegenerative movement disorders of parkinsonian type. These tasks are not trivial due to high inter-subject variability and similarity of clinical presentations of different neurodegenerative disorders in the early stages. This paper aims to give a comprehensive, high-level overview of applications of artificial intelligence through machine learning algorithms in kinematic analysis of movement disorders, specifically Parkinson’s disease (PD). We surveyed papers published between January 2007 and January 2019, within online databases, including PubMed and Science Direct, with a focus on the most recently published studies. The search encompassed papers dealing with the implementation of machine learning algorithms for diagnosis and assessment of PD using data describing motion of upper and lower extremities. This systematic review presents an overview of 48 relevant studies published in the abovementioned period, which investigate the use of artificial intelligence for diagnostics, therapy assessment and progress prediction in PD based on body kinematics. Different machine learning algorithms showed promising results, particularly for early PD diagnostics. The investigated publications demonstrated the potentials of collecting data from affordable and globally available devices. However, to fully exploit artificial intelligence technologies in the future, more widespread collaboration is advised among medical institutions, clinicians and researchers, to facilitate aligning of data collection protocols, sharing and merging of data sets.",science
10.1016/j.freeradbiomed.2019.07.002,Journal,Free Radical Biology and Medicine,scopus,2019-09-01,sciencedirect,Hydroxytyrosol prevents PM<inf>2.5</inf>-induced adiposity and insulin resistance by restraining oxidative stress related NF-κB pathway and modulation of gut microbiota in a murine model,https://api.elsevier.com/content/abstract/scopus_id/85068933540,"Exposure to fine particular matter (≤2.5 μM, PM2.5) contributes to increased risk of obesity and type 2 diabetes. Hydroxytyrosol (HT), a simple polyphenol found in virgin olive oil, is considered to be beneficial for cardiovascular and metabolic disorders. The current study determined whether HT could improve PM2.5-induced adiposity and insulin resistance (IR), and explored the underlying mechanisms. Fifteen adult female C57BL/6j mice on a chow diet were randomly divided into three groups receiving (1) sterile PBS, (2) PM2.5 suspended in sterile PBS (1 mg/mL) and (3) PM2.5+HT (50 mg/kg/day). PM2.5/PBS exposure was administered by oropharynx instillation every other day and HT supplementation was achieved by gavage every day. Four-week PM2.5 exposure did not affect body weight, but significantly increased visceral fat mass. The abdominal adiposity coincided with adipocyte hypertrophy and proliferation in visceral white adipose tissue (WAT), as well as decreased metabolic activity in brown adipose tissue and subcutaneous WAT. PM2.5 enhanced the oxidative stress by diminishing antioxidant enzyme activities in liver and serum, whereas contents of 4-hydroxynonenal (4-HNE), malondialdehyde (MDA) levels in liver and serum were elevated. These changes were accompanied by macrophage infiltration and activation of NF-κB pathway in the liver. Moreover, PM2.5 exposure led to glucose intolerance and insulin insensitivity, impaired hepatic glycogenesis, and decreased insulin-stimulated Akt phosphorylation in peripheral tissues. Importantly, HT treatment prevented PM2.5-induced visceral adipogenesis, oxidative stress, hepatic inflammation and NF-κB activation, systemic and peripheral IR. In vitro, after HepG2 cells were incubated with PM2.5 (0, 5, 25, 50, 100 and 200 μg/mL), reduced glutathione depletion and 4-HNE, 8-hydroxy-2'-deoxyguanosine, MDA increment in a dose-dependent manner were observed; likewise, insulin-stimulated glucose uptake decreased in a dose-dependent manner. Further, with antioxidant NAC and NF-κB inhibitor PDTC, we confirmed that HT attenuated PM2.5-induced IR through restraining NF-κB activation evoked by oxidative stress. In addition, HT could expand gut microbiota richness, reduce pathogenic bacteria and accommodate the microbial architecture in PM2.5-exposed mice, which were correlated with parameters of adiposity, oxidative stress and glycometabolism. HT could effectively correct imbalanced oxidative stress triggered by PM2.5, in turn ameliorated NF-κB pathway and insulin signaling. Gut microbiota may mediate the actions of HT.",science
10.1016/j.envres.2019.108535,Journal,Environmental Research,scopus,2019-09-01,sciencedirect,Urban greenery and mental wellbeing in adults: Cross-sectional mediation analyses on multiple pathways across different greenery measures,https://api.elsevier.com/content/abstract/scopus_id/85067848081,"Background
                  Multiple mechanisms have been proposed to explain how greenery in the vicinity of people's homes enhances their mental health and wellbeing. Mediation studies, however, focus on a limited number of mechanisms and rely on remotely sensed greenery measures, which do not accurately capture how neighborhood greenery is perceived on the ground.
               
                  Objective
                  To examine: 1) how streetscape and remote sensing-based greenery affect people's mental wellbeing; 2) whether and, if so, to what extent the associations are mediated by physical activity, stress, air quality and noise, and social cohesion; and 3) whether differences in the mediation across the streetscape greenery and NDVI exposure metrics occurred.
               
                  Methods
                  We used a population sample of 1029 adult residents of the metropolis of Guangzhou, China, from 2016. Mental wellbeing was quantified by the World Health Organization Well-Being Index (WHO-5). Two objective greenery measures were extracted at the neighborhood level: 1) streetscape greenery from street view data via a convolutional neural network, and 2) the normalized difference vegetation index (NDVI) from Landsat 8 remote sensing images. Single and multiple mediation analyses with multilevel regressions were conducted.
               
                  Results
                  Streetscape and NDVI greenery were weakly and positively, but not significantly, correlated. Our regression results revealed that streetscape greenery and NDVI were, individually and jointly, positively associated with mental wellbeing. Significant partial mediators for the streetscape greenery were physical activity, stress, air quality and noise, and social cohesion; together, they explained 62% of the association. For NDVI, only physical activity and social cohesion were significant partial mediators, accounting for 22% of the association.
               
                  Conclusions
                  Mental health and wellbeing and both streetscape and satellite-derived greenery seem to be both directly correlated and indirectly mediated. Our findings signify that both greenery measures capture different aspects of natural environments and may contribute to people's wellbeing by means of different mechanisms.",science
10.1016/j.cie.2019.06.040,Journal,Computers and Industrial Engineering,scopus,2019-09-01,sciencedirect,"Bernard, an energy intelligent system for raising residential users awareness",https://api.elsevier.com/content/abstract/scopus_id/85067600850,"Energy efficiency is still a hot topic today. Coming roughly the 25% of the energy consumption in EU from the residential sector, very few cheap and simple tools to promote energy efficiency in home users have been developed. The purpose of this paper is to present Bernard, a concept proof designed for filling this gap. This aims that householders become aware of their energy habits and have useful information that help them to redirect their consumption pattern. To achieve these goals, Bernard offers, through a mobile application, the home energy consumption monitoring in real time, the energy price forecast for the next hour and the appliances which are switched on, among others. Furthermore, it is important to highlight that the system has been designed with the premises of being cheap, non-intrusive, reliable and easily scalable, in order that utilities can gradually deploy and provide it to their customers, gaining at the same time valuable information for decision making and improving its corporate social image. Therefore, the adopted solution is based on a real time streaming data architecture suitable for handling huge volumes of data and applying predictive techniques on a cloud-computing environment. The paper provides a detailed description of the system and experimental results evaluating the performance of the predictive modules built. As case study, REFIT and REDD datasets were used.",science
10.1016/j.fct.2019.05.060,Journal,Food and Chemical Toxicology,scopus,2019-09-01,sciencedirect,Di-(2-ethylhexyl)-phthalate induces apoptosis via the PPARγ/PTEN/AKT pathway in differentiated human embryonic stem cells,https://api.elsevier.com/content/abstract/scopus_id/85066943364,"[Objective]
                  Di(2-ethylhexyl) phthalate (DEHP), a widely used plasticizer, may act as an endocrine disruptor and cause developmental toxicity. Differentiated human embryonic stem cells (hESCs) were used to investigate the underlying mechanism of the embryotoxicity induced by DEHP.
                  
                     [Materials and Methods] H9-hESCs were treated with DEHP at different concentrations for 10 days, and the cytotoxicity of DEHP on cell proliferation was determined using a cell-microelectronic sensing technique (Real-Time Cellular Analysis: RTCA). Based on the 50% inhibitory proliferation concentration (IC50), differentiated H9-hESCs were treated with DEHP at 0, 50, 100, and 200 μg/ml for 120 h, followed by measurement of its toxic effects on the transcriptome by mRNA microarray and QuantiGene Plex (QGP). Proteins were detected by the iTRAQ-based proteomics method and the proteins related to the PPARγ/PTEN/Akt pathways were measured by western blotting. The progression of the cell cycle and apoptosis were characterized using flow cytometry (FCM). In other experiments, hESCs were pre-treated with GW9662 (20 μM), a specific PPARγ inhibitor, for 30 min, followed by exposure to GW9662 (20 μM) and DEHP (200 μg/ml) for 120 h to observe the underlying mechanism of DEHP's embryotoxicity.
               
                  [Results]
                  DEHP inhibited H9-hESC cell proliferation in a dose-dependent manner, with an IC50 of 165.78 μg/ml. FCM results showed that DEHP could markedly induce cell cycle arrest and increase apoptosis. Gene microarray and QPG array analyses indicated that the peroxisome proliferator-activated receptor γ (PPARγ) was an apparent target for DEHP. We further demonstrated that DEHP could activate the PPARγ and upregulate the expression of PTEN downstream genes, and then play a negative role in the AKT signaling pathway. Cells pretreated with PPARγ inhibitor, GW9662, were shown to restore the effect of DEHP on the PPARγ/PTEN/AKT signaling pathway, and induce the recovery of cell cycle arrest and apoptosis.
               
                  [Conclusion]
                  DEHP inhibited cell proliferation, promoted cell cycle arrest, and induced apoptosis through the PPARγ/PTEN/AKT signaling pathway in differentiated human embryonic stem cells. It suggested that DEHP exposure possibly cause reproductive or developmental toxicity in humans through the PPARγ signaling pathway.",science
10.1016/j.knosys.2019.05.010,Journal,Knowledge-Based Systems,scopus,2019-09-01,sciencedirect,Augmented label propagation for seed set expansion,https://api.elsevier.com/content/abstract/scopus_id/85065873438,"In many applications such as social network analysis and recommendation systems, it is of particular interest to identify a group of similar nodes/users/items. However, in networks of massive size, manual labeling process becomes intractable. A practical means is to mark a small number of nodes as seeds, and then expand them to the rest (unlabeled) ones, which is also known as seed set expansion. We present a novel method for seed set expansion by leveraging information spreading dynamics through label propagation. In particular, by devising an augmented, community-based label propagation, we can fully exploit the information of the limited seed nodes, and apply the connectivity structure of the whole network in imposing a larger number of constraints on the label propagation process, thus achieving an improved estimation. Our method can increase the effective number of seed nodes in that it can achieve a better estimation than other propagation methods using the same number of seeds. Extensive experiments on real-world datasets demonstrate the effectiveness and adaptiveness of our method, compared to the state-of-the-art approaches.",science
10.1016/j.ins.2019.05.050,Journal,Information Sciences,scopus,2019-09-01,sciencedirect,Link prediction in temporal networks: Integrating survival analysis and game theory,https://api.elsevier.com/content/abstract/scopus_id/85065868765,"Link prediction is an important task in complex network analysis and can be found in many real-world applications such as recommendation systems, information retrieval, and marketing analysis of social networks. This paper focuses on studying the evolution mechanism of real-world temporal networks. Specifically, given a set of temporal links during a fixed time window, how to predict the existence of links at any point in the future. To address this problem, we propose a novel semi-supervised learning framework, which integrates both survival analysis and game theory. First, we carefully define the ϵ-adjacent network sequence, and make use of time stamp on each link to generate the baseline network evolution sequence. Next, to capture the law of network evolution, we employ the Cox Proportional Hazard Model (Cox PHM) to study the relative hazard associated with each temporal link, so as to estimate the coefficients of covariates, which are defined as a set of neighborhood based proximity features. To narrow the area of inquiry, we further propose a game theory based two-way selection mechanism to predict the future network topology. We finally encapsulate these two new technologies in a robust Autonomy-Oriented-Computing (AOC) multi-agent system, and propose a paralleled algorithm to conduct the temporal link prediction task. Extensive experiments were applied to real-world temporal networks to demonstrate both effectiveness and scalability of the proposed approach.",science
10.1016/j.neuroimage.2019.05.021,Journal,NeuroImage,scopus,2019-09-01,sciencedirect,Empathy to emotional voices and the use of real-time fMRI to enhance activation of the anterior insula,https://api.elsevier.com/content/abstract/scopus_id/85065849241,"The right anterior insula (AI), known to have a key role in the processing and understanding of social emotions, is activated during tasks that involve the act of empathising. Neurofeedback provides individuals with a visualisation of their own brain activity, enabling them to regulate and modify this activity. Following previous research investigating the ability of individuals to up-regulate right AI activity levels through neurofeedback, we investigated whether this could be similarly accomplished during an empathy task involving auditory stimuli of human positive and negative emotional expressions. Twenty participants, ten with feedback from right anterior insula and ten with feedback from a sham brain region, participated in two sessions that included sixteen neurofeedback runs and four transfer runs. Results showed that for the second session participants in the right AI neurofeedback group demonstrated better ability to up-regulate their right AI compared to the control group who received sham feedback. Examination of the relationship between individual participants’ empathic traits and their ability to up-regulate right AI activity showed that participants low on empathic traits produced a greater increase in activation of right AI by the end of training. Moreover, the response to positively valenced audio stimuli was greater than for negatively valenced stimuli. These results have implications for therapeutic training of empathy in populations with limited empathic response.",science
10.1016/j.fuel.2019.02.122,Journal,Fuel,scopus,2019-09-01,sciencedirect,An experimental investigation of nanoemulsion enhanced oil recovery: Use of unconsolidated porous systems,https://api.elsevier.com/content/abstract/scopus_id/85064655092,"Utilization of nanoparticles in oil and gas industry has attracted considerable attention of engineers and researchers. In this article, the feasibility of nanoemulsion flooding is investigated as a method for Enhanced Oil Recovery (EOR) through coreflooding experiments, using a packed bed and real reservoir fluids. Nine different mixtures of the solvent, surfactant, and nanoparticles in the form of a nanoemulsion phase are generated and used to recover the oil in the context of an EOR process. Various tests are conducted to determine the properties of porous medium and fluids. To study the production performance of this EOR technique, pressure drop across the packed bed are measured, along with the volumetric measurements of the produced fluids. A baseline injection scheme using seawater is also performed. All the nanoemulsion fluids are synthesized using the same base seawater. The Taguchi experimental design approach is employed in this research to design the experiments. The effects of nanoparticles concentration, along with those of surfactant and solvent components of the injection fluid on the oil recovery at the laboratory scale are investigated using the Analysis of Variance (ANOVA) method. Comparing the performance of waterflooding (WF) and nanoemulsion flooding, enhancement in the Recovery Factor (RF) by using emulsions is between 40–107%. Both the pressure and pressure fluctuations are surprisingly higher in the case of WF in comparison to the emulsion flooding. It is also found that under optimal concentration conditions (0.01 g of nanoparticles, 0.015 mL of surfactant, and 1 mL of solvent per one liter of brine), a recovery factor of up to 60% is achieved.",science
10.1016/j.fusengdes.2019.03.178,Journal,Fusion Engineering and Design,scopus,2019-09-01,sciencedirect,Neural network based prediction of heat flux profiles on STRIKE,https://api.elsevier.com/content/abstract/scopus_id/85063884800,"The instrumented calorimeter STRIKE (Short-Time Retractable Instrumented Kalorimeter Experiment) has been designed with the main purpose of characterizing the SPIDER (Source for Production of Ion of Deuterium Extracted from Radio Frequency plasma) negative ion beam in terms of beam uniformity and divergence during short pulse operations. STRIKE is made of 16 1D Carbon Fiber Composite (CFC) tiles, intercepting the whole beam and observed on the rear side by infrared (IR) cameras. The front observation presents some drawbacks due to optically emitting layer caused by the excited gas between the beam source and the calorimeter, and the material sublimated from the calorimeter surfaces due to the heating itself. This paper proposes a Neural Network-based approach to solve the inverse non-linear problem of determining the energy flux profile impinging on the calorimeter, considering the 2D temperature pattern measured on the rear side of the tiles. Most of the conventional methods used to evaluate the inverse heat flux are unbearably time consuming; since the objective is having a tool for heat flux evaluation for STRIKE real time operation, the need to have a ready-to-go instrument to understand the beam condition becomes stringent. For this reason, in this paper, a Multi-Layer Perceptron has been used to solve the problem. Once properly trained, the neural networks provide a fast evaluation of the impinging flux. Furthermore, there is no need to optimize any parameter since this operation is already included in the self-adjustment of the network weights during the training. The achieved results show the reliability of the proposed method both with stationary and non-stationary heat fluxes.",science
10.1016/j.sysarc.2019.01.007,Journal,Journal of Systems Architecture,scopus,2019-09-01,sciencedirect,A Survey and Taxonomy of FPGA-based Deep Learning Accelerators,https://api.elsevier.com/content/abstract/scopus_id/85063404030,"Deep learning, the fastest growing segment of Artificial Neural Network (ANN), has led to the emergence of many machine learning applications and their implementation across multiple platforms such as CPUs, GPUs and reconfigurable hardware (Field-Programmable Gate Arrays or FPGAs). However, inspired by the structure and function of ANNs, large-scale deep learning topologies require a considerable amount of parallel processing, memory resources, high throughput and significant processing power. Consequently, in the context of real time hardware systems, it is crucial to find the right trade-off between performance, energy efficiency, fast development, and cost. Although limited in size and resources, several approaches have showed that FPGAs provide a good starting point for the development of future deep learning implementation architectures. Through this paper, we briefly review recent work related to the implementation of deep learning algorithms in FPGAs. We will analyze and compare the design requirements and features of existing topologies to finally propose development strategies and implementation architectures for better use of FPGA-based deep learning topologies. In this context, we will examine the frameworks used in these studies, which will allow testing a lot of topologies to finally arrive at the best implementation alternatives in terms of performance and energy efficiency.",science
10.1016/j.datak.2017.07.008,Journal,Data and Knowledge Engineering,scopus,2019-09-01,sciencedirect,Social emotion classification based on noise-aware training,https://api.elsevier.com/content/abstract/scopus_id/85026356456,"Social emotion classification draws many natural language processing researchers’ attention in recent years, since analyzing user-generated emotional documents on the Web is quite useful in recommending products, gathering public opinions, and predicting election results. However, the documents that evoke prominent social emotions are usually mixed with noisy instances, and it is also challenging to capture the textual meaning of short messages. In this work, we focus on reducing the impact of noisy instances and learning a better representation of sentences. For the former, we introduce an “emotional concentration” indicator, which is derived from emotional ratings to weight documents. For the latter, we propose a new architecture named PCNN, which utilizes two cascading convolutional layers to model the word-phrase relation and the phrase–sentence relation. This model regards continuous tokens as phrases based on an assumption that neighboring words are very likely to have internal relations, and semantic feature vectors are generated based on the phrase representation. We also present a Bayesian-based model named WMCM to learn document-level semantic features. Both PCNN and WMCM classify social emotions by capturing semantic regularities in language. Experiments on two real-world datasets indicate that the quality of learned semantic vectors and the performance of social emotion classification can be improved by our models.",science
10.1016/j.neucom.2018.09.099,Journal,Neurocomputing,scopus,2019-08-18,sciencedirect,Developing enhanced conversational agents for social virtual worlds,https://api.elsevier.com/content/abstract/scopus_id/85064902503,"In this paper, we present a methodology for the development of embodied conversational agents for social virtual worlds. The agents provide multimodal communication with their users in which speech interaction is included. Our proposal combines different techniques related to Artificial Intelligence, Natural Language Processing, Affective Computing, and User Modeling. A statistical methodology has been developed to model the system conversational behavior, which is learned from an initial corpus and improved with the knowledge acquired from the successive interactions. In addition, the selection of the next system response is adapted considering information stored into user’s profiles and also the emotional contents detected in the user’s utterances. Our proposal has been evaluated with the successful development of an embodied conversational agent which has been placed in the Second Life social virtual world. The avatar includes the different models and interacts with the users who inhabit the virtual world in order to provide academic information. The experimental results show that the agent’s conversational behavior adapts successfully to the specific characteristics of users interacting in such environments.",science
10.1016/j.oceaneng.2019.106129,Journal,Ocean Engineering,scopus,2019-08-15,sciencedirect,Study on wavelet neural network based anomaly detection in ocean observing data series,https://api.elsevier.com/content/abstract/scopus_id/85067611959,"In this paper, a novel method is presented for detecting anomalies in ocean fixed-point observing time series, which combines wavelet neural network (WNN), classifying threshold and two detecting strategies. The WNN was developed without any labeled training data to simulate the non-anomalous behaviors for next-step prediction. The classifying threshold was constructed according to the estimated distribution of long-term historical residual errors. The observation strategy (OS) and prediction strategy (PS) were designed to detect new unknown anomalies. Two types of marine observing time series from a buoy, deployed at the National Ocean Test Site of China, were selected for verifying the method. The results show that 99% of classifying confidence level is adequate to provide a reasonable trade-off between the false negative and false positive. By using the two detecting strategies and selecting proper estimated distribution of the threshold, the method is efficient for identifying the anomalous points and patterns which were caused by the natural factors or equipment failures. Compared with traditional ANN and wavelet-ANN, the WNN-based method is more tolerant to noise and more sensitive to anomalies with temporal dependencies. Furthermore, this approach introduced here can work in a real-time way and will help ocean engineering managers to obtain informed decisions.",science
10.1016/j.ymeth.2019.03.014,Journal,Methods,scopus,2019-08-15,sciencedirect,Enhancer prediction with histone modification marks using a hybrid neural network model,https://api.elsevier.com/content/abstract/scopus_id/85063315703,"Enhancer is a DNA sequence of a genome that controls transcription of downstream target genes. Enhancers are known to be associated with certain epigenetic signatures. Machine learning tools, such as CSI-ANN, ChromHMM, and RFECS, were developed for predicting enhancers using various epigenetic features. However, predictions by different tools vary widely and quite a significant portion of enhancer predictions does not agree. Thus, computational methods for enhancer prediction should be further developed. In this paper, a hybrid neural network called Enhancer-CRNN, a convolutional neural network (CNN) followed by a recurrent neural network (RNN), was developed and they were used to predict enhancer regions with histone modification marks as input. The CNN in our model is to reflect local characteristics and the RNN is to learn sequential dependencies among the histone marks. Hybridization of both neural networks outperformed existing prediction tools in experiments with GM12878, H1hesc, HeLaS3, and HepG2 cell lines. On average, 13–17 percent of the enhancers predicted by our method were cell type-specific. With the trained model, optimized virtual input histone marks was generated to provide a deeper insight into how histone modification marks can represent enhancer regions in which histone marks indicate active or repressed enhancers. In summary, our model produced accurate annotation of enhancers with detailed information on how histone profiles contribute to the presence of putative enhancers.",science
10.1016/j.ymeth.2019.03.002,Journal,Methods,scopus,2019-08-15,sciencedirect,Machine learning polymer models of three-dimensional chromatin organization in human lymphoblastoid cells,https://api.elsevier.com/content/abstract/scopus_id/85062857567,"We present machine learning models of human genome three-dimensional structure that combine one dimensional (linear) sequence specificity, epigenomic information, and transcription factor binding profiles, with the polymer-based biophysical simulations in order to explain the extensive long-range chromatin looping observed in ChIA-PET experiments for lymphoblastoid cells. Random Forest, Gradient Boosting Machine (GBM), and Deep Learning models were constructed and evaluated, when predicting high-resolution interactions within Topologically Associating Domains (TADs). The predicted interactions are consistent with the experimental long-read ChIA-PET interactions mediated by CTCF and RNAPOL2 for GM12878 cell line. The contribution of sequence information and chromatin state defined by epigenomic features to the prediction task is analyzed and reported, when using them separately and combined.
                  Furthermore, we design three-dimensional models of chromatin contact domains (CCDs) using real (ChIA-PET) and predicted looping interactions. Initial results show a similarity between both types of 3D computational models (constructed from experimental or predicted interactions). This observation confirms the association between genome sequence, epigenomic and transcription factor profiles, and three-dimensional interactions.",science
10.1016/S1361-3723(19)30083-1,Journal,Computer Fraud and Security,scopus,2019-08-01,sciencedirect,AI vs AI: fraudsters turn defensive technology into an attack tool,https://api.elsevier.com/content/abstract/scopus_id/85070686326,"The first rule of managing online fraud and mitigating risk is to remember that fraudsters are entrepreneurs. While it's tempting to think of those committing digital fraud as hoody-wearing lone wolves spending hours in their bedroom working to weasel their way into someone's online account, in reality professional fraud operations look more like the JP Morgan trading floor.
                  Cyber criminals are not simple, hoodie-wearing lone wolves. Many are sophisticated fraud operations using the most advanced technology, including artificial intelligence (AI).
                  The energy and ingenuity with which fraud rings and cyber criminals have deployed AI-based solutions has matched that of the businesses and organisations that work to protect themselves from bad actors. Machines have been put to malicious use in ways ranging from click farms to complex model extraction schemes, explains Swami Vaithianathasamy of Signifyd.",science
10.1016/j.compag.2019.05.049,Journal,Computers and Electronics in Agriculture,scopus,2019-08-01,sciencedirect,Automated pig counting using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85067302123,"Pig counting is one of the most critical topics in farming management and asset estimation. Due to its complexity, traditional agriculture method relies on manual counting, which is obviously inefficient and a waste of manpower. The challenging aspects like partial occlusion, overlapping and different perspectives even limit the usage of traditional computer vision techniques. In recent years, deep learning has become more and more popular for computer vision applications, because of its superior performance comparing to traditional methods. In this paper, we propose a deep learning solution to address the pig counting problem. We present a modified Counting Convolutional Neural Network (Counting CNN) model according to the structure of ResNeXt, and tune a series of experimental parameters. Our CNN model learns the mapping from the image feature to the density map, and obtains the total number of pigs in the entire image by integrating the density map. In order to validate the efficacy of our proposed method, we conduct experiments on a real-world dataset collected from actual piggery farming with 15 pigs in an image averagely. We achieve 1.67 Mean Absolute Error (MAE) per image and outperforms the competing algorithms, which strongly demonstrates that our proposed method can accurately estimate the number of pigs even if they are partially occluded in different perspectives. The detection speed, 42 ms per image, meets the requirements of agricultural application. We share our code and the first pig dataset we collected for pig counting at https://github.com/xixiareone/counting-pigs for livestock husbandry and science research community.",science
10.1016/j.biomaterials.2019.05.010,Journal,Biomaterials,scopus,2019-08-01,sciencedirect,Construction of lanthanide-doped upconversion nanoparticle-Uelx Europaeus Agglutinin-I bioconjugates with brightness red emission for ultrasensitive in vivo imaging of colorectal tumor,https://api.elsevier.com/content/abstract/scopus_id/85065732648,"Lanthanide-doped upconversion nanoparticles (UCNPs)-based active targeting optical bioimaging has attracted tremendous scientific interest because of its noninvasive real-time signal feedback, superior tissue penetration depth and high spatial resolution in early diagnosis of disease. Herein, we synthesize a novel carboxy-terminated silica coated NaErF4: 10% Yb@NaYF4: 40% Yb@NaNdF4: 10% Yb@NaGdF4: 20% Yb UCNPs (termed as UCNP@SiO2-COOH) with 808 nm near-infrared (NIR) excitation and bright 655 nm upconversion luminescence (UCL) emission for realizing deep tissue imaging. Under 808 nm NIR laser excitation (1.5 W cm−2), the UCL of UCNP@SiO2-COOH with relative low concentration (2 mg mL−1) can be successfully visualized under a chicken breast slice with 10 mm thickness. After conjugated with various molecules including NH2-PEG3400-COOH, peptide D-SP5 and Uelx Europaeus Agglutinin-I (UEA-I), biodistributions, clearance pathways and tumor-targeting capacities of the UCNP@SiO2-COOH and corresponding bioconjugates (termed as UCNP@SiO2-PEG, UCNP@SiO2-D-SP5 and UCNP@SiO2-UEA-I, respectively) were investigated by tracking the UCL intensities of livers, kidneys and tumors. Both of in vitro and in vivo experimental results reveal that there is no significant difference for their in vivo biodistributions and clearance pathways. The UCNP@SiO2-UEA-I exhibits much higher SW480 tumor-targeting capacity than those of other bioconjugates. In particular, the as-prepared UCNP@SiO2-UEA-I even to visualize ultrasmall (c.a. 3 mm3 in volume) subcutaneous SW480 tumor in Balb/c nude mouse through intravenous administration. The study implies that the red UCL emitted UCNPs with a minimized heating effect is suitable for deep tissue biomedical imaging and UCNP@SiO2-UEA-I can serve as an efficient optical probe for early diagnosis of SW480 tumor.",science
10.1016/j.ins.2019.05.001,Journal,Information Sciences,scopus,2019-08-01,sciencedirect,Sim2vec: Node similarity preserving network embedding,https://api.elsevier.com/content/abstract/scopus_id/85065142641,"Networks such as social networks, computer networks, and citation networks are ubiquitous in the real world. Aiming to learn distributed representations for nodes in a network, network embedding has attracted widespread attention from quite a few researchers due to its critical application in complex network analysis. However, the majority of existing algorithms merely facilitate the local pairwise proximity or implicitly characterize the neighborhood similarity in a network, which are not expressive enough to characterize the diversity of node similarities. In this paper, we present an innovative network embedding framework, Sim2vec, which can encode more comprehensive node similarities among different nodes in a network into unified latent spaces based on deep neural networks. Specifically, we incorporate the adjacency similarity, the accessibility similarity and the neighborhood similarity between two nodes, and introduce their respective measures. To capture more integral structural information in a network, these node similarities are encoded into low-dimensional and dense vector spaces by jointly optimizing the carefully designed objective function. Extensive experiments conducted on several networks demonstrate that the proposed approach is effective and it outperforms the existing state-of-the-art approaches on a variety of tasks, including node classification, link prediction, node visualization and node clustering.",science
10.1016/j.autcon.2019.04.015,Journal,Automation in Construction,scopus,2019-08-01,sciencedirect,Impact assessment of reinforced learning methods on construction workers' fall risk behavior using virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85064642464,"Given the nature of construction activities, construction workers usually work in a collaborative way. Thus, interpersonal influences among workers play a crucial role in forming and affecting construction workers' safety behaviors. The social learning literature indicates that interpersonal learning occurs in two opposing ways – positive reinforcement by demonstrating preferred behaviors, and negative reinforcement by demonstrating negative consequences of inappropriate behaviors. Amid theoretical disagreements in the social learning literature, it remains unclear in the construction safety literature how the two reinforced learning methods affect construction workers in safety training. To fill the gap, a human-subject experiment (n = 126) was conducted to investigate people's social learning behaviors in a hazardous construction situation – walking between two high-rise buildings. The experiment utilizes a multi-user Virtual Reality (VR) system with a motion tracking feature. Participants were randomly assigned to one of three groups: control group (no instruction was given), not-falling group (participants observed an avatar demonstrating appropriate walking behaviors), and falling group (participants watched an avatar quickly walking across a plank and falling off). Indicators, including walking time on the plank, walking speed, and gaze movement, were recorded and analyzed to quantify the effects of the two reinforced learning methods. The results indicate that demonstrating information with positive consequences (not-falling group) encourages people to follow the demonstration and maintain normal walking in a hazardous situation. Showing information with negative consequences (falling group) induced participants to walk faster and more irregularly, which further led to more mistakes and unsafe behaviors. This study demonstrates the effectiveness of using VR in safety studies and provides recommendations for better safety training programs.",science
10.1016/j.scitotenv.2019.04.238,Journal,Science of the Total Environment,scopus,2019-08-01,sciencedirect,Applying sunscreens on earthworms: Molecular response of Eisenia fetida after direct contact with an organic UV filter,https://api.elsevier.com/content/abstract/scopus_id/85064615222,"The use of organic Ultraviolet (UV) filters has increased in the last years, either in sunscreens, other cosmetics, or even food packaging. These filters may end up in soil and water since the Wastewater Treatment Plants may not successfully remove them. Among them, benzophenones are known to act as endocrine disruptors. However, most of the studies are directed towards vertebrates and aquatic invertebrates, while there is a lack of information on the molecular mechanisms affected by these compounds on soil dwelling invertebrates. Here, we study the impact of direct acute (48 h) contact of 4-hydroxybenzophenone (4-OHBP) at two sublethal concentrations (0.02 and 0.2 mg/mL) on gene expression of the earthworm Eisenia fetida. Investigated genes were involved in endocrine pathways, stress response, detoxification mechanisms, genotoxicity, energy metabolism and epigenetics. Three of them were identified for the first time in earthworms. Our results suggest that exposure to 4-OHBP affected endocrine pathways, causing an increase in the Ecdysone receptor gene (EcR) expression. Moreover, the UV filter induced changes in the CuZn superoxide dismutase gene (CuZn SOD), indicating an effect in the stress response. Finally, significant changes were detected for glyceraldehyde-3-phosphate dehydrogenase gene (GAPDH) expression, indicating that energy metabolism is influenced by the 4-OHBP and highlighting the risks of using GAPDH as an internal reference for Real Time PCR.",science
10.1016/j.eswa.2019.02.013,Journal,Expert Systems with Applications,scopus,2019-08-01,sciencedirect,Machine learning algorithms for predicting drugs–tissues relationships,https://api.elsevier.com/content/abstract/scopus_id/85062845878,"The prediction of drug candidates for given tissues of organisms based on expression data is a critical biological problem. By correctly predicting drug candidates for given tissues, biologists can (1) avoid an experimental process of high-throughput screening that requires excessive time and costly equipment and (2) accelerate the drug discovery process by automatically assigning drug candidates. Although high throughput screening for therapeutic compounds lead to the generation of expression data, the process of correctly assigning candidate drugs based on such data remains a rigorous task. Hence, the design of high-performance machine learning (ML) algorithms is crucial for data analysts who work with clinicians. Clinicians incorporate advanced ML tools into expert and intelligent systems to improve the drug discovery process by accurately identifying drug candidates. The transfer learning approaches that are necessary to improve the prediction performance of several tasks that are involved in identifying drug candidates are presented in this paper. The performances of machine learning algorithms are compared in the transfer learning setting by employing several evaluation measures on real data that are obtained from experiments conducted on rats to identify drug candidates. The experimental results show that the proposed transfer learning approaches outperform baseline approaches in terms of prediction performance and statistical significance.",science
10.1016/j.trc.2019.02.010,Journal,Transportation Research Part C: Emerging Technologies,scopus,2019-08-01,sciencedirect,The effect of social influence and social interactions on the adoption of a new technology: The use of bike sharing in a student population,https://api.elsevier.com/content/abstract/scopus_id/85061773352,"The present study investigates how social influence and social interactions can affect the adoption of new technologies, using stated preference (SP) survey data combined with an “accelerated reality” experience of social interaction among the respondents. Specifically, the intention to use a pro-environmental transport mode (the bike sharing) during a public transport strike within a cohort of students has been analysed. Previous studies have modelled social influence effects using SP data by providing a hypothetical scenario with simulated interactions or information about social conformity processes (i.e. social adoption) during the survey. In our paper, in addition to the impact of assumed social norms, the effect of live/real social interactions is included in the survey. SP survey is developed to investigate the effect of Level-of-Service attributes on the hypothetical choices in the scenario of a public transport strike. Besides the pre-defined attributes characterising the alternatives in the SP design, the survey includes techniques to acquire information on conformity and social interactions. Specifically, the interviewees undertake a before and after stated preference experiment (SP1 and SP2), with a period of group discussion in between the two parts. This SP experiment involves different cognitive and interpersonal mechanisms, such as the functional information exchange on benefits and drawbacks of cycling and bike sharing. The aim is to establish whether hypothetical scenarios of social conformity are different from real/live social interactions and whether these social influence processes actually affect the individuals' mode choice. A joint SP1/SP2 mixed logit (ML) model has been estimated to explore the choice behaviour of individuals and allows us to incorporate the inertia/propensity to change behaviour between SP1 and SP2. Moreover, considering the “Reflexive Layers of Influence” (RLI) framework, the processes generated by social interactions (diffusion, translation and reflexivity) are measured and incorporated in the model. We finally show the effect of these social influence variables on the goodness-of-fit of the models and choice simulation for prediction. We also draw conclusions about the value of such enhanced choice models in understanding and predicting the impacts of social interactions on choice behaviour in the context of new transport technologies.",science
10.1016/j.jep.2019.111928,Journal,Journal of Ethnopharmacology,scopus,2019-07-15,sciencedirect,The repression and reciprocal interaction of DNA methyltransferase 1 and specificity protein 1 contributes to the inhibition of MET expression by the combination of Chinese herbal medicine FZKA decoction and erlotinib,https://api.elsevier.com/content/abstract/scopus_id/85065504267,"Ethnopharmacological relevance
                  The Chinese herbal medicine Fuzheng Kang-Ai (FZKA) decoction obtained from Guangdong Kangmei Pharmaceutical Company, which contains 12 components with different types of constituents, has been used as part of the adjuvant treatment of lung cancer for decades. We previously showed that FZKA decoction enhances the growth inhibition of epidermal growth factor receptor-tyrosine kinase inhibitor (EGFR-TKI)-resistant non-small cell lung cancer (NSCLC) cells by suppressing glycoprotein mucin 1 (MUC1) expression. However, the molecular mechanism underlying the therapeutic potential, particularly in sensitizing or/and enhancing the anti-lung cancer effect of EGFR-TKIs, remains unclear.
               
                  Materials and methods
                  Cell viability was measured using 3-(4, 5-diMEThylthiazol-2-yl)-2, 5-diphenyltetrazolium bromide (MTT) and 5-ethynyl -2′-deoxyuridine (EdU) assays. Western blot analysis was performed to examine the protein expressions of DNA methyltransferase 1 (DNMT1), specificity protein 1 (SP1), and MET, an oncogene encoding for a trans-membrane tyrosine kinase receptor activated by the hepatocyte growth factor (HGF). The expression of MET mRNA was measured by quantitative real-time PCR (qRT-PCR). Exogenous expression of DNMT1 and SP1, and MET were carried out by transient transfection assays. The promoter activity of MET was tested using Dual-luciferase reporter assays. A nude mouse xenografted tumor model further evaluated the effect of the combination of FZKA decoction and erlotinib in vivo.
               
                  Results
                  The combination of FZKA and erlotinib produced an even greater inhibition of NSCLC cell growth. FZKA decreased the expressions of DNMT1, SP1, and MET (c-MET) proteins, and the combination of FZKA and erlotinib demonstrated enhanced responses. Interestingly, there was a mutual regulation of DNMT1 and SP1. In addition, exogenously expressed DNMT1 and SP1 blocked the FZKA-inhibited c-MET expression. Moreover, excessive expressed MET neutralized FZKA-inhibited growth of NSCLC cells. FZKA decreased the mRNA and promoter activity of c-MET, which was not observed in cells with ectopic expressed DNMT1 gene. Similar findings were observed in vivo.
               
                  Conclusion
                  FZKA decreases MET gene expression through the repression and mutual regulation of DNMT1 and SP1 in vitro and in vivo. This leads to inhibit the growth of human lung cancer cells. The combination of FZKA and EGFR-TKI erlotinib exhibits synergy in this process. The regulatory loops among the DNMT1, SP1 and MET converge in the overall effects of FZKA and EGFR-TKI erlotinib. This in vitro and in vivo study clarifies an additional novel molecular mechanism underlying the anti-lung cancer effects in response to the combination of FZKA and erlotinib in gefitinib-resistant NSCLC cells.",science
10.1016/j.neucom.2019.04.022,Journal,Neurocomputing,scopus,2019-07-15,sciencedirect,Real-time event embedding for POI recommendation,https://api.elsevier.com/content/abstract/scopus_id/85064397284,"Location-based social networks (LBSNs) allow users to check-in and share daily lives with others. We have witnessed very rapid development of LBSNs in recent years. Point-of-Interest (POI) recommendation is one of the core services in LBSNs. In this study, we propose a real-time POI embedding model. Instead of capturing intrinsic information, the proposed approach is able to mine real-time information of places and learn the latent representations according to the corresponding geo-tagged posts. On one hand, we employ a Convolutional Neural Networks (CNN) to mine textual information of POIs and learn their intrinsic representation. On the other hand, a multimodal embedding model of location, time and text is applied to keep monitoring posts on POIs and extracts a set of features for representing events or burst information that may attract users. Furthermore, we combine real-time POI embedding with matrix factorization method and propose a more comprehensive POI recommendation algorithm. To verify the effectiveness of our proposed method, we conduct experiments on Twitter dataset with geo-tagged tweets in NYC. Experimental results show that POI recommendation system with taking real-time event into consideration can strongly improve the performance than the one without.",science
10.1016/j.ymssp.2019.03.023,Journal,Mechanical Systems and Signal Processing,scopus,2019-07-15,sciencedirect,Relevance vector machine for tool wear prediction,https://api.elsevier.com/content/abstract/scopus_id/85063349356,"In order to realize real-time and accurate monitoring of the tool wear in machining process, this paper presents a tool wear predictive model based on the integrated radial basis function based kernel principal component analysis (KPCA_IRBF) and relevance vector machine (RVM). The traditional methods such as partial least squares regression (PLS), artificial neural network (ANN) and support vector machine (SVM) can only provide predicted values which have no probabilistic significance. As a sparse probabilistic model, RVM can provide both the predicted value and the corresponding confidence interval (CI). However, the existence of process noises and redundancy will seriously affect the prediction accuracy and the stability of CI. As a new dimension-increment technique, KPCA_IRBF helps to weaken the negative effects of process noises and redundancy by increasing the dimensionality of monitoring features. The fused features obtained by KPCA_IRBF are more sensitive to the change of tool wear. Two different cutting experiments are carried out to verify the effectiveness of KPCA_IRBF in improving the prediction accuracy and ameliorating the CI of RVM. The experimental results show that KPCA_IRBF can reduce the root mean square error (RMSE) of RVM by more than 30% and compress the average width of CI by more than 90%. To further show the advantages of RVM, the traditional methods such as PLS, ANN and SVM are also utilized to realize tool wear prediction. This paper lays the foundation for the application of RVM to industrial field.",science
10.1016/j.jchromb.2019.04.054,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2019-07-01,sciencedirect,Cupric ion functionalized polydopamine coated magnetic microspheres as solid-phase adsorbent for the extraction of purines in plasma,https://api.elsevier.com/content/abstract/scopus_id/85065198785,"In this paper, Cu2+ functionalized Fe3O4@polydopamine core-shell (Fe3O4@PDA@Cu2+) magnetic microspheres were prepared by the chelation between Cu2+ and catechol of polydopamine surface. The synthetic magnetic adsorbent was characterized by Fourier transform infrared spectroscopy, energy dispersive X-ray spectroscopy, vibrating sample magnetometry, thermogravimetric analysis, scanning electron microscope and transmission electron microscopy. Four purines include guanine, adenine, hypoxanthine and xanthine were selected as model compounds to evaluate the applicability of this adsorbent. Several parameters that effected the extraction efficiency, such as extraction time, adsorbent amount, solution pH, ionic strength, eluent type, concentration of eluent and eluent time, were investigated. Under the optimized conditions, good linearity was obtained with correlation coefficients between 0.9983 and 0.9999 for the four analytes, and their LOD and LOQ were 0.42–2.15 ng/mL and 1.41–6.50 ng/mL, respectively. Meanwhile, the RSDs of intra-day and inter-day precision were in the range of 1.43%–5.55% and 4.56%–7.01%, respectively. The spiked recoveries of four purines in real sample were 70.01%–102.42%, indicating this proposed method might have potential applications for the analysis of purines in real samples. In addition, the developed method was used to monitor the concentrations of adenine in rat plasma at different time points after intragastric administration.",science
10.1016/j.jenvman.2019.04.026,Journal,Journal of Environmental Management,scopus,2019-07-01,sciencedirect,Validated predictive modelling of sulfonamide and beta-lactam resistance genes in landfill leachates,https://api.elsevier.com/content/abstract/scopus_id/85064155267,"The spread of antimicrobial resistance via landfill leachates jeopardizes millions of people's health, which can be exacerbated due to the unclear quantitative relationships between leachate characteristics and occurrences of antibiotic resistance genes (ARGs). Here, in parallel with sampling raw leachates from a real landfill, we constructed a lab-scale landfill and collected its leachates for 260 days. All leachate samples were analyzed for the abundance of integrons, sulfonamide resistance (sulR; sul1 and sul2) and beta-lactams resistance (blaR; bla
                     OXA, bla
                     CTX-M, and bla
                     TEM) genes. The enrichment of sulR subtypes was closely associated with the integrons' prevalence during the landfilling process (0.65–0.75 log10(copies/mL)), which can be explained by the multiple linear regression that contained intl1, pH, and nitrogen compounds as variables. The predicted abundance of sulR genes (6.06 ± 0.6 log10(copies/mL)) was statistically the same as the observed value in raw leachates (P = 0.73). The abundance of blaR genes decreased from 5.0 to 2.5 log10(copies/mL) during the experiment (P < 0.001); and a locally weighted regression of blaR genes with integrons, COD and total nitrogen accurately predicted blaR genes abundance in raw leachate (Bootstrap = 10,000, P = 0.67). The partial least squares path modelling (PLS-PM) showed that variations of blaR genes in the lab and raw leachates shared an identical pattern (PLS-PM, Bootstrap = 10,000, P > 0.05), which was influenced by integrons and environmental factors with the coefficients of −0.11 and 0.39, respectively. We believe the validated models are highly useful tools to streamline the strategies for monitoring and prediction of ARGs.",science
10.1016/j.ins.2019.03.044,Journal,Information Sciences,scopus,2019-07-01,sciencedirect,A hybrid group decision making framework for achieving agreed solutions based on stable opinions,https://api.elsevier.com/content/abstract/scopus_id/85063603136,"Polarization in a group’s opinions drives to disagreements and dissent among individuals, which make it harder to achieve group satisfactory decisions. Within Group Decision Making (GDM) problems to soften disagreements, lots of consensus reaching processes (CRPs) have been proposed to converge opinions but rarely consider the existing dynamic relationships among the experts. Meanwhile, Opinion Dynamics studies the evolution of opinions based on the relationships existing among the group members by using Social Network Analysis (SNA). In real-world GDM problems the application of CRPs alone may not be enough to achieve the desired level of agreement when there is too much dissent among experts. In this paper, a novel framework is proposed that hybridizes both the process of making closer opinions realized by CRPs and the evolving relationships among experts based on SNA. This new framework addresses when it might be impossible to achieve the agreement through CRPs, which tries to achieve a potential consensus considering that if opinions are too polarized, maybe different stable opinions states are still suitable and easier to achieve by applying a SNA together with the CRP. This framework is further analyzed through simulation experiments for demonstrating its validity and some properties.",science
10.1016/j.jenvrad.2019.03.019,Journal,Journal of Environmental Radioactivity,scopus,2019-07-01,sciencedirect,Uranium biosorption by Lemna sp. and Pistia stratiotes,https://api.elsevier.com/content/abstract/scopus_id/85063317307,"Biosorption-based technologies have been proposed for the removal of radionuclides from radioactive liquid waste containing organic compounds. Nevertheless, pytoremediation potential of uranium (U) by nonliving aquatic macrophytes Lemna sp. and Pistia stratiotes has not been previously addressed. In this study, uranium biosorption capacity by Pistia stratiotes and Lemna sp. was evaluated by equilibrium and kinetics experiments. The biomasses were added to synthetic and real waste solutions. The assays were tested in polypropylene vials containing 10 mL of uranium nitrate solution and 0.20 g of biomass. Solutions ranging from 0.25 to 84.03 mmol l−1 were employed for the assessment of uranium concentration in each macrophyte. The equilibrium time was 1 h for both macrophytes. Lemna sp. achieved the highest sorption capacity with the use of the synthetic solution, which was 0.68 mmol g−1 for the macrophyte. Since Lemna sp. exhibit a much higher adsorption capacity, only this biomass was exposed to the actual waste solution, being able to adsorb 9.24 × 10−3 mmol g−1 U (total). The results show that these materials are potentially applicable to the treatment of liquid radioactive waste.",science
10.1016/j.ymssp.2019.02.037,Journal,Mechanical Systems and Signal Processing,scopus,2019-07-01,sciencedirect,Neural networks for 3D temperature field reconstruction via acoustic signals,https://api.elsevier.com/content/abstract/scopus_id/85061898371,"Reconstructed 3D temperature field will provide critical input for the control mechanisms to optimize the thermal fluids and combustion process. In this paper, a distributed optical fiber sensing system is used to generate acoustic signals for real-time monitoring and optimization of spatial and temporal distributions of high temperature profile in a boiler furnace in fossil power plants. A code division multiple access (CDMA) based acoustic signal modulation technique for improved signal to noise ratio (SNR) and simultaneous sending/receiving is developed. A kernel regression model which approximates the temperature field as a finite summation of products of space-dependent Gaussian Radial Basis Functions (GRBF) and time-dependent coefficients is established. The inversion problem to estimate the best parameters of Gaussian functions is solved by optimizing a cost function using gradient descent method. Guidance on how to tune design parameters is also given. And regularization is applied for solving the trade-off problem between bias and variance. The numerical simulations show an approximation error less than 5% in 3D temperature field reconstruction. Besides that, the performance of learned model with variation of some relevant design parameters is evaluated, and error analysis for temperature field reconstruction with measurement noise is also given. To validate the availability and efficiency of our proposed 3D temperature field reconstruction mechanism, a 2D temperature field distribution experiment test on microphone is carried out and satisfactory estimation accuracy is achieved.",science
10.1016/j.eswa.2019.01.077,Journal,Expert Systems with Applications,scopus,2019-07-01,sciencedirect,Deep learning in material recovery: Development of method to create training database,https://api.elsevier.com/content/abstract/scopus_id/85061339627,"Increasing the rate of material identification, separation and recovery is a priority in resource management and recovery, and rapid, low cost imaging and interpretation is key. This study uses different combinations of cameras, illuminations and data augmentation techniques to create databases of images to train deep neural networks for the recognition of fibre materials. Using a limited set of 24 material samples sized 1200 cm2, it compares the outcome of reducing them to 30 cm2. The best classification accuracies obtained range from 76.6% to 77.5% indicating it is possible to overcome problems such as limited available materials, time, or storage capabilities, by using a setup with 5 cameras, 5 lights and applying simple software image manipulation techniques. The same method can be used to create deep neural network training databases to recognise a wider range of materials typically found in solid waste streams, in real-time. Furthermore, it offers flexibility as the classification cameras could be deployed at different stages within solid waste processing plants, providing feedback for process control, with the potential of increasing plant efficiency and reducing costs.",science
10.1016/j.future.2018.01.043,Journal,Future Generation Computer Systems,scopus,2019-07-01,sciencedirect,Combining humans and machines for the future: A novel procedure to predict human interest,https://api.elsevier.com/content/abstract/scopus_id/85042366370,"This paper proposes a method to quantify interest. In common terminology, when we engage with an object, e.g. Online Games, Social Networking Websites, Mobile Apps, etc., there is a degree of interest between us and the object. But, owing to the lack of a procedure that can quantify interest, we are unable to tell by how ‘much’ of a factor are we interested in the object. In other words, can we find a number for someone’s interest? In this article, we propose a method that uses the principle of Bayesian Inference to tackle this issue. We formulate the “interest estimation problem” as a state estimation problem to deduce interest (in any object) indirectly from user activity. Activity caused by interest is computed through a subjective–objectiveweighted approach, then using indirect inference rules, we provide numerical estimates of interest. To do that, we model the dynamics of interest through the Ornstein–Uhlenbeck process. To further enhance the base performance, we draw inspiration from Stochastic Volatility models from Finance. Subsequently, drawing upon a self-adapting transfer function, we provide an avant-garde statistical procedure to model the transformation of interest into activity. The individual contributions are then combined and a solution is provided via Particle filters. Validation of the method is done in two ways. (1) Experimentation is performed on real datasets. Through numerical investigation we have found that the method shows good performance. (2) We implement the framework as a Web application and deploy it on an Enterprise Service Bus. The framework has been successfully hosted on a Cloud based Virtualized testbed consisting of several Virtual Machines constructed over XENServer as the underlying hypervisor. Through this experimental setup, we show the efficacy of the proposed algorithm in estimating interest, at much the same time, we demonstrate the viability of the method in practical cloud based deployment scenarios.",science
10.1016/j.jep.2019.03.019,Journal,Journal of Ethnopharmacology,scopus,2019-06-12,sciencedirect,"Ribes orientale: A novel therapeutic approach targeting rheumatoid arthritis with reference to pro-inflammatory cytokines, inflammatory enzymes and anti-inflammatory cytokines",https://api.elsevier.com/content/abstract/scopus_id/85063127228,"Ethnopharmacological relevance
                  The roots of Ribes orientale (Family Grossulariaceae) have long been used as a folk remedy to treat rheumatism and joints pain in Northern Areas of Pakistan.
               
                  Aim of the study
                  The purpose of study was to observe the preventive efficacy of roots of Ribes orientale (RO) aqueous ethanolic extract (30:70) and its aqueous and n-butanol fractions in treating rheumatoid arthritis and to determine its possible mechanism of action.
               
                  Material and methods
                  Arthritis was evaluated in vitro using heat induced bovine serum albumin and egg albumin denaturation and membrane stabilizing assays at 50–6400 μg/ml concentration of extract/fractions whereas, in vivo arthritis was evaluated at 50, 100, 200 mg/kg doses of extract/fractions in formaldehyde model by measuring rat paw volume/diameter. Moreover, highest effective dose (200 mg/kg) of extract/fractions was evaluated in Freünd complete adjuvant (FCA) model. Arthritis was induced in Sprague Dawley rats by immunization with 0.1 ml FCA in left footpad. RO extract/fractions at 200 mg/kg were orally administered from day 0, 30 min prior to adjuvant injection and sustained for 28 days. Paw volume/diameter, arthritic score, body weight, and hematological (WBC, RBC, ESR, Hb and Platelet count) and biochemical (AST, ALT, ALP, urea, creatinine, CRP and RF) parameters were observed. The mRNA expression levels of COX-2, IL-1β, IL-6, NF-kB, TNF-α, IL-4 and IL-10 were measured by real time reverse transcription polymerase chain reaction (RT-PCR) whereas, PGE2 and TNF-α levels in serum samples were measured by Enzyme linked immunosorbent assay (ELISA). Furthermore, radiographs of hind paws and histological changes in ankle joint were analyzed in adjuvant injected rats. The anti-oxidant activity of plant extract and fractions was evaluated using DPPH and reducing power assays. In addition, phytochemistry, total phenolic and flavonoid contents, and HPLC analysis of most active fraction (aqueous fraction) were performed.
               
                  Results
                  Results showed that RO extract and fractions (notably aqueous fraction) significantly reduced protein denaturation and protected erythrocyte membrane in concentration dependent manner. Similarly, extract/fractions induced dose-dependent decrease in paw volume/diameter in the formaldehyde model. Plant extract and fractions significantly suppressed paw swelling and arthritic score, prevented cachexia and remarkably ameliorated hematological and biochemical changes. Furthermore, RO extract/fractions downregulated gene expression levels of PGE2, COX-2, IL-1β, IL-6, NF-kB and TNF-α whereas, upregulated those of IL-4 and IL-10, compared with FCA control rats. The radiographic and histopathologic improvement in joint architecture was also observed in RO treated rats. Piroxicam, used as reference drug, also significantly suppressed arthritis. Additionally, plant exhibited notable anti-oxidant activity and phytochemical analysis revealed the presence of flavonoids and polyphenols.
               
                  Conclusion
                  Results indicated that suppression of pro-inflammatory enzymes/cytokines, inhibition of protein denaturation, lysosomal membrane stabilizing abilities, and redox/free radical scavenging properties of RO extract and fractions support anti-arthritic and immunomodulatory property of Ribes orientale that might be due to its polyphenolic and flavonoid constituents. This suggests that Ribes orientale roots may be used as a therapeutic agent for treating human arthritis.",science
10.1016/j.heliyon.2019.e01806,Journal,Heliyon,scopus,2019-06-01,sciencedirect,Prediction of students’ awareness level towards ICT and mobile technology in Indian and Hungarian University for the real-time: preliminary results,https://api.elsevier.com/content/abstract/scopus_id/85067313361,"An experimental study was conducted to predict the student's awareness of Information and Communication Technology (ICT) and Mobile Technology (MT) in Indian and Hungarian university's students. A primary dataset was gathered from two popular universities located in India and Hungary in the academic year 2017–2018. This paper focuses on the prediction of two major parameters from dataset such as usability and educational benefits using four machine learning classifiers multilayer perceptron (ANN), Support vector machine (SVM), K-nearest neighbor (KNN) and Discriminant (DISC). The multi-classification problem was solved with test, train and validated datasets using machine learning classifiers. One hand, feature aggregation with the train-test-validation technique improved the ANN's prediction accuracy of educational benefits for both countries. Another hand, ANN's accuracy decreases significantly in the prediction of usability. Further, SVM and ANN outperformed the KNN and the DISC in the prediction of awareness level towards ICT and MT in India and Hungary. Also, this paper reveals that the future awareness level for the educational benefits will be Very High or Moderate in both countries. Also, the awareness level is predicted as High and Moderate for usability parameter in both countries. Further, ANN and SVM accuracy and prediction time is compared with T-test at 0.05 significance level which distinguished CPU training time is taken by ANN and SVM using K-fold and Hold out method. Also, K-fold enhanced the significant prediction accuracy of SVM and ANN. the authors also used a STAC web platform to compare the accuracy datasets using T-test and ANOVA test at 0.05 significant level and we found ANN and SVM classifier has no significant difference in prediction accuracy in each dataset. Also, the authors recommend presented predictive models to be deployed as a real-time module of the institute's website for the real-time prediction of ICT & MT awareness level.",science
10.1016/j.mimet.2019.03.003,Journal,Journal of Microbiological Methods,scopus,2019-06-01,sciencedirect,A duplex quantitative real-time PCR assay for the detection and quantification of Xanthomonas phaseoli pv. dieffenbachiae from diseased and latently infected anthurium tissue,https://api.elsevier.com/content/abstract/scopus_id/85064711930,"Anthurium bacterial blight caused by Xanthomonas phaseoli pv. dieffenbachiae (formerly Xanthomonas axonopodis pv. dieffenbachiae) is the major phytosanitary threat in many anthurium growing areas worldwide. Reliable and sensitive diagnostic tools are required for surveillance and certification programs. A duplex real–time quantitative PCR assay was developed for the detection and quantification of X. phaseoli pv. dieffenbachiae from anthurium tissue. This PCR assay targeted a X. phaseoli pv. dieffenbachiae–specific gene encoding an ABC transporter and an internal control encoding for chalcone synthase in Anthurium andreanum. A cycle threshold (Ct), using a receiver-operating characteristic approach (ROC), was implemented to ensure that the declaration of a positive sample was reliable. The duplex real–time assay displayed very high performance with regards to analytical specificity (100% inclusivity, 98.9% exclusivity), analytical sensitivity (LOD95% = 894 bacteria/ml corresponding to 18 bacteria per reaction) and repeatability. We demonstrated the pertinence of this real–time quantitative PCR assay for detecting X. phaseoli pv. dieffenbachiae from diseased leaf tissue (collected from outbreaks on anthurium) and from asymptomatic, latently infected anthurium plants. This assay could be useful for surveillance, as well as for indexing propagative plant material for the presence of X. phaseoli pv. dieffenbachiae.",science
10.1016/j.asoc.2019.03.057,Journal,Applied Soft Computing Journal,scopus,2019-06-01,sciencedirect,Compression of recurrent neural networks for efficient language modeling,https://api.elsevier.com/content/abstract/scopus_id/85064251763,"Recurrent neural networks have proved to be an effective method for statistical language modeling. However, in practice their memory and run-time complexity are usually too large to be implemented in real-time offline mobile applications. In this paper we consider several compression techniques for recurrent neural networks including Long–Short Term Memory models. We make particular attention to the high-dimensional output problem caused by the very large vocabulary size. We focus on effective compression methods in the context of their exploitation on devices: pruning, quantization, and matrix decomposition approaches (low-rank factorization and tensor train decomposition, in particular). For each model we investigate the trade-off between its size, suitability for fast inference and perplexity. We propose a general pipeline for applying the most suitable methods to compress recurrent neural networks for language modeling. It has been shown in the experimental study with the Penn Treebank (PTB) dataset that the most efficient results in terms of speed and compression–perplexity balance are obtained by matrix decomposition techniques.",science
10.1016/j.schres.2019.03.027,Journal,Schizophrenia Research,scopus,2019-06-01,sciencedirect,Evidence of brain network aberration in healthy subjects with urban upbringing – A multimodal DTI and VBM study,https://api.elsevier.com/content/abstract/scopus_id/85064162040,"City living represents not only the allegory of modern life, but also – due to attractive living conditions, employment and infrastructure – a crucial reality for a growing portion of the global society. Regarding the remarkable increase of the schizophrenia incidence in individuals exposed to an urban environment during upbringing the understanding of responsible pathogenetic mechanisms is important. Schizophrenia has been conceptualized as a disorder of brain dysconnectivity. We investigated the association between urban upbringing and gray matter as well as white matter in a large sample of healthy subjects (n = 290). Voxelwise analyses revealed a strong inverse correlation of early life urbanicity and gray matter volume of the bilateral dorsolateral prefrontal cortices (DLPFC) and the right inferior parietal lobe (IPL) as well as the white matter characteristics in the left superior longitudinal fasciculus (SLF). A positive correlation was found for the gray matter volume of the left precuneus. These results may point to an altered brain development associated with urban upbringing, which not only affects single brain regions but a fronto-parietal network. Considering a DLPFC susceptibility to stress, our findings support the hypothesis of the pathogenetic role of social stress in an urban environment.",science
10.1016/j.compbiolchem.2019.03.014,Journal,Computational Biology and Chemistry,scopus,2019-06-01,sciencedirect,Discovery of perturbation gene targets via free text metadata mining in Gene Expression Omnibus,https://api.elsevier.com/content/abstract/scopus_id/85063864313,"There exists over 2.5 million publicly available gene expression samples across 101,000 data series in NCBI's Gene Expression Omnibus (GEO) database. Due to the lack of the use of standardised ontology terms in GEO's free text metadata to annotate the experimental type and sample type, this database remains difficult to harness computationally without significant manual intervention.
                  In this work, we present an interactive R/Shiny tool called GEOracle that utilises text mining and machine learning techniques to automatically identify perturbation experiments, group treatment and control samples and perform differential expression. We present applications of GEOracle to discover conserved signalling pathway target genes and identify an organ specific gene regulatory network.
                  GEOracle is effective in discovering perturbation gene targets in GEO by harnessing its free text metadata. Its effectiveness and applicability has been demonstrated by cross validation and two real-life case studies. It opens up new avenues to unlock the gene regulatory information embedded inside large biological databases such as GEO. GEOracle is available at https://github.com/VCCRI/GEOracle.",science
10.1016/j.cose.2019.02.004,Journal,Computers and Security,scopus,2019-06-01,sciencedirect,An effective security alert mechanism for real-time phishing tweet detection on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85062275871,"Phishing is a form of social engineering crime uses to deceive victims by directing them to a fraudulent website where their private and confidential information are collected for further illegal actions. Phishing attacks have now targeted users at Online Social Networks (OSN)s such as Twitter, Facebook, Myspace, etc. which traditionally, targeting email users. Twitter has become so prevalent to phishers to spread phishing attacks nowadays due to its vast information dissemination and difficult to be detected unlike email. As such, the effectiveness of security alert to prompt Twitter users for the tweet containing phishing Uniform Resource Locator (URL) in real-time is crucial. Many solutions have been proposed but their effectiveness are inadequate and doubtful. In this paper, we propose an effective security alert mechanism making use of a classification model derived from a supervised machine learning technique of Random Forest (RF) and the identified 11 best classification features yielded 94.75% accuracy higher than 94.56% yielded by other researchers who used more than 11 features trained on the same dataset collected from Twitter. To determine its effectiveness, we used 200 phishing URLs collected from Twitter and PhishTank respectively. From our experiment, we are able to justify that such proposed security alert mechanism managed to prompt 97.50% effectively the security alert to Twitter users in real-time.",science
10.1016/j.envsoft.2019.02.015,Journal,Environmental Modelling and Software,scopus,2019-06-01,sciencedirect,Building complex event processing capability for intelligent environmental monitoring,https://api.elsevier.com/content/abstract/scopus_id/85061785554,"Rapid evolution of Internet-of-Things is driving the increased deployment of smart sensors in environmental applications, contributing to many big data characteristics of environmental monitoring. Most of the current environmental monitoring systems are not designed to handle real-time datastreams, and the best practices for datastream processing and predictive analytics are yet to be established. This work presents a complex event processing (CEP) engine for detecting anomalies in real time, and demonstrates it using a series of real monitoring data from the geological carbon sequestration domain. We show that the service-based CEP engine is instrumental for enabling environmental intelligent monitoring systems to ingest heterogeneous datastreams with scalable performance. Our CEP framework requires minimal coding from the user and can be easily extended to other similar environmental monitoring applications.",science
10.1016/j.net.2018.12.020,Journal,Nuclear Engineering and Technology,scopus,2019-06-01,sciencedirect,Numerical evaluation of gamma radiation monitoring,https://api.elsevier.com/content/abstract/scopus_id/85059358720,"Airborne Gamma Ray Spectrometry (AGRS) with its important applications such as gathering radiation information of ground surface, geochemistry measuring of the abundance of Potassium, Thorium and Uranium in outer earth layer, environmental and nuclear site surveillance has a key role in the field of nuclear science and human life. The Broyden–Fletcher–Goldfarb–Shanno (BFGS), with its advanced numerical unconstrained nonlinear optimization in collaboration with Artificial Neural Networks (ANNs) provides a noteworthy opportunity for modern AGRS. In this study a new AGRS system empowered by ANN-BFGS has been proposed and evaluated on available empirical AGRS data. To that effect different architectures of adaptive ANN-BFGS were implemented for a sort of published experimental AGRS outputs. The selected approach among of various training methods, with its low iteration cost and non-diagonal scaling allocation is a new powerful algorithm for AGRS data due to its inherent stochastic properties. Experiments were performed by different architectures and trainings, the selected scheme achieved the smallest number of epochs, the minimum Mean Square Error (MSE) and the maximum performance in compare with different types of optimization strategies and algorithms. The proposed method is capable to be implemented on a cost effective and minimum electronic equipment to present its real-time process, which will let it to be used on board a light Unmanned Aerial Vehicle (UAV). The advanced adaptation properties and models of neural network, the training of stochastic process and its implementation on DSP outstands an affordable, reliable and low cost AGRS design. The main outcome of the study shows this method increases the quality of curvature information of AGRS data while cost of the algorithm is reduced in each iteration so the proposed ANN-BFGS is a trustworthy appropriate model for Gamma-ray data reconstruction and analysis based on advanced novel artificial intelligence systems.",science
10.1016/j.nima.2019.02.023,Journal,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",scopus,2019-05-21,sciencedirect,Identification of SNM based on low-resolution gamma-ray characteristics and neural network,https://api.elsevier.com/content/abstract/scopus_id/85061918595,"The risk of revealing sensitive information of nuclear weapon is an obstacle for comprehensively applying the identification technology in nuclear verification and nuclear security. In order to reduce the risk, low-resolution radiation spectra are suggested to be used in the activities of identifying special nuclear material (SNM) items’ types. In this article, we proposed an effective algorithm that extracts characteristic information from low-resolution gamma-ray spectra of SNMs and identifies the types of SNMs through backpropagation (BP) neural network and template matching method. We established the algorithm by numerical simulations, and then conducted series of experiments to verify and validate this algorithm. The identification results of applying this algorithm to real plutonium (PU) and high enriched uranium (HEU) pits showed that the proposed algorithm is an eligible option for both nuclear verification and nuclear security.",science
10.1016/j.scitotenv.2019.01.345,Journal,Science of the Total Environment,scopus,2019-05-15,sciencedirect,Different modelling approaches for predicting titanium dioxide nanoparticles mobility in intact soil media,https://api.elsevier.com/content/abstract/scopus_id/85061912312,"Understanding the transport behaviour of new and emerging materials such as engineered nanoparticles (ENPs) is vital for the accurate assessment of their functionality and fate in environmental systems. Predicting ENP mobility in soil systems based on common attributes of either soil or ENPs is of significant interest as an alternative to conducting laborious and time consuming column experiments. Thus this study investigates the importance of different soil properties and experimental conditions on titanium dioxide nanoparticles (nTiO2) mobility in real soil media and also evaluates four different modelling approaches including Multiple Linear Regression (MLR), Classification and Regression Tree (CART), Random Forest (RF) and Artificial Neural Network (ANN) for predicting nTiO2 mobility in soil media. The performance of both ANN and RF models were good for predicting nTiO2 transport in soil media, with ANN predictions being slightly superior to RF with less generalization errors. However, RF had the advantage of requiring less input predictors. In comparison the MLR model exhibited poor performance in both calibration and validation datasets, and while the validity of CART was almost acceptable in the calibration dataset, its efficiency was poor for the validation dataset. In addition to soil solution chemistry and hydraulic properties, other important factors having a major contribution to nTiO2 transport through soil included soil fracture associated properties and the existence of preferential flows.",science
10.1016/j.ecoenv.2019.01.103,Journal,Ecotoxicology and Environmental Safety,scopus,2019-05-15,sciencedirect,"Application and enantioselective residue determination of chiral pesticide penconazole in grape, tea, aquatic vegetables and soil by ultra performance liquid chromatography-tandem mass spectrometry",https://api.elsevier.com/content/abstract/scopus_id/85061190919,"Penconazole is a typical triazole fungicide with wide use on fruits, vegetables, and tea plants to control powdery mildew. In the present study, an efficient graphite carbon black solid phase extraction (GCB-SPE) purification combined with chiral ultra performance liquid chromatography tandem mass spectrometry (UPLC-MS/MS) method was developed for determination of penconazole enantiomers in different complex matrices, including grape, tea, soil, lotus root, lotus leaf, lotus seed and hulls. The method was then applied to investigate the enantioselective dissipation of penconazole enantiomers in a real field experiment of grape and soil. As a result, a satisfactory separation of penconazole enantiomers on a chiral Lux Cellulose-2 column (150 mm × 2 mm i.d., 3 µm) was obtained with 0.1% formic acid in methanol and 10 mmol L−1 ammonium acetate in water (75/25, v/v) as mobile phase at 0.25 mL min−1. The enantiomer (+)-penconazole was firstly eluted, and (-)-penconazole was then eluted. The method showed reliable performances in linearity, recovery and precision, the recoveries of (+)-penconazole and (-)-penconazole in all of six matrices were between 70.5% and 121.0% with the relative standard deviations (RSDs) ranging from 0.8% to 23.6% at the low, medium and high spiked levels. The limits of quantitation (LOQs) of this method were lower than 0.0025 mg kg−1 in grape, soil and lotus root, 0.005 mg kg−1 in lotus leaf, lotus seed meat and lotus seed shell, and 0.0125 mg kg−1 in tea. Results of field trials indicated that (-)-penconazole degraded faster than its (+)-isomer in grape. While only a moderate stereoselectivity was observed in soil, with (-)-penconazole preferential degraded. The proposed method could be used to investigate enantioselective environmental behavior of penconazole enantiomers in complex matrices. And results in this study could provide useful information on realistic risk assessment of penconazole in grape.",science
10.1016/j.elerap.2019.100837,Journal,Electronic Commerce Research and Applications,scopus,2019-05-01,sciencedirect,How to derive causal insights for digital commerce in China? A research commentary on computational social science methods,https://api.elsevier.com/content/abstract/scopus_id/85065513176,"The transformation of empirical research due to the arrival of big data analytics and data science, as well as the new availability of methods that emphasize causal inference, are moving forward at full speed. In this Research Commentary, we examine the extent to which this has the potential to influence how e-commerce research is conducted. China offers the ultimate in data-at-scale settings, and the construction of real-world natural experiments. Chinese e-commerce includes some of the largest firms involved in e-commerce, mobile commerce, social media and social networks. This article was written to encourage young faculty and doctoral students to engage in research that can be carried out in near real-time, with truly experimental or quasi-experimental research designs, and with the clear intention of establishing causal inferences that relate the precursors and drivers of observable outcomes through various kinds of processes. We discuss: the relevant data sources and research contexts; the methods perspectives that are appropriate which blend Computer Science, Statistics and Econometrics, how the research can be made relevant for China; and what kinds of findings and research directions are available. This article is not a tutorial on big data analytics methods in general though, nor does it cover just those published works that demonstrate big data methods and empirical causality in other disciplines. Instead, the empirical research covered is mostly taken from Electronic Commerce Research and Applications, which has published many articles on Chinese e-commerce. This Research Commentary invites researchers in China and the Asia Pacific region to expand their coverage to bring into their empirical work the new methods and philosophy of causal data science.",science
10.1016/j.amsu.2019.04.001,Journal,Annals of Medicine and Surgery,scopus,2019-05-01,sciencedirect,"Artificial intelligence, regenerative surgery, robotics? What is realistic for the future of surgery?",https://api.elsevier.com/content/abstract/scopus_id/85064430299,"The potential of surgery lies in the technological advances that would complement it. The landscape of the field will differ depending on the time period being looked at and would no doubt include conjecture. Initial breakthroughs will need to pave the way for future medical technology and apply to the surgical sciences. Within the next 10 years we would expect to see the emergence of big data analysis, cuttingedge image processing techniques for surgical planning and better implementation of virtual and augmented reality in operating theatres for both patient care and teaching purposes. Over the next 50 to 100 years, the use of quantum computing should lead to increased automation in our healthcare systems. The inception of novel biomaterial invention and advanced genetic engineering will usher in the new age of regenerative medicine in the clinical setting. The future of surgery includes many predictions and promises, but it is apparent that the development will lead to bettering outcome and focus on patient care.",science
10.1016/j.actbio.2019.04.004,Journal,Acta Biomaterialia,scopus,2019-05-01,sciencedirect,72-Hour in vivo evaluation of nitric oxide generating artificial lung gas exchange fibers in sheep,https://api.elsevier.com/content/abstract/scopus_id/85063997512,"The large, densely packed artificial surface area of artificial lungs results in rapid clotting and device failure. Surface generated nitric oxide (NO) can be used to reduce platelet activation and coagulation on gas exchange fibers, while not inducing patient bleeding due to its short half-life in blood. To generate NO, artificial lungs can be manufactured with PDMS hollow fibers embedded with copper nanoparticles (Cu NP) and supplied with an infusion of the NO donor S-nitroso-N-acetyl-penicillamine (SNAP). The SNAP reacts with Cu NP to generate NO. This study investigates clot formation and gas exchange performance of artificial lungs with either NO-generating Cu-PDMS or standard polymethylpentene (PMP) fibers. One miniature artificial lung (MAL) made with 10 wt% Cu-PDMS hollow fibers and one PMP control MAL were attached to sheep in parallel in a veno-venous extracorporeal membrane oxygenation circuit (n = 8). Blood flow through each device was set at 300 mL/min, and each device received a SNAP infusion of 0.12 μmol/min. The ACT was between 110 and 180 s in all cases. Blood flow resistance was calculated as a measure of clot formation on the fiber bundle. Gas exchange experiments comparing the two groups were conducted every 24 h at blood flow rates of 300 and 600 mL/min. Devices were removed once the resistance reached 3x baseline (failure) or following 72 h. All devices were imaged using scanning electron microscopy (SEM) at the inlet, outlet, and middle of the fiber bundle. The Cu-PDMS NO generating MALs had a significantly smaller increase in resistance compared to the control devices. Resistance rose from 26 ± 8 and 23 ± 5 in the control and Cu-PDMS devices, respectively, to 35 ± 8 mmHg/(mL/min) and 72 ± 23 mmHg/(mL/min) at the end of each experiment. The resistance and SEM imaging of fiber surfaces demonstrate lower clot formation on Cu-PDMS fibers. Although not statistically significant, oxygen transfer for the Cu-PDMS MALs was 13.3% less than the control at 600 mL/min blood flow rate. Future in vivo studies with larger Cu–PDMS devices are needed to define gas exchange capabilities and anticoagulant activity over a long-term study at clinically relevant ACTs.
               
                  Statement of Significance
                  In artificial lungs, the large, densely-packed blood contacting surface area of the hollow fiber bundle is critical for gas exchange but also creates rapid, surface-generated clot requiring significant anticoagulation. Monitoring of anticoagulation, thrombosis, and resultant complications has kept permanent respiratory support from becoming a clinical reality. In this study, we use a hollow fiber material that generates nitric oxide (NO) to prevent platelet activation at the blood contacting surface. This material is tested in vivo in a miniature artificial lung and compared against the clinical standard. Results indicated significantly reduced clot formation. Surface-focused anticoagulation like this should reduce complication rates and allow for permanent respiratory support by extending the functional lifespan of artificial lungs and can further be applied to other medical devices.",science
10.1016/j.engappai.2019.03.001,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-05-01,sciencedirect,Affective analytics of demonstration sites,https://api.elsevier.com/content/abstract/scopus_id/85062991999,"Multiple-criteria decision-making (MCDM) typically assumes that crowds make completely rational decisions. In MCDM, a crowd as a whole, or its individual members, generally make decisions free from any influence of valence, arousal, emotional state or environment. In contrast, various theories dealing with crowd psychology (Gustave Le Bon, Freudian, Deindividuation, Convergence, Emergent norm, Social identity) analyze, in one form or another, the emotions of the crowd. According to above theories, crowd is influenced by a range of behavioral factors, such as physical, social, psychological, culture, norms, and emotions. It can be argued that the emotional state, valence and arousal of crowds affect their decision making to a considerable degree and multiple criteria crowd behavior modeling must, therefore, consider this impact as well. In this light, the integration of crowd simulation and biometric methods, behavioral operations research and emotions in decision making has taken a prominent place as it leads to a better understanding of crowd emotions and crowd decision making. In this context, the authors developed the Affective Analytics of Demonstration Sites (ANDES) that added to this body of research in four ways. The crowd analysis and simulations conducted with ANDES used a neuro decision matrix. The matrix contains a detailed description of demonstration sites (public spaces) in question and the emotions, valence, arousal and physiological parameters of people present there. With ANDES’s Remote Sensor Network, emotional (emotions, valence, arousal) and physiological (average crowd facial temperature, crowd composition by gender and age group, etc.) parameters of people present at demonstration sites can be mapped. ANDES can assist experts in more effective implementations of public spaces planning and a participation process by attendees by collecting and examining various layers of data on the emotional and physiological parameters of visitors based on a visitors-centric public spaces planning approach. ANDES can determine the public space and real estate values.",science
10.1016/j.jad.2019.03.044,Journal,Journal of Affective Disorders,scopus,2019-05-01,sciencedirect,Short-term prediction of suicidal thoughts and behaviors in adolescents: Can recent developments in technology and computational science provide a breakthrough?,https://api.elsevier.com/content/abstract/scopus_id/85062497590,"Background
                  Suicide is one of the leading causes of death among adolescents, and developing effective methods to improve short-term prediction of suicidal thoughts and behaviors (STBs) is critical. Currently, the most robust predictors of STBs are demographic or clinical indicators that have relatively weak predictive value. However, there is an emerging literature on short-term prediction of suicide risk that has identified a number of promising candidates, including (but not limited to) rapid escalation of: (a) emotional distress, (b) social dysfunction (e.g., bullying, rejection), and (c) sleep disturbance. However, these prior studies are limited in two critical ways. First, they rely almost entirely on self-report. Second, most studies have not focused on assessment of these risk factors using intensive longitudinal assessment techniques that are able to capture the dynamics of changes in risk states at the individual level.
               
                  Method
                  In this paper we explore how to capitalize on recent developments in real-time monitoring methods and computational analysis in order to address these fundamental problems.
               
                  Results
                  We now have the capacity to use: (a) smartphone, wearable computing, and smart home technology to conduct intensive longitudinal assessments monitoring of putative risk factors with minimal participant burden and (b) modern computational techniques to develop predictive algorithms for STBs. Current research and theory on short-term risk processes for STBs, combined with the emergent capabilities of new technologies, suggest that this is an important research agenda for the future.
               
                  Limitations
                  Although these approaches have enormous potential to create new knowledge, the current empirical literature is limited. Moreover, passive monitoring of risk for STBs raises complex ethical issues that will need to be resolved before large scale clinical applications are feasible.
               
                  Conclusions
                  Smartphone, wearable, and smart home technology may provide one point of access that might facilitate both early identification and intervention implementation, and thus, represents a key area for future STB research.",science
10.1016/j.engappai.2019.02.014,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-05-01,sciencedirect,An ensemble semi-supervised learning method for predicting defaults in social lending,https://api.elsevier.com/content/abstract/scopus_id/85062467625,"Social lending is made between peers, and with the risk that the investor can take direct damages from the borrower’s failure to repay, accurate default prediction for borrowers is important. The repayment result can be known after the end of the repayment period, and such data is limited. However, social loans are matched online in real time and large amounts of unlabeled data are being generated. In this paper, we propose a method to combine label propagation and transductive support vector machine (TSVM) with Dempster–Shafer theory for accurate default prediction of social lending using unlabeled data. In order to train a lot of data effectively, we ensemble semi-supervised learning methods with different characteristics. Label propagation is performed so that data having similar features are assigned to the same class and TSVM makes moving away data having different features. Dempster–Shafer fusion method allows accurate labeling by exploiting the merits of the two methods. Experiments are performed using the open data set from Lending Club. The accuracy of the proposed method is improved by about 10% against that of the model using only labeled data, and more accurate labeling can be performed through the proposed ensemble method.",science
10.1016/j.media.2019.01.010,Journal,Medical Image Analysis,scopus,2019-05-01,sciencedirect,f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85062268629,"Obtaining expert labels in clinical imaging is difficult since exhaustive annotation is time-consuming. Furthermore, not all possibly relevant markers may be known and sufficiently well described a priori to even guide annotation. While supervised learning yields good results if expert labeled training data is available, the visual variability, and thus the vocabulary of findings, we can detect and exploit, is limited to the annotated lesions. Here, we present fast AnoGAN (f-AnoGAN), a generative adversarial network (GAN) based unsupervised learning approach capable of identifying anomalous images and image segments, that can serve as imaging biomarker candidates. We build a generative model of healthy training data, and propose and evaluate a fast mapping technique of new data to the GAN’s latent space. The mapping is based on a trained encoder, and anomalies are detected via a combined anomaly score based on the building blocks of the trained model – comprising a discriminator feature residual error and an image reconstruction error. In the experiments on optical coherence tomography data, we compare the proposed method with alternative approaches, and provide comprehensive empirical evidence that f-AnoGAN outperforms alternative approaches and yields high anomaly detection accuracy. In addition, a visual Turing test with two retina experts showed that the generated images are indistinguishable from real normal retinal OCT images. The f-AnoGAN code is available at https://github.com/tSchlegl/f-AnoGAN.",science
10.1016/j.ipm.2019.01.002,Journal,Information Processing and Management,scopus,2019-05-01,sciencedirect,Meta-Circuit machine: Inferencing human collaborative relationships in heterogeneous information networks,https://api.elsevier.com/content/abstract/scopus_id/85061123438,"Human collaborative relationship inference is a meaningful task for online social networks and is called link prediction in network science. Real-world networks contain multiple types of interacting components and can be modeled naturally as heterogeneous information networks (HINs). The current link prediction algorithms in HINs fail to effectively extract training samples from snapshots of HINs; moreover, they underutilise the differences between nodes and between meta-paths. Therefore, we propose a meta-circuit machine (MCM) that can learn and fuse node and meta-path features efficiently, and we use these features to inference the collaborative relationships in question-and-answer and bibliographic networks. We first utilise meta-circuit random walks to obtain training samples in which the basic idea is to perform biased meta-path random walks on the input and target network successively and then connect them. Then, a meta-circuit recurrent neural network (mcRNN) is designed for link prediction, which represents each node and meta-path by a dense vector and leverages an RNN to fuse the features of node sequences. Experiments on two real-world networks demonstrate the effectiveness of our framework. This study promotes the investigation of potential evolutionary mechanisms for collaborative relationships and offers practical guidance for designing more effective recommendation systems for online social networks.",science
10.1016/j.petrol.2019.01.089,Journal,Journal of Petroleum Science and Engineering,scopus,2019-05-01,sciencedirect,Predicting seismic-based risk of lost circulation using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85061035639,"Lost circulation during well drilling and completion wastes productive time, and even kills the well in severe cases. Timely identifying lost circulation events and taking countermeasures has been the focus of related study. However, a real prediction of lost circulation risk before drilling would be an active response to the challenge. In this paper, a technical solution is proposed to evaluate geological lost-circulation risk in the field using 3D seismic data attributes and machine learning technique. First, four seismic attributes (variance, attenuation, sweetness, RMS amplitude) that are the most correlated with lost circulation incidents are recommended. Then a prediction model is built by conducting supervised learning that involves a majority voting algorithm. The performance of the model is illustrated by six unseen drilled wells and shows the ability and potential to forecast lost circulation probability both along well trajectory and in the region far away from the drilled wells. The prediction resolution in the lateral and vertical direction is about 25 m and 6 m (2 ms), respectively, which are distinct advantages over the traditional description of geological structures using seismic data. It shows that the lost circulation risk can be hardly recognized by interpreting one specific seismic attribute, which is a common practice. Finally, the challenges in predicting lost circulation risk using seismic data are summarized. Overall, the study suggests that machine learning would be a practical solution to predict various construction risks that are related to seismic-based geological issues. Knowing in advance the risks, people could avoid or at least minimize the losses by optimizing well deployment in the field and taking preventive measures.",science
10.1016/j.ins.2019.01.028,Journal,Information Sciences,scopus,2019-05-01,sciencedirect,A divide and agglomerate algorithm for community detection in social networks,https://api.elsevier.com/content/abstract/scopus_id/85059953640,"Communities, or clusters, are usually subgraphs of nodes densely interconnected but sparsely linked with others. The nodes with similar properties or behaviors are more likely to be in the same community, and vice versa. However, due to the complexity and diversity of networks, the accurate organization or function of communities in many real networks is often extremely difficult to be recognized. Hence, methods for community detection would have immediate impact on understanding the organizations and functions of networks. Therefore, algorithm design becomes a fundamental problem for many networks. In this paper, the local and global information are applied together to propose a divide and agglomerate (DA) algorithm for community detection in social networks. The DA algorithm achieves the result with a two-stage strategy: Dividing a network into small groups according to node pairs’ similarities, and merging a group with the other who has the biggest attraction for it until the community criterion is steady. The novel similarity, constrained AA index captures the local and global information ensuring the optimal communities detection. The results of experiments show that DA algorithm obtains superior community results compared with six other widely used algorithms, which indicate that DA algorithm has advantages for community detection.",science
10.1016/j.ijhcs.2018.12.011,Journal,International Journal of Human Computer Studies,scopus,2019-05-01,sciencedirect,UrbanSocialRadar: A place-aware social matching model for estimating serendipitous interaction willingness in Korean cultural context,https://api.elsevier.com/content/abstract/scopus_id/85059456392,"In the era of perpetual digital connectedness, information and communication technology has significantly altered the way people communicate and interact with each other. Nonetheless, the computer-mediated communication should only complement offline communication rather than substituting it, as the resultant online ties are not as strong as face-to-face ties. In an effort to understand the motives in making offline social interactions real and ultimately to predict willingness to engage in serendipitous interactions with people encountered in a public place, we propose a place-aware social matching model driven by interpersonal factors (i.e., similarity, complementarity, and intimacy) and socio-spatial factors (i.e., place sociability, information acquisition expectancy, and perceived personal space in a place). Through a web-based social matching survey experiment (N = 1139 matches from 99 participants in Korea) based on a bogus stranger paradigm, we examine the interrelationship between those factors and the interaction willingness using a series of multiple regression analyses and build a prediction model by devising predictive features based on several machine learning models. From this, we find that both factors have statistically significant influence on interaction willingness, yet interpersonal factors have a higher relative importance than the socio-spatial factors. The interesting point is that the predictive power of these factors varies according to the place characteristics and the level of interaction willingness. We also empirically test the predictability of the model built from the controlled lab experiment through real-world experiments. The results reveal that the proposed model predicts interaction willingness in a real world with under 21% error rate within the Korean cultural context. Findings have implications for the design of mobile social networking systems that endeavor to facilitate serendipitous interactions.",science
10.1016/j.cogsys.2018.10.028,Journal,Cognitive Systems Research,scopus,2019-05-01,sciencedirect,Bioinspired decision-making for a socially interactive robot,https://api.elsevier.com/content/abstract/scopus_id/85057001839,"Nowadays, robots and humans coexist in real settings where robots need to interact autonomously making their own decisions. Many applications require that robots adapt their behavior to different users and remember each user’s preferences to engage them in the interaction. To this end, we propose a decision making system for social robots that drives their actions taking into account the user and the robot’s state. This system is based on bio-inspired concepts, such as motivations, drives and wellbeing, that facilitate the rise of natural behaviors to ease the acceptance of the robot by the users. The system has been designed to promote the human-robot interaction by using drives and motivations related with social aspects, such as the users’ satisfaction or the need of social interaction. Furthermore, the changes of state produced by the users’ exogenous actions have been modeled as transitional states that are considered when the next robot’s action has to be selected. Our system has been evaluated considering two different user profiles. In the proposed system, user’s preferences are considered and alter the homeostatic process that controls the decision making system. As a result, using reinforcement learning algorithms and considering the robot’s wellbeing as the reward function, the social robot Mini has learned from scratch two different policies of action, one for each user, that fit the users’ preferences. The robot learned behaviors that maximize its wellbeing as well as keep the users engaged in the interactions.",science
10.1016/j.eng.2018.11.027,Journal,Engineering,scopus,2019-04-01,sciencedirect,The State of the Art of Data Science and Engineering in Structural Health Monitoring,https://api.elsevier.com/content/abstract/scopus_id/85062663661,"Structural health monitoring (SHM) is a multi-discipline field that involves the automatic sensing of structural loads and response by means of a large number of sensors and instruments, followed by a diagnosis of the structural health based on the collected data. Because an SHM system implemented into a structure automatically senses, evaluates, and warns about structural conditions in real time, massive data are a significant feature of SHM. The techniques related to massive data are referred to as data science and engineering, and include acquisition techniques, transition techniques, management techniques, and processing and mining algorithms for massive data. This paper provides a brief review of the state of the art of data science and engineering in SHM as investigated by these authors, and covers the compressive sampling-based data-acquisition algorithm, the anomaly data diagnosis approach using a deep learning algorithm, crack identification approaches using computer vision techniques, and condition assessment approaches for bridges using machine learning algorithms. Future trends are discussed in the conclusion.",science
10.1016/j.resuscitation.2019.02.019,Journal,Resuscitation,scopus,2019-04-01,sciencedirect,Development of a novel cardiopulmonary resuscitation measurement tool using real-time feedback from wearable wireless instrumentation,https://api.elsevier.com/content/abstract/scopus_id/85062471861,"Aim
                  The design and implementation of a wearable training device to improve cardiopulmonary resuscitation (CPR) is presented.
               
                  Methods
                  The MYO contains both Electromyography (EMG) and Inertial Measurement Unit (IMU) sensors which are used to detect effective CPR, and the four common incorrect hand and arm positions viz. relaxed fingers; hands too low on the sternum; patient too close; or patient too far. The device determines the rate and depth of compressions calculated using a Fourier transform and dual-quaternions respectively. In addition, common positional mistakes are determined using classification algorithms (six machine learning algorithms are considered and tested). Feedback via Graphical User Interface (GUI) and audio is integrated.
               
                  Results
                  The system is tested by performing CPR on a mannequin and comparing real-time results to theoretical values. Tests show that although the classification algorithm performed well in testing (98%), in real time, it had low accuracy for certain categories (60%), which are attributable to the MYO calibration, sampling rate and misclassification of similar hand positions. Combining these similar incorrect positions into more general categories significantly improves accuracy, and produces the same improved outcome of improved CPR. The rate and depth measures have a general accuracy of 97%.
               
                  Conclusion
                  The system allows for portable, real-time feedback for use in training and in the field, and shows promise toward classifying and improving the administration of CPR.",science
10.1016/j.forsciint.2019.02.028,Journal,Forensic Science International,scopus,2019-04-01,sciencedirect,Chat Analysis Triage Tool: Differentiating contact-driven vs. fantasy-driven child sex offenders,https://api.elsevier.com/content/abstract/scopus_id/85062400557,"Investigating crimes against children, specifically sexual solicitations, are complicated because not all offenders are contact-driven, meaning they want to meet the minor for sex in the physical world; instead, some offenders are fantasy-driven, in that they are more interested in cybersex and role-play. In addition, the sheer volume of cases involving the online sexual solicitation of minors makes it difficult for law enforcement to determine whether an offender is contact-driven vs. fantasy-driven. However, research shows that there are language-based differences between minors and contact-driven offenders vs. fantasy driven-offenders. Thus, we developed the Chat Analysis Triage Tool (CATT), a forensically sound investigative tool that, based on natural language processing methods, analyzes and compares chats between minors and contact-driven vs. non-contract driven offenders. Using an SVM classifier, we were successful in differentiating the classes based on character trigrams. In a matter of seconds, the existing algorithms provide an identification of an offender’s risk level based on the likelihood of contact offending as inferred from the model, which assists law enforcement in their ability to triage and prioritize cases involving the sexual solicitation of minors.",science
10.1016/j.solener.2019.02.043,Journal,Solar Energy,scopus,2019-04-01,sciencedirect,Hybrid solar still – Liquid desiccant regenerator and water distillation system,https://api.elsevier.com/content/abstract/scopus_id/85061938809,"In 21st century, worlds’ major part is facing the challenges regarding requirement of comfort human condition as well as scarcity of potable water. The deficiency is utmost for hot and humid coastal areas. This leads to the evolution of system, which provides the solution for both sort of problems using low grade solar energy. In present study, hybrid solar still was developed with single slope for lower basin and double slope for upper basin. The performance of system was evaluated as regenerator for 33% concentrated Magnesium Chloride (MgCl2) as a pre-humidified weak liquid desiccant solution in upper basin. As a cogeneration system, lower basin was utilized as distillation system for brackish water having 0.10% concentrated Zinc Oxide (ZnO) nanoparticle with constant depth of 10 mm. ZnO nanoparticles was used to improve the heat transfer and optical characteristics of basefluid as nanoparticles have capability to enhance the thermo-physical properties. Experiment was carried out in month of March under humid climatic condition of location 20.61°N, 72.91°E. The results show that total amount of water desorbed from weak MgCl2 liquid desiccant was 1357.78 ml/m2 and distill water yield of 623.33 ml/m2. The theoretical model was developed for transient analysis and theoretical results were compared with experimental results. The theoretical concentration of regenerated strong liquid desiccant was 35.97%, whereas 34.89% concentration was obtained by Karl Fischer Titration. The hybrid solar still can provide latent cooling load of 0.161 kW/m2 with overall thermal efficiency of 19.20%.",science
10.1016/j.chb.2018.12.021,Journal,Computers in Human Behavior,scopus,2019-04-01,sciencedirect,Automatic cyberbullying detection: A systematic review,https://api.elsevier.com/content/abstract/scopus_id/85059576433,"Automatic cyberbullying detection is a task of growing interest, particularly in the Natural Language Processing and Machine Learning communities. Not only is it challenging, but it is also a relevant need given how social networks have become a vital part of individuals' lives and how dire the consequences of cyberbullying can be, especially among adolescents. In this work, we conduct an in-depth analysis of 22 studies on automatic cyberbullying detection, complemented by an experiment to validate current practices through the analysis of two datasets. Results indicated that cyberbullying is often misrepresented in the literature, leading to inaccurate systems that would have little real-world application. Criteria concerning cyberbullying definitions and other methodological concerns seem to be often dismissed. Additionally, there is no uniformity regarding the methodology to evaluate said systems and the natural imbalance of datasets remains an issue. This paper aims to direct future research on the subject towards a viewpoint that is more coherent with the definition and representation of the phenomenon, so that future systems can have a practical and impactful application. Recommendations on future works are also made.",science
10.1016/j.patcog.2018.11.021,Journal,Pattern Recognition,scopus,2019-04-01,sciencedirect,Learning from crowds with variational Gaussian processes,https://api.elsevier.com/content/abstract/scopus_id/85057800782,"Solving a supervised learning problem requires to label a training set. This task is traditionally performed by an expert, who provides a label for each sample. The proliferation of social web services (e.g., Amazon Mechanical Turk) has introduced an alternative crowdsourcing approach. Anybody with a computer can register in one of these services and label, either partially or completely, a dataset. The effort of labeling is then shared between a great number of annotators. However, this approach introduces scientifically challenging problems such as combining the unknown expertise of the annotators, handling disagreements on the annotated samples, or detecting the existence of spammer and adversarial annotators. All these problems require probabilistic sound solutions which go beyond the naive use of majority voting plus classical classification methods. In this work we introduce a new crowdsourcing model and inference procedure which trains a Gaussian Process classifier using the noisy labels provided by the annotators. Variational Bayes inference is used to estimate all unknowns. The proposed model can predict the class of new samples and assess the expertise of the involved annotators. Moreover, the Bayesian treatment allows for a solid uncertainty quantification. Since when predicting the class of a new sample we might have access to some annotations for it, we also show how our method can naturally incorporate this additional information. A comprehensive experimental section evaluates the proposed method with synthetic and real experiments, showing that it consistently outperforms other state-of-the-art crowdsourcing approaches.",science
10.1016/j.ins.2018.11.028,Journal,Information Sciences,scopus,2019-04-01,sciencedirect,Machine learning based privacy-preserving fair data trading in big data market,https://api.elsevier.com/content/abstract/scopus_id/85056879362,"In the era of big data, the produced and collected data explode due to the emerging technologies and applications that pervade everywhere in our daily lives, including internet of things applications such as smart home, smart city, smart grid, e-commerce applications and social network. Big data market can carry out efficient data trading, which provides a way to share data and further enhances the utility of data. However, to realize effective data trading in big data market, several challenges need to be resolved. The first one is to verify the data availability for a data consumer. The second is privacy of a data provider who is unwilling to reveal his real identity to the data consumer. The third is the payment fairness between a data provider and a data consumer with atomic exchange. In this paper, we address these challenges by proposing a new blockchain-based fair data trading protocol in big data market. The proposed protocol integrates ring signature, double-authentication-preventing signature and similarity learning to guarantee the availability of trading data, privacy of data providers and fairness between data providers and data consumers. We show the proposed protocol achieves the desirable security properties that a secure data trading protocol should have. The implementation results with Solidity smart contract demonstrate the validity of the proposed blockchain-based fair data trading protocol.",science
10.1016/j.ijinfomgt.2018.10.010,Journal,International Journal of Information Management,scopus,2019-04-01,sciencedirect,Modeling user preferences using neural networks and tensor factorization model,https://api.elsevier.com/content/abstract/scopus_id/85056776981,"With the expansion of information on the web, recommendation systems have become one of the most powerful resources to ease the task of users. Traditional recommendation systems (RS) suggest items based only on feedback submitted by users in form of ratings. These RS are not competent to deal with definite user preferences due to emerging and situation dependent user-generated content on social media, these situations are known as contextual dimensions. Though the relationship between contextual dimensions and user’s preferences has been demonstrated in various studies, only a few studies have explored about prioritization of varying contextual dimensions. The usage of all contextual dimensions unnecessary raises the computational complexity and negatively influences the recommendation results. Thus, the initial impetus has been made to construct a neural network in order to determine the pertinent contextual dimensions. The experiments are conducted on real-world movies data-LDOS CoMoDa dataset. The results of neural networks demonstrate that contextual dimensions have a significant effect on users’ preferences which in turn exerts an intense impact on the satisfaction level of users. Finally, tensor factorization model is employed to evaluate and validate accuracy by including neural network’s identified pertinent dimensions which are modeled as tensors. The result shows improvement in recommendation accuracy by a wider margin due to the inclusion of the pertinent dimensions in comparison to irrelevant dimensions. The theoretical and managerial implications are discussed.",science
10.1016/j.future.2018.01.054,Journal,Future Generation Computer Systems,scopus,2019-04-01,sciencedirect,Scalable distributed control plane for On-line social networks support cognitive neural computing in software defined networks,https://api.elsevier.com/content/abstract/scopus_id/85042335028,"Though most of the current proposed distributed control planes maintain strong consistency among their controllers, this paper argues the strong consistency is not a prerequisite and proposes an Event Coordination System (ECS) that enables an efficient event replaying system and a distributed control plane (DisCon) using this event replaying system to construct eventually consistent global network topologies among its controllers without sacrificing scalability. Our ECS implements a novel request handling procedure that ensures a firstly received write request is firstly multi-casted, notified, and updated, so thus our DisCon can maximally ensure the same time sequence in which topology events get updated at different controllers and the constructed topologies can reflect the real network change in practice. We highlight the major mechanisms used, discuss the major causes of this eventual consistency, estimate the inconsistency window among controllers, and show how this eventual consistency does not make a big difference in supporting network applications. Experiments are conducted to evaluate our ECS and DisCon. The results show our DisCon has a larger event replay throughput and a lower event converging delay than HyperFlow, and larger flow setup rate and lower flow setup delay than most of the current distributed control planes.",science
10.1016/j.jep.2018.12.003,Journal,Journal of Ethnopharmacology,scopus,2019-03-25,sciencedirect,Water extract of ginseng and astragalus regulates macrophage polarization and synergistically enhances DDP's anticancer effect,https://api.elsevier.com/content/abstract/scopus_id/85058223879,"Ethnopharmacological relevance
                  In traditional Chinese medicine, supplementing Qi and strengthening body resistance are an important principle of anticancer treatment. Panax ginseng C.A.Mey. (ginseng) and Astragalus membranaceus Bunge (astragalus) are the representative herbs for this therapeutic principle.
               
                  Aim of the study
                  This study aims to explore the effect of the water extract of ginseng and astragalus (WEGA) on regulating macrophage polarization and mediating anticancer in the tumor microenvironment.
               
                  Materials and methods
                  A549 cells were cultured in tumor-associated macrophage (TAM) supernatant with various concentrations of WEGA (0, 5, 10, 20 mg/mL). A549 cell proliferation was determined through methyl thiazole tetrazolium (MTT) assay and real-time cell analysis (RTCA), respectively. In vivo experiments were performed with a Lewis lung cancer (LLC) xenograft mouse model. Forty-eight mice were divided into six groups and treated with saline, WEGA, or cis-diamine dichloro platinum (DDP) with dosage of WEGA (0, 30, 60, 120 mg/kg body weight/day). The different groups were administered with drugs via oral or intraperitoneal injection once a day for 21 consecutive days. Tumor inhibition rate, spleen index, thymus index, cytokine, protein, and mRNA expression levels were detected in mice.
               
                  Results
                  In a co-culture system, WEGA remarkably inhibited A549 cell proliferation, promoted the expression of M1 macrophage markers and inhibited M2 TAMs markers. Therefore, WEGA affected the biological behavior of cancer cells by regulating the expression of some markers relevant to macrophage polarization. In addition, the group of WEGA and DDP chemotherapy effectively inhibited the transplanted tumor growth in mice and improved weight loss and immunosuppressive with the cisplatin inducing.
               
                  Conclusions
                  This study provides mechanistic insights into the anticancer effect of WEGA through the regulation of macrophage polarization and highlights that WEGA could be a novel option for integrative cancer therapies.",science
10.1016/j.ejor.2018.09.025,Journal,European Journal of Operational Research,scopus,2019-03-16,sciencedirect,Individual-level social influence identification in social media: A learning-simulation coordinated method,https://api.elsevier.com/content/abstract/scopus_id/85054743386,"This study develops a learning-simulation coordinated method to perform individual-level causal inference and social influence identification in social media. This method uses machine learning models to predict user adoption behavior, uses simulation to infer unobservable potential outcomes, and uses a counterfactual framework to identify individual-level social influence. The method also uses an adjusting strategy to reduce the effect of homophily and correlated unobservables. Empirical results obtained on a synthetic dataset and a semi-synthetic dataset show that the proposed method performs better on causal inference at the individual and aggregate levels than competitive methods. The computational experiment using a real-world database considers three applications, i.e., new product adoption, repeated purchase and cross selling. The empirical results show that the proposed method performs well on identifying influential members. The results reveal that the global hubs and local central nodes of the versatile friend circles have similar influences on the adoption behavior of the followers.",science
10.1016/j.bios.2018.12.047,Journal,Biosensors and Bioelectronics,scopus,2019-03-15,sciencedirect,Fabrication of an ultrasensitive and selective electrochemical aptasensor to detect carcinoembryonic antigen by using a new nanocomposite,https://api.elsevier.com/content/abstract/scopus_id/85060201085,"A lable-free electrochemical aptasensor was successfully developed for the sensitive detection of carcinoembryonic antigen as a tumor biomarker. To do this, a ternary nanocomposite of hemin, graphene oxide and multi-walled carbon nanotubes was used. The aptamer can be attached to the surface of a hemin, graphene oxide and multi-walled carbon nanotubes glassy carbon electrode through –NHCO- covalent bonds to form a sensing surface. Through fourier transform infrared spectroscopy and scanning electron microscopy, it was indicated that hemin can be successfully incorporated into hemin, graphene oxide and multi-walled carbon nanotubes. Hemin, which protects graphene nanosheets, also serves as an in-situ probe owing to its well-defined redox properties. Multi-walled carbon nanotubes in the modifier enhance conductivity and facilitate the electron transfer between hemin and the glassy carbon electrode. In this study, carcinoembryonic antigen got specifically bound to the aptamer, and the current changes were used for selective and specific detection of that antigen. The devised aptasensor proved to have excellent performance with a wide linear range of 1.0 × 10–15 – 1.0 × 10−8 gmL−1 and a detection limit of 0.82 fg mL−1. The inter-day and intra-day values of RSD% were obtained in the range of 0.10–2.91 and 2.21–4.56 respectively. According to the experiments conducted on real samples, it may be claimed that the proposed label-free electrochemical aptasensor is capable enough of determining carcinoembryonic antigen in clinical diagnostics.",science
10.1016/j.eswa.2018.09.045,Journal,Expert Systems with Applications,scopus,2019-03-15,sciencedirect,TCFACO: Trust-aware collaborative filtering method based on ant colony optimization,https://api.elsevier.com/content/abstract/scopus_id/85054666330,"Recommender systems (RSs) aim to help users to find relevant information based on their preferences instead of searching through extensive volume of information using search engines. Accurate prediction of unknown ratings is one of the key challenges in the analysis of RSs. Collaborative Filtering (CF) is a well-known recommendation method that estimates missing ratings by employing a set of similar users to the target user. An outstanding topic in CF is picking out an appropriate set of users and using them in the rating prediction process. In this paper, a novel CF method is proposed to predict missing ratings accurately. The proposed method called TCFACO uses trust statements as a rich side information with Ant Colony Optimization (ACO) method. TCFACO consists of three main steps. In the first step, users are ranked considering available rating values and social trust relationships. Then, in the second step, the ACO method is utilized to assign proper weight values to users to show how they are similar to the target user. A set of top similar users is filter out in the third step to be used in predicting unknown ratings for the target user. In other words, to speed up identifying similar users, the proposed method first filters out a majority part of dissimilar users and then runs the ACO on only a reduced set of users to weight them. Several experiments were performed on three real-world datasets to evaluate the effectiveness of the proposed method and the results show that the proposed method performs better than the state-of-the-art methods.",science
10.1016/j.neucom.2018.12.039,Journal,Neurocomputing,scopus,2019-03-14,sciencedirect,NPP: A neural popularity prediction model for social media content,https://api.elsevier.com/content/abstract/scopus_id/85059682308,"Online interactive behaviors between Web users often make some social media contents go viral. The popularity of social media contents can help us understand public interest and attention behind user interactions, thus popularity prediction of online contents has become a key task in social media analytics and can facilitate many applications in different domains. However, it is a difficult task for two main reasons. Firstly, popularity can be affected by many factors such as user, text content and time. Secondly, social media data is often noisy, which may degrade the performance of the prediction model. To overcome these difficulties, in this paper, we design a deep learning based popularity prediction model, which extracts and fuses the rich information of text content, user and time series in a data-driven fashion. To deal with the noise in social media data, we incorporate attention mechanism to focus on more informative parts and suppress noisy ones. Experiments on real world datasets demonstrate the effectiveness of our proposed model.",science
10.1016/j.matdes.2018.107577,Journal,Materials and Design,scopus,2019-03-05,sciencedirect,Ensemble Kalman filter-based data assimilation for three-dimensional multi-phase-field model: Estimation of anisotropic grain boundary properties,https://api.elsevier.com/content/abstract/scopus_id/85059744257,"Data assimilation (DA) has been used as a machine learning approach to estimate a system's state and the unknown parameters in its numerical model by integrating observed data into model predictions. In this paper, we propose using the DA methodology based on the ensemble Kalman filter (EnKF) to improve the accuracy of microstructure prediction using three-dimensional multi-phase-field (3D-MPF) model and estimate the model parameters simultaneously. To demonstrate the applicability of the DA methodology, we performed numerical experiments in which a priori assumed true parameters related to the grain boundary (GB) energy cusp and GB mobility peak of Σ7 coincidence site lattice GB were estimated from synthetic data of time-evolving polycrystalline microstructure. Four model parameters related to the Σ7 GB properties were successfully estimated by assimilating the synthetic microstructure data to the 3D-MPF model predictions using the EnKF-based DA method. Furthermore, we accurately reproduced the preliminarily assumed true shapes of GB energy cusp and GB mobility peak by using the estimated parameters. The results suggest that implementation of the EnKF-based DA method in the MPF model has great potential for identifying unknown material properties and estimating unmeasurable microstructure evolutions in polycrystalline materials based on real time-series 3D microstructure observation data.",science
10.1016/j.resourpol.2018.12.013,Journal,Resources Policy,scopus,2019-03-01,sciencedirect,State of the art about metaheuristics and artificial neural networks applied to open pit mining,https://api.elsevier.com/content/abstract/scopus_id/85059167765,"In search of the best way to extract and take advantage of minerals, highlighting that these are part of the most important raw materials for the economic development of today's society, the following bibliographical review is presented, which covers the main metaheuristic techniques highlighted in the optimization of mining processes and artificial neural networks (ANN), fundamental for predicting them; With this, the applications and results of these methods can be observed in mining unit operations such as: blasting, transport and mineral processing, which until now have models or techniques for their prediction that are not applicable in all mining complexes, as well as metaheuristics for three fundamental variables of open-pit planning, which are: geological uncertainty, cutting law and extraction programming. In addition to this, the proposals that have been developed in the global optimization of mining complexes are shown. There is also a brief description of how these techniques were applied to optimize the operations and previous variables of the mining planning, as well as their implementation in several mines around the world. The information shown shows available alternatives for the implementation of new actions in favor of reaching the objectives for real and hypothetical sites, yielding satisfactory results. Finally, the conclusions of this work are presented.",science
10.1016/j.fsi.2018.12.046,Journal,Fish and Shellfish Immunology,scopus,2019-03-01,sciencedirect,Molecular characterization and expression analysis of signal transducer and activator of transcription 1 (STAT1) in Japanese eel Anguilla japonica,https://api.elsevier.com/content/abstract/scopus_id/85059159927,"Signal transducer and activator of transcription 1 (STAT1) is one of critical signal transduction proteins of interferon (IFN) pathway and the structure and function of this protein have been well identified in mammals, but the information about the STAT1 is still limited in teleost fishes. In the present study, the full-length cDNA sequence of STAT1 (AjSTAT1) in Japanese eel (Anguilla japonica) was identified and characterized. Multiple alignment of the amino acid sequence showed that the AjSTAT1 protein has the typical conserved domains including the amino-terminal, coiled-coil, DNA-binding, linker, Src homology 2 (SH2), transcriptional activation domains (TAD). Quantitative real-time polymerase chain reaction (qRT-PCR) analysis revealed a broad expression for AjSTAT1 in a wide range of tissues, with the predominant expression in liver, followed by the spleen, intestine, gills, skin, kidney, and the very low expression in heart and muscle. The AjSTAT1 expressions in liver, spleen and kidney were significantly induced following injection with LPS, the viral mimic poly I:C, and Aeromonas hydrophila infection. In vitro, the AjSTAT1 transcripts of Japanese eel liver cells were significantly enhanced by the treatment of poly I:C or the stimulation of the high concentration of Aeromonas hydrophila (1 × 107 cfu/mL and 1 × 108 cfu/mL). Subcellular localization showed that in the natural state AjSTAT1was uniformly distributed in the cytoplasm, but AjSTAT1 was found to aggregated in the cytoplasm as well as partly in the nucleus after the stimulation of LPS and poly I:C. These results collectively suggested AjSTAT1 is an important transcription factor possibly involved in Japanese eel defense against viral and bacterial infection.",science
10.1016/j.jspd.2018.08.010,Journal,Spine Deformity,scopus,2019-03-01,sciencedirect,Preclinical Bench Testing on a Novel Posterior Dynamic Deformity Correction Device for Scoliosis,https://api.elsevier.com/content/abstract/scopus_id/85057624446,"Study Design
                  Biomechanical test.
               
                  Objective
                  To summarize the preclinical tests performed to assess the durability of a novel fusionless dynamic device for the treatment of adolescent idiopathic scoliosis (AIS).
               
                  Summary of Background Data
                  The minimal invasive deformity correction (MID-C) system is a distractible posterior dynamic deformity correction device designed to reduce scoliosis for AIS patients, to maintain curve correction, and to preserve spinal motion. To overcome the challenges of wear and fatigue of this procedure, the system has two unique features: polyaxial joints at the rod-screw interface and a ceramic coating of the moving parts.
               
                  Methods
                  Five biomechanical tests were performed: Static compression to failure, fatigue loading per ASTM F 1717 with 5.5-mm screws for 10 million cycles (MC) at 5 Hz, wear assessment, wear test of the polyaxial joint under 100 N load for 10 MC, and wear particle implantation in rabbits.
               
                  Results
                  The system failed through buckling of the rod with loads over 3000 N (400% of human body weight). Dynamically, the system maintained 700 N for 10 MC with 5.5 mm screws. The maximum total steady-state wear rate was 0.074 mg/MC (0.03 per polyaxial joint and 0.014 mg/MC for the ratchet mechanism). Histologic evaluation of the particle injection sites indicated no difference in the local tissue response between the control and test articles. At 3 and 6 months postinjection, there were neither adverse local effects nor systemic effects observed.
               
                  Conclusions
                  The unique design features of the MID-C system, based on polyaxial joints and ceramic coating, resulted in favorable static, fatigue, and wear resistance properties. Wear properties were superior to those published for artificial spinal discs. Long-term outcomes from clinical use will be required to correlate these bench tests to the in vivo reality of clinical use.
               
                  Level of Evidence
                  Level V.",science
10.1016/j.ress.2018.07.024,Journal,Reliability Engineering and System Safety,scopus,2019-03-01,sciencedirect,A new approach for estimating the parameters of Weibull distribution via particle swarm optimization: An application to the strengths of glass fibre data,https://api.elsevier.com/content/abstract/scopus_id/85056745362,"Three-parameter Weibull is one of the most popular and most widely-used distribution in many fields of science. Therefore, many studies have been conducted concerning the statistical inferences of the parameters of Weibull distribution. In general, the maximum likelihood (ML) methodology is used in the estimation process of unknown parameters. In this study, the ML estimation of the parameters of Weibull distribution is considered using particle swarm optimization (PSO). As in other heuristic optimization methods, the performance of PSO is affected by initial conditions. The novelty of this study comes from the fact that we propose a new adaptive search space based on confidence intervals in PSO. The modified maximum likelihood (MML) estimators are utilized for constructing the confidence intervals. MML based confidence intervals allow a narrower search space for the parameters of Weibull distribution than the search space used in the literature. Therefore, the performance of PSO increases, since the search space is wisely narrowed. In order to show the performance of the proposed approach, an extensive Monte-Carlo simulation study is conducted. Simulation results show that the proposed approach works well. In addition, real world data is analyzed to show implementation of the proposed method.",science
10.1016/j.phymed.2018.07.008,Journal,Phytomedicine,scopus,2019-03-01,sciencedirect,Lycopus lucidus Turcz. ex Benth. Attenuates free fatty acid-induced steatosis in HepG2 cells and non-alcoholic fatty liver disease in high-fat diet-induced obese mice,https://api.elsevier.com/content/abstract/scopus_id/85055876428,"Background
                  Non-alcoholic fatty liver disease (NAFLD) is closely related to metabolic diseases such as obesity and insulin resistance.
               
                  Purpose
                  We studied whether an ethanol extract of Lycopus lucidus Turcz. ex Benth (LLE) exhibited effects on lipid metabolism in NAFLD.
               
                  Study design
                  An in vitro modelwas established by treatment of HepG2 cells with a 1 mM free fatty acid (FFA) mixture (oleic acid/palmitic acid, 2:1). C57BL/6 mice were fed a high-fat diet (HFD; 60 kcal% fat) for 14 weeks to induce obesity and were treated with or without LLE (100 or 200  mg/kg daily by oral gavage).
               
                  Methods
                  HepG2 cells were exposed to 1 mM FFA, with or without LLE (250 – 1000  mg/ml). Intracellular lipid contents were measured by Oil Red O staining and a Nile Red assay. The body weight, relative liver weight, hepatic lipids, triglycerides (TGs), and total cholesterol (TC) were measured in the mice. Serum alanine aminotransferase (ALT), TG, TC, glucose, insulin, leptin, and tumor necrosis factor-alpha (TNF-α) levels were determined by biochemical or enzyme-linked immunosorbent assays. Histologic analysis was performed in the liver. Western blotting and quantitative real-time polymerase chain reaction were used to analyze the expression of key enzymes of hepatic lipid metabolism.
               
                  Results
                  LLE significantly decreased the intracellular lipid accumulation in FFA-treated HepG2 cells. LLE not only remarkably decreased the expression of lipogenesis genes but also increased β-oxidation in FFA-induced HepG2 cells. In the in vivo study, LLE treatment significantly decreased the body weight, relative liver weight, serum ALT, TC, and low-density lipoprotein cholesterol, as well as the serum glucose, insulin, leptin, and TNF-α levels in HFD-fed mice. The hepatic TG and TC contents were significantly reduced in the LLE-treated groups. Western blot analysis showed that the expression of sterol-regulatory element-binding protein 1 decreased, while that of phosphorylated AMP-activated protein kinase and peroxisome proliferator-activated receptor α increased in the LLE-treated mice.
               
                  Conclusion
                  These results suggest that LLE may exert protective effects against NAFLD-related obesity and metabolic disease.",science
10.1016/j.future.2018.02.011,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Collaborative prognostics in Social Asset Networks,https://api.elsevier.com/content/abstract/scopus_id/85042391186,"With the spread of Internet of Things (IoT) technologies, assets have acquired communication, processing and sensing capabilities. In response, the field of Asset Management has moved from fleet-wide failure models to individualised asset prognostics. Individualised models are seldom truly distributed, and often fail to capitalise the processing power of the asset fleet. This leads to hardly scalable machine learning centralised models that often must find a compromise between accuracy and computational power. In order to overcome this, we present a novel theoretical approach to collaborative prognostics within the Social Internet of Things. We introduce the concept of Social Asset Networks, defined as networks of cooperating assets with sensing, communicating and computing capabilities. In the proposed approach, the information obtained from the medium by means of sensors is synthesised into a Health Indicator, which determines the state of the asset. The Health Indicator of each asset evolves according to an equation determined by a triplet of parameters. Assets are given the form of the equation but they ignore their parametric values. To obtain these values, assets use the equation in order to perform a non-linear least squares fit of their Health Indicator data. Using these estimated parameters, they are interconnected to a subset of collaborating assets by means of a similarity metric. We show how by simply interchanging their estimates, networked assets are able to precisely determine their Health Indicator dynamics and reduce maintenance costs. This is done in real time, with no centralised library, and without the need for extensive historical data. We compare Social Asset Networks with the typical self-learning and fleet-wide approaches, and show that Social Asset Networks have a faster convergence and lower cost. This study serves as a conceptual proof for the potential of collaborative prognostics for solving maintenance problems, and can be used to justify the implementation of such a system in a real industrial fleet.",science
10.1016/j.arabjc.2017.10.006,Journal,Arabian Journal of Chemistry,scopus,2019-03-01,sciencedirect,Silica-based chelating resin bearing dual 8-Hydroxyquinoline moieties and its applications for solid phase extraction of trace metals from seawater prior to their analysis by ICP-MS,https://api.elsevier.com/content/abstract/scopus_id/85034853050,"Solid phase extraction (SPE) using chelating resins has been established as a convenient technique for samples pretreatment prior to trace metal analysis from complex matrices. Oxine chelating agents (e.g., 8-Hydroxyquinoline (8-HQ)) are popular moieties in the synthesis of chelating resins, due to their characteristic coordination chemistry. So far most of the reported silica-oxine chelators encompasses a single oxine molecule per spacer arm. In this work, two 8-HQ ligands have been covalently attached onto silica surface throughout a single linkage. The synthesized resin characterized with FTIR, elemental analysis and SEM. The main parameters affecting SPE procedures, such as pH, and sorption kinetics, investigated using batch experiments. The capacity exchange of the produced resin under optimized conditions was 0.219 and 0.161 mmol g−1 for Cu(II) and Mn(II) respectively. The resin packed into 10 ml standard cartridges and used with a typical SPE manifold for matrix removal prior to an ICP-MS analysis of transition metals (i.e., Cu, Cd, Ni, Pb, Zn, and Co) in seawater certified reference material samples and real samples from high saline seawater near the discharge zone of Yanbu desalination plant. The obtained results confirm the usefulness of the method.",science
10.1016/j.neucom.2018.11.063,Journal,Neurocomputing,scopus,2019-02-28,sciencedirect,Interval-valued data prediction via regularized artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85057866531,"The prediction of interval-valued data is a challenging task as the predicted lower bounds of intervals should not cross over the corresponding upper bounds. In this paper, a regularized artificial neural network (RANN) is proposed to address this difficult problem. It provides a flexible trade-off between prediction accuracy and interval crossing. Compared to existing hard-constrained methods, the RANN has the advantage that it does not necessarily reduce the prediction accuracy while preventing interval crossing. Extensive experiments are conducted based on both simulation and real-life datasets, with comparison to multiple traditional models, including the linear constrained center and range method, the least absolute shrinkage and selection operator-based interval-valued regression, the nonlinear interval kernel regression, the interval multi-layer perceptron and the multi-output support vector regression. Experimental results show that the proposed RANN model is an effective tool for interval-valued data prediction tasks with high prediction accuracy.",science
10.1016/j.chroma.2018.12.022,Journal,Journal of Chromatography A,scopus,2019-02-22,sciencedirect,Development of a high-throughput screening analysis for 288 drugs and poisons in human blood using Orbitrap technology with gas chromatography-high resolution accurate mass spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85059177261,"The screening analysis for drugs and poisons always symbolizes the capabilities of a forensic laboratory. Due to the rapid emergence of new compounds in clinical and forensic intoxication cases, sensitive and specific methods are necessary for the screening of wide range of target compounds. A novel high-throughput screening method has been developed for the toxicological analysis of 288 drugs and poisons in human blood using Orbitrap technology with gas chromatography-high resolution mass spectrometry (GC-HRMS). This method allows for the fast detection and identification of high-throughput forensically important drugs and poisons, e.g., drugs of abuse (cocaine, amphetamines, synthetic cannabinoids, opiates, hallucinogen), sedative-hypnotics, antidepressants, non-steroidal anti-inflammatory drugs, pesticides (acaricides, fungicides, insecticides, nematicides), and cardiovascular agents in one single GC-Q Exactive run. After a simple extraction with ethyl ether and buffer, following centrifugation, the supernatant was injected into the system. For detection, spiked blood samples were analyzed by Orbitrap-GC-HRMS using an electrospray ionization in full scan mode with a scan range from 40 to 650 (m/z). The identification of drugs and poisons in the samples was carried out by searching the accurate molecular mass of characteristic fragment ions, ion rations and retention time (RT) against the in-house library that we developed with 70 ev electron energy. The limit of detection (LOD) for most compounds (249 in a total of 288 compounds) was below 100 ng/mL. For selectivity, no substances have been identified in drug-free blood samples from six different sources, and the method was suitable for the recovery and the carryover. The coefficient of variation (CV) of the RTs was below 0.99% in all reproducibility experiments. Mass accuracy was always better than 3 ppm, corresponding to a maximum mass error of 1.04 millimass units (mmu). The developed method was applied to 136 real samples from forensic cases, demonstrating its suitability for the sensitive and fast screening of high-throughput drugs in human blood samples.",science
10.1016/j.jpba.2018.12.026,Journal,Journal of Pharmaceutical and Biomedical Analysis,scopus,2019-02-20,sciencedirect,Dansyl azide as a selective fluorescence tagging probe for click chemistry reactions and its application to monitor rasagiline in pharmacokinetic studies,https://api.elsevier.com/content/abstract/scopus_id/85058714653,"Click chemistry has been widely used for bioorthogonal labeling of biomolecules for its high efficiency, regioselectivity and biocompatibility. In this study, dansyl azide (DNS-AZ) was introduced as a novel fluorescence labeling reagent for the determination of alkynes based on copper (I)-catalyzed azide alkyne cycloaddition (CuAAC) click chemistry reaction. Rasagiline mesylate (RSM) is an irreversible, selective monoamine oxidase B (MAO-B) inhibitor. It is used as a model example for drugs with terminal alkyne moiety that could be monitored in biological samples with CuAAC reaction. RSM reacts with DNS-AZ in the presence of copper (II) and sodium ascorbate as catalysts to form stable 1,2,3-triazole derivative determined by HPLC with fluorescence detection. The developed methodology was optimized for sensitive and selective determination of RSM in rat plasma. Selegiline (SLG) was used as internal standard. The developed method was validated according to US-FDA guidelines in order to confirm method suitability for the intended application. The method allowed accurate and precise determination of RSM in the linearity range 0.50–100 ng mL−1 with a detection limit of 0.16 ng mL−1 for RSM in rat plasma. To confirm method applicability in real sample analysis, the developed method was employed to quantify RSM in a pharmacokinetic study in rats after administration of a single oral dose of RSM tablet.",science
10.1016/j.scitotenv.2018.09.394,Journal,Science of the Total Environment,scopus,2019-02-15,sciencedirect,"Impact of catalyst load, chemical oxygen demand and nitrite on disinfection and removal of contaminants during catalytic ozonation of wastewater",https://api.elsevier.com/content/abstract/scopus_id/85054758328,"Calcium-silicate mineral Polonite® and aluminum-based catalyst (AL-1010S), previously identified as promising materials for catalytic ozonation, were used as catalysts to investigate the impact of some operating conditions (ratio ozone feed concentration to catalyst load) and wastewater characteristics (chemical oxygen demand - COD and nitrite - NO2 concentration) on the disinfection and removal of contaminants of emerging concern (CECs) during catalytic ozonation of wastewater. Tests conducted in synthetic wastewater using two different ozone gas concentration (4 and 8 g (nm3)) and 6 different catalyst loads provided ratios of 0.08, 0.11, 0.16, and 0.32. Results from the experiments indicated that the ratio of 0.11 was optimal and reached residual disinfection below 2 MPN mL−1 from the initial concentration of 5 ± 2 × 105 MPN mL−1 and removal of atrazine (ATZ) above 80% from the initial concentration of 100 ± 10 μg L−1 for an ozone dose of 41–45 mg L−1. Catalytic ozonation with the selected materials enhanced disinfection and ATZ removal from synthetic wastewater (SWW) in comparison to non-catalytic ozonation by making the treatment performance less sensitive to increased chemical oxygen demand (COD) and nitrite (NO2) in the matrix. Validation of the results in real wastewater effluents confirmed that catalytic ozonation enhanced disinfection. Catalytic ozonation using Polonite® and AL-1010S provided residual bacteria level of 0.6 ± 0.42 MPN mL−1 and 0.29 ± 0.41 MPN mL−1, while non-catalytic ozonation lead to an average residual bacteria level of 1.26 ± 0.09 MPN mL−1 for the same range of transferred ozone dose. However, under the conditions tested, a limited number of CECs were extracted at levels above the limits of quantification and further validation work required to evaluate the performance of catalytic ozonation for the removal of CECs.",science
10.1016/j.oceaneng.2019.01.003,Journal,Ocean Engineering,scopus,2019-02-01,sciencedirect,Data management for structural integrity assessment of offshore wind turbine support structures: data cleansing and missing data imputation,https://api.elsevier.com/content/abstract/scopus_id/85061324147,"Structural Health Monitoring (SHM) and Condition Monitoring (CM) Systems are currently utilised to collect data from offshore wind turbines (OWTs), to enhance the accurate estimation of their operational performance. However, industry accepted practices for effectively managing the information that these systems provide have not been widely established yet. This paper presents a four-step methodological framework for the effective data management of SHM systems of OWTs and illustrates its applicability in real-time continuous data collected from three operational units, with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures. Firstly, a time-efficient synchronisation method that enables the continuous monitoring of these systems is presented, followed by a novel approach to noise cleansing and the posterior missing data imputation (MDI). By the implementation of these techniques those data-points containing excessive noise are removed from the dataset (Step 2), advanced numerical tools are employed to regenerate missing data (Step 3) and fatigue is estimated for the results of these two methodologies (Step 4). Results show that after cleansing, missing data can be imputed with an average absolute error of 2.1%, while this error is kept within the [+ 15.2%−11.0%] range in 95% of cases. Furthermore, only 0.15% of the imputed data fell outside the noise thresholds. Fatigue is found to be underestimated both, when data cleansing does not take place and when it takes place but MDI does not. This makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses.",science
10.1016/j.esd.2018.12.002,Journal,Energy for Sustainable Development,scopus,2019-02-01,sciencedirect,Identifying urban geometric types as energy performance patterns,https://api.elsevier.com/content/abstract/scopus_id/85058706592,"This paper aims to find the impact of geometric parameters on the energy performance of buildings, to using them to identify types regarding major geometric characteristics of a target area. Conventional approaches to control energy efficiency of buildings mainly focus on materials and capacity of insulation, but rarely consider urban and building geometries. By examining energy impacts on urban blocks by urban geometric forms, this paper seeks to identify urban geometric types and energy patterns on urban blocks. To achieve the aims of this study, this paper follows two steps: First, significant indicators for analyzing energy performance are identified in urban geometries; second, the types that capture urban geometry of a real city are categorized. As a result, as a reference for urban planning and design, the paper identifies 13 types that represent the characteristics of urban geometries regarding energy performance. The geometric indicators are carefully measured and their significance to energy performance of buildings is examined through regression analysis. According to these indicators, the 13 types are categorized using a hierarchical clustering algorithm, a machine learning method. Additionally, the 13 types are discussed for implementation as references in urban planning and design, particularly in block planning for a city.",science
10.1016/j.engappai.2018.10.014,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-02-01,sciencedirect,An effective Decision Support System for social media listening based on cross-source sentiment analysis models,https://api.elsevier.com/content/abstract/scopus_id/85056789877,"Nowadays, companies and enterprises are more and more incline to exploit the pervasive action of on-line social media, such as Facebook, Twitter and Instagram. Indeed, several promotional and marketing campaigns are carried out by concurrently adopting several social medial channels. These campaigns reach very quickly a wide range of different categories of users, since many people spend most of their time on on-line social media during the day.
                  In this work, a Decision Support System (DSS) is presented, which is able to efficiently support companies and enterprises in managing promotional and marketing campaigns on multiple social media channels. The proposed DSS continuously monitors multiple social channels, by collecting social media users’ comments on promotions, products, and services. Then, through the analysis of these data, the DSS estimates the reputation of brands related to specific companies and provides feedbacks about a digital marketing campaign.
                  The core of the proposed DSS is a Sentiment Analysis Engine (SAE), which is able to estimate the users’ sentiment in terms of positive, negative or neutral polarity, expressed in a comment. The SAE is based on a machine learning text classification model, which is initially trained by using real data streams coming from different social media platforms specialized in user reviews (e.g., TripAdvisor). Then, the monitoring and the sentiment classification are carried out on the comments continuously extracted from a set of public pages and channels of publicly available social networking platforms (e.g., Facebook, Twitter, and Instagram). This approach is labeled as cross-source sentiment analysis.
                  After some discussions on the design and the implementation of the proposed DSS, some results are shown about the experimentation of the proposed DSS on two scenarios, namely restaurants and consumer electronics online shops. Specifically, first the application of effective sentiment analysis models, created relying on user reviews is discussed: the models achieve accuracies higher than 90%. Then, such models are embedded into the proposed DSS. Finally, the results of a social listening campaign are presented. The campaign was carried out by fusing data streams coming from real social channels of popular companies belonging to the selected scenarios.",science
10.1016/j.cie.2018.08.018,Journal,Computers and Industrial Engineering,scopus,2019-02-01,sciencedirect,Ensemble-based big data analytics of lithofacies for automatic development of petroleum reservoirs,https://api.elsevier.com/content/abstract/scopus_id/85052098750,"Big data-driven ensemble learning is explored in this paper for quantitative geological lithofacies modeling, which is an integral and challenging part of petroleum reservoir development and characterization. Quantitative lithofacies modeling involves detection and recognition of underlying subsurface rock’s lithofacies. It requires real-time data acquisition, handling, storage, conditioning, analysis, and interpretation of raw sensory petroleum logging data. The real-time well-logs data collected from the sensor-based tools suffer from complications such as noise, nonlinearity, imbalance, and high-dimensionality which makes the prediction task more challenging. The existing literature on quantitative lithofacies modeling includes several data-driven techniques ranging from conventional well-logs to artificial intelligence (AI). Recently, multiple classifiers based Ensemble learners have been found to be more robust and reliable paradigms for detection and identification tasks in various machine learning applications, however, these are not well embraced in the petroleum industry. Ensemble methodology combines diverse expert’s opinions to obtain overall ensemble decision which in turn reduces the risk of a wrong decision. Thus, the uncertainties associated with complex reservoir data can be better handled by the use of Ensemble learners than the existing single learner based conventional models. Ensemble-based big data analytics, proposed in the paper, includes development and comparative performance testing of five popular ensemble methods (viz. Bagging, AdaBoost, Rotation forest, Random subspace, and DECORATE) for quantitative lithofacies modeling. Seven state-of-the-art base classifiers were used as members of different Ensemble learners for the analysis of Kansas (U.S.A.) oil-field data. The proposed techniques have been implemented on the widely used WEKA platform. The comparative performance analysis of the proposed techniques, presented in the paper, confirms its supremacy over the existing techniques used for quantitative lithofacies modeling.",science
10.1016/j.neucom.2017.01.119,Journal,Neurocomputing,scopus,2019-01-31,sciencedirect,Shaping graph pattern mining for financial risk,https://api.elsevier.com/content/abstract/scopus_id/85029654317,"In recent years graph pattern mining took a prominent role in knowledge discovery in many scientific fields. From Web advertising to biology and finance, graph data is ubiquitous making pattern-based graph tools increasingly important. When it comes to financial settings, data is very complex and although many successful approaches have been proposed often they neglect the intertwined economic risk factors, which seriously affects the goodness of predictions. In this paper, we posit that financial risk analysis can be leveraged if structure can be taken into account by discovering financial motifs. We look at this problem from a graph-based perspective in two ways, by considering the structure in the inputs, the graphs themselves, and by taking into account the graph embedded structure of the data. In the first, we use gBoost combined with a substructure mining algorithm. In the second, we take a subspace learning graph embedded approach. In our experiments two datasets are used: a qualitative bankruptcy data benchmark and a real-world French database of corporate companies. Furthermore, we propose a graph construction algorithm to extract graph structure from feature vector data. Finally, we empirically show that in both graph-based approaches the financial motifs are crucial for the classification, thereby enhancing the prediction results.",science
10.1016/j.neuroimage.2018.10.021,Journal,NeuroImage,scopus,2019-01-15,sciencedirect,A systematic review of the psychological factors that influence neurofeedback learning outcomes,https://api.elsevier.com/content/abstract/scopus_id/85055742001,"Real-time functional magnetic resonance imaging (fMRI)-based neurofeedback represents the latest applied behavioural neuroscience methodology developed to train participants in the self-regulation of brain regions or networks. However, as with previous biofeedback approaches which rely on electroencephalography (EEG) or related approaches such as brain-machine interface technology (BCI), individual success rates vary significantly, and some participants never learn to control their brain responses at all. Given that these approaches are often being developed for eventual use in a clinical setting (albeit there is also significant interest in using NF for neuro-enhancement in typical populations), this represents a significant hurdle which requires more research. Here we present the findings of a systematic review which focused on how psychological variables contribute to learning outcomes in fMRI-based neurofeedback. However, as this is a relatively new methodology, we also considered findings from EEG-based neurofeedback and BCI. 271 papers were found and screened through PsycINFO, psycARTICLES, Psychological and Behavioural Sciences Collection, ISI Web of Science and Medline and 21 were found to contribute towards the aim of this survey. Several main categories emerged: Attentional variables appear to be of importance to both performance and learning, motivational factors and mood have been implicated as moderate predictors of success, while personality factors have mixed findings. We conclude that future research will need to systematically manipulate psychological variables such as motivation or mood, and to define clear thresholds for a successful neurofeedback effect. Non-responders need to be targeted for interventions and tested with different neurofeedback setups to understand whether their non-response is specific or general. Also, there is a need for qualitative evidence to understand how psychological variables influence participants throughout their training. This will help us to understand the subtleties of psychological effects over time. This research will allow interventions to be developed for non-responders and better selection procedures in future to improve the efficacy of neurofeedback.",science
10.1016/B978-0-12-816176-0.00045-4,Book,Handbook of Medical Image Computing and Computer Assisted Intervention,scopus,2019-01-01,sciencedirect,Challenges in computer assisted interventions,https://api.elsevier.com/content/abstract/scopus_id/85082596227,"Challenges in design, implementation, clinical evaluation, and deployment of computer assisted intervention solutions are manifold. Some of these challenges will be discussed in this chapter.
               Computer assistance in both surgical procedures and radiology interventions aim at augmenting the clinicians with the overall objective of providing better clinical outcome. Multimodal imaging, robotics, artificial intelligence, and augmented reality play a major role in computer assisted interventions. After a brief analysis of the state-of-the-art and practice in this field, we discuss the challenges in design and development, as well as translation and deployment of the technology, from research projects motivated by clinical needs to solutions routinely used within clinical setups. We also consider the required training of surgeons and the surgical team as a major component for smooth and successful translation. We present simulation as an important tool not only for the design and development of computer assisted intervention solutions but also in their fast and smooth translation into daily practice.",science
10.1016/j.procir.2019.05.017,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,The growing path in search of an industrial design identity,https://api.elsevier.com/content/abstract/scopus_id/85076752868,"Knowing that the education system must be reinvented periodically to face the changes of social and cultural paradigm, was reviewed the pedagogical organization of a set of disciplines of an industrial design course that were in operation for a decade. Thus, in view of the objective of restructuring the disciplinary group of industrial design, a new structure has been developed and implemented that could offer students the opportunity to explore problems and challenges that have real applications, increasing the possibility of acquiring competences effectively needed to practice the profession of designer.
                  This restructuring had as its starting point the concept of Project-based learning, which is designated as student-centered pedagogy that involves a dynamic classroom approach in which it is believed that students acquire a deeper knowledge through active exploration of real-world challenges and problems. Consequently, resulting in a learning process organized into levels with increasing degree of complexity. As well, different assimilations of markets and design scenarios.
                  Starting from the first year of the course, where students are still understanding the context of industrial design and its potentialities. At a time when their techniques, principles and methods are still very raw and basic. They are initiated in a LOW-ID and local industry context, to acquire basic skills. The second year allows embark on an intermediate level called MID-ID, with new skills in international brands approach. In the last year of the course the 3rd level is reached, HIGH-ID, with projects with the national industry.
                  The first year of implementation of this curriculum structure showed good results. Thus, favoring a solid interdisciplinary formation with, skills and competences that allow future designers to intervene creatively and competently in a variety of fields. This process allows to progress to the next academic degree to complete and validate the entire formation of the student.",science
10.1016/j.procs.2019.09.224,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Hybrid system for information extraction from social media text: Drug abuse case study,https://api.elsevier.com/content/abstract/scopus_id/85076256057,"Social media are becoming widely used in the healthcare field as a patients-caregivers communication tool giving birth to new sources of information rich with the knowledge that may improve this field. Therefore, social media data analysis becomes a real business requirement for healthcare industrials and data scientists.
                  However, regarding their complexity and unstructured character, existing natural language processing tools cannot succeed their exploitation. In the literature, a wide range of approaches appeared based on dictionaries, linguistic patterns and machine learning having their strengths and weaknesses.
                  In this work, we propose a hybrid system combining the above approaches by taking the advantage of each of them to extract structured and salient drug abuse information from health-related tweets. We improve the system accuracy by real time update of the domain dictionary. We collected 1000000 tweets and we conducted different experiments showing the advantage of hybridization on efficient information extraction from social media data.",science
10.1016/j.entcs.2019.04.014,Journal,Electronic Notes in Theoretical Computer Science,scopus,2019-01-01,sciencedirect,IoT sensors in sea water environment: Ahoy! Experiences from a short summer trial,https://api.elsevier.com/content/abstract/scopus_id/85074842288,"IoT sensors for measuring various sea water parameters, are explored here, aiming towards an educational context, in order to lead to a deeper understanding of the use of aquatic environments as natural resources, and towards the adoption of environmentally friendly behaviors. Sea-water sensing via IoT has not been extensively explored, due to practical difficulties in deployment, and the same applies to devising appropriate scenaria for understanding aquatic parameters in STEM education. A short hands-on IoT sensing trial, that has been conducted in various location of the Aegean sea, is reported in this paper. This research set out to gain insight into real data sets on which to base observations for devising realistic educational scenaria pertaining aquatic parameters. The results of this experiment are meant to guide research further, by shedding light into the IoT sensing issues that are involved in an educational scientific context. The goal is conducting broader research in the area of IoT water sensing towards its further utilization in STEM education.",science
10.1016/j.entcs.2019.04.012,Journal,Electronic Notes in Theoretical Computer Science,scopus,2019-01-01,sciencedirect,An Augmented Reality Prototype for supporting IoT-based Educational Activities for Energy-efficient School Buildings,https://api.elsevier.com/content/abstract/scopus_id/85074700429,"The use of Augmented Reality (AR) technologies is currently being investigated in numerous and diverse application domains. In this work, we discuss the ways in which we are integrating AR into educational in-class activities for the GAIA project, aiming to enhance existing tools that target behavioral changes towards energy efficiency in schools. We combine real-time IoT data from a sensing infrastructure inside a fleet of school buildings with AR software running on tablets and smartphones, as companions to a set of educational lab activities aimed at promoting energy awareness in a STEM context. We also utilize this software as a means to ease access to IoT data and simplify device maintenance. We report on the design and current status of our implementation, describing functionality in the context of our target applications, while also relaying our experiences from the use of such technologies in this application domain.",science
10.1016/j.procs.2019.09.007,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Increase the interest in learning by implementing augmented reality: Case studies studying rail transportation.,https://api.elsevier.com/content/abstract/scopus_id/85073117730,"Learn a subject, for some people, might be an uninteresting and boring activity, especially when the subject to learn are difficult subjects to understand. Many methods used to change learning activities become more enjoyable and interested. This study proposed a new method in learning activities, by applied augmented reality technology in the learning process. The case study used in this paper are implementation the augmented reality in studied subjects related to train technology. In this study, author implement augmented reality on learning material, combines real and virtual things in one media, in this case a mobile device. The impact of implementation of augmented studied, at the end of experiment, author can conclude when implement augmented reality technology in learning material helps the learning process and increasing the impressive and fun factor in learning process and make the learning process more interested. Implementation of Augmented Reality in learning material gives more information about the object being studied, information about on shapes, textures, and provide more visualization for the object.",science
10.1016/j.promfg.2018.12.017,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,AI based injection molding process for consistent product quality,https://api.elsevier.com/content/abstract/scopus_id/85072584818,"In manufacturing processes, Injection Molding is widely used for producing plastic components with large lot size. So, continuous improvements in product quality consistency is crucial to maintaining a competitive edge in the injection molding industry. Various optimization techniques like ANN, GA, Iterative method, and simulation based are being used for optimization of Injection Molding process and obtaining optimal processing conditions. But still due to variation during molding cycles, quality failure occurs. As many constituents like process, Material, machine together yields product quality. This paper is focused on Real time AI based control of process parameters in injection molding cycle. Process parameters and their interrelationship with quality failure has been studied and later supposed to be used to generate algorithm for compensating the deviation of process parameters. Pressure and temperature sensor assisted monitoring system is used to collect data in real time and based on its comparison with the standard values an interrelationship is formed between parameters and plastic material properties. Algorithm generates new process parameter values to compensate the deviation and machine control follows the same. The entire process is supposed to be smart and automatic after being trained with AI and machine learning techniques. Simulation using Moldflow software and real industry collected data has been used for understanding whole molding process establishing relationship between failure and parameters. An automotive product in real industry is chosen for data acquisition, implementation and validation of entire AI based system.",science
10.1016/j.jcmgh.2019.06.001,Journal,Cellular and Molecular Gastroenterology and Hepatology,scopus,2019-01-01,sciencedirect,Single-Cell Analysis Reveals Regional Reprogramming During Adaptation to Massive Small Bowel Resection in Mice,https://api.elsevier.com/content/abstract/scopus_id/85071244865,"Background & Aims
                  The small intestine (SI) displays regionality in nutrient and immunological function. Following SI tissue loss (as occurs in short gut syndrome, or SGS), remaining SI must compensate, or “adapt”; the capacity of SI epithelium to reprogram its regional identity has not been described. Here, we apply single-cell resolution analyses to characterize molecular changes underpinning adaptation to SGS.
               
                  Methods
                  Single-cell RNA sequencing was performed on epithelial cells isolated from distal SI of mice following 50% proximal small bowel resection (SBR) vs sham surgery. Single-cell profiles were clustered based on transcriptional similarity, reconstructing differentiation events from intestinal stem cells (ISCs) through to mature enterocytes. An unsupervised computational approach to score cell identity was used to quantify changes in regional (proximal vs distal) SI identity, validated using immunofluorescence, immunohistochemistry, qPCR, western blotting, and RNA-FISH.
               
                  Results
                  Uniform Manifold Approximation and Projection-based clustering and visualization revealed differentiation trajectories from ISCs to mature enterocytes in sham and SBR. Cell identity scoring demonstrated segregation of enterocytes by regional SI identity: SBR enterocytes assumed more mature proximal identities. This was associated with significant upregulation of lipid metabolism and oxidative stress gene expression, which was validated via orthogonal analyses. Observed upstream transcriptional changes suggest retinoid metabolism and proximal transcription factor Creb3l3 drive proximalization of cell identity in response to SBR.
               
                  Conclusions
                  Adaptation to proximal SBR involves regional reprogramming of ileal enterocytes toward a proximal identity. Interventions bolstering the endogenous reprogramming capacity of SI enterocytes—conceivably by engaging the retinoid metabolism pathway—merit further investigation, as they may increase enteral feeding tolerance, and obviate intestinal failure, in SGS.",science
10.1016/j.chroma.2019.460363,Journal,Journal of Chromatography A,scopus,2019-01-01,sciencedirect,A carbon nanotube sponge as an adsorbent for vapor preconcentration of aromatic volatile organic compounds,https://api.elsevier.com/content/abstract/scopus_id/85068880467,"A carbon nanotube (CNT) sponge was synthesized and examined as an adsorptive material for a thermally desorbed preconcentrator for volatile organic compounds (VOCs). The porous sponge-like material, retaining the intrinsic properties of individual multiwalled (MW) CNTs, was fabricated using spray pyrolysis chemical vapor deposition (CVD). The square pillar form of the CNT sponge was enclosed in a 1/4″ glass tube with fittings for flow-through sampling. Flow of a direct current through the CNT sponge allowed rapid thermal heating to a surface temperature of 264.7 ℃ at a rate of 481.5 ℃/s and a narrow desorption bandwidth of 0.74 s. The preconcentration concept was validated using gas chromatographic analysis of an aromatic VOC mixture, including benzene, toluene, ethylbenzene, and o-xylene (BTEX) vapors at concentrations of 100 parts per billion (ppb). With an adsorption volume of only 100 mL, the enrichment factor of each analyte was 300 (B), 240 (T), 210 (E), and 200 (X), enabling sensitive measurements with limits of detection at the parts per trillion level. Sequential desorption experiments confirmed that a single desorption process evaporates all the analytes inside the preconcentrator with >96% efficiency. There was no humidity effect and no sign of performance degradation after continuous operation for 45 repeated cycles. These results demonstrate that CNT sponges are a suitable material for the enrichment and sensitive determination of VOCs at trace levels. Thus, CNT sponge preconcentrators are advantageous in a variety of applications that permit fast and accurate real-time measurements, including ambient air and workplace air monitoring.",science
10.1016/j.procir.2019.03.041,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,"Design, implementation and evaluation of reinforcement learning for an adaptive order dispatching in job shop manufacturing systems",https://api.elsevier.com/content/abstract/scopus_id/85068485505,"Modern production systems tend to have smaller batch sizes, a larger product variety and more complex material flow systems. Since a human oftentimes can no longer act in a sufficient manner as a decision maker under these circumstances, the demand for efficient and adaptive control systems is rising. This paper introduces a methodical approach as well as guideline for the design, implementation and evaluation of Reinforcement Learning (RL) algorithms for an adaptive order dispatching. Thereby, it addresses production engineers willing to apply RL. Moreover, a real-world use case shows the successful application of the method and remarkable results supporting real-time decision-making. These findings comprehensively illustrate and extend the knowledge on RL.",science
10.1016/j.jagp.2019.05.013,Journal,American Journal of Geriatric Psychiatry,scopus,2019-01-01,sciencedirect,A Future Research Agenda for Digital Geriatric Mental Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85067070294,"The proliferation of mobile, online, and remote monitoring technologies in digital geriatric mental health has the potential to lead to the next major breakthrough in mental health treatments. Unlike traditional mental health services, digital geriatric mental health has the benefit of serving a large number of older adults, and in many instances, does not rely on mental health clinics to offer real-time interventions. As technology increasingly becomes essential in the everyday lives of older adults with mental health conditions, these technologies will provide a fundamental service delivery strategy to support older adults’ mental health recovery. Although ample research on digital geriatric mental health is available, fundamental gaps in the scientific literature still exist. To begin to address these gaps, we propose the following recommendations for a future research agenda: 1) additional proof-of-concept studies are needed; 2) integrating engineering principles in methodologically rigorous research may help science keep pace with technology; 3) studies are needed that identify implementation issues; 4) inclusivity of people with a lived experience of a mental health condition can offer valuable perspectives and new insights; and 5) formation of a workgroup specific for digital geriatric mental health to set standards and principles for research and practice. We propose prioritizing the advancement of digital geriatric mental health research in several areas that are of great public health significance, including 1) simultaneous and integrated treatment of physical health and mental health conditions; 2) effectiveness studies that explore diagnostics and treatment of social determinants of health such as “social isolation” and “loneliness;” and 3) tailoring the development and testing of innovative strategies to minority older adult populations.",science
10.1016/j.toxrep.2019.05.002,Journal,Toxicology Reports,scopus,2019-01-01,sciencedirect,Effect of untreated pharmaceutical plant effluent on cardiac Na<sup>+</sup>-K<sup>+</sup>- ATPase and Ca<sup>2+</sup>-Mg<sup>2+</sup>-ATPase activities in mice (Mus Musculus),https://api.elsevier.com/content/abstract/scopus_id/85065627449,"Cardiovascular diseases are major causes of non-communicable diseases (NCDs)-related throughout the world. Water pollution has been linked with the high global NCD burden but no report exists on the cardiotoxicity of untreated or poorly treated pharmaceutical effluent, despite its indiscriminate discharge into the aquatic environment in Nigeria, as in many other locations of the world. Thus, this study investigated the cardiotoxic effect of oral exposure to pharmaceutical effluent in mice. Thirty (30) male mice (Mus musculus) were randomly divided into 6 groups. Group A (control) received 0.2 ml distilled water, while groups B-F were treated with 0.2 ml 2.5%, 5.0%, 10.0%, 20.0% and 40% concentrations (v/v, effluent/distilled water) of the effluent respectively, for 28 days. Significant reductions (p<0.05) in heart weight and cardiac weight index were observed in the groups treated with 5%, 10%, 20% and 40% concentrations of the effluent, without significant change in body weight. Similarly, 28 day administration of the effluent showed significant decrease in cardiac Na+-K+-ATPase activity (p<0.05) at concentrations 10% and above, in a concentration dependent manner. However, there was insignificant decrease in cardiac Ca2+-Mg2+-ATPase activity of the exposed mice, when compared with the control group. This study provides novel information on the cardiotoxic effects of oral exposure to untreated pharmaceutical effluent, showing reduced Na+-K+-ATPase activity and decreseased myocardial atrophy. Therefore, drinking water contaminated with pharmaceutical effluent may promote the incidence of cardiovascular diseases. Further studies on the exact mechanistic routes of the induced cardiotoxicity are recommended.",science
10.1016/bs.pbr.2019.03.016,Book Series,Progress in Brain Research,scopus,2019-01-01,sciencedirect,On the nature and evolution of the human mind,https://api.elsevier.com/content/abstract/scopus_id/85063761931,"Organisms are faced during their lives with an immense variety of environmental challenges and organism specific problems, for which they have to find adequate solutions in order to survive. Problem solving, in other words, is an essential dynamic survival mechanism, evolved to cope with disturbances in the ecological equilibrium. With the evolution of sensory systems as adaptations to specialized environments, the capacity to process large amounts of sensory information increased and, with that, the power to create more complex models of reality. The object of this review is to present current perspectives on the organization and evolution of the human brain and to examine some of the design principles and operational modes that underlie its information processing capacity. Furthermore, the neural correlates of mind—the set of cognitive faculties involved in perceiving, remembering, reasoning and deciding—will be explored. It will be argued that in primates, and especially humans, the complexity of the neural circuitry of the cerebral cortex is the neural correlate of higher cognitive functions, including mind-like properties and consciousness.",science
10.1016/j.procs.2019.01.012,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Combining supervised and unsupervised machine learning algorithms to predict the learners' learning styles,https://api.elsevier.com/content/abstract/scopus_id/85062675875,"The implementation of an efficient adaptive e-learning system requires the construction of an effective student model that represents the student’s characteristics, among those characteristics, there is the learning style that refers to the way in which a student prefers to learn. Knowing learning styles helps adaptive E-learning systems to improve the learning process by providing customized materials to students. In this work, we have proposed an approach to identify the learning style automatically based on the existing learners’ behaviors and using web usage mining techniques and machine learning algorithms. The web usage mining techniques were used to pre-process the log file extracted from the E-learning environment and capture the learners’ sequences. The captured learners’ sequences were given as an input to the K-modes clustering algorithm to group them into 16 learning style combinations based on the Felder and Silverman learning style model. Then the naive Bayes classifier was used to predict the learning style of a student in real time. To perform our approach, we used a real dataset extracted from an e-learning system’s log file, and in order to evaluate the performance of the used classifier, the confusion matrix method was used. The obtained results demonstrate that our approach yields excellent results.",science
10.1016/j.impact.2018.12.001,Journal,NanoImpact,scopus,2019-01-01,sciencedirect,SUNDS probabilistic human health risk assessment methodology and its application to organic pigment used in the automotive industry,https://api.elsevier.com/content/abstract/scopus_id/85058641247,"The increasing use of engineered nanomaterials (ENMs) in nano-enabled products (NEPs) has raised societal concerns about their possible health and ecological implications. To ensure a high level of human and environmental protection it is essential to properly estimate the risks of these new materials and to develop adequate risk management strategies. To this end, we propose a quantitative Human Health Risk Assessment (HHRA) methodology, which was developed in the European Seventh Framework research project SUN (Sustainable Nanotechnologies) and implemented in the web-based SUN Decision Support System (SUNDS). One of the major strengths of this probabilistic approach as compared to its deterministic alternatives is its ability to clearly communicate the uncertainties in the estimated risks in order to support better risk communication for more objective decision making by industries and regulators.
                  To demonstrate this methodology, we applied it in a real case study involving a nanoscale organic red pigment used in the automotive industry. Our analysis clearly showed that the main source of uncertainty was the extrapolation from (sub)acute in vivo toxicity data to long-term risk. This extrapolation was necessary due to a lack of (sub)chronic in vivo studies for the investigated nanomaterial. Despite the high uncertainty in the final results due to the conservative assumptions made in the risks assessment, the estimated risks are acceptable for all investigated exposure scenarios along the product lifecycle.",science
10.1016/j.chb.2018.08.048,Journal,Computers in Human Behavior,scopus,2019-01-01,sciencedirect,"Should AI-Based, conversational digital assistants employ social- or task-oriented interaction style? A task-competency and reciprocity perspective for older adults",https://api.elsevier.com/content/abstract/scopus_id/85057169443,"This study investigates whether social- versus task-oriented interaction of virtual shopping assistants differentially benefits low versus high Internet competency older consumers with respect to social (perceived interactivity, trust), cognitive (perceived information load), functional (self-efficacy, perceived ease of use, perceived usefulness), and behavioral intent (website patronage intent) outcomes in an online shopping task. A total of 121 older adults (61–89 years) participated in a laboratory experiment with a 2 (digital assistant interaction style: (social-vs. task-oriented) × 2 (user Internet competency: low vs. high) × 2 (user exchange modality: text vs. voice) between-subjects design. The results revealed that users' Internet competency and the digital assistant's conversational style had significant interaction effects on social, functional, and behavioral intent outcomes. Social-oriented digital assistants lead to superior social outcomes (enhanced perceptions of two-way interactivity and trust in the integrity of the site) for older users with high Internet competency, who need less task-related assistance. On the other hand, low-competency older users showed significantly superior cognitive (lower perceived information load) and functional outcomes (greater perceived ease and self-efficacy of using the site) when the digital assistant employed a task-oriented interaction style. Theoretical and agent design implications are discussed.",science
10.1016/j.jmsy.2018.11.005,Journal,Journal of Manufacturing Systems,scopus,2019-01-01,sciencedirect,Simulation study on reward function of reinforcement learning in gantry work cell scheduling,https://api.elsevier.com/content/abstract/scopus_id/85056893587,"In a work cell with material handling gantries, gantry movements constrain the production of the work cell. Due to the fact that the gantry real-time scheduling and the material flow are highly coupled, modeling of the gantry work cell is very challenging. In this paper, we formulate the gantry real-time scheduling problem as a reinforcement learning problem, carried out by Q-learning algorithm. To build a learning model, the definition of reward function is instrumental. To study the learning performance of Q-learning algorithm, we perform simulation experiments with five different reward functions based on different understandings of the production system. It is shown by simulation experiments that the learning performance varies with reward functions and only the reward demonstrating a better understanding of the system outperforms other reward functions. In addition, the results further validate the effectiveness and practicality of the theories and conclusions from the systematic analyses of the gantry work cell.",science
10.1016/j.asoc.2018.10.035,Journal,Applied Soft Computing Journal,scopus,2019-01-01,sciencedirect,Captured multi-label relations via joint deep supervised autoencoder,https://api.elsevier.com/content/abstract/scopus_id/85056870280,"The mapping relations learning between instances and multiple labels should reflect the underlying joint probability distribution following by the data sets. The general solution of such problem is to assume that the samples are subject to a certain distribution, i.e. normal distribution, but this hypothesis cannot excavate the real underlying mapping relations hidden in the data sets. Meanwhile, it is not advisable to suppose that multiple labels are independent of each other. Therefore, we propose the deep supervised autoencoder as a generative model to learn the posterior conditional probability rather than assigning the specific distribution in advance. In this way, we propose the different joint augmented matrices of training instances 
                        
                           
                              X
                           
                           
                              i
                           
                        
                     
 and corresponding label sets 
                        
                           
                              Y
                           
                           
                              i
                           
                        
                      under the three multi-label relations assumptions as the inputs to learn the posterior probability distribution. Finally, the experiments under model assumptions are conducted on six data sets, and we also set different noise levels to verify whether the optimal hypothesis has the ability to handle the corrupted labels. Experiments on images, biology and music real-world data sets show that our method outperforms most of state-of-the-art multi-label classifiers.",science
10.1016/j.cmpb.2018.11.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-01-01,sciencedirect,Predicting combinative drug pairs via multiple classifier system with positive samples only,https://api.elsevier.com/content/abstract/scopus_id/85056787891,"Background and Objective
                  Due to the synergistic effects of drugs, drug combination is one of the effective approaches for treating complex diseases. However, the identification of drug combinations by dose-response methods is still costly. It is promising to develop supervised learning-based approaches to predict potential drug combinations on a large scale. Nevertheless, these approaches have the inadequate utilization of heterogeneous features, which causes the loss of information useful to classification. Moreover, they have an intrinsic bias, because they assume unknown drug pairs as non-combinations, of which some could be real drug combinations in practice.
               
                  Methods
                  To address above issues, this work first designs a two-layer multiple classifier system (TLMCS) to effectively integrate heterogeneous features involving anatomical therapeutic chemical codes of drugs, drug-drug interactions, drug-target interactions, gene ontology of drug targets, and side effects. To avoid the bias caused by labelling unknown samples as negative, it then utilizes the one-class support vector machines, (which requires no negative instance and only labels approved drug combinations as positive instances), as the member classifiers in TLMCS. Last, both a 10-fold cross validation (10-CV) and a novel prediction are performed to validate the performance of TLMCS.
               
                  Results
                  The comparison with three state-of-the-art approaches under 10-CV exhibits the superiority of TLMCS, which achieves the area under the receiver operating characteristic curve = 0.824 and the area under the precision-recall curve = 0.372. Moreover, the experiment under the novel prediction demonstrates its ability, where 9 out of the top-20 predicted combinative drug pairs are validated by checking the published literature. Furthermore, for each of the newly-validated drug combinations, this work analyses the combining mode of the member drugs and investigates their relationship in terms of drug targeting pathways.
               
                  Conclusions
                  The proposed TLMCS provides an effective framework to integrate those heterogeneous features and is trained by only positive samples such that the bias of taking unknown drug pairs as negative samples can be avoided. Furthermore, its results in the novel prediction reveal five types of drug combinations and three types of drug relationships in terms of pathways.",science
10.1016/j.asoc.2018.09.027,Journal,Applied Soft Computing Journal,scopus,2019-01-01,sciencedirect,Repository and Mutation based Particle Swarm Optimization (RMPSO): A new PSO variant applied to reconstruction of Gene Regulatory Network,https://api.elsevier.com/content/abstract/scopus_id/85055896289,"Particle Swarm Optimization (PSO) is a meta-heuristic approach based on swarm intelligence, which is inspired by the social behaviour of bird flocking or fish schooling. The main disadvantage of the basic PSO is that it suffers from premature convergence. To prevent the process of search from premature convergence as well as to improve the exploration and exploitation capability as a whole, here, in this paper, a modified variant, named Repository and Mutation based PSO (RMPSO) is proposed. In RMPSO variant, apart from applying five-staged successive mutation strategies for improving the swarm best as referred in Enhanced Leader PSO (ELPSO), two extra repositories have been introduced and maintained to store personal best and global best solutions having same fitness values. In each step, the personal and global best solutions are chosen randomly from their respective repositories which enhance exploration capability further, retaining the exploitation capability. The computational experiment on benchmark problem instances shows that in most of the cases, RMPSO performs better than other algorithms in terms of the statistical metrics taken into account. Moreover, the performance of the proposed algorithm remains consistent in most of the cases when the dimension of the problem is scaled up. RMPSO is further applied to a practical scenario: the reconstruction of Gene Regulatory Networks (GRN) based on Recurrent Neural Network (RNN) model. The experimental results ensure that the RMPSO performs better than the state-of-the-art methods in the synthetic gene data set (gold standard) as well as real gene data set.",science
10.1016/j.ijbiomac.2018.10.047,Journal,International Journal of Biological Macromolecules,scopus,2019-01-01,sciencedirect,Functional characterization of two ABC transporters in Sinonovacula constricta gills and their barrier action in response to pathogen infection,https://api.elsevier.com/content/abstract/scopus_id/85054840014,"P-glycoprotein (P-gp or ABCB1) and multidrug resistance associated proteins (MRPs or ABCC) belonging to the family of ATP-binding cassette (ABC) transporters protect aquatic organisms from various toxicants and pathogen exposure. The function of ABC transporters of Sinonovacula constricta in response to pathogens was explored by cloning the complete cDNA of ABCB1 and ABCC5 of S. constricta through the rapid amplification of cDNA ends. Tissue-specific expression showed that ABCB1 and ABCC5 have the highest expression in hemocytes and gills among eight examined tissues, respectively. The transport activities of ABCB1 and ABCC5 in the gills were severely inhibited after their corresponding inhibitor treatments. The expression levels and transport activities of ABCB1 and ABCB5 were also investigated by using S. constricta samples infected by Vibrio parahaemolyticus at a final concentration of 107 CFU/mL. Results showed that the mRNA expression levels of ABCB1 and ABCC5 were significantly down-regulated when exposed to V. parahaemolyticus at 6 h and 12 h (P < 0.05) and then recovered to normal level at 24 h and 48 h. Consistently, the activities of the two ABC transporters display the same trends as the mRNA expression levels. The results, combined with that of previous investigations, indicated that these activities may be an innate immune response in S. constricta. Immunohistochemical results justified the tissue localization of P-gp in the interface between external environment and tissues. Taken together, our findings demonstrated that ABC transporters form an active, physiological barrier at the tissue–environment interface in S. constricta gills in response to pathogen infection, and they might play a vital role in adaptation and response to environmental stress and the immune defense.",science
10.1016/j.neulet.2018.07.005,Journal,Neuroscience Letters,scopus,2019-01-01,sciencedirect,The cerebellum and cognition,https://api.elsevier.com/content/abstract/scopus_id/85049808892,"What the cerebellum does to sensorimotor and vestibular control, it also does to cognition, emotion, and autonomic function. This hypothesis is based on the theories of dysmetria of thought and the universal cerebellar transform, which hold that the cerebellum maintains behavior around a homeostatic baseline, automatically, without conscious awareness, informed by implicit learning, and performed according to context. Functional topography within the cerebellum facilitates the modulation of distributed networks subserving multiple different functions. The sensorimotor cerebellum is represented in the anterior lobe with a second representation in lobule VIII, and lesions of these areas lead to the cerebellar motor syndrome of ataxia, dysmetria, dysarthria and impaired oculomotor control. The cognitive / limbic cerebellum is in the cerebellar posterior lobe, with current evidence pointing to three separate topographic representations, the nature of which remain to be determined. Posterior lobe lesions result in the cerebellar cognitive affective syndrome (CCAS), the hallmark features of which include deficits in executive function, visual spatial processing, linguistic skills and regulation of affect. The affective dyscontrol manifests in autism spectrum and psychosis spectrum disorders, and disorders of emotional control, attentional control, and social skill set. This report presents an overview of the rapidly growing field of the clinical cognitive neuroscience of the cerebellum. It commences with a brief historical background, then discusses tract tracing experiments in animal models and functional imaging observations in humans that subserve the cerebellar contribution to neurological function. Structure function correlation studies following focal cerebellar lesions in adults and children permit a finer appreciation of the functional topography and nature of the cerebellar motor syndrome, cerebellar vestibular syndrome, and the third cornerstone of clinical ataxiology – the cerebellar cognitive affective syndrome. The ability to detect the CCAS in real time in clinical neurology with a brief and validated scale should make it possible to develop a deeper understanding of the clinical consequences of cerebellar lesions in a wide range of neurological and neuropsychiatric disorders with a link to the cerebellum.",science
10.1016/j.foodchem.2018.07.072,Journal,Food Chemistry,scopus,2019-01-01,sciencedirect,Patulin removal from apple juice using a novel cysteine-functionalized metal-organic framework adsorbent,https://api.elsevier.com/content/abstract/scopus_id/85049805250,"Patulin (PAT) is one of the most common toxic contaminants of apple juice, which causes severe food safety issues throughout the apple industry. In order to remove PAT efficiently, a metal-organic framework-based adsorbent (UiO-66(NH2)@Au-Cys) was successfully synthesized and used for PAT removal from juice-pH simulation solution and real apple juice. Batch adsorption experiments were systematically performed to study the adsorption behavior for PAT. The results showed that adsorption process could be well described by the Pseudo-second order model and Freundlich isotherm model. The maximum adsorption capacity (4.38 µg/mg) was 10 times higher than the microbe-based biosorbents. Thermodynamic investigation demonstrated that adsorption process was spontaneous and endothermic. Furthermore, no marked cytotoxicity on NIH 3T3 cell lines was observed when the concentration of the adsorbent was lower than 10 μg/mL. Therefore, UiO-66(NH2)@Au-Cys is a potential adsorbent for PAT removal from apple juice with little quality changes.",science
10.1016/j.jvs.2017.10.069,Journal,Journal of Vascular Surgery,scopus,2019-01-01,sciencedirect,Optimization of rifampin coating on covered Dacron endovascular stent grafts for infected aortic aneurysms,https://api.elsevier.com/content/abstract/scopus_id/85042558741,"Objective
                  In the treatment of an infected aorta, open repair and replacement with a rifampin-impregnated Dacron vascular graft decrease the risk of prosthetic graft infections, with several protocols available in the literature. We hypothesize that the same holds true for endovascular aneurysm repair, and after studying and optimizing rifampin solution concentration and incubation period to maximize the coating process of rifampin on Dacron endovascular stent grafts (ESGs), we propose a rapid real-time perioperative protocol.
               
                  Methods
                  Several prepared rifampin solutions, including a negative control solution, were used to coat multiple triplicate sets of Dacron endovascular aortic stent grafts at different but set incubation periods. Rifampin elution from the grafts was studied by spectroscopic analysis. Once an optimized solution concentration and incubation time were determined, the elution of rifampin over time from the graft and the graft's surface characteristics were studied by ultraviolet-visible spectroscopy and atomic force microscopy.
               
                  Results
                  All coated ESGs with any concentration of prepared rifampin solution, regardless of incubation time, immediately demonstrated a visible bright orange discoloration and subsequently after elution procedures returned to the original noncolored state. At the 25-minute incubation time (standard flush), there was no statistical difference in the amount of rifampin coated to the ESGs with 10-mg/mL, 30-mg/mL, and 60-mg/mL solutions (0.06 ± 0.01, 0.07 ± 0.05, and 0.044 ± 0.01, respectively; P > .05). This was also true for a 10-minute incubation time (express flush) of 10-mg/mL and 60-mg/mL rifampin solution concentrations (0.04 ± 0.007 and 0.066 ± 0.014, respectively; P = .22). The elution-over-time of coated rifampin ESG, although not statistically significant, did seem to plateau and to reach a steady state by 50 hours and was confirmed by surface characteristics using atomic force microscopy.
               
                  Conclusions
                  Having studied two variables of rifampin coating techniques to Dacron ESGs, the authors propose a rapid real-time perioperative coating protocol by using a 10-mg/mL rifampin solution for a 10-minute incubation period. As rifampin loosely binds to Dacron ESGs by weak intermolecular forces, a rifampin-coated ESG would need to be inserted in a timely fashion to treat the diseased aorta and to deliver its antibiotic affect. A rapid perioperative coating protocol followed by immediate deployment makes our proposed technique especially useful in an urgent and unstable clinical scenario.
               
                  Clinical Relevance
                  In the treatment of an infected aorta, open repair with rifampin-impregnated vascular grafts has been described to minimize the risk of prosthetic graft infections, with several protocols available in the literature. We hypothesize that the same holds true for endovascular aneurysm repair. After studying and optimizing several variables to maximize the coating process of rifampin on Dacron endovascular stent grafts (ESGs), we propose a standardized rapid real-time perioperative protocol especially useful in an urgent and unstable clinical scenario. To further provide greater personalized patient care, future directions to ESG coating may include coating with a broader spectrum antibiotic (eg, piperacillin and tazobactam) as well as testing of antibiotic-coated ESG elution properties in vivo with animal models.",science
10.1016/j.jbiotec.2018.10.003,Journal,Journal of Biotechnology,scopus,2018-12-20,sciencedirect,Monitoring of antibody-drug conjugation reactions with UV/Vis spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85055668476,"The conjugation reaction of monoclonal antibodies (mAbs) with small-molecule drugs is a central step during production of antibody-drug conjugates (ADCs). The ability to monitor this step in real time can be advantageous for process understanding and control. Here, we propose a method based on UV/Vis spectroscopy in conjunction with partial least squares (PLS) regression for non-invasive monitoring of conjugation reactions. In experiments, the method was applied to conjugation reactions with two surrogate drugs in microplate format as well as at 20 ml scale. All calibrated PLS models performed well in cross-validation (
                        
                           Q
                           2
                        
                        >
                        0.975
                      for all models). In microplate format, the PLS models were furthermore successfully validated with an independent prediction set (
                        
                           R
                           
                              p
                              r
                              e
                              d
                           
                           2
                        
                         
                        =
                         
                        0.9770
                      resp. 0.8940). In summary, the proposed method provides a quick and easily implementable tool for reaction monitoring of ADC conjugation reactions and may in the future support the implementation of Process Analytical Technologies (PAT).",science
10.1016/j.asoc.2018.09.035,Journal,Applied Soft Computing Journal,scopus,2018-12-01,sciencedirect,Data-driven MIMO model-free reference tracking control with nonlinear state-feedback and fractional order controllers,https://api.elsevier.com/content/abstract/scopus_id/85054906128,"In this paper we suggest an extension of the Virtual Reference Feedback Tuning (VRFT) framework to nonlinear state-feedback and fractional order (FO) controllers. Theoretical analysis incentivizes the use of VRFT for tuning general nonlinear controllers to achieve model reference matching because it is expected that the more complex controller parameterization of the nonlinear-state-feedback and FO controllers leads to improved control performance. Key factors needed for successful controller tuning are discussed: good exploration of process dynamics depending on careful input excitation signal selection, the influence of the controller parameterization and the selection of the reference model. VRFT is next applied to a Multi Input-Multi Output (MIMO) nonlinear coupled vertical tank system as a case study, to tune MIMO proportional–integral (PI), fractional order-proportional–integral (FO-PI) and neural network state-feedback controllers. PI and FO-PI controllers are tuned in continuous time but implemented in discrete time to enable their real-world applications. Controllers’ complexity vs. control performance trade-off is revealed. For comparisons purposes, an original combination of VRFT and Batch Fitted Q-Learning is employed as a two-step model-free controller tuning procedure for dramatic performance improvement.",science
10.1016/j.bdq.2018.08.001,Journal,Biomolecular Detection and Quantification,scopus,2018-12-01,sciencedirect,Algorithms for automated detection of hook effect-bearing amplification curves,https://api.elsevier.com/content/abstract/scopus_id/85054887289,"Amplification curves from quantitative Real-Time PCR experiments typically exhibit a sigmoidal shape. They can roughly be divided into a ground or baseline phase, an exponential amplification phase, a linear phase and finally a plateau phase, where in the latter, the PCR product concentration no longer increases. Nevertheless, in some cases the plateau phase displays a negative trend, e.g. in hydrolysis probe assays. This cycle-to-cycle fluorescence decrease is commonly referred to in the literature as the hook effect. Other detection chemistries also exhibit this negative trend, however the underlying molecular mechanisms are different.
                  In this study we present two approaches to automatically detect hook effect-like curvatures based on linear (hookreg) and nonlinear regression (hookregNL). As the hook effect is typical for qPCR data, both algorithms can be employed for the automated identification of regular structured qPCR curves. Therefore, our algorithms streamline quality control, but can also be used for assay optimization or machine learning.",science
10.1016/j.cie.2018.10.017,Journal,Computers and Industrial Engineering,scopus,2018-12-01,sciencedirect,Two metaheuristics for solving no-wait operating room surgery scheduling problem under various resource constraints,https://api.elsevier.com/content/abstract/scopus_id/85054627915,"The problem studied in this paper is operating room surgery scheduling, with resource constraints in each of the three following stages: preoperative, intraoperative, and postoperative stages. The availability of material resources, specialties and qualifications of human resources are integrated, and the aim is to schedule surgeries while minimizing the maximum end time of last activity in stage 3 and the total idle time in the operating rooms. Two metaheuristics, an iterative local search approach and a hybrid genetic algorithm, are provided and tested on real workday instances from the literature. Computational experiments showed that our metaheuristics outperformed the current state-of-the-art solving algorithm which is an ant colony optimization. The hybrid genetic algorithm reached small superiority vs. the iterative local search algorithm. The average reduction in the end time (the total idle time) was 24% (59%) with the iterated local search approach and 24% (70%) with the hybrid genetic algorithm vs. 14% (55%) with the ant colony optimization algorithm.",science
10.1016/j.neunet.2018.09.002,Journal,Neural Networks,scopus,2018-12-01,sciencedirect,Soft + Hardwired attention: An LSTM framework for human trajectory prediction and abnormal event detection,https://api.elsevier.com/content/abstract/scopus_id/85054597180,"As humans we possess an intuitive ability for navigation which we master through years of practice; however existing approaches to model this trait for diverse tasks including monitoring pedestrian flow and detecting abnormal events have been limited by using a variety of hand-crafted features. Recent research in the area of deep-learning has demonstrated the power of learning features directly from the data; and related research in recurrent neural networks has shown exemplary results in sequence-to-sequence problems such as neural machine translation and neural image caption generation. Motivated by these approaches, we propose a novel method to predict the future motion of a pedestrian given a short history of their, and their neighbours, past behaviour. The novelty of the proposed method is the combined attention model which utilises both “soft attention” as well as “hard-wired” attention in order to map the trajectory information from the local neighbourhood to the future positions of the pedestrian of interest. We illustrate how a simple approximation of attention weights (i.e. hard-wired) can be merged together with soft attention weights in order to make our model applicable for challenging real world scenarios with hundreds of neighbours. The navigational capability of the proposed method is tested on two challenging publicly available surveillance databases where our model outperforms the current-state-of-the-art methods. Additionally, we illustrate how the proposed architecture can be directly applied for the task of abnormal event detection without handcrafting the features.",science
10.1016/j.biopha.2018.09.035,Journal,Biomedicine and Pharmacotherapy,scopus,2018-12-01,sciencedirect,SRT1720 ameliorates sodium taurocholate-induced severe acute pancreatitis in rats by suppressing NF-κB signalling,https://api.elsevier.com/content/abstract/scopus_id/85053186406,"Severe acute pancreatitis (SAP) is a medical emergency that is often associated with multiple organ failure and high mortality. Although an SAP diagnosis requires prompt treatment, therapeutic options remain limited. SRT1720 is a newly formulatedSIRT1 activator that exerts multiple pharmacological activities with beneficial health effects. However, its potential as an SAP treatment has not been explored. The current study assessed the effect of SRT1720 on a rat model of sodium taurocholate-induced SAP and explored the underlying mechanism. SAP was induced in rats by retrograde injection of a 3.5% sodium taurocholate solution (1 ml/kg) in the biliopancreatic duct. SRT1720 (5 mg/kg) was administered intraperitoneally after sodium taurocholate exposure. Serum samples were analysed for inflammatory cytokine levels and select enzymatic activities using the enzyme-linked immunosorbent assay and commercial enzyme activity assay kits, respectively; protein expression levels were evaluated by western blotting; mRNA levels of biomarkers were determined by quantitative real-time PCR; histopathological changes were analysed by haematoxylin and eosin staining and immunohistochemistry.SRT1720 treatment significantly reduced serum amylase, lipase, pancreatic histological scores, proinflammatory cytokine (TNF-α and IL-6) levels, and expression of NF-κB and p65 in sodium taurocholate-induced SAP rats. Importantly, the treatment stimulated SIRT1 and IκBα levels in pancreatic tissue. Our data suggest that SRT1720 protects rats from sodium taurocholate-induced SAP by suppressing the NF-κB signalling pathway.",science
10.1016/j.cogsys.2018.07.033,Journal,Cognitive Systems Research,scopus,2018-12-01,sciencedirect,From physics to social interactions: Scientific unification via dynamics,https://api.elsevier.com/content/abstract/scopus_id/85052431714,"The principle of dynamical similitude—the belief that the same behavior may be exhibited by very different systems—allows us to use mathematical models from physics to understand psychological phenomena. Sometimes, model choice is straightforward. For example, the two-frequency resonance map can be used to make predictions about the performance of multifrequency ratios in physical, chemical, physiological and social behavior. Sometimes, we have to dig deeper into our dynamical toolbox to select an appropriate technique. An overview is provided of other methods, including mass-spring modeling and multifractal analysis, that have been applied successfully to various psychological phenomena. A final demonstration of dynamical similitude comes from the use of the same multifractal method that was used to extract team-level experience from the neurophysiological data of individual team members to the analysis of a large scale economic phenomenon, the stock market index. Continual development of analytical methods that are informed by and can be applied to other sciences allows us to treat psychological phenomena as continuous with the rest of the natural world.",science
10.1016/j.future.2018.07.013,Journal,Future Generation Computer Systems,scopus,2018-12-01,sciencedirect,Using behavioral features in tablet-based auditory emotion recognition studies,https://api.elsevier.com/content/abstract/scopus_id/85050510126,"The recognition of emotions in spoken words is one of the most important aspects in human communication and social relationships. Traditional approaches to the study of vocal emotional recognition involve instructing listeners to choose which one of several words describing emotion categories best characterize linguistically neutral utterances or vocalizations uttered by actors portraying various emotional states. To this end, generic experiment control software is usually used, which has some disadvantages. In this paper, we present a system that digitalizes the whole process involved in understanding how people perceive and understand vocal emotions, improving data collection, processing and analysis. Moreover, this system provides a new group of features that allows a more comprehensive characterization of the behavioral dimension underlying vocal emotional recognition. In this paper we describe this system and analyze the relationship between emotional perception, gender, age and Human–Computer Interaction.",science
10.1016/j.future.2018.06.044,Journal,Future Generation Computer Systems,scopus,2018-12-01,sciencedirect,AIEM: AI-enabled affective experience management,https://api.elsevier.com/content/abstract/scopus_id/85050100370,"Nowadays, with rapid development of artificial intelligence technology, the emerging human–machine interaction application researches grow up with machine intelligence, cognitive science and CEM (Customer Experience Management). This paper puts forward a new AIEM (AI-enabled affective experience management) method, blends AI and CEM in the emotion recognition and interactive intelligence application. Besides, in order to create good user experience, AIEM method also strives for the intelligence at various phases of emotion acquisition, emotion recognition, and emotion interaction. This paper introduces the composition and architecture of AIEM from three aspects, i.e. intelligent management of emotion data collection, accuracy management of emotion recognition, and real-time management of emotion interaction. Then we use advanced algorithm and model in two phases of emotion recognition algorithm and emotion computing offloading. Moreover, we select two deep learning algorithms (VGG-Net and Alex-Net) for facial expression recognition and speech emotion recognition, respectively. In the experiment using AIWAC system in real environment, we evaluate the emotion interaction delay in different computing nodes (Cloud and Edge) using AIEM method. Experiment results show that our method can provide intuitive and reasonable user experience management, and select suitable computing nodes for users. Finally, we provide summary and prospect for the future research proposal.",science
10.1016/j.eswa.2018.06.026,Journal,Expert Systems with Applications,scopus,2018-12-01,sciencedirect,To regularize or not: Revisiting SGD with simple algorithms and experimental studies,https://api.elsevier.com/content/abstract/scopus_id/85048555566,"Stochastic Gradient Descent (SGD) is one of the most popular first-order methods to solve optimization problems in large-scale, which has also been widely studied in intelligence system, deep neural networks, or machine learning. In this paper we set out to revisit SGD with practical concerns in mind and hope to provide intuition on how SGD should be done in the right way in applications for expert and intelligence systems.
                  In literature, when implementing SGD, regularization is often added to the loss function, to avoid ill-conditioning or overfitting, or to obtain solutions with desirable sparse structure. Intuitively, regularized loss function deviates from the true loss and in this case SGD may lead to a suboptimal solution. In this paper we revisit the matter of l
                     2 regularization for SGD, to investigate whether or when an explicit regularizer is necessary to obtain the desirable performance. We further introduce a simple stochastic algorithm (ASG) using the accumulated stochastic gradient of the un-regularized loss. Then experiments are carried out on benchmark data sets to validate the theoretical analysis.
                  The findings show that for l
                     2 regularization, (1) SGD without explicit regularizing (SGDE) actually possesses an implicit regularizer, and in the sense of upper bound of the convergence rate, it outperforms SGD regularized explicitly (SGDER) with a constant advantage; (2) ASG without explicit regularizing outperforms both SGDE and SGDER, especially in the case where the number of iteration T cannot be pre-specified; (3) for SGD algorithms, the schemes that places flexible weight on the output of the latest iteration can give a better trade-off, compared with the scheme using the output of the last iteration or taking the average of the output of each iteration, and this suggests that in application a tunable averaging scheme is preferable.
                  This study provides insights on using SGD algorithms for big data applications, e.g., to accelerate SVMs or regularized regression in large-scale, or to improve the performance of online learning or real time forecasting (control). In particular, when T is pre-specified, SGDE (without an explicit regularizer) can give us a well enough perforce with simplicity and understandability; when T cannot be pre-specified, ASG can improve the performance of standard SGD algorithms.",science
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science
10.1016/j.bios.2018.07.073,Journal,Biosensors and Bioelectronics,scopus,2018-11-15,sciencedirect,Aptasensor designed via the stochastic tunneling-basin hopping method for biosensing of vascular endothelial growth factor,https://api.elsevier.com/content/abstract/scopus_id/85051118731,"The Systematic Evolution Ligands by Exponential Enrichment (SELEX) is common used for selection of high affinity single-stranded DNA (ssDNA) aptamer with target protein. However, we do not know what the most stable configuration of the selected aptamer bound with target protein is. Therefore, a systematic search process using the stochastic tunneling-basin hopping (STUN-BH) method is proposed to find the most stable configuration of the ssDNA aptamer specific for vascular endothelial growth factor (VEGF) capture (AptVEGF; 5′-TGTGGGGGTGGACGGGCCGGGTAGA-3′). After the most stable configuration was obtained by the STUN-BH method, molecular dynamics (MD) simulation was carried out to investigate the thermal stability of AptVEGF/VEGF at 300 K in both vacuum and water. All molecular simulations were conducted with the large-scale atomic/molecular massively parallel simulator (LAMMPS), and the AMBER99SB force field was used to describe the atomic interactions for the current AptVEGF/VEGF system. The three most stable AptVEGF/VEGF configurations obtained by the STUN-BH method indicated that AptVEGF residues exhibit greater affinity for VEGF surface loop fragments as compared with surface alpha helix and beta sheet fragments. Results indicated that after the first AptVEGF (AptVEGF I) occupies most of the VEGF loop fragment, the second AptVEGF (AptVEGF II) is adsorbed by the rest of the VEGF loop fragment and the VEGF Chain B beta sheet fragment, resulting in a 24.8% reduction in binding strength as compared to that of AptVEGF I. Furthermore, when AptVEGF I and AptVEGF II chains were stably adsorbed by VEGF, the third AptVEGF (AptVEGF III) chain can only partially attach to VEGF, as confirmed by real AptVEGF-VEGF binding experiments. Lastly, we demonstrated that the aptasensor constructed according to MD simulation is highly sensitive for VEGF with a linear detection range of 10 pg/mL–10 ng/mL.",science
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science
10.1016/j.neuron.2018.08.043,Journal,Neuron,scopus,2018-11-07,sciencedirect,Distinct and Dynamic ON and OFF Neural Ensembles in the Prefrontal Cortex Code Social Exploration,https://api.elsevier.com/content/abstract/scopus_id/85055983211,"The medial prefrontal cortex (mPFC) is important for social behavior, but the mechanisms by which mPFC neurons code real-time social exploration remain largely unknown. Here we utilized miniScopes to record calcium activities from hundreds of excitatory neurons in the mPFC while mice freely explored restrained social targets in the absence or presence of the psychedelic drug phencyclidine (PCP). We identified distinct and dynamic ON and OFF neural ensembles that displayed opposing activities to code real-time behavioral information. We further illustrated that ON and OFF ensembles tuned to social exploration carried information of salience and novelty for social targets. Finally, we showed that dysfunctions in these ensembles were associated with abnormal social exploration elicited by PCP. Our findings underscore the importance of mPFC ON and OFF neural ensembles for proper exploratory behavior, including social exploration, and pave the way for future studies elucidating neural circuit dysfunctions in psychiatric disorders.",science
10.1016/j.ces.2018.05.037,Journal,Chemical Engineering Science,scopus,2018-11-02,sciencedirect,The soft sensor of the molten steel temperature using the modified maximum entropy based pruned bootstrap feature subsets ensemble method,https://api.elsevier.com/content/abstract/scopus_id/85048325503,"The molten steel temperature in ladle furnace is a significant variable, but it is hard to be measured by real-time detection, which has some bad effects on productions. Soft sensors are alternative and effective techniques to solve this issue. In this paper, the soft sensor of the molten steel temperature established by the Modified Maximum Entropy based Pruned Bootstrap Feature Subsets Ensemble (MMEP-BFSE) method is proposed. Although the Bootstrap Feature Subsets Ensemble (BFSE) temperature model is prominent in the precision and the forecasting speed on the large-scale and noisy data, its main drawback is too many sub-models required to combine, which is not always feasible for applications. To alleviate this drawback, the Modified Maximum Entropy based Pruning (MMEP) approach is presented, in which a subset of sub-models that better approximates the complete ensemble is find based on the maximum Rényi entropy and the trade-off parameter between the precision and the diversity of sub-models. Then, the soft sensor of the temperature based on the MMEP-BFSE is established on the practical data. Experiments show that the proposed soft sensor outperforms the others in the precision, and meets the precision requirements. Sub-models of the BFSE temperature model are substantially pruned with improved generalization by the MMEP approach.",science
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science
10.1016/j.ecoinf.2018.09.001,Journal,Ecological Informatics,scopus,2018-11-01,sciencedirect,Real-world plant species identification based on deep convolutional neural networks and visual attention,https://api.elsevier.com/content/abstract/scopus_id/85053339956,"This paper investigates the issue of real-world identification to fulfill better species protection. We focus on plant species identification as it is a classic and hot issue. In tradition plant species identification the samples are scanned specimen and the background is simple. However, real-world species recognition is more challenging. We first systematically investigate what is realistic species recognition and the difference from tradition plant species recognition. To deal with the challenging task, an interdisciplinary collaboration is presented based on the latest advances in computer science and technology. We propose a novel framework and an effective data augmentation method for deep learning in this paper. We first crop the image in terms of visual attention before general recognition. Besides, we apply it as a data augmentation method. We call the novel data augmentation approach attention cropping (AC). Deep convolutional neural networks are trained to predict species from a large amount of data. Extensive experiments on traditional dataset and specific dataset for real-world recognition are conducted to evaluate the performance of our approach. Experiments first demonstrate that our approach achieves state-of-the-art results on different types of datasets. Besides, we also evaluate the performance of data augmentation method AC. Results show that AC provides superior performance. Compared with the precision of methods without AC, the results with AC achieve substantial improvement.",science
10.1016/j.measurement.2018.05.099,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-11-01,sciencedirect,Parallel three-dimensional electrical capacitance data imaging using a nonlinear inversion algorithm and L<sup>p</sup> norm-based model regularization,https://api.elsevier.com/content/abstract/scopus_id/85049483981,"In order to improve image reconstructions, different classes of nonlinear inversion algorithms are developed and used in different research topics like imaging processes in oil industry or the characterization of complex porous media or multiphase flows. These algorithms are able to avoid local minima and to reach more adapted minima of a given misfit function between observed/measured and computed data. Techniques as different as electrical, ultrasound or potential methods, are used. We present here a nonlinear algorithm that allows us to produce permittivity images by using electrical capacitance tomography (ECT). ECT is a non-invasive technique to image non-conductive permittivity distributions and is used in many oil industry imaging applications such as multiphase flows in pipelines, fluidized bed reactors, mixing vessels, and tanks of phase separation. Even if the ECT technique provides low resolution reconstructions, it is cheap, robust and very fast when compared to other imaging tools. In this method one or more rings of electrodes excite a medium to be imaged at high frequencies, and more particularly at frequencies for which a static electrical potential field has fully developed. In many studies of other research groups only one ring of sources is introduced but the reconstruction accuracy was not totally satisfactory due to the 3D nature of the problem to be solved. Instead of using nonlinear stochastic algorithms like the simulated annealing (SA) technique that we optimized in previous studies to image permittivity distributions of granular or solid materials as well as real oil–gas or two-phase flows in 2D cylindrical vessel configurations, we propose here a new ECT inversion tool to image permittivities in a 3D cylindrical configuration. 3D stochastic optimization methods such as SA, neural networks, genetic algorithms can become computationally too prohibitive, and classical local or linear inversion methods excessively smooth images in many cases. Therefore, we propose here a 3D parallel inversion procedure with different numbers of rings and different 
                        
                           
                              
                                 L
                              
                              
                                 p
                              
                           
                        
                      norms, with
                        
                           1
                           <
                           p
                           ⩽
                           2
                        
                     , applied to the model regularization of the misfit function to increase the resolution of the models after inversion. We are able to better reconstruct two-phase and three-phase (oil, gas and solids) mixtures by combining 
                        
                           
                              
                                 L
                              
                              
                                 p
                              
                           
                        
                     -norm regularizations of the misfit function to minimize and several rings of electrodes. All these algorithms have been implemented in a more general parallel framework TOMOFAST-X designed for multi-physics joint inversion purposes, and could also be used in other fields of research such as larger-scale geophysical exploration for instance.",science
10.1016/j.snb.2018.05.141,Journal,"Sensors and Actuators, B: Chemical",scopus,2018-11-01,sciencedirect,A high sensitivity bead-based immunoassay with nanofluidic preconcentration for biomarker detection,https://api.elsevier.com/content/abstract/scopus_id/85048573340,"In this study, we developed a rapid biomarker sensor with a high sensitivity and high selectivity by applying a bead-based immunosensing technique in a nanofluidic preconcentration device. Antibody-coated 300-nm beads and antigens were mixed and then pumped into a valve-integrated nanofluidic preconcentration device for collection and trapping. Because of size differences between the molecules and 300-nm beads, the antigen (molecule) in the mixed solution could be concentrated by up to 10,000-fold in 2 min, but the nanobeads could not be thus concentrated. After concentrated antigens and antibody-coated nanobeads were isolated, micro-particle tracking velocimetry was used to measure the Brownian diffusion of the nanobeads in real time to determine the antigen concentration. Through this preconcentration experiment, we demonstrated a rapid and high-sensitivity detection of prostate-specific antigen with a detection limit of 50 pg/ml in 20 min.",science
10.1016/j.jss.2018.05.005,Journal,Journal of Surgical Research,scopus,2018-11-01,sciencedirect,"Pleural electrical impedance is a sensitive, real-time indicator of pneumothorax",https://api.elsevier.com/content/abstract/scopus_id/85047597849,"Background
                  Chest tube management protocols, particularly in patients with alveolar-pleural air leak due to recent surgery or trauma, are limited by concerns over safety, especially concerns about rapid and occult development of pneumothorax. A continuous, real-time monitor of pneumothorax could improve the quality and safety of chest tube management. We developed a rat model of pneumothorax to test a novel approach of measuring electrical impedance within the pleural space as a monitor of lung expansion.
               
                  Materials and methods
                  Anesthetized Sprague–Dawley rats underwent right thoracotomy. A novel impedance sensor and a thoracostomy tube were introduced into the right pleural space. Pneumothorax of varying volumes ranging from 0.2 to 20 mL was created by syringe injection of air via the thoracostomy tube. Electrical resistance measurements from the pleural sensor and fluoroscopic images were obtained at baseline and after the creation of pneumothorax and results compared.
               
                  Results
                  A statistically significant, dose-dependent increase in electrical resistance was observed with increasing volume of pneumothorax. Resistance measurement allowed for continuous, real-time monitoring of pneumothorax development and the ability to track pneumothorax resolution by aspiration of air via the thoracostomy tube. Pleural resistance measurement demonstrated 100% sensitivity and specificity for all volumes of pneumothorax tested and was significantly more sensitive for pneumothorax detection than fluoroscopy.
               
                  Conclusions
                  The electrical impedance-based pleural space sensor described in this study provided sensitive and specific pneumothorax detection, which was superior to radiographic analysis. Real-time, continuous monitoring for pneumothorax has the potential to improve the safety, quality, and efficiency of postoperative chest tube management.",science
10.1016/j.neunet.2018.03.014,Journal,Neural Networks,scopus,2018-11-01,sciencedirect,Intrinsically motivated reinforcement learning for human–robot interaction in the real-world,https://api.elsevier.com/content/abstract/scopus_id/85044999508,"For a natural social human–robot interaction, it is essential for a robot to learn the human-like social skills. However, learning such skills is notoriously hard due to the limited availability of direct instructions from people to teach a robot. In this paper, we propose an intrinsically motivated reinforcement learning framework in which an agent gets the intrinsic motivation-based rewards through the action-conditional predictive model. By using the proposed method, the robot learned the social skills from the human–robot interaction experiences gathered in the real uncontrolled environments. The results indicate that the robot not only acquired human-like social skills but also took more human-like decisions, on a test dataset, than a robot which received direct rewards for the task achievement.",science
10.1016/j.knosys.2018.05.020,Journal,Knowledge-Based Systems,scopus,2018-10-15,sciencedirect,Multi-granularity feature selection on cost-sensitive data with measurement errors and variable costs,https://api.elsevier.com/content/abstract/scopus_id/85048485797,"In real applications of data mining, machine learning and granular computing, measurement errors, test costs and misclassification costs often occur. Furthermore, the test cost of a feature is usually variable with the error range, and the variability of the misclassification cost is related to the object considered. Recently, some approaches based on rough sets have been introduced to study the error-based cost-sensitive feature selection problem. However, most of them consider only single-granularity cases, thus are not feasible for the case where the granularity diversity between different features should be taken into account. Motivated by this problem, we propose a multi-granularity feature selection approach which considers measurement errors and variable costs in terms of feature-value granularities. For a given feature, the feature-value granularity is evaluated by the error confidence level of the feature values. In this way, we build a theoretic framework called confidence-level-vector-based neighborhood rough set, and present a so-called heuristic feature-granularity selection algorithm, and a relevant competition strategy which can select both features and their respective feature-value granularities effectively and efficiently. Experiment results show that a satisfactory trade-off among feature dimension reduction, feature-value granularity selection and total cost minimization can be achieved by the proposed approach. This work would provide a new insight into the cost-sensitive feature selection problem from the multi-granularity perspective.",science
10.1016/j.jep.2018.06.018,Journal,Journal of Ethnopharmacology,scopus,2018-10-05,sciencedirect,"Ephedra gerardiana aqueous ethanolic extract and fractions attenuate Freund Complete Adjuvant induced arthritis in Sprague Dawley rats by downregulating PGE2, COX2, IL-1β, IL-6, TNF-α, NF-kB and upregulating IL-4 and IL-10",https://api.elsevier.com/content/abstract/scopus_id/85049039990,"Ethnopharmacological relevance
                  The whole plant, roots and stems of Ephedra gerardiana (Family Ephedraceae) have long been used as a folk remedy to treat rheumatism and painful joints in Northern Areas of Pakistan.
               
                  Aim of the study
                  The purpose of study was to observe the preventive efficacy of Ephedra gerardiana (EG) aerial parts in treating rheumatoid arthritis using Freund's complete adjuvant (FCA) induced arthritis in rat model and to determine its possible mechanism of action.
               
                  Material and methods
                  Arthritis was induced in Sprague Dawley rats by immunization with 0.1 ml FCA in left footpad. EG aqueous ethanolic extract (30:70) and its aqueous, n-butanol and ethyl acetate fractions at 200 mg/kg were orally administered from day 0, 30 min prior to adjuvant injection and sustained for 28 days. Paw volume/diameter, arthritic score, body weight, and hematological (WBC, RBC, ESR, Hb and Platelet count) and biochemical (AST, ALT, ALP, urea, creatinine, CRP and RF) parameters were observed. The mRNA expression levels of COX-2, IL-1β, IL-6, NF-kB, TNF-α, IL-4 and IL-10 were measured by real time reverse transcription polymerase chain reaction (RT-PCR) while, PGE2 and TNF-α levels in serum samples were measured by Enzyme linked immunosorbent assay (ELISA). Moreover, radiographs of hind paws and histological changes in ankle joint were analyzed in adjuvant injected rats. In addition, anti-oxidant activity of plant extract and fractions was also evaluated using DPPH and reducing power assays. Also, preliminary phytochemistry and total phenolic and flavonoid contents were investigated in most active fraction (aqueous fraction).
               
                  Results
                  EG extract and fractions (notably aqueous fraction) significantly suppressed paw swelling and arthritic score, prevented cachexia and remarkably ameliorated hematological and biochemical changes. Furthermore, the overproduction of PGE2, COX-2, IL-1β, IL-6, NF-kB and TNF-α were remarkably attenuated in all EG treated rats, however, IL-4 and 10 were markedly increased. The radiographic and histopathologic improvement in joint architecture was also observed in EG treated rats. Piroxicam, used as reference drug, also significantly suppressed arthritis. Additionally, plant exhibited notable anti-oxidant activity and phytochemical analysis revealed the presence of alkaloids, flavonoids, phenols, tannins, saponins and glycosides.
               
                  Conclusion
                  These results indicate that EG extract and fractions significantly attenuated adjuvant arthritis in rats by decreasing the levels of aforementioned pro-inflammatory and increasing the levels of anti-inflammatory mediators. This suggests that Ephedra gerardiana aerial parts might be used as a therapeutic agent for treating human arthritis.",science
10.1016/j.mfglet.2018.09.002,Journal,Manufacturing Letters,scopus,2018-10-01,sciencedirect,Industrial Artificial Intelligence for industry 4.0-based manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85053749537,"The recent White House report on Artificial Intelligence (AI) (Lee, 2016) highlights the significance of AI and the necessity of a clear roadmap and strategic investment in this area. As AI emerges from science fiction to become the frontier of world-changing technologies, there is an urgent need for systematic development and implementation of AI to see its real impact in the next generation of industrial systems, namely Industry 4.0. Within the 5C architecture previously proposed in Lee et al. (2015), this paper provides an insight into the current state of AI technologies and the eco-system required to harness the power of AI in industrial applications.",science
10.1016/j.ins.2018.07.064,Journal,Information Sciences,scopus,2018-10-01,sciencedirect,Identifying advisor-advisee relationships from co-author networks via a novel deep model,https://api.elsevier.com/content/abstract/scopus_id/85050884529,"Advisor-advisee is one of the most important relationships in research publication networks. Identifying it can benefit many interesting applications, such as double-blind peer review, academic circle mining, and scientific community analysis. However, the advisor-advisee relationships are often hidden in research publication network and vary over time, thus are difficult to detect. In this paper, we present a time-aware Advisor-advisee Relationship Mining Model (tARMM) to better identify such relationships. It is a deep model equipped with improved Refresh Gate Recurrent Units (RGRU). Extensive experiments over real-world DBLP data have well verified the effectiveness of our proposed model.",science
10.1016/j.asoc.2018.07.034,Journal,Applied Soft Computing Journal,scopus,2018-10-01,sciencedirect,A hybrid multi-objective AIS-based algorithm applied to simulation-based optimization of material handling system,https://api.elsevier.com/content/abstract/scopus_id/85050115741,"Optimization of complex real-world problems often involves multiple objectives to be considered simultaneously. These objectives are often non-commensurable and competing. For example, material handling is a vital element of industrial processes, which involves a variety of operations including the movement, storage and control of materials throughout the processes of manufacturing, distribution, and disposal while having to satisfy multiple objectives. Having an efficient and effective material handling system (MHS) is of great importance to various industries, such as manufacturing and logistics industries, for maintaining and facilitating a continuous flow of materials through the workplace and guaranteeing that required materials are available when needed. In this paper, a hybrid multi-objective optimization algorithm largely based on Artificial Immune Systems (AIS) is applied to simulation-based optimization of material handling system. This proposed algorithm hybridizes the AIS with the Genetic Algorithm (GA) by incorporating the crossover operator derived from the biological evolution. The reason behind such hybridization is to further enhance the diversity of the clone population and the convergence of the algorithm. In this paper, other than conducting numerical experiments to assess the performance of the proposed algorithm by using several benchmark problems, the proposed algorithm is also applied to optimize a multi-objective simulation-based problem on a material handling system in order to demonstrate the applicability of the proposed algorithm in real-life cases. The results show that for most cases the proposed algorithm outperforms the other benchmark algorithms especially in terms of solution diversity.",science
10.1016/j.chb.2018.03.018,Journal,Computers in Human Behavior,scopus,2018-10-01,sciencedirect,Supports for deeper learning of inquiry-based ecosystem science in virtual environments - Comparing virtual and physical concept mapping,https://api.elsevier.com/content/abstract/scopus_id/85050006016,"Concept mapping is an important tool used in science learning to help students construct understanding about fundamental concepts and how they are related. The EcoXPT research project has the goal of supporting authentic experiment-based inquiry within an immersive virtual world curriculum for middle school ecosystem science. It builds on prior research with the EcoMUVE curriculum, which includes, as a culminating activity, student teams creating hand-drawn concept maps to represent their hypotheses about the causal relationships in a virtual ecosystem. As part of the initial Design-Based Research phase of EcoXPT, researchers developed a new electronic concept mapping tool which was piloted with the EcoMUVE curriculum. This study looks at differences in concept maps drawn by student teams based on whether they were given access to the new concept-mapping tool. The findings provide insight into the impact of concept map scaffolding choices, and inform the design of future versions of the tool.",science
10.1016/j.biomaterials.2018.06.028,Journal,Biomaterials,scopus,2018-10-01,sciencedirect,Imaging γ-Glutamyltranspeptidase for tumor identification and resection guidance via enzyme-triggered fluorescent probe,https://api.elsevier.com/content/abstract/scopus_id/85049317970,"Development of high selectivity, accurate targeted and noninvasive fluorescent probe for monitoring specific enzyme activity associated with the tumor is urgent needed for early diagnosis of cancer and clinical fluorescence interventional resection guidance treatment. Owing to the invasion of malignant tumor cells, tumor cells are mixed with normal cells in the actual tumor location, which make it quite difficult for clinician to diagnose early diagnosis of tumor as well as resection of tumor. To overcome aforementioned obstacle, herein, an ingenious enzyme-activated one and two-photon fluorescent probe TCF-GGT was constructed and synthesized including γ-GGT enzyme specific identification site and far-red fluorophore for imaging. Under simulative physiological condition, probe TCF-GGT demonstrated high selectivity, sensitivity (DL 0.014 mU/mL), rapid response (T
                     
                        e
                      14 min) for the detection of γ-GGT enzyme. By virtue of its biocompatibility, probe was employed for the identification of ovarian cancer cells (A2780 cells) from normal cells (NIH-3T3 cells), particularly in mixed cultivation dish (simulate the actual environment of tumor) through 2D&3D fluorescence imaging with “dual” mark (Nucleic acid labeling used by Hoechst 33342 dye and γ-GGT enzyme labeling used by probe TCF-GGT) for the first time. Probe TCF-GGT could be visualize endogenous γ-GGT activity in HepG-2 cells and zebrafish on the two-photon confocal platform, which is conduce to estimate the inhibitor of γ-GGT enzyme in vivo. Through NaBu (a potential anticancer drug) stimulation, the changes of γ-GGT activity were observed in living MCF-7 cells by using this probe. More importantly, the deep tissue penetration ability of far-red fluorescence allowed the two-photon fluorescent probe TCF-GGT to real-time track γ-GGT activity in tissue slices and tumor xenotransplantation model of mice by the tail vein injection, which showed that this enzyme-triggered fluorogenic probe would be a potential tool for preclinical applications of tumor resection.",science
10.1016/j.ins.2018.06.051,Journal,Information Sciences,scopus,2018-10-01,sciencedirect,"Extension of neighbor-based link prediction methods for directed, weighted and temporal social networks",https://api.elsevier.com/content/abstract/scopus_id/85049109042,"Link prediction is one of the most interesting tasks in social network analysis. It has received considerable attention as evident by the number of studies described in the literature. Recently, heterogeneous, temporal or directed based network models have attracted considerable attention to deal with effectively real complex networks in terms of link prediction. Most of the link prediction measures in the literature don't consider the role of link direction. In this study, we introduce a directional link prediction measure by extending neighbor based measures as directional pattern based to take into account the role of link direction in directed networks. The introduced measure also considers weight and time information of links, which are effective to improve accuracy of link prediction. In experiments, the introduced measure is compared to nine well-known link prediction measures in the literature by using supervised learning algorithms. Experimental results demonstrate that the proposed approach improves remarkably the accuracy of link prediction. This is mainly due to using structural information of networks effectively without requiring more information and computational time.
                  2018.",science
10.1016/j.paid.2018.05.010,Journal,Personality and Individual Differences,scopus,2018-10-01,sciencedirect,"Whichever intelligence makes you happy: The role of academic, emotional, and practical abilities in predicting psychological well-being",https://api.elsevier.com/content/abstract/scopus_id/85047131429,"Recent findings suggest a positive effect of intelligence on psychological well-being but remain inconclusive as to whether this criterion would be better predicted by drawing on emotional and practical abilities–besides traditional “academic” ones–and whether any path from intelligence to well-being bypasses socioeconomic status. We investigated these issues with a sample of 288 working adults (N in path analyses = 157), employing three standard tests of academic intelligence (Matrix Reasoning, Verbal Analogies, General Knowledge); the Mayer-Salovey-Caruso Emotional Intelligence Test; the practical sections of Sternberg's Triarchic Abilities Test to assess practical intelligence; and Ryff's Scales of Psychological Well-Being. Hierarchical regression analyses yielded academic intelligence (Step 1), specifically Matrix Reasoning, and emotional intelligence (Step 2, with practical intelligence), specifically Understanding and Managing Emotions, as independent predictors of well-being. Subsequent path analyses revealed that the effect of academic intelligence on well-being was indirect (mediated by socioeconomic status) and the effect of emotional intelligence a direct one, the latter also being stronger and primarily due to the Managing Emotions branch. While expanding the evidence on the real-life utility of academic intelligence, the present results draw special attention to knowing/reasoning about emotions as an incremental predictor of well-being, the implications of which are discussed.",science
10.1016/j.ijfoodmicro.2018.05.024,Journal,International Journal of Food Microbiology,scopus,2018-09-20,sciencedirect,"In vitro and in vivo effect of 2,6-Di-tert-butyl-4-methylphenol as an antibiofilm agent against quorum sensing mediated biofilm formation of Vibrio spp.",https://api.elsevier.com/content/abstract/scopus_id/85048504978,"This study unveils the in vitro and in vivo antibiofilm potential of 2,6-Di-tert-butyl-4-methylphenol (DTBMP) from Chroococcus turgidus against Vibrio spp. In the preliminary study, cell free culture supernatant (CFCS) of C. turgidus inhibited the violacein production in biomarker strain Chromobacterium violaceum and its mutant strain CV026 in a dose dependent manner. The effective biofilm inhibitory concentration (BIC) of pure compound DTBMP from C. turgidus was identified as 250 μg/ml concentration in tested Vibrio species. Furthermore, DTBMP proved to effectively inhibit the bioluminescence production in V. harveyi and other biofilm related virulence traits such as exopolysaccharides (EPS) production, hydrophobicity index, swimming and swarming motility at its BIC concentration in three major pathogenic vibrios: V. harveyi, V. parahaemolyticus and V. vulnificus. The antibiofilm potential of DTBMP was validated through light, confocal laser scanning and scanning electron microscopic analyses. In addition, the non-bactericidal effect of DTBMP was determined through growth curve and 2,3-bis (2-methyloxy-4-nitro-5-sulfophenyl)-2H-tetrazolium-5-carboxanilide (XTT) assay. Real-time PCR studies revealed the down-regulation of master quorum sensing (QS) regulator genes of V. harveyi such as luxR, luxS, luxP, luxQ and luxO on treatment with DTBMP. In vivo results confirmed that DTBMP augmented the survival rate of Litopenaeus vannamei larvae up to 75, 88 and 66% upon infection with V. harveyi, V. parahaemolyticus and V. vulnificus, respectively. The results of this study ascertain the promising effects of DTBMP as an antibiofilm agent, which could be positively explored to treat biofilm-associated vibrios infections in aquaculture.",science
10.1016/j.chroma.2018.06.035,Journal,Journal of Chromatography A,scopus,2018-09-14,sciencedirect,Tandem column isolation of zirconium-89 from cyclotron bombarded yttrium targets using an automated fluidic platform: Anion exchange to hydroxamate resin columns,https://api.elsevier.com/content/abstract/scopus_id/85051041242,"The development of a tandem column purification method for the preparation of high-purity 89Zr(IV) oxalate is presented. The primary column was a macroporous strongly basic anion exchange resin on styrene divinylbenzene co-polymer. The secondary column, with an internal volume of 33 μL, was packed with hydroxamate resin. A condition of inverted selectivity was developed, whereby the 89Zr eluent solution for the primary column is equivalent to the 89Zr load solution for the secondary column. The ability to transfer 89Zr from one column to the next allows two sequential column clean-up methods to be performed prior to the final elution of the 89Zr(IV) oxalate. This approach assures delivery of high purity 89Zr product and assures a 89Zr product that is eluted in a substantially smaller volume than is possible when using the traditionally-employed single hydroxamate resin column method. The tandem column purification process has been implemented into a prototype automated fluidic system. The system is configured with on-line gamma detection so column effluents can be monitored in near-real time. The automated method was tested using seven cyclotron bombarded Y foil targets. It was found that 95.1 ± 1.3% of the 89Zr present in the foils was recovered in the secondary column elution fraction. Furthermore, elution peak analysis of several 89Zr elution profile radiochromatograms made possible the determination of 89Zr recovery as a function of volume; a 89Zr product volume that contains 90% of the mean secondary column elution peak can be obtained in 0.29 ± 0.06 mL (representing 86 ± 5% of the 89Zr activity in the target). This product volume represents a significant improvement in radionuclide product concentration over the predominant method used in the field. In addition to the reduced 89Zr product elution volume, titrations of the 89Zr product with deferoxamine mesylate salt across two preparatory methods resulted in mean effective specific activity (ESA) values of 279 and 340 T Bq·mmole−1 and mean bindable metals concentrations ([MB]) of 13.5 and 16.7 nmole·g−1. These ESA and [MB] values infer that the 89Zr(IV) oxalate product resulting from this tandem column isolation method has the highest purity reported to date.",science
10.1016/j.jpba.2018.07.012,Journal,Journal of Pharmaceutical and Biomedical Analysis,scopus,2018-09-10,sciencedirect,Investigating the utility of minimized sample preparation and high-resolution mass spectrometry for quantification of monoclonal antibody drugs,https://api.elsevier.com/content/abstract/scopus_id/85050698646,"Determination of the pharmacokinetic (PK) properties of therapeutic monoclonal antibodies (mAbs) is essential for their successful development as drugs. For this purpose, besides the traditional ligand binding assay (LBA), LC–MS/MS method using low resolution mass spectrometers (e.g. triple quadrupole (QqQ)) has become routinely used, however, complicated and lengthy sample pre-treatment (employing immuno-affinity) is often necessary for obtaining sufficient sensitivity and selectivity. In this study, we investigate the capabilities of high-resolution MS instruments for circumventing the complex sample preparation currently needed for sensitive LC–MS/MS-based quantification of mAbs. Employing a simple one-step sample pre-treatment workflow, we compare the ability of three different LC–MS platforms for absolute quantification of a representative monoclonal antibody Rendomab-B1 in serum and plasma. The samples are subjected to protein precipitation with methanol, followed by pellet digestion with trypsin prior to LC–MS analysis. AQUA peptides based on two surrogate mAb peptides selected from an extensive in-silico and experimental screening are used as internal standards. MS/MS acquisitions are developed and systematically examined for 1) a low-resolution QqQ operated in selected reaction monitoring (SRM) acquisition mode, 2) a high-resolution hybrid Quadrupole-Orbitrap (Q-Orbitrap) operated in parallel reaction monitoring (PRM) acquisition mode and 3) a high-resolution hybrid Quadrupole-Time-of-flight (Q-TOF) operated in SRM acquisition mode with enhanced duty cycle (EDC) function. The sensitivity of the high-resolution Q-Orbitrap and Q-TOF methods was significantly higher (LOD of 80 ng/mL) in serum/plasma samples than the low-resolution QqQ method. Finally, the real-world utility of the developed high-resolution MS method with minimized sample handling was demonstrated and validated by determining the PK profile of Rendomab-B1 in mice by a 10-point in vivo study over 15 days.",science
10.1016/j.cmpb.2018.05.029,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-09-01,sciencedirect,Estimating the refractive index of oxygenated and deoxygenated hemoglobin using genetic algorithm – support vector regression model,https://api.elsevier.com/content/abstract/scopus_id/85048604435,"Background and objectives
                  The refractive index of hemoglobin plays important role in hematology due to its strong correlation with the pathophysiology of different diseases. Measurement of the real part of the refractive index remains a challenge due to strong absorption of the hemoglobin especially at relevant high physiological concentrations. So far, only a few studies on direct measurement of refractive index have been reported and there are no firm agreements on the reported values of refractive index of hemoglobin due to measurement artifacts. In addition, it is time consuming, laborious and expensive to perform several experiments to obtain the refractive index of hemoglobin. In this work, we proposed a very rapid and accurate computational intelligent approach using Genetic Algorithm/Support Vector Regression models to estimate the real part of the refractive index for oxygenated and deoxygenated hemoglobin samples.
               
                  Methods
                  These models utilized experimental data of wavelengths and hemoglobin concentrations in building highly accurate Genetic Algorithm/Support Vector Regression model (GA-SVR).
               
                  Results
                  The developed methodology showed high accuracy as indicated by the low root mean square error values of 4.65 × 10−4 and 4.62 × 10−4 for oxygenated and deoxygenated hemoglobin, respectively. In addition, the models exhibited 99.85 and 99.84% correlation coefficients (r) for the oxygenated and deoxygenated hemoglobin, thus, validating the strong agreement between the predicted and the experimental results
               
                  Conclusions
                  Due to the accuracy and relative simplicity of the proposed models, we envisage that these models would serve as important references for future studies on optical properties of blood.",science
10.1016/j.cmpb.2018.06.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-09-01,sciencedirect,Fuzzy decision support systems to diagnose musculoskeletal disorders: A systematic literature review,https://api.elsevier.com/content/abstract/scopus_id/85048589929,"Background and objective
                  Musculoskeletal disorders (MSDs) are one of the most important causes of disability with a high prevalence. The accurate and timely diagnosis of these disorders is often difficult. Clinical decision support systems (CDSSs) can help physicians to diagnose diseases quickly and accurately. Given the ambiguous nature of MSDs, fuzzy logic can be helpful in designing the CDSSs knowledge bases. The present study aimed to review the studies on fuzzy CDSSs to diagnose MSDs.
               
                  Methods
                  A comprehensive search was conducted in Medline, Scopus, Cochrane Library, and ISI Web of Science databases to identify relevant studies published until March 15, 2016. Studies were included in which CDSSs were developed using fuzzy logic to diagnose MSDs, and tested their accuracy using real data from patients.
               
                  Results
                  Of the 3188 papers examined, 23 papers included according to the inclusion criteria. The results showed that among all the designed CDSSs only one (CADIAG-2) was implemented in the clinical environment. In about half of the included studies (52%), CDSSs were designed to diagnose inflammatory/infectious disorder of the bone and joint. In most of the included studies (70%), the knowledge was extracted using a combination of three methods (acquiring from experts, analyzing the data, and reviewing the literature). The median accuracy of fuzzy rule-based CDSSs was 91% and it was 90% for other fuzzy models. The most frequently used membership functions were triangular and trapezoidal functions, and the most used method for inference was the Mamdani.
               
                  Conclusions
                  In general, fuzzy CDSSs have a high accuracy to diagnose MSDs. Despite the high accuracy, these systems have been used to a limited extent in the clinical environments. To design of knowledge base for CDSSs to diagnose MSDs, rule-based methods are used more than other fuzzy methods.",science
10.1016/j.neuroimage.2018.05.078,Journal,NeuroImage,scopus,2018-09-01,sciencedirect,Cortical dynamics underpinning the self-other distinction of touch: A TMS-EEG study,https://api.elsevier.com/content/abstract/scopus_id/85048507625,"Touch supports processes crucial to human social behaviour, adding a bodily dimension to the perception and understanding of others' feelings. Mirror cortical activity was proposed to underpin the interpersonal sharing of touch, allowing an automatic and unconscious simulation of others' somatic states. However, recent evidence questioned the existence of a tactile shared representation in the primary somatosensory cortex (S1), and the neural correlates of self-other distinction in the somatosensory system remains unknown. We address these issues by exploring S1 reactivity, and the associated neural network oscillations and connectivity, to self and others' touch. Transcranial Magnetic Stimulation combined with Electroencephalography (TMS-EEG) recordings were performed during tactile perception and observation, looking for differences in cortical activation and connectivity between felt and seen touch. The sight of a touch directed to a human body part, but not to an object, triggered an early activation of S1 as a felt touch did, which, in both conditions, propagated to fronto-parietal regions. Critically, touch perception and observation shared an effective connectivity network generated in the beta band, which is typically associated to unconscious tactile processing. Conversely, alpha band connectivity, a marker of conscious tactile processing, was detected only for real tactile stimulation. Alpha connectivity within a fronto-parietal pathway seems to underpin the ability to distinguish self and others' somatosensory states, controlling and distinguishing shared tactile representations in S1.",science
10.1016/j.diin.2018.05.004,Journal,Digital Investigation,scopus,2018-09-01,sciencedirect,Laying foundations for effective machine learning in law enforcement. Majura – A labelling schema for child exploitation materials,https://api.elsevier.com/content/abstract/scopus_id/85047981760,"The health impacts of repeated exposure to distressing concepts such as child exploitation materials (CEM, aka ‘child pornography’) have become a major concern to law enforcement agencies and associated entities. Existing methods for ‘flagging’ materials largely rely upon prior knowledge, whilst predictive methods are unreliable, particularly when compared with equivalent tools used for detecting ‘lawful’ pornography. In this paper we detail the design and implementation of a deep-learning based CEM classifier, leveraging existing pornography detection methods to overcome infrastructure and corpora limitations in this field. Specifically, we further existing research through direct access to numerous contemporary, real-world, annotated cases taken from Australian Federal Police holdings, demonstrating the dangers of overfitting due to the influence of individual users' proclivities. We quantify the performance of skin tone analysis in CEM cases, showing it to be of limited use. We assess the performance of our classifier and show it to be sufficient for use in forensic triage and ‘early warning’ of CEM, but of limited efficacy for categorising against existing scales for measuring child abuse severity.
                  We identify limitations currently faced by researchers and practitioners in this field, whose restricted access to training material is exacerbated by inconsistent and unsuitable annotation schemas. Whilst adequate for their intended use, we show existing schemas to be unsuitable for training machine learning (ML) models, and introduce a new, flexible, objective, and tested annotation schema specifically designed for cross-jurisdictional collaborative use.
                  This work, combined with a world-first ‘illicit data airlock’ project currently under construction, has the potential to bring a ‘ground truth’ dataset and processing facilities to researchers worldwide without compromising quality, safety, ethics and legality.",science
10.1016/j.chroma.2018.06.016,Journal,Journal of Chromatography A,scopus,2018-08-24,sciencedirect,Development and optimization of a solid-phase microextraction gas chromatography–tandem mass spectrometry methodology to analyse ultraviolet filters in beach sand,https://api.elsevier.com/content/abstract/scopus_id/85048474681,"A methodology based on solid-phase microextraction (SPME) followed by gas chromatography–tandem mass spectrometry (GC–MS/MS) has been developed for the simultaneous analysis of eleven multiclass ultraviolet (UV) filters in beach sand. To the best of our knowledge, this is the first time that this extraction technique is applied to the analysis of UV filters in sand samples, and in other kind of environmental solid samples. Main extraction parameters such as the fibre coating, the amount of sample, the addition of salt, the volume of water added to the sand, and the temperature were optimized. An experimental design approach was implemented in order to find out the most favourable conditions. The final conditions consisted of adding 1 mL of water to 1 g of sample followed by the headspace SPME for 20 min at 100 °C, using PDMS/DVB as fibre coating. The SPME-GC–MS/MS method was validated in terms of linearity, accuracy, limits of detection and quantification, and precision. Recovery studies were also performed at three concentration levels in real Atlantic and Mediterranean sand samples. The recoveries were generally above 85% and relative standard deviations below 11%. The limits of detection were in the pg g−1 level. The validated methodology was successfully applied to the analysis of real sand samples collected from Atlantic Ocean beaches in the Northwest coast of Spain and Portugal, Canary Islands (Spain), and from Mediterranean Sea beaches in Mallorca Island (Spain). The most frequently found UV filters were ethylhexyl salicylate (EHS), homosalate (HMS), 4-methylbenzylidene camphor (4MBC), 2-ethylhexyl methoxycinnamate (2EHMC) and octocrylene (OCR), with concentrations up to 670 ng g−1.",science
10.1016/j.jchromb.2018.05.030,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2018-08-01,sciencedirect,"Micellar HPLC-UV method for the simultaneous determination of levodopa, carbidopa and entacapone in pharmaceuticals and human plasma",https://api.elsevier.com/content/abstract/scopus_id/85047428534,"A method based on micellar liquid chromatography to quantify levodopa, carbidopa and entacapone in plasma is reported. The sample pretreatment was a simple dilution in a pure micellar solution then filtration and direct injection, without requiring extraction or purification steps. The three drugs were resolved from the matrix in 7 min, using an aqueous solution of 0.1 M sodium dodecyl sulphate-10% n-propanol-0.3 tiethylamine, adjusted at pH 2.8 with 0.02 M orthophosphoric acid as mobile phase, running under isocratic mode at 1.0 mL/ min through VP-ODS column. The detection was done by UV (ultraviolet) absorbance at 225 nm. The method was successfully validated by the International Conference Harmonization guidelines in terms of: selectivity, linearity (r2 > 0.998) over the concentration ranges of 0.025–1.2, 0.05–1.0 and 0.3–2.0 μg mL−1 with limits of detection of 0.01, 6.16 × 10−3 and 0.02 μg mL−1 and limits of quantification of 0.03, 0.02 and 0.07 μg mL−1 for levodopa, carbidopa and entacapone, respectively. The proposed method was applied successfully for quantification of the studied drugs in their different dosage forms. Moreover, the method was further extensive to the quantification of the studied drugs in spiked human plasma and was successfully validated by the guidelines of the European Medicines Agency. The proposed procedures were successfully evaluated to determine the studied drugs in real human plasma. The procedure was found reliable, practical, cost-effective, available, short period, easy-to-handle, low-cost, environmental-friendly, secure, useful for the analysis of numerous samples per day. Lastly, the method was performed to the analysis of incurred, using quality control samples in the same analytical run, with adequate results. Therefore, it can be implementable for custom analysis in clinical laboratories.",science
10.1016/j.foodchem.2018.02.002,Journal,Food Chemistry,scopus,2018-08-01,sciencedirect,Quadruplex gold immunochromatogaraphic assay for four families of antibiotic residues in milk,https://api.elsevier.com/content/abstract/scopus_id/85042846210,"In this study, we developed a quadruplex gold immunochromatogaraphic assay (GICA) for the simultaneous determination of four families of antibiotics including β-lactams, tetracyclines, streptomycin and chloramphenicol in milk. For qualitative analysis, the visual cut-off values were measured to be 2–100 ng/mL, 16–32 ng/mL, 50 ng/mL and 2.4 ng/mL for β-lactams, tetracyclines, streptomycin and chloramphenicol, respectively. For quantitative analysis, the detection ranges were 0.13–1 ng/mL for penicillin G, 0.13–8 ng/mL for tetracycline, 0.78–25 ng/mL for streptomycin, 0.019–1.2 ng/mL for chloramphenicol in milk respectively, with linear correlation coefficients higher than 0.97. The spiked experiment indicated that the mean recoveries ranged from 84.5% to 107.6% with coefficient of variations less than 16.2%, and real sample analysis revealed that the GICA can produce consistent results with instrumental analysis. These results demonstrated that this novel immunoassay is a promising approach for rapidly screening common antibiotic residues in milk.",science
10.1016/j.phymed.2018.04.036,Journal,Phytomedicine,scopus,2018-07-15,sciencedirect,"Total sesquiterpene lactones isolated from Inula helenium L. attenuates 2,4-dinitrochlorobenzene-induced atopic dermatitis-like skin lesions in mice",https://api.elsevier.com/content/abstract/scopus_id/85050540239,"Background
                  
                     Inula helenium L. is an herb whose anti-inflammatory properties are attributed to its active components, the sesquiterpene lactones (SLs). Our previous study demonstrated that the total sesquiterpene lactones isolated from Inula helenium L. (TSL-IHL), consisting mainly of alantolactone (AL) and isoalantolactone (IAL), may have potential in the prevention and treatment of rheumatoid arthritis (RA). However, the effect of TSL-IHL on atopic dermatitis (AD) has not been studied yet.
               
                  Aim of the study
                  The present study evaluates the potential of TSL-IHL as a treatment for AD.
               
                  Methods/Study designs
                  The effects of TSL-IHL on the expression of inflammatory genes and the activation of NF-κB signaling pathway in HaCat cells were examined by quantitative real-time PCR and western blotting, respectively, and compared with those of AL and IAL. The protective effect of TSL-IHL against AD was tested in a mouse model induced by 2,4-dinitrochlorobenzene (DNCB), in which AD-like skin lesions were induced in ICR mice by sensitizing once with 100 µl of 7% DNCB painted on their shaved back skin and then challenging with 20 µl of 0.2% DNCB five times on their right ears at 3 day intervals starting on day 5 post-sensitization.
               
                  Results
                  TSL-IHL, as well as AL and IAL, could all inhibit TNF-α-induced activation of NF-κB and the expression of TNF-α, IL-1, and IL-4 in HaCat cells in a dose-dependent manner in the range of 0.6–2.4 µg/ml. The topical application of TSL-IHL (1% W/W in emollient cream) attenuated DNCB-induced dermatitis severity and right ear swelling. The serum levels of IgE, TNF-α and IFN-γ in TSL-IHL-treated mice were reduced by 81.39%, 89.69%, and 87.85%, respectively, while the mRNA levels of IL-4, IL-5 and IL-13, in the back-skin lesions of TSL-IHL-treated mice were reduced by 39.21%, 40.62% and 48.12%, respectively, compared with the untreated controls. Histopathological examination showed that TSL-IHL treatment reduced epidermis/dermis thickening and dermal inflammatory infiltration in both ear and back skins.
               
                  Conclusions
                  We suggest that TSL-IHL inhibited the development of AD-like skin symptoms by regulating cytokine expression and may be an effective alternative therapy for AD.",science
10.1016/j.neucom.2018.01.065,Journal,Neurocomputing,scopus,2018-07-05,sciencedirect,Incorporating network structure with node contents for community detection on large networks using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85044381671,"Community detection is an important task in social network analysis. In community detection, in general, there exist two types of the models that utilize either network topology or node contents. Some studies endeavor to incorporate these two types of models under the framework of spectral clustering for a better community detection. However, it was not successful to obtain a big achievement since they used a simple way for the combination. To reach a better community detection, it requires to realize a seamless combination of these two methods. For this purpose, we re-examine the properties of the modularity maximization and normalized-cut models and fund out a certain approach to realize a seamless combination of these two models. These two models seek for a low-rank embedding to represent of the community structure and reconstruct the network topology and node contents, respectively. Meanwhile, we found that autoencoder and spectral clustering have a similar framework in their low- rank matrix reconstruction. Based on this property, we proposed a new approach to seamlessly combine the models of modularity and normalized-cut via the autoencoder. The proposed method also utilized the advantages of the deep structure by means of deep learning. The experiment demonstrated that the proposed method can provide a nonlinearly deep representation for a large-scale network and reached an efficient community detection. The evaluation results showed that our proposed method outperformed the existing leading methods on nine real-world networks.",science
10.1016/j.ijantimicag.2018.02.018,Journal,International Journal of Antimicrobial Agents,scopus,2018-07-01,sciencedirect,Identification and bioevaluation of SRI-12742 as an antimicrobial agent against multidrug-resistant Acinetobacter baumannii,https://api.elsevier.com/content/abstract/scopus_id/85048519265,"Multidrug-resistant Acinetobacter baumannii (MDR-Ab) is one of the most significant nosocomial pathogens that is being increasingly isolated in healthcare settings worldwide. Owing to its inherent drug-resistant nature, coupled with its ability to readily acquire resistance to other antibiotic classes, there is a real dearth of antibiotics available to treat infections with MDR-Ab. A commercially available library was screened against MDR-Ab BAA-1605 to identify novel inhibitory molecules. The selectivity index of a hit was tested against Vero cells and in vitro efficacy was profiled against a panel of clinical MDR-Ab. The bacteriostatic or bactericidal nature was determined by time–kill experiments, and synergy with clinically approved drugs was determined by the chequerboard method. Additionally, in vivo efficacy was measured in a murine neutropenic A. baumannii thigh infection model. SRI-12742 was identified as a potent active hit, with a minimum inhibitory concentration (MIC) of 4 mg/L against BAA-1605. Its activity was then profiled against a MDR-Ab clinical strain panel (MICs 4 mg/L to >64 mg/L). SRI-12742 exhibited concentration-dependent bactericidal activity and caused an ca. 16 log10 CFU/mL reduction at 10 × MIC in 24 h, which is comparable with minocycline. In a murine neutropenic thigh infection model of A. baumannii infection, SRI-12742 reduced CFU counts by ca. 0.9 log10 CFU, which is comparable with polymyxin B. In addition, SRI-12742 synergised with all classes of antibiotics tested. SRI-12742 exhibits all of the criteria necessary to be positioned as a novel lead with potential to be deployed for the treatment of infections caused by MDR-Ab.",science
10.1016/j.chemosphere.2018.03.090,Journal,Chemosphere,scopus,2018-07-01,sciencedirect,Sequential application of Fenton and ozone-based oxidation process for the abatement of Ni-EDTA containing nickel plating effluents,https://api.elsevier.com/content/abstract/scopus_id/85047432383,"Treatment of Ni-EDTA in industrial nickel plating effluents was investigated by integrated application of Fenton and ozone-based oxidation processes. Determination of integrated sequence found that Fenton oxidation presented higher apparent kinetic rate constant of Ni-EDTA oxidation and capacity for contamination load than ozone-based oxidation process, the latter, however, was favorable to guarantee the further mineralization of organic substances, especially at a low concentration. Serial-connection mode of two oxidation processes was appraised, Fenton effluent after treated by hydroxide precipitation and filtration negatively affected the overall performance of the sequential system, as evidenced by the removal efficiencies of Ni2+ and TOC dropping from 99.8% to 98.7%, and from 74.8% to 66.6%, respectively. As a comparison, O3/Fe2+ oxidation process was proved to be more effective than other processes (e.g. O3-Fe2+, O3/H2O2/Fe2+, O3/H2O2-Fe2+), and the final effluent Ni2+ concentration could satisfied the discharge standard (<0.1 mg L−1, China) under the optimal conditions (H2O2 dosage of 1.0 mL L−1, Fe2+: H2O2 mole ratio of 1.46, and reaction time of 10 min for Fenton reaction, initial influent pH of 3.0, O3 dosage of 252 mg L−1, Fe2+ of 150 mg L−1, and reaction time of 30 min for O3/Fe2+ oxidation). Furthermore, pilot-scale test was carried out to study the practical treatability towards the real nickel plating effluent, revealing the effective removal of some other co-existence contaminations. And Fenton reaction has contributed most, with the percentage ranging from 72.41% to 93.76%. The economic cost advantage made it a promising alternative to the continuous Fenton oxidation.",science
10.1016/j.yofte.2018.05.004,Journal,Optical Fiber Technology,scopus,2018-07-01,sciencedirect,Fiber Bragg grating based temperature profiling in ferromagnetic nanoparticles-enhanced radiofrequency ablation,https://api.elsevier.com/content/abstract/scopus_id/85047266101,"In this work, we report the real-time temperature profiling performed with a fiber Bragg grating (FBG) sensing system, applied to a ferromagnetic nanoparticles (NP)-enhanced radiofrequency ablation (RFA) for interventional cancer care. A minimally invasive RFA setup has been prepared and applied ex vivo on a liver phantom; NPs (with concentrations of 5 and 10 mg/mL) have been synthesized and injected within the tissue prior to ablation, in order to facilitate the heat distribution to the peripheral sides of the treated tissue. A network of 15 FBG sensors has been deployed in situ in order to detect the parenchymal temperature distribution and estimate the thermal profiles in real time during the ablation, highlighting the impact of the NPs on the RFA mechanism. The results confirm that NP-enhanced ablation with 5 mg/mL density shows a better heat penetration that a standard RFA achieving an almost double-sized lesion, while a higher density (10 mg/mL) does not improve the heat distribution. Thermal data are reported highlighting both spatial and temporal gradients, evaluating the capability of NPs to deliver sufficient heating to the peripheral sides of the tumor borders.",science
10.1016/j.compag.2018.05.002,Journal,Computers and Electronics in Agriculture,scopus,2018-07-01,sciencedirect,A multispectral machine vision system for invertebrate detection on green leaves,https://api.elsevier.com/content/abstract/scopus_id/85046824238,"Detection and identification of invertebrate pests in farming fields is a prerequisite necessity for integrated pest management (IPM), however, current sensing technologies do not meet the requirements for IPM. Currently, farmers have to first sample pests and then manually count and identify them, in a way that is time-consuming, labour-intensive and error-prone. Machine vision technology has taken over part of the work in a more efficient and accurate manner. However, current machine vision systems (MVSs) have limitations in detecting pests on crops and the counting and identification are constrained in laboratories or pest traps, resulting in the exact time and locations of pests being unknown, hindering more proper decisions and efficient actions. In this study, we developed a multispectral MVS to detect common invertebrate pests on green leaves in natural environment. First, it was found that, besides visible light and near-infrared, the ultraviolet is a good indicator to distinguish green leaves from other materials. Then for multispectral or hyperspectral data processing, we proposed two models, one named normalised hypercube and another named hyper-hue, which are less affected by uneven illumination and can reflect data distribution, resulting in more accurate classification than the normal method of spectral angle mapper (SAM). Further, the relationship between spectral angle and the relative angle of hyper-hue was studied and it was found that usually, data of hyper-hue has larger inter-class distances which could contribute to better classification. At last, to solve the practical problems of image registration and real-time infield applications, instead of registering 2D images, the MVS created and registered 3D point clouds. In an experiment of detecting twelve types of common invertebrate pests on crops, the proposed MVS showed acceptable accuracy.",science
10.1016/j.knosys.2018.03.025,Journal,Knowledge-Based Systems,scopus,2018-07-01,sciencedirect,On the predictive analysis of behavioral massive job data using embedded clustering and deep recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/85044262883,"The recent proliferation of social networks as a main source of information and interaction has led to a huge expansion of automatic e-recruitment systems and by consequence the multiplication of web channels (job boards) that are dedicated to job offers disseminating. In a strategic and economic context where cost control is fundamental, it has become necessary to identify the relevant job board for a given new job offer has become necessary. The purpose of this work is to present the recent results that we have obtained on a new job board recommendation system that is a decision-making tool intended to guide recruiters while they are posting a job on the Internet. Firstly, the Doc2Vec embedded representation is used to analyse the textual content of the job offers, then the job applicant clickstreams history on various job boards are stored in a large learning database, and then represented as time series. Secondly, a deep neural network architecture is used to predict future values of the clicks on the job boards. Third, and in parallel, dimensionality reduction techniques are used to transform the clicks numerical time series into temporal symbolic sequences. Forecasting algorithms are then used to predict future symbols for each sequence. Finally, a list of top ranked job boards are kept by maximizing the clickstreams forecasting in both representations. Our experiments are tested on a real dataset, coming from a job-posting database of an industrial partner. The promising results have shown that using deep learning, the recommendation system outperforms standard multivariate models.",science
10.1016/j.knosys.2018.03.016,Journal,Knowledge-Based Systems,scopus,2018-07-01,sciencedirect,Enhancing user creativity: Semantic measures for idea generation,https://api.elsevier.com/content/abstract/scopus_id/85044259734,"Human creativity generates novel ideas to solve real-world problems. This thereby grants us the power to transform the surrounding world and extend our human attributes beyond what is currently possible. Creative ideas are not just new and unexpected, but are also successful in providing solutions that are useful, efficient and valuable. Thus, creativity optimizes the use of available resources and increases wealth. The origin of human creativity, however, is poorly understood, and semantic measures that could predict the success of generated ideas are currently unknown. Here, we analyze a dataset of design problem-solving conversations in real-world settings by using 49 semantic measures based on WordNet 3.1 and demonstrate that a divergence of semantic similarity, an increased information content, and a decreased polysemy predict the success of generated ideas. The first feedback from clients also enhances information content and leads to a divergence of successful ideas in creative problem solving. These results advance cognitive science by identifying real-world processes in human problem solving that are relevant to the success of produced solutions and provide tools for real-time monitoring of problem solving, student training and skill acquisition. A selected subset of information content (IC Sánchez–Batet) and semantic similarity (Lin/Sánchez–Batet) measures, which are both statistically powerful and computationally fast, could support the development of technologies for computer-assisted enhancements of human creativity or for the implementation of creativity in machines endowed with general artificial intelligence.",science
10.1016/j.asoc.2017.08.034,Journal,Applied Soft Computing Journal,scopus,2018-07-01,sciencedirect,OSFSMI: Online stream feature selection method based on mutual information,https://api.elsevier.com/content/abstract/scopus_id/85029554202,"Feature selection is used to choose a subset of the most informative features in pattern identification based on machine learning methods. However, in many real-world applications such as online social networks, it is either impossible to acquire the entire feature set or to wait for the complete set of features before starting the feature selection process. To handle this issue, online streaming feature selection approaches have been recently proposed to provide a complementary algorithmic methodology by choosing the most informative features. Most of these methods suffer from challenges such as high computational cost, stability of the generated results and the size of the final features subset. In this paper, two novel feature selection methods called OSFSMI and OSFSMI-k are proposed to select the most informative features from online streaming features. The proposed methods employ mutual information concept in a streaming manner to evaluate correlation between features and also to assess the relevancy and redundancy of features in complex classification tasks. The proposed methods do not use any learning model in their search process, and thus can be classified as filter-based methods Several experiments are performed to compare the performance of the proposed algorithms with the state-of-the-art online streaming feature selection methods The reported results show that the proposed methods performs better than the others in most of the cases.",science
10.1016/j.lfs.2018.04.041,Journal,Life Sciences,scopus,2018-06-15,sciencedirect,miRNA-150-5p associate with antihypertensive effect of epigallocatechin-3-gallate revealed by aorta miRNome analysis of spontaneously hypertensive rat,https://api.elsevier.com/content/abstract/scopus_id/85046167889,"Aims
                  The antihypertensive mechanism (s) of the epigallocatechin-3-gallate (EGCG), a major effective component in green tea, might associate with microRNAs (miRNAs). Here, we aimed to investigate which microRNA in aorta of spontaneously hypertensive rats (SHRs) were modulated by administration of EGCG and its mechanism.
               
                  Main methods
                  The pharmacokinetic behaviors of EGCG and epigallocatechin (EGC) in Sprague-Dawley rats were analyzed by HPLC and DRUG AND STATISTICS software. Blood pressure of SHRs was monitored by the tail-cuff method, the miRNomes of aorta from SHRs was analyzed with deep sequencing, and expression of hypertension-associated miRNAs with significant change and their host genes and target genes were validated by real-time PCR and Western blot.
               
                  Key findings
                  The plasma deposition of EGCG and EGC best fitted a mono-compartmental model with maximum plasma concentration post-dose (Cmax, 6.65 vs 4.45 μg/ml) and the corresponding time (Tmax, 15 vs 10 min). Systolic blood pressure (SBP) of SHRs decreased to the lowest point by 34.04 mmHg and recovered by 23.39 mmHg after 15 and 30 min of administration at dose of 300 mg/kg BW EGCG, respectively, and it decreased again at 60 min and recovered at time 2 h. Total 35 upregulated and 18 downregulated miRNAs were identified compared to the control group (p < .01) after EGCG administration. Expression of hypertension-associated miRNA-126a-3p and miRNA-150-5p were further validated. In turn, their host gene and target genes were up-regulated and down-regulated, respectively.
               
                  Significance
                  Our results indicated that miRNA-150-5p might be involved in the antihypertensive effect of EGCG through SP1/AT1R pathway.",science
10.1016/j.actamat.2018.04.011,Journal,Acta Materialia,scopus,2018-06-15,sciencedirect,Sacrificing trap density to achieve short-delay and high-contrast mechanoluminescence for stress imaging,https://api.elsevier.com/content/abstract/scopus_id/85046027882,"Trap-controlled mechanoluminescence (ML) enables the direct observation of stress concentration of load-bearing objects through imaging the ML distribution, showing numerous prospects in stress detection, bio-imaging and optical displays. However, the applications of trap-controlled ML materials universally require long-time delay to fade the noise of symbiotic persistent luminescence (PersL) in order to achieve high-contrast ML images. In view of the difficulty to solve the PersL problem through individually eliminating the PersL traps, herein we propose a novel strategy of sacrificing trap density which decreases PersL and ML traps as a whole. By employing Sr2+ substitution to decrease the trap density of Ca2Nb2O7:Pr3+, we identify a novel composition of (Ca0.5Sr0.5)2Nb2O7:Pr3+ displaying short-delay and high-contrast ML images, and evaluate its practicability through a 2-dimensional in-situ imaging experiment of dynamic stress distribution. The underlying mechanism is ascribed to the greater decrease ratio of PersL intensity than ML intensity as a result of the larger detrapping rate of traps due to stress (leading to ML) than that due to thermal energy (PersL). Furthermore, multi-spectral investigations of (Ca,Sr)2Nb2O7:Pr3+ system reveal a distinctive electron transition process co-regulated by trap levels, charge transfer state and crystal field. The proposed strategy and the associated phosphors are expected to initiate the reconstruction of PersL-type ML materials and bring important implications for real-world stress imaging.",science
10.1016/j.vaccine.2018.05.043,Journal,Vaccine,scopus,2018-06-14,sciencedirect,Plasmid pcDNA3.1-s11 constructed based on the S11 segment of grass carp reovirus as DNA vaccine provides immune protection,https://api.elsevier.com/content/abstract/scopus_id/85046864452,"Although some commercial vaccines against grass carp reovirus (GCRV) are available, given the many varieties of GCRV and limited types of vaccines, the disease caused by GCRV remains a major problem, which leads to economic losses in grass carp aquaculture. A reovirus strain (GCRV-HN14) was recently isolated from local diseased fish in our laboratory. The S11 segment of GCRV-HN14 was speculated to encode the virus capsid protein VP35. In our study, the S11 segment was cloned into the eukaryotic expression vector pcDNA3.1(+) to construct the recombinant plasmid pcDNA3.1-s11, which was then transfected into CIK cells, and the VP35 protein was successfully expressed. Grass carp was immunized with pcDNA3.1-s11, and the in vivo distribution and expression of the pcDNA3.1-s11 plasmids were analyzed by PCR and Western blot. Recombinant plasmids were detected in the blood, liver, spleen, kidney, and muscle. However, protein expression could only be detected in the muscle. The immune protection of the pcDNA3.1-s11 plasmid in grass carp was evaluated using a series of experiments. Results showed that the population of white blood cells significantly increased at 1, 7, and 14 days post-immunization (dpi) and reached a peak with (9.58 ± 0.72) × 107/ml at 7 dpi (P < 0.01 or P < 0.05). The percentage of neutrophils reached a peak with (24.13 ± 2.38)% at 7 dpi (P < 0.01), whereas the lymphocytes peaked with (93.30 ± 4.71)% at 14 dpi (P < 0.05). Serum antibody levels were significantly enhanced in immunized fish at 14, 21, and 28 dpi (P < 0.01). The mRNA expression levels of type I interferon, immunoglobulin M, Toll-like receptor 22, and major histocompatibility complex class I were significantly up-regulated in the head kidney and spleen of immunized fish (P < 0.05). Grass carp immunized with pcDNA3.1-s11 exhibited a higher survival percentage (70.4%–73.3%) than the controls (5%–13%). Overall, as a DNA vaccine, the pcDNA3.1-s11 plasmid could induce immune protection against GCRV.",science
10.1016/j.jep.2017.11.005,Journal,Journal of Ethnopharmacology,scopus,2018-06-12,sciencedirect,Anti-thrombotic and pro-angiogenic effects of Rubia cordifolia extract in zebrafish,https://api.elsevier.com/content/abstract/scopus_id/85044162661,"Ethnopharmacological relevance
                  
                     Rubia cordifolia is a common traditional Chinese medicine that promotes blood circulation and eliminates blood stasis, and has been used to cure diseases related to blood stasis syndrome (BSS) clinically for many years. It has been previously demonstrated that anti-thrombosis and pro-angiogenesis can improve BSS. However, the anti-thrombotic and pro-angiogenic activities of Rubia cordifolia have not been well investigated.
               
                  Aim of study
                  To determine the potential anti-thrombotic and pro-angiogenic activities of Rubia cordifolia and to elucidate the underlying mechanisms. In addition, the major chemical constituents of Rubia cordifolia extract (QC) were qualitatively analysed by UPLC-Q-TOF/MS to explore the association between pharmacological activity and chemical constituents.
               
                  Material and methods
                  The QC samples were composed of a 95% ethanol extract and an aqueous extract following extraction using 95% ethanol. UPLC-Q-TOF/MS was used to analyse the major chemical constituents of QC. For the anti-thrombotic experiment of QC, a phenylhydrazine (PHZ)-induced AB strain zebrafish thrombosis model was used. The zebrafish larvae were stained using O-dianisidine, and the heart and caudal vein of the zebrafish were observed and imaged with a fluorescence microscope. The staining intensity of erythrocytes in the heart (SI) of each group and the morphology of thrombus in the caudal vein were used to assess the anti-thrombotic effect of QC. For the pro-angiogenic assay of QC, the intersegmental blood vessel (ISV) insufficiency model of Tg(fli-1: EGFP)y1 transgenic zebrafish (Flik zebrafish), which was induced by the VEGF receptor tyrosine kinase inhibitor II (VRI), was used. The morphology of the intact ISVs and defective ISVs was observed to evaluate the pro-angiogenic activity of QC. The mechanism involved in promoting angiogenesis was studied with real-time PCR.
               
                  Results
                  A total of 12 components in QC were identified based on standard compounds and references, including nine anthraquinones and three naphthoquinones. After treatment with QC, the PHZ-induced thrombosis in AB strain zebrafish larvae decreased to a certain degree, which we believe was related to its dosages, and the therapeutic effect within the 50–200 µg/mL QC treatment groups was especially prominent (P < 0.01, P < 0.001) compared to that in the PHZ model group. Similarly, QC also recovered the loss of the ISVs, which was induced by VRI in Flik zebrafish larvae, which have a certain dose-effect relationship. The pro-angiogenic activity of QC was also conspicuous (P < 0.01, P < 0.001) compared to that of the VRI model group. The following real-time PCR assay proved that QC significantly restored the VRI-induced downregulation of vWF, VEGF-A, kdrl, and flt-1 in Flik zebrafish (P < 0.05, P < 0.01, P < 0.001).
               
                  Conclusions
                  A total of 12 compounds from QC were analysed by UPLC-Q-TOF/MS. The data of the pharmacological experiments demonstrated that QC presented anti-thrombotic and pro-angiogenic activities in zebrafish, and the principal active components were likely anthraquinones and naphthoquinones. Thus, the current study provided a theoretical basis for the clinical use of Rubia cordifolia as a traditional Chinese medicine in promoting blood circulation and eliminating stasis.",science
10.1016/j.ins.2018.03.023,Journal,Information Sciences,scopus,2018-06-01,sciencedirect,Fast multi-subsequence monitoring on streaming time-series based on Forward-propagation,https://api.elsevier.com/content/abstract/scopus_id/85044134627,"Streaming time-series has drawn unprecedented interests from the computer science researchers. It requires faster execution time and less memory space than traditional approaches in processing historical time-series. Given the real-time constraint in the analysis over streaming time-series, a proper pre-processing step may not even be applicable. Subsequence monitoring is one of the main functions used in a wide range of time series related applications, e.g. quantitative trading in the stock market. In this paper, we propose a novel approach for multi- subsequence monitoring on streaming time-series. The proposed Forward-propagation NSPRING (FPNS) approach is inspired by the forward propagation mechanism in Artificial Neural Networks (ANN). In our proposed approach the concept of forward propagation is adopted to by-pass the unnecessary calculations as in NSPRING where the whole matrix is computed for the final result. FPNS computes a small part of the matrix by indexing only the necessary calculations with the aid of the forward propagation mechanism. As a result, FPNS can effectively reduce the execution time. In the experiments, we compared the scalability, execution time and memory requirement of FPNS, NSPRING, and UCR-DTW using synthetic and real datasets. The experimental results show that on average, FPNS is about three times faster than NSPRING and one order of magnitude faster than UCR-DTW. In addition, FPNS preserves the same accuracy with NSPRING while FPNS runs much faster than NSPRING.",science
10.1016/j.asoc.2018.02.026,Journal,Applied Soft Computing Journal,scopus,2018-06-01,sciencedirect,Meta-Lamarckian learning in multi-objective optimization for mobile social network search,https://api.elsevier.com/content/abstract/scopus_id/85043530128,"Mobile Social Networks (MSNs) have recently brought a revolution in socially-oriented applications and services for mobile phones. In this paper, we consider the search problem in a MSN that aims at simultaneously maximizing the user's search outcome (recall) and mobile phone performance (battery usage). Because of the conflicting nature of these two objectives, the problem is dealt within the context of Multi-Objective Optimization (MOO). Our proposed approach hybridizes a Multi-objective Evolutionary Algorithm based on Decomposition (MOEA/D) with a Meta-Lamarckian (ML) learning strategy that learns from the problem's properties and objective functions. The ML strategy is devised for adaptively select the best performing local search heuristic for each case, from a pool of general-purpose heuristics, so as to locally optimize the solutions during the evolution. We evaluated our propositions on a realistic multi-objective MSN search problem using trace-driven experiments with real mobility and social patterns. Extensive experimental studies reveal that the proposed method successfully learns the behaviour of individual local search heuristics during the evolution, adaptively follows the pattern of the best performing heuristics at different areas of the objective space and offers better performance in terms of both convergence and diversity than its competitors.
                  The proposed Meta-Lamarckian based MOEA does not utilize any problem-specific heuristics, as most cases in the literature do, facilitating its applicability to other combinatorial MOO problems. To test its generalizability the proposed method is also evaluated on various test instances of the well-studied multi-objective Permutation Flow Shop Scheduling Problem.",science
10.1016/j.knosys.2018.03.005,Journal,Knowledge-Based Systems,scopus,2018-06-01,sciencedirect,Unsupervised geographically discriminative feature learning for landmark tagging,https://api.elsevier.com/content/abstract/scopus_id/85043325506,"Recently, a large number of geo-tagged landmark images have been uploaded through various social media services. Usually, these geo-tagged images are annotated by users with GPS and tags related to the landmarks where they are taken. Landmark tagging aims to automatically annotate an image with the tags to describe the landmark where the image is taken. It has been observed that the images and tags show strong correlation with the geographical locations. The widely used assumption by many existing tagging methods is that images are independently and identically distributed is not effective to capture the geographical correlation. In this paper, we study the novel problem of utilizing the geographical correlation among images and landmarks for better tagging landmark images. In particular, we propose an unsupervised feature learning approach to learn the geographically discriminative features across geographical locations, by integrating latent space learning and geographically structural analysis (LSGSA) into a joint model. A latent space learning model is proposed to effectively fuse the heterogeneous features of visual content and tags. Meanwhile, the geographical structure analysis and group sparsity are applied to learn the geographically discriminative features. Then, a geo-guided sparse reconstruction method is proposed to tag images by utilizing the discriminative information of features, in which the landmark-specific tags are boosted by a weighting method. Experiments on the real-world datasets demonstrate the superiority of our approach.",science
10.1016/j.knosys.2018.03.002,Journal,Knowledge-Based Systems,scopus,2018-06-01,sciencedirect,SocksCatch: Automatic detection and grouping of sockpuppets in social media,https://api.elsevier.com/content/abstract/scopus_id/85042924912,"Since 2004, online social media (OSN) have evolved hugely. This fast development had interesting effects to increase the connection and information exchange of users, but some negative effects also appeared, including fake accounts number growing day after day.
                  The sockpuppets are the multiple fake accounts created by the same user. They are the source of several types of manipulation such as those created to praise, defend or support a person or organization or to manipulate public opinion.
                  In this article, we present SocksCatch, a complete process to detect and group sockpuppets which is composed of three main phases: first phase is the data collection and selection; second phase is the detection of the sockpuppet accounts using machine learning algorithms; third phase is the grouping of sockpuppet accounts created by the same user using graph theory.
                  Experiments have been performed for the three phases using real data crawled from english Wikipedia. The results compare six machine learning algorithms for the detection phase and show that SocksCatch detects between 89% and 95% of the selected sockpuppets depending on the algorithms. We also compare five community detection algorithms for the grouping phase, and show that SocksCatch’s grouped sockpuppets and the real sockpuppet’s groups are similar between 80% and 88%, according to the cluster’s comparison measures: normalized variation of information (NVI) and normalized mutual information (NMI).",science
10.1016/j.measurement.2018.02.060,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-06-01,sciencedirect,Development of a novel machine vision procedure for rapid and non-contact measurement of soil moisture content,https://api.elsevier.com/content/abstract/scopus_id/85042874145,"Soil moisture measurement is one of the essential management components to decrease water consumption and prevent water stresses in plants. In this study, a fast and non-contact method using machine vision and artificial intelligence was developed so as to make operators capable of having an estimate of soil moisture by taking only one image. Three soil textures along with three levels of added organic matter were applied. Mean comparison and the subsequent stepwise multiple regression were applied to find superior features from different color spaces. ANFIS and stepwise multiple regression were used to predict the soil moisture. Results indicated that the general model could predict the soil moisture with mean absolute error of less than 1.1%. This value reached to 0.3% for some sub-models belonging to the texture–organic matter group. Application of the present method is highly recommended for soil moisture measurement because of simple implementation and potential for online measurements.",science
10.1016/j.ijmedinf.2018.01.015,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,Humanitarian health computing using artificial intelligence and social media: A narrative literature review,https://api.elsevier.com/content/abstract/scopus_id/85040945850,"Introduction
                  According to the World Health Organization (WHO), over 130 million people are in constant need of humanitarian assistance due to natural disasters, disease outbreaks, and conflicts, among other factors. These health crises can compromise the resilience of healthcare systems, which are essential for achieving the health objectives of the sustainable development goals (SDGs) of the United Nations (UN). During a humanitarian health crisis, rapid and informed decision making is required. This is often challenging due to information scarcity, limited resources, and strict time constraints. Moreover, the traditional approach to digital health development, which involves a substantial requirement analysis, a feasibility study, and deployment of technology, is ill-suited for many crisis contexts. The emergence of Web 2.0 technologies and social media platforms in the past decade, such as Twitter, has created a new paradigm of massive information and misinformation, in which new technologies need to be developed to aid rapid decision making during humanitarian health crises.
               
                  Objective
                  Humanitarian health crises increasingly require the analysis of massive amounts of information produced by different sources, such as social media content, and, hence, they are a prime case for the use of artificial intelligence (AI) techniques to help identify relevant information and make it actionable. To identify challenges and opportunities for using AI in humanitarian health crises, we reviewed the literature on the use of AI techniques to process social media.
               
                  Methodology
                  We performed a narrative literature review aimed at identifying examples of the use of AI in humanitarian health crises. Our search strategy was designed to get a broad overview of the different applications of AI in a humanitarian health crisis and their challenges. A total of 1459 articles were screened, and 24 articles were included in the final analysis.
               
                  Results
                  Successful case studies of AI applications in a humanitarian health crisis have been reported, such as for outbreak detection. A commonly shared concern in the reviewed literature is the technical challenge of analyzing large amounts of data in real time. Data interoperability, which is essential to data sharing, is also a barrier with regard to the integration of online and traditional data sources.
                  Human and organizational aspects that might be key factors for the adoption of AI and social media remain understudied. There is also a publication bias toward high-income countries, as we identified few examples in low-income countries. Further, we did not identify any examples of certain types of major crisis, such armed conflicts, in which misinformation might be more common.
               
                  Conclusions
                  The feasibility of using AI to extract valuable information during a humanitarian health crisis is proven in many cases. There is a lack of research on how to integrate the use of AI into the work-flow and large-scale deployments of humanitarian aid during a health crisis.",science
10.1016/j.asoc.2017.05.039,Journal,Applied Soft Computing Journal,scopus,2018-06-01,sciencedirect,Teranga Go!: Carpooling Collaborative Consumption Community with multi-criteria hesitant fuzzy linguistic term set opinions to build confidence and trust,https://api.elsevier.com/content/abstract/scopus_id/85020448290,"Boosting collaborative or participatory consumption is a priority for the European Commission. It is in line with the provisions of the Europe 2020 Strategy, which proposes that consumption of goods and services should take place in accordance with smart, sustainable and inclusive growth. These have motivated us to develop an online community for collaborative consumption centered in the Senegalese community that travels by car from Europe to Africa named Teranga Go!. Carpooling relationships are based on the sense of a real existing community, social experiences among users, and connection through technology, where confidence is the key concept. To help creating values of confidence, trust and safety among the members of the Teranga Go! community, we have implemented an intelligent decision support system in the platform based on computing with words. The participants of a carpooling experience act as experts that assess the driver aptitudes and determine, together with the history of the driver, a linguistic value for the driver's karma which represents the collective opinion of people that have traveled with the driver. The karma is a public label attached to the site user profiles. A Multi-Expert Multi-Criteria Decision Making model is applied using Hesitant Fuzzy Linguistic Terms to represent the expert opinions.",science
10.1016/j.jpba.2018.02.061,Journal,Journal of Pharmaceutical and Biomedical Analysis,scopus,2018-05-30,sciencedirect,A simple blood microdialysis in freely-moving rats for pharmacokinetic–pharmacodynamic modeling study of Shengmai injection with simultaneous determination of drug concentrations and efficacy levels in dialysate,https://api.elsevier.com/content/abstract/scopus_id/85043395317,"Microdialysis is a powerful in vivo sampling technique for pharmacokinetic–pharmacodynamic (PK-PD) modeling of drugs in pre-clinical and clinical studies. However, the noticeable limitations of previous studies using microdialysis were that animals anesthesia in the whole experiment and the combination of microdialysis and blood sampling for drug and (or) effect detection, which can obviously influence PK and PD behavior of drugs. In this study, a simple blood microdialysis sampling system in freely-moving rats was established for simultaneous study of PK and PD of Shengmai injection (SMI) effect on inducing real-time nitric oxide (NO) release on isoproterenol (ISO) induced myocardial ischemia rats. The LC–MS/MS and HPLC with fluorescence detection (HPLC-FLD) methods were developed to determine ginsenside Rg1, Rg2, Re, Rf, Rb1, Rd and Rc, the main effective components of SMI, and NOx
                     −, the main oxidation products of NO, in dialysates respectively. Through simultaneous determination of drug concentrations and NO efficacy levels in dialysate, the developed methods were successfully applied to set up concentration-time and effect-time profiles followed by PK-PD modeling of SMI effect on inducing NO release after intravenous administration of 10.8 mL kg−1 SMI in myocardial ischemia rats. The PK-PD modeling characterized the dose-effect relationships of SMI and behaved good prediction ability. The established blood microdialysis in freely-moving rats is an appealing technology for rational PK-PD studies when selecting suitable blood endogenous micromolecule as effect marker.",science
10.1016/j.vaccine.2017.03.018,Journal,Vaccine,scopus,2018-05-24,sciencedirect,Propagation of Brazilian Zika virus strains in static and suspension cultures using Vero and BHK cells,https://api.elsevier.com/content/abstract/scopus_id/85016059574,"The recent spread of Zika virus (ZIKV) in the Americas and the Pacific has reached alarming levels in more than 60 countries. However, relatively little is known about the disease on a virological and epidemiological level and its consequences for humans. Accordingly, a large demand for in vitro derived Brazilian ZIKV material to support in vitro and in vivo studies has arisen. However, a prompt supply of ZIKV and ZIKV antigens cannot be guaranteed as the production of this virus typically using Vero or C6/36 cell lines remains challenging.
                  Here we present a production platform based on BHK-21 suspension (BHK-21SUS) cells to propagate Brazilian ZIKV at larger quantities in perfusion bioreactors. Scouting experiments performed in tissue culture flasks using adherent BHK-21 and Vero cells have demonstrated similar permissivity and virus yields for four different Brazilian ZIKV isolates. The cell-specific yield of infectious virus particles varied between respective virus strains (1–48PFU/cell), and the ZIKV isolate from the Brazilian state Pernambuco (ZIKVPE) showed to be a best performing isolate for both cell lines. However, infection studies of BHK-21SUS cells with ZIKVPE in shake flasks resulted in poor virus replication, with a maximum titer of 8.9×103
                     PFU/mL. Additional RT-qPCR measurements of intracellular and extracellular viral RNA levels revealed high viral copy numbers within the cell, but poor virus release. Subsequent cultivation in a perfusion bioreactor using an alternating tangential flow filtration system (ATF) under controlled process conditions enabled cell concentrations of about 1.2×107
                     cells/mL, and virus titers of 3.9×107
                     PFU/mL. However, while the total number of infectious virus particles was increased, the cell-specific yield (3.3PFU/cell) remained lower than determined in adherent cell lines. Nevertheless, the established perfusion process allows to provide large amounts of ZIKV material for research and is a first step towards process development for manufacturing inactivated or live-attenuated ZIKV vaccines.",science
10.1016/j.enconman.2018.03.010,Journal,Energy Conversion and Management,scopus,2018-05-15,sciencedirect,Probability density forecasting of wind power using quantile regression neural network and kernel density estimation,https://api.elsevier.com/content/abstract/scopus_id/85043471018,"Owing to the increasingly serious social energy crisis nowadays, wind power and other renewable energy are paid more attention. However, penetration of wind power prominently enhances the degree of complexity and difficulty in planning and dispatching of electric power systems. High-precision and more-information short term wind power forecasting (STWPF) results can effectively alleviate the uncertainly of wind power and balance the electrical power. Kernel function and bandwidth selection method have significant impact on the results of STWPF. A hybrid wind power probability density prediction method based on quantile regression neural network and Epanechnikov kernel function using Unbiased cross-validation (QRNNE-UCV) is presented. The wind power predicting results at different conditional quantiles are used as the input of kernel density estimation (KDE), which is capable of estimating the comprehensive wind power probability density forecasting information at any time in the future. In order to evaluate the wind power prediction results, the paper constructs two evaluation criteria, including evaluation metrics of point prediction results and evaluation metrics of prediction interval (PI). As a point prediction result, the probability mean is first constructed in the paper. Two real datasets of wind power from Ontario, Canada, are used to verify the QRNNE-UCV method. Moreover, by comparing with the probability density results at various confidence levels, the influence of confidence level on STWPF is investigated in this article. Experiment results show that the QRNNE-UCV method can construct more accurate PI and probability density curves, and the calculated probability mean is superior to the other point predictions. Meanwhile, the quality of PICP and PINAW improves with the increase of confidence level. The above prediction results have the ability to validly quantify the indeterminacy of wind power generation in contrast to existing support vector quantile regression (SVQR) and quantile regression neural network and triangle kernel function (QRNNT) probability density forecasting methods.",science
10.1016/j.bios.2018.01.018,Journal,Biosensors and Bioelectronics,scopus,2018-05-15,sciencedirect,Fast and sensitive near-infrared fluorescent probes for ALP detection and 3d printed calcium phosphate scaffold imaging in vivo,https://api.elsevier.com/content/abstract/scopus_id/85041332697,"Alkaline phosphatase (ALP) is a critical biological marker for osteoblast activity during early osteoblast differentiation, but few biologically compatible methods are available for its detection. Here, we describe the discovery of highly sensitive and rapidly responsive novel near-infrared (NIR) fluorescent probes (NIR-Phos-1, NIR-Phos-2) for the fluorescent detection of ALP. ALP cleaves the phosphate group from the NIR skeleton and substantially alters its photophysical properties, therefore generating a large “turn-on” fluorescent signal resulted from the catalytic hydrolysis on fluorogenic moiety. Our assay quantified ALP activity from 0 to 1.0UmL−1 with a 10−5−10−3
                     UmL−1 limit of detection (LOD), showing a response rate completed within 1.5min. A potentially powerful approach to probe ALP activity in biological systems demonstrated real-time monitoring using both concentration- and time-dependent variations of endogenous ALP in live cells and animals. Based on high binding affinity to bone tissue of phosphate moiety, bone-like scaffold-based ALP detection in vivo was accessed using NIR probe-labeled three-dimensional (3D) calcium deficient hydroxyapatite (CDHA) scaffolds. They were subcutaneously implanted into mice and monitored ALP signal changes using a confocal imaging system. Our results suggest the possibility of early-stage ALP detection during neo-bone formation inside a bone defect, by in vivo fluorescent evaluation using 3D CDHA scaffolds.",science
10.1016/j.jtbi.2018.02.015,Journal,Journal of Theoretical Biology,scopus,2018-05-14,sciencedirect,An approach for reduction of false predictions in reverse engineering of gene regulatory networks,https://api.elsevier.com/content/abstract/scopus_id/85042729548,"A gene regulatory network discloses the regulatory interactions amongst genes, at a particular condition of the human body. The accurate reconstruction of such networks from time-series genetic expression data using computational tools offers a stiff challenge for contemporary computer scientists. This is crucial to facilitate the understanding of the proper functioning of a living organism. Unfortunately, the computational methods produce many false predictions along with the correct predictions, which is unwanted. Investigations in the domain focus on the identification of as many correct regulations as possible in the reverse engineering of gene regulatory networks to make it more reliable and biologically relevant. One way to achieve this is to reduce the number of incorrect predictions in the reconstructed networks. In the present investigation, we have proposed a novel scheme to decrease the number of false predictions by suitably combining several metaheuristic techniques. We have implemented the same using a dataset ensemble approach (i.e. combining multiple datasets) also. We have employed the proposed methodology on real-world experimental datasets of the SOS DNA Repair network of Escherichia coli and the IMRA network of Saccharomyces cerevisiae. Subsequently, we have experimented upon somewhat larger, in silico networks, namely, DREAM3 and DREAM4 Challenge networks, and 15-gene and 20-gene networks extracted from the GeneNetWeaver database. To study the effect of multiple datasets on the quality of the inferred networks, we have used four datasets in each experiment. The obtained results are encouraging enough as the proposed methodology can reduce the number of false predictions significantly, without using any supplementary prior biological information for larger gene regulatory networks. It is also observed that if a small amount of prior biological information is incorporated here, the results improve further w.r.t. the prediction of true positives.",science
10.1016/j.saa.2018.01.067,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2018-05-05,sciencedirect,Simultaneous determination of Magnolol and Honokiol by amino acid ionic liquid synchronous fluorescence spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85041798656,"A novel method based on amino acid ionic liquids (AAILs) as an additive synchronous fluorescence spectrometry is proposed for simultaneous determination of magnolol (MN) and honokiol (HN) in traditional Chinese medicine Houpu. The overlapping fluorescence spectrum of MN and HN could be completely separated in the AAILs medium. Experiment parameters (the type and concentration of AAILs, pH values and temperature) were discussed. The detection limits of MN and HN reached 1.46ng/mL, 0.92ng/mL and the recovery rates ranged from 98.6%–100.7%, 99.7%–100.6%, respectively. This methods was successfully employed for simultaneously determination of MN and HN in real samples. No significant differences could be found in the results of this method and the pharmacopoeia of People's Republic of China 2015 (Ch.P.2015). The experiment mechanisms were discussed by the Gaussian simulation and fluorescence quantum yield.",science
10.1016/j.psyneuen.2018.02.036,Journal,Psychoneuroendocrinology,scopus,2018-05-01,sciencedirect,The role of oxytocin in implicit personal space regulation: An fMRI study,https://api.elsevier.com/content/abstract/scopus_id/85044470578,"Personal space, defined as the distance individuals choose to maintain between themselves and others, is an indicator of affiliation and closeness. Most paradigms that measure personal space preferences involve explicit choice and therefore fail to examine the implicit aspects of such preferences. In the current study, we sought to investigate an implicit form of interpersonal space that is more closely related to real-life situations involving affiliation. We studied the effects of oxytocin (OT) on neural networks that involve affiliation and tested the impact on personal space preferences. In a double-blind placebo-controlled study, we asked participants to choose between two rooms that differed only in the distances between two stimuli. The stimuli were either social stimuli (two chairs) or non-social stimuli (table and plant). The behavioral results showed that OT caused participants to choose a closer space in social blocks but did not affect their choices in non-social blocks. Imaging results revealed an interaction between stimulus and treatment (OT/PL) in the dorsal striatum, an area that is related to approach motivation and is part of the reward circuitry. Specifically, OT increased activity in the dorsal striatum in the social blocks and decreased this activity in the non-social blocks. The results of the study strengthen the social salience theory regarding OT, indicating that OT does not uniformly affect all social responses and that context has a determining impact on our behavior.",science
10.1016/j.ultsonch.2018.01.002,Journal,Ultrasonics Sonochemistry,scopus,2018-05-01,sciencedirect,Ultrasonically synthesis of Mn- and Cu- @ ZnS-NPs-AC based ultrasound assisted extraction procedure and validation of a spectrophotometric method for a rapid preconcentration of Allura Red AC (E129) in food and water samples,https://api.elsevier.com/content/abstract/scopus_id/85040001223,"This study is devoted on Allura Red as food colorant preconcentration and determination in beverage, fruit juice and drink water samples is based on usage of Mn- and Cu- @ ZnS-NPs-AC as new sorbent for ultrasound-assisted-dispersive solid-phase microextraction (UA-DSPME) combined with ultraviolet–visible spectrophotometric based method (UV–Vis). Contribution of volume of eluent, pH, sorbent mass and sonication time on response following conduction of 28 experiments were optimized and investigated while their significantly justified according to p-value. Values of “Prob > F” less than 0.0500 is proportional with their significant influence on recovery of analyte. Under the optimum conditions 0.14 mL of THF; pH of 2.5; 8 mg of sorbent and 3 min sonication time guide and help achievement of limit of quantification (LOQ) and limit of detection (LOD) of 6.08 and 20.26 ng mL−1, respectively. The accuracy of method was validated according to calculation of recovery following spiking 400 and 600 ng mL−1 to blank solution and recovery as more reliable indication of accuracy 93.41 and 102.17% recoveries with RSD < 3.5%, which demonstrate the successful applicability of present method for real sample analysis. The maximum sorbent capacity was 50.0 mg g−1 based on Langmuir isotherm as best model with high correlation coefficient. Combination of UA-DSPME and UV–Vis lead to higher sensitivity and lower cost for accurate and repeatable monitoring of Allura Red level in beverage, fruit juice and drink water samples with acceptable recovery and reasonable RSD%.",science
10.1016/j.jneumeth.2017.07.020,Journal,Journal of Neuroscience Methods,scopus,2018-04-15,sciencedirect,Automated face recognition of rhesus macaques,https://api.elsevier.com/content/abstract/scopus_id/85026478684,"Background
                  Rhesus macaques are widely used in biomedical research. Automated behavior monitoring can be useful in various fields (including neuroscience), as well as having applications to animal welfare but current technology lags behind that developed for other species. One difficulty facing developers is the reliable identification of individual macaques within a group especially as pair- and group-housing of macaques becomes standard. Current published methods require either implantation or wearing of a tracking device.
               
                  New method
                  I present face recognition, in combination with face detection, as a method to non-invasively identify individual rhesus macaques in videos. The face recognition method utilizes local-binary patterns in combination with a local discriminant classification algorithm.
               
                  Results
                  A classification accuracy of between 90 and 96% was achieved for four different groups. Group size, number of training images and challenging image conditions such as high contrast all had an impact on classification accuracy. I demonstrate that these methods can be applied in real time using standard affordable hardware and a potential application to studies of social structure.
               
                  Comparison with existing method(s)
                  Face recognition methods have been reported for humans and other primate species such as chimpanzees but not rhesus macaques. The classification accuracy with this method is comparable to that for chimpanzees. Face recognition has the advantage over other methods for identifying rhesus macaques such as tags and collars of being non-invasive.
               
                  Conclusions
                  This is the first reported method for face recognition of rhesus macaques, has high classification accuracy and can be implemented in real time.",science
10.1016/j.neucom.2018.01.034,Journal,Neurocomputing,scopus,2018-04-12,sciencedirect,Question retrieval for community-based question answering via heterogeneous social influential network,https://api.elsevier.com/content/abstract/scopus_id/85041621612,"Community-based question answering platforms have attracted substantial users to share knowledge and learn from each other. As the rapid enlargement of community-based question answering (CQA) platforms, quantities of overlapped questions emerge, which makes users confounded to select a proper reference. It is urgent for us to take effective automated algorithms to reuse historical questions with corresponding answers. In this paper, we focus on the problem with question retrieval, which aims to match historical questions that are relevant or semantically equivalent to resolve one’s query directly. The challenges in this task are the lexical gaps between questions for the word ambiguity and word mismatch problem. Furthermore, limited words in queried sentences cause sparsity of word features. To alleviate these challenges, we propose a novel framework named HSIN which encodes not only the question contents but also the asker’s social interactions to enhance the question embedding performance. More specifically, we apply random walk based learning method with recurrent neural network to match the similarities between asker’s question and historical questions proposed by other users. Extensive experiments on a large-scale dataset from a real world CQA site Quora show that employing the heterogeneous social network information outperforms the other state-of-the-art solutions in this task.",science
10.1016/j.jmsy.2018.04.001,Journal,Journal of Manufacturing Systems,scopus,2018-04-01,sciencedirect,Porosity prediction: Supervised-learning of thermal history for direct laser deposition,https://api.elsevier.com/content/abstract/scopus_id/85045401863,"The objective of this study is to investigate the relationship between the melt pool characteristics and the defect occurrence in an as-built additive manufacturing part. One of the major detrimental microstructure properties associated with additive manufacturing (AM) is porosity within final parts. State-of-the-art porosity detection methods focus primarily on post-manufacturing approaches that are susceptible to high cost of process, longer process time, and are incapable of characterizing pores during fabrication. A real-time porosity prediction method is developed using morphological characteristics of the melt pool boundary (i.e., features obtained via functional principal component analysis (FPCA)). A thermal monitoring system is used to capture the time-varying melt pool signal, which are labeled as either pores or normal melt pools by X-ray tomography. Supervised learning methods are utilized to identify the patterns of melt pool images and build a black-box model for the probability distribution of class labels (namely, porosity) based on data characteristics of predictors (e.g., melt pool characteristics). The resultant model does not depend on specific design of specimens with varying material properties; and can be effectively developed as long as thermal-porosity data can be obtained. In the current study, multiple supervised machine learning approaches are used to classify melt pools to predict porosity in a part. Two different accuracy measures are used and numerical experiments show that among the classification approaches used (i.e., Decision Tree (DT), K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Linear Discriminant Analysis (LDA), and Quadratic Discriminant Analysis (QDA)), KNN results in the highest rate of accurately classifying melt pools (98.44%). However, DT results in the lowest rate for incorrectly identifying normal melt pools as pores (0.03%). A comparative study is conducted that compares the performance of supervised learning methods leveraging the proposed morphological model and simple metrics of the melt pool. Numerical experiments show that the morphological model combined with supervised learning techniques vastly outperform the simple melt pool metrics combined with supervised learning techniques (approximately 250% better performance for correctly predicting abnormal melt pools). Our approach may potentially be applied to other AM processes that share similar energy-material interactions (e.g., powder bed fusion, electron beam melting).",science
10.1016/j.dcn.2018.02.012,Journal,Developmental Cognitive Neuroscience,scopus,2018-04-01,sciencedirect,Social network size relates to developmental neural sensitivity to biological motion,https://api.elsevier.com/content/abstract/scopus_id/85043399583,"The ability to perceive others’ actions and goals from human motion (i.e., biological motion perception) is a critical component of social perception and may be linked to the development of real-world social relationships. Adult research demonstrates two key nodes of the brain’s biological motion perception system—amygdala and posterior superior temporal sulcus (pSTS)—are linked to variability in social network properties. The relation between social perception and social network properties, however, has not yet been investigated in middle childhood—a time when individual differences in social experiences and social perception are growing. The aims of this study were to (1) replicate past work showing amygdala and pSTS sensitivity to biological motion in middle childhood; (2) examine age-related changes in the neural sensitivity for biological motion, and (3) determine whether neural sensitivity for biological motion relates to social network characteristics in children. Consistent with past work, we demonstrate a significant relation between social network size and neural sensitivity for biological motion in left pSTS, but do not find age-related change in biological motion perception. This finding offers evidence for the interplay between real-world social experiences and functional brain development and has important implications for understanding disorders of atypical social experience.",science
10.1016/j.energy.2018.01.159,Journal,Energy,scopus,2018-04-01,sciencedirect,Multiobjective optimization of ethylene cracking furnace system using self-adaptive multiobjective teaching-learning-based optimization,https://api.elsevier.com/content/abstract/scopus_id/85041748366,"The ethylene cracking furnace system is crucial for an olefin plant. Multiple cracking furnaces are used to convert various hydrocarbon feedstocks to smaller hydrocarbon molecules, and the operational conditions of these furnaces significantly influence product yields and fuel consumption. This paper develops a multiobjective operational model for an industrial cracking furnace system that describes the operation of each furnace based on current feedstock allocations, and uses this model to optimize two important and conflicting objectives: maximization of key products yield, and minimization of the fuel consumed per unit ethylene. The model incorporates constraints related to material balance and the outlet temperature of transfer line exchanger. The self-adaptive multiobjective teaching-learning-based optimization algorithm is improved and used to solve the designed multiobjective optimization problem, obtaining a Pareto front with a diverse range of solutions. A real industrial case is investigated to illustrate the performance of the proposed model: the set of solutions returned offers a diverse range of options for possible implementation, including several solutions with both significant improvement in product yields and lower fuel consumption, compared with typical operational conditions.",science
10.1016/j.pupt.2018.01.012,Journal,Pulmonary Pharmacology and Therapeutics,scopus,2018-04-01,sciencedirect,"Therapeutic administration of inhaled INS1009, a treprostinil prodrug formulation, inhibits bleomycin-induced pulmonary fibrosis in rats",https://api.elsevier.com/content/abstract/scopus_id/85041702503,"Idiopathic pulmonary fibrosis is a progressive and lethal disease and while there are now two approved drugs (Esbriet® and Ofev®) additional effective treatments are still needed. Recently, prostacyclin analogs such as iloprost and treprostinil (TRE) have been shown to exert some protection against bleomycin-induced pulmonary fibrosis in mice when administered in a prophylactic regimen. In this study, we evaluated the effect of the inhaled treprostinil prodrug hexadecyl-treprostinil (C16TR) formulated in a lipid nanoparticle (INS1009) administered therapeutically in a fibrotic rat model. Male Fischer 344 rats challenged with intra-tracheal saline instillation were then treated with daily inhaled phosphate buffered saline (PBS) while rats challenged with bleomycin sulfate (3.5–4.0 mg/kg) instillation were treated with either daily inhaled PBS, daily inhaled INS1009 (10, 30, or 100 μg/kg), or twice-daily orally with the anti-fibrotic compound pirfenidone (100 mg/kg). Dosing started on day 10 post-bleomycin challenge and continued until day 27 after bleomycin. Lungs were harvested 24 h after the last dose of treatment for evaluation of lung hydroxyproline content and pulmonary histology. Lung hydroxyproline content increased from 421 μg/lung lobe in saline challenged and PBS treated animals to 673 μg/lung lobe in bleomycin challenged and PBS treated rats. Treatment of bleomycin challenged rats with 10, 30, or 100 μg/kg INS1009 dose-dependently reduced lung hydroxyproline content to 563, 501, and 451 μg/lung lobe, respectively, and pirfenidone decreased hydroxyproline content to 522 μg/lung lobe. Histologically, both INS1009 (100 μg/kg) and pirfenidone (100 mg/kg) reduced the severity of subepithelial fibrosis. Single dose pharmacokinetic (PK) studies of inhaled INS1009 in bleomycin challenged rats showed dose-dependent increases in lung C16TR concentration and plasma TRE on day 10 post-bleomycin challenge. Multiple dose PK studies of inhaled INS1009 showed dose-dependent increases only in lung C16TR concentration on day 27 post-bleomycin challenge. We also investigated the effects of TRE on the cytokine transforming growth factor-β1 (TGF-β1)-stimulated collagen gene and protein expressions in cultured human lung fibroblasts, assessed by real-time PCR and Sirius Red staining, respectively. In human fibroblasts, TRE (0.001–10 μM) inhibited TGF-β1 (20 ng/mL)-induced expression of collagen mRNA and protein in a concentration-dependent manner. These results demonstrated that inhaled INS1009, administered in a therapeutic dosing paradigm, dose-dependently (10–100 μg/kg) inhibited bleomycin-induced pulmonary fibrosis in rats. This effect may involve direct actions of TRE in suppressing collagen expression in lung fibroblasts.",science
10.1016/j.cmpb.2018.01.015,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-04-01,sciencedirect,Automatic energy expenditure measurement for health science,https://api.elsevier.com/content/abstract/scopus_id/85041430221,"Background and objective
                  It is crucial to predict the human energy expenditure in any sports activity and health science application accurately to investigate the impact of the activity. However, measurement of the real energy expenditure is not a trivial task and involves complex steps. The objective of this work is to improve the performance of existing estimation models of energy expenditure by using machine learning algorithms and several data from different sensors and provide this estimation service in a cloud-based platform.
               
                  Methods
                  In this study, we used input data such as breathe rate, and hearth rate from three sensors. Inputs are received from a web form and sent to the web service which applies a regression model on Azure cloud platform. During the experiments, we assessed several machine learning models based on regression methods.
               
                  Results
                  Our experimental results showed that our novel model which applies Boosted Decision Tree Regression in conjunction with the median aggregation technique provides the best result among other five regression algorithms.
               
                  Conclusions
                  This cloud-based energy expenditure system which uses a web service showed that cloud computing technology is a great opportunity to develop estimation systems and the new model which applies Boosted Decision Tree Regression with the median aggregation provides remarkable results.",science
10.1016/j.jenvman.2018.01.009,Journal,Journal of Environmental Management,scopus,2018-04-01,sciencedirect,Facile synthesis of hierarchical nickel (III) oxide nanostructure: A synergistic remediating action towards water contaminants,https://api.elsevier.com/content/abstract/scopus_id/85041421044,"Heavy metal ion removal from consumable water is an indispensable need to maintain healthy life. Therefore cost effective and highly efficient sorbents are strongly needed to pose threat to real water pollution. Nanomaterials are widely used to maintain clean aqueous system in a very cost effective way with high removal efficiency. In this present work, pure coral like Ni2O3 nanostructures were prescribed for Cr(VI) remediation which were prepared by two step synthesis procedure at room temperature. The single hierarchical morphology as confirmed from HRTEM (size∼200 nm) were subjected to toxic Cr(VI) ion removal experiments. They were found to remove ∼65% Cr(VI) ions that was higher than that of pure Ni2O3 nanoparticles of comparable size. The enhanced properties were explained on the basis of the defect states present within the nanostructure, investigated by positron annihilation lifetime spectroscopy (PALS). It was found that the hierarchical nanostructure had more number of di-vacancies and vacancy-clusters as compared to the particles. On performing isotherm fitting, it was found that the coral like morphology had a high heterogeneity factor that aided to a high adsorption rate when compared to the pure Ni2O3 nanoparticles (which had a homogenous surface). The synthesized nanostructure was severely toxic to bacterial community having minimum inhibitory concentration (MIC) of ∼300 μg/L. Also the nanostructure exhibited dual functionality towards Cr(VI) and bacteria contaminated water at 200 μg/ml. The maximum Cr(VI) removal efficiency for this dual system is found to be 39% whereas antibacterial activity was turned out to be 30% which was extensively higher than that of toxic Cr(VI) ions. A plausible mechanism for the dual functionality was also predicted.",science
10.1016/j.cptl.2017.12.018,Journal,Currents in Pharmacy Teaching and Learning,scopus,2018-04-01,sciencedirect,Utilizing desirable difficulties for sterile compounding training in a skills-based laboratory course,https://api.elsevier.com/content/abstract/scopus_id/85040361754,"Background and purpose
                  Sterile compounding skills are essential components of a professional pharmacy curriculum. The theory of desirable difficulties has been used to facilitate deeper learning of material in other disciplines, but has not been described in pharmacy sterile compounding instruction. The purpose of this work was to evaluate whether challenges introduced in sterile compounding would act as desirable difficulties and result in greater student confidence in their sterile compounding competency.
               
                  Educational activity and setting
                  Students in the fourth semester of Pharmacy Skills and Applications, a laboratory-based skills course, were presented with challenges in sterile compounding and were asked to complete a questionnaire rating their confidence and describing their experience.
               
                  Findings
                  The majority (92.8%) of students reported that the activity increased their confidence in their sterile compounding skills. Students’ open-ended responses suggested that most of the knowledge gained was strategic in nature.
               
                  Discussion
                  The results of this activity met the instructors’ initial goals by positively impacting students’ confidence in their ability to overcome challenges with sterile products compounding. Course instructors may explore additional skills in which to introduce desirable difficulties in order to build student confidence.
               
                  Summary
                  Course instructors were pleased with the implementation and results of this desirable difficulties activity and plan to continue its use again in future semesters. Incorporating more real-world challenges throughout the skills-lab course may be beneficial to student learning and confidence. With thoughtful planning, faculty at other institutions can readily incorporate similar activities within their own courses.",science
10.1016/j.compmedimag.2017.04.004,Journal,Computerized Medical Imaging and Graphics,scopus,2018-04-01,sciencedirect,Virtual bacterium colony in 3D image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85018988519,"Several heuristic, biologically inspired strategies have been discovered in recent decades, including swarm intelligence algorithms. So far, their application to volumetric imaging data mining is, however, limited. This paper presents a new flexible swarm intelligence optimization technique for segmentation of various structures in three- or two-dimensional images. The agents of a self-organizing colony explore their host, use stigmergy to communicate themselves, and mark regions of interest leading to the object extraction. Detailed specification of the bacterium colony segmentation (BCS) technique in terms of both individual and social behaviour is described in this paper. The method is illustrated and evaluated using several experiments involving synthetic data, computed tomography studies, and ultrasonography images. The obtained results and observations are discussed in terms of parameter settings and potential application of the method in various segmentation tasks.",science
10.1016/j.jep.2017.12.010,Journal,Journal of Ethnopharmacology,scopus,2018-03-25,sciencedirect,Reishi mushroom Ganoderma lucidum Modulates IgA production and alpha-defensin expression in the rat small intestine,https://api.elsevier.com/content/abstract/scopus_id/85039454217,"Ethnopharmacological relevance
                  Immunoglobulin A (IgA) secretion and alpha-defensins play a role in the innate immune system to protect against infection. Ganoderma lucidum (W.Curt.: Fr.) P. Karst. (Reishi) is a well-known mushroom in traditional Chinese medicine. This study aimed to determine the effects of Reishi on IgA secretion from Peyer's patch (PP) cells and alpha-defensin-5 (RD-5) and RD-6 expression in the rat small intestine.
               
                  Materials and methods
                  The rats received an oral injection of 0.5–5mg/kg of Reishi powder (1mL/kg) by sonde. All animals were euthanized 24h after Reishi administration. We examined RD-5, RD-6, and Toll-like receptor (TLR) 4 mRNA levels in the jejunum, ileum, and in Peyer's patches (PP) through quantitative real-time PCR analysis. IgA secretion from PP was measured through enzyme-linked immunosorbent assay of the supernatant after primary culture.
               
                  Results
                  Reishi increased IgA secretion in the presence of lipopolysaccharide (LPS) and increased TLR4 mRNA levels, but had no effect on the viability of PP cells. Moreover, Reishi increased RD-5, RD-6, and TLR4 mRNA levels significantly in the ileum in a concentration-dependent manner.
               
                  Conclusions
                  Reishi can induce IgA secretion and increase the mRNA levels of RD-5 and RD-6 in the rat small intestine, through a TLR4-dependent pathway. The present results indicate that Reishi might reduce the risk of intestinal infection.",science
10.1016/j.jappgeo.2018.01.006,Journal,Journal of Applied Geophysics,scopus,2018-03-01,sciencedirect,Inferring the most probable maps of underground utilities using Bayesian mapping model,https://api.elsevier.com/content/abstract/scopus_id/85044639536,"Mapping the Underworld (MTU), a major initiative in the UK, is focused on addressing social, environmental and economic consequences raised from the inability to locate buried underground utilities (such as pipes and cables) by developing a multi-sensor mobile device. The aim of MTU device is to locate different types of buried assets in real time with the use of automated data processing techniques and statutory records. The statutory records, even though typically being inaccurate and incomplete, provide useful prior information on what is buried under the ground and where. However, the integration of information from multiple sensors (raw data) with these qualitative maps and their visualization is challenging and requires the implementation of robust machine learning/data fusion approaches. An approach for automated creation of revised maps was developed as a Bayesian Mapping model in this paper by integrating the knowledge extracted from sensors raw data and available statutory records. The combination of statutory records with the hypotheses from sensors was for initial estimation of what might be found underground and roughly where. The maps were (re)constructed using automated image segmentation techniques for hypotheses extraction and Bayesian classification techniques for segment-manhole connections. The model consisting of image segmentation algorithm and various Bayesian classification techniques (segment recognition and expectation maximization (EM) algorithm) provided robust performance on various simulated as well as real sites in terms of predicting linear/non-linear segments and constructing refined 2D/3D maps.",science
10.5604/01.3001.0010.8661,Journal,Annals of Hepatology,scopus,2018-03-01,sciencedirect,"Antifibrotic mechanism of pinocembrin: Impact on oxidative stress, inflammation and TGF-β/Smad inhibition in rats",https://api.elsevier.com/content/abstract/scopus_id/85042274081,"Introduction. Type-1 hepatorenal syndrome (HRS-1) portends a poor prognosis in patients with cirrhosis. Currently available medical therapies are largely ineffective, save for liver transplantation. We aimed to determine if pentoxifylline (PTX) therapy in addition to the standard of care of volume expansion with albumin and vasoconstriction with midodrine and octreotide (AMO) is safe and efficacious compared to AMO in HRS-1 treatment.
                  
                     Material and methods. Hospitalized subjects with decompensated cirrhosis and HRS-1 were enrolled. PTX or placebo was administered with AMO therapy for up to 14 days. The primary endpoint was HRS-1 resolution (serum creatinine ≤ 1.5 g/dL for > 24 h). Secondary endpoints were change in creatinine and MELD score, partial treatment response, 30-and 180-day overall and transplant free survival.
                  
                     Results. Twelve subjects with mean age 58.9 ± 6.2 years were enrolled and randomized. Mean MELD score was 26.5 ± 7.4 and 58.3% were male. Overall cohort 30- and 180-day survival was 58.3% and 33.3% respectively. Two subjects underwent liver transplantation. HRS-1 resolution (16.7% vs. 16.7%, p = 1.000), partial treatment response (33.3% vs. 16.7%, p = 0.505), change in creatinine (+0.48 g/dL, 95% CI -0.49-1.46 vs. +0.03 g/dL, 95% CI -0.640.70, p = 0.427), 30-day survival (66.6% vs. 50.0%, p = 0.558) and 180-day survival (50.0% vs. 16.7%, p = 0.221) were similar between the two groups. Serious adverse events necessitating treatment discontinuation were rare (n = 1, PTX).
                  
                     Discussion. The addition of PTX to AMO in the treatment of HRS-1 is safe when compared to the current standard of care. Future large-scale prospective study to validate the efficacy of this treatment seems warranted.",science
10.1016/j.diin.2017.12.003,Journal,Digital Investigation,scopus,2018-03-01,sciencedirect,Criminal motivation on the dark web: A categorisation model for law enforcement,https://api.elsevier.com/content/abstract/scopus_id/85041635143,"Research into the nature and structure of ‘Dark Webs’ such as Tor has largely focused upon manually labelling a series of crawled sites against a series of categories, sometimes using these labels as a training corpus for subsequent automated crawls. Such an approach is adequate for establishing broad taxonomies, but is of limited value for specialised tasks within the field of law enforcement. Contrastingly, existing research into illicit behaviour online has tended to focus upon particular crime types such as terrorism. A gap exists between taxonomies capable of holistic representation and those capable of detailing criminal behaviour. The absence of such a taxonomy limits interoperability between agencies, curtailing development of standardised classification tools.
                  We introduce the Tor-use Motivation Model (TMM), a two-dimensional classification methodology specifically designed for use within a law enforcement context. The TMM achieves greater levels of granularity by explicitly distinguishing site content from motivation, providing a richer labelling schema without introducing inefficient complexity or reliance upon overly broad categories of relevance. We demonstrate this flexibility and robustness through direct examples, showing the TMM's ability to distinguish a range of unethical and illegal behaviour without bloating the model with unnecessary detail.
                  The authors of this paper received permission from the Australian government to conduct an unrestricted crawl of Tor for research purposes, including the gathering and analysis of illegal materials such as child pornography. The crawl gathered 232,792 pages from 7651 Tor virtual domains, resulting in the collation of a wide spectrum of materials, from illicit to downright banal. Existing conceptual models and their labelling schemas were tested against a small sample of gathered data, and were observed to be either overly prescriptive or vague for law enforcement purposes - particularly when used for prioritising sites of interest for further investigation.
                  In this paper we deploy the TMM by manually labelling a corpus of over 4000 unique Tor pages. We found a network impacted (but not dominated) by illicit commerce and money laundering, but almost completely devoid of violence and extremism. In short, criminality on this ‘dark web’ is based more upon greed and desire, rather than any particular political motivations.",science
10.1016/j.jenvrad.2017.12.002,Journal,Journal of Environmental Radioactivity,scopus,2018-03-01,sciencedirect,Nuclear accident consequence assessment in Hong Kong using JRODOS,https://api.elsevier.com/content/abstract/scopus_id/85039756935,"The JRODOS (Java-based Real-time Online DecisiOn Support) is a decision support system for off-site emergency management for releases of radioactive material into the environment. This paper documents the application of JRODOS by the Hong Kong Observatory in accident consequence assessment and emergency preparedness studies. For operational considerations, the most computational efficient dispersion model in JRODOS, ATSTEP, is adopted. Verification studies for JRODOS's ATSTEP model have been conducted. Comparison with tracer experiment results showed that under neutral atmospheric conditions and distances up to 50 km, the JRODOS simulation outputs were in general of the same order of magnitude with the tracer data. To further evaluate the capability of JRODOS in short-range simulation, a case study on the Fukushima nuclear power plant accident was also carried out. JRODOS was able to produce realistic simulation results which were comparable to the actual airborne monitoring data of the Cs-137 ground deposition from the Fukushima accident.
                  Furthermore, the results of a comprehensive study to assess the potential consequences of accidents at a nearby nuclear power station are presented. Simulation using the French S3 source term for the Guangdong Nuclear Power Station at Daya Bay showed that the projected effective doses within Hong Kong remain far below the IAEA generic criteria of projected dose for urgent protective actions in sheltering/evacuation, while the projected equivalent dose in thyroid may meet the IAEA generic criteria for use of thyroid blocking agent at some areas in the northeastern part of Hong Kong, at distances of up to about 40 km from Daya Bay depending on the prevailing weather conditions in different seasons.",science
10.1016/j.inffus.2017.05.003,Journal,Information Fusion,scopus,2018-03-01,sciencedirect,A Social-aware online short-text feature selection technique for social media,https://api.elsevier.com/content/abstract/scopus_id/85019594702,"Large-scale text categorisation in social environments, characterised by the high dimensionality of feature spaces, is one of the most relevant problems in machine learning and data mining nowadays. Short-texts, which are posted at unprecedented rates, accentuate both the importance of learning tasks and the challenges posed by such large feature space. A collection of social media short-texts does not only provide textual information but also topological information given by the relationships between posts and their authors. The linked nature of social data causes new complementary data dimensions to be added to the feature space, which, at the same time, becomes sparser. Additionally, in the context of social media, posts usually arrive simultaneously in streams, which hinders the deployment of efficient traditional feature selection techniques that assume a feature space fully known in advance. Hence, efficient and scalable online feature selection becomes an important requirement in numerous large-scale social applications. This work presents an online feature selection technique for high-dimensional data based on the integration of two information sources, social and content-based, for the real-time classification of short-text streams coming from social media. It focuses on discovering implicit relations amongst new posts, already known ones and their corresponding authors to identify groups of socially related posts. Then, each discovered group is represented by a set of non-redundant and relevant textual features. Finally, such features are used to train different learning models for classifying newly arriving posts. Extensive experiments conducted on real-world short-texts demonstrate that the proposed approach helps to improve classification results when compared to state-of-the-art and traditional online feature selection techniques.",science
10.1016/j.jneumeth.2017.12.014,Journal,Journal of Neuroscience Methods,scopus,2018-02-15,sciencedirect,Extracting information from the shape and spatial distribution of evoked potentials,https://api.elsevier.com/content/abstract/scopus_id/85039751518,"Background
                  Over 90 years after its first recording, scalp electroencephalography (EEG) remains one of the most widely used techniques in human neuroscience research, in particular for the study of event-related potentials (ERPs). However, because of its low signal-to-noise ratio, extracting useful information from these signals continues to be a hard-technical challenge. Many studies focus on simple properties of the ERPs such as peaks, latencies, and slopes of signal deflections.
               
                  New method
                  To overcome these limitations, we developed the Wavelet-Information method which uses wavelet decomposition, information theory, and a quantification based on single-trial decoding performance to extract information from evoked responses.
               
                  Results
                  Using simulations and real data from four experiments, we show that the proposed approach outperforms standard supervised analyses based on peak amplitude estimation. Moreover, the method can extract information using the raw data from all recorded channels using no a priori knowledge or pre-processing steps.
               
                  Comparison with existing method(s)
                  We show that traditional approaches often disregard important features of the signal such as the shape of EEG waveforms. Also, other approaches often require some form of a priori knowledge for feature selection and lead to problems of multiple comparisons.
               
                  Conclusions
                  This approach offers a new and complementary framework to design experiments that go beyond the traditional analyses of ERPs. Potentially, it allows a wide usage beyond basic research; such as for clinical diagnosis, brain-machine interfaces, and neurofeedback applications requiring single-trial analyses.",science
10.1016/j.jep.2017.10.017,Journal,Journal of Ethnopharmacology,scopus,2018-02-15,sciencedirect,Effects of Danhong Injection on platelet aggregation in hyperlipidemia rats,https://api.elsevier.com/content/abstract/scopus_id/85032172151,"Ethnopharmacological relevance
                  Danhong Injection (DHI), a Chinese medical product extracted from Radix et Rhizoma Salviae Miltiorrhizae (Salvia miltiorrhiza Bge., Labiatae, Danshen in Chinese) and Flos Carthami (Carthamus tinctorius L., Compositae, Honghua in Chinese), has been reported to have effects on inflammatory, anti-fibrinolytic properties, antithrombotic and decrease blood-lipid. It is extensively used for the clinical treatment of cardiovascular disease. This study aimed to investigate the effects of DHI on blood-lipid levels and platelet aggregation rate in hyperlipidemia rats.
               
                  Materials and methods
                  Rats were randomly divided into 6 groups: normal control (NC), model control (MC), DHI-treated control at doses of 1.0mL/kg, 2.0mL/kg, 4.0mL/kg, respectively, and Simvastatin positive control at dose of 2.0mg/kg. All DHI treated groups were intraperitoneally injected for 7 days. The effects of DHI on serum triglyceride (TG), total cholesterol (TC), low density lipoprotein cholesterol (LDL-C) and high density lipoprotein cholesterol (HDL-C) were evaluated. And platelet activating factor (PAF), platelet membrane glycoprotein IIb/IIIa (GP IIb/IIIa) and 6-keto-prostaglandin F1а (6-K-PGF1а) were determined by enzyme-linked immunosorbent assay (ELISA). Moreover, the expression of prostaglandin I-2 (PGI2), prostaglandin E-2 (PGE2) and thromboxane A2 (TXA2) in liver was determined by real-time PCR.
               
                  Results
                  Compared with the MC group, the rats treated with DHI had significantly reduced TC, TG, LDL-C, FIB, GP IIb/IIIa and platelet aggregation. Meanwhile, the thrombin time (TT), activated partial thrombin time (APTT), prothrombin time (PT), 6-K-PGF1а was significantly increased. Expression of PGI2 and PGE2 mRNA was significantly increased, whereas the TXA2 was significantly reduced.
               
                  Conclusions
                  This study demonstrated that the blood lipid and platelet aggregation has a regulatory effect after DHI treatment. The insights gained from this study will improve understanding of the mechanisms involved in the effect of DHI on hyperlipidemia and the pharmacological rationale for the use of DHI in diseases caused by formation of thrombosis and lipid metabolic disorders.",science
10.1016/j.ynstr.2018.02.001,Journal,Neurobiology of Stress,scopus,2018-02-01,sciencedirect,c-Fos mapping of brain regions activated by multi-modal and electric foot shock stress,https://api.elsevier.com/content/abstract/scopus_id/85043513508,"Real-world stressors are complex and multimodal, involving physical, psychological, and social dimensions. However, the brain networks that mediate stress responses to these stimuli need to be further studied. We used c-Fos mapping in mice to characterize brain circuits activated by exposure to a single episode of multimodal stress (MMS), and compared these to circuits activated by electric foot shocks (EFS). We focused on characterizing c-Fos activity in stress-relevant brain regions including the paraventricular nucleus (PVN) of the hypothalamus and the bed nucleus of the stria terminalis (BNST). We also assessed stress-induced activation of CRH-positive neurons in each of these structures. MMS and EFS activated an overlapping network of brain regions with a similar time course. c-Fos expression within the PVN and the BNST peaked 30–60 min after exposure to both MMS and EFS, and returned to baseline levels within 24 h. Quantification of c-Fos expression within BNST subregions revealed that while c-Fos expression peaked in all subregions 30–60 min after MMS and EFS exposure, the neuronal density of c-Fos expression was significantly higher in the dorsomedial and ventral BNST relative to the dorsolateral BNST. Our preliminary assessment indicated that a great majority of MMS or EFS-activated neurons in the PVN were CRH-positive (>87%); in contrast, about 6–35% of activated neurons in the BNST were CRH-positive. Our findings indicate that both MMS and EFS are effective at activating stress-relevant brain areas and support the use of MMS as an effective approach for studying multidimensional stress in animal models. The results also reveal that the PVN and BNST are part of a common neural circuit substrate involved in neural processing related to stress.",science
10.1016/j.vetmic.2017.12.019,Journal,Veterinary Microbiology,scopus,2018-02-01,sciencedirect,Evaluation of a peroxygen-based disinfectant for inactivation of porcine epidemic diarrhea virus at low temperatures on metal surfaces,https://api.elsevier.com/content/abstract/scopus_id/85039794048,"Porcine epidemic diarrhea virus (PEDV) spread rapidly across the United States in part due to contaminated livestock trailers. The objective of this study was to test a peroxygen-based disinfectant for the ability to inactivate PEDV on aluminum surfaces at 4 °C or −10 °C. Forty 3-week-old individually housed barrows were used as a bioassay to determine the infectivity of PEDV after treatment with either a 1:100 or 1:600 dilution of a peroxygen-based disinfectant with 10 or 30 min of contact time. One coupon matched to one pig was the experimental unit. Coupons in the positive control and disinfectant treatment groups were contaminated with 2 mL of feces spiked with PEDV. A negative control group was contaminated with PEDV-negative feces. Following treatment, the feces and disinfectant remaining in the coupons was collected and administered to pigs intragastrically. Rectal swabs were collected from pigs 3 and 7 days post-inoculation (DPI) and tested for PEDV by RT-qPCR. Samples from all coupons, except the negative control, were positive by RT-qPCR for PEDV before and after treatment. All rectal swabs from the pigs in the negative control and the seven disinfectant treatment groups were RT-qPCR negative for PEDV on 3 and 7 DPI. All pigs in the positive control at 4 °C and 3 of 4 pigs in the positive control conducted at −10 °C were RT-qPCR positive for PEDV on 3 and 7 DPI. Both the 1:100 and 1:600 dilutions of peroxygen-based disinfectant successfully inactivated PEDV under the conditions of this study.",science
10.1016/j.ecolind.2017.11.031,Journal,Ecological Indicators,scopus,2018-02-01,sciencedirect,Multiclass classification methods in ecology,https://api.elsevier.com/content/abstract/scopus_id/85036460929,"Multiclass classification refers to the construction of a model able to classify a response variable that can take more than two classes. Most ecological indices are naturally multiclass (e.g. water quality index: bad, regular, good) and the generation of models able to predict the output class in novel situations is required. In this study, we introduce seven representative multiclass classification techniques, classic and more recent, their rationale, advantages, disadvantages and a practical R code to implement them. These methods are: (1) Linear discriminant analysis (LDA), (2) a consensus of binomial logistic regression (CLR), (3) multinomial regression (MNR) and (4) support vector machine (SVM), (5) Classification and Regression Trees (CART), (6) Random Forest (RF) and (7) Stagewise Additive Modelling using a Multi-class Exponential (SAMME) loss function. We showed their implementation under simulated and a real data set to classify phytoplankton organisms into morphology-based functional groups. Results suggest that the nature of the data (i.e. linear vs non-linear) influence the predictive ability of multi-class classification models. Real phytoplankton data was accurately classified (error<0.05) by RF, SAMME and CLR, while SVM and CART were close to nominal 0.05 and LDA performed worst, with the higher error rate (ca. 0.7). The expected behaviour of the response variable should be considered when choosing a model for multiclass classification. The use of the generalization error allows to objectively rank among competing models. We showed the differences in interpretability among models, which is critical to decipher causal relationships among variables or to design management plans. We hope this article contributes to increase the use of these techniques, some of them flexible and distribution-free, and to improve the quality of multiclass classification models applied to ecological problems.",science
10.1016/j.asoc.2017.11.014,Journal,Applied Soft Computing Journal,scopus,2018-02-01,sciencedirect,CC-GA: A clustering coefficient based genetic algorithm for detecting communities in social networks,https://api.elsevier.com/content/abstract/scopus_id/85035017527,"A community structure is an integral part of a social network. Detecting such communities plays an important role in a wide range of applications, including but not limited to cluster analysis, recommendation systems and understanding the behaviour of complex systems. Researchers have derived many algorithms to discover the community structures of networks. Discovering communities is a challenging task, and there is no single algorithm that produces the best results for all networks. Therefore, despite many elegant solutions, discovering communities remains an active area of research. In this paper, we propose a novel algorithm, the Clustering Coefficient-based Genetic Algorithm (CC-GA), for detecting them in social and complex networks. Researchers have used several genetic algorithms to detect communities, but the proposed algorithm is novel in terms of both the generation of the initial population and the mutation method, and these improve its efficiency and accuracy. Experiments on a variety of real-world datasets and a comparison to state-of-the-art genetic and non-genetic-based algorithms show improved results.",science
10.1016/j.jenvman.2017.11.002,Journal,Journal of Environmental Management,scopus,2018-02-01,sciencedirect,Combined strategy for removal of Reactive Black 5 by biomass sorption on Macrocystis pyrifera and zerovalent iron nanoparticles,https://api.elsevier.com/content/abstract/scopus_id/85034076595,"Reactive Black 5, RB5, has been used as a model azo dye to evaluate the removal efficiency of sorption on Macrocystis pyrifera biomass (Mpyr) and commercial zerovalent iron nanoparticles (nZVI) in individual and combined treatments. The best conditions for the treatment with the isolated materials were first determined, and then, in series and combined treatments were performed under these conditions, achieving removal efficiencies higher than 80% of the initial dye concentration. Strengths and weaknesses of all removal strategies (individual, in series and combined) are analyzed regarding the application on real effluents. Mpyr efficiently adsorbed RB5, but also increased the total organic content by partial dissolution of components of the algal biomass. Removal experiments with commercial nZVI were also efficient but liberated Fe to the solution, and sulfanilic acid was observed after the treatment as a product of RB5 degradation. In contrast, after the Mpyr treatment, no sulfanilic acid was detected, suggesting that sulfanilic acid is efficiently adsorbed by the biomass. The best condition was the integrated use of Mpyr and nZVI, with a remarkable removal efficiency (69–80%) obtained after only 1 h of treatment. Finally, nZVI were successfully immobilized in Mpyr, and the hybrid material was used to remove RB5 in continuous flow experiments at pH 3, obtaining a removal capacity of 39.9 mg RB5 g−1 after a total processed volume of 630 mL of [RB5]0 = 100 mg L−1.",science
10.1016/j.ins.2017.10.041,Journal,Information Sciences,scopus,2018-02-01,sciencedirect,A Q-learning-based memetic algorithm for multi-objective dynamic software project scheduling,https://api.elsevier.com/content/abstract/scopus_id/85032349573,"Software project scheduling is the problem of allocating employees to tasks in a software project. Due to the large scale of current software projects, many studies have investigated the use of optimization algorithms to find good software project schedules. However, despite the importance of human factors to the success of software projects, existing work has considered only a limited number of human properties when formulating software project scheduling as an optimization problem. Moreover, the changing environments of software companies mean that software project scheduling is a dynamic optimization problem. However, there is a lack of effective dynamic scheduling approaches to solve this problem. This work proposes a more realistic mathematical model for the dynamic software project scheduling problem. This model considers that skill proficiency can improve over time and, different from previous work, it considers that such improvement is affected by the employees’ properties of motivation and learning ability, and by the skill difficulty. It also defines the objective of employees’ satisfaction with the allocation. It is considered together with the objectives of project duration, cost, robustness and stability under a variety of practical constraints. To adapt schedules to the dynamically changing software project environments, a multi-objective two-archive memetic algorithm based on Q-learning (MOTAMAQ) is proposed to solve the problem in a proactive-rescheduling way. Different from previous work, MOTAMAQ learns the most appropriate global and local search methods to be used for different software project environment states by using Q-learning. Extensive experiments on 18 dynamic benchmark instances and 3 instances derived from real-world software projects were performed. A comparison with seven other meta-heuristic algorithms shows that the strategies used by our novel approach are very effective in improving its convergence performance in dynamic environments, while maintaining a good distribution and spread of solutions. The Q-learning-based learning mechanism can choose appropriate search operators for the different scheduling environments. We also show how different trade-offs among the five objectives can provide software managers with a deeper insight into various compromises among many objectives, and enabling them to make informed decisions.",science
10.1016/j.snb.2017.07.155,Journal,"Sensors and Actuators, B: Chemical",scopus,2018-02-01,sciencedirect,Calibrating chemical multisensory devices for real world applications: An in-depth comparison of quantitative machine learning approaches,https://api.elsevier.com/content/abstract/scopus_id/85029469409,"Chemical multisensor devices need calibration algorithms to estimate gas concentrations. Their possible adoption as indicative air quality measurements devices poses new challenges due to the need to operate in continuous monitoring modes in uncontrolled environments. Several issues, including slow dynamics, continue to affect their real world performances. At the same time, the need for estimating pollutant concentrations on board the devices, especially for wearables and IoT deployments, is becoming highly desirable. In this framework, several calibration approaches have been proposed and tested on a variety of proprietary devices and datasets; still, no thorough comparison is available to researchers. This work attempts a benchmarking of the most promising calibration algorithms according to recent literature with a focus on machine learning approaches. We test the techniques against absolute and dynamic performances, generalization capabilities and computational/storage needs using three different datasets sharing continuous monitoring operation methodology. Our results can guide researchers and engineers in the choice of optimal strategy. They show that non-linear multivariate techniques yield reproducible results, outperforming linear approaches. Specifically, the Support Vector Regression method consistently shows good performances in all the considered scenarios. We highlight the enhanced suitability of shallow neural networks in a trade-off between performance and computational/storage needs. We confirm, on a much wider basis, the advantages of dynamic approaches with respect to static ones that only rely on instantaneous sensor array response. The latter have been shown to be best choice whenever prompt and precise response is needed.",science
10.1016/j.neucom.2017.09.013,Journal,Neurocomputing,scopus,2018-01-31,sciencedirect,Constrained common cluster based model for community detection in temporal and multiplex networks,https://api.elsevier.com/content/abstract/scopus_id/85030643949,"On one hand, the detection of tightly connected groups, also known as community detection in complex networks, is a prominent problem for network analysis and mining. On the other hand, almost all of social, biological, bibliographic, communication and computer systems are modeled as temporal networks, the topological structures of which evolve with time, or multiplex networks, each pair of nodes of which has multiple linked relations. Current methods of community detection for temporal networks are based on incremental, independent or evolutionary clustering, and for multiplex networks are based on fusion of the multiple links. However, all these methods ignore the common structure hidden in the networks, which is denoted as the common cluster here. So in this paper, we propose a constrained common cluster based model (C
                     3 model) to analyze the temporal and multiplex networks, which can not only detect the community structure, but also identify the importance of each node based on the common cluster structure of both two classes of networks. The intrinsic assumption of the proposed model is that there are common or coincident clusters hidden in these networks. In detail, we first construct the Markov steady-state matrices of each snapshot of temporal network or each slice of multiplex network. Next, we propose the object function of C
                     3 model by combining the Markov steady-state matrices, similarity matrices with community membership matrices of each snapshot or slice of the network. Last, a gradient descent algorithm based on non-negative matrix factorization is proposed for the object function. Experiments on both synthetic datasets and real-world networks demonstrate that the proposed C
                     3 model has competitive performance based on the evaluation indexes NMI and error of community detection, otherwise, the proposed model could identify the importance of nodes of the temporal or multiplex networks.",science
10.1016/j.chroma.2017.11.053,Journal,Journal of Chromatography A,scopus,2018-01-12,sciencedirect,Core-shell magnetic molecularly imprinted polymers used rhodamine B hydroxyproline derivate as template combined with in situ derivatization for the specific measurement of L-hydroxyproline,https://api.elsevier.com/content/abstract/scopus_id/85034811951,"In this work, a novel core-shell magnetic molecularly imprinted polymers (MMIPs) for the measurement of L-Hydroxyproline (Hyp) in dairy products was prepared. The derivative of Hyp using N-hydroxysuccinimidyl rhodamine B ester (RBS) as derivatization reagent was employed as template to prepare RBS-Hyp-MMIPs (Fe3O4@MIPs for RBS-Hyp). A new analytical procedure of in situ derivatization with MMIPs (ISD-MMIPs) has been developed for the specific extraction and determination of Hyp in dairy products by ultra high performance liquid chromatography tandem mass spectrometry. The RBS-Hyp-MMIPs was characterized by fourier transform infrared spectrometer and transmission electron microscopy, and evaluated by adsorption experiments. The adsorption process followed Langumuir adsorption isotherm with maximum adsorption capacity of RBS-Hyp on RBS-Hyp-MMIPs at 96 mg/g. In addition, RBS-Hyp-MMIPs showed a short equilibrium time (15.0 min), rapid magnetic separation (5 s) and high stability (retained 95.3% after six cycles). Under the optimized conditions, good linearity was observed with the limits of detection (S/N > 3) and limits of quantification (S/N > 10) at 0.1 and 0.5 ng/mL, respectively. On account of the specific extraction performance of RBS-Hyp-MMIPs, not any interference peak from real sample matrix was observed in the chromatograms of milk powder, liquid milk and milk drink. The proposed procedure was successfully applied for selective determination of Hyp from dairy products with satisfactory validation results, which is of great significance to food safety.",science
