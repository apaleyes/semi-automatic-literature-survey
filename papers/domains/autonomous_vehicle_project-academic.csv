doi,publication_date,publication,publisher,title,abstract,database
,2017-08-28,a,,deeptest automated testing of deep neural network driven autonomous cars," Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. 
However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. 
In this paper, we design, implement and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explores different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.",project-academic
10.1145/3180155.3180220,2018-05-27,p,ACM,deeptest automated testing of deep neural network driven autonomous cars," Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.",project-academic
10.1109/ICRA.2018.8460655,2018-05-21,p,IEEE,self supervised deep reinforcement learning with generalized computation graphs for robot navigation," Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and None $N$ None -step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg",project-academic
,2017-09-29,a,,self supervised deep reinforcement learning with generalized computation graphs for robot navigation," Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and $N$-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at this http URL",project-academic
,2017-02-03,a,,uncertainty aware reinforcement learning for collision avoidance," Reinforcement learning can enable complex, adaptive behavior to be learned automatically for autonomous robotic platforms. However, practical deployment of reinforcement learning methods must contend with the fact that the training process itself can be unsafe for the robot. In this paper, we consider the specific case of a mobile robot learning to navigate an a priori unknown environment while avoiding collisions. In order to learn collision avoidance, the robot must experience collisions at training time. However, high-speed collisions, even at training time, could damage the robot. A successful learning method must therefore proceed cautiously, experiencing only low-speed collisions until it gains confidence. To this end, we present an uncertainty-aware model-based learning algorithm that estimates the probability of collision together with a statistical estimate of uncertainty. By formulating an uncertainty-dependent cost function, we show that the algorithm naturally chooses to proceed cautiously in unfamiliar environments, and increases the velocity of the robot in settings where it has high confidence. Our predictive model is based on bootstrapped neural networks using dropout, allowing it to process raw sensory inputs from high-bandwidth sensors such as cameras. Our experimental evaluation demonstrates that our method effectively minimizes dangerous collisions at training time in an obstacle avoidance task for a simulated and real-world quadrotor, and a real-world RC car. Videos of the experiments can be found at this https URL.",project-academic
10.1109/WACV45572.2020.9093332,2020-03-01,p,IEEE,uncertainty aware short term motion prediction of traffic actors for autonomous driving," We address one of the crucial aspects necessary for safe and efficient operations of autonomous vehicles, namely predicting future state of traffic actors in the autonomous vehicle’s surroundings. We introduce a deep learning-based approach that takes into account a current world state and produces raster images of each actor’s vicinity. The rasters are then used as inputs to deep convolutional models to infer future movement of actors while also accounting for and capturing inherent uncertainty of the prediction task. Extensive experiments on real-world data strongly suggest benefits of the proposed approach. Moreover, following successful tests the system was deployed to a fleet of autonomous vehicles.",project-academic
10.1109/TNET.2018.2869244,2018-12-01,a,IEEE,an online context aware machine learning algorithm for 5g mmwave vehicular communications," Millimeter-Wave (mmWave) bands have become the de-facto candidate for 5G vehicle-to-everything (V2X) since future vehicular systems demand Gbps links to acquire the necessary sensory information for (semi)-autonomous driving. Nevertheless, the directionality of mmWave communications and its susceptibility to blockage raise severe questions on the feasibility of mmWave vehicular communications. The dynamic nature of 5G vehicular scenarios and the complexity of directional mmWave communication calls for higher context-awareness and adaptability. To this aim, we propose an None online learning algorithm None addressing the problem of None beam selection with environment-awareness None in mmWave vehicular systems. In particular, we model this problem as a contextual multi-armed bandit problem. Next, we propose a lightweight context-aware online learning algorithm, namely fast machine learning (FML), with proven performance bound and guaranteed convergence. FML exploits coarse user location information and aggregates the received data to learn from and adapt to its environment. Furthermore, we demonstrate the feasibility of a real-world implementation of FML by proposing a standard-compliant protocol based on the existing architecture of cellular networks and the forthcoming features of 5G. We also perform an extensive evaluation using realistic traffic patterns derived from Google Maps. Our evaluation shows that FML enables mmWave base stations to achieve near-optimal performance on average within 33 mins of deployment by learning from the available context. Moreover, None FML remains within None ~ 5% None of the optimal performance None by swift adaptation to system changes (i.e., blockage, traffic).",project-academic
10.1177/0278364917727062,2018-04-02,a,,deep spatiotemporal models for robust proprioceptive terrain classification," Terrain classification is a critical component of any autonomous mobile robot system operating in unknown real-world environments. Over the years, several proprioceptive terrain classification techniques have been introduced to increase robustness or act as a fallback for traditional vision based approaches. However, they lack widespread adaptation due to various factors that include inadequate accuracy, robustness and slow run-times. In this paper, we use vehicle-terrain interaction sounds as a proprioceptive modality and propose a deep Long-Short Term Memory (LSTM) based recurrent model that captures both the spatial and temporal dynamics of such a problem, thereby overcoming these past limitations. Our model consists of a new Convolution Neural Network (CNN) architecture that learns deep spatial features, complemented with LSTM units that learn complex temporal dynamics. Experiments on two extensive datasets collected with different microphones on various indoor and outdoor terrains demonstrate state-of-the-art performance compared to existing techniques. We additionally evaluate the performance in adverse acoustic conditions with high ambient noise and propose a noise-aware training scheme that enables learning of more generalizable models that are essential for robust real-world deployments.",project-academic
10.1109/TETC.2021.3050733,2021-01-07,a,,sharks smart hacking approaches for risk scanning in internet of things and cyber physical systems based on machine learning," Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are increasingly being deployed across multiple functionalities, ranging from healthcare devices and wearables to critical infrastructures, e.g., nuclear power plants, autonomous vehicles, smart cities, and smart homes. These devices are inherently not secure across their comprehensive software, hardware, and network stacks, thus presenting a large attack surface that can be exploited by hackers. In this article, we present an innovative technique for detecting unknown system vulnerabilities, managing these vulnerabilities, and improving incident response when such vulnerabilities are exploited. The novelty of this approach lies in extracting intelligence from known real-world CPS/IoT attacks, representing them in the form of regular expressions, and employing machine learning (ML) techniques on this ensemble of regular expressions to generate new attack vectors and security vulnerabilities. Our results show that 10 new attack vectors and 122 new vulnerability exploits can be successfully generated that have the potential to exploit a CPS or an IoT ecosystem. The ML methodology achieves an accuracy of 97.4% and enables us to predict these attacks efficiently with an 87.2% reduction in the search space. We demonstrate the application of our method to the hacking of the in-vehicle network of a connected car. To defend against the known attacks and possible novel exploits, we discuss a defense-in-depth mechanism for various classes of attacks and the classification of data targeted by such attacks. This defense mechanism optimizes the cost of security measures based on the sensitivity of the protected resource, thus incentivizing its adoption in real-world CPS/IoT by cybersecurity practitioners.",project-academic
10.1109/TPAMI.2021.3109025,2021-09-01,a,Institute of Electrical and Electronics Engineers (IEEE),pvnas 3d neural architecture search with point voxel convolution," 3D neural networks are widely used in real-world applications (e.g., AR/VR headsets, self-driving cars). They are required to be fast and accurate; however, limited hardware resources on edge devices make these requirements rather challenging. Previous work processes 3D data using either voxel-based or point-based neural networks, but both types of 3D models are not hardware-efficient due to the large memory footprint and random memory access. In this paper, we study 3D deep learning from the efficiency perspective. We first systematically analyze the bottlenecks of previous 3D methods. We then combine the best from point-based and voxel-based models together and propose a novel hardware-efficient 3D primitive, Point-Voxel Convolution (PVConv). We further enhance this primitive with the sparse convolution to make it more effective in processing large (outdoor) scenes. Based on our designed 3D primitive, we introduce 3D Neural Architecture Search (3D-NAS) to explore the best 3D network architecture given a resource constraint. We evaluate our proposed method on six representative benchmark datasets, achieving state-of-the-art performance with 1.8-23.7x measured speedup. Furthermore, our method has been deployed to the autonomous racing vehicle of MIT Driverless, achieving larger detection range, higher accuracy and lower latency.",project-academic
10.1109/LRA.2020.2967296,2020-01-17,p,IEEE,aerial single view depth completion with image guided uncertainty estimation," On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.",project-academic
10.1109/ICRA48506.2021.9560756,2021-05-30,p,IEEE,siamese anchor proposal network for high speed aerial tracking," In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of ∼200 frames/s.",project-academic
,2020-12-19,a,,siamese anchor proposal network for high speed aerial tracking," In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of around 200 frames/s.",project-academic
,2019-01-06,a,,exploring applications of deep reinforcement learning for real world autonomous driving systems," Deep Reinforcement Learning (DRL) has become increasingly powerful in recent years, with notable achievements such as Deepmind's AlphaGo. It has been successfully deployed in commercial vehicles like Mobileye's path planning system. However, a vast majority of work on DRL is focused on toy examples in controlled synthetic car simulator environments such as TORCS and CARLA. In general, DRL is still at its infancy in terms of usability in real-world applications. Our goal in this paper is to encourage real-world deployment of DRL in various autonomous driving (AD) applications. We first provide an overview of the tasks in autonomous driving systems, reinforcement learning algorithms and applications of DRL to AD systems. We then discuss the challenges which must be addressed to enable further progress towards real-world deployment.",project-academic
10.1109/ACCESS.2020.2981463,2020-03-18,a,IEEE,cooperative autonomous driving oriented mec aided 5g v2x prototype system design field tests and ai based optimization tools," Vehicle-to-Everything (V2X) requirements from cooperative autonomous driving can be characterized as ultra-reliable, low latency, high traffic, and high mobility. These requirements introduce great challenges in the air interface and protocol stack design, resource allocation, network deployment, and all the way up to mobile (or multi-access) edge computing (MEC), cloud and application layer. In this paper, we present a cooperative autonomous driving oriented MEC-aided 5G-V2X prototype system design and the rationale behind the design choices. The prototype system is developed based on a next-generation radio access network (NG-RAN) experimental platform, a cooperative driving vehicle platoon, and an MEC server providing high definition (HD) 3D dynamic map service. Field tests are conducted and the results demonstrate that the combination of 5G-V2X, MEC and cooperative autonomous driving can be pretty powerful. Considering the remaining challenges in the commercial deployment of 5G-V2X networks and future researches, we propose two artificial intelligence (AI) based optimization tools. The first is a deep-learning-based tool called deep spatio-temporal residual networks with a permutation operator (PST-ResNet). By providing city-wide user and network traffic prediction, PST-ResNet can help to reduce the capital expense (CAPEX) and operating expense (OPEX) costs of commercial 5G-V2X networks. The second is a swarm intelligence based optimization tool called subpopulation collaboration based dynamic self-adaption cuckoo Search (SC-DSCS), which can be widely used to solve complex optimization problems in future researches. The effectiveness of proposed optimization tools is verified by real-world data and benchmark functions.",project-academic
,2007-12-28,p,,toward domain neutral human level metacognition," We have found that implementing a metacognitive loop (MCL), which gives intelligent systems the ability to selfmonitor their ongoing performance and make targeted changes to their various action-determining components, can play an important role in helping systems cope with the unexpected problems and events that are the inevitable result of real-world deployment. In this paper, we discuss our work with MCL-enhanced intelligent systems, and describe the ontologies that allow MCL to reason about, appropriately classify and respond to the perfomance anomalies it detects. Introduction: The Hardest AI Problem and the Metacognitive Loop It is widely agreed that AI has been extremely successful in the narrow sense: given any of a large variety of well-defined AI problems, there is (or, so goes the common wisdom, there could easily be) an implemented solution using reasonably well-understood techniques. Or at the very least, there are solutions to similar problems, so that there is much reason to expect solutions to the problem at hand. But in the wide sense, AI is a disappointment. Although many AI systems are at or beyond human-level competence at the individual tasks for which they were designed (from chess playing to medical diagnosis), AI systems are nowhere near human-level competence across the board. This is not simply a matter of building a system that has numerous subsystems, one for each of hundreds or thousands of individual tasks. The combined skills of a doctor, lawyer, chess-master, linguist, etc., does not a human make. For humans have, in addition to whatever number of individual skills, the ability to do reasonably well when faced with situations for which they have not been specifically trained. This general competence, the ability to muddle through when faced with the unexpected or unfamiliar, we consider to be the the core of human-level common sense. Indeed, this ability may well be the key to how we are able to train: we recognize when we lack an ability, make a decision to gain it, and recognize when it is time to stop learning—when training is complete; or complete enough for our purposes; or when it is ineffective, too slow, too expensive, or no longer important. We Copyright c © 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. also (sometimes!) recognize when we are in over our heads, and then we ask for help or wisely give up. It is this general sort of ability that current AI systems lack, with the result that they tend to be brittle, easily breaking when confronted with situations beyond their set of narrow competencies. Why is this so? And why has the brittleness problem been so hard to solve? Our hypothesis is this: while there are well-established and sohpisticated AI technologies for dealing with change or novelty e.g., machine learning (ML) and commonsense reasoning (CSR), neither alone is adequate to the task in question, since each needs the other to realize its true potential. Thus ML needs reasoned guidance (a form of CSR) as to when, why, what, and how to learn; and CSR needs trainable modules (to which ML can be applied) so that the fruits of such reasoning can be applied to bring about better future performance. Proper melding of ML and CSR should, in our view, go a long way toward solving the brittleness problem and bringing us closer to the ultimate goal of AI. What will it take to meld ML and CSR in such a way as to solve the brittleness problem, i.e., to build a system that (under a wide range of unforeseen circumstances) adjusts itself instead of breaking? We have isolated four capacities. First of all, a system will need to know enough about what it is doing (its goals, its actions, and their results), so that it can detect—and then assess—when those goals are not being achieved (Brachman 2002). This is a key place where CSR comes into play, in reasoning after the fact about such goal failures. Other relevant approaches include case-based reasoning and meta-level planning (Cox 2005; Anderson & Oates 2007). Second, it will need to be able to make targeted changes to itself when there are indications of current inadequacies in what it is doing. This is where ML can come into play: if the desired changes involve any sort of training or adapting, the relevant trainable modules and their associated training processes must be invoked. Third, it will need to be able to apply the same first two capacities to monitor how a given self-change is working out (thus there is a form of recursion involved). This again involves CSR in order to assess whether the targeted change is occurring properly. And fourth, it will need to do this in real time. This is a tall order, but the elements are clear enough to allow progress. This paper reports on our work to date and where we see it headed. The rest of the paper is organized as follows: We outline our specific approach to these four capacities (which we call MCL: the metacognitive loop); we discuss some early pilot studies; we present three ontologies that allow MCL to reason about, and appropriately classify and respond to the perfomance anomolies it detects; we show how these ontologies have been applied to a simulated autonomous vehicle domain; and we conclude with some general considerations and a discussion of future work.",project-academic
10.3389/FROBT.2021.739023,2021-01-01,a,Frontiers Media SA,robust asv navigation through ground to water cross domain deep reinforcement learning," This paper presents a framework to alleviate the Deep Reinforcement Learning (DRL) training data sparsity problem that is present in challenging domains by creating a DRL agent training and vehicle integration methodology. The methodology leverages accessible domains to train an agent to solve navigational problems such as obstacle avoidance and allows the agent to generalize to challenging and inaccessible domains such as those present in marine environments with minimal further training. This is done by integrating a DRL agent at a high level of vehicle control and leveraging existing path planning and proven low-level control methodologies that are utilized in multiple domains. An autonomy package with a tertiary multilevel controller is developed to enable the DRL agent to interface at the prescribed high control level and thus be separated from vehicle dynamics and environmental constraints. An example Deep Q Network (DQN) employing this methodology for obstacle avoidance is trained in a simulated ground environment, and then its ability to generalize across domains is experimentally validated. Experimental validation utilized a simulated water surface environment and real-world deployment of ground and water robotic platforms. This methodology, when used, shows that it is possible to leverage accessible and data rich domains, such as ground, to effectively develop marine DRL agents for use on Autonomous Surface Vehicle (ASV) navigation. This will allow rapid and iterative agent development without the risk of ASV loss, the cost and logistic overhead of marine deployment, and allow landlocked institutions to develop agents for marine applications.",project-academic
10.1109/ICC.2019.8761117,2019-05-20,p,IEEE,machine learning for position prediction and determination in aerial base station system," A novel framework for dynamic 3-D deployment of unmanned aerial vehicle (UAV) in the aerial base station system (ABSS) that based on the machine learning algorithms is proposed. In the framework, the UAV is deployed as an aerial base station to serve a group of ground users and is placed based on the prediction of the users' mobility. The joint problem of prediction of users' track and 3-D deployment of the UAV is formulated for maximizing the sum transmit rate. A two-step approach is proposed for predicting the movement of users and for determining the dynamic 3-D placement of the UAV. Firstly, an echo state network (ESN) based prediction algorithm is utilized for predicting the future positions of users based on the real-world datasets collected from Twitter. Secondly, an iterative K-Means based algorithm is proposed for obtaining the optimal placement of UAV at each time slot based on the output of ESN model. Numerical results are illustrated for showing the superiority of the proposed algorithm over the prevalent algorithm on prediction tasks. The accuracy and efficiency of the proposed framework are also investigated. Additionally, compared with static placement of the UAV, the advantage of dynamic 3-D deployment is demonstrated.",project-academic
10.1016/B978-0-12-820276-0.00010-8,2020-05-18,c,Academic Press,unmanned aerial systems autonomy cognition and control," Abstract None None None None The increasing trend towards a higher level of autonomy in unmanned aerial systems (UASs) had led to lower requirements for control by the human operator and to an increasing capability to perform complex tasks by reacting to the environmental influences. Nevertheless, current UASs are designed to function in static and predictable environments. Therefore, it is envisaged that the existing uncertainties and dynamic changes, caused when an unmanned aerial vehicle (UAV) is operating in an unknown environment, would reduce its performance significantly. The uncertainties can be also incurred through interaction with other complex and intelligent systems, such as humans. We present a compact literature survey of UAS control and navigation as a basic knowledge to develop UASs from the perspective of the control engineer. Besides, we present several control strategies to maintain a UAS, as well as multi-UASs, under a network setting under various scenarios. Several simulations are given to illustrate the performance of the controllers in MATLAB®. Advances in computing power and algorithms currently enable the development of systems with a high degree of autonomy. Nonetheless, there is a large gap between practical operation in the real-world and laboratory implementation, as safe deployment of UASs requires validation of their behavior under almost all envisaged scenarios. A reliable and autonomous operation of such a system requires design and development of a cognitive control system that acquires knowledge and understanding of the surrounding environment via perception, reasoning, and learning. Cognitive control systems in UASs will enhance their safety and performance. Cognitive control can also be used in cooperative execution of complex tasks where multiple agents such as humans, machines, or both interact. Such UASs will have a great potential to be used in extreme environments such as search and rescue in the case of disaster, nuclear decommissioning operations, deep-sea exploration, mining, etc.",project-academic
10.3390/RS12244193,2020-12-21,a,Multidisciplinary Digital Publishing Institute (MDPI),post disaster building damage detection from earth observation imagery using unsupervised and transferable anomaly detecting generative adversarial networks," We present an unsupervised deep learning approach for post-disaster building damage detection that can transfer to different typologies of damage or geographical locations. Previous advances in this direction were limited by insufficient qualitative training data. We propose to use a state-of-the-art Anomaly Detecting Generative Adversarial Network (ADGAN) because it only requires pre-event imagery of buildings in their undamaged state. This approach aids the post-disaster response phase because the model can be developed in the pre-event phase and rapidly deployed in the post-event phase. We used the xBD dataset, containing pre- and post- event satellite imagery of several disaster-types, and a custom made Unmanned Aerial Vehicle (UAV) dataset, containing post-earthquake imagery. Results showed that models trained on UAV-imagery were capable of detecting earthquake-induced damage. The best performing model for European locations obtained a recall, precision and F1-score of 0.59, 0.97 and 0.74, respectively. Models trained on satellite imagery were capable of detecting damage on the condition that the training dataset was void of vegetation and shadows. In this manner, the best performing model for (wild)fire events yielded a recall, precision and F1-score of 0.78, 0.99 and 0.87, respectively. Compared to other supervised and/or multi-epoch approaches, our results are encouraging. Moreover, in addition to image classifications, we show how contextual information can be used to create detailed damage maps without the need of a dedicated multi-task deep learning framework. Finally, we formulate practical guidelines to apply this single-epoch and unsupervised method to real-world applications.",project-academic
10.1109/ICRA48506.2021.9561076,2021-05-30,p,IEEE,task driven deep image enhancement network for autonomous driving in bad weather," Visual perception in autonomous driving is a crucial part of a vehicle to navigate safely and sustainably in different traffic conditions. However, in bad weather such as heavy rain and haze, the performance of visual perception is greatly affected by several degrading effects. Recently, deep learning-based perception methods have addressed multiple degrading effects to reflect real-world bad weather cases but have shown limited success due to 1) high computational costs for deployment on mobile devices and 2) poor relevance between image enhancement and visual perception in terms of the model ability. To solve these issues, we propose a task-driven image enhancement network connected to the high-level vision task, which takes in an image corrupted by bad weather as input. Specifically, we introduce a novel low memory network to reduce most of the layer connections of dense blocks for less memory and computational cost while maintaining high performance. We also introduce a new task-driven training strategy to robustly guide the high-level task model suitable for both high-quality restoration of images and highly accurate perception. Experiment results demonstrate that the proposed method improves the performance among lane and 2D object detection, and depth estimation largely under adverse weather in terms of both low memory and accuracy.",project-academic
,2021-10-14,a,,task driven deep image enhancement network for autonomous driving in bad weather," Visual perception in autonomous driving is a crucial part of a vehicle to navigate safely and sustainably in different traffic conditions. However, in bad weather such as heavy rain and haze, the performance of visual perception is greatly affected by several degrading effects. Recently, deep learning-based perception methods have addressed multiple degrading effects to reflect real-world bad weather cases but have shown limited success due to 1) high computational costs for deployment on mobile devices and 2) poor relevance between image enhancement and visual perception in terms of the model ability. To solve these issues, we propose a task-driven image enhancement network connected to the high-level vision task, which takes in an image corrupted by bad weather as input. Specifically, we introduce a novel low memory network to reduce most of the layer connections of dense blocks for less memory and computational cost while maintaining high performance. We also introduce a new task-driven training strategy to robustly guide the high-level task model suitable for both high-quality restoration of images and highly accurate perception. Experiment results demonstrate that the proposed method improves the performance among lane and 2D object detection, and depth estimation largely under adverse weather in terms of both low memory and accuracy.",project-academic
10.1631/FITEE.1900637,2021-07-14,a,Zhejiang University Press,pre training with asynchronous supervised learning for reinforcement learning based autonomous driving," Rule-based autonomous driving systems may suffer from increased complexity with large-scale intercoupled rules, so many researchers are exploring learning-based approaches. Reinforcement learning (RL) has been applied in designing autonomous driving systems because of its outstanding performance on a wide variety of sequential control problems. However, poor initial performance is a major challenge to the practical implementation of an RL-based autonomous driving system. RL training requires extensive training data before the model achieves reasonable performance, making an RL-based model inapplicable in a real-world setting, particularly when data are expensive. We propose an asynchronous supervised learning (ASL) method for the RL-based end-to-end autonomous driving model to address the problem of poor initial performance before training this RL-based model in real-world settings. Specifically, prior knowledge is introduced in the ASL pre-training stage by asynchronously executing multiple supervised learning processes in parallel, on multiple driving demonstration data sets. After pre-training, the model is deployed on a real vehicle to be further trained by RL to adapt to the real environment and continuously break the performance limit. The presented pre-training method is evaluated on the race car simulator, TORCS (The Open Racing Car Simulator), to verify that it can be sufficiently reliable in improving the initial performance and convergence speed of an end-to-end autonomous driving model in the RL training stage. In addition, a real-vehicle verification system is built to verify the feasibility of the proposed pre-training method in a real-vehicle deployment. Simulations results show that using some demonstrations during a supervised pre-training stage allows significant improvements in initial performance and convergence speed in the RL training stage.",project-academic
,2020-03-23,a,,adversarial attacks on monocular depth estimation," Recent advances of deep learning have brought exceptional performance on many computer vision tasks such as semantic segmentation and depth estimation. However, the vulnerability of deep neural networks towards adversarial examples have caused grave concerns for real-world deployment. In this paper, we present to the best of our knowledge the first systematic study of adversarial attacks on monocular depth estimation, an important task of 3D scene understanding in scenarios such as autonomous driving and robot navigation. In order to understand the impact of adversarial attacks on depth estimation, we first define a taxonomy of different attack scenarios for depth estimation, including non-targeted attacks, targeted attacks and universal attacks. We then adapt several state-of-the-art attack methods for classification on the field of depth estimation. Besides, multi-task attacks are introduced to further improve the attack performance for universal attacks. Experimental results show that it is possible to generate significant errors on depth estimation. In particular, we demonstrate that our methods can conduct targeted attacks on given objects (such as a car), resulting in depth estimation 3-4x away from the ground truth (e.g., from 20m to 80m).",project-academic
,2019-06-20,a,,deep learning in the automotive industry recent advances and application examples," One of the most exciting technology breakthroughs in the last few years has been the rise of deep learning. State-of-the-art deep learning models are being widely deployed in academia and industry, across a variety of areas, from image analysis to natural language processing. These models have grown from fledgling research subjects to mature techniques in real-world use. The increasing scale of data, computational power and the associated algorithmic innovations are the main drivers for the progress we see in this field. These developments also have a huge potential for the automotive industry and therefore the interest in deep learning-based technology is growing. A lot of the product innovations, such as self-driving cars, parking and lane-change assist or safety functions, such as autonomous emergency braking, are powered by deep learning algorithms. Deep learning is poised to offer gains in performance and functionality for most ADAS (Advanced Driver Assistance System) solutions. Virtual sensing for vehicle dynamics application, vehicle inspection/heath monitoring, automated driving and data-driven product development are key areas that are expected to get the most attention. This article provides an overview of the recent advances and some associated challenges in deep learning techniques in the context of automotive applications.",project-academic
10.1016/J.ENGAPPAI.2020.103799,2020-09-01,a,Pergamon,trajectory based lateral control a reinforcement learning case study," Abstract None None Reinforcement Learning (RL) has been employed in many applications of robotics and has steadily been gaining traction in the field of Autonomous Driving (AD). This paper proposes a Deep Reinforcement Learning based approach for lateral Vehicle Motion Control (VMC), and explores the generalization capabilities of the approach. The proposed methodology uses a sequence of waypoints generated from a planning module of an AD stack as the input. The network has been trained to predict accurate steering commands to follow the given trajectory. In this paper we detail our implementation and share our learning experience on real-vehicle deployment of the RL based controller. Our experiments yield promising results with an agent trained on less than 4 h of simulated driving experience without any real-world data. The trained agent is able to successfully complete unseen and more complex tracks using different unseen vehicle models. The agent safely reached up to 150 km/h in simulation and up to 60 km/h in a real-life Sport Utility Vehicle (SUV) weighing more than 2000 kg.",project-academic
10.1109/TITS.2021.3108851,2021-09-06,a,Institute of Electrical and Electronics Engineers (IEEE),multi objective genetic algorithm for optimizing an elm based driver distraction detection system," Driver Assistance Systems (DAS) have been progressively incorporated into commercial vehicles in recent years. All these systems are paving the way for the forthcoming autonomous vehicle which will become a reality in the near future. Existing systems are based on numerous electronic systems with advanced skills, high performances, and high degrees of adaptability and intelligence. As is to be expected, these cutting-edge features require, in most cases, the use of powerful computing platforms. However, the deployment of such platforms is not an easy task, since they have to be integrated in the vehicle where there exist important restrictions regarding size, power consumption and cost. In this sense, every smart proposal aimed at reducing the complexity of these systems without degrading performance, is always a valuable contribution in the field. In this work, we propose a methodology to reduce the dimensionality of a driver distraction recognition system. The methodology is based on a multi-objective genetic algorithm that looks for the minimum set of useful features collected during the driving task and also for the simplest recognition system. The recognition algorithm is an Extreme Learning Machine (ELM) whose simplicity and fast learning procedure make it especially suitable to be used by a Genetic Algorithm which needs to evaluate thousands of candidate solutions. The proposed methodology has been tested with a real-world database collected from different drivers performing an itinerary with an instrumented car. The results obtained validate the proposal as a method to reduce the complexity of a driver distraction recognition system.",project-academic
,2020-08-02,a,,iot system for real time near crash detection for automated vehicle testing," Our world is moving towards the goal of fully autonomous driving at a fast pace. While the latest automated vehicles (AVs) can handle most real-world scenarios they encounter, a major bottleneck for turning fully autonomous driving into reality is the lack of sufficient corner case data for training and testing AVs. Near-crash data, as a widely used surrogate data for traffic safety research, can also serve the purpose of AV testing if properly collected. To this end, this paper proposes an Internet-of-Things (IoT) system for real-time near-crash data collection. The system has several cool features. First, it is a low-cost and standalone system that is backward-compatible with any existing vehicles. People can fix the system to their dashboards for near-crash data collection and collision warning without the approval or help of vehicle manufacturers. Second, we propose a new near-crash detection method that models the target's size changes and relative motions with the bounding boxes generated by deep-learning-based object detection and tracking. This near-crash detection method is fast, accurate, and reliable; particularly, it is insensitive to camera parameters, thereby having an excellent transferability to different dashboard cameras. We have conducted comprehensive experiments with 100 videos locally processed at Jetson, as well as real-world tests on cars and buses. Besides collecting corner cases, it can also serve as a white-box platform for testing innovative algorithms and evaluating other AV products. The system contributes to the real-world testing of AVs and has great potential to be brought into large-scale deployment.",project-academic
10.1145/3416014.3424600,2020-11-16,p,"Association for Computing Machinery, Inc",real time low pixel infrared human detection from unmanned aerial vehicles," To improve the speed and accuracy in human detection in Search and Rescue (SAR) operations, this paper presents a novel and highly efficient machine learning empowered system by extending the You Only Look Once (YOLO) algorithm, which is designed and deployed on an embedded system. The proposed approach has been evaluated under real-world conditions on a Jetson AGX Xavier platform and the results have shown a well-balanced system in terms of accuracy, speed and portability. Moreover, the system demonstrates its resilience to perform low-pixel human detection on infrared images received from an Unmanned Aerial Vehicle (UAV) at low-light conditions, different altitudes and postures such as sitting, walking and running. The proposed approach has achieved in a constrained environment a total of 89.26% of accuracy and 24.6 FPS, surpassing the barrier of real-time object recognition.",project-academic
10.1109/TITS.2021.3103441,2021-08-16,a,IEEE,overriding autonomous driving systems using adaptive adversarial billboards," The success of deep neural networks (DNNs) has led to its increased deployment in various real-world applications, which provides strong incentives for motivated adversaries to manipulate the results and models generated by these algorithms. We present an automated, physically-realizable, dynamic adversarial attack to compromise an end-to-end trained DNN controlled autonomous vehicle. The attack is initiated by installing a billboard displaying videos on the roadside to incoming DNN controlled vehicles so that the vehicle tracks an adversary customized trajectory. The billboard contains an integrated camera to enable estimation of the pose of the approaching vehicle. The dynamic billboard images (i.e., a video) continuously adapt to the vehicle's relative pose with respect to the billboard while being robust to variations in lighting, view angle, and weather. The attack's effectiveness is shown on a recently developed off-the-shelf high-fidelity simulator, CARLA, for autonomous vehicles. CARLA utilizes an end-to-end learning-based autonomous navigation system. The proposed approach is applicable to other end-to-end trained autonomous cyber-physical systems.",project-academic
10.1117/12.2194372,2015-10-13,p,International Society for Optics and Photonics,simulation of a multispectral multicamera off road autonomous vehicle perception system with virtual autonomous navigation environment vane," We present a case-study in using specialized, physics-based software for high-fidelity environment and electro-optical
sensor modeling in order to produce simulated sensor data that can be used to train a multi-spectral perception system for
unmanned ground vehicle navigation. This case-study used the Virtual Autonomous Navigation Environment (VANE)
to simulate filtered, multi-spectral imaging sensors. The VANE utilizes ray-tracing and hyperspectral material properties
to capture the sensor-environment interaction. In this study we focus on a digital scene of the ERDC test track in
Vicksburg, MS that has extremely detailed representation of the vegetation and ground texture. The scene model is used
to generate imagery that simulates the output of specialized terrain perception hardware developed by Southwest
Research Institute, which consists of stereo pair of 3-channel cameras. The perception system utilizes stereo processing,
the multi-spectral responses, and image texture features in order to create a 3-dimensional world model suitable for
offroad vehicle navigation, providing depth information and an estimated terrain class label for every pixel by utilizing
machine learning. While the process of training the perception system generally involves hand-labeling data collected
through manned missions, the ability to generate data for certain environments and lighting conditions represents an
enabling technology for deployment in new theaters. We demonstrate an initial capability to simulate data and train the
perception system and present the results compared to the system trained with real-world data from the same location.",project-academic
,2021-09-30,a,,emergency vehicles audio detection and localization in autonomousdriving," Emergency vehicles in service have right-of-way over all other vehicles. Hence, all other vehicles are supposed to take proper actions to yield emergency vehicles with active sirens. As this task requires the cooperation between ears and eyes for human drivers, it also needs audio detection as a supplement to vision-based algorithms for fully autonomous driving vehicles. In urban driving scenarios, we need to know both the existence of emergency vehicles and their relative positions to us to decide the proper actions. We present a novel system from collecting the real-world siren data to the deployment of models using only two cost-efficient microphones. We are able to achieve promising performance for each task separately, especially within the crucial 10m to 50m distance range to react (the size of our ego vehicle is around 5m in length and 2m in width). The recall rate to determine the existence of sirens is 99.16% , the median and mean angle absolute error is 9.64° and 19.18° respectively, and the median and mean distance absolute error of 9.30m and 10.58m respectively within that range. We also benchmark various machine learning approaches that can determine the siren existence and sound source localization which includes direction and distance simultaneously within 50ms of latency.",project-academic
,2021-09-28,a,,safetynet safe planning for real world self driving vehicles using machine learned policies," In this paper we present the first safe system for full control of self-driving vehicles trained from human demonstrations and deployed in challenging, real-world, urban environments. Current industry-standard solutions use rule-based systems for planning. Although they perform reasonably well in common scenarios, the engineering complexity renders this approach incompatible with human-level performance. On the other hand, the performance of machine-learned (ML) planning solutions can be improved by simply adding more exemplar data. However, ML methods cannot offer safety guarantees and sometimes behave unpredictably. To combat this, our approach uses a simple yet effective rule-based fallback layer that performs sanity checks on an ML planner's decisions (e.g. avoiding collision, assuring physical feasibility). This allows us to leverage ML to handle complex situations while still assuring the safety, reducing ML planner-only collisions by 95%. We train our ML planner on 300 hours of expert driving demonstrations using imitation learning and deploy it along with the fallback layer in downtown San Francisco, where it takes complete control of a real vehicle and navigates a wide variety of challenging urban driving scenarios.",project-academic
,2021-10-22,a,,model a modularized end to end reinforcement learning framework for autonomous driving," Heated debates continue over the best autonomous driving framework. The classic modular pipeline is widely adopted in the industry owing to its great interpretability and stability, whereas the end-to-end paradigm has demonstrated considerable simplicity and learnability along with the rise of deep learning. We introduce a new modularized end-to-end reinforcement learning framework (ModEL) for autonomous driving, which combines the merits of both previous approaches. The autonomous driving stack of ModEL is decomposed into perception, planning, and control module, leveraging scene understanding, end-to-end reinforcement learning, and PID control respectively. Furthermore, we build a fully functional autonomous vehicle to deploy this framework. Through extensive simulation and real-world experiments, our framework has shown great generalizability to various complicated scenarios and outperforms the competing baselines.",project-academic
,2020-06-18,,,building an artificial intelligence system for an autonomous vehicle, An apparatus for building an artificial-intelligence system is provided. The apparatus accesses images of a real-world scene and generates an image of a simulated object corresponding to a real-world object using a first generative adversarial network (GAN). The apparatus inserts the image of the simulated object into the images of the real-world scene to produce images of the real-world scene including the simulated object. The apparatus applies the images of the real-world scene including the simulated object to a second GAN to remove visual artifacts thereby producing a training set of images of the real-world scene including the simulated object. The apparatus trains an artificial-intelligence algorithm using the training set of images to build the artificial-intelligence system to detect the real-world object in further images of the real-world scene and outputs the artificial-intelligence system for deployment on an autonomous vehicle.,project-academic
,2019-05-09,a,,mitigating deep learning vulnerabilities from adversarial examples attack in the cybersecurity domain," Deep learning models are known to solve classification and regression problems by employing a number of epoch and training samples on a large dataset with optimal accuracy. However, that doesn't mean they are attack-proof or unexposed to vulnerabilities. Newly deployed systems particularly on a public environment (i.e public networks) are vulnerable to attacks from various entities. Moreover, published research on deep learning systems (Goodfellow et al., 2014) have determined a significant number of attacks points and a wide array of attack surface that has evidence of exploitation from adversarial examples. Successful exploit on these systems could lead to critical real world repercussions. For instance, (1) an adversarial attack on a self-driving car running a deep reinforcement learning system yields a direct misclassification on humans causing untoward accidents.(2) a self-driving vehicle misreading a red light signal may cause the car to crash to another car (3) misclassification of a pedestrian lane as an intersection lane that could lead to car crashes. This is just the tip of the iceberg, computer vision deployment are not entirely focused on self-driving cars but on many other areas as well - that would have definitive impact on the real-world. These vulnerabilities must be mitigated at an early stage of development. It is imperative to develop and implement baseline security standards at a global level prior to real-world deployment.",project-academic
10.3390/S19204357,2019-10-09,a,Sensors (Basel),real time hybrid multi sensor fusion framework for perception in autonomous vehicles," There are many sensor fusion frameworks proposed in the literature using different sensors and fusion methods combinations and configurations. More focus has been on improving the accuracy performance; however, the implementation feasibility of these frameworks in an autonomous vehicle is less explored. Some fusion architectures can perform very well in lab conditions using powerful computational resources; however, in real-world applications, they cannot be implemented in an embedded edge computer due to their high cost and computational need. We propose a new hybrid multi-sensor fusion pipeline configuration that performs environment perception for autonomous vehicles such as road segmentation, obstacle detection, and tracking. This fusion framework uses a proposed encoder-decoder based Fully Convolutional Neural Network (FCNx) and a traditional Extended Kalman Filter (EKF) nonlinear state estimator method. It also uses a configuration of camera, LiDAR, and radar sensors that are best suited for each fusion method. The goal of this hybrid framework is to provide a cost-effective, lightweight, modular, and robust (in case of a sensor failure) fusion system solution. It uses FCNx algorithm that improve road detection accuracy compared to benchmark models while maintaining real-time efficiency that can be used in an autonomous vehicle embedded computer. Tested on over 3K road scenes, our fusion algorithm shows better performance in various environment scenarios compared to baseline benchmark networks. Moreover, the algorithm is implemented in a vehicle and tested using actual sensor data collected from a vehicle, performing real-time environment perception.",project-academic
,2017-09-11,a,,autonomous quadrotor landing using deep reinforcement learning," Landing an unmanned aerial vehicle (UAV) on a ground marker is an open problem despite the effort of the research community. Previous attempts mostly focused on the analysis of hand-crafted geometric features and the use of external sensors in order to allow the vehicle to approach the land-pad. In this article, we propose a method based on deep reinforcement learning that only requires low-resolution images taken from a down-looking camera in order to identify the position of the marker and land the UAV on it. The proposed approach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level control policy for the navigation toward the marker. We implemented different technical solutions, such as the combination of vanilla and double DQNs, and a partitioned buffer replay. Using domain randomization we trained the vehicle on uniform textures and we tested it on a large variety of simulated and real-world environments. The overall performance is comparable with a state-of-the-art algorithm and human pilots.",project-academic
,2021-07-18,a,,vision based autonomous car racing using deep imitative reinforcement learning," Autonomous car racing is a challenging task in the robotic control area. Traditional modular methods require accurate mapping, localization and planning, which makes them computationally inefficient and sensitive to environmental changes. Recently, deep-learning-based end-to-end systems have shown promising results for autonomous driving/racing. However, they are commonly implemented by supervised imitation learning (IL), which suffers from the distribution mismatch problem, or by reinforcement learning (RL), which requires a huge amount of risky interaction data. In this work, we present a general deep imitative reinforcement learning approach (DIRL), which successfully achieves agile autonomous racing using visual inputs. The driving knowledge is acquired from both IL and model-based RL, where the agent can learn from human teachers as well as perform self-improvement by safely interacting with an offline world model. We validate our algorithm both in a high-fidelity driving simulation and on a real-world 1/20-scale RC-car with limited onboard computation. The evaluation results demonstrate that our method outperforms previous IL and RL methods in terms of sample efficiency and task performance. Demonstration videos are available at this https URL",project-academic
10.1109/LRA.2021.3097345,2021-07-16,p,Institute of Electrical and Electronics Engineers (IEEE),vision based autonomous car racing using deep imitative reinforcement learning," Autonomous car racing is a challenging task in the robotic control area. Traditional modular methods require accurate mapping, localization and planning, which makes them computationally inefficient and sensitive to environmental changes. Recently, deep-learning-based end-to-end systems have shown promising results for autonomous driving/racing. However, they are commonly implemented by supervised imitation learning (IL), which suffers from the distribution mismatch problem, or by reinforcement learning (RL), which requires a huge amount of risky interaction data. In this work, we present a general deep imitative reinforcement learning approach (DIRL), which successfully achieves agile autonomous racing using visual inputs. The driving knowledge is acquired from both IL and model-based RL, where the agent can learn from human teachers as well as perform self-improvement by safely interacting with an offline world model. We validate our algorithm both in a high-fidelity driving simulation and on a real-world 1/20-scale RC-car with limited onboard computation. The evaluation results demonstrate that our method outperforms previous IL and RL methods in terms of sample efficiency and task performance. Demonstration videos are available at None https://caipeide.github.io/autorace-dirl/ .",project-academic
10.3390/ROBOTICS9010008,2020-02-25,a,MDPI AG,sim to real quadrotor landing via sequential deep q networks and domain randomization," The autonomous landing of an Unmanned Aerial Vehicle (UAV) on a marker is one of the most challenging problems in robotics. Many solutions have been proposed, with the best results achieved via customized geometric features and external sensors. This paper discusses for the first time the use of deep reinforcement learning as an end-to-end learning paradigm to find a policy for UAVs autonomous landing. Our method is based on a divide-and-conquer paradigm that splits a task into sequential sub-tasks, each one assigned to a Deep Q-Network (DQN), hence the name Sequential Deep Q-Network (SDQN). Each DQN in an SDQN is activated by an internal trigger, and it represents a component of a high-level control policy, which can navigate the UAV towards the marker. Different technical solutions have been implemented, for example combining vanilla and double DQNs, and the introduction of a partitioned buffer replay to address the problem of sample efficiency. One of the main contributions of this work consists in showing how an SDQN trained in a simulator via domain randomization, can effectively generalize to real-world scenarios of increasing complexity. The performance of SDQNs is comparable with a state-of-the-art algorithm and human pilots while being quantitatively better in noisy conditions.",project-academic
10.1109/ITSC48978.2021.9564899,2021-07-05,p,IEEE,learning a model for inferring a spatial road lane network graph using self supervision," Interconnected road lanes are a central concept for navigating urban roads. Currently, most autonomous vehicles rely on preconstructed lane maps as designing an algorithmic model is difficult. However, the generation and maintenance of such maps is costly and hinders large-scale adoption of autonomous vehicle technology. This paper presents the first self-supervised learning method to train a model to infer a spatially grounded lane-level road network graph based on a dense segmented representation of the road scene generated from onboard sensors. A formal road lane network model is presented and proves that any structured road scene can be represented by a directed acyclic graph of at most depth three while retaining the notion of intersection regions, and that this is the most compressed representation. The formal model is implemented by a hybrid neural and search-based model, utilizing a novel barrier function loss formulation for robust learning from partial labels. Experiments are conducted for all common road intersection layouts. Results show that the model can generalize to new road layouts, unlike previous approaches, demonstrating its potential for real-world application as a practical learning-based lane-level map generator.",project-academic
,2021-07-05,a,,learning a model for inferring a spatial road lane network graph using self supervision," Interconnected road lanes are a central concept for navigating urban roads. Currently, most autonomous vehicles rely on preconstructed lane maps as designing an algorithmic model is difficult. However, the generation and maintenance of such maps is costly and hinders large-scale adoption of autonomous vehicle technology. This paper presents the first self-supervised learning method to train a model to infer a spatially grounded lane-level road network graph based on a dense segmented representation of the road scene generated from onboard sensors. A formal road lane network model is presented and proves that any structured road scene can be represented by a directed acyclic graph of at most depth three while retaining the notion of intersection regions, and that this is the most compressed representation. The formal model is implemented by a hybrid neural and search-based model, utilizing a novel barrier function loss formulation for robust learning from partial labels. Experiments are conducted for all common road intersection layouts. Results show that the model can generalize to new road layouts, unlike previous approaches, demonstrating its potential for real-world application as a practical learning-based lane-level map generator.",project-academic
10.1109/CIST49399.2021.9357196,2020-06-05,p,IEEE,end to end neural network for vehicle dynamics modeling," Autonomous vehicles have to meet high safety standards in order to be commercially viable. Before real-world testing of an autonomous vehicle, extensive simulation is required to verify software functionality and to detect unexpected behavior. This incites the need for accurate models to match real system behavior as closely as possible. During driving, planing and control algorithms also need an accurate estimation of the vehicle dynamics in order to handle the vehicle safely. Until now, vehicle dynamics estimation has mostly been performed with physics-based models. Whereas these models allow specific effects to be implemented, accurate models need a variety of parameters. Their identification requires costly resources, e.g., expensive test facilities. Machine learning models enable new approaches to perform these modeling tasks without the necessity of identifying parameters. Neural networks can be trained with recorded vehicle data to represent the vehicle's dynamic behavior. We present a neural network architecture that has advantages over a physics-based model in terms of accuracy. We compare both models to real-world test data from an autonomous racing vehicle, which was recorded on different race tracks with high- and low-grip conditions. The developed neural network architecture is able to replace a single-track model for vehicle dynamics modeling.",project-academic
10.1109/ICECOS47637.2019.8984590,2019-10-01,p,IEEE,the lateral control of autonomous vehicles a review," Human need safety, comfort, and speed in driving-requirements that can be fulfiled by autonomous vehicles that enable drivers to avoid obstacles and maintain a safe distance from other motorists. These function are executed through lateral vehicle control, which has been the subject of considerable research. The current research was aimed at providing a comprehensive review and description of previous investigations that implemented both conventional and innovative lateral control methods, such as proportional- integral-derivative control, fuzzy logic, artificial intelligence, neural networks, genetic algorithms, and combined approaches. The evaluated studies were also classified into two categories, namely simulation and experimental research that used real-world tools. The paper concludes with a recomendation to use an alternative method called direct inverse control. Which is a modification of neural network- based control. This method is advantageous because it uses output/input feedback, thereby effectively functioning in unpredicable terrain. This feature is highly suitable because autonomous vehicles are non-linear system.",project-academic
,2016-01-01,a,,next generation intelligent driver vehicle infrastructure cooperative system for energy efficient driving in connected vehicle environment escholarship," Author(s): Qi, Xuewei | Advisor(s): Barth, Matthew J | Abstract: Transportation-related fossil fuel consumption and greenhouse gas emissions have received increasing public concern in recent years. To reduce energy consumption and mitigate the environmental impact of transportation activities, this dissertation research work aims at providing technical solutions by taking advantage of recent technology development in vehicle automation, vehicle connectivity and vehicle electrification. More specifically, a driver-vehicle-infrastructure cooperative framework for energy efficient driving of plug-in electric vehicles (PEVs) is proposed in this dissertation. Within this framework, this research improves energy efficiency of PEVs in the following ways: vehicle dynamics optimization and powertrain optimization, as well as co-optimization between them. For vehicle dynamics optimization, a connected ecodriving system has been designed for PEVs to optimize their speed profiles when travelling through signalized intersections, by receiving real-time signal phase and timing information obtained through wireless communications. The calculated optimal speed trajectory (in terms of energy efficiency) is provided to the driver through an in-vehicle display in real-time. The performance of this connected ecodriving system is implemented and evaluated at different automation levels: human driving without considering the driver error, human driving considering the driver error, and partial automated (longitudinal) driving. Numerical analysis with real-world driving data shows that there is 12% ,14% and 21% potential energy savings that can be achieved by these proposed strategies respectively. For powertrain operation optimization, an evolutionary algorithm based power-split control system for plug-in hybrid electric vehicle has been designed and evaluated with real-world traffic data. The designed model is used to optimally control the power-split between two different power sources (i.e., battery and gas tank) by considering various traffic conditions to achieve the minimum fuel consumption when satisfying total power-demand. In addition, a reinforcement-learning based autonomous learning strategy is also proposed for learning the optimal power-split decision based on historical driving data. Approximately 14% and 12% energy savings are identified by these two different powertrain operation strategies respectively.For co-optimization of the vehicle dynamics and powertrain optimization, a bi-level optimization strategy has been designed and tested with real-world driving data to achieve augmented energy benefits from the compound effect of vehicle dynamics and powertrain operations optimization. An average of 29% improvement of fuel efficiency for the tested PHEV is identified by combining the vehicle dynamics and powertrain operation optimization. The main contribution of this dissertation research is the design and validation of a driver-vehicle-infrastructure framework for PEV energy efficient driving. To the best of our knowledge, this is one of the first efforts to systematically investigate the potential energy benefits of both vehicle dynamics and powertrain operation optimization as well as its compound effect with real-world driving data for PEVs. The designed connected eco-driving system and power-split control model are quite promising in improving PEV energy efficiency.",project-academic
10.1007/978-981-16-1244-2_26,2021-01-01,a,"Springer, Singapore",application of neuroevolution in autonomous cars," With the onset of electric vehicles, and them becoming more and more popular, autonomous cars are the future in the travel/driving experience. The barrier to reaching level 5 autonomy is the difficulty in the collection of data that incorporates good driving habits and the lack thereof. The problem with current implementations of self-driving cars is the need for massively large datasets and the need to evaluate the driving in the dataset. We propose a system that requires no data for its training. An evolutionary model would have the capability to optimize itself towards the fitness function. We have implemented neuroevolution, a form of genetic algorithm, to train/evolve self-driving cars in a simulated virtual environment with the help of Unreal Engine 4, which utilizes Nvidia’s PhysX Physics Engine to portray real-world vehicle dynamics accurately. We were able to observe the serendipitous nature of evolution and have exploited it to reach our optimal solution. We also demonstrate the ease in generalizing attributes brought about by genetic algorithms and how they may be used as a boilerplate upon which other machine learning techniques may be used to improve the overall driving experience.",project-academic
10.1145/3324884.3415294,2020-12-21,p,IEEE,express an energy efficient and secure framework for mobile edge computing and blockchain based smart systems," As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.",project-academic
10.2514/6.2008-5913,2009-01-01,p,American Institute of Aeronautics and Astronautics,control and design of multiple unmanned air vehicles for persistent surveillance," Control of multiple autonomous aircraft for search and exploration, is a topic of current research interest for applications such as weather monitoring, geographical surveys, search and rescue, tactical reconnaissance, and extra-terrestrial exploration, and the need to distribute sensing is driven by considerations of efficiency, reliability, cost and scalability. Hence, this problem has been extensively studied in the fields of controls and artificial intelligence. 
The task of persistent surveillance is different from a coverage/exploration problem, in that all areas need to be continuously searched, minimizing the time between visitations to each region in the target space. This distinction does not allow a straightforward application of most exploration techniques to the problem, although ideas from these methods can still be used. The use of aerial vehicles is motivated by their ability to cover larger spaces and their relative insensitivity to terrain. However, the dynamics of Unmanned Air Vehicles (UAVs) adds complexity to the control problem. Most of the work in the literature decouples the vehicle dynamics and control policies, but their interaction is particularly interesting for a surveillance mission. Stochastic environments and UAV failures further enrich the problem by requiring the control policies to be robust, and this aspect is particularly important for hardware implementations. For a persistent mission, it becomes imperative to consider the range/endurance constraints of the vehicles. The coupling of the control policy with the endurance constraints of the vehicles is an aspect that has not been sufficiently explored. Design of UAVs for desirable mission performance is also an issue of considerable significance. The use of a single monolithic optimization for such a problem has practical limitations, and decomposition-based design is a potential alternative. 
In this research high-level control policies are devised, that are scalable, reliable, efficient, and robust to changes in the environment. Most of the existing techniques that carry performance guarantees are not scalable or robust to changes. The scalable techniques are often heuristic in nature, resulting in lack of reliability and performance. Our policies are tested in a multi-UAV simulation environment developed for this problem, and shown to be near-optimal in spite of being completely reactive in nature. We explicitly account for the coupling between aircraft dynamics and control policies as well, and suggest modifications to improve performance under dynamic constraints. A smart refueling policy is also developed to account for limited endurance, and large performance benefits are observed. The method is based on the solution of a linear program that can be efficiently solved online in a distributed setting, unlike previous work. The Vehicle Swarm Technology Laboratory (VSTL), a hardware testbed developed at Boeing Research and Technology for evaluating swarm of UAVs, is described next and used to test the control strategy in a real-world scenario. The simplicity and robustness of the strategy allows easy implementation and near replication of the performance observed in simulation. Finally, an architecture for system-of-systems design based on Collaborative Optimization (CO) is presented. Earlier work coupling operations and design has used frameworks that make certain assumptions not valid for this problem. The efficacy of our approach is illustrated through preliminary design results, and extension to more realistic settings is also demonstrated.",project-academic
10.1109/INTELLISYS.2017.8324372,2017-09-01,p,IEEE,machine learning and deep neural network artificial intelligence core for lab and real world test and validation for adas and autonomous vehicles ai for efficient and quality test and validation," Autonomous vehicles are now the future of automobile industry. Human drivers can be completely taken out of the loop through the implementation of safe and intelligent autonomous vehicles. Although we can say that HW and SW development continues to play a large role in the automotive industry, test and validation of these systems is a must. The ability to test these vehicles thoroughly and efficiently will ensure their proper and flawless operation. When a large number of people with heterogeneous knowledge and skills try to develop an autonomous vehicle together, it is important to use a sensible engineering process. State of the art techniques for such development include Waterfall, Agile & V-model, where test & validation (T&V) process is an integral part of such a development cycle. This paper will propose a new methodology using machine learning & deep neural network (AI-core) for lab & real-world T&V for ADAS (Advanced driver assistance system) and autonomous vehicles. The methodology will initially connect T&V of individual systems in each level of development and that of complete system efficiently, by using the proposed phase methodology, in which autonomous driving functions are grouped under categories, special T&V processes are carried on simulation as well as in HIL systems. The complete transition towards AI in the field of T&V will be a sequence of steps. Initially the AI-core is fed with available test scenarios, boundary conditions for the test cases and scenarios, and examples, the AI-core will conduct virtual tests on simulation environment using available test scenarios and further generates new test cases and scenarios for efficient and precise tests. These test cases and scenarios are meant to cover all available cases and concentrate on the area where bugs or failures occur. The complete surrounding environment in the simulation is also controlled by the AI-core which means that the system can attain endless/all-possible combinations of the surrounding environment which is necessary. Results of the tests are sorted and stored, critical and important tests are again repeated in the real-world environment using automated cars with other real subsystems to depict the surrounding environment, which are all controlled by the AI-core, and meanwhile the AI-core is always in the loop and learning from each and every executed test case and its results/outcomes. The main goal is to achieve efficient and high quality test and validation of systems for automated driving, which can save precious time in the development process. As a future scope of this methodology, we can step-up to make most parts of test and validation completely autonomous.",project-academic
10.1109/IVS.2019.8814001,2019-06-09,p,IEEE,cnn based object detection on low precision hardware racing car case study," Increasing interest in deep learning and convolutional neural networks resulted in the last years in multiple techniques aiming to improve their accuracy, training speed, and inference speed. At the same time, their computational cost triggered the design of several dedicated hardware architectures, aiming to handle the elevated number of operations neural networks require with minimal power budget, often exploiting reduced precision arithmetic. In this case study, we analyzed how several techniques can be merged together in the design of a track detector for a self-driving racing car, illustrating a step-by-step procedure required to adapt several theoretical works to a real-world scenario. Compared with the best previous detector, the new Proteins cone detector is optimized for low-precision deep learning accelerators. It runs 50% faster on GPU than the previous detector and at a simulated 272.5 FPS on a 1 W ASIC or at 16.4 FPS on a 12 W FPGA and achieves a detection score 16% higher than the previous implementation.",project-academic
10.1109/ITSC.2019.8917158,2019-11-01,p,IEEE,vision based lane changing behavior detection using deep residual neural network," Accurate lane localization and lane change detection are crucial in advanced driver assistance systems and autonomous driving systems for safer and more efficient trajectory planning. Conventional localization devices such as Global Positioning System only provide road-level resolution for car navigation, which is incompetent to assist in lane-level decision making. The state of art technique for lane localization is to use Light Detection and Ranging sensors to correct the global localization error and achieve centimeter-level accuracy, but the real-time implementation and popularization for LiDAR is still limited by its computational burden and current cost. As a cost-effective alternative, vision-based lane change detection has been highly regarded for affordable autonomous vehicles to support lane-level localization. A deep learning based computer vision system is developed to detect the lane change behavior using the images captured by a front-view camera mounted on the vehicle and data from the inertial measurement unit for highway driving. Testing results on real-world driving data have shown that the proposed method is robust with real-time working ability and could achieve around 87% lane change detection accuracy. Compared to the average human reaction to visual stimuli, the proposed computer vision system works 9 times faster, which makes it capable of helping make life-saving decisions in time.",project-academic
,2019-11-08,a,,vision based lane changing behavior detection using deep residual neural network," Accurate lane localization and lane change detection are crucial in advanced driver assistance systems and autonomous driving systems for safer and more efficient trajectory planning. Conventional localization devices such as Global Positioning System only provide road-level resolution for car navigation, which is incompetent to assist in lane-level decision making. The state of art technique for lane localization is to use Light Detection and Ranging sensors to correct the global localization error and achieve centimeter-level accuracy, but the real-time implementation and popularization for LiDAR is still limited by its computational burden and current cost. As a cost-effective alternative, vision-based lane change detection has been highly regarded for affordable autonomous vehicles to support lane-level localization. A deep learning-based computer vision system is developed to detect the lane change behavior using the images captured by a front-view camera mounted on the vehicle and data from the inertial measurement unit for highway driving. Testing results on real-world driving data have shown that the proposed method is robust with real-time working ability and could achieve around 87% lane change detection accuracy. Compared to the average human reaction to visual stimuli, the proposed computer vision system works 9 times faster, which makes it capable of helping make life-saving decisions in time.",project-academic
,2020-09-01,p,,express an energy efficient and secure framework for mobile edge computing and blockchain based smart systems this research is in part supported by the national natural science foundation of china project no 61972001," As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.",project-academic
10.1109/ICC42927.2021.9500318,2021-06-14,p,IEEE,reinforcement learning for autonomous vehicle movements in wireless sensor networks," In this work we use autonomous vehicles to improve the performance of Wireless Sensor Networks (WSNs). In contrast to other autonomous vehicle applications, WSNs have two metrics for performance evaluation. First, quality of information (QoI) which is used to measure the quality of sensed data (e.g., measurement uncertainties or signal strength). Second, quality of service (QoS) which is used to measure the network’s performance for data forwarding (e.g., delay and packet losses). As a use case, we consider wireless acoustic sensor networks, where a group of speakers move inside a room and there are autonomous vehicles installed with microphones for streaming the audio data. We formulate the problem as a Markov decision problem (MDP) and solve it using Deep-Q-Networks (DQN). Additionally, we compare the performance of DQN solution to two different real-world implementations: speakers holding/passing microphones and microphones being preinstalled in fixed positions.We show using simulations that the performance of autonomous vehicles in terms of QoI and QoS is better than the real-world implementation in some scenarios. Moreover, we study the impact of the vehicles speed on the learning process of the DQN solution and show how low speeds degrade the performance. Finally, we compare the DQN solution to a heuristic one and provide theoretical analysis of the performance with respect to dynamic WSNs.",project-academic
10.1109/UBI-MEDIA.2019.00014,2019-08-01,p,Institute of Electrical and Electronics Engineers Inc.,the matter of deep reinforcement learning towards practical ai applications," Reinforcement Learning (RL) is an extraordinarily paradigm that aims to solve a complex problem. This technique leverages the traditional feedforward networks with temporal-difference learning to overcome supervised and unsupervised real-world problems. However, RL is one of state-of-the-art topic due to the opaque aspects in design and implementation. Also, in which situation we will get performance gain from RL is still unclear. Therefore, This study firstly examines the impact of Experience Replay in Deep Q-Learning agent with Self-Driving Car application. Secondly, The impact of Eligibility Trace in RNN A3C agents with Breakout AI game application is studied. Our results indicated that these two techniques enhance RL performance by more than 20 percent as compared with traditional RL methods.",project-academic
10.1109/ISI49825.2020.9280513,2020-11-09,p,IEEE,a virtual simulation environment using deep learning for autonomous vehicles obstacle avoidance," Autonomous vehicles which are capable of operating independently will be commercially available in the near future. Autonomous driving systems are becoming more complicated and must be successfully checked before implementation. Within this framework, falls our research work. The key purpose of this paper is to implement a simulation environment for autonomous vehicles. We first created this environment which is a novel high fidelity driving simulator that can connect arbitrary interfaces, build simulated worlds consisting of scenarios and incidents experienced by drivers in real-world driving, and incorporate fully autonomous driving. The simulator makes possible to clone the behavior of human driver face as well as some complex situations such as obstacle avoidance maneuvers. The work consists in creating a virtual simulation environment to collect training data used to train vehicles on how to steer themselves. The simulator is, thus, like a video game of car racing. Indeed we used the scenes to make some driving experiences. After collecting the training data, we chose to use deep learning explicitly Convolutional Neural Networks to create a model for autonomous vehicles that avoid obstacles. Clearly, the true challenge for an autonomous vehicle is to navigate without the possibility of collision. This simulator is invested to assess the performance of an autonomous vehicle and to analyze its self-driving activities. In this method, the suggested solution proves to be feasible, efficient and reliable for autonomous vehicle simulation research.",project-academic
,2019-01-01,b,Packt Publishing,neural networks with keras cookbook," Implement neural network architectures by building them from scratch for multiple real-world applications.

	Key Features

	
		From scratch, build multiple neural network architectures such as CNN, RNN, LSTM in Keras
	
		Discover tips and tricks for designing a robust neural network to solve real-world problems
	
		Graduate from understanding the working details of neural networks and master the art of fine-tuning them


	Book Description

	This book will take you from the basics of neural networks to advanced implementations of architectures using a recipe-based approach.

	We will learn about how neural networks work and the impact of various hyper parameters on a network's accuracy along with leveraging neural networks for structured and unstructured data.

	Later, we will learn how to classify and detect objects in images. We will also learn to use transfer learning for multiple applications, including a self-driving car using Convolutional Neural Networks.

	We will generate images while leveraging GANs and also by performing image encoding. Additionally, we will perform text analysis using word vector based techniques. Later, we will use Recurrent Neural Networks and LSTM to implement chatbot and Machine Translation systems.

	Finally, you will learn about transcribing images, audio, and generating captions and also use Deep Q-learning to build an agent that plays Space Invaders game.

	By the end of this book, you will have developed the skills to choose and customize multiple neural network architectures for various deep learning problems you might encounter.

	What you will learn

	
		Build multiple advanced neural network architectures from scratch
	
		Explore transfer learning to perform object detection and classification
	
		Build self-driving car applications using instance and semantic segmentation
	
		Understand data encoding for image, text and recommender systems
	
		Implement text analysis using sequence-to-sequence learning
	
		Leverage a combination of CNN and RNN to perform end-to-end learning
	
		Build agents to play games using deep Q-learning


	Who this book is for

	This intermediate-level book targets beginners and intermediate-level machine learning practitioners and data scientists who have just started their journey with neural networks. This book is for those who are looking for resources to help them navigate through the various neural network architectures; you'll build multiple architectures, with concomitant case studies ordered by the complexity of the problem. A basic understanding of Python programming and a familiarity with basic machine learning are all you need to get started with this book.",project-academic
10.17638/03021623,2018-05-22,a,University of Liverpool,an exploration of traffic signal control using multi agent market based mechanisms," Traffic congestion is a major issue on many urban road networks around the world. The distributed and stochastic nature of traffic has attracted the multi-agent and market mechanism community to the traffic domain which has resulted in many novel approaches to both traffic control and traffic assignment. However, the real-world application of many market-based traffic control systems remains in question because they require technology that has not yet been developed, e.g., autonomous cars. This thesis focuses on the use of market mechanisms for traffic control, more specifically, the application of market principles set forth in market-based multi-robot systems to the traffic domain. Thus, the primary goal of this thesis is the design, implementation and evaluation of a multi-agent market-based traffic control system which does not rely on vehicle agents and other major changes to vehicles or transportation infrastructure. Evaluation of the traffic control system is conducted on two grid-based maps using six different traffic scenarios. The traffic scenarios represent various traffic patterns which include changes in traffic intensity and direction. The traffic scenarios are simulated in SUMO, an open source, macro traffic simulator. Additionally, performance is measured using three metrics: travel time, traffic density, and number of stops. This thesis makes five contributions: (i) demonstration of the efficacy of a novel multi-agent market-based traffic control methodology; (ii) demonstration of the efficacy of a market-based technique for dynamic coalition formation; (iii) analysis of three key traffic control parameters used by SCOOT, a popular urban adaptive traffic control mechanism used in over a dozen countries; (iv ) development of a Python implementation of SCOOT for use on SUMO and (v) a thorough evaluation of the novel market-based mechanisms introduced here, along with SCOOT and a reinforcement-learning traffic controller, over a variety of road traffic conditions. This thesis provides a unique insight into the behaviour of three key traffic control parameters and results show that the novel market-based mechanism has the potential to improve traffic performance in traffic conditions that are less than ideal for SCOOT.",project-academic
,2012-01-01,b,,architecture support for automobile autonomy a state of the art survey," Highly automated driving systems promise increased road traffic safety, as well as positive impacts on sustainable transportation by means of increased traffic efficiency and environmental friendliness. The design and development of such systems require scientific advances in a number of areas. One area is the vehicle's electrical/electronic (E/E) architecture. The E/E architecture can be presented using a number of views, of which an important one is the functional view. The functional view describes the decomposition of the system into its main logical components, along with the hierarchical structure, the component inter-connections, and requirements. When this view captures the principal ideas and patterns that constitute the foundation of a variety of specific architectures, it may be termed as a reference architecture. Two reference architectures for highly automated driving form the principal contribution of this thesis. The first reference architecture is for cooperative driving. In a cooperative driving situation, vehicles and road infrastructure in the vicinity of a vehicle continuously exchange wireless information and this information is then used to control the motion of the vehicle. The second reference architecture is for autonomous driving, wherein the vehicle is capable of driver-less operation even without direct communication with external entities. The description of both reference architectures includes their main components and the rationale for how these components should be distributed across the architecture and its layers. These architectures have been validated via multiple real-world instantiations, and the guidelines for instantiation also form part of the architecture description. A comparison with similar architectures is also provided, in order to highlight the similarities and differences. The comparisons show that in the context of automated driving, the explicit recognition of components for semantic understanding, world modeling, and vehicle platform abstraction are unique to the proposed architecture. These components are not unusual in architectures within the Artificial Intelligence/robotics domains; the proposed architecture shows how they can be applied within the automotive domain. A secondary contribution of this thesis is a description of a lightweight, four step approach for model based systems engineering of highly automated driving systems, along with supporting model classes. The model classes cover the concept of operations, logical architecture, application software components, and the implementation platforms. The thesis also provides an overview of current implementation technologies for cognitive driving intelligence and vehicle platform control, and recommends a specific setup for development and accelerated testing of highly automated driving systems, that includes model- and hardware-in-the-loop techniques in conjunction with a publish/subscribe bus. Beyond the more ""traditional"" engineering concepts, the thesis also investigates the domain of machine consciousness and computational self-awareness. The exploration indicates that current engineering methods are likely to hit a complexity ceiling, breaking through which may require advances in how safety-critical systems can self-organize, construct, and evaluate internal models to reflect their perception of the world. Finally, the thesis also presents a functional architecture for the brake system of an autonomous truck. This architecture proposes a reconfiguration of the existing brake systems of the truck in a way that provides dynamic, diversified redundancy, and an increase in the system reliability and availability, while meeting safety requirements.",project-academic
10.1016/J.INFFUS.2021.09.004,2022-02-01,a,Elsevier,multimodal earth observation data fusion graph based approach in shared latent space," Abstract None None Multiple and heterogenous Earth observation (EO) platforms are broadly used for a wide array of applications, and the integration of these diverse modalities facilitates better extraction of information than using them individually. The detection capability of the multispectral unmanned aerial vehicle (UAV) and satellite imagery can be significantly improved by fusing with ground hyperspectral data. However, variability in spatial and spectral resolution can affect the efficiency of such dataset's fusion. In this study, to address the modality bias, the input data was projected to a shared latent space using cross-modal generative approaches or guided unsupervised transformation. The proposed adversarial networks and variational encoder-based strategies used bi-directional transformations to model the cross-domain correlation without using cross-domain correspondence. It may be noted that an interpolation-based convolution was adopted instead of the normal convolution for learning the features of the point spectral data (ground spectra). The proposed generative adversarial network-based approach employed dynamic time wrapping based layers along with a cyclic consistency constraint to use the minimal number of unlabeled samples, having cross-domain correlation, to compute a cross-modal generative latent space. The proposed variational encoder-based transformation also addressed the cross-modal resolution differences and limited availability of cross-domain samples by using a mixture of expert-based strategy, cross-domain constraints, and adversarial learning. In addition, the latent space was modelled to be composed of modality independent and modality dependent spaces, thereby further reducing the requirement of training samples and addressing the cross-modality biases. An unsupervised covariance guided transformation was also proposed to transform the labelled samples without using cross-domain correlation prior. The proposed latent space transformation approaches resolved the requirement of cross-domain samples which has been a critical issue with the fusion of multi-modal Earth observation data. This study also proposed a latent graph generation and graph convolutional approach to predict the labels resolving the domain discrepancy and cross-modality biases. Based on the experiments over different standard benchmark airborne datasets and real-world UAV datasets, the developed approaches outperformed the prominent hyperspectral panchromatic sharpening, image fusion, and domain adaptation approaches. By using specific constraints and regularizations, the network developed was less sensitive to network parameters, unlike in similar implementations. The proposed approach illustrated improved generalizability in comparison with the prominent existing approaches. In addition to the fusion-based classification of the multispectral and hyperspectral datasets, the proposed approach was extended to the classification of hyperspectral airborne datasets where the latent graph generation and convolution were employed to resolve the domain bias with a small number of training samples. Overall, the developed transformations and architectures will be useful for the semantic interpretation and analysis of multimodal data and are applicable to signal processing, manifold learning, video analysis, data mining, and time series analysis, to name a few.",project-academic
,2017-05-15,a,,airsim high fidelity visual and physical simulation for autonomous vehicles," Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.",project-academic
10.1007/978-3-319-67361-5_40,2017-05-15,p,"Springer, Cham",airsim high fidelity visual and physical simulation for autonomous vehicles," Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.",project-academic
,2019-03-27,,,training testing and verifying autonomous machines using simulated environments," In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment—in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack—to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle.",project-academic
10.1109/JIOT.2020.3010700,2021-01-15,a,Institute of Electrical and Electronics Engineers,dynamic resource allocation model for distribution operations using sdn," In vehicular None ad hoc None networks, autonomous vehicles generate a large amount of data prior to support in-vehicle applications. So, big storage and high computation platform are needed. On the other hand, the computation for vehicular networks at the cloud platform requires low latency. Applying edge computation (EC) as a new computing paradigm has potentials to provide computation services while reducing the latency and improving the total utility. We propose a three-tier EC framework to set the elastic calculating processing capacity and dynamic route calculation to suitable edge servers for real-time vehicle monitoring. This framework includes the cloud computation layer, EC layer, and device layer. The formulation of the resource allocation approach is similar to an optimization problem. We design a new reinforcement learning (RL) algorithm to deal with the resource allocation problem assisted by cloud computation. By integration of EC and software-defined networking (SDN), this study provides a new SDN edge (SDNE) framework for resource assignment in vehicular networks. The novelty of this work is to design a multiagent RL-based approach using experience reply. The proposed algorithm stores the users’ communication information and the network tracks’ state in real time. The results of simulation with various system factors are presented to display the efficiency of the suggested framework. We present results with a real-world case study.",project-academic
10.1007/978-981-15-2369-4_33,2020-01-01,a,"Springer, Singapore",machine learning an overview of classification techniques," Nowadays, machine learning plays a vital role in software industry and is of utmost demand in day-to-day life activities. Machine learning has emerged as one of the popular technology for solving real-world applications as autonomous vehicle, speech recognition, image processing, natural language processing and so on. As per Intel/IDC, about 76% of Indian companies are feeling the dearth of skilled talented professional in machine learning. By 2025, it is estimated that the machine learning sector in software industries will grow up to the $16 billion share. In this paper, different machine learning model based on supervised approach is proposed and compared the performance in terms of accuracy on training data and test data, precision, recall and F measure. Python is used for experimental work.",project-academic
10.3311/PPTR.15837,2020-06-29,a,Periodica Polytechnica Budapest University of Technology and Economics,fast prototype framework for deep reinforcement learning based trajectory planner," Reinforcement Learning, as one of the main approaches of machine learning, has been gaining high popularity in recent years, which also affects the vehicle industry and research focusing on automated driving. However, these techniques, due to their self-training approach, have high computational resource requirements. Their development can be separated into training with simulation, validation through vehicle dynamics software, and real-world tests. However, ensuring portability of the designed algorithms between these levels is difficult. A case study is also given to provide better insight into the development process, in which an online trajectory planner is trained and evaluated in both vehicle simulation and real-world environments.",project-academic
,2018-03-31,a,,indoor flight of ar drone 2 0 uav in vicon motion capture system," Swarming behavior with artificial intelligence have been extensively simulated as computer based by researchers and students, using unmanned aerial vehicles with autopilot software will allow theses simulations to enter the real-world. In this project, the Paparazzi UAV autopilot software is to be integrated with the Vicon motion capture system allowing an AR Drone 2.0 to fly autonomously. The solution provided indicates that the Paparazzi software can be integrated with a Vicon system. The solution has the potential to be used on various unmanned aerial vehicle platforms.",project-academic
10.3390/RS13122308,2021-06-12,a,Multidisciplinary Digital Publishing Institute,spatial super resolution of real world aerial images for image based plant phenotyping," Unmanned aerial vehicle (UAV) imaging is a promising data acquisition technique for image-based plant phenotyping. However, UAV images have a lower spatial resolution than similarly equipped in field ground-based vehicle systems, such as carts, because of their distance from the crop canopy, which can be particularly problematic for measuring small-sized plant features. In this study, the performance of three deep learning-based super resolution models, employed as a pre-processing tool to enhance the spatial resolution of low resolution images of three different kinds of crops were evaluated. To train a super resolution model, aerial images employing two separate sensors co-mounted on a UAV flown over lentil, wheat and canola breeding trials were collected. A software workflow to pre-process and align real-world low resolution and high-resolution images and use them as inputs and targets for training super resolution models was created. To demonstrate the effectiveness of real-world images, three different experiments employing synthetic images, manually downsampled high resolution images, or real-world low resolution images as input to the models were conducted. The performance of the super resolution models demonstrates that the models trained with synthetic images cannot generalize to real-world images and fail to reproduce comparable images with the targets. However, the same models trained with real-world datasets can reconstruct higher-fidelity outputs, which are better suited for measuring plant phenotypes.",project-academic
10.1109/ASYU50717.2020.9259830,2020-10-15,p,IEEE,real time implementation of mini autonomous car based on mobilenet single shot detector," In this paper, in order to realize a prototype of an autonomous vehicle, we present a framework that consists of convolutional neural networks and image processing methods. The study is comprised of two main parts as software and hardware. In the hardware part, a small-sized smart video car kit is used as the prototype of the autonomous car. This programmable tool consists of Raspberry Pi, servo motors and a USB webcam whose angle of vision is equal to 120°. In the software part, we propose an algorithm in which we use Convolutional Neural Networks to detect the objects (vehicles, pedestrians, and traffic signs) and Hough transformation to detect the road lanes. Based on the outputs of the object and lane detections, the system decides the speed and the direction of the car in real-time. In our results, the vehicle performs autonomous driving in the scaled real-world application.",project-academic
,2020-12-31,a,,vehicular network slicing for reliable access and deadline constrained data offloading a multi agent on device learning approach," Efficient data offloading plays a pivotal role in computational-intensive platforms as data rate over wireless channels is fundamentally limited. On top of that, high mobility adds an extra burden in vehicular edge networks (VENs), bolstering the desire for efficient user-centric solutions. Therefore, unlike the legacy inflexible network-centric approach, this paper exploits a software-defined flexible, open, and programmable networking platform for an efficient user-centric, fast, reliable, and deadline-constrained offloading solution in VENs. In the proposed model, each active vehicle user (VU) is served from multiple low-powered access points (APs) by creating a noble virtual cell (VC). A joint node association, power allocation, and distributed resource allocation problem is formulated. As centralized learning is not practical in many real-world problems, following the distributed nature of autonomous VUs, each VU is considered an edge learning agent. To that end, considering practical location-aware node associations, a joint radio and power resource allocation non-cooperative stochastic game is formulated. Leveraging reinforcement learning's (RL) efficacy, a multi-agent RL (MARL) solution is proposed where the edge learners aim to learn the Nash equilibrium (NE) strategies to solve the game efficiently. Besides, real-world map data, with a practical microscopic mobility model, are used for the simulation. Results suggest that the proposed user-centric approach can deliver remarkable performances in VENs. Moreover, the proposed MARL solution delivers near-optimal performances with approximately 3% collision probabilities in case of distributed random access in the uplink.",project-academic
10.26083/TUPRINTS-00018613,2021-01-01,a,,development of a method for the fusion of environment perception sensor data for an automated vehicle," Autonomous driving is currently one of the most anticipated future technologies of the automotive world, and researchers from all over the world are dedicated to this task. In the same pursuit, the aDDa project at TU Darmstadt is a collaboration of researchers and students, focused on jointly engineering a car into a fully autonomous vehicle. As such, the aDDa research vehicle is outfitted with a wide array of sensors for environment perception.

Within the scope of the aDDa project, this thesis covers the fusion of data from LIDAR, RADAR and camera sensors into a unified environment model. Specifically, this work focuses on providing real-time environment perception, including fusion and interpretation of data from different sensors using only on-board hardware resources.

The developed method is a software pipeline, consisting of an analytical low-level sensor fusion stage, a 3D semantic segmentation model based on deep learning, and analytical clustering and tracking methods, as well as a proof-of-concept for estimating drivable space. This method is designed to maximize robustness, by minimizing the influence of the used machine learning approach on the reliability of obstacle detection. The sensor fusion pipeline runs in real-time with an output frequency of 10 Hz, and a pipeline delay of 120 to 190 milliseconds in the encountered situations on public roads.

An evaluation of several scenarios shows that the developed system can reliably detect a target vehicle in a variety of real-world situations.

The full contributions of this work not only include the development of a sensor fusion pipeline, but also methods for sensor calibration, as well as a novel method for generating training data for the used machine learning approach. In contrast to existing manual methods of data annotation, this work presents a scalable solution for annotating real-world sensor recordings to generate training data for 3D machine perception approaches for autonomous driving.",project-academic
10.14264/UQL.2020.887,2020-07-06,a,,accurate dense depth from light field technology for object segmentation and 3d computer vision," Depth estimation affects feature extraction, object segmentation and three-dimensional (3D) reconstruction. Practical applications impacted by depth estimation include autonomous vehicle navigation, computational photography, augmented and visual reality. Recent advancements in neural network algorithms have been linked to an increase in depth estimation accuracy. With the aid of graphics processing units (GPU), examples where neural networks have been used for improving depth estimation accuracy are depth from video, multiple images, stereo image pairs or a single image. Despite the emphasis for neural networks to improve depth estimation algorithms, the datasets used in experimental evaluations have not seen the same amount of attention. The benchmark datasets for depth estimation may be lacking in efficiency for obtaining real data, high-resolution images or scenes containing complex object structures. Consequently, this results in many state-of-the-art depth estimation algorithms to fail in practical applications since these scenarios are not considered during the training procedure. Recent state-of-the-art depth estimation algorithms declare that their methodologies are not suitable for occlusion or non-Lambertian surfaces. The Lambertian approximation is defined by two cases. The first case is different viewpoints from multiple cameras are photo-consistent. The second case is objects are composed by a collection of piecewise, planar surfaces. Since many objects in reality are not bound by these two cases, algorithms assuming Lambertian approximations produce low accuracy in practical applications. In this thesis, we propose a cost-efficient, high-resolution dataset that contains scenes of challenging object shapes. The dataset is acquired using light field technology for depth estimation from a Lytro camera. The proposed dataset contains high-resolution images with objects addressing the Lambertian approximation problem. This dataset aims to improve the accuracy of current depth estimation algorithms by instigating difficult evaluations observed in real-world scenarios. The depth information used for ground truth data in our proposed dataset is adapted from the Lytro software for converting the four dimensional (4D) light field file into the isolated depth channel. In comparison to benchmark datasets, this is a cost-effective solution for acquiring real data. We also propose a detailed study and utilisation of generative adversarial networks to predict depth from a single view. During the training procedure of the generative adversarial network, a loss function is optimized for the purpose of depth prediction from a single image. We analyse the generative adversarial method for depth from a single image on the proposed depth dataset in addition to benchmark depth datasets.",project-academic
10.6092/POLITO/PORTO/2518884,2012-01-01,a,Politecnico di Torino,development and evaluation of neural network based virtual air data sensor for estimation of aerodynamic angles," Aerodynamic angles of ight vehicles are necessary to pilot and automatically control of aircraft. These angles are usually measured using probes that protrude from the vehicle surface out into the ow eld. However, this arrangement was found to be unacceptable for modern unmanned airplanes whenever stealthiness features are required. In addition, redundant sensor arrangements, when dictated by safety regulations, were also critical because of the possible heavy impact on the airframe of small UAVs. New virtual software-based systems were therefore developed in order to nd a viable solution for reducing the number of traditional hardware-based air data sensors, and they oered the benet of simplifying air data system architectures. The aerodynamic angles were derived from inertial data and by exploiting the airspeed sourced by the Pitot-static system. The relationship between these parameters and the aerodynamic angles was a complex, non-linear function that was not easily described by means of aircraft models. The main goal of this work, which was aimed at UAV applications, was to analyze the aircraft system and develop virtual sensors by exploiting soft computing methods, such as neural prediction techniques, in order to assess the feasibility of this kind of neural system. The performance of virtual sensors were tested using real hardware in the simulation loop and to represent real-world ight conditions: wind gusts, air turbulence and internal sensor noise were simulated. A sensitivity analysis was carried out to study the performance of virtual sensors even when realistic accuracy of measured signals, processed by neural networks, and failure modes were simulated. Finally, neural networks resulted to be suited for aerodynamic angle estimation technique: the neural networks worked properly with the available vehicle data and demonstreted to be as accurate as traditional probes",project-academic
,2014-04-09,a,,vision based autonomous robotic control for advanced inspection and repair," The advanced inspection system is an autonomous control and analysis system that improves the inspection and remediation operations for ground and surface systems. It uses optical imaging technology with intelligent computer vision algorithms to analyze physical features of the real-world environment to make decisions and learn from experience. The advanced inspection system plans to control a robotic manipulator arm, an unmanned ground vehicle and cameras remotely, automatically and autonomously. There are many computer vision, image processing and machine learning techniques available as open source for using vision as a sensory feedback in decision-making and autonomous robotic movement. My responsibilities for the advanced inspection system are to create a software architecture that integrates and provides a framework for all the different subsystem components; identify open-source algorithms and techniques; and integrate robot hardware.",project-academic
,2019-11-29,b,,ai crash course," This friendly and accessible guide to AI theory and programming in Python requires no maths or data science background.
Key Features
Roll up your sleeves and start programming AI models

No math, data science, or machine learning background required

Packed with hands-on examples, illustrations, and clear step-by-step instructions

5 hands-on working projects put ideas into action and show step-by-step how to build intelligent software
Book Description
AI is changing the world – and with this book, anyone can start building intelligent software!

Through his best-selling video courses, Hadelin de Ponteves has taught hundreds of thousands of people to write AI software. Now, for the first time, his hands-on, energetic approach is available as a book. Taking a graduated approach that starts with the basics before easing readers into more complicated formulas and notation, Hadelin helps you understand what you really need to build AI systems with reinforcement learning and deep learning. Five full working projects put the ideas into action, showing step-by-step how to build intelligent software using the best and easiest tools for AI programming:

Google Colab
Python
TensorFlow
Keras
PyTorch

AI Crash Course teaches everyone to build an AI to work in their applications. Once you've read this book, you're only limited by your imagination.
What you will learn
Master the key skills of deep learning, reinforcement learning, and deep reinforcement learning

Understand Q-learning and deep Q-learning

Learn from friendly, plain English explanations and practical activities

Build fun projects, including a virtual-self-driving car

Use AI to solve real-world business problems and win classic video games

Build an intelligent, virtual robot warehouse worker
Who this book is for
If you want to add AI to your skillset, this book is for you. It doesn't require data science or machine learning knowledge. Just maths basics (high school level).",project-academic
,2018-04-25,a,,driving policy transfer via modularity and abstraction," End-to-end approaches to autonomous driving have high sample complexity and are difficult to scale to realistic urban driving. Simulation can help end-to-end driving systems by providing a cheap, safe, and diverse training environment. Yet training driving policies in simulation brings up the problem of transferring such policies to the real world. We present an approach to transferring driving policies from simulation to reality via modularity and abstraction. Our approach is inspired by classic driving systems and aims to combine the benefits of modular architectures and end-to-end deep learning approaches. The key idea is to encapsulate the driving policy such that it is not directly exposed to raw perceptual input or low-level vehicle dynamics. We evaluate the presented approach in simulated urban environments and in the real world. In particular, we transfer a driving policy trained in simulation to a 1/5-scale robotic truck that is deployed in a variety of conditions, with no finetuning, on two continents. The supplementary video can be viewed at this https URL",project-academic
,2007-01-06,p,Morgan Kaufmann Publishers Inc.,sharing the road autonomous vehicles meet human drivers," In modern urban settings, automobile traffic and collisions lead to endless frustration as well as significant loss of life, property, and productivity. Recent advances in artificial intelligence suggest that autonomous vehicle navigation may soon be a reality. In previous work, we have demonstrated that a reservation-based approach can efficiently and safely govern interactions of multiple autonomous vehicles at intersections. Such an approach alleviates many traditional problems associated with intersections, in terms of both safety and efficiency. However, the system relies on all vehicles being equipped with the requisite technology-a restriction that would make implementing such a system in the real world extremely difficult. In this paper, we extend this system to allow for incremental deployability. The modified system is able to accommodate traditional human-operated vehicles using existing infrastructure. Furthermore, we show that as the number of autonomous vehicles on the road increases, traffic delays decrease monotonically toward the levels exhibited in our previous work. Finally, we develop a method for switching between various human-usable configurations while the system is running, in order to facilitate an even smoother transition. The work is fully implemented and tested in our custom simulator, and we present detailed experimental results attesting to its effectiveness.",project-academic
10.1109/DSN-W.2018.00027,2018-06-25,p,IEEE,avfi fault injection for autonomous vehicles," Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S. roads, offering the promise of improvements in traffic management, safety, and the comfort and efficiency of vehicular travel. With this increasing popularity and ubiquitous deployment, resilience has become a critical requirement for public acceptance and adoption. Recent studies into the resilience of AVs have shown that though the AV systems are improving over time, they have not reached human levels of automation. Prior work in this area has studied the safety and resilience of individual components of the AV system (e.g., testing of neural networks powering the perception function). However, methods for holistic end-to-end resilience assessment of AV systems are still non-existent.",project-academic
10.2514/6.2017-3085,2017-06-05,p,American Institute of Aeronautics and Astronautics,exploring concepts of operations for on demand passenger air transportation," In recent years, a surge of interest in ""flying cars"" for city commutes has led to rapid development of new technologies to help make them and similar on-demand mobility platforms a reality. To this end, this paper provides analyses of the stakeholders involved, their proposed operational concepts, and the hazards and regulations that must be addressed. Three system architectures emerged from the analyses, ranging from conventional air taxi to revolutionary fully autonomous aircraft operations, each with vehicle safety functions allocated differently between humans and machines. Advancements for enabling technologies such as distributed electric propulsion and artificial intelligence have had major investments and initial experimental success, but may be some years away from being deployed for on-demand passenger air transportation at scale.",project-academic
10.1109/MWC.2020.9085257,2020-05-13,a,IEEE,artificial intelligence driven fog radio access networks recent advances and future trends," The articles in this special section focus on artificial intelligence-driven fog radio access networks. To satisfy the explosively increasing demands of highspeed data applications and access requirements from a massive number of Internet-of-Things (IoT) devices, a paradigm of fog computing-based radio access network (F-RAN) has emerged as a promising evolution path for the fifth generation (5G) radio access networks. By taking full advantage of distributed caching and centralized processing, F-RANs provide great flexibility to satisfy the quality-of-service requirements of various 5G services. With the rapid deployment of 5G communication networks, the application of F-RANs to the envisioned sixth-generation (6G) mobile network has attracted extensive attention from academia, industry, and government agencies. The 6G network progress in enhanced mobile broadband, massive machine-type communications and ultra-reliable and low-latency communications will lead to the fast development of new applications, including augmented reality (AR), virtual reality (VR), holographic communications, vehicle-to-everything (V2X), self-driving cars, massive sensors connective on the ground and several tens of thousands of satellites connective in the sky.",project-academic
,2018-10-03,a,,deep learning based caching for self driving car in multi access edge computing," Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to high delay of car-to-DC communication. To address these challenges, we propose a deep learning based caching for self-driving car, by using Deep Learning approaches deployed on the Multi-access Edge Computing (MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, in order to cache entertainment contents stylized for car passengers' features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers. Third, each car requests MLP output from MEC server and compares its CNN and MLP outputs by using k-means and binary classification. Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay. To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied. The simulation results show that the accuracy of our prediction for the contents need to be cached in the areas of the self-driving car is achieved at 98.04% and our approach can minimize delay.",project-academic
10.1109/GLOBECOM42002.2020.9322556,2020-12-01,p,IEEE,caching placement and resource allocation for ar application in uav noma networks," The cache-enabling unmanned aerial vehicle (UAV) cellular networks with massive access capability supported by non-orthogonal multiple access (NOMA) are investigated in this paper. The delivery of multi-media contents for the mixed augmented reality (AR) and normal multi-media application is assisted by multiple mobile UAV base stations, which cache popular contents for wireless backhaul link traffic offloading. To cope with the dynamic content requests and mobility of users in practical scenarios, the dynamic optimization problem for user association, caching placement of UAVs, real-time deployment of UAVs, and power allocation of NOMA is modeled as a stackelberg game to minimize the long-term content delivery delay. Specifically, the game is decomposed into a leader level problem and a number of follower level problems. A correction mechanism is added in deep reinforcement learning (DRL) to optimize the user association in leader level. A meta actor network is proposed in DRL to jointly optimize the UAVs caching placement, real-time UAVs deployment and power allocation of NOMA in follower level. Then, a dynamic caching placement and resource allocation algorithm based on multi-agent meta deep reinforcement learning is proposed to minimize the long-term content delivery delay. Finally, we demonstrate that the considerable gains are achieved by the proposed algorithm.",project-academic
10.1007/978-981-15-9255-3_1,2021-01-01,a,"Springer, Singapore",challenges for and with autonomous vehicles an introduction," The deployment of autonomous vehicles has been announced for years. Yet, full autonomous vehicles are not on public roads. Elon Musk, speaking at an event during the first half of 2020, stated that his firm will be able to present a fully autonomous vehicle technology by the end of the year. This statement is met with skepticism, especially because several of the challenges that existed have not been solved. Road traffic laws have not been adjusted to face the reality of driving by an autonomous machine. The only way that full autonomous vehicles can hit public roads is through test procedures. There also exists quite some uncertainty on who should be liable for accidents with autonomous vehicles. Accidents may occur, and this is something that adversarial machine learning is showing. Even with the best set of sensors, the interpretation of the sensed environment may be misinterpreted. Connectivity is being suggested as a possible solution to several of the problems autonomous vehicles are facing. Deploying autonomous vehicles will also challenge business organization, as car manufacturers may turn their business vehicles into mobility service providers. This may require a different type of organization within the firm.",project-academic
10.1109/TNNLS.2021.3056444,2021-02-19,a,IEEE,data driven performance prescribed reinforcement learning control of an unmanned surface vehicle," An unmanned surface vehicle (USV) under complicated marine environments can hardly be modeled well such that model-based optimal control approaches become infeasible. In this article, a self-learning-based model-free solution only using input-output signals of the USV is innovatively provided. To this end, a data-driven performance-prescribed reinforcement learning control (DPRLC) scheme is created to pursue control optimality and prescribed tracking accuracy simultaneously. By devising state transformation with prescribed performance, constrained tracking errors are substantially converted into constraint-free stabilization of tracking errors with unknown dynamics. Reinforcement learning paradigm using neural network-based actor-critic learning framework is further deployed to directly optimize controller synthesis deduced from the Bellman error formulation such that transformed tracking errors evolve a data-driven optimal controller. Theoretical analysis eventually ensures that the entire DPRLC scheme can guarantee prescribed tracking accuracy, subject to optimal cost. Both simulations and virtual-reality experiments demonstrate the remarkable effectiveness and superiority of the proposed DPRLC scheme.",project-academic
,2016-01-01,a,,autonomy of military robots assessing the technical and legal a œjus in belloa s thresholds 32 j marshall j info tech privacy l 57 2016," While robots are still absent from our homes, they have started to spread over battlefields. However, the military robots of today are mostly remotely controlled platforms, with no real autonomy. This paper will disclose the obstacles in implementing autonomy for such systems by answering a technical question: What level of autonomy is needed in military robots and how and when might it be achieved, followed by a techno-legal one: How to implement the rules of humanitarian law within autonomous fighting robots, in order to allow their legal deployment? The first chapter scrutinizes the significance of autonomy in robots and the metrics used to quantify it, which were developed by the US Department of Defense. The second chapter focuses on the autonomy of ""state-of-the-art” robots (e.g.; Google’s self-driving car, DARPA’s projects, etc.) for navigation, ISR or lethal missions. Based on public information, we will get a hint of the architectures, the functioning, the thresholds and technical limitations of such systems. The bottleneck to a higher autonomy of robots seems to be their poor “perceptive intelligence.” The last chapter looks to the requirements of humanitarian law (rules of “jus in bello”/rules of engagement) to the legal deployment of autonomous lethal robots on the battlefields. The legal and moral reasoning of human soldiers, complying with humanitarian law, is a complex cognitive process which must be emulated by autonomous robots that could make lethal decisions. However, autonomous completion of such “moral” tasks by artificial agents is much more challenging than the autonomous implementation of other tasks, such as navigation, ISR or kinetic attacks. Given the limits of current Artificial Intelligence, it is highly unlikely that robots will acquire such moral capabilities anytime soon. Therefore, for the time being, the autonomous weapon systems might be legally deployed, but only in very particular circumstances, where the requirements of humanitarian law happen to be irrelevant. 2015] AUTONOMY OF MILITARY ROBOTS 59 I. THE MEANING OF AUTONOMY IN ROBOTS AND WAYS TO QUANTIFY IT A) DEFINING AUTONOMY IN ROBOTS The term “robot” is based on the Czech word “robota,” meaning “serf or slave,” and came into being in Karel Capek’s 1921 play R.U.R. (Rosumovi Univerzalni Roboti or Rossum’s Universal Robots). Today, a robot is defined as “a mechanical creature which can function autonomously.”2 This concept of autonomy is correlated but different from automation. While both processes can be executed independently, from start to finish without human intervention, there is a qualitative distinction between them. An automated system normally operates with no human intervention, but is not self-directed and lacks decision-making capabilities. It only replaces routine processes with software/hardware that follows a step-by-step order, which usually requires human supervision. In a certain way, an automated system is rigid, blind, and, one might say, stupid. An autonomous system has the aim to emulate human cognitive processes rather than to simply eliminate them. Therefore, autonomy requires three main characteristics (which also help to identify whether a machine is truly autonomous): (1) The “frequency of human operator interactions” that the machine needs in order to function; (2) The machine’s ability to function successfully despite “environmental uncertainty”; and (3) The machine’s level of assertiveness to each of various operational decisions that let the machine to complete its mission.3 An autonomous system may also learn or acquire new knowledge, such as adopting new methods to accomplish its tasks or adjusting to changing surroundings. Over the last twenty years there have been many attempts to identify and quantify the “levels of autonomy” in robots. The degree of autonomy of a robot has been considered, at least in the beginning, from the viewpoint of human interaction/interface with a robotic system. B) SHERIDAN’S LEVELS OF AUTONOMY During his work for the National Aeronautics and Space Admin2. Robin R. Murphy, Introduction to AI Robotics 2 (2000), reproduced in Benjamin Kastan, AUTONOMOUS WEAPONS SYSTEMS: A COMING LEGAL “SINGULARITY?” 1 J. L. TECH & POL’Y 45, 49 (2013). 3. William Marra and McNeil, Sonia, Understanding “The Loop”: Regulating the Next Generation of War Machines, 36 HARV, J. L. & PUB. POL’Y 1, 3 (2012). 60 J. INFORMATION TECHNOLOGY & PRIVACY LAW [VOL. XXXII istration (NASA), Thomas Sheridan created both a categorization and vocabulary to express the state of human-machine interaction at any given moment during a mission.4 His classification is structured into levels and implies that autonomy is a delegation of a complete task to a computer, that a system operates on a single level of autonomy for any given task, and that these levels are discrete and represent steps of growing difficulty. 5 At Level one, a machine is automated. Levels two through four emphasize the allocation of the decision-making capacity between human and machine. Levels five through nine offer an initial decision-making power to the machine and confer to human operators special levels of approval or veto power. At Level 10, a machine is fully autonomous. Most other tentative classifications for quantifying robots’ autonomy seem to follow the steps of Sheridan’s early work. The United States Department of Defense (US DOD), for example, has funded a number of studies about the “levels of autonomy” in robots in order to aid their development.6 Further analysis of these studies is provided in later sections. C) AIR FORCE RESEARCH LAB SCALE OF AUTONOMY The Air Force Research Lab (AFRL)’s autonomy frame considers 11 levels of autonomy, specifically for Unmanned Aerial Vehicles (UAV): Remotely piloted vehicle; Execute pre-planned mission remotely; Changeable mission; Robust response to real-time faults/events; Fault/event adaptive vehicle; Real-time multi-vehicle coordination; Real time multi-vehicle cooperation; Battle space knowledge; Battle space single cognizance; Battle space swarm cognizance; and Fully autonomous7 There is a perspective, common in aviation, to consider the fighter 4. THOMAS B. SHERIDAN, TELEROBOTICS, AUTOMATION, AND HUMAN SUPERVISORY CONTROL (1992). 5. Id. 6. DEF. SCI. BD., TASK FORCE REPORT: THE ROLE OF AUTONOMY IN DOD SYSTEMS (July 2012) at 4, available at https://fas.org/irp/agency/dod/dsb/autonomy.pdf (hereinafter TASK FORCE REPORT). 7. Eric Sholes, Evolution of a UAV Autonomy Classification Taxonomy, AEROSPACE CONFERENCE DIGEST (2007), available at http://ieeexplore.ieee.org/stamp/ stamp.jsp?tp=a orient means to analyze the information, and use it to update the current reality; decide means to determine a course of action; act means to follow through with a decision. FRANS P.B. OSINGA, SCIENCE, STRATEGY AND WAR: THE STRATEGIC THEORY OF JOHN BOYD, 235 (2006). 9. See Paul Scharre, Robotics on the Battlefield Part I: Range, Persistence and Daring, CENTER FOR A NEW AMERICAN SECURITY, 13 (2014), available at http://www.cnas.org/range-persistence-daring (stating that “[m]achines that perform a function for some period of time, then stop and wait for human input before continuing, are often referred to as ‘semiautonomous’ or ‘human in the loop.’ Machines that can perform a function entirely on their own but have a human in a monitoring role, with the ability to intervene if the machine fails or malfunctions, are often referred to as ‘humansupervised autonomous’ or ‘human on the loop.’ Machines that can perform a function entirely on their own and humans are unable to intervene are often referred to as ‘fully autonomous’ or ‘human out of the loop.’”",project-academic
10.23919/WAC50355.2021.9559586,2021-08-01,p,IEEE,virtual testing and policy deployment framework for autonomous navigation of an unmanned ground vehicle using reinforcement learning," The use of deep reinforcement learning (DRL) as a framework for training a mobile robot to perform optimal navigation in an unfamiliar environment is a suitable choice for implementing AI with real-time robotic systems. In this study, the environment and surrounding obstacles of an Ackermann-steered UGV are reconstructed into a virtual setting for training the UGV to centrally learn the optimal route (guidance actions to be taken at any given state) towards a desired goal position using Multi-Agent Virtual Exploration in Deep Q-Learning (MVEDQL) for various model configurations. The trained model policies are to be transferred to a physical vehicle and compared based on their individual effectiveness for performing autonomous waypoint navigation. Prior to incorporating the learned model with the physical UGV for testing, this paper outlines the development of a GUI application to provide an interface for remotely deploying the vehicle and a virtual reality framework reconstruction of the training environment to assist safely testing the system using the reinforcement learning model.",project-academic
,2018-01-01,a,MDPI,uav or drones for remote sensing applications volume 1," The rapid development and growth of unmanned aerial vehicles (UAVs) as a remote sensing platform, as well as advances in the miniaturization of instrumentation and data systems, have resulted in an increasing uptake of this technology in the environmental and remote sensing science communities. Although tough regulations across the globe may still limit the broader use of UAVs, their use in precision agriculture, ecology, atmospheric research, disaster response biosecurity, ecological and reef monitoring, forestry, fire monitoring, quick response measurements for emergency disaster, Earth science research,volcanic gas sampling, monitoring of gas pipelines, mining plumes, humanitarian observations and biological/chemo-sensing tasks continues to increase. This Special Issue provides a forum for high-quality peer-reviewed papers that broaden the awareness and understanding of UAV developments, applications of UAVs for remote sensing, and associated developments in sensor technology, data processing and communications, and UAV system design and sensing capabilities. This topic encompasses many algorithms and process flows and tools, including: robust vehicle detection in aerial images based on cascaded convolutional neural networks; a stereo dual-channel dynamic programming algorithm for UAV image stitching, as well as seamline determination based on PKGC segmentation for remote sensing image mosaicking; the implementation of an IMU-aided image stacking algorithm in digital cameras; the study of multispectral characteristics at different observation angles, rapid three-dimensional reconstruction for image sequence acquired from UAV cameras; comparisons of Riegl Ricopter UAV Lidar-derived canopy height and DBH with terrestrial Lidar; vision based target finding and inspection of a ground target using a multirotor UAV system; a localization framework for real-time UAV autonomous landing using an on-ground deployed visual approach; curvature continuous and bounded path planning for fixed-wing UAVs; the calculation and identification of the aerodynamic parameters for small-scaled fixed-wing UAVs Several wildfire and agricultural applications of UAVS including: deep learning-based wildfire identification in UAV imagery; postfire vegetation survey campaigns; secure utilization of beacons; and UAVS used in emergency response systems for building fire hazards; observing spring and fall phenology in a deciduous forest with aerial drone imagery; the design and testing of a UAV mapping system for agricultural field surveying; artificial neural network to predict vine water status spatial variability using multispectral information obtained from an unmanned aerial vehicle; automatic hotspot and sun glint detection in UAV multispectral images obtained via uncooled thermal camera calibration and optimization of the photogrammetry process for UAV applications in agriculture; olive yield forecast tool based on the tree canopy geometry using UAS imagery; spatial scale gap filling downscaling method for applications in precision agriculture; automatic co-registration algorithm to remove canopy shaded pixels in UAV-borne thermal images to improve the estimation of crop water stress on vineyards; methodologies for improving plant pest surveillance in vineyards and crops using UAV-based hyperspectral and spatial data; UAV-assisted dynamic clustering of wireless sensors and networks for crop health monitoring. Several applications of UAVS in the fields of environment and conservation including the following: the automatic detection of pre-existing termite mounds through UAS and hyperspectral imagery; aerial mapping of forests affected by pathogens using UAVs; hyperspectral sensors and artificial i ntelligence; coral reef and coral bleaching monitoring; invasive grass and vegetation surveys in remote arid lands. UAVs are also utilized in many other applications: vicarious calibration of SUAS microbolometer temperature imagery for the estimation of radiometric land surface temperature; the documentation of hiking trails in alpine areas; the detection of nuclear sources by UAV teleoperation using a visuo-haptic augmented reality interface; the design of a UAV-embedded microphone array system for sound source localization in outdoor environments; the monitoring of concentrated solar power plants, accuracy analysis of a dam model from drone surveys, mobile sensing and actuation infrastructure, UAV-based frameworks for river hydromorphological characterization; online aerial terrain mapping for ground robot navigation.",project-academic
10.1109/GHTC.2018.8601597,2018-10-01,p,IEEE,the edna public safety drone bullet stopping lifesaving," Urban gun violence in cities across the world is a serious issue for public safety agencies and disaster management organizations. This led us to the development of the EDNA drone, an aerial robotics solution designed to equip first responders in high-risk settings with lifesaving-edge tools for situational awareness and non-lethal conflict resolution. The EDNA is an unmanned aerial vehicle (UAV) that delivers the patent-pending “Predictive Probable Cause” technology. The EDNA drone is designed to provide automated real-time analysis to assist teams entering high-risk situations where gun violence may occur. By leveraging machine learning, biometric sensors, and advanced materials in the field and routing feedback to an intuitive augmented-reality interface, the EDNA will provide autonomous threat detection and bullet-stopping capabilities wherever those features are needed‐‐to groups such as Police and Sheriff's Departments, Fire Departments, and EMT and emergency rescue teams. Data from the EDNA drone's sensors is fed to machine learning algorithms running on the drone in real-time. Through a neural network trained on past data, the EDNA is able to detect the presence and location of firearms and explosives, even through walls or other obstacles. Through the use of advanced metal foams and composite materials, the armored drone can even stop bullets‐‐functionality which has obvious benefits for humanitarian deployment.",project-academic
,2016-03-16,a,John Marshall Law School,autonomy of military robots assessing the technical and legal jus in bello thresholds 32 j marshall j info tech privacy l 57 2016," While robots are still absent from our homes, they have started to spread over battlefields. However, the military robots of today are mostly remotely controlled platforms, with no real autonomy. This paper will disclose the obstacles in implementing autonomy for such systems by answering a technical question: What level of autonomy is needed in military robots and how and when might it be achieved, followed by a techno-legal one: How to implement the rules of humanitarian law within autonomous fighting robots, in order to allow their legal deployment? The first chapter scrutinizes the significance of autonomy in robots and the metrics used to quantify it, which were developed by the US Department of Defense. The second chapter focuses on the autonomy of ""state-of-the-art” robots (e.g.; Google’s self-driving car, DARPA’s projects, etc.) for navigation, ISR or lethal missions. Based on public information, we will get a hint of the architectures, the functioning, the thresholds and technical limitations of such systems. The bottleneck to a higher autonomy of robots seems to be their poor “perceptive intelligence.” The last chapter looks to the requirements of humanitarian law (rules of “jus in bello”/rules of engagement) to the legal deployment of autonomous lethal robots on the battlefields. The legal and moral reasoning of human soldiers, complying with humanitarian law, is a complex cognitive process which must be emulated by autonomous robots that could make lethal decisions. However, autonomous completion of such “moral” tasks by artificial agents is much more challenging than the autonomous implementation of other tasks, such as navigation, ISR or kinetic attacks. Given the limits of current Artificial Intelligence, it is highly unlikely that robots will acquire such moral capabilities anytime soon. Therefore, for the time being, the autonomous weapon systems might be legally deployed, but only in very particular circumstances, where the requirements of humanitarian law happen to be irrelevant. 2015] AUTONOMY OF MILITARY ROBOTS 59 I. THE MEANING OF AUTONOMY IN ROBOTS AND WAYS TO QUANTIFY IT A) DEFINING AUTONOMY IN ROBOTS The term “robot” is based on the Czech word “robota,” meaning “serf or slave,” and came into being in Karel Capek’s 1921 play R.U.R. (Rosumovi Univerzalni Roboti or Rossum’s Universal Robots). Today, a robot is defined as “a mechanical creature which can function autonomously.”2 This concept of autonomy is correlated but different from automation. While both processes can be executed independently, from start to finish without human intervention, there is a qualitative distinction between them. An automated system normally operates with no human intervention, but is not self-directed and lacks decision-making capabilities. It only replaces routine processes with software/hardware that follows a step-by-step order, which usually requires human supervision. In a certain way, an automated system is rigid, blind, and, one might say, stupid. An autonomous system has the aim to emulate human cognitive processes rather than to simply eliminate them. Therefore, autonomy requires three main characteristics (which also help to identify whether a machine is truly autonomous): (1) The “frequency of human operator interactions” that the machine needs in order to function; (2) The machine’s ability to function successfully despite “environmental uncertainty”; and (3) The machine’s level of assertiveness to each of various operational decisions that let the machine to complete its mission.3 An autonomous system may also learn or acquire new knowledge, such as adopting new methods to accomplish its tasks or adjusting to changing surroundings. Over the last twenty years there have been many attempts to identify and quantify the “levels of autonomy” in robots. The degree of autonomy of a robot has been considered, at least in the beginning, from the viewpoint of human interaction/interface with a robotic system. B) SHERIDAN’S LEVELS OF AUTONOMY During his work for the National Aeronautics and Space Admin2. Robin R. Murphy, Introduction to AI Robotics 2 (2000), reproduced in Benjamin Kastan, AUTONOMOUS WEAPONS SYSTEMS: A COMING LEGAL “SINGULARITY?” 1 J. L. TECH & POL’Y 45, 49 (2013). 3. William Marra and McNeil, Sonia, Understanding “The Loop”: Regulating the Next Generation of War Machines, 36 HARV, J. L. & PUB. POL’Y 1, 3 (2012). 60 J. INFORMATION TECHNOLOGY & PRIVACY LAW [VOL. XXXII istration (NASA), Thomas Sheridan created both a categorization and vocabulary to express the state of human-machine interaction at any given moment during a mission.4 His classification is structured into levels and implies that autonomy is a delegation of a complete task to a computer, that a system operates on a single level of autonomy for any given task, and that these levels are discrete and represent steps of growing difficulty. 5 At Level one, a machine is automated. Levels two through four emphasize the allocation of the decision-making capacity between human and machine. Levels five through nine offer an initial decision-making power to the machine and confer to human operators special levels of approval or veto power. At Level 10, a machine is fully autonomous. Most other tentative classifications for quantifying robots’ autonomy seem to follow the steps of Sheridan’s early work. The United States Department of Defense (US DOD), for example, has funded a number of studies about the “levels of autonomy” in robots in order to aid their development.6 Further analysis of these studies is provided in later sections. C) AIR FORCE RESEARCH LAB SCALE OF AUTONOMY The Air Force Research Lab (AFRL)’s autonomy frame considers 11 levels of autonomy, specifically for Unmanned Aerial Vehicles (UAV): Remotely piloted vehicle; Execute pre-planned mission remotely; Changeable mission; Robust response to real-time faults/events; Fault/event adaptive vehicle; Real-time multi-vehicle coordination; Real time multi-vehicle cooperation; Battle space knowledge; Battle space single cognizance; Battle space swarm cognizance; and Fully autonomous7 There is a perspective, common in aviation, to consider the fighter 4. THOMAS B. SHERIDAN, TELEROBOTICS, AUTOMATION, AND HUMAN SUPERVISORY CONTROL (1992). 5. Id. 6. DEF. SCI. BD., TASK FORCE REPORT: THE ROLE OF AUTONOMY IN DOD SYSTEMS (July 2012) at 4, available at https://fas.org/irp/agency/dod/dsb/autonomy.pdf (hereinafter TASK FORCE REPORT). 7. Eric Sholes, Evolution of a UAV Autonomy Classification Taxonomy, AEROSPACE CONFERENCE DIGEST (2007), available at http://ieeexplore.ieee.org/stamp/ stamp.jsp?tp=a orient means to analyze the information, and use it to update the current reality; decide means to determine a course of action; act means to follow through with a decision. FRANS P.B. OSINGA, SCIENCE, STRATEGY AND WAR: THE STRATEGIC THEORY OF JOHN BOYD, 235 (2006). 9. See Paul Scharre, Robotics on the Battlefield Part I: Range, Persistence and Daring, CENTER FOR A NEW AMERICAN SECURITY, 13 (2014), available at http://www.cnas.org/range-persistence-daring (stating that “[m]achines that perform a function for some period of time, then stop and wait for human input before continuing, are often referred to as ‘semiautonomous’ or ‘human in the loop.’ Machines that can perform a function entirely on their own but have a human in a monitoring role, with the ability to intervene if the machine fails or malfunctions, are often referred to as ‘humansupervised autonomous’ or ‘human on the loop.’ Machines that can perform a function entirely on their own and humans are unable to intervene are often referred to as ‘fully autonomous’ or ‘human out of the loop.’”",project-academic
,2020-01-01,a,Hilaris SRL,novel gpu enabled deep learning architecture for lidar based auto labelling for autonomous vehicles," As Autonomous vehicles (AV) are closer to becoming reality, it becomes mandatory to be able to characterise the performance of the sensors used in AV before it gets into production deployment. This validation process requires large amounts of ground truth data to be established with precise information about the real world position and pose of the objects around the vehicle. LIDAR is a preferred sensor for ground truthing due to its ability to estimate the depth of the objects precisely. In order to reduce the manual efforts in ground truthing,.In this paper, we propose a novel deep learning network for automated object detection and pose estimation on LIDAR point cloud data, for automated ground truthing. The algorithm is based on a multi-layer deep 3D convolutional neural network with a custom loss function and activation layers. Typically, the volume of point cloud input data itself is huge plus the computational complexity makes training and inferencing highly time intensive. The architecture of the deep learning network is considered in such a way, that the activation functions for the particular layers are designed based on the sensitivity of the feature, which is being extracted from that layer .This helped in saving time of computation with our compromising the accuracy of feature extraction. Loss function was designed so that it utilizes regression to achieve efficient localization of objects. Though the architecture of the network helped improving, the speed of training and inferencing, further improvement was required for efficient training turnaround time and real time inferencing, which was achieved with efficient utilisation of NVDIA GPUs, which was the hardware, used to deploy the automated labelling algorithms The above approaches ensured real time execution of the inferencing engine on Velodyne HDL 64 and 128 LIDAR, which was essential for real time labelling and ground truthing",project-academic
10.1109/IROS.2018.8593871,2018-05-04,p,IEEE,motion planning among dynamic decision making agents with deep reinforcement learning," Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.",project-academic
,2018-05-04,a,,motion planning among dynamic decision making agents with deep reinforcement learning," Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed, without the use of a 3D Lidar.",project-academic
10.1109/TASE.2018.2877499,2019-10-01,a,IEEE,coarse to fine uav target tracking with deep reinforcement learning," The aspect ratio of a target changes frequently during an unmanned aerial vehicle (UAV) tracking task, which makes the aerial tracking very challenging. Traditional trackers struggle from such a problem as they mainly focus on the scale variation issue by maintaining a certain aspect ratio. In this paper, we propose a coarse-to-fine deep scheme to address the aspect ratio variation in UAV tracking. The coarse-tracker first produces an initial estimate for the target object, then a sequence of actions are learned to fine-tune the four boundaries of the bounding box. The coarse-tracker and the fine-tracker are designed to have different action spaces and operating target. The former dominates the entire bounding box and the latter focuses on the refinement of each boundary. They are trained jointly by sharing the perception network with an end-to-end reinforcement learning architecture. Experimental results on benchmark aerial data set prove that the proposed approach outperforms existing trackers and produces significant accuracy gains in dealing with the aspect ratio variation in UAV tracking. None Note to Practitioners —During the past years, unmanned aerial vehicle (UAV) have gained much attention for both industrial and consumer uses. It is in urgent demand to endow the UAV with intelligent vision-based techniques, and the automatic target following via visual tracking methods as one of the most fundamental intelligent features could promote various applications of UAVs, such as surveillance, augmented reality, and behavior modeling. Nonetheless, the primary issue of a UAV-based tracking method is the platform itself: it is not stable, it tends to have sudden movements, it generates nonhomogeneous data (scale, angle, rotation, depth, and so on), all of them tend to change the aspect ratio of the target frequently and further increase the difficulty of object tracking. This paper aims to address the aspect ratio change (ARC) problem in UAV tracking. We present a coarse-to-fine strategy for UAV tracking. Specifically, the coarse bounding box is obtained to locate the target firstly. Then, a refinement scheme is performed on each boundary to further improve the position estimate. The tracker is proved to be effective to increase the resistance to the ARC. Such a method can be implemented on UAV to improve the target-following performance.",project-academic
10.1109/EIT.2018.8500102,2018-05-03,p,IEEE,behavioral cloning for lateral motion control of autonomous vehicles using deep learning," Current trend of the automotive industry combined with research by the major tech companies has proved that self-driving vehicles are the future. With successful demonstration of neural network based autonomous driving, NVIDIA has introduced a new paradigm for autonomous driving software. The biggest challenge for self-driving cars is autonomous lateral control. An end-to-end model seems very promising in providing a complete software stack for autonomous driving. Although this system is not ready to be provided as a feature in the market today, it is one of the many steps in the right direction to make self-driving cars a reality. The work described in this paper focusses on how an end-to-end model is implemented. The subtleties of training a successful end-to-end model are highlighted with the aim of providing an insight on deep learning and software required for neural network training. Detailed analyses of data acquisition and training systems are provided and installation procedures for all required tools and software discussed. TORCS is used for developing and testing the end-to-end model. Approximately ten hours of driving data was collected from two different tracks. Using four hours of data from a track, we trained a deep neural network to steer a car inside simulation. Even with such a small training set, the end-to-end model developed demonstrated capabilities to maintain lanes and complete laps in different tracks. For a multilane track, like the one used for training, the model demonstrated an autonomy of 96.62%. For single lane unknown tracks, the model steered the vehicle successfully for 89.02% of the time. The results indicate that end-to-end learning and behavioral cloning can be used to drive autonomously in new and unknown scenarios.",project-academic
10.30564/AIA.V1I1.569,2019-07-19,a,Bilingual Publishing Co.,to perform road signs recognition for autonomous vehicles using cascaded deep learning pipeline," Autonomous vehicle is a vehicle that can guide itself without human conduction. It is capable of sensing its environment and moving with little or no human input. This kind of vehicle has become a concrete reality and may pave the way for future systems where computers take over the art of driving. Advanced artificial intelligence control systems interpret sensory information to identify appropriate navigation paths, as well as obstacles and relevant road signs. In this paper, we introduce an intelligent road signs classifier to help autonomous vehicles to recognize and understand road signs. The road signs classifier based on an artificial intelligence technique. In particular, a deep learning model is used, Convolutional Neural Networks (CNN). CNN is a widely used Deep Learning model to solve pattern recognition problems like image classification and object detection. CNN has successfully used to solve computer vision problems because of its methodology in processing images that are similar to the human brain decision making. The evaluation of the proposed pipeline was trained and tested using two different datasets. The proposed CNNs achieved high performance in road sign classification with a validation accuracy of 99.8% and a testing accuracy of 99.6%. The proposed method can be easily implemented for real time application.",project-academic
10.1109/ICCAR.2017.7942721,2017-04-24,p,IEEE,object detection on panoramic images based on deep learning," Panoramic image can be widely used in many applications, such as virtual reality, visual surveillance and autonomous vehicle, because of its large field of view. However, the inherent distortion for panorama causes object detection to be a challenging task. This paper focuses on the multi-class objects detection in panoramic images using deep learning method. The proposed system uses three fisheye cameras to efficiently create panoramas and build a large dataset. A region based convolutional neutral network (R-CNN) is implemented to train and test on an indoor panoramic image dataset. Experiments show great improvement performance on ten categories of distorted indoor objects with a mean average precision of 68.7%.",project-academic
,2019-09-18,,,shared vehicle management device and management method of shared vehicle," The present invention relates to a shared vehicle management method comprising: a step of allowing at least one processor to receive a vehicle allocation request signal; a step of allowing at least one processor to determine a vehicle to be allocated based on a first travelling path information included in the allocation request signal; a step of allowing at least one processor to authenticate driving eligibility of a user for a manned autonomous driving vehicle when the manned autonomous driving vehicle is selected as the vehicle to be allocated; and a step of allowing at least one processor to provide a passenger auxiliary autonomous driving vehicle option. A shared vehicle management apparatus is able to manage an autonomous driving vehicle. An autonomous driving vehicle may be interworked with a robot. A shared vehicle management apparatus may be implemented through an artificial intelligence algorithm. A shared vehicle management apparatus may create augmented reality (AR) content. According to the present invention, it is possible to lower a service price for a user.",project-academic
,2021-01-07,,,shared vehicle management device and shared vehicle management method," The present invention relates to a shared vehicle management method comprising the steps in which: at least one processor receives a vehicle dispatch request signal reception; the at least one processor decides on a vehicle to be dispatched on the basis of first driving route information included in the dispatch request signal; if a manned autonomous vehicle is decided to be the vehicle to be dispatched, the at least one processor authenticates driver qualification of a user for the manned autonomous vehicle; and the at least one processor provides a passenger-assisted autonomous vehicle option. A shared vehicle management device may manage an autonomous vehicle. The autonomous vehicle may be linked with a robot. The shared vehicle management device may be implemented through an artificial intelligence algorithm. The shared vehicle management device may create augmented reality (AR) content.",project-academic
,2007-07-22,p,AAAI Press,towards an adaptive approach for distributed resource allocation in a multi agent system for solving dynamic vehicle routing problems," Introduction. The existing problem of continuous planning in transportation logistics requires the solving of dynamic Vehicle Routing Problems (dynamic VRPs) which is an NP-complete optimization problem. The task of continuous planning assumes the existence of individual commit times for orders to be released for execution with specific commitment strategies and is similar to the problem of maintaining a guaranteed response time in real-time systems that, in a dynamic environment, applies additional restrictions on planning algorithms. This paper describes the developed multi-agent platform for solving the dynamic multi-vehicle pickup and delivery problem with soft time windows (dynamic m-PDPSTW) that supports goaldriven behavior of autonomous agents with a multi-objective decision-making model. Further research on the design of adaptive mechanisms for run-time feedback-directed adjustment of scheduling algorithms through learning and experience of applied decision options is outlined. The market-based method for distributed dynamic resource allocation. The authors’ multi-agent approach to continuous planning in complex uncertain environments implements the concept of the dynamic distributed resource allocation (Modi et al. 2002) whereby decision making is carried out by means of asynchronous quasi-parallel processes of negotiation between the agents of resources and the agents of orders which are working distributively in a virtual marketplace over all the agents of the complex shared ontology object. Goal-driven behavior of autonomous agents is supported by the developed multiobjective decision-making model based on individual goals, criteria, and preference functions defined in the virtual marketplace ontology and methods of agent self-appraisal and decision-making strategies (priority of criteria, value superposition, and homeostasis). In the implemented framework for agent knowledge representation, based on Prof. Marvin Minsky’s concept of frames, each autonomous agent in the virtual marketplace has its individual knowledge, agent memory with a dynamic decision-making table, experience of applied deciCopyright © 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. sion options, and reality representation of the world model (a shared ontological scene of reality) in an individual ontological scene and has its own perception via sensors and facades (Chevelev et al. 2006). The presented process of self-organization in such a multi-agent system is based on the constant search to maintain a dynamic balance among the interests of all participants in the interaction by means of an economically decentralized method of agent behavioral coordination. The microeconomic model defines violation functions of agent preferences with personal accounts for agents and reflects individual expenses and profits for all agents at any moment of distributed decision-making process. Furthermore, this microeconomic model provides the basis for decentralized mechanisms for controlling emergent behavior and stabilizing of agent swarms. Control methods of self-organization in complex environments. Conducted experiments on agent microeconomic parameters demonstrates that the complex system of interacting autonomous agents is characterized by the opportunity of the existence of several stable equilibria (attractors), by the unpredictable nonlinear processes of transitions between them, and by the emergence of resonating and oscillatory properties in the system. Special attention was given to the simulated processes of the significant internal reconfiguration of the agent system in response to the smallest external signals (a catastrophe) – trifling alterations on the agent local level led to a large-scale schedule reconstruction. Effective control mechanisms for selforganization need to be developed to make multi-agent systems more effective in solving dynamic VRPs with a view to achieving practical levels of performance for continuous planning in complex environments with higher levels of uncertainty, such as multi-modal logistics with multiple, competing companies. The developed mechanisms provide control methods for achieving both of the contending objectives: the transition of the multi-agent system toward the global quasi-optimal state while avoiding undesirable local attractors and the stabilization of agent activity and limitation of schedule reconstruction for maintaining a guaranteed response time for orders to be scheduled and released for execution according to their individual commitment times.",project-academic
,2021-01-07,,,apparatus for providing advertisement for vehicle and method for providing advertisement for vehicle," The present invention relates to an apparatus for providing an advertisement for a vehicle, the apparatus comprising a processor which receives data generated by at least one server, generates, on the basis of the data, augmented reality (AR) advertisement data matching the outer edge of a road on which a vehicle is driving, and provides a signal such that a graphic object on the basis of the advertisement data is displayed on at least one display provided in the vehicle. The apparatus for providing an advertisement for a vehicle may be provided in an autonomous vehicle. The autonomous vehicle may be connected to a robot. The apparatus for providing an advertisement for a vehicle may be implemented using an artificial intelligence (AI) algorithm.",project-academic
,2020-04-16,,,vehicular advertisement providing device and vehicular advertisement providing method," Disclosed is a vehicular advertisement providing device including a processor configured to receive data generated by at least one server, to generate augmented reality (AR) advertisement data that matches the outside of a road in which a vehicle travels based on the data, and to provide a signal for displaying a graphic object based on the advertisement data on at least one display included in the vehicle. The vehicular advertisement providing device is included in an autonomous vehicle. The autonomous vehicle is associated with a robot. The vehicular advertisement providing device is implemented using an artificial intelligence (AI) algorithm.",project-academic
,2021-01-07,,,electronic device and method for operating electronic device," The present invention relates to a method for operating an electronic device, comprising: a step in which at least one processor receives a signal generated as a vehicle enters a preset area; a step in which the at least one processor receives a parking request signal of the vehicle; and a step in which the at least one processor provides at least one from among the vehicle and a robot interacting with the vehicle, with a wake-up signal of an interaction device, wherein the interaction device is a device for performing mutual cooperative control of the vehicle and the robot. The vehicle may be an autonomous vehicle. A server, the autonomous vehicle, and the robot can exchange signals with each other by using 5G communication. The server, the autonomous vehicle, and the robot can be implemented by using an artificial intelligence (AI) algorithm. The server, the autonomous vehicle, and the robot can generate augmented reality (AR) content.",project-academic
,2021-01-07,,,electronic device for autonomous vehicle and method for operating electronic device for autonomous vehicle," The present invention relates to an electronic device for an autonomous vehicle, comprising at least one processor for outputting direction information through an output device when manual-driving state information about the vehicle is received through an interface unit, and outputting vehicle driving-related content according to a user's state through the output device when autonomous-driving state information about the vehicle is received through the interface unit. Data generated by the electronic device for an autonomous vehicle can be transmitted to an external device through a 5G communication method. The electronic device for an autonomous vehicle can be implemented by using artificial intelligence algorithms. The data generated by the electronic device for an autonomous vehicle can be implemented as augmented reality content.",project-academic
,2020-12-03,,,traffic accident management device and traffic accident management method, The present invention relates to a traffic accident management method comprising the steps in which: at least one processor obtains data relating to a context of an autonomous vehicle; at least one processor determines whether or not an accident of the autonomous vehicle has occurred on the basis of the data; and at least one processor determines the matter of responsibility of the accident by means of an artificial intelligence algorithm. A traffic accident management device can manage a traffic accident of the autonomous vehicle. The autonomous vehicle can be linked to a robot. The traffic accident management device can be implemented by means of the artificial intelligence (AI) algorithm. The traffic accident management device can generate augmented reality (AR) content.,project-academic
10.1109/TIV.2019.2919460,2019-05-28,a,Institute of Electrical and Electronics Engineers (IEEE),functional safety verification for autonomous ugvs methodology presentation and implementation on a full scale system," Autonomous vehicles (AVs) are expected to be on public roads in the near future, but some critical aspects of this reality are yet to be resolved. One of these aspects is the lack of a sufficient safety-performance-verification technique. The existing tools of functional-safety engineering do not provide a comprehensive solution for the verification of artificial intelligence and machine learning. For the verification of this type of algorithms, it has become widely accepted in the recent years that simulation tests should be used. Nevertheless, to the best of our knowledge, no detailed method for how these simulation tests should be performed has yet been suggested. To start tackling this gap, this paper presents a verification methodology based on the statistical testing of AVs’ safety-related functionality in simulated scenarios. Also, presented here is a test-case implementation of the methodology on a full-scale autonomous unmanned ground vehicle (UGV). In this example, the functionality of safe autonomous off-road navigation is verified. It is shown that the statistical performance data that are gathered using simulation can be used to accurately predict the overall safety performance of UGVs in real life. Our intention is that this paper will provide a starting point for the further discussion on the exact way simulation tests shall be used for the safety verification of AVs.",project-academic
10.1007/978-3-030-32564-0_54,2019-10-23,a,"Springer, Cham",contribution to research the applied engineering protocol to implement a fuzzy regulator for autonomous driving of an automotive model implemented in virtual reality," Monitoring and controlling the autonomous driving in automotive sector where high traffic density and risk factors are recorded it’s today a common trend in global research and high potential for artificial intelligence implementation. But reaching to the large scale market and the series production in the same time it’s a quite difficult problem that has to be approached and solved by engineers. The objective of the present research paper is mainly to innovate the application of a fuzzy regulator and to model a specific vehicle type in virtual reality through multidisciplinary components. It aims to implement some authentic methods for data collection, transfer and whole digital management, in the vehicle control system for automotive sector correlated with the virtual reality protocols, meaning that the algorithms and protocols of the vehicle in different conditions will be modeled and digitally tested in a special environment a priori to their implementation on full scale model. Specific objectives consist in a short technical presentation of the fuzzy regulator operational protocol for system communication method in the case of an road vehicle with autonomous driving capabilities and a practical set-up conducted in the Laboratory of Artificial Intelligence for Automotive Sector at Technical University from Cluj-N with the technical data retrieved from virtual reality tested model. Artificial intelligence applied to the control system is integrated in the model when protocols are defined in virtual reality for optimizing the driving conditions and improving the stability and steering, thus positively impacting the environment, society and autonomous vehicles.",project-academic
,2019-08-26,,,apparatus and method for virtual home service," One embodiment of the present invention relates to an apparatus for a virtual home service, configured to provide data for supporting a virtual home interface to a vehicle device that provides the virtual home interface for controlling operation of a home appliance. The apparatus comprises: a communication unit; a home information collection unit configured to obtain a blueprint of a home through the communication unit based on user identification information of the home appliance, and obtain a 3D drawing by converting the blueprint; a home appliance identification unit configured to obtain, through the communication unit, inside images and SLAM information of the home and identify a location and a state of the home appliance based on the inside images and SLAM information; and a virtual home implementation unit configured to generate virtual home information by reflecting the location and the state of the home appliance in the 3D drawing, wherein the virtual home information is provided, as data for supporting the virtual home interface, to the vehicle device. According to one embodiment of the present invention, at least one of an autonomous vehicle, a user terminal, and a server may be linked or converged with an artificial intelligence module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, and a device associated with the fifth generation communication service. According to the present invention, a user of a robot cleaner is able to receive, without a separate device, the virtual home interface reflecting a home appliance disposed in the home.",project-academic
,2017-07-14,p,,examining the myths around autonomous cars what does the future hold," The interest with which academia, industry and societies anticipate a full scale launch of autonomous and connected vehicles, which is one of the most critical components underpinning the transformation of a modern city to a truly ‘smart’ one, is higher than ever before. This is because these vehicles have, in theory at least, the potential to completely transform urban development as known today, with a revolution in ground transport, regulations permitting, that could dramatically change the landscape of cities and have an enormous economic, social, spatial, and mobility impact. Artificial intelligence with its deep learning functions that model high-level data concepts through the use of architectures of multiple non-linear transformations is ultimately employed as a tool which empowers the car to make better decisions than a human driver ever could; but at the same time needs to be a user-centred technology that ‘understands’ and ‘satisfies’ the human user and the markets. Although recent studies showed that a priori acceptability of fully automated cars could be likely for many drivers today, the universal embracement of such a monumental mobility paradigm transition is still a complex proposition. This is because, despite a number of potential beneficial outcomes that make driverless vehicles an inescapable future reality, the implementation of vehicle automation, will not be straightforward, predictable or unproblematic; there is a wide spectrum of social dilemmas and complicated human factors issues that may arise from such an ‘untested’ and ‘powerful’ innovation. None The present work develops an understanding of its key opportunities and challenges via the analysis of a series of semi-structured in-depth interviews with academic experts in transport and vehicle automation studies. The interviews were designed to test some of the myths referring to autonomous and connected vehicles with an emphasis on exploring some of the potentially darker or ambiguous sides of this smart mobility paradigm. Therefore the present study’s main output is the formation of a ‘road map’ or ‘theory-driven taxonomy’ of the possible key impacts (positive and negative) of car automation.",project-academic
,2019-04-16,a,,artificial intelligence on board electric vehicle autonomous driving," In a period, in which technological development dominated the socio-economic scene, with an aim of evolving and adapting to human needs, the Artificial Intelligence sector could only become the centre of scientific research. When the keyword becomes ""comfort"", the automation world is highly considered: machine learning, from this point of view, is of great interest for the human assistance process. None The focus of the following thesis research is, in particular, to recreate a case study in which the concept of machine autonomy embraces the theme of mobility. The automotive industry, in fact, has concentrated for many years a large part of its resources in the implementation of assisted driving systems and, more recently, autonomous driving. The new vehicles are equipped with an increasing number of optional and advanced security systems. None In detail, the project carried out during this research, which took place at the company bylogix srl of Grugliasco, concerns the problem of the Path Following, i.e. the ability of the vehicle to follow a desired trajectory in relation to factors that depend from the intrinsic characteristics of the car and the surrounding environment. None The Path Following topic raises many questions related to the ethical, bureaucratic and penal responsibilities of any high-risk situations, as well as the definition of the priority levels to be attributed to the entities involved. Moreover, as the urban reality is varied and dynamic, it is necessary that such systems can predict the most common situations and react very quickly to external stimuli. None The present case concerns the implementation of a controller which, given a predetermined trajectory, can process the optimum steering angle for maintaining the path. None In particular, the LQR control has been chosen, starting from a reference signal involving the desired values of the lateral position, the lateral velocity, the yaw angle and the yaw rate, to minimize a cost function with the aim of reducing the deviations between the mentioned values and the real ones. The dynamics of the vehicle, which in the real case is a new generation electric model, has been approximated for this purpose using the Bicycle Model. None Through the tests performed on the Matlab / Simulink platform, it was possible to compare the results obtained by the different choices of the weight coefficients of the matrices involved. Finally, the same study was revised for the use of the LQI control to highlight any aspects that can be deduced from the comparison between the various results.",project-academic
,1998-06-01,b,,computer vision accv 98 third asian conference on computer vision hong kong china january 8 10 1998 proceedings," On typical implementations of Hough transform for improving its performances.- Hierarchical segmentation and representation with dynamic link architecture neural network.- Perceptually consistent segmentation of texture using multiple channel filter.- Optimal edge detection under difficult imaging conditions.- Restoring image quality through structure preserving de-noising.- Feature saliency from noise variations in invariants.- Multiscale image representation and edge detection.- Rotation invariant texture features from Gabor filters.- Euclidean invariants of linear scale-spaces.- Segmenting objects at multiple scales: A robust approach.- Multi-grid edge models for magnifying digital images.- Scale and rotation invariant recognition method using higher-order local autocorrelation features of log-polar image.- Script and language identification from document images.- Document categorization for document image understanding.- Recognition of various bar-graph structures based on layout model.- Word-class bigram statistics language model for a hand-written chinese character recognizer.- Log classification by single X-ray scans using texture features from growth rings.- Precise and fast form identification method by using adaptive base lines for matching.- Combinatorial coarse classification method for OLCCR.- Detecting characters in grey-scale scene images.- Conic based image transfer for 2-D Objects: A linear algorithm.- Minimal conditions on intrinsic parameters for Euclidean reconstruction.- Surface based hypothesis verification in intensity images using geometric and appearance data.- Next best viewpoint (NBV) planning for active object modeling based on a learning-by-showing approach.- Object recognition by matching symbolic edge graphs.- Interpretation of complex scenes using Bayesian networks.- Recognition of urban scene using silhouette of buildings and city map database.- A cooperative inference mechanism for extracting road information automatically.- Model-based active object recognition using MRF matching and sensor planning.- Improved image classification using morphing.- Reconstruction of non-manifold objects from two orthographic views.- 3D object recognition using segment-based stereo vision.- The state of color vision research.- Color vision and color media processing research in Asia.- Recent advances in detection and description of buildings from multiple aerial images.- Visual surveillance of human activity.- Bayesian paradigm for recognition of objects -On typical implementations of Hough transform for improving its performances.- Hierarchical segmentation and representation with dynamic link architecture neural network.- Perceptually consistent segmentation of texture using multiple channel filter.- Optimal edge detection under difficult imaging conditions.- Restoring image quality through structure preserving de-noising.- Feature saliency from noise variations in invariants.- Multiscale image representation and edge detection.- Rotation invariant texture features from Gabor filters.- Euclidean invariants of linear scale-spaces.- Segmenting objects at multiple scales: A robust approach.- Multi-grid edge models for magnifying digital images.- Scale and rotation invariant recognition method using higher-order local autocorrelation features of log-polar image.- Script and language identification from document images.- Document categorization for document image understanding.- Recognition of various bar-graph structures based on layout model.- Word-class bigram statistics language model for a hand-written chinese character recognizer.- Log classification by single X-ray scans using texture features from growth rings.- Precise and fast form identification method by using adaptive base lines for matching.- Combinatorial coarse classification method for OLCCR.- Detecting characters in grey-scale scene images.- Conic based image transfer for 2-D Objects: A linear algorithm.- Minimal conditions on intrinsic parameters for Euclidean reconstruction.- Surface based hypothesis verification in intensity images using geometric and appearance data.- Next best viewpoint (NBV) planning for active object modeling based on a learning-by-showing approach.- Object recognition by matching symbolic edge graphs.- Interpretation of complex scenes using Bayesian networks.- Recognition of urban scene using silhouette of buildings and city map database.- A cooperative inference mechanism for extracting road information automatically.- Model-based active object recognition using MRF matching and sensor planning.- Improved image classification using morphing.- Reconstruction of non-manifold objects from two orthographic views.- 3D object recognition using segment-based stereo vision.- The state of color vision research.- Color vision and color media processing research in Asia.- Recent advances in detection and description of buildings from multiple aerial images.- Visual surveillance of human activity.- Bayesian paradigm for recognition of objects - Innovative applications.- Toward motion picture grammars.- Hierarchical texture segmentation.- Range image segmentation: Adaptive grouping of edges into regions.- Optimising the complete image feature extraction chain.- A unified framework for salient curves, regions, and junctions inference.- Learning multiscale image models of 2D object classes.- 3D model centered framework for CV and VR.- Image-based geometrically-correct photorealistic scene/object modeling (IBPhM): A review.- Measuring object surface shape and reflectance properties.- Robust image composition algorithms for augmented reality.- Context-based recognition of manipulative hand gestures for human computer interaction.- An algorithm for recursive structure and motion recovery under affine projection.- Relative affine depth: Structure from motion by an uncalibrated camera.- The eigenspace method for rigid motion recovery from less than eight point correspondences.- 3D shape and motion analysis from image blur and smear: A unified approach.- 3D line's extraction from 2D Spatio-Temporal Image created by sine slit.- Toward non-intrusive motion capture.- Appearance based visual learning and object recognition with illumination invariance.- Evidence-based scene interpretation considering subjective certainty of recognition.- Robust hypothesis verification for model based object recognition using Gaussian error model.- Shape modeling from multiple view images using GAs.- 3-D reconstruction of multipart self-occluding objects.- On analysis of cloth drape range data.- VR models from epipolar images: An approach to minimize errors in synthesized images.- Shape and pose parameter estimation of 3D multi-part objects.- Generating 3D models of objects using multiple visual cues in image sequences.- Strategical tracking of polyhedral objects by reactive change of projection pattern - Reactive Range Finder -.- Autonomous vision-guided robot manipulation control.- A new adaptive approach on rapid obstacle detection in range image.- Recognition of shape models for general roads.- Visual detection of obstacles assuming a locally planar ground.- Potential-based modeling of 2D regions using non-uniform source distributions.- A linear algorithm for motion from three weak perspective images using Euler angles.- On Learning spatio-temporal relational structures in two different domains.- An efficient iterative pose estimation algorithm.- A new multistage approach to motion and structure estimation by gradually enforcing geometric constraints.- Tracking a person with pre-recorded image database and a pan, tilt, and zoom camera.- Recovery of motion and structure from optical flow under perspective projection by solving linear simultaneous equations.- Vector coherence mapping: A parallelizable approach to image flow computation.- Robust motion segmentation using rank ordering estimators.- Optical flow in the scale space.- Motion detection in temporal clutter.- A novel fast three-step search algorithm for block-matching motion estimation.- Moving vehicle detection and tracking in image sequences.- Gesture recognition from image motion based on subspace method and HMM.- Identifying faces under varying pose using a single example view.- Multiple camera based human motion estimation.- An autonomous facial caricaturing based on a model of visual illusion - Experimental modeling of visual illusion -.- 3D estimation of facial muscle parameter from the 2D marker movement using neural network.- Appearance-based face recognition under large head rotations in depth.- Skin-color modeling and adaptation.- Human information retrieval by face extraction and recognition on TV news images using subspace method.- Converting facial expressions using recognition-based analysis of image Sequences.- Muscle-based feature models for analyzing facial expressions.- A morphological method for moving object segmentation and posture recognition.- Detection of glasses in facial images.- Non-monotonic continuous dynamic programming for spotting recognition of hesitated gestures from time-varying images.- Face recognition using a face-only database: A new approach.",project-academic
10.1007/3-540-63460-6,1997-01-01,p,Springer Berlin Heidelberg,computer analysis of images and patterns 7th international conference caip 97 kiel germany september 10 12 1997 proceedings," Computational complexity reduction in eigenspace approaches.- An algorithm for intrinsic dimensionality estimation.- Fully unsupervised clustering using centre-surround receptive fields with applications to colour-segmentation.- Multi-sensor fusion with Bayesian inference.- MORAL - A vision-based object recognition system for autonomous mobile systems.- Real-time pedestrian tracking in natural scenes.- Non-rigid object recognition using principal component analysis and geometric hashing.- Object identification with surface signatures.- Computing projective and permutation invariants of points and lines.- Point projective and permutation invariants.- Computing 3D projective invariants from points and lines.- 2D ? 2D geometric transformation invariant to arbitrary translations, rotations and scales.- Extraction of filled-in data from colour forms.- Improvement of vessel segmentation by elastically compensated patient motion in digital subtraction angiography images.- Three-dimensional quasi-binary image restoration for confocal microscopy and its application to dendritic trees.- Mosaicing of flattened images from straight homogeneous generalized cylinders.- Well-posedness of linear shape-from-shading problem.- Comparing convex shapes using Minkowski addition.- Deformation of discrete object surfaces.- Non-Archimedean normalized fields in texture analysis tasks.- The Radon transform-based analysis of bidirectional structural textures.- Textures and structural defects.- Self-calibration from the absolute conic on the plane at infinity.- A badly calibrated camera in ego-motion estimation - propagation of uncertainty.- 6DOF calibration of a camera with respect to the wrist of a 5-axis machine tool.- Automated camera calibration and 3D egomotion estimation for augmented reality applications.- Optimally rotation-equivariant directional derivative kernels.- A hierarchical filter scheme for efficient corner detection.- Defect detection on leather by oriented singularities.- Uniqueness of 3D affine reconstruction of lines with affine cameras.- Distortions of stereoscopic visual space and quadratic Cremona transformations.- Self-evaluation for active vision by the geometric information criterion.- Discrete-time rigidity-constrained optical flow.- An iterative spectral-spatial Bayesian labeling approach for unsupervised robust change detection on remotely sensed multispectral imagery.- Contrast enhancement of badly illuminated images based on Gibbs distribution and random walk model.- Adaptive non-linear predictor for lossless image compression.- Beyond standard regularization theory.- Fast stereovision by coherence detection.- Stereo matching using M-estimators.- Robust location based partial correlation.- Optimization of stereo disparity estimation using the instantaneous frequency.- Segmentation from motion: Combining Gabor- and Mallat-wavelets to overcome aperture and correspondence problem.- Contour segmentation with recurrent neural networks of pulse-coding neurons.- Multigrid MRF based picture segmentation with cellular neural networks.- Computing stochastic completion fields in linear-time using a resolution pyramid.- A Bayesian network for 3d object recognition in range data.- Improving the shape recognition performance of a model with Gabor filter representation.- Bayesian decision versus voting for image retrieval.- A structured neural network invariant to cyclic shifts and rotations.- Morphological grain operators for binary images.- A parallel 12-subiteration 3D thinning algorithm to extract medial lines.- Architectural image segmentation using digital watersheds.- Morphological iterative closest point algorithm.- Planning multiple views for 3-D object recognition and pose determination.- Fast and reliable object pose estimation from line correspondences.- Statistical 3-D object localization without segmentation using wavelet analysis.- A real-time monocular vision-based 3D mouse system.- Face recognition by elastic bunch graph matching.- A conditional mixture of neural networks for face detection, applied to locating and tracking an individual speaker.- Lipreading using Fourier transform over time.- Phantom faces for face analysis.- A new hardware structure for implementation of soft morphological filters.- A method for anisotropy analysis of 3D images.- Fast line and rectangle detection by clustering and grouping.- 1st and 2nd order recursive operators for adaptive edge detection.- Smoothing noisy images without destroying predefined feature carriers.- Local subspace method for pattern recognition.- Testing the effectiveness of Non-Linear Rectification on gabor energy.- Neural-like thinning processing.- Detection of the objects with given shape on the grey-valued pictures.- Automatic parameter selection for object recognition using a parallel multiobjective genetic algorithm.- Unsupervised texture segmentation using Hermite transform filters.- Decomposition of the Hadamard matrices and fast Hadamard transform.- A characterization of digital disks by discrete moments.- ""One-step"" short-length DCT algorithms with data representation in the direct sum of the associative algebras.- Character extraction from scene image using fuzzy entropy and rule-based technique.- Facial image recognition using neural networks and genetic algorithms.- An energy minimisation approach to the registration, matching and recognition of images.- ""Error-free"" calculation of the convolution using generalized Mersenne and Fermat transforms over algebraic fields.- A new method of texture binarization.- Parameter optimisation of an image processing system using evolutionary algorithms.- Analysis of learning using segmentation models.- Stereo processing of image data from the Air-Borne CCD-scanner WAAC.- An adaptive method of color road segmentation.- Optical flow detection using a general noise model for gradient constraint.- Algorithmic solution and simulation results for vision-based autonomous mode of a planetary rover.- A framework for feature-based motion recovery in ground plane vehicle navigation.- Terrain reconstruction from multiple views.- Detecting motion independent of the camera movement through a log-polar differential approach.- Coordinate-free camera calibration.- A passive real-time gaze estimation system for human-machine interfaces.- An active vision system for obtaining high resolution depth information.",project-academic
10.1109/GTSD.2018.8595590,2018-11-01,p,IEEE,real time self driving car navigation using deep neural network," In this paper, a monocular vision-based self-driving car prototype using Deep Neural Network on Raspberry Pi is proposed. Self-driving cars are one of the most increasing interests in recent years as the definitely developing relevant hardware and software technologies toward fully autonomous driving capability with no human intervention. Level-3/4 autonomous vehicles are potentially turning into a reality in near future. Convolutional Neural Networks (CNNs) have been shown to achieve significant performance in various perception and control tasks in comparison to other techniques in the latest years. The key factors behind these impressive results are their ability to learn millions of parameters using a large amount of labeled data. In this work, we concentrate on finding a model that directly maps raw input images to a predicted steering angle as output using a deep neural network. The technical contributions of this work are two-fold. First, the CNN model parameters were trained by using data collected from vehicle platform built with a 1/10 scale RC car, Raspberry Pi 3 Model B computer and front-facing camera. The training data were road images paired with the time-synchronized steering angle generated by manually driving. Second, road tests the model on Raspberry to drive itself in the outdoor environment around oval-shaped and 8-shaped with traffic sign lined track. The experimental results demonstrate the effectiveness and robustness of autopilot model in lane keeping task. Vehicle’s top speed is about 5-6km/h in a wide variety of driving conditions, regardless of whether lane markings are present or not.",project-academic
10.1007/978-981-15-2568-1_11,2019-12-28,p,Springer Science and Business Media LLC,development status and challenges of unmanned vehicle driving technology," Nowadays, artificial intelligence instead of the human race driving is no longer just a dream, but gradually becomes a reality. Internet of Things and smart technologies are gradually being used in vehicles, so cars can have their own ideas. Driverless cars are one of the typical representatives. Driverless cars, that is, unmanned cars on the road, mainly through the sensor system installed on the vehicle, intelligent software and various environmental sensing devices, to sense the state and environment of the vehicle itself and its surrounding environment. At the same time, according to the software set the motion track to reach the destination. Compared to traditional cars, unmanned vehicles have the characteristics of high safety, high reliability and intelligence, which are the main development directions of future cars. This paper will introduce the unmanned car driving technology from three aspects: application value, domestic and international development status and main challenges.",project-academic
,2020-01-09,,,vehicle network apparatus and operation method thereof," Provided is a vehicle network apparatus including a plurality of SDN switches and a gateway configured to identify a route for transmitting data of a device connected to at least one software defined network (SDN) switch among the plurality of switches and control the plurality of SDN switches so that the data is transmitted based on the identified route, and an operation method thereof. In the present disclosure, at least one of the vehicle network apparatus, a vehicle, and an autonomous vehicle may operate in association with an artificial intelligence (AI) module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, and a 5G service-related device, for example.",project-academic
10.3389/FFUTR.2021.688482,2021-08-26,a,Frontiers Media SA,automotive intelligence embedded in electric connected autonomous and shared vehicles technology for sustainable green mobility," The automotive sector digitalization accelerates the technology convergence of perception, computing processing, connectivity, propulsion, and data fusion for electric connected autonomous and shared (ECAS) vehicles, bringing new computing paradigms at the edge with embedded cognitive capabilities into the vehicle domains and data infrastructure to provide holistic intrinsic and extrinsic intelligence for new mobility applications. Innovation occurs predominantly in ECAS vehicles' architectures, intelligent functions, operations, and automotive digital infrastructure. Artificial Intelligence (AI), cellular/wireless connectivity, edge computing, Internet of Things (IoT), Internet of Intelligent Things, digital twins (DTs), virtual/augmented reality (VR/AR) and distributed ledger technologies (DLTs) converge to facilitate vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I) and vehicle-to-everything (V2X) communication and automation. Expanding automotive intelligence at the vehicle and mobility system level allows the Internet of Vehicles (IoV) and Internet of Energy (IoE) to become the key enabling technologies to realize future autonomous driving scenarios that embed cognition and autonomous functions. Vehicles become intelligent connected edge micro-servers on wheels, powered by software, smart virtual functions and integrated into the digital infrastructure. Electrification, automation, connectivity, digitalization, decarbonization, decentralization, and standardization are the main drivers that unlock intelligent vehicles' potential for sustainable green mobility applications. ECAS vehicles act as autonomous agents using swarm intelligence to communicate and exchange information either directly or indirectly with each other and the infrastructure, accessing independent services such as energy, high-definition maps, routs, infrastructure information, traffic lights, tolls, parking (micropayments) and finding emergent/intelligent solutions. Digitalization is also radically transforming the powertrains in electric vehicles (EVs). For example, in the battery domain, the batteries' architectures are optimizing the cables to the sensors and sensing point. Innovations like smart battery cells assembled in complex battery systems, with wireless communication between the smart cells and the central battery management system (BMS), enable ultra-high-speed interaction with the smart battery cell parameters. The article presents ECAS vehicles' evolution towards domain controller, zonal vehicle, and federated vehicle/edge/cloud-centric based on distributed intelligence at the vehicle and infrastructure level architectures and the role of AI techniques and methods to implement the different autonomous driving and optimization functions for sustainable green mobility.",project-academic
10.7146/AUL.277.192,2018-11-07,a,AU Library Scholarly Publishing Services - E-Books,tractoreye vision based real time detection for autonomous vehicles in agriculture," Agricultural vehicles such as tractors and harvesters have for decades been able to navigate automatically and more efficiently using commercially available products such as auto-steering and tractor-guidance systems. However, a human operator is still required inside the vehicle to ensure the safety of vehicle and especially surroundings such as humans and animals. To get fully autonomous vehicles certified for farming, computer vision algorithms and sensor technologies must detect obstacles with equivalent or better than human-level performance. Furthermore, detections must run in real-time to allow vehicles to actuate and avoid collision. None None None This thesis proposes a detection system (TractorEYE), a dataset (FieldSAFE), and procedures to fuse information from multiple sensor technologies to improve detection of obstacles and to generate a map.  None None TractorEYE is a multi-sensor detection system for autonomous vehicles in agriculture. The multi-sensor system consists of three hardware synchronized and registered sensors (stereo camera, thermal camera and multi-beam lidar) mounted on/in a ruggedized and water-resistant casing. Algorithms have been developed to run a total of six detection algorithms (four for rgb camera, one for thermal camera and one for a Multi-beam lidar) and fuse detection information in a common format using either 3D positions or Inverse Sensor Models. A GPU powered computational platform is able to run detection algorithms online. For the rgb camera, a deep learning algorithm is proposed DeepAnomaly to perform real-time anomaly detection of distant, heavy occluded and unknown obstacles in agriculture. DeepAnomaly is -- compared to a state-of-the-art object detector Faster R-CNN -- for an agricultural use-case able to detect humans better and at longer ranges (45-90m) using a smaller memory footprint and 7.3-times faster processing. Low memory footprint and fast processing makes DeepAnomaly suitable for real-time applications running on an embedded GPU.  None None FieldSAFE is a multi-modal dataset for detection of static and moving obstacles in agriculture. The dataset includes synchronized recordings from a rgb camera, stereo camera, thermal camera, 360-degree camera, lidar and radar. Precise localization and pose is provided using IMU and GPS. Ground truth of static and moving obstacles (humans, mannequin dolls, barrels, buildings, vehicles, and vegetation) are available as an annotated orthophoto and GPS coordinates for moving obstacles.  None None None Detection information from multiple detection algorithms and sensors are fused into a map using Inverse Sensor Models and occupancy grid maps.  None None This thesis presented many scientific contribution and state-of-the-art within perception for autonomous tractors; this includes a dataset, sensor platform, detection algorithms and procedures to perform multi-sensor fusion. Furthermore, important engineering contributions to autonomous farming vehicles are presented such as easily applicable, open-source software packages and algorithms that have been demonstrated in an end-to-end real-time detection system. The contributions of this thesis have demonstrated, addressed and solved critical issues to utilize camera-based perception systems that are essential to make autonomous vehicles in agriculture a reality.",project-academic
10.37591/JOTSSN.V7I1.3971,2020-06-10,a,,autonomous vehicles the future of transportation," Abstract None None None None Autonomous vehicles are anticipated to be the future of automobile transportation which is efficient safe and cost effective, several automobile companies have put their foot in the vast segment of autonomous vehicles and are currently working towards manufacturing driverless vehicles. From Internet giant Google Inc. to major Automobile manufacturing companies like BMW, Mercedes, Toyota, Tesla motors and world’s largest Taxi firm Uber, all major and minor companies are putting a foot in this extremely vast and amazingly innovative segment in the automotive world. Autonomous Vehicles has already become a reality and very soon Autonomous cars and bikes will hit the streets. The basic aim of this invention or development is to ease the efforts of the passengers and drivers, by taking full or partial control of the vehicle and transporting them from one place to other without letting them put a finger on the steering or a foot on the pedal. This paper gives a brief idea of all the systems used in making an autonomous vehicle and its applications, all the different types of sensors used in autonomous vehicles like RADAR, LIDAR, GPS, INS etc., and various software and Hardware used. Also, the detailed timelines, right from the first development to the recent discoveries in the field of autonomous mobility and its advantages and disadvantages have been discussed in this paper. None None None None Keywords: None None None Hardware, software, RADAR, LIDAR, GPS, INS, autonomous, artificial intelligence, autopilot, mechatronics None None None Cite this Article None None Shirin Siddiqui, Amaan Khan, Prashant Rade. Autonomous Vehicles: The Future of Transportation. None Journal of Telecommunication, Switching Systems and Networks . 2020; 7(1): 8–13p.",project-academic
,2019-10-28,a,,overview of the plexil plan execution technology and its applications in autonomous piloting projects at nasa," Automated planning is a key Artificial Intelligence technology enabling Unmanned Aerial Systems (UAS) and the eminent reality of Urban Air Mobility (UAM). It produces plans, which formalize procedures often performed by humans. Plans differ from other kinds of computer programs in their ability to react and interact with a dynamically changing environment. Aviation plans must encode the procedural knowledge, reasoning capability, and capacity for multi-tasking held by competent human pilots. Correct execution of these plans (performed by software called an executive) in the dynamic airspace environment is vital to the success of each automated flight, and the safety of the vehicle and all things in its path. In the early 2000s NASA developed a plan representation language and executive called PLEXIL (Plan Execution Interchange Language) that has successfully been applied in several NASA aviation and UAS projects. Autonomy Operating System (AOS), Cockpit Hierarchical Automated Planning and Execution (CHAP-E), and ICAROUS are all projects that have used PLEXIL to help encode and automatically execute flight procedures, some normally performed by human pilots. AOS also automates a subset of pilot/Air Traffic Control communication towards enabling UAS entry into the National Airspace. PLEXIL has been open-source software since 2008 and has seen usage in a wide range of prototypical autonomy applications in academia, government, and industry. In this presentation, we describe PLEXIL and highlight its significant accomplishments in the aviation domain.",project-academic
,1990-01-01,a,,communications three dimensional visualization of mission planning and control for the nps autonomous underwater vehicle," Unmanned vehicles can operate where humans cannot or do not want to go. The last decade's advances in computer processor capability and speed, component miniaturization, signal processing, and high-energy density power supplies have made remotely operated vehicles (ROV's) and, to some extent, autonomous vehicles, a reality. In an effort to further advance this technology, the Naval Postgraduate School (NPS) is constructing a small autonomous underwater vehicle (AUY) with an onboard mission control computer. The mission controller software for this vehicle is a knowledge-based artificial intelligence (AI) system requiring thorough analysis and testing before the AUV is operational. We discuss how rapid prototyping of this software has been demonstrated by developing controller code on a LISP machine and using an Ethernet link with a graphics workstation to simulate the controller's environment. Additionally, we discuss the development of a new testing simulator using a KEE expert system shell that is designed to examine AUV controller subsystems and vehicle models before integrating them with the full AUV for its test environment missions. This AUV simulator utilizes an interactive Mission Planning Control Console and is fully autonomous once initial parameters are selected.",project-academic
10.1109/ICDCS.2018.00131,2018-07-02,p,IEEE,openvdap an open vehicular data analytics platform for cavs," In this paper, we envision the future connected and autonomous vehicles (CAVs) as a sophisticated computer on wheels, with substantial on-board sensors as data sources and a variety of services running on top to support autonomous driving or other functions. In general, these services are computationally expensive, especially for the machine learning based applications (e.g., CNN-based object detection). Nevertheless, the on-board computation unit possess limited compute resources, raising a huge challenge to deploy these computation-intensive services on the vehicle. On the contrary, the cloud-based architecture conceptually with unconstrained resources suffers from unexpected extended latency that attributes to the large-scale Internet data transmission; thus, adversely affecting the services' real-time performance, quality of services and user experiences. To address this dilemma, inspired by the promising edge computing paradigm, we propose to build an Open Vehicular Data Analytics Platform (OpenVDAP) for CAVs, which is a full-stack edge based platform including an on-board computing/communication unit, an isolation-supported and security & privacy-preserved vehicle operation system, an edge-aware application library, as well as an optimal workload of?oading and scheduling strategy, allowing CAVs to dynamically detect each service's status, computation overhead and the optimal of?oading destination so that each service could be finished within an acceptable latency and limited bandwidth consumption. Most importantly, contrast to the proprietary platform, OpenVDAP is an open-source platform that offers free APIs and real-?eld vehicle data to the researchers and developers in the community, allowing them to deploy and evaluate applications on the real environment.",project-academic
,2018-12-07,a,,zero shot deep reinforcement learning driving policy transfer for autonomous vehicles based on robust control," Although deep reinforcement learning (deep RL) methods have lots of strengths that are favorable if applied to autonomous driving, real deep RL applications in autonomous driving have been slowed down by the modeling gap between the source (training) domain and the target (deployment) domain. Unlike current policy transfer approaches, which generally limit to the usage of uninterpretable neural network representations as the transferred features, we propose to transfer concrete kinematic quantities in autonomous driving. The proposed robust-control-based (RC) generic transfer architecture, which we call RL-RC, incorporates a transferable hierarchical RL trajectory planner and a robust tracking controller based on disturbance observer (DOB). The deep RL policies trained with known nominal dynamics model are transfered directly to the target domain, DOB-based robust tracking control is applied to tackle the modeling gap including the vehicle dynamics errors and the external disturbances such as side forces. We provide simulations validating the capability of the proposed method to achieve zero-shot transfer across multiple driving scenarios such as lane keeping, lane changing and obstacle avoidance.",project-academic
10.1109/ITSC.2018.8569612,2018-12-07,p,IEEE,zero shot deep reinforcement learning driving policy transfer for autonomous vehicles based on robust control," Although deep reinforcement learning (deep RL) methods have lots of strengths that are favorable if applied to autonomous driving, real deep RL applications in autonomous driving have been slowed down by the modeling gap between the source (training) domain and the target (deployment) domain. Unlike current policy transfer approaches, which generally limit to the usage of uninterpretable neural network representations as the transferred features, we propose to transfer concrete kinematic quantities in autonomous driving. The proposed robust-control-based (RC) generic transfer architecture, which we call RL-RC, incorporates a transferable hierarchical RL trajectory planner and a robust tracking controller based on disturbance observer (DOB). The deep RL policies trained with known nominal dynamics model are transfered directly to the target domain, DOB-based robust tracking control is applied to tackle the modeling gap including the vehicle dynamics errors and the external disturbances such as side forces. We provide simulations validating the capability of the proposed method to achieve zero-shot transfer across multiple driving scenarios such as lane keeping, lane changing and obstacle avoidance.",project-academic
10.1109/LRA.2020.2969927,2018-11-17,a,,augmented lidar simulator for autonomous driving," In Autonomous Driving (AD), detection and tracking of obstacles on the roads is a critical task. Deep-learning based methods using annotated LiDAR data have been the most widely adopted approach for this. Unfortunately, annotating 3D point cloud is a very challenging, time- and money-consuming task. In this paper, we propose a novel LiDAR simulator that augments real point cloud with synthetic obstacles (e.g., cars, pedestrians, and other movable objects). Unlike previous simulators that entirely rely on CG models and game engines, our augmented simulator bypasses the requirement to create high-fidelity background CAD models. Instead, we can simply deploy a vehicle with a LiDAR scanner to sweep the street of interests to obtain the background point cloud, based on which annotated point cloud can be automatically generated. This unique ""scan-and-simulate"" capability makes our approach scalable and practical, ready for large-scale industrial applications. In this paper, we describe our simulator in detail, in particular the placement of obstacles that is critical for performance enhancement. We show that detectors with our simulated LiDAR point cloud alone can perform comparably (within two percentage points) with these trained with real data. Mixing real and simulated data can achieve over 95% accuracy.",project-academic
10.1109/ICRA40945.2020.9196844,2020-05-01,p,,uncertainty quantification with statistical guarantees in end to end autonomous driving control," Deep neural network controllers for autonomous driving have recently benefited from significant performance improvements, and have begun deployment in the real world. Prior to their widespread adoption, safety guarantees are needed on the controller behaviour that properly take account of the uncertainty within the model as well as sensor noise. Bayesian neural networks, which assume a prior over the weights, have been shown capable of producing such uncertainty measures, but properties surrounding their safety have not yet been quantified for use in autonomous driving scenarios. In this paper, we develop a framework based on a state-of-the-art simulator for evaluating end-to-end Bayesian controllers. In addition to computing pointwise uncertainty measures that can be computed in real time and with statistical guarantees, we also provide a method for estimating the probability that, given a scenario, the controller keeps the car safe within a finite horizon. We experimentally evaluate the quality of uncertainty computation by three Bayesian inference methods in different scenarios and show how the uncertainty measures can be combined and calibrated for use in collision avoidance. Our results suggest that uncertainty estimates can greatly aid decision making in autonomous driving.",project-academic
,2019-09-21,a,,uncertainty quantification with statistical guarantees in end to end autonomous driving control," Deep neural network controllers for autonomous driving have recently benefited from significant performance improvements, and have begun deployment in the real world. Prior to their widespread adoption, safety guarantees are needed on the controller behaviour that properly take account of the uncertainty within the model as well as sensor noise. Bayesian neural networks, which assume a prior over the weights, have been shown capable of producing such uncertainty measures, but properties surrounding their safety have not yet been quantified for use in autonomous driving scenarios. In this paper, we develop a framework based on a state-of-the-art simulator for evaluating end-to-end Bayesian controllers. In addition to computing pointwise uncertainty measures that can be computed in real time and with statistical guarantees, we also provide a method for estimating the probability that, given a scenario, the controller keeps the car safe within a finite horizon. We experimentally evaluate the quality of uncertainty computation by several Bayesian inference methods in different scenarios and show how the uncertainty measures can be combined and calibrated for use in collision avoidance. Our results suggest that uncertainty estimates can greatly aid decision making in autonomous driving.",project-academic
10.1186/S13007-017-0173-7,2017-04-08,a,BioMed Central,a real time phenotyping framework using machine learning for plant stress severity rating in soybean," Phenotyping is a critical component of plant research. Accurate and precise trait collection, when integrated with genetic tools, can greatly accelerate the rate of genetic gain in crop improvement. However, efficient and automatic phenotyping of traits across large populations is a challenge; which is further exacerbated by the necessity of sampling multiple environments and growing replicated trials. A promising approach is to leverage current advances in imaging technology, data analytics and machine learning to enable automated and fast phenotyping and subsequent decision support. In this context, the workflow for phenotyping (image capture → data storage and curation → trait extraction → machine learning/classification → models/apps for decision support) has to be carefully designed and efficiently executed to minimize resource usage and maximize utility. We illustrate such an end-to-end phenotyping workflow for the case of plant stress severity phenotyping in soybean, with a specific focus on the rapid and automatic assessment of iron deficiency chlorosis (IDC) severity on thousands of field plots. We showcase this analytics framework by extracting IDC features from a set of ~4500 unique canopies representing a diverse germplasm base that have different levels of IDC, and subsequently training a variety of classification models to predict plant stress severity. The best classifier is then deployed as a smartphone app for rapid and real time severity rating in the field. We investigated 10 different classification approaches, with the best classifier being a hierarchical classifier with a mean per-class accuracy of ~96%. We construct a phenotypically meaningful ‘population canopy graph’, connecting the automatically extracted canopy trait features with plant stress severity rating. We incorporated this image capture → image processing → classification workflow into a smartphone app that enables automated real-time evaluation of IDC scores using digital images of the canopy. We expect this high-throughput framework to help increase the rate of genetic gain by providing a robust extendable framework for other abiotic and biotic stresses. We further envision this workflow embedded onto a high throughput phenotyping ground vehicle and unmanned aerial system that will allow real-time, automated stress trait detection and quantification for plant research, breeding and stress scouting applications.",project-academic
10.1109/ACCESS.2019.2953326,2019-11-13,a,IEEE,learn to navigate cooperative path planning for unmanned surface vehicles using deep reinforcement learning," Unmanned surface vehicle (USV) has witnessed a rapid growth in the recent decade and has been applied in various practical applications in both military and civilian domains. USVs can either be deployed as a single unit or multiple vehicles in a fleet to conduct ocean missions. Central to the control of USV and USV formations, path planning is the key technology that ensures the navigation safety by generating collision free trajectories. Compared with conventional path planning algorithms, the deep reinforcement learning (RL) based planning algorithms provides a new resolution by integrating a high-level artificial intelligence. This work investigates the application of deep reinforcement learning algorithms for USV and USV formation path planning with specific focus on a reliable obstacle avoidance in constrained maritime environments. For single USV planning, with the primary aim being to calculate a shortest collision avoiding path, the designed RL path planning algorithm is able to solve other complex issues such as the compliance with vehicle motion constraints. The USV formation maintenance algorithm is capable of calculating suitable paths for the formation and retain the formation shape robustly or vary shapes where necessary, which is promising to assist with the navigation in environments with cluttered obstacles. The developed three sets of algorithms are validated and tested in computer-based simulations and practical maritime environments extracted from real harbour areas in the UK.",project-academic
10.1109/TASE.2018.2830655,2018-05-16,a,IEEE,generalized haar filter based object detection for car sharing services," Object detection is important in car sharing services. Accuracy, efficiency, and low memory consumption are desirable for object detection in car sharing services. This paper presents a network system that satisfies all these requirements. Our approach first divides the object detection task into multiple simpler local regression tasks. Then, we propose the generalized Haar filter-based convolutional neural network to reduce the consumption of memory and computing resource. To achieve real-time performance, we introduce a sparse window generation strategy to reduce the number of input image patches without sacrificing accuracy. We perform experiments on both vehicle and pedestrian data sets. Experimental results demonstrate that our approach can accurately detect objects under challenging conditions. None Note to Practitioners —Object detection is an important part of intelligent vehicle technologies, which play an important role in car sharing services. Object detection provides metadata for collision avoidance, self-driving systems, and driver-assistance systems, which can result in better safety and consumer experiences in car sharing services. Although deep learning has achieved an excellent performance in object detection, they consume a large amount of storage and computing resource, which makes them difficult to be deployed for car sharing services. This paper suggests a novel approach which is based on the generalized Haar filter and the local regression strategy. Our approach is accurate, efficient, and light. The experimental results verify the effectiveness of the proposed approach in car sharing services.",project-academic
10.1155/2020/4372847,2020-03-20,a,Hindawi Limited,vehicle detection and ranging using two different focal length cameras," Vehicle detection is a crucial task for autonomous driving and demands high accuracy and real-time speed. Considering that the current deep learning object detection model size is too large to be deployed on the vehicle, this paper introduces the lightweight network to modify the feature extraction layer of YOLOv3 and improve the remaining convolution structure, and the improved Lightweight YOLO network reduces the number of network parameters to a quarter. Then, the license plate is detected to calculate the actual vehicle width and the distance between the vehicles is estimated by the width. This paper proposes a detection and ranging fusion method based on two different focal length cameras to solve the problem of difficult detection and low accuracy caused by a small license plate when the distance is far away. The experimental results show that the average precision and recall of the Lightweight YOLO trained on the self-built dataset is 4.43% and 3.54% lower than YOLOv3, respectively, but the computing speed of the network decreases 49 ms per frame. The road experiments in different scenes also show that the long and short focal length camera fusion ranging method dramatically improves the accuracy and stability of ranging. The mean error of ranging results is less than 4%, and the range of stable ranging can reach 100 m. The proposed method can realize real-time vehicle detection and ranging on the on-board embedded platform Jetson Xavier, which satisfies the requirements of automatic driving environment perception.",project-academic
10.1109/CRV.2018.00024,2018-05-08,p,IEEE,a hierarchical deep architecture and mini batch selection method for joint traffic sign and light detection," Traffic light and sign detectors on autonomous cars are integral for road scene perception. The literature is abundant with deep learning networks that detect either lights or signs, not both, which makes them unsuitable for real-life deployment due to the limited graphics processing unit (GPU) memory and power available on embedded systems. The root cause of this issue is that no public dataset contains both traffic light and sign labels, which leads to difficulties in developing a joint detection framework. We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets. Our method solves the overlapping issue where instances from one dataset are not labelled in the other dataset. We are the first to present a network that performs joint detection on traffic lights and signs. We measure our network on the Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small Traffic Lights benchmark for traffic light detection and show it outperforms the existing Bosch Small Traffic light state-of-the-art method. We focus on autonomous car deployment and show our network is more suitable than others because of its low memory footprint and real-time image processing time. Qualitative results can be viewed at https://youtu.be/ YmogPzBXOw.",project-academic
10.1109/ACCESS.2020.3046499,2021-01-01,a,IEEE,real time energy harvesting aided scheduling in uav assisted d2d networks relying on deep reinforcement learning," Unmanned aerial vehicle (UAV)-assisted device-to-device (D2D) communications can be deployed flexibly thanks to UAVs’ agility. By exploiting the direct D2D interaction supported by UAVs, both the user experience and network performance can be substantially enhanced at public events. However, the continuous moving of D2D users, limited energy and flying time of UAVs are impediments to their applications in real-time. To tackle this issue, we propose a novel model based on deep reinforcement learning in order to find the optimal solution for the energy-harvesting time scheduling in UAV-assisted D2D communications. To make the system model more realistic, we assume that the UAV flies around a central point, the D2D users move continuously with random walk model and the channel state information encountered during each time slot is randomly time-variant. Our numerical results demonstrate that the proposed schemes outperform the existing solutions. The associated energy efficiency game can be solved in less than one millisecond by an off-the-shelf processor using trained neural networks. Hence our deep reinforcement learning techniques are capable of solving real-time resource allocation problems in UAV-assisted wireless networks.",project-academic
,2020-12-13,a,,edge intelligence for autonomous driving in 6g wireless system design challenges and solutions," In a level-5 autonomous driving system, the autonomous driving vehicles (AVs) are expected to sense the surroundings via analyzing a large amount of data captured by a variety of onboard sensors in near-real-time. As a result, enormous computing costs will be introduced to the AVs for processing the tasks with the deployed machine learning (ML) model, while the inference accuracy may not be guaranteed. In this context, the advent of edge intelligence (EI) and sixth-generation (6G) wireless networking are expected to pave the way to more reliable and safer autonomous driving by providing multi-access edge computing (MEC) together with ML to AVs in close proximity. To realize this goal, we propose a two-tier EI-empowered autonomous driving framework. In the autonomous-vehicles tier, the autonomous vehicles are deployed with the shallow layers by splitting the trained deep neural network model. In the edge-intelligence tier, an edge server is implemented with the remaining layers (also deep layers) and an appropriately trained multi-task learning (MTL) model. In particular, obtaining the optimal offloading strategy (including the binary offloading decision and the computational resources allocation) can be formulated as a mixed-integer nonlinear programming (MINLP) problem, which is solved via MTL in near-real-time with high accuracy. On another note, an edge-vehicle joint inference is proposed through neural network segmentation to achieve efficient online inference with data privacy-preserving and less communication delay. Experiments demonstrate the effectiveness of the proposed framework, and open research topics are finally listed.",project-academic
10.1109/MWC.001.2000292,2021-05-14,a,Institute of Electrical and Electronics Engineers (IEEE),edge intelligence for autonomous driving in 6g wireless system design challenges and solutions," In a level-5 autonomous driving system, the autonomous driving vehicles (AVs) are expected to sense the surroundings via analyzing a large amount of data captured by a variety of onboard sensors in near-real-time. As a result, enormous computing costs will be introduced to the AVs for processing the tasks with the deployed machine learning (ML) model, while the inference accuracy may not be guaranteed. In this context, the advent of edge intelligence (EI) and sixth-generation (6G) wireless networking are expected to pave the way to more reliable and safer autonomous driving by providing multi-access edge computing (MEC) together with ML to AVs in close proximity. To realize this goal, we propose a two-tier EI-empowered autonomous driving framework. In the autonomous-vehicles tier, the autonomous vehicles are deployed with the shallow layers by splitting the trained deep neural network model. In the edge-intelligence tier, an edge server is implemented with the remaining layers (also deep layers) and an appropriately trained multi-task learning (MTL) model. In particular, obtaining the optimal offloading strategy (including the binary offloading decision and the computational resources allocation) can be formulated as a mixed-integer nonlinear programming (MINLP) problem, which is solved via MTL in near-real-time with high accuracy. On another note, an edge-vehicle joint inference is proposed through neural network segmentation to achieve efficient online inference with data privacy-preserving and less communication delay. Experiments demonstrate the effectiveness of the proposed framework, and open research topics are finally listed.",project-academic
10.1109/AERO.2018.8396807,2018-03-03,p,IEEE,learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles," Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400–500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.",project-academic
10.1109/JIOT.2020.3043716,2021-04-15,a,IEEE,computing systems for autonomous driving state of the art and challenges," The recent proliferation of computing technologies (e.g., sensors, computer vision, machine learning, and hardware acceleration) and the broad deployment of communication mechanisms (e.g., dedicated short-range communication, cellular vehicle-to-everything, 5G) have pushed the horizon of autonomous driving, which automates the decision and control of vehicles by leveraging the perception results based on multiple sensors. The key to the success of these autonomous systems is making a reliable decision in real-time fashion. However, accidents and fatalities caused by early deployed autonomous vehicles arise from time to time. The real traffic environment is too complicated for current autonomous driving computing systems to understand and handle. In this article, we present state-of-the-art computing systems for autonomous driving, including seven performance metrics and nine key technologies, followed by 12 challenges to realize autonomous driving. We hope this article will gain attention from both the computing and automotive communities and inspire more research in this direction.",project-academic
10.1016/J.ESWA.2016.03.024,2016-10-01,a,"Pergamon Press, Inc.",building detection from orthophotos using a machine learning approach," Automatic building detection in orthophotos via a machine learning approach.Flexible framework that exploits supervised learning.Applying the covariance descriptor to the building detection problem.An extended performance study of several combination segmentation-descriptor.Classification performance is obtained with K-NN, Partial Least Square and SVM. Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixelwise decisions. This paper presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings on aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Moreover, we introduce a principled evaluation that allows selecting the best pair segmentation algorithm-region descriptor for the task of building detection. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing such as intelligent unmanned aerial vehicle navigation and automatic 3D city modeling.",project-academic
,2019-05-14,,,unmanned aerial vehicle detection method based on deep learning," The invention discloses an unmanned aerial vehicle detection method based on deep learning. The method comprises the steps of collecting data; data enhancement; constructing a deep convolutional neural network model; performing model training; perform ing model deployment; and applying the model. A cascaded convolutional neural network model is used, and a correction module is added, so that the detection performance of the model can be further improved only by carrying out a small amount of human intervention in the detection process. Through model compression, the model can run on the embedded equipment in real time. And various performance parameters of the unmanned aerial vehicle can be given by combining a database technology. The method has the advantages that the type of the unmanned aerial vehicle can be judged. A correction module is also added, so that the detection performance of the model can be further improved only by carrying out a small amount of human intervention in the detection process. The database technology is combined, various performance parameters of the unmanned aerial vehicle can be given, and control over the unmanned aerial vehicle is facilitated.",project-academic
10.1109/ICRA.2019.8793743,2019-05-20,p,IEEE,training a binary weight object detector by knowledge transfer for autonomous driving," Autonomous driving has harsh requirements of small model size and energy efficiency, in order to enable the embedded system to achieve real-time on-board object detection. Recent deep convolutional neural network based object detectors have achieved state-of-the-art accuracy. However, such models are trained with numerous parameters and their high computational costs and large storage prohibit the deployment to memory and computation resource limited systems. Low-precision neural networks are popular techniques for reducing the computation requirements and memory footprint. Among them, binary weight neural networks (BWNs) are the extreme case which quantizes the float-point into just 1 bit. BWNs are difficult to train and suffer from accuracy deprecation due to the extreme low-bit representation. To address this problem, we propose a knowledge transfer (KT) method to aid the training of BWN using a full-precision teacher network. We built DarkNet- and MobileNet-based binary weight YOLOv2 detectors and conduct experiments on KITTI benchmark for car, pedestrian and cyclist detection. The experimental results show that the proposed method maintains high detection accuracy while reducing the model size of DarkNet-YOLO from 257 MB to 8.8 MB and MobileNet-YOLO from 193 MB to 7.9 MB.",project-academic
10.1109/DTPI52967.2021.9540195,2021-07-15,p,IEEE,parallel mining operating systems from digital twins to mining intelligence," With the rapid development and modernization requirement of global coal industry, there is an emerging need for intelligent and unmanned mining systems. In this paper, the Intelligent Mining Operating System (IMOS) is proposed and developed, based on the parallel management and control of mining operating infrastructure that integrates the intelligent mining theory, the ACP-based (Artificial societies, Computational experiments, Parallel execution) parallel intelligence approaches, and the new generation of artificial intelligence (AI) technologies. To satisfy the intelligent and unmanned demand of open-pit mines, the IMOS architecture is developed by integrating the theory of digital quadruplets. The main subsystems and functions of IMOS are elaborated in detail, including a single-vehicle operating subsystem, multi-vehicle collaboration subsystem, vehicle-road collaboration subsystem, unmanned intelligent subsystem, dispatch management subsystem, parallel management and control subsystem, supervisory subsystem, remote takeover subsystem, and communication subsystem. The IMOS presented in this paper is the first integrated solution for intelligent and unmanned mines in China, and has been implemented over ten main open pits in the past few years. Its deployment and utilization will effectively improve the production efficiency and safety level of open-pit mines, promote the construction of ecological mines, and bring great significance to the realization of sustainable mining development.",project-academic
10.1109/TIM.2020.3001659,2020-06-11,a,IEEE,real time fault detection for uav based on model acceleration engine," With the wide applications of the unmanned aerial vehicle (UAV) in the civilian and military fields, its operational safety has drawn much attention. A series of fault detection methods are studied to avoid disasters. Due to the capabilities of strong feature extraction and massive flight data processing, the deep learning-based methods have received extensive attention. However, restricted by UAV airborne size, weight, and power consumption, a significant challenge is posed to deploy these complicated detection methods in the airborne application, which requires to run in real time. In this article, a fault detection model acceleration engine (FDMAE) for UAV real-time fault detection is realized under the airborne constraint. First, a high-performance detection model is designed based on stacked long short-term memory networks, and fault detection is achieved by a statistical threshold in this method. Second, a model pruning method based on principal component analysis is proposed to improve computing efficiency. Finally, the pruned fault detection method is optimized and integrated as a flexible acceleration engine through high-level synthesis and deployed on an airborne embedded computing platform based on a field-programmable gate array. Real UAV flight data are used to verify the proposed FDMAE. By comparing accuracy, the area under the receiver operating characteristic curve, speed, and power consumption, the effectiveness of the FDMAE is proven.",project-academic
10.3390/S21041339,2021-02-13,a,Multidisciplinary Digital Publishing Institute,robustifying the deployment of tinyml models for autonomous mini vehicles," Standard-sized autonomous vehicles have rapidly improved thanks to the breakthroughs of deep learning. However, scaling autonomous driving to mini-vehicles poses several challenges due to their limited on-board storage and computing capabilities. Moreover, autonomous systems lack robustness when deployed in dynamic environments where the underlying distribution is different from the distribution learned during training. To address these challenges, we propose a closed-loop learning flow for autonomous driving mini-vehicles that includes the target deployment environment in-the-loop. We leverage a family of compact and high-throughput tinyCNNs to control the mini-vehicle that learn by imitating a computer vision algorithm, i.e., the expert, in the target environment. Thus, the tinyCNNs, having only access to an on-board fast-rate linear camera, gain robustness to lighting conditions and improve over time. Moreover, we introduce an online predictor that can choose between different tinyCNN models at runtime—trading accuracy and latency—which minimises the inference’s energy consumption by up to 3.2×. Finally, we leverage GAP8, a parallel ultra-low-power RISC-V-based micro-controller unit (MCU), to meet the real-time inference requirements. When running the family of tinyCNNs, our solution running on GAP8 outperforms any other implementation on the STM32L4 and NXP k64f (traditional single-core MCUs), reducing the latency by over 13× and the energy consumption by 92%.",project-academic
,2020-11-03,a,,distributional reinforcement learning for mmwave communications with intelligent reflectors on a uav," In this paper, a novel communication framework that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In order to maximize the downlink sum-rate, the optimal precoding matrix (at the base station) and reflection coefficient (at the IR) are jointly derived. Next, to address the uncertainty of mmWave channels and maintain line-of-sight links in a real-time manner, a distributional reinforcement learning approach, based on quantile regression optimization, is proposed to learn the propagation environment of mmWave communications, and, then, optimize the location of the UAV-IR so as to maximize the long-term downlink communication capacity. Simulation results show that the proposed learning-based deployment of the UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a static IR, and a direct transmission schemes, in terms of the average data rate and the achievable line-of-sight probability of downlink mmWave communications.",project-academic
10.1109/GLOBECOM42002.2020.9348040,2020-12-01,p,IEEE,distributional reinforcement learning for mmwave communications with intelligent reflectors on a uav," In this paper, a novel communication framework that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In order to maximize the downlink sum-rate, the optimal precoding matrix (at the base station) and reflection coefficient (at the IR) are jointly derived. Next, to address the uncertainty of mmWave channels and maintain line-of-sight links in a realtime manner, a distributional reinforcement learning approach, based on quantile regression optimization, is proposed to learn the propagation environment of mmWave communications, and, then, optimize the location of the UAV-IR so as to maximize the long-term downlink communication capacity. Simulation results show that the proposed learning-based deployment of the UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a static IR, and a direct transmission schemes, in terms of the average data rate and the achievable line-of-sight probability of downlink mmWave communications.",project-academic
,2019-12-31,a,,mir vehicle cost effective research platform for autonomous vehicle applications," This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a feasible option of transforming an electric ride-on-car into a modular Graphics Processing Unit (GPU) powered autonomous platform equipped with the capability that supports test and deployment of various intelligent autonomous vehicles algorithms. To use a platform for research, two components must be provided: perception and control. The sensors such as incremental encoders, an Inertial Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR) must be able to be installed on the platform to add the capability of environmental perception. A microcontroller-powered control box is designed to properly respond to the environmental changes by regulating drive and steering motors. This drive-by-wire capability is controlled by a GPU powered laptop computer where high-level perception algorithms are processed and complex actions are generated by various methods including behavior cloning using deep neural networks. The main goal of this paper is to provide an adequate and comprehensive approach for fabricating a cost-effective platform that would contribute to the research quality from the wider community. The proposed platform is to use a modular and hierarchical software architecture where the lower and simpler motor controls are taken care of by microcontroller programs, and the higher and complex algorithms are processed by a GPU powered laptop computer. The platform uses the Robot Operating System (ROS) as middleware to maintain the modularity of the perceptions and decision-making modules. It is expected that the level three and above autonomous vehicle systems and Advanced Driver Assistance Systems (ADAS) can be tested on and deployed to the platform with a decent real-time system behavior due to the capabilities and affordability of the proposed platform.",project-academic
10.1109/LRA.2021.3064284,2020-08-18,a,,super human performance in gran turismo sport using deep reinforcement learning," Autonomous car racing is a major challenge in robotics. It raises fundamental problems for classical approaches such as planning minimum-time trajectories under uncertain dynamics and controlling the car at the limits of its handling. Besides, the requirement of minimizing the lap time, which is a sparse objective, and the difficulty of collecting training data from human experts have also hindered researchers from directly applying learning-based approaches to solve the problem. In the present work, we propose a learning-based system for autonomous car racing by leveraging a high-fidelity physical car simulation, a course-progress proxy reward, and deep reinforcement learning. We deploy our system in Gran Turismo Sport, a world-leading car simulator known for its realistic physics simulation of different race cars and tracks, which is even used to recruit human race car drivers. Our trained policy achieves autonomous racing performance that goes beyond what had been achieved so far by the built-in AI, and, at the same time, outperforms the fastest driver in a dataset of over 50,000 human players.",project-academic
,2020-03-06,a,,practical reinforcement learning for mpc learning from sparse objectives in under an hour on a real robot," Model Predictive Control (MPC) is a powerful control technique that handles constraints, takes the system's dynamics into account, and optimizes for a given cost function. In practice, however, it often requires an expert to craft and tune this cost function and find trade-offs between different state penalties to satisfy simple high level objectives. In this paper, we use Reinforcement Learning and in particular value learning to approximate the value function given only high level objectives, which can be sparse and binary. Building upon previous works, we present improvements that allowed us to successfully deploy the method on a real world unmanned ground vehicle. Our experiments show that our method can learn the cost function from scratch and without human intervention, while reaching a performance level similar to that of an expert-tuned MPC. We perform a quantitative comparison of these methods with standard MPC approaches both in simulation and on the real robot.",project-academic
10.3929/ETHZ-B-000404690,2020-07-31,p,OpenReview,practical reinforcement learning for mpc learning from sparse objectives in under an hour on a real robot," Model Predictive Control (MPC) is a powerful control technique that handles constraints, takes the system's dynamics into account, and optimizes for a given cost function. In practice, however, it often requires an expert to craft and tune this cost function and find trade-offs between different state penalties to satisfy simple high level objectives. In this paper, we use Reinforcement Learning and in particular value learning to approximate the value function given only high level objectives, which can be sparse and binary. Building upon previous works, we present improvements that allowed us to successfully deploy the method on a real world unmanned ground vehicle. Our experiments show that our method can learn the cost function from scratch and without human intervention, while reaching a performance level similar to that of an expert-tuned MPC. We perform a quantitative comparison of these methods with standard MPC approaches both in simulation and on the real robot.",project-academic
10.1109/IROS40897.2019.8967722,2019-11-01,p,IEEE,informed region selection for efficient uav based object detectors altitude aware vehicle detection with cycar dataset," Deep Learning-based object detectors enhance the capabilities of remote sensing platforms, such as Unmanned Aerial Vehicles (UAVs), in a wide spectrum of machine vision applications. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such algorithms in scenarios that impose low-latency constraints during inference, in order to make mission-critical decisions in real-time. In this paper, we address the challenge of efficient deployment of region-based object detectors in aerial imagery, by introducing an informed methodology for extracting candidate detection regions (proposals). Our approach considers information from the UAV on-board sensors, such as flying altitude and light-weight computer vision filters, along with prior domain knowledge to intelligently decrease the number of region proposals by eliminating false-positives at an early stage of the computation, reducing significantly the computational workload while sustaining the detection accuracy. We apply and evaluate the proposed approach on the task of vehicle detection. Our experiments demonstrate that state-of-the-art detection models can achieve up to 2.6x faster inference by employing our altitude-aware data-driven methodology. Alongside, we introduce and provide to the community a novel vehicle-annotated and altitude-stamped dataset of real UAV imagery, captured at numerous flying heights under a wide span of traffic scenarios.",project-academic
10.1109/NAECON46414.2019.9057988,2019-07-15,p,IEEE,real time 3 d segmentation on an autonomous embedded system using point cloud and camera," Present day autonomous vehicle relies on several sensor technologies for it’s autonomous functionality. The sensors based on their type and mounted-location on the vehicle, can be categorized as: line of sight and non-line of sight sensors and are responsible for the different level of autonomy. These line of sight sensors are used for the execution of actions related to localization, object detection and the complete environment understanding. The surrounding or environment understanding for an autonomous vehicle can be achieved by segmentation. Several traditional and deep learning related techniques providing semantic segmentation for an input from camera is already available, however with the advancement in the computing processor, the progression is on developing the deep learning application replacing traditional methods. This paper presents an approach to combine the input of camera and lidar for semantic segmentation purpose. The proposed model for outdoor scene segmentation is based on the frustum pointnet, and ResNet which utilizes the 3d point cloud and camera input for the 3d bounding box prediction across the moving and non-moving object and thus finally recognizing and understanding the scenario at the point-cloud or pixel level. For real time application the model is deployed on the RTMaps framework with Bluebox (an embedded platform for autonomous vehicle). The proposed architecture is trained with the CITYScpaes and the KITTI dataset.",project-academic
,2019-07-01,a,IEEE,real time 3 d segmentation on an autonomous embedded system using point cloud and camera," Present day autonomous vehicle relies on several sensor technologies for it’s autonomous functionality. The sensors based on their type and mounted-location on the vehicle, can be categorized as: line of sight and non-line of sight sensors and are responsible for the different level of autonomy. These line of sight sensors are used for the execution of actions related to localization, object detection and the complete environment understanding. The surrounding or environment understanding for an autonomous vehicle can be achieved by segmentation. Several traditional and deep learning related techniques providing semantic segmentation for an input from camera is already available, however with the advancement in the computing processor, the progression is on developing the deep learning application replacing traditional methods. This paper presents an approach to combine the input of camera and lidar for semantic segmentation purpose. The proposed model for outdoor scene segmentation is based on the frustum pointnet, and ResNet which utilizes the 3d point cloud and camera input for the 3d bounding box prediction across the moving and non-moving object and thus finally recognizing and understanding the scenario at the point-cloud or pixel level. For real time application the model is deployed on the RTMaps framework with Bluebox (an embedded platform for autonomous vehicle). The proposed architecture is trained with the CITYScpaes and the KITTI dataset.",project-academic
10.3390/RS12010182,2020-01-01,a,Multidisciplinary Digital Publishing Institute,real time detection of ground objects based on unmanned aerial vehicle remote sensing with deep learning application in excavator detection for pipeline safety," Unmanned aerial vehicle (UAV) remote sensing and deep learning provide a practical approach to object detection. However, most of the current approaches for processing UAV remote-sensing data cannot carry out object detection in real time for emergencies, such as firefighting. This study proposes a new approach for integrating UAV remote sensing and deep learning for the real-time detection of ground objects. Excavators, which usually threaten pipeline safety, are selected as the target object. A widely used deep-learning algorithm, namely You Only Look Once V3, is first used to train the excavator detection model on a workstation and then deployed on an embedded board that is carried by a UAV. The recall rate of the trained excavator detection model is 99.4%, demonstrating that the trained model has a very high accuracy. Then, the UAV for an excavator detection system (UAV-ED) is further constructed for operational application. UAV-ED is composed of a UAV Control Module, a UAV Module, and a Warning Module. A UAV experiment with different scenarios was conducted to evaluate the performance of the UAV-ED. The whole process from the UAV observation of an excavator to the Warning Module (350 km away from the testing area) receiving the detection results only lasted about 1.15 s. Thus, the UAV-ED system has good performance and would benefit the management of pipeline safety.",project-academic
10.1117/12.2028340,2013-10-22,p,International Society for Optics and Photonics,multi modal target detection for autonomous wide area search and surveillance," Generalised wide are search and surveillance is a common-place tasking for multi-sensory equipped autonomous systems. Here we present on a key supporting topic to this task - the automatic interpretation, fusion and detected target reporting from multi-modal sensor information received from multiple autonomous platforms deployed for wide-area environment search. We detail the realization of a real-time methodology for the automated detection of people and vehicles using combined visible-band (EO), thermal-band (IR) and radar sensing from a deployed network of multiple autonomous platforms (ground and aerial). This facilities real-time target detection, reported with varying levels of confidence, using information from both multiple sensors and multiple sensor platforms to provide environment-wide situational awareness. A range of automatic classification approaches are proposed, driven by underlying machine learning techniques, that facilitate the automatic detection of either target type with cross-modal target confirmation. Extended results are presented that show both the detection of people and vehicles under varying conditions in both isolated rural and cluttered urban environments with minimal false positive detection. Performance evaluation is presented at an episodic level with individual classifiers optimized for maximal each object of interest (vehicle/person) detection over a given search path/pattern of the environment, across all sensors and modalities, rather than on a per sensor sample basis. Episodic target detection, evaluated over a number of wide-area environment search and reporting tasks, generally exceeds 90%+ for the targets considered here.",project-academic
10.1109/IVS.2018.8500633,2018-06-26,p,IEEE,autonomous rc car for education purpose in istem projects," Software simulation and real environment running parallel execution is a lately proposed method, which also provides full coverage and convenience to accomplish autonomous driving education purpose. This paper introduces a new high-school iSTEM program of autonomous vehicles education. This program uses a Scaled RC-Car platform with several sensors and Raspberry Pi embedded platform, to build an autonomous driving car in scaled indoor simulation environment. The RC-Car is capable of safely autonomous driving. Many existing algorithms are put together to provide the necessary functions of autonomous driving, such lane detection, obstacle detection, lane following, vehicle control etc. In this paper, we provide the details of this program, hardware and software components of the RC-Car, Deep learning end-to-end approaching of algorithm deployment, and future works.",project-academic
10.1007/978-3-030-59155-7_37,2020-09-14,p,"Springer, Cham",how to conduct experiments with a real car experiences and practical guidelines," Higher computational power, new dimensions of interconnectivity and modern machine learning techniques are necessary for building a fully autonomous car, but exhibit an enormous technical complexity. Research about new approaches and technology for handling this complexity raises a problem: On the one side, researchers advocate transitions and replacements for the current systems mainly without deploying them in real cars on the streets. On the other side applying theoretical approaches without clear evidence of their practical benefits is risky for the practitioners. As a solution to close this gap, researchers should bring their ideas more often into physical cars and support their proposals with measurements from realistic experiments.",project-academic
,2020-01-01,a,,how to conduct experiments with a real car experiences and practical guidelines," Higher computational power, new dimensions of interconnectivity and modern machine learning techniques are necessary for building a fully autonomous car, but exhibit an enormous technical complexity. Research about new approaches and technology for handling this complexity raises a problem: On the one side, researchers advocate transitions and replacements for the current systems mainly without deploying them in real cars on the streets. On the other side applying theoretical approaches without clear evidence of their practical benefits is risky for the practitioners. As a solution to close this gap, researchers should bring their ideas more often into physical cars and support their proposals with measurements from realistic experiments.",project-academic
10.1109/TBC.2020.2983298,2021-03-01,a,Institute of Electrical and Electronics Engineers (IEEE),an innovative machine learning based scheduling solution for improving live uhd video streaming quality in highly dynamic network environments," The latest advances in terms of network technologies open up new opportunities for high-end applications, including using the next generation video streaming technologies. As mobile devices become more affordable and powerful, an increasing range of rich media applications could offer a highly realistic and immersive experience to mobile users. However, this comes at the cost of very stringent Quality of Service (QoS) requirements, putting significant pressure on the underlying networks. In order to accommodate these new rich media applications and overcome their associated challenges, this paper proposes an innovative Machine Learning-based scheduling solution which supports increased quality for live omnidirectional (360°) video streaming. The proposed solution is deployed in a highly dynamic Unmanned Aerial Vehicle (UAV)-based environment to support immersive live omnidirectional video streaming to mobile users. The effectiveness of the proposed method is demonstrated through simulations and compared against three state-of-the-art scheduling solutions, such as: static Prioritization (SP), Required Activity Detection Scheduler (RADS) and Frame Level Scheduler (FLS). The results show that the proposed solution outperforms the other schemes involved in terms of PSNR, throughput and packet loss rate.",project-academic
10.1007/978-3-030-70740-8_3,2020-10-21,p,"Springer, Cham",combat ugv support of company task force operations," Effective deployment of military forces and equipment in diverse operations requires the widest possible support of modern technical means. Robotic, semi-autonomous or autonomous means using artificial intelligence can also be important for reconnaissance and orientation in the operational area, as well as for identifying and destroying the enemy, and saving soldiers' lives. The paper describes the research into the requirements for these unmanned systems, with an emphasis on their abilities to bypass or pass obstacles, to ascertain a wide range of information from the theatre of operations and to transmit it to the commander in real time. The tasks can be fulfilled either semi-autonomously, under the control of the operator or autonomously, including diverse offensive activities. With the use of the Maneuver Control System CZ the possibilities of maneuver planning and the use of the unmanned ground vehicle group to support the combat action of the company task force are described here. A case study was conducted as a basis for the development of the article. The scenarios of three tactical situations describe the possibilities of the effective tactical use of a group of autonomous means in a wooded and open terrain, as well as in attacking the enemy.",project-academic
,2019-09-06,,,unmanned aerial vehicle detection system and method based on multi channel radio frequency signals," The invention discloses an unmanned aerial vehicle detection system and method based on multi-channel radio frequency signals. The system comprises a radio frequency receiving link, a microprocessor preprocessing module, a calculation decision unit and a cloud server training optimization module. The radio frequency receiving link receives an unmanned aerial vehicle remote controller radio frequency signal. The microprocessor preprocessing module performs analog-to-digital conversion on the output signal of the radio frequency receiving link and then performs multi-channel time sequence synchronization, and after synchronization, time domain waveforms of multi-channel unmanned aerial vehicle radio frequency signals are spliced into a matrix form to be output. The cloud server training optimization module is used for training a machine learning model for supply. The calculation decision-making unit receives the data output by the microprocessor preprocessing module to realize effectivedetection of the unmanned aerial vehicle and identification of the model of the unmanned aerial vehicle. According to the method, unmanned aerial vehicle remote controller signals on multiple channelsare detected in parallel, signal characteristics of the unmanned aerial vehicle remote controller signals are extracted, counted and analyzed, and then unmanned aerial vehicle detection is achieved.The system has the advantages of being low in cost, convenient to deploy, easy to operate and high in anti-interference capability.",project-academic
,2021-07-01,a,,carsnn an efficient spiking neural network for event based autonomous cars on the loihi neuromorphic research processor," Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",project-academic
10.1109/IJCNN52387.2021.9533738,2021-07-18,p,IEEE,carsnn an efficient spiking neural network for event based autonomous cars on the loihi neuromorphic research processor," Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",project-academic
10.1007/S10514-016-9588-7,2017-04-01,a,Springer US,an incremental nonparametric bayesian clustering based traversable region detection method," Navigation capability in complex and unknown outdoor environments is one of the major requirements for an autonomous vehicle and a robot that perform tasks such as a military mission or planetary exploration. Robust traversability estimation in unknown environments would allow the vehicle or the robot to devise control and planning strategies to maximize their effectiveness. In this study, we present a self-supervised on-line learning architecture to estimate the traversability in complex and unknown outdoor environments. The proposed approach builds a model by clustering appearance data using the newly proposed incremental nonparametric Bayesian clustering algorithm. The clusters are then classified as being either traversable or non-traversable. Because our approach effectively groups unknown regions with similar properties, while the vehicle is in motion without human intervention, the vehicle can be deployed to new environments by automatically adapting to changing environmental conditions. We demonstrate the performance of the proposed clustering algorithm through intensive experiments using synthetic and real data and evaluate the viability of the traversability estimation using real data sets collected in outdoor environment.",project-academic
,2018-06-20,a,,a hierarchical deep architecture and mini batch selection method for joint traffic sign and light detection," Traffic light and sign detectors on autonomous cars are integral for road scene perception. The literature is abundant with deep learning networks that detect either lights or signs, not both, which makes them unsuitable for real-life deployment due to the limited graphics processing unit (GPU) memory and power available on embedded systems. The root cause of this issue is that no public dataset contains both traffic light and sign labels, which leads to difficulties in developing a joint detection framework. We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets. Our method solves the overlapping issue where instances from one dataset are not labelled in the other dataset. We are the first to present a network that performs joint detection on traffic lights and signs. We measure our network on the Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small Traffic Lights benchmark for traffic light detection and show it outperforms the existing Bosch Small Traffic light state-of-the-art method. We focus on autonomous car deployment and show our network is more suitable than others because of its low memory footprint and real-time image processing time. Qualitative results can be viewed at this https URL",project-academic
10.1109/ACCESS.2021.3050522,2021-01-11,a,IEEE,spectrum sharing uav assisted mission critical communication learning aided real time optimisation," We propose an unmanned aerial vehicle (UAV) communications scheme with spectrum-sharing mechanism to provide mission-critical services such as disaster recovery and public safety. Specifically, the UAVs can serve as flying base stations to provide extended network coverage for the affected area under spectrum-sharing cognitive radio networks (CRNs). To cope with the effects of network destruction in a disaster, we propose a real-time optimisation framework for resource allocation (e.g., power and number of UAVs) for CRNs assisted by UAV relays. The proposed optimisation scheme aims at optimising the network throughput of primary and secondary networks under the stringent constraint of maximum tolerable interference impinged on the primary users. We also propose a deep neural network (DNN) model to significantly reduce the execution time under real-time solution of mixed-integer UAV deployment problems. For both primary and secondary networks, our real-time optimisation algorithms impose low computational complexity, hence, have a low execution time in solving throughput optimisation problems, which demonstrates the benefit of our approached proposed for spectrum-sharing UAV-assisted mission-critical services.",project-academic
10.1109/ICCE-BERLIN.2018.8576190,2018-09-01,p,IEEE,end to end learning based self driving using jacintonet," Automated driving functions, like highway driving and parking assist, are getting increasing deployed in high-end cars with the trend moving towards the self-driving car. With the advent of deep learning, many traditional computer vision techniques have been replaced by deep convolutional neural networks (CNN). End to end learning is one of the paradigm for self-driving, in which user provides a input images from the front facing camera to the given neural network and the network outputs the car control signals such as throttle, steering and braking. The paper proposes an embedded friendly convolutional neural network, ‘Jacintonet’, to demonstrate self-driving using end to end learning paradigm in a virtual simulation environment. Paper discusses key learning during the training methodology and presents the results on embedded platform. Texas Instruments (TI) TDA2x System on Chip (SoC) is used as embedded platform for running ‘Jacintonet’, real-time to demonstrate self-driving car in the virtual simulator.",project-academic
10.1109/TMC.2020.3042925,2020-12-07,a,IEEE,online altitude control and scheduling policy for minimizing aoi in uav assisted iot wireless networks," This paper considers Unmanned Aerial Vehicle (UAV) assisted Internet of Things (IoT) networks, where low resource IoT devices periodically sample a stochastic process and need to upload more recent information to a Base Station (BS). Among the myriad of applications, there is a need for timely delivery of data (for example, status-updates) before the data becomes outdated and loses its value. Since transmission capabilities of IoT devices are limited, it may not always be feasible to transmit over one hop transmission to the BS. To address this challenge, UAVs with virtual queues are deployed as middle layer between IoT devices and the BS to relay recent information over unreliable channels. In the absence of channel conditions, the optimal online scheduling policy is investigated as well as dynamic UAV altitude control that maintains a fresh status of information at the BS. The objective of this paper is to minimize the Expected Weighted Sum Age of Information (EWSA) for IoT devices. First, the problem is formulated as an optimization problem that is however generally hard to solve. Second, an online model free Deep Reinforcement Learning (DRL) is proposed, where the deployed UAV obtains instantaneous channel state information (CSI) in real time along with any adjustment to its deployment altitude. Third, we formulate the online problem as a Markov Decision Process (MDP) and Proximal Policy Optimization (PPO) algorithm, which is a highly stable state-of-the-art DRL algorithm, is leveraged to solve the formulated problem. Finally, extensive simulations are conducted to verify findings and comprehensive comparisons with other baseline approaches are provided to demonstrate the effectiveness of the proposed design.",project-academic
10.22260/ISARC2009/0042,2009-06-27,p,IAARC-University of Texas at Austin,fpga based real time color tracking for robotic formation control," In construction automation, the tracking of worker location or a moving object is important for labor monitoring, resource management, and machine coordination. For object tracking, a camera is often utilized to obtain information of construction vehicle motion which can then be employed in coordination controls. Real-time tracking of autonomous vehicles, particularly for the control of multiple targets in formations, still suffers from constraints imposed in computation resources. Here the field programmable gate array (FPGA) technology is applied in a prototypical tracking system for vehicles by using a CMOS camera to detect their color-tags. The raw image from the Bayer color pattern is used to indicate the 2-dimensional position of vehicles and encrypted infrared commands are issued to deploy them in a leader-follower formation. It is shown that the novel system-on-programmable-chip with parallel control cores design can efficiently handle color recognition and multi-vehicle control while significantly reduces memory requirement and computation time. Introduction The digital camera has become a popular sensor for monitoring and surveillance systems. By improvement of the semiconductor technology, modern digital cameras with high pixel number can provide greater image detail in various applications. A digital image sensor usually utilizes an array consists of the charged-couple device (CCD) or complementary metal oxide semiconductor (CMOS). By passing light through the lens and color filter array (CFA), the real image is transformed into the mosaic-like RGB image projected on the digital image sensor array (Lukac and Plataniotis, 2007). The raw RGB image then is reconstructed as a meaningful image for human perception by de-mosaicking (Lee, 2005) and color correction (Gonzalez and Woods, 2002). For sensing applications, the additional image processing to extract object’s color strength or contour (Nixon and Aguado, 2008) is required for every image pixel. Moreover, it should be noted that imaging processing consumes a lot of memory space and most of computation resources in a computer system. The digital camera is also a popular sensor in a multi-robot system (Fierro et al., 2002) for obstacle detection and environment learning. Such a system is a very valuable tool in the development of an automated coordination system for construction vehicles. In a real-time object tracking and detection system, particularly for moving targets, the picture acquisition and image processing speed critically determines the system performance. Low computation speed will cause the loss of precise driving control for the multirobot system and results in collisions. When the robot system needs a high resolution camera to improve imaging details of the object, the coherent time delay with massive computation for image processing will occur. On the other hand, even the powerful microprocessor can mitigate time delay, the higher power consumption is also unsuitable for a mini robot system with battery powered operation (Braunl, 2006). Thus a compromise scheme for the multi-vehicle system in image processing issues is sharing the image processing and strategy making tasks in an external server (Fierro et al., 2002). Therefore, the vehicle carries only a simple embedded system which captures and sends image data to the server by wireless in order to get a balance between power consumption and execution speed. Based on the same idea, we propose a new colour-based tracking system for vehicle coordination using color-tag recognition for identification with an external server. This scheme will achieve higher performance of power management and real-time control speed. In our external se when runn propose u designed b of low pow designed e digital cam et al., 2000 burden in leader-foll The pa prediction resource u Some disc Processi Image in comput better cho prediction Bayer Patt The m The co the circled need to re define the G ⇔ B ⇔ where Color Pred In real reflection 26th Internatio design, each v rver by an en ing the whol se the Field P y using an FP er, low cost, xternal server era equipped ), and the dyn the FPGA ch owing strateg per is organiz , and noise fil sage, and the ussion of the ng of Raw I processing wi ation speed. T ice for lower and noise filt ern osaic-like RG",project-academic
,2018-08-30,a,,baidu apollo auto calibration system an industry level data driven and learning based vehicle longitude dynamic calibrating algorithm," For any autonomous driving vehicle, control module determines its road performance and safety, i.e. its precision and stability should stay within a carefully-designed range. Nonetheless, control algorithms require vehicle dynamics (such as longitudinal dynamics) as inputs, which, unfortunately, are obscure to calibrate in real time. As a result, to achieve reasonable performance, most, if not all, research-oriented autonomous vehicles do manual calibrations in a one-by-one fashion. Since manual calibration is not sustainable once entering into mass production stage for industrial purposes, we here introduce a machine-learning based auto-calibration system for autonomous driving vehicles. In this paper, we will show how we build a data-driven longitudinal calibration procedure using machine learning techniques. We first generated offline calibration tables from human driving data. The offline table serves as an initial guess for later uses and it only needs twenty-minutes data collection and process. We then used an online-learning algorithm to appropriately update the initial table (the offline table) based on real-time performance analysis. This longitudinal auto-calibration system has been deployed to more than one hundred Baidu Apollo self-driving vehicles (including hybrid family vehicles and electronic delivery-only vehicles) since April 2018. By August 27, 2018, it had been tested for more than two thousands hours, ten thousands kilometers (6,213 miles) and yet proven to be effective.",project-academic
10.1145/3349801.3349809,2019-11-14,a,,edgenet balancing accuracy and performance for edge based convolutional neural network object detectors," Visual intelligence at the edge is becoming a growing necessity for low latency applications and situations where real-time decision is vital. Object detection, the first step in visual data analytics, has enjoyed significant improvements in terms of state-of-the-art accuracy due to the emergence of Convolutional Neural Networks (CNNs) and Deep Learning. However, such complex paradigms intrude increasing computational demands and hence prevent their deployment on resource-constrained devices. In this work, we propose a hierarchical framework that enables to detect objects in high-resolution video frames, and maintain the accuracy of state-of-the-art CNN-based object detectors while outperforming existing works in terms of processing speed when targeting a low-power embedded processor using an intelligent data reduction mechanism. Moreover, a use-case for pedestrian detection from Unmanned-Areal-Vehicle (UAV) is presented showing the impact that the proposed approach has on sensitivity, average processing time and power consumption when is implemented on different platforms. Using the proposed selection process our framework manages to reduce the processed data by 100x leading to under 4W power consumption on different edge devices.",project-academic
10.1145/3278721.3278786,2018-12-27,p,ACM,overtrust of robots in high risk scenarios," From personal robot assistant to self-driving vehicles, artificial intelligence (AI) is the backbone underlying millions of future advanced applications. As robots become increasingly pervasive in daily life, it is expected that robots will augment human laborers in many domains in the near future. When robots are deployed in the real world, the underlying assumption is that they are capable of accomplishing their given tasks. However, researchers have shown that robots made mistakes, and in several cases, humans tend to overtrust robotic systems (Abney 2017; Borenstein et al. 2017; Robinette, Howard, and Wagner 2017). Overtrust of a robot happens in scenarios where (1) a person accepts risk because that person believes the robot can perform a function that it cannot or (2) the person accepts too much risk because the expectation is that the system will mitigate the risk."" (Abney 2017). In particular, we are interested in two emerging domains where an appropriate amount of trust is a minimal requirement and overtrust could cause harm: 1) healthcare scenarios and 2) self-driving car (i.e. autonomous driving) scenarios. Both healthcare and autonomous driving scenarios often involve high risks, and the negative outcomes could be detrimental to the user. The objective of our research focuses on 1) investigating the causes that contribute to human overtrust of these robots systems 2) developing a behavior-based computational model to predict overtrust, and 3) developing techniques to mitigate outcomes caused by the overtrust.",project-academic
,2020-05-15,a,,collective risk minimization via a bayesian model for statistical software testing," In the last four years, the number of distinct autonomous vehicles platforms deployed in the streets of California increased 6-fold, while the reported accidents increased 12-fold. This can become a trend with no signs of subsiding as it is fueled by a constant stream of innovations in hardware sensors and machine learning software. Meanwhile, if we expect the public and regulators to trust the autonomous vehicle platforms, we need to find better ways to solve the problem of adding technological complexity without increasing the risk of accidents. We studied this problem from the perspective of reliability engineering in which a given risk of an accident has severity and probability of occurring. Timely information on accidents is important for engineers to anticipate and reuse previous failures to approximate the risk of accidents in a new city. However, this is challenging in the context of autonomous vehicles because of the sparse nature of data on the operational scenarios (driving trajectories in a new city). Our approach was to mitigate data sparsity by reducing the state space through monitoring of multiple-vehicles operations. We then minimized the risk of accidents by determining proper allocation of tests for each equivalence class. Our contributions comprise (1) a set of strategies to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian model that estimates changes in the risk of accidents, and (3) a feedback control-loop that minimizes these risks by reallocating test effort. Our results are promising in the sense that we were able to measure and control risk for a diversity of changes in the operational scenarios. We evaluated our models with data from two real cities with distinct traffic patterns and made the data available for the community.",project-academic
10.1145/3387939.3388616,2020-06-29,p,ACM,collective risk minimization via a bayesian model for statistical software testing," In the last four years, the number of distinct autonomous vehicles platforms deployed in the streets of California increased 6-fold, while the reported accidents increased 12-fold. This can become a trend with no signs of subsiding as it is fueled by a constant stream of innovations in hardware sensors and machine learning software. Meanwhile, if we expect the public and regulators to trust the autonomous vehicle platforms, we need to find better ways to solve the problem of adding technological complexity without increasing the risk of accidents. We studied this problem from the perspective of reliability engineering in which a given risk of an accident has severity and probability of occurring. Timely information on accidents is important for engineers to anticipate and reuse previous failures to approximate the risk of accidents in a new city. However, this is challenging in the context of autonomous vehicles because of the sparse nature of data on the operational scenarios (driving trajectories in a new city). Our approach was to mitigate data sparsity by reducing the state space through monitoring of multiple-vehicles operations. We then minimized the risk of accidents by determining proper allocation of tests for each equivalence class. Our contributions comprise (1) a set of strategies to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian model that estimates changes in the risk of accidents, and (3) a feedback control-loop that minimizes these risks by real-locating test effort. Our results are promising in the sense that we were able to measure and control risk for a diversity of changes in the operational scenarios. We evaluated our models with data from two real cities with distinct traffic patterns and made the data available for the community.",project-academic
10.1109/ACCESS.2020.3046999,2021-01-01,a,IEEE,a framework for the synergistic integration of fully autonomous ground vehicles with smart city," Most of the vehicle manufacturers aim to deploy level-5 fully autonomous ground vehicles (FAGVs) on city roads in 2021 by leveraging extensive existing knowledge about sensors, actuators, telematics and Artificial Intelligence (AI) gained from the level-3 and level-4 autonomy. FAGVs by executing non-trivial sequences of events with decimetre-level accuracy live in Smart City (SC) and their integration with all the SC components and domains using real-time data analytics is urgent to establish better swarm intelligent systems and a safer and optimised harmonious smart environment enabling cooperative FAGVs-SC automation systems. The challenges of urbanisation, if unmet urgently, would entail severe economic and environmental impacts. The integration of FAGVs with SC helps improve the sustainability of a city and the functional and efficient deployment of hand over wheels on robotized city roads with behaviour coordination. SC can enable the exploitation of the full potential of FAGVs with embedded centralised systems within SC with highly distributed systems in a concept of Automation of Everything (AoE). This article proposes a synergistic integrated FAGV-SC holistic framework — FAGVinSCF in which all the components of SC and FAGVs involving recent and impending technological advancements are moulded to make the transformation from today’s driving society to future’s next-generation driverless society smoother and truly make self-driving technology a harmonious part of our cities with sustainable urban development. Based on FAGVinSCF, a simulation platform is built both to model the varying penetration levels of FAGV into mixed traffic and to perform the optimal self-driving behaviours of FAGV swarms. The results show that FAGVinSCF improves the urban traffic flow significantly without huge changes to the traffic infrastructure. With this framework, the concept of Cooperative Intelligent Transportation Systems (C-ITS) is transformed into the concept of Automated ITS (A-ITS). Cities currently designed for cars can turn into cities developed for citizens using FAGVinSCF enabling more sustainable cities.",project-academic
10.1109/AIPR50011.2020.9425341,2020-10-13,p,IEEE,enhancing network edge connectivity and computation security in drone video analytics," Unmanned Aerial Vehicle (UAV) systems with high-resolution video cameras are used for many operations such as aerial imaging, search and rescue, and precision agriculture. Multi-drone systems operating in Flying Ad Hoc Networks (FANETS) are inherently insecure and require efficient security schemes to defend against cyber-attacks such as e.g., Man-in-the-middle, Replay and Denial of Service attacks. In this paper, we propose a cloud-based, end-to-end security framework viz., ""DroneNet-Sec"" that provides secure network-edge connectivity, and computation security for drone video analytics to defend against common attack vectors in UAV systems. The DroneNet-Sec features a dynamic security scheme that uses machine learning to detect anomaly events and adopts countermeasures for computation security of containerized video analytics tasks. The security scheme comprises of a custom secure packet designed with MAVLink protocol for ensuring data privacy and integrity, without high degradation of the performance in a real-time FANET deployment. We evaluate DroneNet-Sec in a hybrid testbed that synergies simulation and emulation via an open-source network simulator (NS-3) and a research platform for mobile wireless networks (POWDER). Our performance evaluation experiments in our holistic hybrid-testbed show that DroneNet-Sec successfully detects learned anomaly events and effectively protects containerized tasks execution as well as communication in drones video analytics in a light-weight manner.",project-academic
10.1007/978-3-030-59897-6_11,2021-01-01,a,"Springer, Cham",internet of things and artificial intelligence enabled secure autonomous vehicles for smart cities," The ever-increasing count of vehicles wrecks several cities in the global scenario. Smart cities have evolved as a winning strategy that helps to cope up with this issue and overcome the urban problems such as pollution, traffic, waste management, optimization of energy consumption, and so on. Technologies such as machine learning (ML), Internet of Things (IoT), artificial intelligence (AI), big data analytics, cloud computing, and smart sensors serve as tools that provide enormous possibilities in the smart revolution. Several researchers are working on developing a complete system that performs information gathering, alternate identification, smart predictions, review of choices, decision-making, and taking suitable actions. These systems impose various challenges in terms of governance, economy, mobility, environment, people, and living. This chapter provides an in-depth analysis of these challenges in smart cities with respect to autonomous vehicles and also offers real-time solutions to overcome these challenges. A comparative analysis of the existing algorithms is done, and the optimal algorithms that can help in implementation of the system with a user-friendly approach and linguistic flexibility are proposed. Factors such as use of unmanned aerial vehicles (UAV), vehicle-to-vehicle and vehicle-to-infrastructure communication, deployment of location and path planning, data routing, dynamic coordination, data transmission, privacy, and cybersecurity are also considered while designing the system.",project-academic
,2018-03-13,a,,feature selective small object detection via knowledge based recurrent attentive neural network," At present, the performance of deep neural network in general object detection is comparable to or even surpasses that of human beings. However, due to the limitations of deep learning itself, the small proportion of feature pixels, and the occurence of blur and occlusion, the detection of small objects in complex scenes is still an open question. But we can not deny that real-time and accurate object detection is fundamental to automatic perception and subsequent perception-based decision-making and planning tasks of autonomous driving. 
Considering the characteristics of small objects in autonomous driving scene, we proposed a novel method named KB-RANN, which based on domain knowledge, intuitive experience and feature attentive selection. It can focus on particular parts of image features, and then it tries to stress the importance of these features and strengthenes the learning parameters of them. Our comparative experiments on KITTI and COCO datasets show that our proposed method can achieve considerable results both in speed and accuracy, and can improve the effect of small object detection through self-selection of important features and continuous enhancement of proposed method, and deployed it in our self-developed autonomous driving car.",project-academic
,2018-03-13,a,,knowledge based recurrent attentive neural network for small object detection," At present, the performance of deep neural network in general object detection is comparable to or even surpasses that of human beings. However, due to the limitations of deep learning itself, the small proportion of feature pixels, and the occurence of blur and occlusion, the detection of small objects in complex scenes is still an open question. But we can not deny that real-time and accurate object detection is fundamental to automatic perception and subsequent perception-based decision-making and planning tasks of autonomous driving. Considering the characteristics of small objects in autonomous driving scene, we proposed a novel method named KB-RANN, which based on domain knowledge, intuitive experience and feature attentive selection. It can focus on particular parts of image features, and then it tries to stress the importance of these features and strengthenes the learning parameters of them. Our comparative experiments on KITTI and COCO datasets show that our proposed method can achieve considerable results both in speed and accuracy, and can improve the effect of small object detection through self-selection of important features and continuous enhancement of proposed method, and deployed it in our self-developed autonomous driving car.",project-academic
,2020-07-28,,,long distance pipeline inspection method based on yolov3 pruning network and deep learning defogging model," The invention belongs to an image processing technology based on deep learning, and particularly relates to a long-distance pipeline inspection method based on a YOLOv3 pruning network and a deep learning defogging model. The method comprises the following steps: 1, constructing and training an AOD-Net defogging network model; 2, designing a YOLOv3 backbone network and a loss function; 3, performing image data acquisition and training on the target area in an unmanned aerial vehicle inspection mode; 4, performing compression and accelerated calculation on the YOLOv3 model through a scaling factor gamma pruning method based on a BN layer; 5, deploying the AOD-Net and YOLOv3 joint model to an embedded module of the unmanned aerial vehicle for target task detection; and 6, returning the inspection task detection result of the long-distance pipeline of the unmanned aerial vehicle to the background system in real time. The system is used for being deployed on an unmanned aerial vehicle embedded module to perform long-distance pipeline inspection work, and the labor cost is greatly reduced while high detection precision, good real-time performance and high efficiency are guaranteed.",project-academic
10.1002/AGJ2.20841,2021-09-01,a,"John Wiley & Sons, Ltd",potato crop stress identification in aerial images using deep learning based object detection," Recent research on the application of remote sensing and deep learning-based analysis in precision agriculture demonstrated a potential for improved crop management and reduced environmental impacts of agricultural production. Despite the promising results, the practical relevance of these technologies for actual field deployment requires novel algorithms that are customized for analysis of agricultural images and robust to implementation on natural field imagery. The paper presents an approach for analyzing aerial images of a potato crop using deep neural networks. The main objective is to demonstrate automated spatial recognition of a healthy versus stressed crop at a plant level. Specifically, we examine premature plant senescence resulting in drought stress on Russet Burbank potato plants. The proposed deep learning model, named Retina-UNet-Ag, is a variant of Retina-UNet (Jaeger et al., 2018) and includes connections from low-level semantic dense representation maps to the feature pyramid network. The paper also introduces a dataset of field images acquired with a Parrot Sequoia camera carried by a Solo unmanned aerial vehicle. Experimental validation demonstrated the ability for distinguishing healthy and stressed plants in field images, achieving an average Dice score coefficient of 0.74. A comparison to related state-of-the-art deep learning models for object detection revealed that the presented approach is effective for the task at hand. The method applied here is conducive toward the assessment and recognition of potato crop stress (early plant senescence resulting from drought stress in this case) in natural aerial field images collected under real conditions.",project-academic
,2021-06-14,a,,potato crop stress identification in aerial images using deep learning based object detection," Recent research on the application of remote sensing and deep learning-based analysis in precision agriculture demonstrated a potential for improved crop management and reduced environmental impacts of agricultural production. Despite the promising results, the practical relevance of these technologies for actual field deployment requires novel algorithms that are customized for analysis of agricultural images and robust to implementation on natural field imagery. The paper presents an approach for analyzing aerial images of a potato crop using deep neural networks. The main objective is to demonstrate automated spatial recognition of a healthy versus stressed crop at a plant level. Specifically, we examine premature plant senescence resulting in drought stress on Russet Burbank potato plants. The proposed deep learning model, named Retina-UNet-Ag, is a variant of Retina-UNet (Jaeger et al., 2018) and includes connections from low-level semantic dense representation maps to the feature pyramid network. The paper also introduces a dataset of field images acquired with a Parrot Sequoia camera carried by a Solo unmanned aerial vehicle. Experimental validation demonstrated the ability for distinguishing healthy and stressed plants in field images, achieving an average Dice score coefficient of 0.74. A comparison to related state-of-the-art deep learning models for object detection revealed that the presented approach is effective for the task at hand. The method applied here is conducive toward the assessment and recognition of potato crop stress (early plant senescence resulting from drought stress in this case) in natural aerial field images collected under real conditions.",project-academic
10.1109/TITS.2020.2980855,2021-03-01,a,IEEE,an efficient and scalable simulation model for autonomous vehicles with economical hardware," Autonomous vehicles rely on sophisticated hardware and software technologies for acquiring holistic awareness of their immediate surroundings. Deep learning methods have effectively equipped modern self-driving cars with high levels of such awareness. However, their application requires high-end computational hardware, which makes utilization infeasible for the legacy vehicles that constitute most of today’s automotive industry. Hence, it becomes inherently challenging to achieve high performance while at the same time maintaining adequate computational complexity. In this paper, a monocular vision and scalar sensor-based model car is designed and implemented to accomplish autonomous driving on a specified track by employing a lightweight deep learning model. It can identify various traffic signs based on a vision sensor as well as avoid obstacles by using an ultrasonic sensor. The developed car utilizes a single Raspberry Pi as its computational unit. In addition, our work investigates the behavior of economical hardware used to deploy deep learning models. In particular, we herein propose a novel, computationally efficient, and cost-effective approach. The designed system can serve as a platform to facilitate the development of economical technologies for autonomous vehicles that can be used as part of intelligent transportation or advanced driver assistance systems. The experimental results indicate that this model can achieve real-time response on a resource-constrained device without significant overheads, thus making it a suitable candidate for autonomous driving in current intelligent transportation systems.",project-academic
10.1109/ITSC.2019.8917085,2019-10-27,p,IEEE,machine learning method to ensure robust decision making of avs," Replacing the human driver to perform the Dynamic Driving Task (DDT)[1] will require perception, complex analysis and assessment of traffic situation. The path leading to success the deployment of fully Autonomous Vehicle (AV) depends on the resolution of a lot of challenges. Both the safety and the security aspects of AV constitute the core of regulatory compliance and technical research. The Autonomous Driving System (ADS) should be designed to ensure a safe manoeuvre and a stable behaviour despite the technological limitations, the uncertainties and hazards which characterize the real traffic conditions. In fully Autonomous Driving situation, detecting all relevant objects and agents should be sufficient to generate a warning, however the ADS requires further complex data analysis steps to quantify and improve the safety of decision making. This paper aims to improve the robustness of decision-making in order to mimic human-like decision ability. The approach is based on machine learning to identify the criticality of the dynamic situation and enabling ADS to make appropriate decision and fulfil safe manoeuvre.",project-academic
10.3390/ELECTRONICS9030518,2020-03-21,a,Multidisciplinary Digital Publishing Institute,automatic emotion recognition for the calibration of autonomous driving functions," The development of autonomous driving cars is a complex activity, which poses challenges about ethics, safety, cybersecurity, and social acceptance. The latter, in particular, poses new problems since passengers are used to manually driven vehicles; hence, they need to move their trust from a person to a computer. To smooth the transition towards autonomous vehicles, a delicate calibration of the driving functions should be performed, making the automation decision closest to the passengers’ expectations. The complexity of this calibration lies in the presence of a person in the loop: different settings of a given algorithm should be evaluated by assessing the human reaction to the vehicle decisions. With this work, we for an objective method to classify the people’s reaction to vehicle decisions. By adopting machine learning techniques, it is possible to analyze the passengers’ emotions while driving with alternative vehicle calibrations. Through the analysis of these emotions, it is possible to obtain an objective metric about the comfort feeling of the passengers. As a result, we developed a proof-of-concept implementation of a simple, yet effective, emotions recognition system. It can be deployed either into real vehicles or simulators, during the driving functions calibration.",project-academic
,2018-04-17,a,,training a binary weight object detector by knowledge transfer for autonomous driving," Autonomous driving has harsh requirements of small model size and energy efficiency, in order to enable the embedded system to achieve real-time on-board object detection. Recent deep convolutional neural network based object detectors have achieved state-of-the-art accuracy. However, such models are trained with numerous parameters and their high computational costs and large storage prohibit the deployment to memory and computation resource limited systems. Low-precision neural networks are popular techniques for reducing the computation requirements and memory footprint. Among them, binary weight neural network (BWN) is the extreme case which quantizes the float-point into just $1$ bit. BWNs are difficult to train and suffer from accuracy deprecation due to the extreme low-bit representation. To address this problem, we propose a knowledge transfer (KT) method to aid the training of BWN using a full-precision teacher network. We built DarkNet- and MobileNet-based binary weight YOLO-v2 detectors and conduct experiments on KITTI benchmark for car, pedestrian and cyclist detection. The experimental results show that the proposed method maintains high detection accuracy while reducing the model size of DarkNet-YOLO from 257 MB to 8.8 MB and MobileNet-YOLO from 193 MB to 7.9 MB.",project-academic
10.1109/JSEN.2020.3003312,2020-11-01,a,Institute of Electrical and Electronics Engineers (IEEE),monitoring of occupant states in autonomous vehicles using capacitance sensing imaging," The increasing popularity of autonomous vehicles has heightened the need to deploy robust systems that guarantee the safety and comfort of vehicle occupants. Such systems are required to monitor the presence and posture of occupants in real-time. This paper proposes a novel system that combines capacitive sensing with machine learning to achieve real-time occupant detection and posture recognition. The main constituent of the system is a capacitance-sensing mat that spans both the seat base (SB) and the backrest (BR) of a typical vehicle seat. The mat is connected to a sensing circuitry that continuously monitors variations in capacitance inside the mat to generate grayscale capacitance-sensing images (CSIs). The CSIs are real-time pictorial representations of the variations in capacitance caused within the mat due to changes in the position and the posture of occupants. The real-time CSIs then serve as inputs to a k-nearest-neighbors-based (k-NN) classifier that is capable of identifying different posture classes. The classifier is pre-trained using a previously acquired database consisting of a collection of CSIs belonging to known posture classes. Subsequently, the performance of the classifier is validated, and the system is deployed for real-time occupant detection and posture recognition.",project-academic
10.1109/IVS.1994.639471,1994-10-24,p,IEEE,the development of a fully autonomous ground vehicle fagv," As a first step toward the creation of a fully autonomous vehicle that operates in a real world environment, we are currently developing a prototype autonomous ground vehicle (AGV) for use in factories and other industrial/business sites based on behavior-based artificial intelligence (AI) control. This flexible and fully autonomous AGV (FAGV) is expected to operate efficiently in a normal industrial environment without any external guidance. The crucial technique employed is a non-Cartesian way of organizing software agents for the creation of a highly responsive control program. The resulting software is considerably reduced in size. Through numerous experiments using mobile robots we confirmed that these new control programs excel in functionality, efficiency, flexibility and robustness. The second key technique in the planning stage is evolutionary computation, of which genetic algorithms are a principal technique. An online, real-time evolution of the control program will be incorporated in later phases of the project to make FAGVs adaptable to any given operational environment after deployment. The first prototype FAGV has an active vision and behaviour-based control system.",project-academic
10.1007/S11045-020-00736-X,2021-01-01,a,Springer US,clmip cross layer manifold invariance based pruning method of deep convolutional neural network for real time road type recognition," Recently, deep learning based models have demonstrated the superiority in a variety of visual tasks like object detection and instance segmentation. In practical applications, deploying advanced networks into real-time applications such as autonomous driving is still challenging due to expensive computational cost and memory footprint. In this paper, to reduce the size of deep convolutional neural network (CNN) and accelerate its reasoning, we propose a cross-layer manifold invariance based pruning method named CLMIP for network compression to help it complete real-time road type recognition in low-cost vision system. Manifolds are higher-dimensional analogues of curves and surfaces, which can be self-organized to reflect the data distribution and characterize the relationship between data. Therefore, we hope to guarantee the generalization ability of deep CNN by maintaining the consistency of the data manifolds of each layer in the network, and then remove the parameters with less influence on the manifold structure. Therefore, CLMIP can be regarded as a tool to further investigate the dependence of model structure on network optimization and generalization. To the best of our knowledge, this is the first time to prune deep CNN based on the invariance of data manifolds. During experimental process, we use the python based keyword crawler program to collect 102 first-view videos of car cameras, including 137 200 images (320 × 240) of four road scenes (urban road, off-road, trunk road and motorway). Finally, the classification results have demonstrated that CLMIP can achieve state-of-the-art performance with a speed of 26 FPS on NVIDIA Jetson Nano.",project-academic
,2016-01-01,a,,predictive control under uncertainty for safe autonomous driving integrating data driven forecasts with control design," Self-driving vehicles have attracted a lot of interest due to their potential to significantly reduce traffic fatalities and transform people's lives. The reducing costs of advanced sensing technologies and the increasing capabilities of embedded computing hardware have enabled the commercialization of highly automated driving features. However, the reliable operation of autonomous vehicles is still a challenge and a major barrier in the large scale acceptance and deployment of the technology.This dissertation focuses on the challenges of designing safe control strategies for self-driving vehicles due to the presence of uncertainty arising from the non-deterministic forecasts of the driving scene. The overall goal is to unify elements from the fields of vehicle dynamics modeling, machine learning, real-time optimization and control design under uncertainty to enable the safe operation of self-driving vehicles. We propose a systematic framework based on Model Predictive Control (MPC) for the controller design, the effectiveness of which is demonstrated via applications such as lateral stability control, autonomous cruise control and autonomous overtaking on highways. Data collected from our experimental vehicles is used to build predictive models of the vehicle and the environment, and characterize the uncertainty therein. Several approaches for the control design are presented based on a worst-case or probabilistic view of the uncertain forecasts, depending on the application. The proposed control methodologies are validated by experiments performed on prototype passenger vehicles and are executed in real-time on embedded hardware with limited computational power. The experiments show the ability of the proposed framework to handle a variety of driving scenarios including aggressive maneuvers on low-friction surfaces such as snow and navigation in the presence of multiple vehicles.",project-academic
,2020-06-19,,,efficient terminal distribution method applying automatic following robot and internet of things system," The invention provides an efficient tail-end distribution method applying an automatic following robot and an Internet of Things system for industries such as express delivery. According to the method, an automatic following robot is required to be deployed in a tail-end distribution scene; compatibility upgrading is carried out on a cargo tracking system of a user, Internet of Things upgrading iscarried out on elevators, entrance guards and other devices in a tail-end distribution scene, and the tail-end distribution efficiency is improved through the steps of contact before arrival of cargoes, contact before distribution, distribution path planning, automatic following delivery, real-time distribution monitoring and the like. According to the method, existing mature technologies such asautomatic following, the Internet of Things and an artificial intelligence voice robot are effectively utilized, and a novel distribution method is provided. Compared with traditional manual distribution and low-efficiency unmanned vehicle distribution, beneficial man-machine function complementation is achieved. After the method provided by the invention is implemented, the automation and informatization of terminal distribution scenes such as residential areas and the like can be remarkably improved, the distribution success rate in unit time is improved, the burden of courier is reduced, and the cost of terminal distribution is reduced.",project-academic
10.3390/APP11072925,2021-03-25,a,MDPI AG,object detection distributed cloud computing and parallelization techniques for autonomous driving systems," Autonomous vehicles are increasingly becoming a necessary trend towards building the smart cities of the future. Numerous proposals have been presented in recent years to tackle particular aspects of the working pipeline towards creating a functional end-to-end system, such as object detection, tracking, path planning, sentiment or intent detection, amongst others. Nevertheless, few efforts have been made to systematically compile all of these systems into a single proposal that also considers the real challenges these systems will have on the road, such as real-time computation, hardware capabilities, etc. This paper reviews the latest techniques towards creating our own end-to-end autonomous vehicle system, considering the state-of-the-art methods on object detection, and the possible incorporation of distributed systems and parallelization to deploy these methods. Our findings show that while techniques such as convolutional neural networks, recurrent neural networks, and long short-term memory can effectively handle the initial detection and path planning tasks, more efforts are required to implement cloud computing to reduce the computational time that these methods demand. Additionally, we have mapped different strategies to handle the parallelization task, both within and between the networks.",project-academic
10.3390/S21134618,2021-07-05,a,Multidisciplinary Digital Publishing Institute,machine learning for the dynamic positioning of uavs for extended connectivity," Unmanned Aerial Vehicle (UAV) networks are an emerging technology, useful not only for the military, but also for public and civil purposes. Their versatility provides advantages in situations where an existing network cannot support all requirements of its users, either because of an exceptionally big number of users, or because of the failure of one or more ground base stations. Networks of UAVs can reinforce these cellular networks where needed, redirecting the traffic to available ground stations. Using machine learning algorithms to predict overloaded traffic areas, we propose a UAV positioning algorithm responsible for determining suitable positions for the UAVs, with the objective of a more balanced redistribution of traffic, to avoid saturated base stations and decrease the number of users without a connection. The tests performed with real data of user connections through base stations show that, in less restrictive network conditions, the algorithm to dynamically place the UAVs performs significantly better than in more restrictive conditions, reducing significantly the number of users without a connection. We also conclude that the accuracy of the prediction is a very important factor, not only in the reduction of users without a connection, but also on the number of UAVs deployed.",project-academic
10.3390/RS13183777,2021-09-20,a,Multidisciplinary Digital Publishing Institute,mapping canopy heights in dense tropical forests using low cost uav derived photogrammetric point clouds and machine learning approaches," Tropical forests are a key component of the global carbon cycle and climate change mitigation. Field- or LiDAR-based approaches enable reliable measurements of the structure and above-ground biomass (AGB) of tropical forests. Data derived from digital aerial photogrammetry (DAP) on the unmanned aerial vehicle (UAV) platform offer several advantages over field- and LiDAR-based approaches in terms of scale and efficiency, and DAP has been presented as a viable and economical alternative in boreal or deciduous forests. However, detecting with DAP the ground in dense tropical forests, which is required for the estimation of canopy height, is currently considered highly challenging. To address this issue, we present a generally applicable method that is based on machine learning methods to identify the forest floor in DAP-derived point clouds of dense tropical forests. We capitalize on the DAP-derived high-resolution vertical forest structure to inform ground detection. We conducted UAV-DAP surveys combined with field inventories in the tropical forest of the Congo Basin. Using airborne LiDAR (ALS) for ground truthing, we present a canopy height model (CHM) generation workflow that constitutes the detection, classification and interpolation of ground points using a combination of local minima filters, supervised machine learning algorithms and TIN densification for classifying ground points using spectral and geometrical features from the UAV-based 3D data. We demonstrate that our DAP-based method provides estimates of tree heights that are identical to LiDAR-based approaches (conservatively estimated NSE = 0.88, RMSE = 1.6 m). An external validation shows that our method is capable of providing accurate and precise estimates of tree heights and AGB in dense tropical forests (DAP vs. field inventories of old forest: r2 = 0.913, RMSE = 31.93 Mg ha−1). Overall, this study demonstrates that the application of cheap and easily deployable UAV-DAP platforms can be deployed without expert knowledge to generate biophysical information and advance the study and monitoring of dense tropical forests.",project-academic
10.1109/IBCAST.2013.6512147,2013-05-02,p,IEEE,an artificial intelligence based novel approach for real time allocation of armament to hostile targets," For some specified targets, it is desired to identify the optimal configuration for the assignment of weapons for a given deployment of different types of weapon systems along with their required quantity in order to achieve a desired level of damage subject to the minimal cost and mission specific constraints. This problem, in its essence, is an NP-complete combinatorial optimization problem in the area of command and control research. In defense-related applications of artificial intelligence, this problem is referred as Weapon Target Assignment (WTA) problem. The problem can be formulated as a non-linear integer programming problem for which no exact methods exist to solve even the small size instances. Our focus is on the Dynamic Weapon Target Assignment (DWTA) problem. A discrete-event system simulation model is developed taking into account the resource constraints, resource capability constraints, strategy constraints and engagement feasibility constraints. Three different methods are employed; MMR, Reactive Tabu Search and a newly proposed artificial intelligence based simulation-optimization hybrid framework. A set of rules is generated based on the optimization module that is then employed for real-time control. The computational results show very promising prospects of the proposed approach, not only for DWTA but also for any real-time decision-making problem like Cooperative Unmanned Air Vehicle Mission Assignment etc.",project-academic
10.1007/S10846-021-01441-Y,2021-09-01,a,Springer Netherlands,al tune a family of methods to effectively tune uav controllers in in flight conditions," In the paper, a family of novel real-time tuning methods for an unmanned aerial vehicle (UAV) altitude controller in in-flight conditions. The methods allow the controller’s gains to be adapted only on the basis of measurements from a basic sensory equipment and by constructing the optimization cost function in an on-line fashion with virtually no impeding computational complexity; in the case of the altitude controller as in this paper for a hexacopter, altitude measurements were used only. The methods are not dependent on the measurement level, and present the approach in a generally applicable form to tuning arbitrary controllers with low number of parameters. Real-world experimental flights, preceded by simulation tests, have shown which method should behave best in a noisy environment when e.g. wind disturbances act on a UAV while it is in autonomous flight. As the methods can potentially be extended to other control loops or controller types, making this a versatile, rapid-tuning tool. It has been shown that a well-tuned controller using the proposed AL-TUNE scheme outperforms controllers that are tuned just to stabilize the system. AL-TUNE provides a new way of using UAVs in terms of adaptivity to changing their dynamic properties and can be deployed rapidly. This enables new applications and extends the usability of fully autonomous UAVs, unlike other tuning methods, which basically require the availability of a UAV model. The core difference with respect to other research from the field is that other authors either use a model of a UAV to optimize the gains analytically or use machine learning techniques, what increases time consumption, whereas the presented methods offer a rapid way to tune controllers, in a reliable way, with deterministic time requirements.",project-academic
,1992-03-01,a,"Monterey, California. Naval Postgraduate School",nps auv integrated simulator," Abstract : The development and testing of Autonomous Underwater Vehicle (AUV) hardware and software is greatly complicated by vehicle inaccessibility during operation. Integrated simulation remotely links vehicle components and support equipment with graphics simulation workstations, allowing complete real-time, pre-mission, pseudo-mission and post-mission visualization and analysis in the lab environment. Integrated simulator testing of software and hardware is a broad and versatile method that supports rapid and robust diagnosis and correction of system faults. This method is demonstrated using the Naval Postgraduate School (NPS) AUV. High-resolution three-dimensional graphics workstations can provide real-time representations of vehicle dynamics, control system behavior, mission execution, sensor processing and object classification. Integrated simulation is also useful for development of the variety of sophisticated artificial intelligence applications needed by an AUV. Examples include sonar classification using an expert system and path planning using a circle world model. The flexibility and versatility provided by this approach enables visualization and analysis of all aspects of AUV development. Integrated simulator networking is recommended as a fundamental requirement for AUV research and deployment. Autonomous underwater vehicles, Graphics, Simulation, Path planning, Sonar classification, Expert systems, Real-Time operating systems.",project-academic
10.2514/6.2005-6437,2005-01-01,p,American Institute of Aeronautics and Astronautics,entry abort determination using non adaptive neural networks for mars precision landers," The 2009 Mars Science Laboratory (MSL) will attempt the first precision landing on Mars using a modified version of the Apollo Earth entry guidance program. The guidance routine, Entry Terminal Point Controller (ETPC), commands the deployment of a supersonic parachute after converging the range to the landing target. For very dispersed cases, ETPC may not converge the range to the target and safely command parachute deployment within Mach number and dynamic pressure constraints. A full-lift up abort can save 85% of these failed trajectories while abandoning the precision landing objective. Though current MSL requirements do not call for an abort capability, an autonomous abort capability may be desired, for this mission or future Mars precision landers, to make the vehicle more robust. The application of artificial neural networks (NNs) as an abort determination technique was evaluated by personnel at the National Aeronautics and Space Administration (NASA) Johnson Space Center (JSC). In order to implement an abort, a failed trajectory needs to be recognized in real time. Abort determination is dependent upon several trajectory parameters whose relationships to vehicle survival are not well understood, and yet the lander must be trained to recognize unsafe situations. Artificial neural networks (NNs) provide a way to model these parameters and can provide MSL with the artificial intelligence necessary to independently declare an abort. Using the 2009 Mars Science Laboratory (MSL) mission as a case study, a non-adaptive NN was designed, trained and tested using Monte Carlo simulations of MSL descent and incorporated into ETPC. Neural network theory, the development history of the MSL NN, and initial testing with severe dust storm entry trajectory cases are discussed in Reference 1 and will not be repeated here. That analysis demonstrated that NNs are capable of recognizing failed descent trajectories and can significantly increase the survivability of MSL for very dispersed cases. NN testing was then broadened to evaluate fully dispersed entry trajectories. The NN correctly classified 99.7% of descent trajectories as abort or nonabort and reduced the probability of an unsafe parachute deployment by 83%. This second, broader testing phase is discussed in this paper.",project-academic
,2020-01-01,a,,autonomous driving vehicle control auto calibration system an industry level data driven and learning based vehicle longitudinal dynamic calibrating algorithm," The control module is a crucial part for autonomous driving systems, a typical control algorithm often requires vehicle dynamics (such as longitudinal dynamics) as inputs, which, unfortunately are difficult to calibrate in real time. Further, it is also a challenge to reflect instantaneous changes in longitudinal dynamics (e.g. load changes) using a calibration table. As a result, control performance may deteriorate when load changes considerably (especially for small cargoes). In this paper, we will show how we build a data-driven longitudinal calibration procedure using machine learning techniques to adapt load changes in real time. We first generated offline calibration tables from human driving data. The offline table serves as an initial guess for later uses, and it only requires twenty minutes of data collection and processing. We then used an online learning algorithm to appropriately update the initial table (the offline table) based on real-time performance analysis. Experiments indicated (a) offline auto-calibration leads to a better control accuracy, compared with manual calibration; (b) online auto-calibration is capable to handle load changes and significantly reduce real time control error. This system has been deployed to more than one hundred Baidu self-driving vehicles (both hybrid and electronic vehicles) since April 2018. By January 2019, the system had been tested for more than 2,000 hours and over 10,000 kilometers (6,213 miles) and was still proven to be effective.",project-academic
10.1109/IV47402.2020.9304778,2020-10-19,p,IEEE,autonomous driving vehicle control auto calibration system an industry level data driven and learning based vehicle longitudinal dynamic calibrating algorithm," The control module is a crucial part for autonomous driving systems, a typical control algorithm often requires vehicle dynamics (such as longitudinal dynamics) as inputs, which, unfortunately are difficult to calibrate in real time. Further, it is also a challenge to reflect instantaneous changes in longitudinal dynamics (e.g. load changes) using a calibration table. As a result, control performance may deteriorate when load changes considerably (especially for small cargoes). In this paper, we will show how we build a data-driven longitudinal calibration procedure using machine learning techniques to adapt load changes in real time. We first generated offline calibration tables from human driving data. The offline table serves as an initial guess for later uses, and it only requires twenty minutes of data collection and processing. We then used an online learning algorithm to appropriately update the initial table (the offline table) based on real-time performance analysis. Experiments indicated (a) offline auto-calibration leads to a better control accuracy, compared with manual calibration; (b) online auto-calibration is capable to handle load changes and significantly reduce real time control error. This system has been deployed to more than one hundred Baidu self-driving vehicles (both hybrid and electronic vehicles) since April 2018. By January 2019, the system had been tested for more than 2,000 hours and over 10,000 kilometers (6,213 miles) and was still proven to be effective.",project-academic
10.1109/CVPRW53098.2021.00022,2021-06-01,p,IEEE,simulation driven design and test for safety of ai based autonomous vehicles," An autonomous vehicle (AV) integrates sophisticated perception and localization components to create a model of the world around it, which is then used to navigate the vehicle safely. Machine learning (ML) based models are pervasively used in these components to extract object information from noisy sensor data. The requirements for these components are primarily set to achieve as high accuracy as possible. With modern AVs deploying many sensors (cameras, radars, and LiDARs), processing all the data in real-time leads to engineers making trade-offs which might result in a sub-optimal system in certain driving situations. Due to the lack of precise requirements on individual components, modular testing and validation also becomes challenging. In this paper, we formulate the problem of deriving abstract world model accuracy needed for safe AV behavior from top level driving scenario simulations. This is computationally expensive as the world model can contain many objects with several attributes and an AV extracts a world model every time-step during the simulation. We describe approaches to efficiently address the problem and derive component-level requirements and tests.",project-academic
10.1016/J.ESWA.2021.114937,2021-09-15,a,Pergamon,search and rescue operation using uavs a case study," Abstract None None Many people go missing in the wild every year. In this paper, the Search and Rescue (SAR) mission is conducted using a novel system comprising an Unmanned Aerial Vehicle (UAV) coupled with real-time machine-learning-based object detection system embedded on a smartphone. Human detection from UAV in the wilderness is a challenging task, because of many constraints involved such as lack of computing and communication infrastructures. We proposed a novel combination of a robust architecture deployed on a smartphone and a novel Convolutional Neural Network (CNN) model to fulfil the goals of the project. Our approach achieved 94.73% of accuracy and 6.8 FPS on a smartphone. Our approach is highly portable, cost-effective, fast with high accuracy. This novel system is expected to contribute significantly to maximise chances of saving lives in the wild. This developed system has been recently launched by Police Scotland to facilitate the SAR teams to locate missing persons in Scotland wilderness.",project-academic
10.2139/SSRN.2602160,2015-05-04,a,,autonomy of military robots assessing the technical and legal jus in bello thresholds," While robots are still absent from our homes, they have started to spread over battlefields. However, the military robots of today are mostly remotely controlled platforms, with no real autonomy. This paper will disclose the obstacles in implementing autonomy for such systems, by answering a technical question: “What level of autonomy is needed in military robots and how and when might it be achieved?”, followed by a techno-legal one; “How to implement the rules of humanitarian law within autonomous fighting robots, in order to allow their legal deployment?”The first chapter scrutinizes the significance of autonomy in robots and the metrics used to quantify it, which were developed by the US Department of Defense.The second chapter focuses on the autonomy of ‘state-of-the-art’ robots (e.g.; Google’s self-driving car, DARPA’s projects, etc) for navigation, ISR or lethal missions. Based on public information, we will get a hint of the architectures, the functioning, the thresholds and technical limitations of such systems. The bottleneck to a higher autonomy of robots seems to be their poor ‘perceptive intelligence’. The last chapter looks to the requirements of humanitarian law (rules of ‘jus in bello’/rules of engagement) to the legal deployment of autonomous lethal robots on the battlefields. The legal and moral reasoning of human soldiers, complying with humanitarian law, is a complex cognitive process which must be emulated by autonomous robots that could make lethal decisions. However, autonomous completion of such ‘moral’ tasks by artificial agents is much more challenging than the autonomous implementation of other tasks, such as navigation, ISR or kinetic attacks. Given the limits of current Artificial Intelligence, it is highly unlikely that robots will acquire such 'moral' capabilities anytime soon. Therefore, for the time being, the autonomous weapon systems might be legally deployed, but only in very particular circumstances, where the requirements of humanitarian law happen to be irrelevant.",project-academic
10.1016/J.TRENG.2021.100068,2021-06-01,a,Elsevier BV,real time traffic quantization using a mini edge artificial intelligence platform," Abstract None None Traffic analysis is dependent on reliable and accurate datasets that quantify the vehicle composition, speed and traffic density over a long period of time. The utilisation of big data is required if equitable and efficient transportation networks are to be realised for smart, interconnected cities of the future. The rapid and widespread adoption of digital twins, IoT (Internet of Things), artificial intelligence and mini edge computing technologies serve as the catalyst to rapidly develop and deploy smart systems for real-time data acquisition of traffic in and around urban and metropolitan areas. This paper presents a proof of concept of a mini edge computing platform for real-time edge processing, which serves as a digital twin of a multi-lane freeway located in Pretoria, South Africa. Video data acquired from an Unmanned Aerial Vehicle (UAV) is processed using a neural network architecture designed for real-time object detection tracking of vehicles. The implementation successfully counted vehicles (cars and trucks) together with an estimation of the speed of each detected vehicle. These results compare favourably to the ground truth data with vehicle counting accuracies of 5% realised. Detection of sparse motorcycles and pedestrians were less than optimal. This proof of concept can be easily scaled and deployed over a wide geographic area. Integration of these cyber-physical assets can be incorporated into existing video monitoring systems or fused with optical sensors as a single data acquisition system.",project-academic
10.1109/ISQED.2018.8357325,2018-03-13,p,IEEE,low cost and power cnn deep learning solution for automated driving," Automated driving functions, like highway driving and parking assist, are increasingly getting deployed in high-end cars with the ultimate goal of realizing self-driving car using Deep learning techniques like convolution neural network (CNN). For mass-market deployment, the embedded solution is required to address the right cost and performance envelope along with security and safety. In the case of automated driving, one of the key functionality is “finding drivable free space”, which is addressed using deep learning techniques like CNN. These CNN networks pose huge computing requirements in terms of hundreds of GOPS/TOPS (Giga or Tera operations per second), which seems beyond the capability of today's embedded SoC. This paper covers various techniques consisting of fixed-point conversion, sparse multiplication, fusing of layers and network pruning, for tailoring on the embedded solution. These techniques are implemented on the device by means of optimized Deep learning library for inference. The paper concludes by demonstrating the results of a CNN network running in real time on TI's TDA2X embedded platform producing a high-quality drivable space output for automated driving.",project-academic
,2021-09-23,a,,learning based path planning for long range autonomous valet parking," In this paper, to reduce the congestion rate at the city center and increase the quality of experience (QoE) of each user, the framework of long-range autonomous valet parking (LAVP) is presented, where an Electric Autonomous Vehicle (EAV) is deployed in the city, which can pick up, drop off users at their required spots, and then drive to the car park out of city center autonomously. In this framework, we aim to minimize the overall distance of the EAV, while guarantee all users are served, i.e., picking up, and dropping off users at their required spots through optimizing the path planning of the EAV and number of serving time slots. To this end, we first propose a learning based algorithm, which is named as Double-Layer Ant Colony Optimization (DL-ACO) algorithm to solve the above problem in an iterative way. Then, to make the real-time decision, while consider the dynamic environment (i.e., the EAV may pick up and drop off users from different locations), we further present a deep reinforcement learning (DRL) based algorithm, which is known as deep Q network (DQN). The experimental results show that the DL-ACO and DQN-based algorithms both achieve the considerable performance.",project-academic
10.1007/S10514-020-09922-Z,2020-07-01,a,Springer US,exploration of the applicability of probabilistic inference for learning control in underactuated autonomous underwater vehicles," Underwater vehicles are employed in the exploration of dynamic environments where tuning of a specific controller for each task would be time-consuming and unreliable as the controller depends on calculated mathematical coefficients in idealised conditions. For such a case, learning task from experience can be a useful alternative. This paper explores the capability of probabilistic inference learning to control autonomous underwater vehicles that can be used for different tasks without re-programming the controller. Probabilistic inference learning uses a Gaussian process model of the real vehicle to learn the correct policy with a small number of real field experiments. The use of probabilistic reinforcement learning looks for a simple implementation of controllers without the burden of coefficients calculation, controller tuning or system identification. A series of computational simulations were employed to test the applicability of model-based reinforcement learning in underwater vehicles. Three simulation scenarios were evaluated: waypoint tracking, depth control and 3D path tracking control. The 3D path tracking is done by coupling together a line-of-sight law with probabilistic inference for learning control. As a comparison study LOS-PILCO algorithm can perform better than a robust LOS-PID. The results show that probabilistic model-based reinforcement learning can be a deployable solution to motion control of underactuated AUVs as it can generate capable policies with minimum quantity of episodes.",project-academic
10.3390/COMPUTATION9020012,2021-01-29,a,Multidisciplinary Digital Publishing Institute,the inus platform a modular solution for object detection and tracking from uavs and terrestrial surveillance assets," Situational awareness is a critical aspect of the decision-making process in emergency response and civil protection and requires the availability of up-to-date information on the current situation. In this context, the related research should not only encompass developing innovative single solutions for (real-time) data collection, but also on the aspect of transforming data into information so that the latter can be considered as a basis for action and decision making. Unmanned systems (UxV) as data acquisition platforms and autonomous or semi-autonomous measurement instruments have become attractive for many applications in emergency operations. This paper proposes a multipurpose situational awareness platform by exploiting advanced on-board processing capabilities and efficient computer vision, image processing, and machine learning techniques. The main pillars of the proposed platform are: (1) a modular architecture that exploits unmanned aerial vehicle (UAV) and terrestrial assets; (2) deployment of on-board data capturing and processing; (3) provision of geolocalized object detection and tracking events; and (4) a user-friendly operational interface for standalone deployment and seamless integration with external systems. Experimental results are provided using RGB and thermal video datasets and applying novel object detection and tracking algorithms. The results show the utility and the potential of the proposed platform, and future directions for extension and optimization are presented.",project-academic
10.1109/ICAIIC48513.2020.9065203,2020-02-20,p,IEEE,uav assisted real time data processing using deep q network for industrial internet of things," Industrial internet of things (IIoT) enables edge computing technology to provide communication between the machines that produce a large amount of data and locate at the edge network. A task scheduling is implemented in the edge node. Furthermore, the real-time data can achieve with the lowest latency that allowed by the edge node near the edge network. However, a mobile machine such as an autonomous guided vehicle can interfere in this situation. Because the vehicle also needs service by the edge node. Over that, quality of service (QoS) performance can decrease. Therefore, this paper deploys an unmanned aerial vehicle (UAV) as an edge node to provide service to the edge network through optimizing the trajectory of UAV, where the edge network request task using a Deep Q-Network (DQN) Learning. The result shows that using machine learning, notably the DQN algorithm, can increase the number of the machine that can be provided service. Subsequently, the real-time data can achieve either the interrupt occurs at the edge node.",project-academic
,2020-01-01,a,University of Glasgow,cognitive networking for next generation of cellular communication systems," This thesis presents a comprehensive study of cognitive networking for cellular networks with contributions that enable them to be more dynamic, agile, and efficient. To achieve this, machine learning (ML) algorithms, a subset of artificial intelligence, are employed to bring such cognition to cellular networks. More specifically, three major branches of ML, namely supervised, unsupervised, and reinforcement learning (RL), are utilised for various purposes: unsupervised learning is used for data clustering, while supervised learning is employed for predictions on future behaviours of networks/users. RL, on the other hand, is utilised for optimisation purposes due to its inherent characteristics of adaptability and requiring minimal knowledge of the environment.

Energy optimisation, capacity enhancement, and spectrum access are identified as primary design challenges for cellular networks given that they are envisioned to play crucial roles for 5G and beyond due to the increased demand in the number of connected devices as well as data rates. Each design challenge and its corresponding proposed solution are discussed thoroughly in separate chapters.

Regarding energy optimisation, a user-side energy consumption is investigated by considering Internet of things (IoT) networks. An RL based intelligent model, which jointly optimises the wireless connection type and data processing entity, is proposed. In particular, a Q-learning algorithm is developed, through which the energy consumption of an IoT device is minimised while keeping the requirement of the applications--in terms of response time and security--satisfied. The proposed methodology manages to result in 0% normalised joint cost--where all the considered metrics are combined--while the benchmarks performed 54.84% on average. Next, the energy consumption of radio access networks (RANs) is targeted, and a traffic-aware cell switching algorithm is designed to reduce the energy consumption of a RAN without compromising on the user quality-of-service (QoS). The proposed technique employs a SARSA algorithm with value function approximation, since the conventional RL methods struggle with solving problems with huge state spaces. The results reveal that up to 52% gain on the total energy consumption is achieved with the proposed technique, and the gain is observed to reduce when the scenario becomes more realistic.

On the other hand, capacity enhancement is studied from two different perspectives, namely mobility management and None unmanned aerial vehicle (UAV) assistance.
Towards that end, a predictive handover (HO) mechanism is designed for mobility management in cellular networks by identifying two major issues of Markov chains based HO predictions. First, revisits--which are defined as a situation whereby a user visits the same cell more than once within the same day--are diagnosed as causing similar transition probabilities, which in turn increases the likelihood of making incorrect predictions. This problem is addressed with a structural change; i.e., rather than storing 2-D transition matrix, it is proposed to store 3-D one that also includes HO orders. The obtained results show that 3-D transition matrix is capable of reducing the HO signalling cost by up to 25.37%, which is observed to drop with increasing randomness level in the data set. Second, making a HO prediction with insufficient criteria is identified as another issue with the conventional Markov chains based predictors. Thus, a prediction confidence level is derived, such that there should be a lower bound to perform HO predictions, which are not always advantageous owing to the HO signalling cost incurred from incorrect predictions. The outcomes of the simulations confirm that the derived confidence level mechanism helps in improving the prediction accuracy by up to 8.23%.

Furthermore, still considering capacity enhancement, a UAV assisted cellular networking is considered, and an unsupervised learning-based UAV positioning algorithm is presented. A comprehensive analysis is conducted on the impacts of the overlapping footprints of multiple UAVs, which are controlled by their altitudes. The developed k-means clustering based UAV positioning approach is shown to reduce the number of users in outage by up to 80.47% when compared to the benchmark symmetric deployment.

Lastly, a QoS-aware dynamic spectrum access approach is developed in order to tackle challenges related to spectrum access, wherein all the aforementioned types of ML methods are employed. More specifically, by leveraging future traffic load predictions of radio access technologies (RATs) and Q-learning algorithm, a novel proactive spectrum sensing technique is introduced. As such, two different sensing strategies are developed; the first one focuses solely on sensing latency reduction, while the second one jointly optimises sensing latency and user requirements. In particular, the proposed Q-learning algorithm takes the future load predictions of the RATs and the requirements of secondary users--in terms of mobility and bandwidth--as inputs and directs the users to the spectrum of the optimum RAT to perform sensing. The strategy to be employed can be selected based on the needs of the applications, such that if the latency is the only concern, the first strategy should be selected due to the fact that the second strategy is computationally more demanding. However, by employing the second strategy, sensing latency is reduced while satisfying other user requirements. The simulation results demonstrate that, compared to random sensing, the first strategy decays the sensing latency by None 85.25%, while the second strategy enhances the full-satisfaction rate, where both mobility and bandwidth requirements of the user are simultaneously satisfied, by 95.7%.

Therefore, as it can be observed, three key design challenges of the next generation of cellular networks are identified and addressed via the concept of cognitive networking, providing a utilitarian tool for mobile network operators to plug into their systems. The proposed solutions can be generalised to various network scenarios owing to the sophisticated ML implementations, which renders the solutions both practical and sustainable.",project-academic
,2021-09-01,a,,an efficient deep learning approach using improved generative adversarial networks for incomplete information completion of self driving," Autonomous driving is the key technology of intelligent logistics in Industrial Internet of Things (IIoT). In autonomous driving, the appearance of incomplete point clouds losing geometric and semantic information is inevitable owing to limitations of occlusion, sensor resolution, and viewing angle when the Light Detection And Ranging (LiDAR) is applied. The emergence of incomplete point clouds, especially incomplete vehicle point clouds, would lead to the reduction of the accuracy of autonomous driving vehicles in object detection, traffic alert, and collision avoidance. Existing point cloud completion networks, such as Point Fractal Network (PF-Net), focus on the accuracy of point cloud completion, without considering the efficiency of inference process, which makes it difficult for them to be deployed for vehicle point cloud repair in autonomous driving. To address the above problem, in this paper, we propose an efficient deep learning approach to repair incomplete vehicle point cloud accurately and efficiently in autonomous driving. In the proposed method, an efficient downsampling algorithm combining incremental sampling and one-time sampling is presented to improves the inference speed of the PF-Net based on Generative Adversarial Network (GAN). To evaluate the performance of the proposed method, a real dataset is used, and an autonomous driving scene is created, where three incomplete vehicle point clouds with 5 different sizes are set for three autonomous driving situations. The improved PF-Net can achieve the speedups of over 19x with almost the same accuracy when compared to the original PF-Net. Experimental results demonstrate that the improved PF-Net can be applied to efficiently complete vehicle point clouds in autonomous driving.",project-academic
10.1007/S13177-021-00272-3,2021-09-15,a,Springer US,auto alert a spatial and temporal architecture for driving assistance in road traffic environments," Over the last decade, the Advanced Driver Assistance System (ADAS) concept has evolved prominently. ADAS involves several advanced approaches such as automotive electronics, vehicular communication, RADAR, LIDAR, computer vision, and its associated aspects such as machine learning and deep learning. Of these, computer vision and machine learning-based solutions have mainly been effective that have allowed real-time vehicle control, driver-aided systems, etc. However, most of the existing works deal with ADAS deployment and autonomous driving functionality in countries with well-disciplined lane traffic. These solutions and frameworks do not work in countries and cities with less-disciplined/ chaotic traffic. Hence, critical ADAS functionalities and even L2/ L3 autonomy levels in driving remain a major open challenge. In this regard, this work proposes a novel framework called Auto-Alert. Auto-Alert performs a two-stage spatial and temporal analysis based on external traffic environment and tri-axial sensor system for safe driving assistance. This work investigates time-series analysis with deep learning models for driving events prediction and assistance. Further, as a basic premise, various essential design considerations towards the ADAS are discussed. Significantly, the Convolutional Neural Network (CNN) and Long-Short-Term-Memory (LSTM) models are applied in the proposed Auto-Alert. It is shown that the LSTM outperforms the CNN with 99% for the considered window length. Importantly, this also involves developing and demonstrating an efficient traffic monitoring and density estimation system. Further, this work provides the benchmark results for Indian Driving Dataset (IDD), specifically for the object detection task. The findings of this proposed work demonstrate the significance of using CNN and LSTM networks to assist the driver in the holistic traffic environment.",project-academic
10.1109/EUVIP50544.2021.9483987,2021-06-23,p,IEEE,implementation and accuracy evaluation of fixed camera based object positioning system employing cnn detector," Today, different positioning applications such as location-based services and autonomous navigation are requiring more and more precision. Especially fully autonomous navigation requires accurate positioning solution, not only for the vehicle but also for the surrounding objects. Thus, many new positioning techniques, algorithms and fusion schemes have been developed. One essential technique is visual positioning. Thanks to intensive research in neural networks and deep learning, Convolutional Neural Network-based (CNN) object detectors have evolved greatly in recent years. This paper proposes a widely deployable scheme of fixed camera-based (e.g. surveillance camera) object positioning utilizing the CNN-detector. The accuracy of the implemented positioning solution is evaluated with precise Real-Time Kinematic (RTK) satellite positioning receiver. The implemented system can be used in indoors and outdoors, and it can estimate simultaneously positions from multiple camera views for multiple objects in real-time. When positioning a person, the measured mean positioning error was 10.7–15.6 cm with a simple bias correction and a standard deviation was 6.7–8.7 cm. Thus, the accuracy is excellent and would be sufficient to wide variety of applications.",project-academic
,2021-01-15,a,,paddleseg a high efficient development toolkit for image segmentation," Image Segmentation plays an essential role in computer vision and image processing with various applications from medical diagnosis to autonomous car driving. A lot of segmentation algorithms have been proposed for addressing specific problems. In recent years, the success of deep learning techniques has tremendously influenced a wide range of computer vision areas, and the modern approaches of image segmentation based on deep learning are becoming prevalent. In this article, we introduce a high-efficient development toolkit for image segmentation, named PaddleSeg. The toolkit aims to help both developers and researchers in the whole process of designing segmentation models, training models, optimizing performance and inference speed, and deploying models. Currently, PaddleSeg supports around 20 popular segmentation models and more than 50 pre-trained models from real-time and high-accuracy levels. With modular components and backbone networks, users can easily build over one hundred models for different requirements. Furthermore, we provide comprehensive benchmarks and evaluations to show that these segmentation algorithms trained on our toolkit have more competitive accuracy. Also, we provide various real industrial applications and practical cases based on PaddleSeg. All codes and examples of PaddleSeg are available at this https URL.",project-academic
10.1007/978-3-030-60843-9_3,2019-05-13,p,"Springer, Cham",reinforcement learning of supply chain control policy using closed loop multi agent simulation," Reinforcement Learning (RL) has achieved a degree of success in control applications such as online gameplay and autonomous driving, but has rarely been used to manage operations of business-critical systems such as supply chains. A key aspect of using RL in the real world is to train the agent before deployment by computing the effect of its exploratory actions on the environment. While this effect is easy to compute for online gameplay (where the rules of the game are well known) and autonomous driving (where the dynamics of the vehicle are predictable), it is much more difficult for complex systems due to associated complexities, such as uncertainty, adaptability and emergent behaviour. In this paper, we describe a framework for effective integration of a reinforcement learning controller with an actor-based multi-agent simulation of the supply chain network including the warehouse, transportation system, and stores, with the objective of maximizing product availability while minimising wastage under constraints.",project-academic
,2021-07-13,a,,real time pothole detection using deep learning," Roads are connecting line between different places, and used daily. Roads' periodic maintenance keeps them safe and functional. Detecting and reporting the existence of potholes to responsible departments can help in eliminating them. This study deployed and tested on different deep learning architecture to detect potholes. The images used for training were collected by cellphone mounted on the windshield of the car, in addition to many images downloaded from the internet to increase the size and variability of the database. Second, various object detection algorithms are employed and compared to detect potholes in real-time like SDD-TensorFlow, YOLOv3Darknet53 and YOLOv4Darknet53. YOLOv4 achieved the best performance with 81% recall, 85% precision and 85.39% mean Average Precision (mAP). The speed of processing was 20 frame per second. The system was able to detect potholes from a range on 100 meters away from the camera. The system can increase the safety of drivers and improve the performance of self-driving cars by detecting pothole time ahead.",project-academic
10.1109/LGRS.2020.2993652,2021-06-01,a,Institute of Electrical and Electronics Engineers (IEEE),minet efficient deep learning automatic target recognition for small autonomous vehicles," On-the-fly automatic target recognition (ATR) is a challenge for small autonomous vehicles performing remote sensing. Advances in deep learning have made object detection practicable on data from a variety of sensor types, and neural network-based object detector models trained on big data sets of natural images are commonly adapted to the remote sensor (RS) domain via transfer learning. However, constraints of small vehicle hardware, such as computational performance and battery power, limit capacity for running deep learning models onboard. Standard pretrained object detection models, such as YOLO and R-CNN, contain large convolutional neural networks requiring tens to hundreds of billions of floating-point operations to distinguish between many natural image object classes. Such large models may be overly complex for ATR tasks in RS data. This letter describes an efficient deep learning model, MiNet, developed to detect mine-like objects in sonar data. It was built in Keras and TensorFlow and trained entirely on real and synthetically generated sonar data using an incremental training procedure. MiNet was successfully deployed onboard small OceanServer Iver3 autonomous underwater vehicles during the REBOOT sea trial and predicted the latitude, longitude, and class of objects detected in sonar images within minutes of the completion of each mission leg.",project-academic
10.1109/COMPE49325.2020.9200107,2020-07-02,p,IEEE,inspection of concrete structures by a computer vision technique and an unmanned aerial vehicle," We have proposed a visual inspection technique for concrete structures using deep learning and a hardware ecosystem, an Unmanned Aerial Vehicle (UAV). The UAV is a quadcopter that can fly to unreachable sections of a site which consists of a camera that captures images of the concrete surfaces via a mobile device and feed the real time images in the CNN model. The images taken from such remote locations may contain different types of surfaces, shadowed regions and surfaces with holes. The cracks are properly detected by the CNN ‘AlexNet’ algorithm and masking with sliding window technique in such conditions due to variation in the image data set. The experimental results were simulated on a standard online data set of 40,000 images of Mendeley Data which is freely available and 3000 images have been chosen from the entire data set for this method. The classes have been divided into 2 categories of ‘crack’ and ‘no crack’ for the proposed method’s data set. There are 1050 training images and 450 testing images for each category. Experimental results were achieved on Google Colab cloud service using Python Tensorflow API (Application Programming Interface). The proposed ‘AlexNet’ CNN algorithm achieves 98.4 % accuracy and the model is deployed to a masking technique with sliding window to detect cracks in a 3008x2000 pixel resolution image by breaking the image into 227x227 pixel resolution image patches. The experimental results have proved that the proposed method handles noisy background such as cracks with shadows and stains, cracks on rusty and rough surfaces and minor dimension cracks with good efficiency.",project-academic
10.3390/JMSE9111166,2021-10-23,a,Multidisciplinary Digital Publishing Institute,auv obstacle avoidance planning based on deep reinforcement learning," In a complex underwater environment, finding a viable, collision-free path for an autonomous underwater vehicle (AUV) is a challenging task. The purpose of this paper is to establish a safe, real-time, and robust method of collision avoidance that improves the autonomy of AUVs. We propose a method based on active sonar, which utilizes a deep reinforcement learning algorithm to learn the processed sonar information to navigate the AUV in an uncertain environment. We compare the performance of double deep Q-network algorithms with that of a genetic algorithm and deep learning. We propose a line-of-sight guidance method to mitigate abrupt changes in the yaw direction and smooth the heading changes when the AUV switches trajectory. The different experimental results show that the double deep Q-network algorithms ensure excellent collision avoidance performance. The effectiveness of the algorithm proposed in this paper was verified in three environments: random static, mixed static, and complex dynamic. The results show that the proposed algorithm has significant advantages over other algorithms in terms of success rate, collision avoidance performance, and generalization ability. The double deep Q-network algorithm proposed in this paper is superior to the genetic algorithm and deep learning in terms of the running time, total path, performance in avoiding collisions with moving obstacles, and planning time for each step. After the algorithm is trained in a simulated environment, it can still perform online learning according to the information of the environment after deployment and adjust the weight of the network in real-time. These results demonstrate that the proposed approach has significant potential for practical applications.",project-academic
,2021-01-01,,,ros based airborne target detection and tracking method," The invention discloses an ROS-based airborne target detection and tracking method, and belongs to the technical field of unmanned aerial vehicle target detection and tracking. According to the invention, the YOLOv3 deep learning target detection algorithm and the improved KCF related filtering target tracking algorithm are combined to form a target detection tracking function packet, the information redundancy in the image sequence and the effect of the target detection algorithm are comprehensively considered, and on the premise that the target tracking algorithm can achieve super real-timeperformance, an image is selected in an intermittent frame extraction mode to perform target detection, and thus performing target tracking processing on subsequent frames of the current detection frame in sequence without difference after the specific target is locked. In a short time, the target tracking algorithm can process the latest received image, the purpose of interval detection real-timetracking is achieved, the problem of frame loss in the initial stage of target tracking is solved, the advantages of high accuracy of the detection algorithm and high real-time performance of the tracking algorithm are brought into full play, and transplantation and deployment can be conducted on a terminal platform with limited resources.",project-academic
10.1007/S12517-021-07457-W,2021-06-01,a,Springer International Publishing,uav landmark detection on fast region based cnn," The extensive use application of visual perception technology in an unmanned aerial vehicle (UAV) has brought great changes to the application of UAVs in various fields. It is challenging to detect landmark images for UAVs as UAV video-monitoring equipment needs to analyze the whole frame image through complex calculations in real time. Convolutional neural networks (CNNs) have shown advances in the object detection and segmentation fields. However, during UAV flights in different environments, the performance of landmark detection to deteriorate seriously has been caused by the uncertainty of landmark orientation, the diversity of landmark types, and the similarities in different object classes. This paper presents landmark detection of an UAV based on fast region-based convolutional neural networks (Fast R-CNN) adapting to complex and rapid flying environment changes. The proposed model design is improved by optimizing the model’s objective function, which offers higher accuracy and robustness. The proposed system offers detection in real time by utilizing multi-core processors to realize multi-threaded operations more effectively to improve the operation speed of the overall algorithm. Theoretical analysis and experimental results demonstrate landmark recognition with an accuracy of at least 96% to match deployed in UAVs and make correct multiple classifications simultaneously based on Fast R-CNN.",project-academic
,2021-01-29,,,security plan generation scheduling method and system based on machine learning and collaborative filtering," The invention discloses a security plan generation scheduling method and system based on machine learning and collaborative filtering. The system comprises an aerial unmanned aerial vehicle equipmentgroup, a ground mobile robot equipment group, an equipment deployment platform, a monitoring center station, a positioning navigation module and a communication network system. The unmanned aerial vehicle equipment group is composed of a plurality of unmanned aerial vehicles, the ground mobile robot equipment group is composed of a plurality of robots, the equipment deployment platform is providedwith a ground area wireless charging module, and the monitoring center station can display monitoring information in real time and control the unmanned aerial vehicles and the ground mobile robots. The method comprises real-time state inspection, task receiving, task execution (such as fault processing, intrusion processing, plan generation, plan optimization and equipment scheduling) and task completion. According to the invention, routine and emergent security and protection task execution can be carried out according to the original plan, and an optimization scheme can be improved or a newplan can be directly generated according to the actual task execution situation, so that the security and protection task efficiency and the rationality of the plan are improved.",project-academic
10.3390/ELECTRICITY2020007,2021-04-06,a,Multidisciplinary Digital Publishing Institute,energy efficient on platform target classification for electric air transportation systems," Due to the predicted rise of Unmanned Aircraft Systems (UAS) in commercial, civil, and military operations, there is a desire to make UASs more energy efficient so they can proliferate with ease of deployment and maximal life per charge. To address current limitations, a three-tiered approach is investigated to mitigate Unmanned Aerial Vehicle (UAV) hover time, reduce network datalink transmission to a ground station, and provide a real-time framework for Sense-and-Avoidance (SAA) target classification. An energy-efficient UAS architecture framework is presented, and a corresponding SAA prototype is developed using commercial hardware to validate the proposed architecture using an experimental methodology. The proposed architecture utilizes classical computer vision methods within the Detection Subsystem coupled with deeply learned Convolutional Neural Networks (CNN) within the Classification Subsystem. Real-time operations of three frames per second are realized enabling UAV hover time and associated energy consumption during SAA processing to be effectively eliminated. Additional energy improvements are not addressed in the scope of this work. Inference accuracy is improved by 19% over baseline COTS models and current non-adaptive, single-stage SAA architectures. Overall, by pushing SAA processing to the edge of the sensors, network offload transmissions and reductions in processing time and energy consumption are feasible and realistic in future battery-powered electric air transportation systems.",project-academic
,2020-01-01,a,Durham University,deep learning approaches for autonomous uav control and mapping in cluttered outdoor environments," In complex unstructured environments such as under the canopy of densely forested areas, autonomous and intelligent unmanned aerial vehicle (UAV) flight continues to be an unaddressed challenging problem. The main predicament in the development of a system supporting autonomous and intelligent fly lies primarily due to the lack of an available dataset. During this research, a method was developed to enable rapid data labelling in real-time, which is suitable for data gathered from most mounted cameras (handheld, ground vehicles and/or UAV), regardless of their resolution. Leveraging this dataset creation capability, the proposed trail following approach outperforms the state-of-the-art approaches for trail navigation within a complex forest canopy environment. Additionally, extensive testing demonstrated that the proposed approach does not suffer loss of performance even when replacing the camera between flights.

Another issue with navigating in such an environment (i.e. under the canopy) is the lack of generalisation across varying domains (i.e. farmland, deserts, savanna etc). This is further aggravated by seasonal environmental variations such that a model trained during summer will not be generalised to the same environment during the winter. To solve this issue a multi-task approach presents a deep neural network which eliminates the need to follow a trail, by providing the UAV with the ability to identify the safest area to navigate, regardless of the existing altitude and whether or not a trail is visible in the scene. This new approach increases the navigational control from three to six DoF (Degrees of Freedom). Furthermore, the final results demonstrated superior performance for navigation than the comparators approach.

Besides autonomously navigating in the environment, an intelligent UAV is expected to increase its resourcefulness by mapping while simultaneously exploring the environment. This would facilitate the commencement of search and rescue operations to be carried by either one or a swarm of intelligent UAV. This research entailed the development of a grid-based map that can store the position of obstacles and trails within the search area, while allowing onboard processing. Additionally, this approach adopts a hybrid network that combines Reinforcement Learning and Online Learning to improve navigability, exploration and adaptability to unseen environments, thus allowing search and rescue operations to be extended without requiring offline training.

Overall, this research aims to investigate new and efficient ways for intelligent UAV to perform an end-to-end operation and achieve real-time mapping and autonomous navigation in an unstructured environment. The findings in this research are important in that they culminate into three extensively tested approaches for navigation and exploration that can be deployed either on a ground control station or on-board of a UAV.",project-academic
,2020-11-26,,,a technique for traffic prediction and congestion control in iot networks using machine learning," A TECHNIQUE FOR TRAFFIC PREDICTION AND CONGESTION CONTROL IN IOT NETWORKS USING MACHINE LEARNING At present, all the real time applications in the world are deployed with smart technology using internet of things. Particularly in transportation system, any congestion in the traffic affects the transportation of goods, medically equipped vehicles, tourist logistics management, etc. For unmanned vehicle, 5G network with wireless sensor deployed for communication of data, especially in internet of things enabled smart city. The data input are observed by sensors of highly configured cameras, mobile devices and radio frequency identification tags. The information are grouped as datasets, for example, vehicle number, speed of all the vehicles, timings, paths and current congestion status. After grouping of datasets, it is deployed with machine learning algorithm. A supervised learning involving statistics, logistic regression model which is a classification algorithm is applied to predict the probability of target parameter. A threshold set can be used to observe the probability and classified into classes with logistic regression model. This prediction model for traffic analysis provides good accuracy and efficiency involving smart technology in the city managing the transportation system. It predicts the traffic congestion in advance and congestion control is performed from the notification received in smart devices at end user. 1| P a g e A TECHNIQUE FOR TRAFFIC PREDICTION AND CONGESTION CONTROL IN IOT NETWORKS USING MACHINE LEARNING Drawings NO OF VEHICLES CAMERAVEHICLE NO - SENSORS 5G NETWORK) TIME CURRENT STA~t"" OF1 CONGESTION Fig. I DATA COLLECTION",project-academic
,2020-10-27,,,agricultural insurance survey unmanned aerial vehicle device rotor wing and fixed wing unmanned aerial vehicle flight platform," The utility model belongs to the field of unmanned aerial vehicle remote sensing application, and discloses an agricultural insurance survey unmanned aerial vehicle device, rotor wing and fixed wing unmanned aerial vehicle flight platform, which comprises a server for realizing training, optimization and deployment of an image segmentation model based on deep learning and storage of crop survey information; the Internet is connected with the server and is used for realizing data communication; the ground control station is connected with the Internet and is used for loading task planning dataand comprehensive monitoring of the image segmentation model, unmanned aerial vehicle remote control and telemetry data; and the unmanned aerial vehicle is connected with the ground control station and is used for acquiring, segmenting and splicing the images. According to the agricultural insurance survey unmanned aerial vehicle device capable of automatically measuring the crop disaster area, agricultural insurance survey loss assessment is taken as an application background, a server and a ground control station are taken as supports, an unmanned aerial vehicle flight platform is taken as acarrier, embedded visual calculation is taken as a core, and a survey unmanned aerial vehicle system capable of automatically measuring the crop disaster area is developed.",project-academic
,2020-01-01,a,Longdom Publishing SL,towards holistic scene understanding in autonomous driving," Holistic scene understanding is a vital component of the self-driving vehicles of the future. It is crucial that those vehicles are able to understand and interpret their environment in order to drive safely. This requires precise detection of surrounding objects (vehicles, humans, traffic objects, nature), discrimination between drivable and non-drivable surfaces (road, sidewalk, buildings) and segmentation of static and dynamic objects into high-level semantic classes. In the past, computer vision has tackled these problems separately due to their complexity and high computational needs. Nowadays, deep learning-based systems are trained on manually annotated datasets to solve these problems, however they face multiple challenges: 1) the number of the annotated semantic classes are limited by the available datasets to few dozen decreasing the variety of recognizable objects, 2) the density of annotations is inversely proportional to the size of the datasets, rendering huge dataset incompatible for precise segmentation, and 3) detection and segmentation are solved separately, that leads to higher memory and computational demands. Our research addresses the aforementioned challenges by proposing new methods to: 1) train a single network on multiple datasets with different semantic classes and different type of annotations, and 2) solve simultaneously with a single network the problems of detection and semantic segmentation. We have deployed those networks in our autonomous driving car with real-time performance. We demonstrate state-of-the-art results, together with a fivefold increase in the number of recognizable classes, and we integrate efficiently detection and segmentation into a joint panoptic segmentation system, taking important steps towards achieving holistic scene understanding.",project-academic
,2020-11-10,,,method for analyzing cracks of porcelain bottle of power transmission and transformation line in real time based on yolact algorithm," The invention discloses a method for analyzing cracks of a porcelain bottle of a power transmission and transformation line in real time based on a YOLACT algorithm, and belongs to the technical fieldof power transmission and transformation line porcelain bottle crack real-time analysis. The technical problem to be solved is to provide an improvement of a method for analyzing cracks of a porcelain bottle of a power transmission and transformation line in real time based on a YOLACT algorithm. According to the technical scheme, the method comprises the steps of collecting and marking power transmission and transformation line porcelain bottle crack data through unmanned aerial vehicle field shooting and power transmission line defect and fault data summarization, covering multiple scenes and multiple types of porcelain bottle crack data, and establishing a porcelain bottle crack semantic segmentation data set; carrying out model optimization and pruning operation on the basis of a YOLACT algorithm model, constructing a lightweight real-time semantic segmentation deep learning model, carrying out training on the basis of the improved YOLACT algorithm model, and deploying the algorithm model and training data in a mobile terminal embedded device for real-time reasoning analysis; the method is applied to crack analysis of the power transmission and transformation line porcelain bottle.",project-academic
10.1007/978-3-030-14156-1_23,2019-01-01,a,"Springer, Cham",real time driving risk assessment for onboard accident prevention application to vocal driving risk assistant adas and autonomous driving," Accident risk assessment is a research field that has been started in the 60’s, in particular on the basis of «risk triangle» theory proposed by Frank E. Bird in 1969. This theory of risk uses the notion of «near misses» observation that leads to «safety rules» in a large number of application fields such as manufacturing, firemen, etc. Note that this approach is the opposite of what some automotive teams are currently starting (observing «everything» recorded on a big database): Most of the time nothing happens (no incident, no surprise). Risk experts do not do this. They are focused on «near misses» observation only, instead of observing the global process where at least 99.99% of data are not relevant for risk assessment. And observation of accidents is not relevant neither: accident is a rare combination of «near miss» situation and bad luck (stochastic process). Risk experts work on safety rules made to keep the situation as far as possible from near miss. In the domain of road safety, this approach has been developed mainly by road infrastructure experts in order to understand deep and deterministic reasons of near misses and propose ways of shaping roads and road signs in order to minimize it. This paper deals with presentation of results of a 15 years long collaborative research that extracted knowledge from road infrastructure experts and researchers, and put it into an on-board knowledge-based artificial intelligence in order to score driving risk dynamically and in real time. Indeed, there is no inherently bad driving behaviour and there is no inherently dangerous infrastructures, contrary to what many people think (black spots, harsh/brutal driving behaviour, etc.). It is when driving behaviour is inappropriate to driving context that driving risk appears. Driving context is described by infrastructure characteristics (geometry and functionality), by location of other users of the infrastructure (cars, trucks, bicycles, pedestrians, …), by weather conditions, etc. In this list, infrastructure takes 75% of the global weight, and then the artificial intelligence uses the digital map, and does pattern recognition on this digital map, in order to describe infrastructure context. ADAS sensors give additional inputs such as inter-distance, size of free space, time to collision, visibility measurement … Then driving risk depends dynamically on the context (infrastructure, traffic, visibility, …) and on the driving behaviour, through a sensor plus map fusion, made by the artificial intelligence. This artificial intelligence has been integrated inside a software API called SafetyNex that is already under deployment. This tool can alert human driver before dangerous situation, letting time to smoothly slow down and avoid potential bad surprises. Of course it can also alert the AD (Autonomous driving system) in order to automate a cautious driving behaviour (in urban areas for instance). The Artificial Intelligence estimates driving risk 20 times per second and this paper shows on real uses cases how this risk assessment anticipates potential danger. In addition, risk profiles are recorded on the cloud. We think that this risk profile recording (both for human driver and autonomous car) can be a start of comparison in terms of road safety, and a good communication vector from car manufacturers to car insurance that will need «proofs» if they ever propose a special cheap pricing. It is important as car insurers are expected to pay a part of the value brought by ADAS and autonomous vehicle because they act on risk. Of course, car insurer will accept if and only if ADAS and AD reduce accident rate and cost loss. So we conclude on the economic value of artificial intelligence in connected and intelligent cars using the cloud to exchange risk data.",project-academic
10.1016/J.INFFUS.2021.07.004,2022-01-01,a,Elsevier,saccadefork a lightweight multi sensor fusion based target detector," Abstract None None Commercialization of self-driving applications requires precision and reliability of the perception system due to the highly dynamic and complex road environment. Early perception systems either rely on the camera or on LiDAR for moving obstacle detection. With the development of vehicular sensors and deep learning technologies, the multi-view and sensor fusion based convolutional neural network (CNN) model for detection tasks has become a popular research area. In this paper, we present a novel multi-sensor fusion-based CNN model–SaccadeFork–that integrates the image and upsampled LiDAR point clouds as the input. SaccadeFork includes two modules: (1) a lightweight backbone that consists of hourglass convolution feature extraction module and a parallel dilation convolution module for adaptation of the system to different target sizes; (2) an anchor-based detection head. The model also considers deployment of resource-limited edge devices in the vehicle. Two refinement strategies, i.e., Mixup and Swish activation function are also adopted to improve the model. Comparison with a series of latest models on public dataset of KITTI shows that SaccadeFork can achieve the optimal detection accuracy on vehicles and pedestrians under different scenarios. The final model is also deployed and tested on a local dataset collected based on edge devices and low-cost sensor solutions, and the results show that the model can achieve real-time efficiency and high detection accuracy.",project-academic
10.2514/6.1991-3729,1991-10-21,p,American Institute of Aeronautics and Astronautics,an intelligent pilot vehicle interface for a day night adverse weather pilotage system d naps," The Aviation Applied Technology Directorate (AATD) of the U.S. Army Aviation Systems Command (AVSCOM) Fort Eustis, Virginia has awarded competitive contracts for the development of pilot cognitive decision aiding. The Daymight Adverse Weather Pilotage System (D/NAPS) program will use artificial intelligence (AI) and integrate with advanced pilotage sensors, controls, and displays in order to demonstrate the pilot cognitive decision aids. D/NAPS will incorporate lessons learned from the Defense Advanced Research Projects Agency (DARPA) and U.S. Air Force (USAF) Pilot’s Associate (PA) program for fixed-wing aircraft. The primary purpose of D/NAPS is to use artificial intelligence technology to maximize combat helicopter mission effectiveness and survivability for day/night adverse weather operations. The Pilot-Vehicle Interface @VI) is the key component of any system that offers pilot cognitive decision aiding, since the PVI is the intelligent interface that determines how and when to aid the pilot. This paper will present an overview of the Pilot’s Associate and D/NAPS programs, and will elucidate the requirements of an intelligent Pilot-Vehicle Interface. The D/NAPS program is a technology demonstration program sponsored by the Aviation Applied Technology Directorate of the U.S. Army Aviation Systems Command. N o competitive contracts have been awarded for the development of pilot cognitive decision aiding by applying artificial intelligence technology to encode expert knowledge and to integrate it with advanced pilotage sensors, controls, and displays. Experiences from the DARPA/USAF Pilot’s Associate program that applied artificial intelligence to aid the pilots of fixed-wing fighter aircraft will be used by D/NAPS Copyright@l991 by the American Institute of Aeronautics and Astrona~ti~~, Inc. All rights reserved. 159 Patricia A. Casper Stratford, Connecticut United Technologies Sikorsky Aircraft Division where appropriate. A downselect to one contractor to conduct ground-based integration and actual flight demonstration of the pilotage system will occur in August 1992. One of the D/NAPS prime contractors is Sikorsky Aircraft, whose major subcontractors include Texas Instruments and United Technologies Research Center (UTRC). The other award was presented to McDonnell Douglas Helicopter with IBM as principal subcontractor. Sikorsky Aircraft and UTRC have the responsibility of designing and implementing the Pilot-Vehicle Interface module, a key component of D/NAPS. The remainder of this section contains an overview of the D/NAPS program, the PA program, and the purpose of an intelligent Pilot-Vehicle Interface. The next section contains a discussion of the PVI in the PA program and a review of the different aircraft and mission requirements for the D/NAPS program. This section also contains a high-level overview of the Sikorsky Team’s approach to the D/NAPS PVI. DARPA and the Air Force began the pilot’s Associate program in 1986 as a means of exploiting artificial intelligence technology to improve the mission effectiveness and survivability of advanced tactical aircraft and as an application demonstration for real-time, cooperating knowledge-based systems. Two independent development contracts were awarded at that time to Lockheed Aeronautical Systems Company and McDonnell Aircraft Company. Currently, only the Lockheed team is funded towards developing a full functionality real-time demonstration for 1992. The purpose of the PA program is to build a trusted “associate” or assistant for the pilot, not to build a system capable of autonomous operation (without the pilot-bthe-loop). Further references to the Pilot’s Associate program may be found in References 1,2, and 5. The system should improve the combat effectiveness and survivability of the pilot when confronted with difficult situations such as unanticipated threat conditions or on-board system failures, or when he or she is overloaded with data and tasks. The PA should be capable of enhancing the pilot’s situational awareness, interpreting the pilot’s intent, and responding to pilot directives. The Pilot’s Associate is composed of five functional subsystems. Two of these systems are involved in assessment tasks, the Systems Status module and the Situation Assessment module. W o systems are involved in planning, the Mission Planner and the Tactical Planner. The fifth subsystem is an intelligent interface between the vehicle and the pilot, called the Pilot-Vehicle Interface. An executive controls and coordinates the different subsystems, and assimilates additional input information from sensors and mission processors. The Systems Status subsystem monitors the on-board aircraft components. This subsystem must continuously monitor and maintain the health of all the intemal systems of the aircraft. It must diagnose and predict faults, and automatically correct or compensate for these faults within the limits authorized by the pilot. This subsystem must also respond to an emergency either by advising the pilot or by automatically performing certain cockpit functions. The Situation Assessment subsystem monitors the extemal environment of the aircraft. This subsystem must provide an accurate and coherent assessment of the type, position, and intent of external entities that might affect the planned mission. The Situation Assessment subsystem comlates sensor information such as radar and intelligence information from external sources. The external entities of the aircraft could be either friend or foe, so this subsystem must assess both the action and intent of each external entity. The Mission Planning subsystem provides the pilot with appropriate information about the current plan and alternative plans as necessary. It updates the existing plan as events unfold and compares the pre-planned model with actual events. It must advise the pilot on the current phase of the mission and permit contingency planning and route replanning if the situation warrants. The Tactics Planner subsystem assists the pilot in responding to threats. This subsystem sorts and prioritizes the threats and targets of the aircraft and assists in countermeasure selection and weapons deployment. In addition, this subsystem helps coordinate the wingman roles. The Pilot-Vehicle Interface is the critical link between the other functional subsystems of the PA and the pilot. It controls the content and timing of the cockpit displays. It must display prioritized information to the pilot in a natural medium based on the mission context and the pilot’s intent. The role of the PVI will be explained further in the next section. The Executive controls the activities of the PA. The Executive allocates resources to the different subsystems, coordinates activities within the subsystems, and passes data between the subsystems. The Coglhve Decision AidiD/NAPS .. One of the main objectives of the D/NAPS program is to provide cognitive decision aiding to a single pilot flying a covert mission behind enemy lines in all types of environmental conditions around the clock. In contrast to the PA mission, D/NAPS is not an armed attack mission, and it must be capable of being performed at day or night and in adverse weather. In addition, the covert nature of the mission requires that most of the flying behind enemy lines occurs at Napof-th+Earth WOE) altitudes (as close to the earth’s surface as terrain and conditions allow). The demanding conditions under which the D/NAPS mission is flown provide significant challenges to an AI system, the main goals of which are to increase mission effectiveness and survivability and to reduce pilot workload. The expert system components of the D/NAPS program are referred to as the Cognitive Decision Aiding System (CDAS). The CDAS Contains the same five modules as used by the PA program, however the functionality of each module will vary slightly. The Mission Planner performs mute planning. The Tactical Planner performs near-term I",project-academic
,1989-04-20,a,,telerobotic control for teams of semi autonomous agents phase 1," Abstract : A Robotic Command Center, is to be developed to allow a commander and two drivers (three people) to control four remote vehicles. The drivers will be attempting to control two vehicles each--a difficult task. Giving vehicles a measure of autonomy is one way to simplify that task. On the other hand, deployed vehicles must not be hampered by software with limited competence or reliability. The only solution available soon is a vehicle control interface that allows for the entire range of possibilities between autonomous behavior and continuous teleoperation. Ideas are fused from telerobotics and from the Reaction Planning subfield of Artificial Intelligence, to develop a technology that permits vehicles to react autonomously to expected circumstances, while also permitting the human operator to instruct vehicles about what to do and how to do it. This study will program some examples of behaviors for the vehicles to perform semi-autonomously, and those behaviors by running them in the Team Works I environment. An interface was designed and built that allows the vehicle driver to communicate with the intelligent software controlling any and all of the vehicles. A single person is capable of controlling four simulated vehicles at the same time. The competence of the vehicle is to be expanded to give the operator new ways of instructing the vehicles, and to push those capabilities toward deployment in the real world.",project-academic
10.1145/1082473.1082545,2005-07-25,p,ACM,multiagent traffic management an improved intersection control mechanism," Traffic congestion is one of the leading causes of lost productivity and decreased standard of living in urban settings. Recent advances in artificial intelligence suggest vehicle navigation by autonomous agents will be possible in the near future. In a previous paper, we proposed a reservation-based system for alleviating traffic congestion, specifically at intersections. This paper extends our prototype implementation in several ways with the aim of making it more implementable in the real world. In particular, we 1) add the ability of vehicles to turn, 2) enable them to accelerate while in the intersection, and 3) augment their interaction capabilities with a detailed protocol such that the vehicles do not need to know anything about the intersection control policy. The use of this protocol limits the interaction of the driver agent and the intersection manager to the extent that it is a reasonable approximation of reliable wireless communication. Finally, we describe how different intersection control policies can be expressed with this protocol and limited exchange of information. All three improvements are fully implemented and tested, and we present detailed empirical results validating their effectiveness.",project-academic
10.1016/J.TRPRO.2016.05.240,2016-01-01,a,Elsevier Publications,advanced driver assistance system for road environments to improve safety and efficiency," The advances in Information Technologies have led to more complex road safety applications. These systems provide multiple possibilities for improving road transport. The integrated system that this paper presents deals with two aspects that have been identified as key topics: safety and efficiency. To this end, the development and implementation of an integrated advanced driver assistance system (ADAS) for rural and intercity environments is proposed. The system focuses mainly on single-carriageways roads, given the complexity of these environments compared to motorways and the high number of severe and fatal accidents on them. The proposed system is based on advanced perception techniques, vehicle automation and communications between vehicles (V2V) and with the infrastructure (V2I). Sensor fusion architecture based on computer vision and laser scanner technologies are developed. It allows real time detection and classification of obstacles, and the identification of potential risks. The driver receives this information and some warnings generated by the system. In case, he does not react in a proper way, the vehicle could perform autonomous actions (both on speed control or steering maneuvers) to improve safety and/or efficiency. Furthermore, a multimodal V2V and V2I communication system, based on GeoNetworking, facilitates the flow of information between vehicles and assists in the detection and information broadcasting processes. All this, combined with vehicle positioning, detailed digital maps and advanced map-matching algorithms, establish the decision algorithms of different ADAS systems. The applications developed include: adaptive cruise control with consumption optimization, overtaking assistance system in single-carriageways roads that takes into account appropriate speed evolution and identifies most suitable road stretches for the maneuver; assistance system in intersections with speed control during approximation maneuvers, and collision avoidance system with the possibility of evasive maneuvers. To this end, mathematical vehicle dynamics models have been used to ensure the stability, and propulsion system models are used to establish efficient patterns, Artificial Intelligence and simulation are used for experimentation and evaluation of algorithms to be implemented in the control unit. Finally, the system is designed to warn the driver if a risk is detected and, if necessary, to take control of the vehicle. The system has been implemented on a passenger car and has been tested in specific scenarios on a test track with satisfactory results. Language: en",project-academic
,2019-03-29,a,,autonomous highway driving using deep reinforcement learning," The operational space of an autonomous vehicle (AV) can be diverse and vary significantly. This may lead to a scenario that was not postulated in the design phase. Due to this, formulating a rule based decision maker for selecting maneuvers may not be ideal. Similarly, it may not be effective to design an a-priori cost function and then solve the optimal control problem in real-time. In order to address these issues and to avoid peculiar behaviors when encountering unforeseen scenario, we propose a reinforcement learning (RL) based method, where the ego car, i.e., an autonomous vehicle, learns to make decisions by directly interacting with simulated traffic. The decision maker for AV is implemented as a deep neural network providing an action choice for a given system state. In a critical application such as driving, an RL agent without explicit notion of safety may not converge or it may need extremely large number of samples before finding a reliable policy. To best address the issue, this paper incorporates reinforcement learning with an additional short horizon safety check (SC). In a critical scenario, the safety check will also provide an alternate safe action to the agent provided if it exists. This leads to two novel contributions. First, it generalizes the states that could lead to undesirable ""near-misses"" or ""collisions "". Second, inclusion of safety check can provide a safe and stable training environment. This significantly enhances learning efficiency without inhibiting meaningful exploration to ensure safe and optimal learned behavior. We demonstrate the performance of the developed algorithm in highway driving scenario where the trained AV encounters varying traffic density in a highway setting.",project-academic
,2019-08-24,a,,planning beyond the sensing horizon using a learned context," Last-mile delivery systems commonly propose the use of autonomous robotic vehicles to increase scalability and efficiency. The economic inefficiency of collecting accurate prior maps for navigation motivates the use of planning algorithms that operate in unmapped environments. However, these algorithms typically waste time exploring regions that are unlikely to contain the delivery destination. Context is key information about structured environments that could guide exploration toward the unknown goal location, but the abstract idea is difficult to quantify for use in a planning algorithm. Some approaches specifically consider contextual relationships between objects, but would perform poorly in object-sparse environments like outdoors. Recent deep learning-based approaches consider context too generally, making training/transferability difficult. Therefore, this work proposes a novel formulation of utilizing context for planning as an image-to-image translation problem, which is shown to extract terrain context from semantic gridmaps, into a metric that an exploration-based planner can use. The proposed framework has the benefit of training on a static dataset instead of requiring a time-consuming simulator. Across 42 test houses with layouts from satellite images, the trained algorithm enables a robot to reach its goal 189\% faster than with a context-unaware planner, and within 63\% of the optimal path computed with a prior map. The proposed algorithm is also implemented on a vehicle with a forward-facing camera in a high-fidelity, Unreal simulation of neighborhood houses.",project-academic
10.1109/37.621469,1997-10-01,a,IEEE,human control strategy abstraction verification and replication," In this article, we describe and develop methodologies for modeling and transferring human control strategy. This research has potential application in a variety of areas such as the intelligent vehicle highway system, human-machine interfacing, real-time training, space telerobotics, and agile manufacturing. We specifically address the following issues: (1) how to efficiently model human control strategy through learning cascade neural networks, (2) how to select state inputs in order to generate reliable models, (3) how to validate the computed models through an independent, hidden Markov model-based procedure, and (4) how to effectively transfer human control strategy. We have implemented this approach experimentally in the real-time control of a human driving simulator, and are working to transfer these methodologies for the control of an autonomous vehicle and a mobile robot. In providing a framework for abstracting computational models of human skill, we expect to facilitate analysis of human control, the development of human-like intelligent machines, improved human-robot coordination, and the transfer of skill from one human to another.",project-academic
,2019-09-23,a,,sensor augmented neural adaptive bitrate video streaming on uavs," Recent advances in unmanned aerial vehicle (UAV) technology have revolutionized a broad class of civil and military applications. However, the designs of wireless technologies that enable real-time streaming of high-definition video between UAVs and ground clients present a conundrum. Most existing adaptive bitrate (ABR) algorithms are not optimized for the air-to-ground links, which usually fluctuate dramatically due to the dynamic flight states of the UAV. In this paper, we present SA-ABR, a new sensor-augmented system that generates ABR video streaming algorithms with the assistance of various kinds of inherent sensor data that are used to pilot UAVs. By incorporating the inherent sensor data with network observations, SA-ABR trains a deep reinforcement learning (DRL) model to extract salient features from the flight state information and automatically learn an ABR algorithm to adapt to the varying UAV channel capacity through the training process. SA-ABR does not rely on any assumptions or models about UAV's flight states or the environment, but instead, it makes decisions by exploiting temporal properties of past throughput through the long short-term memory (LSTM) to adapt itself to a wide range of highly dynamic environments. We have implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the results show that our system outperforms the best known existing ABR algorithm by 21.4% in terms of the average quality of experience (QoE) reward.",project-academic
10.1109/TMM.2019.2945167,2020-06-01,a,IEEE,sensor augmented neural adaptive bitrate video streaming on uavs," Recent advances in unmanned aerial vehicle (UAV) technology have revolutionized a broad class of civil and military applications. However, the designs of wireless technologies that enable real-time streaming of high-definition video between UAVs and ground clients present a conundrum. Most existing adaptive bitrate (ABR) algorithms are not optimized for the air-to-ground links, which usually fluctuate dramatically due to the dynamic flight states of the UAV. In this paper, we present SA-ABR, a new sensor-augmented system that generates ABR video streaming algorithms with the assistance of various kinds of inherent sensor data that are used to pilot UAVs. By incorporating the inherent sensor data with network observations, SA-ABR trains a deep reinforcement learning (DRL) model to extract salient features from the flight state information and automatically learn an ABR algorithm to adapt to the varying UAV channel capacity through the training process. SA-ABR does not rely on any assumptions or models about UAV's flight states or the environment, but instead, it makes decisions by exploiting temporal properties of past throughput through the long short-term memory (LSTM) to adapt itself to a wide range of highly dynamic environments. We have implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the results show that our system outperforms the best known existing ABR algorithm by 21.4% in terms of the average quality of experience (QoE) reward.",project-academic
,2006-01-01,a,,human usable and emergency vehicle aware control policies for autonomous intersection management," Traffic congestion and automobile accidents are two of the leading causes of decreased standard of living and lost productivity in urban settings. Recent advances in artificial intelligence and, specifically, intelligent vehicle technology suggest that vehicles driven entirely by autonomous agents will be possible in the near future. In previous work, we presented a novel reservation-based approach for governing interactions of multiple autonomous vehicles, specifically at intersections. This approach alleviated many traditional problems associated with intersections, in terms of both safety and efficiency. However, such a system relies on all vehicles being equipped with the requisite technology — a restriction that would make implementing such a system in the real world extremely difficult. In this paper, we augment the system such that it is able to accomodate traditional human-operated vehicles using existing infrastructure. Furthermore, we show that as the number of autonomous vehicles on the road increases, traffic delays decrease monotonically toward the levels exhibited in the system involving only autonomous vehicles. Additionally, we demonstrate how the system can be extended to allow high-priority vehicles such as ambulances, police cars, or fire trucks through more quickly without placing undue burden on other vehicles. Both augmentations are fully implemented and tested in our custom simulator, and we present detailed experimental results attesting to their effectiveness.",project-academic
10.1016/J.KNOSYS.2018.04.015,2018-08-01,a,Elsevier,teaching a vehicle to autonomously drift a data based approach using neural networks," Abstract None None This paper presents a novel approach to teach a vehicle how to drift, in a similar manner that professional drivers do. Specifically, a hybrid structure formed by a Model Predictive Controller and feedforward Neural Networks is employed for this purpose. The novelty of this work lies in a) the adoption of a data-based approach to achieve autonomous drifting along a wide range of road radii and body slip angles, and b) in the implementation of a road terrain classifier to adjust the system actuation depending on the current friction characteristics. The presented drift control system is implemented in a multi-actuated ground vehicle equipped with active front steering and in-wheel electric motors and trained to drift by a real test driver using a driver-in-the-loop setup. Its performance is verified in the simulation environment IPG-CarMaker through different open loop and path following drifting manoeuvres.",project-academic
10.1109/ITSC.2018.8569665,2018-11-01,p,IEEE,monocular fisheye camera depth estimation using sparse lidar supervision," Near-field depth estimation around a self-driving car is an important function that can be achieved by four wide-angle fisheye cameras having a field of view of over 180°. Depth estimation based on convolutional neural networks (CNNs) produce state of the art results, but progress is hindered because depth annotation cannot be obtained manually. Synthetic datasets are commonly used but they have limitations. For instance, they do not capture the extensive variability in the appearance of objects like vehicles present in real datasets. There is also a domain shift while performing inference on natural images illustrated by many attempts to handle the domain adaptation explicitly. In this work, we explore an alternate approach of training using sparse LiDAR data as ground truth for depth estimation for fisheye camera. We built our own dataset using our self-driving car setup which has a 64-beam Velodyne LiDAR and four wide angle fisheye cameras. To handle the difference in view-points of LiDAR and fisheye camera, an occlusion resolution mechanism was implemented. We started with Eigen's multiscale convolutional network architecture [1] and improved by modifying activation function and optimizer. We obtained promising results on our dataset with RMSE errors comparable to the state-of-the-art results obtained on KITTI.",project-academic
,2019-01-15,,,deep reinforcement learning based low speed vehicle following decision making method," The invention discloses a deep reinforcement learning-based low-speed vehicle following decision-making method, which is implemented in the following manner: at first, receiving position, speed and acceleration information of front and back vehicles as an environmental state in real time through the Internet of vehicles, and expressing a present state and behavior of an unmanned vehicle; then, constructing an Actor-Critic framework-based deep reinforcement learning structure; and finally, selecting, by Actor, an appropriate action according to the present environmental state, and continuouslyperforming training and learning through an evaluation made by Critic, thereby obtaining an optimal control strategy to ensure that the unmanned vehicle can be kept at a certain safe distance away from the front and back vehicles and implement automatic low-speed running of the vehicle following the front vehicle under an urban congestion working condition. According to the deep reinforcement learning-based low-speed vehicle following decision-making method, the driving comfort is improved, the traffic safety is also ensured, and the clarity of a congested lane is further improved.",project-academic
10.3390/E23060737,2021-06-11,a,Multidisciplinary Digital Publishing Institute,improved q learning algorithm based on approximate state matching in agricultural plant protection environment," An Unmanned Aerial Vehicle (UAV) can greatly reduce manpower in the agricultural plant protection such as watering, sowing, and pesticide spraying. It is essential to develop a Decision-making Support System (DSS) for UAVs to help them choose the correct action in states according to the policy. In an unknown environment, the method of formulating rules for UAVs to help them choose actions is not applicable, and it is a feasible solution to obtain the optimal policy through reinforcement learning. However, experiments show that the existing reinforcement learning algorithms cannot get the optimal policy for a UAV in the agricultural plant protection environment. In this work we propose an improved Q-learning algorithm based on similar state matching, and we prove theoretically that there has a greater probability for UAV choosing the optimal action according to the policy learned by the algorithm we proposed than the classic Q-learning algorithm in the agricultural plant protection environment. This proposed algorithm is implemented and tested on datasets that are evenly distributed based on real UAV parameters and real farm information. The performance evaluation of the algorithm is discussed in detail. Experimental results show that the algorithm we proposed can efficiently learn the optimal policy for UAVs in the agricultural plant protection environment.",project-academic
10.3390/APP10196997,2020-10-07,a,Multidisciplinary Digital Publishing Institute,deep learning for traffic sign recognition based on spatial pyramid pooling with scale analysis," In the area of traffic sign detection (TSD) methods, deep learning has been implemented and achieves outstanding performance. The detection of a traffic sign, as it has a dual function in monitoring and directing the driver, is a big concern for driver support systems. A core feature of autonomous vehicle systems is the identification of the traffic sign. This article focuses on the prohibitive sign. The objective is to detect in real-time and reduce processing time considerably. In this study, we implement the spatial pyramid pooling (SPP) principle to boost Yolo V3’s backbone network for the extraction of functionality. Our work uses SPP for more comprehensive learning of multiscale object features. Then, perform a comparative investigation of Yolo V3 and Yolo V3 SPP across various scales to recognize the prohibitory sign. Comparisons with Yolo V3 SPP models reveal that their mean average precision (mAP) is higher than Yolo V3. Furthermore, the test accuracy findings indicate that the Yolo V3 SPP model performs better than Yolo V3 for different sizes.",project-academic
10.1145/3097983.3105812,2017-08-04,p,ACM,planning and learning under uncertainty theory and practice," This talk will describe recent progress on modeling, planning, learning, and control of autonomous systems operating in dynamic environments, with an emphasis on addressing the challenges faced on various timescales. For example, autonomous robotic agents need to plan/execute safe paths and avoid imminent collisions given noisy sensory information (short timescale), learn how to interact with other agents (possibly humans) with intents that are not known (medium timescale), and perform complex cooperative tasks given imperfect models and knowledge of the environment and teammate actions (long timescale). These tasks are often constrained to be done using onboard computation and perception, which can add significant complexity to the system. The talk will highlight several recently developed solutions to these challenges that have been implemented to demonstrate high-speed agile flight of a quadrotor in unknown, cluttered environments, autonomous navigation of a ground vehicle in complex indoor environments alongside pedestrians, and real-time cooperative multiagent planning with an onboard deep learning-based perception system.",project-academic
10.1109/EIT48999.2020.9208241,2020-07-01,p,IEEE,integrated framework of autonomous vehicle with traffic sign recognition in simulation environment," This study proposes an integrated framework for autonomous vehicle research in a simulated environment. There has been much research on the simulations of vehicles and environments, the recognition of traffic signs, and the lateral/longitudinal controls of a vehicle. Yet, not many systems are available for autonomous vehicle researchers to test and improve their algorithms in a realistic simulated environment with sensor suites in their own car model. We aim to provide an integrated framework for a programmable autonomous vehicle in a simulated environment. The simulated vehicle is capable of autonomous driving with traffic sign recognition using deep learning-based object detection capability as well as lateral and longitudinal controllers. To show the feasibility of the proposed system, we built a simulated robotic vehicle with an environment where traffic signs are placed alongside a road. We also integrated a module for object detection and recognition to determine the longitudinal behavior of the vehicle. In addition, the current study implemented a lateral controller based on a convolutional neural network for the vehicle to make it drive by itself. We believe that the proposed integrated framework can be utilized by researchers and educators and lower entry barriers in the prosperous autonomous vehicle research.",project-academic
,2018-03-06,,,phased array identification method and system," The invention provides a phased array identification method and system to realize object motion recognition including gesture recognition, automotive anti-collision recognition, collision avoidance and anti-attack recognition of an unmanned aerial vehicle, and smart missile and ship collision prevention recognition. The system is composed of a phased array antenna array, a phased array T/R assembly array and a signal processing system. A phased array millimeter wave is emitted and a millimeter wave reflected by a detected object is received; and calculation is carried out to determine a spacecoordinate of the detected object. The calculation includes one based on an artificial intelligence algorithm and is implemented by steps of target recognition, correction, searching, tracking, and gazing and the like. The signal processing system includes a Von's computer, a non-Von's computer, a neural network, and an artificial intelligence system. The phased array identification system can bemanufactured into a two-in-one MMIC chip and a three-in-one SoC MMIC chip.",project-academic
10.1016/J.OCEANENG.2021.109049,2021-08-01,a,Pergamon,a fault diagnosis method based on attention mechanism with application in qianlong 2 autonomous underwater vehicle," Abstract None None This study proposed a fault diagnosis method based on deep learning and attention mechanism for autonomous underwater vehicle (AUV). Firstly, a data attention mechanism is proposed to introduce dynamic weighting coefficients of monitoring variables to realize dynamic decorrelation. Then, the automatic feature engineering is realized by a bi-directional gated recurrent unit (GRU) network to acquire the time dynamic characteristics of monitoring variables. Finally, fault detection is implemented via multi-layer perceptron (MLP). With respect to fault identification, this study embeds a spatial attention mechanism in the fault detection network to capture the semantic relationship between monitoring variables and faults, and fault identification result can be obtained by parsing this semantic relationship. We present a new loss function and training strategy for cooperation between the fault detection and identification tasks. The proposed method is validated on the monitoring data of Qianlong-2 AUV obtained during the mission in the South China Sea, which shows the effectiveness and superiority of the method.",project-academic
10.1109/INISTA.2014.6873613,2014-06-23,p,IEEE,fuzzy logic based design of classical behaviors for mobile robots in ros middleware," Autonomous mobile vehicles are used in many applications to realize special tasks. These tasks involve obstacle avoidance, target reaching and/or tracking. Such vehicles include the use of artificial intelligence to assist the vehicle's operator. Fuzzy logic can be used in the design of an autonomous vehicle to improve the classical control mechanisms. Classical robot control/decision mechanisms can give imperfect results due to sensor compensation errors or calculation costs. These drawbacks can be eliminated by using a combined fuzzy inference. In this study, we have modified the mobile robot ATEKS, which is an intelligent wheelchair, by introducing three fuzzy inference systems to realize goal reaching, obstacle avoidance and a controller for combined behavior selection. Designed fuzzy control system has been implemented on Robot Operating System (ROS) under Ubuntu 12.04 operating system and tested under Gazebo simulation platform. Simulation results verified faithful behavior outputs of ATEKS.",project-academic
10.24018/EJFOOD.2020.2.3.45,2020-06-19,a,European Open Access Publishing (Europa Publishing),deep learning based self driving car jetbot with nvidia ai board to deliver items at agricultural workplace with object finding and avoidance functions," In this study, we attempt to develop a deep learning-based self-driving car system to deliver items (e.g., harvested onions, agri-tools, PET bottles) to agricultural (agri-) workers at an agri-workplace. The system is based around a car-shaped robot, JetBot, with an NVIDIA artificial intelligence (AI) oriented board. JetBot can find diverse objects and avoid them. We implemented experimental trials at a real warehouse where various items (glove, boot, sickle (falx), scissors, and hoe), called obstacles, were scattered. The assumed agri-worker was a man suspending dried onions on a beam. Specifically, we developed a system focusing on the function of precisely detecting obstacles with deep learning-based techniques (techs), self-avoidance, and automatic delivery of small items for manual agri-workers and managers. Both the car-shaped figure and the deep learning-based obstacles-avoidance function differ from existing mobile agri-machine techs and products with respect to their main aims and structural features. Their advantages are their low costs in comparison with past similar mechanical systems found in the literature and similar commercial goods. The robot is extremely agile and easily identifies and learns obstacles. Additionally, the JetBot kit is a minimal product and includes a feature allowing users to arbitrarily expand and change functions and mechanical settings.
This study consists of six phases: (1) designing and confirming the validity of the entire system, (2) constructing and tuning various minor system settings (e.g., programs and JetBot specifications), (3) accumulating obstacle picture data, (4) executing deep learning, (5) conducting experiments in an indoor warehouse to simulate a real agri-working situation, and (6) assessing and discussing the trial data quantitatively (presenting the success and error rates of the trials) and qualitatively. We consider that from the limited trials, the system can be judged as valid to some extent in certain situations. However, we were unable to perform more broad or generalizable experiments (e.g., execution at mud farmlands and running JetBot on non-flat floor). We present experimental ranges for the success ratio of these trials, particularly noting crashed obstacle types and other error types. We were also able to observe features of the system’s practical operations. The novel achievements of this study lie in the fusion of recent deep learning-based agricultural informatics. In the future, agri-workers and their managers could use the proposed system in real agri-places as a common automatic delivering system. Furthermore, we believe, by combining this application with other existing systems, future agri-fields and other workplaces could become more comfortable and secure (e.g., delivering water bottles could avoid heat (stress) disorders).",project-academic
10.1109/IVS.2019.8813897,2019-06-09,p,IEEE,end to end deep learning applied in autonomous navigation using multi cameras system with rgb and depth images," The present work demonstrates how an autonomous navigation system of ‘End-to-End’ deep learning principles is directly improved in its response process, depending on the information obtained by different input images configurations. For this, a methodology was developed to allow working with RGB and depth images, which were obtained through a Microsoft Kinect V2 sensor device. Three cameras were used for this experiment. The images of the different cameras were concatenated or grouped, generating new and different input configurations from the vision system. To develop the presented methodology, two support and validation systems were implemented. Through the process of computer simulation, it was able to test the first approaches and define the most important ones. In order to validate the proposed methodology and solutions in real world situations, a 1/4 scale automotive vehicle was prototyped. Finally, the experiments shows the importance of the use of multi-cameras systems for a better performance of autonomous navigation systems based on End-to-End learning approach, heaving an average error of 2.41 degrees in the best configuration tested, with three RGB cameras.",project-academic
,2019-01-01,a,,end to end deep learning applied in autonomous navigation using multi cameras system with rgb and depth images," The present work demonstrates how an autonomous navigation system of ‘End-to-End’ deep learning principles is directly improved in its response process, depending on the information obtained by different input images configurations. For this, a methodology was developed to allow working with RGB and depth images, which were obtained through a Microsoft Kinect V2 sensor device. Three cameras were used for this experiment. The images of the different cameras were concatenated or grouped, generating new and different input configurations from the vision system. To develop the presented methodology, two support and validation systems were implemented. Through the process of computer simulation, it was able to test the first approaches and define the most important ones. In order to validate the proposed methodology and solutions in real world situations, a 1/4 scale automotive vehicle was prototyped. Finally, the experiments shows the importance of the use of multi-cameras systems for a better performance of autonomous navigation systems based on End-to-End learning approach, heaving an average error of 2.41 degrees in the best configuration tested, with three RGB cameras.",project-academic
,2016-12-18,a,University of Oklahoma,fully autonomous self powered intelligent wireless sensor for real time traffic surveillance in smart cities," Reliable, real-time traffic surveillance is an integral and crucial function of the 21st century intelligent transportation systems (ITS) network. This technology facilitates instantaneous decision-making, improves roadway efficiency, and maximizes existing transportation infrastructure capacity, making transportation systems safe, efficient, and more reliable. Given the rapidly approaching era of smart cities, the work detailed in this dissertation is timely in that it reports on the design, development, and implementation of a novel, fully-autonomous, self-powered intelligent wireless sensor for real-time traffic surveillance. Multi-disciplinary, innovative integration of state-of-the-art, ultra-low-power embedded systems, smart physical sensors, and the wireless sensor network—powered by intelligent algorithms—are the basis of the developed Intelligent Vehicle Counting and Classification Sensor (iVCCS) platform. The sensor combines an energy-harvesting subsystem to extract energy from multiple sources and enable sensor node self-powering aimed at potentially indefinite life. A wireless power receiver was also integrated to remotely charge the sensor’s primary battery. Reliable and computationally efficient intelligent algorithms for vehicle detection, speed and length estimation, vehicle classification, vehicle re-identification, travel-time estimation, time-synchronization, and drift compensation were fully developed, integrated, and evaluated. Several length-based vehicle classification schemes particular to the state of Oklahoma were developed, implemented, and evaluated using machine learning algorithms and probabilistic modeling of vehicle magnetic length. A feature extraction employing different techniques was developed to determine suitable and efficient features for magnetic signature-based vehicle re-identification. Additionally, two vehicle re-identification models based on matching vehicle magnetic signature from a single magnetometer were developed. Comprehensive system evaluation and extensive data analyses were performed to fine-tune and validate the sensor, ensuring reliable and robust operation. Several field studies were conducted under various scenarios and traffic conditions on a number of highways and urban roads and resulted in 99.98% detection accuracy, 97.4782% speed estimation accuracy, and 97.6951% classification rate when binning vehicles into four groups based on their magnetic length. Threshold-based, re-identification results revealed 65.25%~100% identification rate for a window of 25~500 vehicles. Voting-based, re-identification evaluation resulted in 90~100% identification rate for a window of 25~500 vehicles. The developed platform is portable and cost-effective. A single sensor node costs only $30 and can be installed for short-term use (e.g., work zone safety, traffic flow studies, roadway and bridge design, traffic management in atypical situations), as well as long-term use (e.g., collision avoidance at intersections, traffic monitoring) on highways, roadways, or roadside…",project-academic
10.3390/MACHINES7020024,2019-04-15,a,MDPI AG,neural network based learning from demonstration of an autonomous ground robot," This paper presents and experimentally validates a concept of end-to-end imitation learning for autonomous systems by using a composite architecture of convolutional neural network (ConvNet) and Long Short Term Memory (LSTM) neural network. In particular, a spatio-temporal deep neural network is developed, which learns to imitate the policy used by a human supervisor to drive a car-like robot in a maze environment. The spatial and temporal components of the imitation model are learned by using deep convolutional network and recurrent neural network architectures, respectively. The imitation model learns the policy of a human supervisor as a function of laser light detection and ranging (LIDAR) data, which is then used in real time to drive a robot in an autonomous fashion in a laboratory setting. The performance of the proposed model for imitation learning is compared with that of several other state-of-the-art methods, reported in the machine learning literature, for spatial and temporal modeling. The learned policy is implemented on a robot using a Nvidia Jetson TX2 board which, in turn, is validated on test tracks. The proposed spatio-temporal model outperforms several other off-the-shelf machine learning techniques to learn the policy.",project-academic
10.1016/J.CONENGPRAC.2020.104630,2020-11-01,a,Pergamon,vision based robust control framework based on deep reinforcement learning applied to autonomous ground vehicles," Abstract None None Given the recent advances in computer vision, image processing and control systems, self-driving vehicles has been one of the most promising and challenging research topics nowadays. The design of vision-based robust controllers to keep an autonomous car in the center of the lane, despite uncertainties and disturbances, is still an ongoing challenge. This paper presents a hybrid control architecture that combines Deep Reinforcement Learning (DRL) and Robust Linear Quadratic Regulator (RLQR) for vision-based lateral control of an autonomous vehicle. Evolutionary estimation is used to model the vehicle uncertainties. For performance comparison, a DRL method and three other hybrid controllers are also evaluated. The inputs for each controller are real-time semantically segmented RGB camera images which serve as the basis to calculate continuous steering actions to keep the vehicle on the center of the lane with a constant velocity. Simulation results show that the proposed hybrid RLQR with evolutionary estimation of uncertainties architecture outperforms the other algorithms implemented. It presents lower tracking errors, smoother steering inputs, total collision avoidance and better generalization in new urban environments. Furthermore, it significantly decreases the required training time.",project-academic
,2020-08-03,a,,lidar point cloud processing based on projection methods a comparison," An accurate and rapid-response perception system is fundamental for autonomous vehicles to operate safely. 3D object detection methods handle point clouds given by LiDAR sensors to provide accurate depth and position information for each detection, together with its dimensions and classification. The information is then used to track vehicles and other obstacles in the surroundings of the autonomous vehicle, and also to feed control units that guarantee collision avoidance and motion planning. Nowadays, object detection systems can be divided into two main categories. The first ones are the geometric based, which retrieve the obstacles using geometric and morphological operations on the 3D points. The seconds are the deep learning-based, which process the 3D points, or an elaboration of the 3D point-cloud, with deep learning techniques to retrieve a set of obstacles. This paper presents a comparison between those two approaches, presenting one implementation of each class on a real autonomous vehicle. Accuracy of the estimates of the algorithms has been evaluated with experimental tests carried in the Monza ENI circuit. The position of the ego vehicle and the obstacle is given by GPS sensors with RTK correction, which guarantees an accurate ground truth for the comparison. Both algorithms have been implemented on ROS and run on a consumer laptop.",project-academic
10.23919/AEITAUTOMOTIVE50086.2020.9307387,2020-11-18,p,IEEE,lidar point cloud processing based on projection methods a comparison," An accurate and rapid-response perception system is fundamental for autonomous vehicles to operate safely. 3D object detection methods handle point clouds given by LiDAR sensors to provide accurate depth and position information for each detection, together with its dimensions and classification. The information is then used to track vehicles and other obstacles in the surroundings of the autonomous vehicle, and also to feed control units that guarantee collision avoidance and motion planning. Nowadays, object detection systems can be divided into two main categories. The first ones are the geometric based, which retrieve the obstacles using geometric and morphological operations on the 3D points. The seconds are the deep learning-based, which process the 3D points, or an elaboration of the 3D point-cloud, with deep learning techniques to retrieve a set of obstacles. This paper presents a comparison between those two approaches, presenting one implementation of each class on a real autonomous vehicle. Accuracy of the estimates of the algorithms has been evaluated with experimental tests carried in the Monza ENI circuit. The positions of the ego vehicle and the obstacle are given by GPS sensors with real time kinematic (RTK) correction, which guarantees an accurate ground truth for the comparison. Both algorithms have been implemented on ROS and run on a consumer laptop.",project-academic
10.1109/ICRA.2019.8794446,2019-05-20,p,IEEE,a reinforcement learning approach for control of a nature inspired aerial vehicle," In this work, reinforcement learning is used to develop a position controller for an underactuated natureinspired Unmanned Aerial Vehicle (UAV). This particular configuration of UAVs achieves lift by spinning its entire body contrary to standard multi-rotors or fixed-wing aircraft. Deep Deterministic Policy Gradients (DDPG) with Ape-X Distributed Prioritized Experience Replay was used to train neural network function approximators that were implemented as the final control policy. The reinforcement learning agent was trained in simulations and directly ported over to real-life hardware. Position control tests were performed on the learned control policy and compared to a baseline PID controller. The learned controller was found to exhibit better control over the inherent oscillations that arise from the non-linear dynamics of the platform.",project-academic
10.23919/CHICC.2018.8482830,2018-07-25,p,IEEE,monocular vision based autonomous landing of quadrotor through deep reinforcement learning," An improved deep reinforcement learning (DRL) method is proposed to solve autonomous landing problem of quadrotor. Autonomous landing is a significant function for unmanned aerial vehicle (UAV) such as quadrotor. Previous solutions are mainly based on relative position calculation or the landmark detection, which either needs massive additional sensors or lacks intelligence. In this paper, we focus on realizing autonomous landing through DRL method. Whole landing process is implemented by an improved deep Q-learning network (DQN) based end-to-end control scheme. Only one down-looking camera is used to capture raw images directly as input states. An Aruco tag is placed at the landing region for feature extraction. Double network and the dueling architecture are applied to improve DQN algorithm. Besides, the reward function is well designed to fit the auto-landing scenario. The experiments show that the improved DQN can make the quadrotor land on the landmark successfully and achieve better performance while comparing to the original deep Q-learning solution.",project-academic
10.3390/S19020313,2019-01-14,a,Multidisciplinary Digital Publishing Institute,development of a recognition system for spraying areas from unmanned aerial vehicles using a machine learning approach," Unmanned aerial vehicle (UAV)-based spraying systems have recently become important for the precision application of pesticides, using machine learning approaches. Therefore, the objective of this research was to develop a machine learning system that has the advantages of high computational speed and good accuracy for recognizing spray and non-spray areas for UAV-based sprayers. A machine learning system was developed by using the mutual subspace method (MSM) for images collected from a UAV. Two target lands: agricultural croplands and orchard areas, were considered in building two classifiers for distinguishing spray and non-spray areas. The field experiments were conducted in target areas to train and test the system by using a commercial UAV (DJI Phantom 3 Pro) with an onboard 4K camera. The images were collected from low (5 m) and high (15 m) altitudes for croplands and orchards, respectively. The recognition system was divided into offline and online systems. In the offline recognition system, 74.4% accuracy was obtained for the classifiers in recognizing spray and non-spray areas for croplands. In the case of orchards, the average classifier recognition accuracy of spray and non-spray areas was 77%. On the other hand, the online recognition system performance had an average accuracy of 65.1% for croplands, and 75.1% for orchards. The computational time for the online recognition system was minimal, with an average of 0.0031 s for classifier recognition. The developed machine learning system had an average recognition accuracy of 70%, which can be implemented in an autonomous UAV spray system for recognizing spray and non-spray areas for real-time applications.",project-academic
10.1007/S11235-015-0131-5,2020-10-01,a,Springer US,traffic collisions early warning aided by small unmanned aerial vehicle companion," Most traffic surveillance systems are based on videos which captured by fixed cameras on bridges, intersections, etc. However, many traffic collisions may occur in many places without such surveillance systems, e.g., in rural highway. Researchers have developed a set of techniques to improve safety on these places, while it is still not enough to reduce collision risk. Based on a novel concept, this paper proposes a traffic collisions early warning scheme aided by small unmanned aerial vehicle (UAV) companion. Basically, it is a vision-based driver assistance system, and the difference in comparison with the available schemes lies in the camera is flying along with the host vehicle. In particular, the system’s framework and the vision-based vehicle collision detection algorithm are proposed. The small UAV works in two switchable modes, i.e., high speed flight or low speed motion. The high speed flight corresponds to the host vehicle moving in highway, while the low speed motion includes hover, vertical takeoff and landing. In addition, as the on-line machine learning is applied, the detection procedure can be implemented in real-time, which is critical in practical applications. Extensive experimental results and examples demonstrate the effectiveness of the proposed method, and its real-time performance outperforms typical tracking methods such as that based on Gaussian mixture model. Moreover, this scheme can be easily extended for some other similar application scenarios.",project-academic
10.1186/2193-1801-2-188,2013-04-27,a,Springer International Publishing,neuro fuzzy controller to navigate an unmanned vehicle," A Neuro-fuzzy control method for an Unmanned Vehicle (UV) simulation is described. The objective is guiding an autonomous vehicle to a desired destination along a desired path in an environment characterized by a terrain and a set of distinct objects, such as obstacles like donkey traffic lights and cars circulating in the trajectory. The autonomous navigate ability and road following precision are mainly influenced by its control strategy and real-time control performance. Fuzzy Logic Controller can very well describe the desired system behavior with simple “if-then” relations owing the designer to derive “if-then” rules manually by trial and error. On the other hand, Neural Networks perform function approximation of a system but cannot interpret the solution obtained neither check if its solution is plausible. The two approaches are complementary. Combining them, Neural Networks will allow learning capability while Fuzzy-Logic will bring knowledge representation (Neuro-Fuzzy). In this paper, an artificial neural network fuzzy inference system (ANFIS) controller is described and implemented to navigate the autonomous vehicle. Results show several improvements in the control system adjusted by neuro-fuzzy techniques in comparison to the previous methods like Artificial Neural Network (ANN).",project-academic
10.1109/TCSI.2019.2921714,2019-06-19,a,IEEE,a real time 17 scale object detection accelerator with adaptive 2000 stage classification in 65 nm cmos," Machine learning has become ubiquitous in applications including object detection, image/video classification, and natural language processing. While machine learning algorithms have been successfully used in many practical applications, accurate, fast, and low-power hardware implementations of such algorithms is still a challenging task, especially for mobile systems such as Internet of Things (IoT), autonomous vehicles, and smart drones. This paper presents an energy-efficient programmable ASIC accelerator for object detection. Our ASIC accelerator supports multi-class (e.g., face, traffic sign, car license plate, and pedestrian) that are programmable, many-object (up to 50) in one image with different sizes (17-scale support with 6 down-/11 up-scaling), and high accuracy (AP of 0.87/0.81/0.72/0.76 for FDDB/AFW/BTSD/Caltech datasets). We designed an integral channel detector with 2,000 classifiers for rigid boosted templates, where the number of stages used for classification can be adaptively controlled depending on the content of the search window. This can be implemented with a more modular hardware, compared to support vector machine (SVM) and deformable parts model (DPM) designs. By jointly optimizing the algorithm and the efficient hardware architecture, the prototype chip implemented in 65nm CMOS demonstrates real-time object detection of 20–50 frames/s with low power consumption of 22.5–181.7 mW (0.54–1.75 nJ/pixel) at 0.58–1.1 V supply.",project-academic
10.1109/IVS.2005.1505140,2005-06-06,p,IEEE,turning the corner improved intersection control for autonomous vehicles," Traffic congestion is one of the leading causes of lost productivity and decreased standard of living in urban settings. Recent advances in artificial intelligence suggest vehicle navigation by autonomous agents will be possible in the near future. In a previous paper, we proposed a reservation-based system for alleviating traffic congestion, specifically at intersections. This paper extends our prototype implementation in several ways with the aim of making it more implementable in the real world. In particular, we 1) add the ability of vehicles to turn, 2) enable them to accelerate while in the intersection, 3) give a better sensor model and communication-efficient heuristic to our driver agent, and 4) augment their interaction capabilities with a detailed protocol such that the vehicles do not need to know anything about the intersection control policy. The use of this protocol limits the interaction of the driver agent and the intersection manager to the extent that it is a reasonable approximation of reliable wireless communication. We then use this protocol to implement a new control policy: the stop sign. All three improvements are fully implemented and tested, and we present detailed empirical results validating their effectiveness.",project-academic
10.1109/ACCESS.2019.2895832,2019-01-29,a,Institute of Electrical and Electronics Engineers (IEEE),in vehicle cognitive route decision using fuzzy modeling and artificial neural network," The departments of transportation worldwide are facing various challenges despite introducing and incorporating various vehicular features. One of such challenges is to make vehicles autonomous, intelligent, and capable of self-learning to evolve their knowledge repository. In this paper, human cognition is proposed to be implemented in vehicles so that they can perform human-like decisions. Therefore, the process of vehicular route decision is debated cognitively in order to provide route information intelligently. The in-vehicle routes provided by the GPS are not optimal and lack on-demand user requirements. GPS connectivity issues, in certain conditions, make it difficult for vehicles to take real-time decisions. This leads to the idea of self-decision by the vehicle controller. We propose a cognitive framework for vehicles to make self-decisions that use cognitive memory for storing route experiences. The framework strengthens the existing in-vehicle route finding capability and its provision in a more realistic manner. The user is provided with all available route-related information that is required for the journey. In addition, the route episodes are learned, stored, and accessed inside the cognitive memory for an optimal route provision. The vehicle learns about the routes and matures with route-experience by itself with the passage of time. In simulations, fuzzy modeling is used to validate the impact of cognitive parameters over static/conventional parameters. Moreover, artificial neural networks are used to minimize the error rate in learning to achieve cognitive route decisions. The proposed in-vehicle cognitive framework outperforms the existing route provision system that is inadequate and provokes the user's anxieties during driving. Besides, the proposed scheme gradually gets mature in delivering optimal as well as latest route-related information.",project-academic
10.1109/RADARCONF2043947.2020.9266686,2020-09-21,p,IEEE,combined object detection and tracking on high resolution radar imagery for autonomous driving using deep neural networks and particle filters," This paper presents a novel approach for target detection in radar imagery, which combines an object detector and a multi target particle filter tracker. Object detection is implemented using deep neural networks, as opposed to the traditional radar object detection methods. This technique is applied to a dataset collected with a 79 GHz FMCW radar mounted on a vehicle. In this approach, object detection and tracking of roadside objects are performed in an alternating fashion to reduce the computational load required by the real time processing. The results and the thorough analysis of the parameters showed that this approach is feasible and can be successfully utilised in radar imagery for autonomous driving.",project-academic
10.1186/S13638-021-01971-X,2021-12-01,a,SpringerOpen,caramel results on a secure architecture for connected and autonomous vehicles detecting gps spoofing attacks," The main goal of the H2020-CARAMEL project is to address the cybersecurity gaps introduced by the new technological domains adopted by modern vehicles applying, among others, advanced Artificial Intelligence and Machine Learning techniques. As a result, CARAMEL enhances the protection against threats related to automated driving, smart charging of Electric Vehicles, and communication among vehicles or between vehicles and the roadside infrastructure. This work focuses on the latter and presents the CARAMEL architecture aiming at assessing the integrity of the information transmitted by vehicles, as well as at improving the security and privacy of communication for connected and autonomous driving. The proposed architecture includes: (1) multi-radio access technology capabilities, with simultaneous 802.11p and LTE-Uu support, enabled by the connectivity infrastructure; (2) a MEC platform, where, among others, algorithms for detecting attacks are implemented; (3) an intelligent On-Board Unit with anti-hacking features inside the vehicle; (4) a Public Key Infrastructure that validates in real-time the integrity of vehicle’s data transmissions. As an indicative application, the interaction between the entities of the CARAMEL architecture is showcased in case of a GPS spoofing attack scenario. Adopted attack detection techniques exploit robust in-vehicle and cooperative approaches that do not rely on encrypted GPS signals, but only on measurements available in the CARAMEL architecture.",project-academic
10.1109/ICCES.2018.8639313,2018-12-01,p,IEEE,a deep learning approach for vehicle detection," The autonomous driving needs some several features to achieve driving without human interference. One of these features is vehicle classification and detection since the target of this process is to help the CPU ’’Central Processing Unit"" of the vehicle to see what is around the vehicle, in order to evaluate the situation to take the best decision for each situation in real time. This paper is focusing on the classification process of the video-based vehicle detection, to achieve that, different deep learning techniques have been implemented which are known as convolutional neural networks (CNN) architectures. These CNN architectures are ResNet, Inception-ResnetV2,InceptionV3, NASNet, MobileNetV2, and PNASNet architectures. Also there are two different datasets have been trained in these architectures to evaluate them. These datasets are Kitti dataset to train on car detection only, in additions to MIO-TCD dataset to detect various types of vehicles. The Inception-ResnetV2 have shown the best performance in our results.",project-academic
10.1007/978-3-319-69266-1_13,2016-09-21,p,"Springer, Cham",object segmentation for vehicle video and dental cbct by neuromorphic convolutional recurrent neural network," The neuromorphic visual processing inspired by the biological vision system of brain offers an alternative process into applying machine vision in various environments. With the emerging interests on transportation safety enhancement of Advanced Driver Assistance System or a driverless car, the neuromorphic convolutional recurrent neural networks was proposed and tested for the night-time vehicle or VRU detection. The effectiveness of proposed convolutional-recurrent neural networks of neuromorphic visual processing was evaluated successfully for the object detection without optimized complex template matching or prior denoising neural network. The real life road video dataset at night time demonstrated 98% of successful detection/segmentation rate with 0% False Positive. The robust performance of proposed convolutional-recurrent neural network was also applied successfully to the tooth segmentation of dental X-ray 3D CT including the gum region. The feature extraction was based on neuromorphic visual processing filters of either hand-cut filters mimicking the visual cortex experimentation or the auto-encoder filter trained by partial X-ray images. The consistent performance of either hand-cut filters or the small auto-encoder filters demonstrated the feasibility of real-time and robust neuromorphic vision implemented by either the small embedded system or the portable computer.",project-academic
10.1007/S11554-021-01110-1,2021-05-31,a,Springer Berlin Heidelberg,nighttime object detection system with lightweight deep network for internet of vehicles," Autonomous driving systems in internet of vehicles (IoV) applications usually adopt a cloud computing mode. In these systems, information got at the edge of the cloud computing center for data analysis and situation response. However, the conventional IoV face enormous challenges to meet the requirements in terms of storage, communication, and computing problems because of the considerable amount of information on the traffic environment. The environment perception during the nighttime is poorer than that during the daytime that this problem also requires addressing. To solve these problems, we propose a nighttime object detection scheme based on a lightweight deep learning model in the edge computing mode. First, the pedestrian detection and the vehicle detection algorithm that using the thermal images based on the YOLO architecture. We can implement the model on edge devices that can achieve real-time detection through the designed lightweight strategy. Next, a spatial prior information and temporal prior information into the detection algorithm and divide the frames into key and non-key frames to increase the performance and speed of the system simultaneously. Finally, we implemented the detection network for performance and feasibility verification on the Jetson TX2 edge device. The experimental results show that the proposed system can achieve real-time and high-accuracy object detection on edge devices.",project-academic
10.1109/INDICON.2015.7443253,2015-12-01,p,IEEE,particle swarm optimization for the control of a swarm of biological robots," The objective of this paper is to discuss the control of a swarm of robots using the Particle Swarm Optimization (PSO) technique. The authors present fundamental research being conducted at the Autonomous Vehicle Systems Laboratory located at University of the Incarnate Word in developing biologically inspired robots emulating insect foraging and search behavior. PSO technique is used in order to characterize the artificial intelligence and social behaviors implemented in the multi-robot systems. Additionally, the authors will discuss novel approaches for integrating the results into the realm of collaborative and formation control of autonomous ground and air vehicles.",project-academic
10.1109/YAC.2019.8787608,2019-06-06,p,IEEE,design and implementation of vehicle unlocking system based on face recognition," There are some shortcomings in both safety and convenience for existing vehicle unlocking methods, mostly due to the separation between the vehicle and its key. As an improvement, we propose a vehicle unlocking system based on face recognition. The system includes hardware and software. The hardware scheme adopts a modular design, and try to make full use of existing devices of the autonomous driving system and ADAS. The software uses two different deep learning algorithms: FaceNet to verify facial identity, and modified ResNet to distinguish between real faces and secondary faces. A prototype is implemented using the embedded platform Raspberry Pi, and a series of tests are carried out on it. The prototype verifies the feasibility of the hardware scheme and the effectiveness of the algorithms. Test results show that the system is available day and night, quick in unlocking, safe and reliable.",project-academic
10.1109/TVT.2021.3062418,2021-02-26,a,Institute of Electrical and Electronics Engineers (IEEE),orchestrated scheduling and multi agent deep reinforcement learning for cloud assisted multi uav charging systems," This paper proposes a cloud-assisted joint charging scheduling and energy management framework for unmanned aerial vehicle (UAV) networks. For charging the UAVs those are extremely power hungry, charging towers are considered for plug-and-play charging during run-time operations. The charging towers should be cost-effective, thus it is equipped with photovoltaic power generation and energy storage systems functionalities. Furthermore, the towers should be cooperative for more cost-effectiveness by intelligent energy sharing. Based on the needs and setting, this paper proposes 1) charging scheduling between UAVs and towers and 2) cooperative energy managements among towers. For charging scheduling, the UAVs and towers should be scheduled for maximizing charging energy amounts and the scheduled pairs should determine charging energy allocation amounts. Here, two decisions are correlated, None i.e. , it is a non-convex problem. We re-formulate the non-convex to convex for guaranteeing optimal solutions. Lastly, the cooperative energy sharing among towers is designed and implemented with multi-agent deep reinforcement learning and then intelligent energy sharing can be realized. We can observe that the two methods are related and it should be managed, coordinated, and harmonized by a centralized orchestration manager under the consideration of fairness, energy-efficiency, and cost-effectiveness. Our data-intensive performance evaluation verifies that our proposed framework achieves desired performance.",project-academic
,2020-08-14,a,,an improved deep convolutional neural network based autonomous road inspection scheme using unmanned aerial vehicles," Advancements in artificial intelligence (AI) gives a great opportunity to develop an autonomous devices. The contribution of this work is an improved convolutional neural network (CNN) model and its implementation for the detection of road cracks, potholes, and yellow lane in the road. The purpose of yellow lane detection and tracking is to realize autonomous navigation of unmanned aerial vehicle (UAV) by following yellow lane while detecting and reporting the road cracks and potholes to the server through WIFI or 5G medium. The fabrication of own data set is a hectic and time-consuming task. The data set is created, labeled and trained using default and an improved model. The performance of both these models is benchmarked with respect to accuracy, mean average precision (mAP) and detection time. In the testing phase, it was observed that the performance of the improved model is better in respect of accuracy and mAP. The improved model is implemented in UAV using the robot operating system for the autonomous detection of potholes and cracks in roads via UAV front camera vision in real-time.",project-academic
10.1109/CODIT.2018.8394934,2018-04-10,p,IEEE,adaptive dynamic programming based motion control of autonomous underwater vehicles," In this paper, Adaptive Dynamic Programming (ADP) technique is utilized to achieve optimal motion control of Autonomous Underwater Vehicle (AUV) System. The paper proposes a model-free based method that takes into consideration the actuator input and obstacle position while tracing an optimal path. The concept of machine learning enables to develop a path-planner which aims to avoid collisions with static obstacles. The ADP approach is realized to approximate the solution of the cost functional for optimization purpose by which the positions of the locally situated obstacles need not be priori-known until they are within a designed approximation safety envelope. The methodology is implemented to achieve the path-planning objective using dynamic programming technique. The Least-squares policy method serves as a recursive algorithm to approximate the value function for the domain, providing an approach for the finite space discrete control system. The concept behind the design of an obstacle-free path finder is to generate an optimal action that minimizes the local cost, defined by a functional, under constrained optimization. The most advantageous value function is described by the Hamilton Jacobi Bellman (HJB) equation, that is impractical to solve using analytical methods. To overcome the complex calculations subject to HJB, a method based on Reinforcement Learning (RL), called ADP is implemented. This paper outlines the concept of machine learning to realize a real time obstacle avoidance system.",project-academic
10.1109/ISCAS45731.2020.9180841,2020-10-12,p,IEEE,pointnet on fpga for real time lidar point cloud processing," LiDAR sensors have been widely used in many autonomous vehicle modalities, such as perception, mapping, and localization. This paper presents an FPGA-based deep learning platform for real-time point cloud processing targeted on autonomous vehicles. The software driver for the Velodyne LiDAR sensor is modified and moved into the on-chip processor system, while the programmable logic is designed as a customized hardware accelerator. As the state-of-art deep learning algorithm for point cloud processing, PointNet is successfully implemented on the proposed FPGA platform. Targeted on a Xilinx Zynq UltraScale+ MPSoC ZCU104 development board, the FPGA implementations of PointNet achieve the computing performance of 182.1 GOPS and 280.0 GOPS for classification and segmentation respectively. The proposed design can support an input up to 4096 points per frame. The processing time is 19.8 ms for classification and 34.6 ms for segmentation, which meets the real-time requirement for most of the existing LiDAR sensors.",project-academic
,2020-05-29,a,,pointnet on fpga for real time lidar point cloud processing," LiDAR sensors have been widely used in many autonomous vehicle modalities, such as perception, mapping, and localization. This paper presents an FPGA-based deep learning platform for real-time point cloud processing targeted on autonomous vehicles. The software driver for the Velodyne LiDAR sensor is modified and moved into the on-chip processor system, while the programmable logic is designed as a customized hardware accelerator. As the state-of-art deep learning algorithm for point cloud processing, PointNet is successfully implemented on the proposed FPGA platform. Targeted on a Xilinx Zynq UltraScale+ MPSoC ZCU104 development board, the FPGA implementations of PointNet achieve the computing performance of 182.1 GOPS and 280.0 GOPS for classification and segmentation respectively. The proposed design can support an input up to 4096 points per frame. The processing time is 19.8 ms for classification and 34.6 ms for segmentation, which meets the real-time requirement for most of the existing LiDAR sensors.",project-academic
10.1109/JIOT.2020.3048050,2021-10-15,a,IEEE,deep learning based intelligent intervehicle distance control for 6g enabled cooperative autonomous driving," Research on the sixth-generation cellular networks (6G) is gaining huge momentum to achieve ubiquitous wireless connectivity. Connected autonomous vehicles (CAVs) is a critical vertical application for 6G, holding great potentials of improving road safety, road and energy efficiency. However, the stringent service requirements of CAV applications on reliability, latency, and high speed communications will present big challenges to 6G networks. New channel access algorithms and intelligent control schemes for connected vehicles are needed for 6G-supported CAV. In this article, we investigated 6G-supported cooperative driving, which is an advanced driving mode through information sharing and driving coordination. First, we quantify the delay upper bounds of 6G vehicle-to-vehicle (V2V) communications with hybrid communication and channel access technologies. A deep learning neural network is developed and trained for the fast computation of the delay bounds in real-time operations. Then, an intelligent strategy is designed to control the intervehicle distance for cooperative autonomous driving. Furthermore, we propose a Markov chain-based algorithm to predict the parameters of the system states, and also a safe distance mapping method to enable smooth vehicular speed changes. The proposed algorithms are implemented in the AirSim autonomous driving platform. Simulation results show that the proposed algorithms are effective and robust with safe and stable cooperative autonomous driving, which greatly improve the road safety, capacity, and efficiency.",project-academic
10.25394/PGS.7651997.V1,2019-06-10,a,Purdue University Graduate School,fast and robust uav to uav detection and tracking algorithm," Unmanned Aerial Vehicle (UAV) technology is being increasingly used in a wide variety of applications ranging from remote sensing, to delivery, to security. As the number of UAVs increases, there is a growing need for UAV to UAV detection and tracking systems for both collision avoidance and coordination. Among possible solutions, autonamous “see-and-avoid” systems based on low-cost high-resolution video cameras offer the important advantages of light-weight and low power sensors. However, in order to be effective, camera based “see-and-avoid” systems will require sensitive, robust, and computationally efficient algorithms for UAV to UAV detect and tracking (U2U-D&T) from a moving camera.In this thesis, we propose a general architecture for a highly accurate and computationally efficient U2U-D&T algorithms for detecting UAVs from a camera mounted on a
moving UAV platform. The thesis contains three studies of U2U-D&T algorithms.In the first study, we present a new approach to detect and track other UAVs from a
single camera in our own UAV. Given the sequence of video frames, we estimate the background motion via perspective transformation model and then identify distinctive points
in the background subtracted image to detect moving objects. We find spatio-temporal
characteristics of each moving object through optical flow matching and then classify our
targets which have very different motion compared with background. We also perform
tracking based on Kalman filter to enforce the temporal consistency on our detection. The
algorithm is tested on real videos from UAVs and results show that it is effective to detect
and track small UAVs with limited computing resources.In the second study, we present a new approach to detect and track UAVs from a single camera mounted on a different UAV. Initially, we estimate background motions via
a perspective transformation model and then identify moving object candidates in the
background subtracted image through deep learning classifier trained on manually labeled
datasets. For each moving object candidates, we find spatio-temporal traits through optical flow matching and then prune them based on their motion patterns compared with the
background. Kalman filter is applied on pruned moving objects to improve temporal consistency among the candidate detections. The algorithm was validated on video datasets
taken from a UAV. Results demonstrate that our algorithm can effectively detect and track
small UAVs with limited computing resources. The system in the third study is based on a computationally efficient pipeline consisting
of moving object detection from a motion stabilized image, classification with a hybrid
neural network, followed by Kalmann tracking. The algorithm is validated using video
data collected from multiple fixed-wing UAVs that is manually ground-truthed and publicly
available. Results indicate that the proposed algorithm can be implemented on practical
hardware and robustly achieves highly accurate detection and tracking of even distant and
faint UAVs.",project-academic
10.1109/ITSC.2019.8917492,2019-10-01,p,IEEE,hybrid physics based and data driven approach to estimate the radar cross section of vehicles," Radar technology is one of the key technologies used in automotive scene recognition for autonomous driving systems and advanced driver assistance systems (ADAS). ADAS development requires the exhaustive validation of participating radar systems, and validation through actual test driving can be expensive. Although promising as a replacement for real test driving, virtual test driving is time-consuming owing to the fact that it simulates radar systems in detail, employing physics-based electromagnetic simulation techniques. This paper describes a hybrid physics-based and data-driven approach to reduce the computation time required for such simulations. The radar cross-section (RCS) of a vehicle is chosen as a target result obtained through electromagnetic simulations. The data-driven model is implemented with a cascade of two convolutional neural networks (CNNs) which are trained using ground truth data calculated with a physics-based ray-tracing method. The ray-tracing method is employed for generating both the training data and a part of the input to one of the CNNs. The correlation coefficient between the estimated and ground truth RCSs can be approximately 0.8 while the computation time is lower than 120 ms.",project-academic
10.1109/SYSCON48628.2021.9447097,2021-04-15,p,IEEE,experimental validation of a steering control system using an adaptive fuzzy controller and computer vision," This paper proposes an adaptive steering control strategy for self-driving cars based on a Fuzzy Expert System and Reinforcement Learning. Our objective consists in deriving an appropriate control law directly from a real vehicle that allows it to navigate on several types of lanes, by controlling the position in relation to the center of the tracks and also the translation speed of the vehicle. Using an on-line Reinforcement Learning approach, the Fuzzy expert controller is derived considering the coupling and non-linearity of the model on straight and winding tracks. To do this, an embedded camera captures the images and sends them to the computer vision algorithm responsible for performing tracks detection and recognition. From that, the control references which indicate the navigation path and direction on the lane are calculated. The main contribution of this work is to apply an online reinforcement learning approach to tune and optimize the fuzzy steering controller while the vehicle navigates through different routes. Using a real vehicle equipped with an embedded computer and also the implemented web user interface, the learning evolution of the adaptive fuzzy controller can be managed remotely during trial in actual environments. Experimental results showed that the learned fuzzy expert controller controls the self-driving car during the path tracking and precisely performs the execution of different maneuvers.",project-academic
10.1109/AIPR.2016.8010547,2016-10-01,p,IEEE Computer Society,real time detection and classification of traffic light signals," Traffic light detection is an important part of Advanced Driver Assist as well as autonomous vehicle systems which ensures timely and appropriate reaction to traffic lights (TLs) in cross sections. In this paper we introduce a robust and realtime approach to detect TLs and recognize its status in complex traffic scenes solely based on image processing techniques. The proposed system uses color properties of the scene to detect TLs in real-time. An innovative technique has been developed to significantly decrease compute requirement for detection of TL color by using one Lookup Table independent of lighting conditions. Each candidate region is further analyzed, using features analysis, to segregate actual TL signals among all candidate regions. As in similar machine learning techniques, an unsupervised classifier using a set of significant features has been developed to accurately segregate circular, semi-circular, and arrow shaped TL signals without using a training dataset. The final C++ code has been implemented and optimized on intelplatform using 1920x1080 frame resolution to recognize the status of TLs during day-time and night-time scenes, achieving 95% precision and 94.7% recall at 30FPS.",project-academic
,2014-09-26,a,Compiègne,urban environment perception and navigation using robotic vision conception and implementation applied to automous vehicle," The development of autonomous vehicles capable of getting around on urban roads can provide important benefits in reducing accidents, in increasing life comfort and also in providing cost savings. Intelligent vehicles for example often base their decisions on observations obtained from various sensors such as LIDAR, GPS and Cameras. Actually, camera sensors have been receiving large attention due to they are cheap, easy to employ and provide rich data information. Inner-city environments represent an interesting but also very challenging scenario in this context,where the road layout may be very complex, the presence of objects such as trees, bicycles,cars might generate partial observations and also these observations are often noisy or even missing due to heavy occlusions. Thus, perception process by nature needs to be able to dea lwith uncertainties in the knowledge of the world around the car. While highway navigation and autonomous driving using a prior knowledge of the environment have been demonstrating successfully,understanding and navigating general inner-city scenarios with little prior knowledge remains an unsolved problem. In this thesis, this perception problem is analyzed for driving in the inner-city environments associated with the capacity to perform a safe displacement basedon decision-making process in autonomous navigation. It is designed a perception system that allows robotic-cars to drive autonomously on roads, with out the need to adapt the infrastructure,without requiring previous knowledge of the environment and considering the presenceof dynamic objects such as cars. It is proposed a novel method based on machine learning to extract the semantic context using a pair of stereo images, which is merged in an evidential grid to model the uncertainties of an unknown urban environment, applying the Dempster-Shafer theory. To make decisions in path-planning, it is applied the virtual tentacle approach to generate possible paths starting from ego-referenced car and based on it, two news strategies are proposed. First one, a new strategy to select the correct path to better avoid obstacles and tofollow the local task in the context of hybrid navigation, and second, a new closed loop control based on visual odometry and virtual tentacle is modeled to path-following execution. Finally, a complete automotive system integrating the perception, path-planning and control modules are implemented and experimentally validated in real situations using an experimental autonomous car, where the results show that the developed approach successfully performs a safe local navigation based on camera sensors.",project-academic
10.1109/I-SMAC.2018.8653736,2018-08-01,p,IEEE,a novel design of autonomous cars using iot and visual features," Autonomous car is a ground vehicle that is capable of driving without user interference. Traffic congestion and number of collisions are major issues in road traffic control due to rapid increase day-by-day. Autonomous cars provide a solution to this problem in an efficient and economical way. The proposed system utilizes mathematical models like neural networks and image processing techniques to sense the environment. This is implemented as three major components: curved road detection (steering), road sign and signal detection and obstacle detection (collision avoidance). Back Propagation is used for steering control with detection of curved roads; Haar features are used for road signal, sign detection and a distance sensor for collision avoidance. Data collected from the sensors is sent to a server for processing. Based on the result, a command is sent to the car. A GPS module attached to the car identifies the location of the car and with the help of a 3rd party location service, route to destination is identified and directions are sent to the car. Wireless networks are used to transmit data between sensors and the server. Python scripts are used to control and integrate all the units together. The designed system can attain high accuracy with real – time constraints.",project-academic
10.7467/KSAE.2019.27.5.379,2019-05-01,a,The Korean Society Of Automotive Engineers,implementation of autonomous driving system in the intersection area equipped with traffic lights," In this paper, we studied an autonomous vehicle driving system at an intersection equipped with traffic lights. We proposed deep learning based traffic light recognition algorithm, crossing/stop decision algorithm, path generation, and path following method. In addition, we implemented the proposed systems into a real vehicle environment. The main contribution of this paper is a crossing/stop decision algorithm to determine whether a test vehicle will pass through an intersection or stop in accordance with the recognized traffic light condition. This algorithm was designed based on vehicle speed and the distance between the position of the stop line and the vehicle. Ioniq PHEV, a vehicle equipped with sensors for autonomous driving, was used in order to evaluate the performance of the proposed system. The test vehicle drove through the intersection at the proving ground located in Ochang Campus, Chungbuk National University. The experimental results showed that the test vehicle successfully passed through the intersection in accordance with the traffic light status with a maximum speed of 30 kph on a straight course and a maximum speed of 10 kph on a 90° corner course.",project-academic
10.1007/978-981-13-3741-3_8,2019-01-01,a,"Springer, Singapore",futurology and future prospect of drone cps," Our ancestors could reasonably expect the future lives of their children by looking for the lives of their ancestors. Nowadays, artificial intelligence is rapidly replacing most of the jobs that humans have done with natural intelligence in the current generation. However, currently, it is hard to find out formal education about futurism to prepare for the era of artificial intelligence. Memorizing education useless in the era of artificial intelligence has been currently implemented throughout primary school to university education. The ‘CPS Revolution’ will radically change the hierarchy of human needs defined by Abraham Maslow, which leads to anywhere CPS economy that affects virtually every aspect of human life such as smart home, smart factory, smart city and smart grid etc. Due to the relatively short history, there is no realistic discussion on future prospect of drone CPS in comparison with previous industrial revolutions in terms of futurology. For instance, rather than producing cars by means of transportation, it is believed that much more weight will be devoted to the production of autonomous flying cars to enjoy leisure time. The purpose of this chapter is an attempt to outline future possibilities that are likely to occur in the drone CPS, such as exponential speed in cyber-physical bridging development and an AI instrument to speed up anywhere CPS economy. Subsequently this chapter presented future prospects of drones as a new necessity such as computer, car and smartphone.",project-academic
10.2139/SSRN.3566915,2020-04-02,a,,car auomation simulator using machine learning," Recent advancement in computation power of computer has enabled research in self – driving vehicle. A self-driving vehicle is autonomous in nature and do not need any driver for making decisions on the movement of vehicle. Self-driving vehicle reads the data by capturing images from the four sides of the car and use GPS technology to find path between given source and destination. Once path is fixed then there is need for mathematical model to make decisions on the movement of vehicle. There are two ways to make decisions. One way is to read the images and detect various objects in the image and then taking movement decisions but this method requires training on huge set of labeled images even to detect few objects. Second way is to use CNN to extract features from a given image and training a model to take decisions on movement of vehicle. Training of model using neural networks requires considerably smaller image dataset than required with object detection. Convolutional Neural Network consists of layers of neurons. Successive layers of neural network are used to extract features from the image. A simulator for self-driving car is required to simulate real world traffic conditions and then check the trained model in this environment. This simulation is necessary before model can be implemented on actual vehicle to prevent loss of life and loss of vehicle due to model inaccuracies. Real world traffic can be simulated with the help of mission games having good graphics like Grand Theft Auto. Proposed project is to develop a simulator for self-driving vehicle using Grand Theft Auto for road and traffic simulation. This project has four phases. First phase involves reading input to the game and output from the game. Second phase involves collecting data from the game. Third phase is to train a mathematical model using CNN. Finally, fourth phase is to check trained model and detecting other objects for driving a vehicle in game.",project-academic
10.1109/ICVES.2016.7548165,2016-07-10,p,IEEE,a new hopfield type neural network approach to multi goal vehicle navigation in unknown environments," A Hopfield-type neural networks (HNN) algorithm associated with histogram navigation method is proposed in this paper for real-time map building and path planning for multiple goals applications. In real world applications such as rescue robots, service robots, mining mobile robots, and mine searching robots, etc., an autonomous vehicle needs to reach multiple goals with a shortest path that, in this paper, is capable of being implemented by a HNN method with minimized overall distance. Once a global trajectory is planned, a foraging-enabled trail is created to guide the vehicle to the multiple goals. A histogram-based local navigation algorithm is employed to plan a collision-free path along the trail planned by the global path planner. A re-planning-based algorithm aims to generate trajectory while an autonomous vehicle explores through a terrain with map building in unknown environments. In this paper, simulation and experimental results demonstrate that the real-time concurrent mapping and multi-goal navigation of an autonomous vehicle is successfully performed under unknown environments.",project-academic
,2020-10-20,a,,computer and deep neural networks with driverless mechanical car design," Drastic alterations from the robotics and smart controllers attracted a radical shift in automotive tech market place that contributes to your driver less vehicles during this new era. For all these autos to safely operate from the current traffic and out of disagreeable surroundings, plenty of issues in navigation, vision, and also manage really need to go solved. To embrace it forcing car technological invention into latest research and academic, we all need cost efficient and economic mechanics. Through this circumstance we call for something that might feature present motor autos and also convert men and women driver-less cars which may attain academicians and research areas. This newspaper suggests that a portable mechanical style and style which might be manufactured and squeeze into to active autos may be implemented to get a point to come up with an autonomous motor car. Traditional cars might be altered for consideration of a driver-less automobile using assorted actuators. Popularly motors function as actuators on your automation in this motor vehicle. A pneumatic technique was constructed to automate the projected purpose aside from such types of motors. The mechanical construction is a vital part of an autonomous auto or truck that's often necessarily to become shifted and intended such manners it's dynamically unwavering. The platform architecture, technical elegance, and also operation evaluation through the duration of sovereign driving together along with your platform really are more compared with two additional convolutional neural networks that we reimplemented with the entire take to have the purpose evaluation of these networks that is projected. The educated variant with the projected system is just four times greater when compared with PilotNet variant and somewhere around 250 times even larger in contrast to AlexNet variant. While elegance and dimension with this novel technique are much somewhat lower compared along with different designs that leads to decrease latency and increased rate through the duration of inference, our strategy promised that the performance, accomplishing prosperous autonomous driving together with similar effectiveness in comparison with autonomous driving together with just two additional designs. What's More, the projected deep neural network down Sized the needs for real-time inference Components Seeing computational capability, price, and also measurements.",project-academic
10.3182/20020721-6-ES-1901.01303,2002-01-01,a,Elsevier,high level control of autonomous robots using a behavior based scheme and reinforcement learning," Abstract None None This paper proposes a behavior-based scheme for high-level control of autonomous robots. Two main characteristics can be highlighted in the control scheme. Behavior coordination is done through a hybrid methodology, which takes in advantages of the robustness and modularity in competitive approaches, as well as optimized trajectories in cooperative ones. As a second feature, behavior state/action mapping is learnt by means of Reinforcement Learning (RL). A new continuous approach of the Q_learning algorithm, implemented with a multi-layer neural network, is used. The behavior-based scheme attempts to fulfill simple missions in which several behaviors/tasks compete for the vehicle's control. This paper is centered in the RL-based behaviors. In order to test the feasibility of the proposed Neural-Q_learning scheme, real experiments with the underwater robot ODIN in a target following behavior were done. Results showed the convergence of the behavior into an optimal state/action mapping. Discussion about the proposed approach is given, as well as an overall description of the high level control scheme.",project-academic
,2020-12-26,a,,deep learning based intelligent inter vehicle distance control for 6g enabled cooperative autonomous driving," Research on the sixth generation cellular networks (6G) is gaining huge momentum to achieve ubiquitous wireless connectivity. Connected autonomous driving (CAV) is a critical vertical envisioned for 6G, holding great potentials of improving road safety, road and energy efficiency. However the stringent service requirements of CAV applications on reliability, latency and high speed communications will present big challenges to 6G networks. New channel access algorithms and intelligent control schemes for connected vehicles are needed for 6G supported CAV. In this paper, we investigated 6G supported cooperative driving, which is an advanced driving mode through information sharing and driving coordination. Firstly we quantify the delay upper bounds of 6G vehicle to vehicle (V2V) communications with hybrid communication and channel access technologies. A deep learning neural network is developed and trained for fast computation of the delay bounds in real time operations. Then, an intelligent strategy is designed to control the inter-vehicle distance for cooperative autonomous driving. Furthermore, we propose a Markov Chain based algorithm to predict the parameters of the system states, and also a safe distance mapping method to enable smooth vehicular speed changes. The proposed algorithms are implemented in the AirSim autonomous driving platform. Simulation results show that the proposed algorithms are effective and robust with safe and stable cooperative autonomous driving, which greatly improve the road safety, capacity and efficiency.",project-academic
10.1109/ICIP.2019.8803189,2019-01-01,p,IEEE Computer Society,recognizing chinese texts with 3d convolutional neural network," In this paper, we propose a deep learning system to localize and recognize Chinese texts in scenes with signage and road marks through 3D convolutional neural network. The proposed system adopts YOLO for detecting target location and exploits 3D convolutional neural network for recognizing the contents. The proposed design outperforms the existing designs based on LSTM and achieves real-time processing performance, which is feasible to be implemented on embedded platforms. The proposed system reaches over 90% accuracy in recognizing Chinese texts on bird’s-eye viewing road marks in a self-driving vehicle equipped with a fisheye camera. In addition, this system can achieve 20 fps execution speed with NVIDIA DIGITS DevBox with 1080Ti GPU, which is fast enough for autonomous driving applications.",project-academic
10.1109/EESCO.2015.7253926,2015-09-10,p,IEEE,intelligent traffic with connected vehicles intelligent and connected traffic systems," This paper describes the structured approach involved in the development of an Intelligent Autonomous (self-driving, unmanned, driverless or robotic) Vehicles. In which autopilot with artificial intelligence are critical subsystems whose development requires multidisciplinary approach along with concurrent engineering to create a better, safer and reliable future. We have studied and implemented a miniature scale model with outcome of satisfactory results of supporting realistic vehicular mobility simulation using concepts of swarm technology discussed in this paper. Our Model must be equipped with a variety of instrumentation and controls depending upon the mission of the target vehicle. Mechatronics, Systems Engineering (SE), Control Systems (CS), Swarm Technology, Artificial Intelligence, Image Processing Cloud Computing, Virtualization with caching, Fuzzy Logic and Neural Networks has a potential scope of design for the prototype needed to be developed that will navigate to a desired location with obstacle avoidance. In this design of autonomous vehicles have access to information about their surroundings gathered from its several sensors such as Radar, GPS including a very important component of this system Infrastructure Unit which is connected virtually with Vehicle's Operating System, mapping and direction system is discussed broadly. Here, Infrastructure Unit plays a major role in routing the traffic to maintain free flow and accident avoidance, by provides information such as Routes, Traffic, Time, Directions to Vehicles and maintain constant speed for all vehicles to achieve an efficient autonomous transportation reducing accidents to zero. To improve the response time and storage of V2I Communication a new approach of caching and virtualization are encapsulated with a better and faster hardware such as Solid State Technology. This study has various applications in Space Science, Oceanography, and Automation in Traffic control which can effortlessly meet the necessity, scalability of future Generation.",project-academic
10.1109/ICAMECHS.2016.7813486,2016-11-01,p,IEEE,intelligent adaptive precrash control for autonmous vehicle agents cbr engine hybrid a path planner," PreCrash problem of Intelligent Control of autonomous vehicles robot is a very complex problem, especially vehicle pre-crash scenariws and at points of intersections in real-time environmenta. This Paper presents a novel architecture of Intelligent adaptive control for autonomous vehicle agent that depends on Artificial Intelligence Techniques that applies case-based reasoning techniques, where Parallel CBR Engines are implemented for different scenarios' of PreCrash problem and sub-problems of intersection safety and collision avoidance, in the higher level of the controller and A∗ path planner for path planning and at lower-levels it also uses some features of autonomous vehicle dynamics. Moreover, the planner is enhanced by combination of Case-Based Planner. All modules are presented and discussed. Experimental results are conducted in the framework of Webots autonomous vehicle tool and overall results are good for the CBR Engine for Adaptive control and also for the hybrid Case-Based Planner, A∗ and D∗ motion planner along with conclusion and future work.",project-academic
,2004-01-01,a,University of Delaware,a practical framework for formation planning and control of multiple unmanned ground vehicles," Finding trajectories in real-time for multiple vehicles moving in a dynamic environment while satisfying all constraints is challenging. For some special groups of systems, group flatness and formation laws allow for a parameterization of the member's trajectories by the leader's flat outputs, which can significantly reduce the problem's complexity. 
In the literature, most studies have focused on one aspect of the robot motion planning and control problem. Robot path planning is typically addressed using artificial intelligence techniques. Robot motion coordination and control schemes are developed using control techniques. The path planning and motion coordination and control are usually treated as two separate problems. In this research, we bridge the gap between path planning, trajectory generation, and motion control. A technique for real-time path planning has been developed and implemented. A practical framework for on-line planning and control of formations of multiple unmanned vehicles to traverse between goal points in a dynamic environment has been proposed. The formation is allowed to dynamically change in order to avoid obstacles in the environment while minimizing a cost function aimed at obtaining collision-free and deadlock-free paths. The framework combines global search and local optimization. The global path for the leader of a group is generated via a graph search method. Algorithms are developed to generate smooth trajectories from discrete path sequences. The trajectory planner optimizes the trajectory locally to satisfy the dynamics and input constraints of the individual vehicles while accounting for inter-vehicle collisions and path constraints. A Lyapunov-based controller is designed to keep the vehicles on their planned trajectories. The framework has been extended to multiple unmanned vehicles with trailers. Formation following of a simulated autonomous small grain harvesting system is presented. A powerful set of hardware-in-the-loop software tools for developing and testing behaviors of a group of robots is designed. Illustrative experiments of groups of unmanned vehicles show promise of this approach.",project-academic
10.1109/ITSC.2019.8917394,2019-10-01,p,IEEE,reduced kernel extreme learning machine for traffic sign recognition," Traffic Sign Recognition (TSR) is an important application that must be incorporated in autonomous vehicles. However, machine learning methods, used normally for TSR, demand high computational resources, which is in conflict with a system that is to be incorporated into a vehicle where size, cost, power consumption and real-time response are important requirements. In this paper, we propose a TSR system based on a Reduced Kernel Extreme Learning machine (RK-ELM) which is efficiently implemented in a Graphic Processing Unit (GPU). On the one hand, the inherent simplicity of ELM-based models makes possible the recognition process to be realized in a very fast and direct way. On the other hand, the computations involved in RK-ELM can be easily implemented in a GPUs so the recognition process is clearly boosted. Experiments carried out with a commonly used dataset benchmark validate our proposal.",project-academic
10.1049/IET-CSR.2019.0014,2019-10-01,a,The Institution of Engineering and Technology,extreme learning based non linear model predictive controller for an autonomous underwater vehicle simulation and experimental results," In this study, an extreme learning-based non-linear model predictive controller (NMPC) is proposed for path following planning of an autonomous underwater vehicle (AUV) using horizontal way-points. The proposed controller comprises a kinematic controller and a dynamic controller. The kinematic controller is designed by using back-stepping approach whilst the dynamic controller is designed by employing the NMPC approach. The dynamics of the AUV is identified in real-time by employing an extreme learning machine (ELM) structure. In view of achieving improved performance of the ELM structure, its hidden layer parameters are optimally determined by applying Jaya optimisation algorithm. The resulting ELM model is then used to design a NMPC considering the constraint on rudder planes. The tracking performance of the proposed controller is compared with that of two recently reported control algorithms namely, None None None $H_\infty $ None None None H None ∞ None None None None None None state feedback controller and inverse optimal self-tuning proportional–integral–derivative (PID) controller. The proposed controller is implemented using MATLAB and then in real-time on a prototype AUV developed in the authors’ laboratory. From both the simulation and experimental results obtained, it is observed that the proposed controller exhibits superior tracking performance compared to both None None None $H_\infty $ None None None H None ∞ None None None None None None state feedback controller and inverse optimal self-tuning PID controller.",project-academic
10.1109/WCNC.2019.8886037,2019-04-15,p,IEEE,pedestrian detection for autonomous driving within cooperative communication system," The ability to perceive and understand surrounding road-users behaviors is crucial for self-driving vehicles to correctly plan reliable reactions. Computer vision that relies mostly on machine learning techniques enables autonomous vehicles to perform several required tasks such as pedestrian detection. Furthermore, within a fully autonomous driving environment, driverless vehicle has to communicate and share perceived data with its neighboring vehicles for more safe navigation. In this context, our paper proposes a warning notification diffusion solution related to real-time pedestrian presence detection, through an inter-vehicle communication system. To achieve this purpose, pedestrian and vehicle recognition is required. Thus, we implemented intended detectors. We used Histogram of Oriented Gradients (HOG) descriptor with the linear Support Vector Machine (SVM) classifier for the pedestrian detector, and Haar feature-based cascade classifier to reach vehicle detection. The performance evaluation of our solution leads to fairly good detection accuracy around 90% for pedestrian and 88% for vehicle.",project-academic
10.1016/J.COMPAG.2021.106179,2021-07-01,a,Elsevier,improving deep learning sorghum head detection through test time augmentation," Abstract None None The continuous growth of the world’s population requires immediate action to ensure food security. Sorghum is among the five most-produced cereals and is a dietary staple in many developing countries. Therefore, it is of great importance to obtain precise information for improving cereal productivity. An indicator for estimating sorghum yields is the number of crop heads in different branching arrangements. Approaches based on image processing and artificial intelligence have proved useful for automatically and efficiently obtaining this type of information for different crops. However, their application to sorghum crops presents some additional challenges owing to differences in the shape and color of sorghum heads. In this study, a methodology to detect sorghum heads in unmanned aerial vehicle imagery was investigated, and its performance was evaluated using a standard quality index in object detection problems (mean average precision). Specifically, test-time-augmentation (TTA) techniques have been implemented using a set of geometrical and color transformations selected according to the sorghum plant imagery requiring analysis, as well as four different ensemble learning methods. Because these methods are weighted, two different approaches for calculating these weights to improve sorghum head detection have been proposed. The results show that in sorghum head detection, TTA strategies outperform detection based only on individual transformed testing sets. Moreover, these results were improved by the use of different weights during the ensemble of TTA results.",project-academic
10.1007/11552413_152,2005-09-14,p,"Springer, Berlin, Heidelberg",soft computing based real time traffic sign recognition a design approach," The traffic sign detection and recognition system is an essential module of the driver warning and assistance system. During the last few years much research effort has been devoted to autonomous vehicle navigation using different algorithm. Proposed work includes a neural network based drivers assistance system for traffic sign detection. In this paper authors have implemented a high-speed color camera to enhance its performance in real time scanning. The proposed algorithm increases the efficiency of the system by 7 to 10% as compared to conventional algorithms. The system includes two main modules: detection module and recognition module. In the detection module, the thresholding is used to segment the image. The features of traffic signs are investigated and used to detect potential objects. In recognition module, we use complimenting and then ANDing techniques. The joint use of classification and validation networks can reduce the false positive rate. There liability demonstrated by the proposed method suggests that this system could be a part of an integrated driver warning and assistance system based on computer vision technology.",project-academic
10.1016/S0736-5845(99)00033-2,1999-10-01,a,Elsevier Limited,a new approach to vision based unsupervised learning of unexplored indoor environment for autonomous land vehicle navigation," Abstract None None A vision-based approach to unsupervised learning of the indoor environment for autonomous land vehicle (ALV) navigation is proposed. The ALV may, without human's involvement, self-navigate systematically in an unexplored closed environment, collect the information of the environment features, and then build a top-view map of the environment for later planned navigation or other applications. The learning system consists of three subsystems: a feature location subsystem, a model management subsystem, and an environment exploration subsystem. The feature location subsystem processes input images, and calculates the locations of the local features and the ALV by model matching techniques. To facilitate feature collection, two laser markers are mounted on the vehicle which project laser light on the corridor walls to form easily detectable line and corner features. The model management subsystem attaches the local model into a global one by merging matched corner pairs as well as line segment pairs. The environment exploration subsystem guides the ALV to explore the entire navigation environment by using the information of the learned model and the current ALV location. The guidance scheme is based on the use of a pushdown transducer derived from automata theory. A prototype learning system was implemented on a real vehicle, and simulations and experimental results in real environments show the feasibility of the proposed approach.",project-academic
,2014-01-01,a,Universidad de Cuenca,implementacion de un detector de coral utilizando filtros gabor wavelets y maquinas de aprendizaje," RESUMEN None Este trabajo se enfoca en la implementacion de un detector de arrecife de coral de desempeno rapido que se utiliza para un vehiculo autonomo submarino (Autonomous Underwater Vehicle, AUV, por sus siglas en ingles). Una deteccion rapida de la presencia de coral asegura la estabilizacion del AUV frente al arrecife en el menor tiempo posible, evitando colisiones con el coral. La deteccion de coral se hace en una imagen que captura la escena que percibe la camara del AUV. Se realiza una clasificacion pixel por pixel entre dos clases: arrecife de coral y el plano de fondo que no es coral. A cada pixel de la imagen se le asigna un vector caracteristico, el mismo que se genera mediante el uso de filtros Gabor Wavelets. Estos son implementados en C++ y la libreria OpenCV. Los vectores caracteristicos son clasificados a traves de nueve algoritmos de maquinas de aprendizaje. El desempeno de cada algoritmo se compara mediante la precision y el tiempo de ejecucion. El algoritmo de Arboles de Decision resulto ser el mas rapido y preciso de entre todos los algoritmos. Se creo una base de datos de 621 imagenes de corales de Belice (110 imagenes de entrenamiento y 511 imagenes de prueba). None Palabras clave: AUV, arrecife de coral, maquinas de aprendizaje, filtros Gabor Wavelets, OpenCV. None ABSTRACT None This work focuses on the implementation of a fast coral reef detector that is used for an Autonomous Underwater Vehicle (AUV, its acronym in English). A fast detection of the presence of coral ensures the AUV stabilization in front of coral reef in the shortest possible time, avoiding collisions with coral. The coral detection is carried out on an image that captures the scene that the AUV’s camera perceives. A pixel-by-pixel classification is performed between two classes: coral reef and the background that is non-coral reef. Each pixel of the image is assigned to a feature vector, which is generated by using Gabor Wavelet filters. These are implemented in C++ and the OpenCV library. The feature vectors are classified using nine machine learning algorithms. The performance of each algorithm is compared with the accuracy and execution time. The Decision Tree algorithm proved to be the fastest and most accurate of all the algorithms. We created a database of 621 images of coral reefs in Belize (110 of training images and 511 of testing images). None Keywords: AUV, coral reef, machine learning, Gabor Wavelets filters, OpenCV.",project-academic
10.1016/J.IFACOL.2019.12.529,2019-01-01,a,Elsevier,autonomous canal following by a micro aerial vehicle using deep cnn," Abstract None None Globally, large-scale irrigation canal networks serve as the backbone of agriculture in many important river basins. However, these water channels are in a constant threat of erosion, silt accumulation and structural damages over time which significantly reduces the water carrying capacity. Therefore, periodic inspections of the canals are required for critical operations and maintenance tasks. Due to the vast lengths of the channels and time-critical operations, automation has become a necessity. In this paper, we have proposed an aerial autonomous canal traversal system using ResNet50 inspired deep convolutional neural network. Given the uniqueness of our problem, we have generated our dataset for supervised learning and validation and later evaluated the proposed approach on a real canal. We have implemented our approach on a COTS micro-aerial vehicle. We have designed our system in such a way that it takes 200ms from perception to action thereby making the system real-time. We compare the superior performance of our Res Net 50 inspired network with other state-of-the-art CNNs trained on canal datasets.",project-academic
10.3390/APP11167225,2021-08-05,a,MDPI AG,processor in the loop architecture design and experimental validation for an autonomous racing vehicle," Self-driving vehicles have experienced an increase in research interest in the last decades. Nevertheless, fully autonomous vehicles are still far from being a common means of transport. This paper presents the design and experimental validation of a processor-in-the-loop (PIL) architecture for an autonomous sports car. The considered vehicle is an all-wheel drive full-electric single-seater prototype. The retained PIL architecture includes all the modules required for autonomous driving at system level: environment perception, trajectory planning, and control. Specifically, the perception pipeline exploits obstacle detection algorithms based on Artificial Intelligence (AI), and the trajectory planning is based on a modified Rapidly-exploring Random Tree (RRT) algorithm based on Dubins curves, while the vehicle is controlled via a Model Predictive Control (MPC) strategy. The considered PIL layout is implemented firstly using a low-cost card-sized computer for fast code verification purposes. Furthermore, the proposed PIL architecture is compared in terms of performance to an alternative PIL using high-performance real-time target computing machine. Both PIL architectures exploit User Datagram Protocol (UDP) protocol to properly communicate with a personal computer. The latter PIL architecture is validated in real-time using experimental data. Moreover, they are also validated with respect to the general autonomous pipeline that runs in parallel on the personal computer during numerical simulation.",project-academic
10.1007/978-981-33-6862-0_28,2021-01-01,a,"Springer, Singapore",object detection for autonomous vehicles using deep learning algorithm," Self-driving cars is recently gaining an increasing interest from the people across the globe. Over 33,000 Americans are killed in car accidents every year and lots of those accidents are often avoided by implementing the autonomous vehicle detection. Different ways are developed to manage and detect the road obstacles with the help of the techniques like machine learning and artificial intelligence. To resolve the issues associated with the existing vehicle detection like vehicle type recognition, low detection accuracy, and slow speed, many algorithms like the fast and faster region-based convolutional neural networks (RCNNs) are implemented but those were not supportive in real time because of the speed at which they compute and its two-step architecture with the faster RCNN, which is the enhanced version of RCNNs that runs at a speed of 7 frames per second. As it is observed that the CNN family has two steps (object detection and classification), which can reduce the response time in real time with good accuracy and high image resolution. So, the vehicle detection model like YOLOv2 and YOLOv3 is taken into consideration in this paper as they are very useful in real-time detection with a comparatively higher frame rate. As YOLO family of algorithms will mostly use the single step detection and classification. YOLO has an FPS rate of 45 which is pretty good in the real-time scenarios. We had an average of 90.4 using the taken algorithm for each image in this paper with a lower resolution image alone.",project-academic
,2020-04-03,,,real time multi modal language analysis system and method based on mobile edge intelligence," The invention discloses a real-time multi-modal language analysis system and method based on mobile edge intelligence, and the system comprises three types of mobile edge intelligent servers: a mobilebase station (MGS), an unmanned vehicle (UGV) and an unmanned aerial vehicle (UAV), and the computing resources of the three types of mobile edge intelligent servers are sequentially reduced, and themoving flexibility is sequentially improved. According to the real-time multi-modal language analysis system, language data of a user is divided into three modalities, namely characters, voice and images, and a calculation task is allocated to a proper MEI server to be executed according to the calculation and analysis difficulty and the size of required calculation resources. According to the method, a real-time multi-modal language analysis and calculation problem in a dynamic environment is constructed, then a task unloading matrix and a resource allocation matrix are generated through a deep learning online optimization method, and meanwhile, movement path planning of an MEI server is automatically implemented according to channel conditions and interference during communication. Thetrained DNN can be suitable for a dynamic scene in which the number of multi-modal computing tasks changes, and has very high practicability.",project-academic
,2018-03-16,a,,monocular fisheye camera depth estimation using sparse lidar supervision," Near field depth estimation around a self driving car is an important function that can be achieved by four wide angle fisheye cameras having a field of view of over 180. Depth estimation based on convolutional neural networks (CNNs) produce state of the art results, but progress is hindered because depth annotation cannot be obtained manually. Synthetic datasets are commonly used but they have limitations. For instance, they do not capture the extensive variability in the appearance of objects like vehicles present in real datasets. There is also a domain shift while performing inference on natural images illustrated by many attempts to handle the domain adaptation explicitly. In this work, we explore an alternate approach of training using sparse LiDAR data as ground truth for depth estimation for fisheye camera. We built our own dataset using our self driving car setup which has a 64 beam Velodyne LiDAR and four wide angle fisheye cameras. To handle the difference in view points of LiDAR and fisheye camera, an occlusion resolution mechanism was implemented. We started with Eigen's multiscale convolutional network architecture and improved by modifying activation function and optimizer. We obtained promising results on our dataset with RMSE errors comparable to the state of the art results obtained on KITTI.",project-academic
10.1109/ICAMIMIA47173.2019.9223365,2019-10-01,p,Institute of Electrical and Electronics Engineers Inc.,autonomous car simulation using evolutionary neural network algorithm," Automation with artificial intelligence (AI) has widely implemented in robotics, transportation and manufacture. AI has become a powerful technology that change human life and help human more flexible doing something. In this paper, it will show a result of simulation from an autonomous car using the evolutionary neural network algorithm which combines genetic algorithm and neural network. The purpose of the simulation is to test the model that we develop to know the right direction based on the track, so the evolutionary neural network that implemented to the autonomous car be able to deliver the best solution before it implements in the real machine or car technology. Genetic algorithm combines with a neural network to reach an evolution condition. The evolution process is achieved through crossover, mutation and selection process, so the algorithm will give the best result from the iteration of the experiment. The result of our experiment shows that evolutionary neural network algorithm give the best result within 3 layer architecture, with iteration average is 14.5 reach finish point (check point) 3 in the track simulation. Based on the simulation, our car model can find out the right direction.",project-academic
10.1007/S41870-021-00747-2,2021-08-04,a,Springer Singapore,vision based outdoor navigation of self driving car using lane detection," The evolution of artificial intelligence has served as the catalyst in the field of technology and is making our imaginations real. One of such creation is the birth of self- driving car (autonomous robot). In this paper, a self-driving car physical prototype based on traditional visual method of lane keeping, implemented on Raspberry Pi is proposed which is capable of maneuvering on various kind of tracks autonomously. The proposed method comprises of taking an image from a front facing dashboard camera of the car, detecting the lane from the image and analysing the deviation of the car from the road which is further used to keep the car on the track. The proposed method is implemented on a 1/10 scale car which contains Raspberry Pi 3 Model-B computer and Pi Cam Rev 1.3 for computations and processing. The testing was done without any human intervention on self-made lined track having all kind of turns. The experimental results demonstrate the effectiveness and the robustness of the self-driving car in terms of the navigation error while following the reference trajectory.",project-academic
10.1109/GNCC42960.2018.9018891,2018-08-01,p,IEEE,a realtime q learning method for unmanned surface vehicle target tracking," Target tracking is a key problem of motion planning for unmanned surface vehicle (USV). This paper presented a Q-learning based method for real time USV target tracking planning in an uncertain environment. In this work, the improved Q-learning reinforcement learning algorithm was proposed. In additional, the Q-learning based motion planning model of USV was implemented, in which the continuous reinforcement strategy was designed to determine the training mode between learning and exploration period. Off-line and on-line real time simulation test was carried out to verify the learning ability and availability of the Q-learning algorithm. The result shows that this Q-learning based method can optimize a high rewarded path autonomously and navigate USV to fixed or moving targets in real time.",project-academic
10.1109/CICA.2009.4982774,2009-05-27,p,IEEE,tutorial cica t computing with intelligence for identification and control of nonlinear systems," System characterization and identification are fundamental problems in systems theory and play a major role in the design of controllers. System identification and nonlinear control has been proposed and implemented using intelligent systems such as neural networks, fuzzy logic, reinforcement learning, artificial immune system and many others using inverse models, direct/indirect adaptive, or cloning a linear controller. Adaptive Critic Designs (ACDs) are neural networks capable of optimization over time under conditions of noise and uncertainty. The ACD technique develops optimal control laws using two networks - critic and action. There are merits for each approach adopted will be presented. The primary aim of this tutorial is to provide control and system engineers/researchers from industry/academia, new to the field of computational intelligence with the fundamentals required to benefit from and contribute to the rapidly growing field of computational intelligence and its real world applications, including identification and control of power and energy systems, unmanned vehicle navigation, signal and image processing, and evolvable and adaptive hardware systems.",project-academic
10.1109/ICSSE52999.2021.9537945,2021-08-26,p,IEEE,path planning and obstacle avoidance based on reinforcement learning for uav application," Applications of drones in the military and daily life have increased in recent years. However, it is necessary to have obstacle avoidance capability. Path planning is also needed for automated tasks. In this study, path planning and obstacle avoidance based on a reinforcement learning algorithm are implemented in an unmanned aerial vehicle (UAV). For global path planning, a Q-learning algorithm is utilized to find the path between waypoints first. Then the local obstacle avoidance system is applied to train the UAV by the Deep Q-learning algorithm in Microsoft AirSim unreal environment.",project-academic
10.1007/978-981-16-0935-0_5,2021-01-01,a,"Springer, Singapore",vehicle detection and count in the captured stream video using machine learning," The technology of vehicle detection in the captured video has implementation in the variety of fields. This emerging technology when implemented over the real-time video feeds can be beneficial for the missions of search and rescue in remote areas, where access is hampered by mountains and vast land areas without road networks. Areas afflicted by natural disaster (earthquake, flood) may be aided and improved by autonomous UAV systems, in military applications and civilians due to its ability to operate over large, difficult terrain. Rescue or surveillance missions include people and vehicle detection from aerial platforms. The supreme benefit of vehicle detection in the real-time streaming video feed is to track the terrorist intrusion over the borders and hit them. The recent terrorist attack occurred in the Indian soil at Uri, Pulwama, which could be avoided by using the enhanced vehicle detection techniques implied in the live stream video by machine learning. This chapter presents to recognize and identify the moving objects in the live video stream for specific interest. This chapter aims to explore the existing challenging issue in the area of unsupervised surveillance and security. The detection of vehicles is implemented with enhanced algorithms and machine learning libraries like OpenCV, TensorFlow, and others. The various approaches are used to identify and track the specific object through the trained model from the captured video.",project-academic
10.1016/J.BDR.2021.100241,2021-07-15,a,Elsevier,brains for robots application of the mivar expert systems for implementation of autonomous intelligent robots," Abstract None None Recently the contemporary robotic systems can manipulate different objects and make decisions in a range of situations due to significant advances in innovation technologies and artificial intelligence. The new expert technologies can handle millions of instructions on computers and smartphones, which allow them to be used as a tool to create “decision-making systems” for autonomous robots. The goal of this paper was to create a dynamic algorithm of robot actions that can be used in the decision module has been considered. It is proposed to use Mivar expert systems of a new generation for high-level control. The experiment results showed that Mivar decision-making systems can control groups of small robots and even an unmanned autonomous car in real time. The algorithms created in the Mivar environment can be very flexible, and their build-up depends only on engineering approaches. In addition to traditional low-level robot control systems, a Mivar decision-making system has been implemented, which can be considered as universal “Brains” for autonomous intelligent robots and now knowledge bases can be created and various robots can be trained for practical tasks.",project-academic
,2021-10-01,a,,a deep learning approach to dead reckoning navigation for autonomous underwater vehicles with limited sensor payloads," This paper presents a deep learning approach to aid dead-reckoning (DR) navigation using a limited sensor suite. A Recurrent Neural Network (RNN) was developed to predict the relative horizontal velocities of an Autonomous Underwater Vehicle (AUV) using data from an IMU, pressure sensor, and control inputs. The RNN network is trained using experimental data, where a doppler velocity logger (DVL) provided ground truth velocities. The predictions of the relative velocities were implemented in a dead-reckoning algorithm to approximate north and east positions. The studies in this paper were twofold I) Experimental data from a Long-Range AUV was investigated. Datasets from a series of surveys in Monterey Bay, California (U.S) were used to train and test the RNN network. II) The second study explore datasets generated by a simulated autonomous underwater glider. Environmental variables e.g ocean currents were implemented in the simulation to reflect real ocean conditions. The proposed neural network approach to DR navigation was compared to the on-board navigation system and ground truth simulated positions.",project-academic
10.32603/1993-8985-2021-24-3-49-59,2021-06-23,a,St. Petersburg Electrotechnical University LETI,метод автоматического определения трехмерной траектории транспортных средств на изображении," Introduction . An important part of an automotive unmanned vehicle (UV) control system is the environment analysis module. This module is based on various types of sensors, e.g. video cameras, lidars and radars. The development of computer and video technologies makes it possible to implement an environment analysis module using a single video camera as a sensor. This approach is expected to reduce the cost of the entire module. The main task in video image processing is to analyse the environment as a 3D scene. The 3D trajectory of an object, which takes into account its dimensions, angle of view and movement vector, as well as the vehicle pose in a video image, provides sufficient information for assessing the real interaction of objects. A basis for constructing a 3D trajectory is vehicle pose estimation. None Aim . To develop an automatic method for estimating vehicle pose based on video data analysis from a single video camera. None Materials and methods . An automatic method for vehicle pose estimation from a video image was proposed based on a cascade approach. The method includes vehicle detection, key points determination, segmentation and vehicle pose estimation. Vehicle detection and determination of its key points were resolved via a neural network. The segmentation of a vehicle video image and its mask preparation were implemented by transforming it into a polar coordinate system and searching for the outer contour using graph theory. None Results . The estimation of vehicle pose was implemented by matching the Fourier image of vehicle mask signatures and the templates obtained based on 3D models. The correctness of the obtained vehicle pose and angle of view estimation was confirmed by experiments based on the proposed method. The vehicle pose estimation had an accuracy of 89 % on an open Carvana image dataset. None Conclusion . A new approach for vehicle pose estimation was proposed, involving the transition from end-to-end learning of neural networks to resolve several problems at once, e.g., localization, classification, segmentation, and angle of view, towards cascade analysis of information. The accuracy level of end-to-end learning requires large sets of representative data, which complicates the scalability of solutions for road environments in Russia. The proposed method makes it possible to estimate the vehicle pose with a high accuracy level, at the same time as involving no large costs for manual data annotation and training.",project-academic
10.1109/ICUAS.2019.8798329,2019-06-01,p,IEEE,a vision based unmanned aircraft system for autonomous grasp transport," The progress in sensor technologies, computer capabilities and artificial intelligence has endowed the unmanned aircraft system (UAS) with more autonomous abilities. Motivated by the 6th International Unmanned Aerial Vehicle Innovation Grand Prix (UAVGP), a UAS with high degree of autonomy was developed to perform the mission of building a simulated tower using prefabricated components. According to the requirement of the competition, the UAS was designed and implemented from the following four parts: 1) navigation and control, 2) recognition and location, 3) grasp and construction, and 4) task planning and scheduling. Different levels of autonomy have been given to the UAS based on these parts. The system hardware was developed on a quadrotor platform by integrating various components, including sensors, computers, power and grasp mechanism. Software which included precise navigation, mission planning, real-time perception and control was implemented and integrated with the developed UAS hardware. The performance in the test environment and actual competition showed that the UAS could perform the mission without human intervention with high autonomy and reliability. This paper addresses the major components and development process of the UAS and describes its application to the practical mission.",project-academic
10.1109/ACMI53878.2021.9528185,2021-07-08,p,IEEE,speed bump pothole detection with single shot multibox detector algorithm speed control for autonomous vehicle," The development of self-driving cars has always been an extensive research field for the automobile industry. To make a capable self-driving car, many challenges need to be resolved. Detection of the road condition is one of them. This paper focuses on a particular part-detection of speed bumps and potholes using a camera and analyzing the video feed with the help of artificial intelligence. To solve this problem a popular and lightweight algorithm, SSD (Single Shot Multibox Detector) is used. This is an optimal choice because of being lightweight and also accurate enough to run on mobile devices and to use in real-life situations. For detecting speed bumps and potholes, a dataset has been created based on the road structure of Bangladesh as the main priority of this system is to work on the local environment. Raspberry Pi has been used as the main processing unit because of being small but powerful. A warning system has been implemented so that it can warn the onboard driver about the upcoming pothole or speed bump. This system can also send a signal to the speed controller unit of the car to reduce the speed on detection to avoid accidents or damages to the car. The speed control unit is a microcontroller-based system that uses an ATmega328 microcontroller and L298 motor driver. This paper summarizes the combination of an artificial intelligence-based detection system injunction with a microcontroller-based speed control system in a cost-effective way that can be used in building self-driving cars.",project-academic
10.1109/ICICCS51141.2021.9432186,2021-05-06,p,IEEE,pothole and object detection for an autonomous vehicle using yolo," Object Detection is an key software and a fundamental task for an autonomous driving system that provides remarkable change in computer vision. In recent years, company's are planning to launch autonomous vehicle in an full swing that's the most important ascpets for object detection and one of most challenging task for locating specific object from from multiple objects in a specific scenario. The computer vision and machine learning algorithm is the important tool for detecting objects in and around the environment. In this paper, which consists of two parts The first part is implemented on object detection in the surrounding with Yolo (You Only Look Once)Algorithm provides exact classification and position which is configured on newly created datasets for classes of object: a car, a person, a truck, a bus, traffic light, motorcycle, pothole, wetland uses the Convolutional Neural Network and max-polling layer for prediction that improves detecting of small target and these deep learning technique provides a high accuracy for detecting real world. Detecting potholes in Indian road help the autonomous vehicle to move smoothly without getting struck in the potholes. In part two of the proposed method is implemented on Raspberry pi4 a popular embedded computer board explores suitability for the running objects. That solves the real world problems and improves the impact on detecting objects. Knowing pothole and wetland detection for self-driving vehicle is needed badly to solve the road lay problems like: accident, slowing down the transport system these are solved by deep learning.",project-academic
,2021-04-16,a,,deep learning based real time detection and object tracking on an autonomous rover with gpu based embedded device," In recent years, there has been a growing interest in autonomous systems with artificial intelligence, especially in the military, home automation and smart cities sectors. In this project, the aim is to develop, through an artificial neural network capable of detecting objects, a system that can make a rover-type vehicle independent. An autonomous vehicle is a system capable of perceiving its environment and moving safely with little or no human input. None None Based on an appropriate network according to the needs, a tracking algorithm is developed, which gives the memory to the intelligence, i.e. it can assign an identity to any detected object, around frames in a real-time video. The implementation of a tracking algorithm would allow the system to be more dynamic and to perform more complex functions than simply detecting and tracking the object frame by frame. None This paper explores the possibility to create an autonomous system that allows the user to select the desired mode of use by means of a graphic user interface. A Follow Me module is implemented, a technology that is now present in many systems of this type, such as drones or domestic robots, which allows the drone to follow a moving object around autonomously. The Follow Me module allows any person detected to voluntarily activate and, vice versa, deactivate the tracking function of the system. None Among the functions implemented in the security module, the identity switch recognizer plays a central role. In the context of multiple objects tracking, one of the most common situations is in fact the overlapping of the target object with other objects in the image. It is therefore necessary to have a security function that is aware of this behavior and warns the system of a possible ID. Computer vision systems have difficulty in maintaining the identity of the individuals over long periods of time; many modern vision systems multiple objects are based on tracking identification, which means they propagate the identities along the track. None None None The following work is part of a larger research project, entitled ""INTEGRATION OF OBJECT DETECTION IN REAL-TIME IMAGES IN AUTONOMOUS VEHICLE DRIVING"", supported by the National University of Cordoba, aimed at the autonomous operation of a rover-type land vehicle. The tests that will be carried out will relate to the use of a very specific board, the INVIDIA Jetson-Nano, which is mounted in the physical system supplied to the general project.",project-academic
10.17605/OSF.IO/MDHJU,2021-05-30,a,,deep learning and real time computer vision based feature matching in flying adhoc networks," Flying Adhoc Networks (FANETs) are getting huge popularity in assorted applications for civilian, corporate and defense applications. FANET is a specialized class of the Mobile Adhoc Networks (MANET) having computer vision, sensor devices and the Global Positioning based System (GPS) for live monitoring and logging the environment under surveillance. From the past few period, FANETs were widely and rapidly used for the monitoring and controlling of scenarios civil wars and local commotions. FANET makes used of assorted Unmanned Aerial Vehicle (UAV) which is useful and because of which the pre-programmed plans running on the flights of such a type of flying and other means of possible related objects were implemented.UAV describes pre-programmed and structured flying object which can also meats aircraft without the need of any kind of dedicated pilot on boarded. This research paper is focusing on the real time integration of UAV based real-time deep learning methods with real time extraction and feature matching techniques from the camera of relevant flying FANET aircrafts and because of which the definite and accurate target can be easily extracted. The proposed manuscript is presenting the effective way of technique in both civil as well as in military defense and thereby to fully recognize the enhanced activities of many underlying suspicious person which were targeted and also to locate the exact flying objects which were being released exactly by the opponent (or) targeted country.In the proposed manuscript, the real time extraction and integration of the OpenCV with additional feature descriptors and extractors in the absolute form of camera for the deep learning based real time FANET is being proposed and evident that the method and strategic tactical decisions were made by the explicit use of this proposed methodology in real time occurrences. This proposed empirical research proposal is targeting the effective integration of the high performance and super-computing-based library OpenCV because of which the high dimensional and high efficacy evaluation by the features that actually can be extracted have been analyzed. This feature-based point was found to be projected to be evaluated on the base of corners, edges and inner parameters of the real-time image in FANET.",project-academic
10.17762/TURCOMAT.V12I1S.1760,2021-04-11,a,"Auricle Technologies, Pvt., Ltd.",implementation paper of traffic signal detection and recognition using deep learning," Traffic boards and traffic signals are used to maintain proper traffic through busy roads. They help to recognize the rules to follow when driving the vehicle. These signs warn the distracted driver, and prevent his/her actions which could lead to an accident. We have proposed a system which can help recognize these boards and signals at real time thus avoiding major mishap. A real-time automatic sign detection and recognition can help the driver, significantly increasing his/her safety. Lately traffic sign recognition has got an immense interest lately by large scale companies such as Google, Apple and Volkswagen etc. which is driven by the market needs for intelligent applications such as autonomous driving, driver assistance systems (ADAS), mobile mapping, Mobil eye, Apple, etc.  Hence, here, we have implemented to do the same with cost efficient manner using Raspberry Pi. The proposed system detects the traffic board or traffic signals, capture its image which through deep learning approach recognizes the same to give result on dashboard as well it gives the measures of distance from front obstacle which helps to implement brake system if obstacle is near. PiCam is used to capture images of traffic sings and is connected to RaspberryPi. Monitor is used to display required output, showing type of sign and distance of collision. This proposal will avoid large number of accidents occurring at bridges and work in progress area due to automated braking system and simultaneous reduce death ratio.",project-academic
10.1109/ZINC.2019.8769392,2019-05-29,p,IEEE,classification of objects detected by the camera based on convolutional neural network," Nowadays, we are trying to achieve as much vehicle autonomy as possible by developing Advanced Driver-Assistance Systems (ADAS). For such a system to make decisions, it should have insight into the environment of the vehicle, e.g. the objects surrounding the vehicle. During forward driving, the information about the objects in front of the vehicle is usually obtained by a front view in-vehicle camera. This paper describes the image classification method of the objects in the front of the vehicle based on deep convolutional neural networks (CNN). Such CNN is supposed to be implemented in embedded system of an autonomous vehicle and the inference should satisfy real-time constraints. This means that the CNN should be structured to have fast inference by reducing the number of operations as much as possible, but still having satisfying accuracy. This can be achieved by reducing the number of parameters which also means that the resulting network has lower memory requirements. This paper describes the process of realizing such a network, from image dataset development up to the CNN structuring and training. The proposed CNN is compared to the state-of-the-art deep neural network in terms of classification accuracy, inference speed and memory requirements.",project-academic
10.1504/IJCVR.2010.038193,2010-01-01,a,Inderscience Publishers,novel design for real time path tracking with computer vision using neural networks," Accurate localisation and mapping is a problem of great interest and significance in mobile robotics. In most of the cases, the environment is unstructured and is unknown beforehand. Building an autonomous robot in the real time environment is quite challenging and requires modelling and investigation. In this paper, the path tracking by using computer vision techniques in robotics is employed. Attempt is made to make the robot completely autonomous and to control it from remote locations. A robotic car has been constructed and image processing operations like wiener filtering, thresholding and Hough transforms have been applied. Introduction of neural networks gives it an autonomous sense. Wireless communication is implemented to accomplish the above desired task in real time. A novel approach to steer the robot using stepper motor is designed and implemented by transmitting the control commands wirelessly.",project-academic
,2020-01-01,a,E.T.S.I. Industriales (UPM),reconstruccion del entorno del vehiculo para guiado autonomo en escenarios complejos reconstruction of the vehicle environment for autonomous guidance incomplex scenarios," La tecnologia LiDAR 3D cada vez esta teniendo mas repercusion en un campo emergente de aplicacion, el vehiculo autonomo. Fabricantes, desarrolladores e investigadores integran este tipo de sensores para aplicaciones de reconocimiento del entorno debido a las ventajas que aporta. Ademas, los sensores laser escaner han ganado especial protagonismo en la conduccion autonoma a partir de la evolucion de los laseres 2D a 3D, debido a que estos ultimos suplen satisfactoriamente los problemas de observacion parcial de los objetos que tenian los sensores 2D. La informacion espacial que proporcionan los LiDAR 3D es significativamente mas completa, lo que otorga de versatilidad para ser utilizados para otros fines. Esta versatilidad se hace patente en la variedad de algoritmos basados en tecnologia LiDAR que se encuentran en la literatura. Si bien, su aplicacion principal es el reconocimiento de obstaculos, para garantizar una navegacion autonoma terrestre segura, es necesario ampliar el campo de aplicacion. En este sentido, esta Tesis Doctoral plantea el estudio de las capacidades de los sensores LiDAR y el desarrollo de algoritmos centrados en dos de las lineas principales de investigacion del vehiculo autonomo: la caracterizacion del entorno y el posicionamiento y mapeado. Ambas lineas constituyen las bases de la percepcion del vehiculo que, a su vez, es la encargada de generar un modelo del entendimiento del entorno. Este entendimiento extraido del entorno a partir de los sensores tiene especial relevancia en la seguridad durante la navegacion cuando es utilizado en capas posteriores, como la Planificacion de trayectorias o la Toma de decisiones, dentro de la estructura del vehiculo autonomo. Por ello, la Tesis aborda por un lado la problematica de la caracterizacion del entorno, aportando soluciones respecto a la identificacion de obstaculos, no solo centrandose en entornos urbanos, sino tambien en entornos off-road, donde la orografia es irregular y el entorno desestructurado. Asimismo, debido a la versatilidad de estos sensores, se consigue llevar a cabo desarrollos para la caracterizacion horizontal de la via, estableciendo los limites de esta (ya sean escenarios urbanos, interurbanos o con terreno no preparado) o extrayendo las lineas viales, obteniendo informacion relevante acerca del ancho de carril y el error lateral en el o el numero total de carriles disponibles. Sobre la misma caracterizacion del entorno, se pueden establecer ciertos criterios que apoyen y mejoren el posicionamiento durante la navegacion autonoma. De este modo, se han implementado metodos analiticos que, a traves de las herramientas de caracterizacion desarrolladas, puedan apoyar una navegacion autonoma o reconstruir el mapa por donde se circula. Uno de los aspectos mas relevantes de esta Tesis es la aplicacion de algoritmos de Machine Learning a problemas concretos de la conduccion autonoma. A partir del desarrollo de estas tecnicas, concretamente en el campo del Deep Learning, junto a la gran cantidad de informacion que proporcionan los sensores LiDAR 3D, es posible disenar modelos con gran rendimiento y precision. En este sentido, ya han demostrado su validez posicionandose en el estado del arte respecto a problemas de segmentacion semantica, pero aun existe un gran desarrollo por delante ante problemas de regresion como en el caso de lograr un posicionamiento preciso. Por ello, se ha planteado y desarrollado algoritmos basados en redes de convolucion que infieren la odometria del vehiculo. A partir de estos modelos es posible obtener los valores de velocidad y variacion del angulo de guinada entre dos observaciones consecutivas, lo que proporciona una consistencia local del posicionamiento. Ademas, esta estimacion de la odometria puede servir para asistir a metodos convencionales cuando estos encuentran dificultades a la hora de converger a un resultado esperado. Teniendo en cuenta que el problema de posicionamiento global esta condicionado analiticamente, las soluciones basadas en metodos geometricos pueden alcanzar resultados precisos. Sin embargo, en funcion de la informacion disponible del entorno, se puede originar un peor rendimiento o precision. Los modelos basados en tecnicas de Deep Learning, al abordar el problema del posicionamiento con otro enfoque, no son tan sensibles a variaciones en la informacion del entorno y, de esta manera, se pueden emplear como asistencia en metodos estrictamente geometricos y conseguir una consistencia global del posicionamiento. Los resultados obtenidos en cada desarrollo son contrastados y evaluados en diferentes situaciones reales a traves de vehiculos autonomos o instrumentados. Asimismo, la adquisicion de datos y creacion de datasets para la implementacion de los algoritmos, se ha realizado utilizando diferentes sensores como el Velodyne VLP-16 y el Ouster OS-1 64, en ensayos en entornos controlados, urbanos o todoterreno. ----------ABSTRACT---------- LiDAR technology is increasingly having an impact in an emerging field of application: the autonomous vehicle. Manufacturers, developers and researchers integrate such sensors in applications used for recognition of the environment due to their numerous advantages. Furthermore, the laser scanner sensors have gained special prominence in autonomous driving due to the evolution of lasers from 2D to 3D, since the latter have fixed the problems of partial objects observation that 2D sensors had. In fact, the spatial information provided by LiDAR 3D is significantly more complete, which gives them a versatile nature and enables them to be used for other purposes. This versatility is evident from the variety of algorithms based on technology LiDAR that can be found in the literature. Although its main field of application is the obstacles detection, in order to guarantee safe autonomous ground navigation, it is of utmost importance to expand such field of application. In this regard, the present Doctoral Thesis focuses the study of the capabilities of LiDAR sensors and the development of algorithms focused on the two main areas of research of the autonomous vehicle: the characterization of the environment and positioning and mapping. Both areas constitute the basis of the perception of the vehicle which is also capable of generating a model for the understanding of the surrounding environment. Such understanding of the environment developed from the sensors has special relevance for a safe navigation when it is used in subsequent layers within the structure of the autonomous vehicle, such as ”Path planning” or ”Decision making”. On the one hand, this Thesis deals with the problem of the characterization of the environment in order to provide solutions for obstacles identification, focusing not only on urban environments but also on off-roads areas, where the ground is uneven and the environment unstructured. On the other hand, given the versatile of these sensors, the Thesis achieves developments for the horizontal characterization of the road, estimating its limits (either in urban scenarios, interurban or not-prepared ground) or extracting road lane lines, obtaining relevant information about the lane width and the lateral error in it or the total number of lanes available. Based on the same characterization of the environment, it is possible to establish certain criteria to support and enhance the positioning for an autonomous navigation. In this regard, analytical methods have been implemented based on the characterization tools already developed to support autonomous navigation or reconstruct the map where the vehicle drives. One of the most relevant aspects of this Thesis is the application of Machine Learning algorithms to specific problems of the autonomous driving. Due to the development of these techniques, specifically in the field of Deep Learning, together with the large amount of information provided by the 3D LiDAR sensors, it is possible to design models with great performance and precision. In this respect, they have already proven their performance by positioning themselves in the state of the art regarding semantic segmentation problems; however, there is still room for improvement in terms of regression problems, such as the case of achieving a precise positioning. For such purpose, it is proposed and developed algorithms based on convolutional neural networks that infer the odometry of the vehicle. Based on these models, it is possible to obtain the speed value and yaw angle rate between two consecutive observations, providing a local consistency positioning. Furthermore, this odometry estimation can be used to assist traditional methods when they encounter difficulties in converging to an expected result. Considering that the global positioning problem is analytically conditioned, the solutions based on geometric methods can achieve precise results. Nevertheless, depending on the information available from the environment, a worse performance or precision may originate. Given the fact that models based on techniques Deep Learning address the problem of positioning with another approach, they are not excessively sensitive to variations of the environment information and, therefore, can be used as assistance in methods strictly geometric, in order to achieve a global consistency positioning. The results derived from each development are contrasted and evaluated in different real situations through autonomous or instrumented vehicles. Likewise, the data acquisition and creation of datasets for the implementation of the algorithms, have been carried out using different sensors, such as the Velodyne VLP-16 and the Ouster OS-1 64 in controlled urban or off-road environments.",project-academic
,2020-03-31,a,,inverse reinforcement learning for adas," This project has been developed in collaboration with my team co-worker Francesco Allegra, a mechatronic engineering student, at Addfor S.p.A., with the guidelines of our academic supervisor Stefano Alberto Malan. The writing of the thesis has been divided as follow: I wrote chapters 2-5-6 while Francesco Allegra wrote chapters 1-3-5 and the results achieved so far have been summarized in “Conclusion”. None In this thesis It has been addressed the problem of using Inverse Reinforcement learning algorithms in order to realize autonomous driving’s applications.Among all the possible goals, “autonomous driving” is one of the most challenging, since it is a task performed by a huge amount of people everyday, and that is becoming more and more complex as the number of vehicles grows up during the years. The complexity of driving lies in the fact that a driving scenario is strongly unpredictable and unstructured, either in highways and especially in a city. Furthermore, it has been shown that most of car accident causes can mostly be attributed to human-driver’s misjudgments or distractions. These are some of the reasons which led to the introduction of ADAS in modern urban cars, that assists the driver in some of the fundamental tasks that can be executed while driving (regulate the acceleration, parking, maintain the lane), but according to the SAE we are still far from the highest level of automation (Level 5) that indicates the ability of the car of driving by itself without any human input. At the moment, ADAS are implemented through classical control techniques, e.g. P.I.D, P.I or P.D., or using some advanced control theories like Model predictive control.Simultaneously, Artificial Intelligence (AI) has acquired a lot of importance, spreading in a wide range of engineering sectors since it provides solutions in a very efficient and cleaver manner. Reinforcement Learning, the third None branch of ML, can effectively be involved as a decision-making problem solver, and it is just here that the control problem in autonomous driving meets machine learning.The focal point of RL is the Reward, a feedback signal able to show how good or bad are the taken action, so RL is the right choice only if we are dealing with tasks that can be accomplished in a small environment requiring discrete state and action spaces, instead if we focus our attention on complex scenarios with continuous spaces, it leads to wrong result, since we can’t guarantee the correctness of the chosen reward; those limits opened the door to a new theory, introduced by Andrew Ng and Russel in 2000s as inverse reinforcement learning, which aim is to find the reward in the cases cited before. None The objective of this thesis is to explain how to use the projection-based method, an inverse reinforcement learning algorithm, to realize an adaptive cruise control and a lane keeping control, given a set of data provided by Addfor S.p.A., which describes the driving style of two different expert human drivers that our agent should emulate. The entire code has been written in MATLAB while the scheme containing the agent block, the vehicle dynamic block and the sensors blocks, has been realized in Simulink. Moreover, driving scenario Toolbox has been used to build a driving scenario ad hoc for the problem. In the Conclusion It has been discussed the advantages and disadvantages of applying this procedure by comparing the results of the simulations with the ones obtained from already known techniques.",project-academic
,2020-03-31,a,,inverse reinforcement learning for autonomous driving," This project has been developed in collaboration with my team co-worker Francesco Allegra, a mechatronic engineering student, at Addfor S.p.A., with the guidelines of our academic supervisor Stefano Alberto Malan. The writing of the thesis has been divided as follow: I wrote chapters 2-5-6 while Francesco Allegra wrote chapters 1-3-5 and the results achieved so far have been summarized in “Conclusion”. In this thesis It has been addressed the problem of using Inverse Reinforcement learning algorithms in order to realize autonomous driving’s applications.Among all the possible goals, “autonomous driving” is one of the most challenging, since it is a task performed by a huge amount of people everyday, and that is becoming more and more complex as the number of vehicles grows up during the years. The complexity of driving lies in the fact that a driving scenario is strongly unpredictable and unstructured, either in highways and especially in a city. Furthermore, it has been shown that most of car accident causes can mostly be attributed to human-driver’s misjudgments or distractions. These are some of the reasons which led to the introduction of ADAS in modern urban cars, that assists the driver in some of the fundamental tasks that can be executed while driving (regulate the acceleration, parking, maintain the lane), but according to the SAE we are still far from the highest level of automation (Level 5) that indicates the ability of the car of driving by itself without any human input. At the moment, ADAS are implemented through classical control techniques, e.g. P.I.D, P.I or P.D., or using some advanced control theories like Model predictive control.Simultaneously, Artificial Intelligence (AI) has acquired a lot of importance, spreading in a wide range of engineering sectors since it provides solutions in a very efficient and cleaver manner. Reinforcement Learning, the third branch of ML, can effectively be involved as a decision-making problem solver, and it is just here that the control problem in autonomous driving meets machine learning.The focal point of RL is the Reward, a feedback signal able to show how good or bad are the taken action, so RL is the right choice only if we are dealing with tasks that can be accomplished in a small environment requiring discrete state and action spaces, instead if we focus our attention on complex scenarios with continuous spaces, it leads to wrong result, since we can’t guarantee the correctness of the chosen reward; those limits opened the door to a new theory, introduced by Andrew Ng and Russel in 2000s as inverse reinforcement learning, which aim is to find the reward in the cases cited before. The objective of this thesis is to explain how to use the projection-based method, an inverse reinforcement learning algorithm, to realize an adaptive cruise control and a lane keeping control, given a set of data provided by Addfor S.p.A., which describes the driving style of two different expert human drivers that our agent should emulate. The entire code has been written in MATLAB while the scheme containing the agent block, the vehicle dynamic block and the sensors blocks, has been realized in Simulink. Moreover, driving scenario Toolbox has been used to build a driving scenario ad hoc for the problem. In the Conclusion It has been discussed the advantages and disadvantages of applying this procedure by comparing the results of the simulations with the ones obtained from already known techniques.",project-academic
,2020-01-01,a,,machine learning classification of objects from rbg images and point clouds obtained from a mls system in railroad environment," The data fusion of RGB images and 3d point clouds captured from a Mobile Laser Scanning(MLS) platform is gaining more research interest recently due to its application in various fields such as railway infrastructure management, road traffic infrastructure maintenance, and autonomous vehicle navigation. Especially in the railway industry, periodical surveys are undertaken by mounting the MLS platform to the rails. And the data captured from the surveys are further post-processed to obtain a railway infrastructure model. However, the creation of such infrastructure models is time-consuming and involves a lot of manual labor, as understanding and identifying objects in the scene is quite difficult. The overall time taken to create such models can be drastically reduced by introducing a machine-learning algorithm to perform the classification task. This research proposes a novel framework that leverages both RGB images and 3D point clouds for efficient inventory mapping. The research segments are – object detection and classification, Character recognition from detected objects, and Positioning the detected objects in the point clouds. For this study, two objects of interest are selected.; they are - kilometer markers and Signals. Training samples for these objects are created from the RGB images, and a machine learning classifier is trained using these samples for object detection. As a result, the object's location in the RGB images is identified. Since the kilometer marker contains digit values in it, the detected kilometer marker images are further processed for character recognition. The task of character recognition is performed using a deep learning model that is being trained to recognize digits from a natural environment. The recognized kilometer values attribute to the semantic information of the objects. 
Furthermore, to obtain the 3d geometry, the objects detected in the image are reprojected to 3d point clouds using internal spatial parameters as they are captured from the same platform. With some processing, the geometry and its subsequent point cloud structure of the objects are obtained and thus locating the object in the real world accurately. The different classifiers used in this study are tested for their performance in classifying the objects, and their accuracy is assessed. Among them, the multi-class SVM with RBF kernel is selected for further object detection. It produces an overall accuracy of 96%. Similarly, the character recognition model is evaluated for its performance, and the accuracy is assessed. The algorithms are implemented in python, and the efficiency of the framework is evaluated. --- For access to the full thesis, please contact the ITC Library (library-itc@utwente.nl)",project-academic
10.1016/J.NET.2018.12.020,2019-06-01,a,Elsevier,numerical evaluation of gamma radiation monitoring," Abstract None None Airborne Gamma Ray Spectrometry (AGRS) with its important applications such as gathering radiation information of ground surface, geochemistry measuring of the abundance of Potassium, Thorium and Uranium in outer earth layer, environmental and nuclear site surveillance has a key role in the field of nuclear science and human life. The Broyden–Fletcher–Goldfarb–Shanno (BFGS), with its advanced numerical unconstrained nonlinear optimization in collaboration with Artificial Neural Networks (ANNs) provides a noteworthy opportunity for modern AGRS. In this study a new AGRS system empowered by ANN-BFGS has been proposed and evaluated on available empirical AGRS data. To that effect different architectures of adaptive ANN-BFGS were implemented for a sort of published experimental AGRS outputs. The selected approach among of various training methods, with its low iteration cost and non-diagonal scaling allocation is a new powerful algorithm for AGRS data due to its inherent stochastic properties. Experiments were performed by different architectures and trainings, the selected scheme achieved the smallest number of epochs, the minimum Mean Square Error (MSE) and the maximum performance in compare with different types of optimization strategies and algorithms. The proposed method is capable to be implemented on a cost effective and minimum electronic equipment to present its real-time process, which will let it to be used on board a light Unmanned Aerial Vehicle (UAV). The advanced adaptation properties and models of neural network, the training of stochastic process and its implementation on DSP outstands an affordable, reliable and low cost AGRS design. The main outcome of the study shows this method increases the quality of curvature information of AGRS data while cost of the algorithm is reduced in each iteration so the proposed ANN-BFGS is a trustworthy appropriate model for Gamma-ray data reconstruction and analysis based on advanced novel artificial intelligence systems.",project-academic
,2019-08-09,,,unmanned aerial vehicle based aerial image and static planning map matched displaying method," The invention discloses an unmanned aerial vehicle-based aerial image and static planning map matched displaying method. The method comprises the steps of step 1: endowing a coordinate to each pixel point in a picture shot by an unmanned aerial vehicle by use of an unmanned aerial vehicle mapping technology and an artificial intelligence identification technology when the unmanned aerial vehicle flies for the first time; and step 2, superposing a planning map and the mapping image, cutting lines in the planning map into countless points, and determining the density of the planning points according to the accuracy need, and determining a unique matched GPS (Global Positioning System) coordinate for each planing point. According to the unmanned aerial vehicle-based aerial image and static planning map matched displaying method, the three-dimensional planning design, engineering construction and patrol management can be implemented by use of the conventional planning map in combination with the dynamic video image. The method facilitates engineering lofting and construction and can be further applied to patrol management; the ownership scope is superposed in real time through patrol of the unmanned aerial vehicle, the management efficiency can be greatly improved and cross-border management is prevented.",project-academic
,2019-10-25,a,,analysis of environmental conditions on the performances of autonomous driving algorithms," In the last years autonomous driving has been, and continues to be nowadays, one of the most trending topics in the automotive environment. The progress performed in that field is continuously growing, also thanks to a huge amount of investments done by all the main car manufacturers. Vision systems play a key role into this process of driving automation, that’s why during this work two of them will be accurately analyzed through a validation procedure that allows to evaluate their limits and the main critical issues depending on the environmental conditions. None None None None The two systems that will be analyzed are: a lane detection system (fundamental to perform autonomous lane keeping) and an object detection system (needed for a lot of functions like the automatic braking or the recognition of road signs). The choice of these two systems is mainly due to the fact that they perform some of the most important tasks needed for autonomous driving. The lane detection system has been implemented in Matlab® using the same working principle of the GOLD system developed by Massimo Bertozzi and Alberto Broggi. The object detection system, instead, is YOLOv3, which is the most powerful algorithm for object detection in real time currently available. It is based on neural networks and has been developed by Joseph Redmond et al. . The validation procedure has been done through a series of tests performed using a specific dataset for each system. Each dataset has been developed taking into account the following parameters: lighting condition, presence of defects and weather conditions. None None None None The main aim of this work is to evaluate how and if these parameters influence the level of performance, in order to understand what must be improved and what, instead, has reached a sufficient level of maturity. The results of this analysis shown a certain level of robustness for both the systems, especially for YOLOv3, however also some weaknesses have been discovered. The lane detection system gave bad results in roads with unclear or colored road markings, moreover, bad weather conditions and macro defects leaded to a significant performance degradation. For what concerns YOLOv3, it shown to have a higher level of robustness in every condition, detecting most of the objects even with low resolution input images. The parameter that influenced most significantly the performances are the lighting conditions, which leaded every time to a worsening of the results.",project-academic
10.1109/INDIANCC.2016.7441102,2016-01-01,p,Institute of Electrical and Electronics Engineers Inc.,sensor health monitoring using simple data driven approaches," Present day high end vehicles contain as many as 100 microprocessors and have more than 100 million lines of code [3]. Electronic Control Units (ECUs) use numerous sensors spread across various sub-systems to perform a variety of functions such as stability control, adaptive cruise control, power train control, autonomous driving, etc. The accuracy of sensors degrades over the vehicle lifetime. The control logic of vehicles uses sensor measurements to detect the vehicle state and give appropriate commands to control the vehicle. Faults in sensors cause wrong feedback to be sent to the control logic and subsequently commands given by the control logic become faulty. Thus the effect of a sensor fault can be observed in subsystems controlled by the control logic. So advanced diagnosis techniques are required to detect the sensor degradation. In this work, a comparison is made between two different automotive sensor health monitoring methods used to diagnose sensor faults. The methods that are compared are: lookup table based method and machine learning (using multiple linear regression) based method. The comparison will enable one to choose the appropriate method by considering the attributes required for a particular application like accuracy, amount of computation required, simplicity, etc. Sensor faults are detected by comparing the current sensor output with a nominal no-fault sensor block output at the particular operating point of the system. The lookup table method was implemented in Matlab while the machine learning method was implemented using R programming language. The proposed methods are illustrated on the case example of motor fault in a Hybrid Electric Vehicle to analyze their efficacy. They have been found to be valid for all drive cycles and can be used for diagnosing sensor faults in real time.",project-academic
10.18174/452437,2018-01-01,a,Wageningen University,advanced classification of volunteer potato in a sugar beet field," Volunteer potato is a major problem in sugar beet production in the Netherlands, and adequate control of volunteer potato is critical. This is stressed by a statutory obligation in the Netherlands under which farmers have to remove volunteer potato plants from their fields before the 1st of July in the growing season every year, to a maximum level of two remaining plants per square meter. In 2011, the EU SmartBot project, a cross-border collaboration project which involved 24 different partners from Germany and the Netherlands, was initiated to develop a robotic system for several applications including for agricultural use. In AgroBot, part of the SmartBot project, a small-sized and vision-based autonomous weed control system was to be developed for effective control of volunteer potato plants in a sugar beet field. As a robotic platform, the Clearpath Husky A200 UGV (Unmanned Ground Vehicle) was to be used in this project. Due to the reduced carrying capacity of the robotic platform (Husky), additional infrastructure like a hood was not a viable option. Moreover, artificial lighting was not considered feasible either because the mobile platform was battery operated. Thus, the system should be able to perform robustly in scenes that are fully exposed to ambient lighting conditions. Within the EU SmartBot project, the primary objective of this research was identified as: None to develop a computer vision procedure that detects volunteer potato plants under ambient light conditions in a sugar beet field For a complete weed control pipeline, including weed detection and weed removal, the following requirements were set. The automatic weeding system should: None None None None effectively control more than 95% of the volunteer potato; None None None None ensure less than 5% of undesired control of sugar beet plants; None None None None ensure a classification time of less than 1 second per field image for real-time operation in the field. None None None None It was indicated that due to the potential non-perfect performance of actual weed removal, classification accuracy should be considerably higher than 95%. The steps required to fulfil the above-mentioned objective form the main line of this thesis including vegetation segmentation (Chapter 2 and 3) and sugar beet/volunteer potato classification (Chapter 4 and 5). Chapter 2 addressed the research question: “Does a ground shadow detection and removal enhance the performance of vegetation segmentation under natural illumination conditions in the field?” In Chapter 2, an algorithm was described and evaluated for ground shadow detection and removal based on colour space conversion and a multilevel threshold. The advantage of using the proposed algorithm was assessed for vegetation segmentation with field images that were acquired by a High Dynamic Range (HDR) camera under natural illumination. Compared with no shadow removal, applying shadow removal enhanced the performance of vegetation segmentation under natural illumination conditions in the field with an average of 20%, 4.4% and 13.5% in precision, specificity and modified accuracy, respectively, and did not reduce segmentation performance when shadows were not present. The average processing time was 0.46 s, which is feasible when real-time application in the field is considered. Chapter 3 addressed the research question: “Do different combinations of colour index and threshold technique result in different segmentation performance when evaluated on field images? Given the varying conditions in the field, is it better to use one specific combination at all times or the combination should be adapted to the field conditions at hand for best segmentation performance?” In Chapter 3, the performance of 40 combinations of eight colour indices and five threshold techniques for vegetation segmentation were evaluated. A clear difference in performance, represented in terms of MA (Modified Accuracy), was observed among various combinations under the given conditions of this research. CIVE+Kapur showed the best performance, while VEG+Kapur showed the worst on the dataset. When adapting the combination to the given conditions yielded a slightly higher performance than when using a single combination for all (in this case CIVE+Kapur). Consistent results were obtained when validated on a different independent image dataset. The expected advantage of adapting the combination to the field condition is not large because it seems that for practical use, the slight improvement when adapting the combination to the field conditions does not outweigh the investment in sensor technology and software needed to accurately determine the different conditions in the field. Chapter 4 and 5 focussed on classification and addressed the following research questions: “Does an algorithm using a Bag-of-Visual-Words (BoVW) model and SIFT or SURF descriptors meet the requirements set for the classification of volunteer potato and sugar beet under natural and varying daylight conditions? If the BoVW model does not meet the requirements, does a deep learning approach, particularly transfer learning based on Convolutional Neural Network (ConvNet, or CNN) provide an effective and better performance to meet the requirements with limited amount of dataset? Are the processing times (or calculation times) fast enough for real-time application?” For the classification of sugar beet and volunteer potato under ambient varying daylight conditions, Chapter 4 proposed a classification algorithm using a Bag-of-Visual-Words (BoVW) model based on SIFT or SURF features as well as crop row information in the form of the Out-of-Row Regional Index (ORRI). The highest classification accuracy of 96.5% with false-negative of 0% obtained using SIFT and ORRI with SVM is considerably better than previously reported approaches for weed classification; however, the false-positive rate of 7% deviates from the requirements since misclassification should be less than 5%. The average classification time of 0.10-0.11 s met the real-time requirements. Adding location information (ORRI) improved overall classification accuracy significantly. The proposed approach proved its potential under varying natural light conditions. Since the required classification accuracy was not obtained in Chapter 4, further research was carried out for the classification of sugar beet and volunteer potato under ambient varying daylight conditions. Chapter 5 evaluated a transfer learning procedure with three different implementations of AlexNet (Part I), and then assessed the performance amongst different ConvNet architectures (Part II): AlexNet, VGG-19, GoogLeNet, ResNet-50, ResNet-101 and Inception-v3. In Part I, the highest classification accuracy (98.0%) was obtained with AlexNet in Scenario 2. In scenario 1 and 3, the highest classification accuracy of 97.0% and 97.3% were obtained, respectively. In Part II, the highest classification accuracy of 98.7% was obtained. This result, to the best of our knowledge, was considerably better than any other approaches mentioned in the literature for crop and weed classification. Transfer learning provided very promising performance for the classification of sugar beet and volunteer potato images under ambient varying light conditions. A deep learning approach based on ConvNet provided better performance than the one in Chapter 4, and satisfied the requirements. All procedures were feasible for real-time field applications (the classification time < 0.1 s). The full pipeline for weed detection consists of three steps: 1) vegetation segmentation, i.e. separating pixels in an image into plant pixels and non-plant pixels, 2) individual object identification, i.e. identification of individual plants (objects) in the set of plant pixels obtained after segmentation, and 3) classification of the plants into two classes, sugar beet (crop) and volunteer potato (weed). In this thesis, steps 1 and 3, i.e. image segmentation and classification of sugar beet/volunteer potato were successfully addressed. Step 2, the identification of individual plants in the images was not addressed. Despite this limitation, it can be concluded that significant progress has been made in this area of study, given the fact that reported algorithms were developed using images captured in full daylight with significant variations in light colour and intensity; a distinct challenge that so far has been circumvented by using hoods and artificial lighting. Yet, the question remains unanswered whether a full pipeline, including all three steps, would be able to meet the requirements identified at the onset of the research. With current hardware and suitable implementation of software, it seems that the requirement of 1 s per image for real-time operation of a weed control system can be attained. The highest classification accuracy of 98.7% obtained in Chapter 5 is supportive in meeting the required 95% control of volunteer potatoes, but when the ConvNet classification would be implemented in a full pipeline also containing vegetation segmentation and individual plant identification, a degraded performance can be expected. Given the fact that the images in this research were obtained under varying daylight conditions, the results showed potential of the proposed approach and compared favourably with classification results in the range of 85-90% that were obtained in various previous researches using hoods and artificial lighting. Therefore, it is safe to say that this research has laid the foundation for a small-sized robotic platform to come into action for weed control in the field.",project-academic
,2018-05-01,a,,real time identification of an unmanned quadcopter flight dynamics using fully tuned radial basis function network," A quadcopter is a four-rotor unmanned aerial vehicle (UAV) with nonlinear and strongly coupled dynamics system. A precise dynamics model is important for developing a robust controller for a quadcopter. NN model capable to obtain the accurate dynamics model from actual data without having any governing mathematical model or priori assumptions. Recursive system identification based on neural network (NN) offers an alternative method for quadcopter dynamics modelling. Recursive learning algorithms, such as Constant Trace (CT) can be implemented to solve insufficient training data and over-fitting problems by developing a new model from real-time flight data in each time step. The modelling results from the NN model could be inaccurate due to inappropriate model structure selection, excessive number of hidden neurons and insufficient training data. Typically, the model structures and hidden neuron are determined by using trial and error approach to obtain the best network configuration. This study utilised a fully tuned radial basis function (RBF) neural network to obtain a minimal structure and avoid pre-determining the number of hidden neurons by introducing the adding and pruning neuron strategy. The prediction performance of the proposed fully tuned RBF was compared with Multilayer Perceptron (MLP), Hybrid Multilayer Perceptron (HMLP) and RBF networks trained with CT algorithm. The findings indicated that the fully tuned RBF with minimal resource allocating networks (MRAN) automatically selected seven neurons with 9.5177 % prediction accuracy and 5.89ms mean training time. The results also showed that the proposed extended minimal resource allocating networks (EMRAN) algorithm is capable to adapt with dynamics changes and infer quadcopter model with an even shorter training time (4.16ms) than MRAN and suitable for real-time system identification.",project-academic
10.1109/INERTIALSENSORS.2018.8577143,2018-09-01,p,IEEE,visual lnertial hybridization technique based on beacons identified by deep learning," Safran has been working for several years on autonomy of vehicles. Whether it is airborne with the UAV Patroller, or on the ground with the military vehicle eRider and with the civilian autonomous car in cooperation with Valeo. This paper focuses on the use of visual information to improve the localization of the car, more precisely, it presents, from a theoretical point of view, the hybridization of the inertial sensors measurement with the line of sight of known position visual beacons: road signs detected on the camera image thanks to deep learning. This fusion algorithm has been implemented in a prototype version of Safran's well know Epsilon 10 navigator and simulation results as well as first real-time results are presented.",project-academic
,2015-01-01,a,,artificial neural controller synthesis for torcs," With the development of science and technology, computer games, video games
and mobile games as an entertainment are becoming more popular in our society.
Although all of the digital games offer excellent graphics, the quality of gameplays
is still a weak point of many games, particularly off-line games. There are few
crucial issues that could improve off-line gameplay. Storyline, level of difficulty,
rewards, reinforcement used, gaming strategy, and the inclusion of None-Player
Character (NPC). NPC is an important factor in a game. Player can easily complete
the game if the NPC used is too easy to be defeated. In other way, player may
uninstall the game if they found the game is not beatable after spending few days
on the game. As such, there are many Artificial Intelligence (AI) techniques have
been introduced and included in different games genres in order to generate better
and attractive NPC. Those NPCs may consist of human player characteristics and
behaviors in handling the game. Generating car racing game NPC is crucial as there
are complex problems found in car racing game. Many factors can influence the
controller's behavior such as varying road conditions, damage control and
unexpected behaviors of opponents. The inclusion of AI technique could generate
better car racing game NPC and it is also beneficial to autonomous mobile car
manufacturing as the generated controllers could be transferred to real car for auto
piloting. In this research, a free open source 3D-based simulator named The Open
Racing Car Simulator (TORCS) is chosen as the research platform. The main
motivation of this research is to investigate whether hybrid Differential Evolution
(DE) and Feed-forward Neural Network (FFNN) as well as hybrid Pareto-based
Differential Evolution (POE) and FFNN could generate better controllers that could
replace normal NPC used in the car racing games. The focuses of the experiments
involved four main research objectives: (1) to test the feasibility of the hybrid DE
and FFNN in TORCS; (2) to obtain a suitable fitness function for evolving
autonomous car controllers; (3) to reduce the time taken in the optimization
processes and improve the efficiency of controllers' driving behaviors by minimizing
the number of sensors used; and (4) to determine which combination of multiobjective
functions is most suitable for evolving the required autonomous car
controllers. The results showed: (1) DE hybrid FFNN could generate optimal
controllers, (2) the proposed fitness function had successfully generated the
required car's racing controllers, (3) the proposed minimization algorithm had been
successfully minimize the number of RF sensors used, (4) the PDE algorithm could
be implemented to generate optimal solutions for car racing controllers, and (5) the
combination of components for average car speed and distance between the car
and track axis is very important compared to other components. As a conclusion,
this research has shown that the DE hybrid FFNN algorithm and PDE hybrid FFNN
algorithm are useful and promising in evolving autonomous car racing controller.",project-academic
,2009-07-23,p,World Scientific and Engineering Academy and Society (WSEAS),plenary lecture 1 concurrent neural classifiers for pattern recognition with applications in biometrics satellite imagery and autonomous navigation," We present the model of Concurrent Neural Classifiers (CNC) representing a collection of small neural networks, which use a global winner-takes-all strategy. Each neural module is trained to correctly classify the patterns of one class only and the number of modules equals the number ""M"" of classes. One considers the case of choosing the SOM (Self-Organized-Map) as a neural module. The CNC training technique is a supervised one, but for any individual net, the SOM specific unsupervised training algorithm is used. We built ""M"" training pattern sets and each neural module is trained with the pattern set characterized by the corresponding class label.

Several presented CNC applications are dedicated to biometrics; first one has as target the recognition of color facial images and second belongs to iris recognition. One also considers a CNC application corresponding to the case of decision fusion by implementation of a multimodal biometric model.

Second series of applications focuse on the CNC model for pattern recognition in multispectral satellite imagery. The implemented neural classifiers are evaluated using some LANDSAT ETM+ images composed by a set of multispectral pixels, each pixel corresponding to one of several categories (vegetation, buildings, water, and so on). Third kind of considered CNC applications correspond to visual identification of road direction of an autonomous vehicle. We present the experimental results obtained by computer simulation. We have also performed, trained and tested a real time neural path follower based on CNC model, implemented on a mobile robot (car toy).",project-academic
10.1155/2011/523094,2011-01-01,a,Hindawi,navigation behaviors based on fuzzy artmap neural networks for intelligent autonomous vehicles," The use of hybrid intelligent systems (HISs) is necessary to bring the behavior of intelligent autonomous vehicles (IAVs) near the human one in recognition, learning, adaptation, generalization, decision making, and action. First, the necessity of HIS and some navigation approaches based on fuzzy ArtMap neural networks (FAMNNs) are discussed. Indeed, such approaches can provide IAV with more autonomy, intelligence, and real-time processing capabilities. Second, an FAMNN-based navigation approach is suggested. Indeed, this approach must provide vehicles with capability, after supervised fast stable learning: simplified fuzzy ArtMap (SFAM), to recognize both target-location and obstacle-avoidance situations using FAMNN1 and FAMNN2, respectively. Afterwards, the decision making and action consist of two association stages, carried out by reinforcement trial and error learning, and their coordination using NN3. Then, NN3 allows to decide among the five (05) actions to move towards 30°, 60°, 90°, 120°, and 150°. Third, simulation results display the ability of the FAMNN-based approach to provide IAV with intelligent behaviors allowing to intelligently navigate in partially structured environments. Finally, a discussion, dealing with the suggested approach and how its robustness would be if implemented on real vehicle, is given.",project-academic
,2015-01-01,a,,intelligent and connected traffic systems," This paper describes the structured approach involved in the development of an Intelligent Autonomous (self­ driving, unmanned, driverless or robotic) Vehicles. In which autopilot with artificial intelligence are critical subsystems whose development requires multidisciplinar y approach along with concurrent engineering to create a better, safer and reliable future. We have studied and implemented a miniature scale model with outcome of satisfactory results of supporting realistic vehicular mobility simulation using concepts of swarm technology discussed in this paper. Our Model must be equipped with a variety of instrumentation and controls depending upon the mission of the target vehicle. Mechatronics, Systems Engineering (SE), Control Systems (CS), Swarm Technology, Artificial Intelligence, Image Processing Cloud Computing, Virtualization with caching, Fuzzy Logic and Neural Networks has a potential scope of design for the prototype needed to be developed that will navigate to a desired location with obstacle avoidance. In this design of autonomous vehicles have access to information about their surroundings gathered from its several sensors such as Radar, GPS including a very important component of this system Infrastructure Unit which is connected virtually with Vehicle's Operating System, mapping and direction system is discussed broadly. Here, Infrastructure Unit plays a major role in routing the traffic to maintain free flow and accident avoidance, by provides information such as Routes, Traffic, Time, Directions to Vehicles and maintain constant speed for all vehicles to achieve an efficient autonomous transportation reducing accidents to zero. To improve the response time and storage of V2I Communication a new approach of caching and virtualization are encapsulated with a better and faster hardware such as Solid State Technology. This study has various applications in Space Science, Oceanography, and Automation in Traffic control which can effortlessly meet the necessity, scalability of future Generation.",project-academic
,1990-06-01,a,,guidance and control system for an autonomous vehicle," Abstract : The Naval Postgraduate School (NPS) is currently involved in a long- term project to investigate and develop real-time control software, artificial intelligence, computer architecture and control systems theory as they pertain to U.S. Navy autonomous vehicle programs. In support of this goal, the NPS is currently designing and fabricating a testbed autonomous underwater vehicle. This work describes the design, development, and testing of a Guidance Subsystem for this testbed vehicle which uses portions of cubic spirals as the desired path to follow between waypoints. In addition, data translation firmware and real-time software for the control surfaces and main motors is designed, implemented and tested. The process of selecting and implementing an appropriate computer architecture in support of these goals is also discussed and detailed, along with the choice of associated computer hardware and real-time operating system software. (rh)",project-academic
10.1007/978-981-16-1249-7_40,2022-01-01,a,,naturalistic driving simulation using automation," The automobile industry has been finding ways to make driving safer and more convenient. We have reached a point where we need to automate the process of driving and make it more affordable. The present implementations are very robotic and cannot run among human-driven vehicles, and this made us realize the need of having a more naturalistic driving style for the autonomous vehicles. This research paper focuses on making a level 3 autonomous vehicle with the help of computer vision and deep learning. The main objective is to achieve the most ideal results in lane detection and object detection which can be worked upon to improve results. The reason that this project is of such great value is the fact that 80%of road accidents happen due to human error and negligence and we believe that providing a driver aid of some sorts could be really helpful in such scenarios. With the help of this paper we will be able to obtain high values with great accuracy with the help of which this can be implemented in real-time vehicles by just making a few alterations and by simple calibrations. We believe this will be a step toward a complete autonomous future.",project-academic
,2016-05-27,a,E.T.S. de Ingenieros Informáticos (UPM),sistema de comunicaciones v2x para vehiculos inteligentes como soporte para sistemas cooperativos," En el desarrollo socioeconomico de la Union Europea se contemplan los sistemas inteligentes de transporte cooperativos (C-ITS) como un medio para reducir la siniestralidad, mejorar la calidad medioambiental (ahorro de energia y reduccion de la contaminacion), aumento de la eficiencia del transporte, de la capacidad de la infraestructura existente y de la productividad de las empresas, especialmente las de transporte. Estos C-ITS estan englobados en el plan 2020 de la Union Europea sobre las Smart Cities. Un paso previo a conseguir las aplicaciones cooperativas es la puesta en servicio de VANETs (Vehicular Area NETworks) y para ello son necesarias las comunicaciones intervehiculares (V2V) y con la infraestructura (V2I), denominadas genericamente como V2X. Sin embargo, en la actualidad no existe disponible comercialmente ningun tipo de tecnologia ni hardware ni software para dar soporte a estas comunicaciones en el entorno vehicular, quedando los equipos disponibles al uso restringido de los fabricantes de automoviles o empresas de electronica, por lo que la implantacion de esta tecnologia queda muy lejos de un usomasivo orientandose sobre todo hacia el ambito de la investigacion, en proyectos de desarrollo de sistemas cooperativos e, incluso, de vehiculos autonomos. Por tanto, en esta tesis doctoral se ha planteado el desarrollo de un hardware de comunicaciones y su software de control. Este debe ser capaz de dar servicios a comunicaciones V2X, siguiendo los estandares Europeos e internacionales en el ambito y todos los elementos que caracterizan esta tecnologia. Asimismo, el correcto funcionamiento de esta tecnologia de comunicaciones ha sido validado mediante la implementacion y puesta en servicio de cuatro sistemas cooperativos que involucran a los tres elementos fundamentales de la carretera: el vehiculo, la via y los usuarios. Para ello se ha colaborado con el grupo de investigacion Sistemas Inteligentes para la Movilidad y Comunicacion Accesible (SIMCA) perteneciente al Departamento de Inteligencia Artificial de la Escuela Tecnica Superior de Ingenieros Informaticos y con el Instituto Universitario de investigacion del Automovil (INSIA) ambos de la Universidad Politecnica de Madrid. Durante el desarrollo de esta tesis se ha utilizado la tecnologia disponible mas puntera en ese momento. En concreto se han utilizado dos tecnologias totalmente diferentes de comunicacion, WSAN (Redes inalambricas de sensores y actuadores) y DSRC (Comunicaciones dedicadas de corto alcance), las cuales tienen diferentes estandares de comunicacion. Inicialmente y gracias a la tecnologia WSAN se desarrollo un novedoso algoritmo de enrutamiento basado en geoposicionamiento creando una VANET de recoleccion de datos. Una vez demostrada la capacidad de crear una VANET lo suficientemente robusta y fiable se desarrollo un sistema cooperativo para prevenir accidentes con peatones. Posteriormente con la liberacion de la normativa europea de comunicaciones intervehiculares, a traves del Instituto Europeo de Estandarizacion de las Telecomunicaciones (ETSI), se pudo avanzar hacia la tecnologia DSRC. Para ello se ha desarrollado un modulo de comunicaciones ITS de diseno propio, denominado ITS DSRC-UPM-INSIA. Los estandares de comunicacion intervehicular han sido analizados y se ha desarrollado un software que cumple las especificaciones para poder realizar una geocomunicacion. Durante la implementacion de estas se han detectado diferentes problemas y errores los cuales se han ido solucionando. Finalmente gracias a los modulos DSRC-UPM-INSIA se han desarrollado aplicaciones cooperativas de asistencia al conductor ADAS (Advanced Driver Assistance System) para demostrar las funcionalidades y capacidades de los modulos. En esta tesis se muestran tres sistemas cooperativos que se han desarrollado con la tecnologia DSRC que abordan diferentes problematicas: Un sistema de aviso a peatones en entornos urbanos e interurbanos, usando comunicaciones V2V y V2P. Sistema de aviso de la presencia de ciclistas en las inmediaciones del vehiculo, usando comunicaciones V2V y V2P. Aviso de motocicletas en carreteras con baja visibilidad incluyendo avisos de angulo muerto, usando comunicaciones V2V. El sistema cooperativo basado en WSAN y los tres sistemas cooperativos basados DSRC expuestos en la presente tesis han sido probados en condiciones controladas y de trafico real obteniendose unos resultados optimos. None ABSTRACT In the socioeconomic development of the European Union, the cooperative intelligent transport systems (C-ITS) are targeted towards reducing accidents, improving environmental quality (energy conservation and pollution reduction), increasing efficiency of transportation, increasing the capacity of the current infrastructure and business productivity. These C-ITS are part of the 2020 plan of the European Union for Smart Cities. A previous step to getting the cooperative applications is to create VANETs (Vehicular Area Networks) and for that the inter-vehicle communications (V2V) and vehicle to infrastructure (V2I) are necessary, generically known as V2X. However, there is currently no commercially available technology or any hardware or software to support these communications in the vehicular environment, leaving the equipment available to the restricted use of automakers and electronics companies, exclusively. Therefore, the implementation of this technology is far from widespread use, especially oriented towards the field of research, in development projects of cooperative systems and even autonomous vehicles. Consequently, this thesis proposes the development of hardware and control software, that is capable of providing services to communications V2X, following European and international standards in the field. Once implemented the core system, the proper functioning of this communications technology has been validated through implementation and commissioning of four cooperative systems involving the three fundamental elements of the road: the vehicle, route and users. This thesis has been developed in collaboration with the research group Intelligent Systems for Mobility and Communication Accessible (SIMCA) belonging to Department of Artificial Intelligence of the School of Computer Engineers and the University Automobile Research Institute (INSIA) both belonging to Technical University ofMadrid. In order to achieve this, the most advanced technology available at that time has been used: Two completely different communication technologies have been applied, WSAN (Wireless Sensor and Actuator Network) and DSRC (Dedicated Short Range Communication), which follow different communication standards. At first a novel routing algorithm was developed with the WSAN technology, based on geolocation and creating a VANET type collection data tree. Once demonstrated the ability to create a sufficiently robust and reliable VANET a cooperative system has been developed for the avoidance of collisions with pedestrians. Later, with the release of the European standards for inter-vehicle communications, through the European Telecommunications Standards Institute (ETSI), the European DSRC technology (ITS-G5) has undergoes an important step forward to create a VANET with this technology, the DSRC module UPM-INSIA has been designed as part of this thesis, with the ability of perform V2X communications following European Standards to guarantee the interoperability. In order to do so, intervehicular communication standards have been analyzed and developed a software that meets the specifications to provide geocommunication. During the implementation of the standards different lacks and errors of the current delivered version have been detected which have been solved. Together with the DSRC-UPM-INSIA modules, a set of cooperative ADAS applications have also been developed to demonstrate their functionalities and capacities. In this thesis three cooperative systems have been developed with the DSRC technology that tackle different problems: Pedestrian warning system for urban and interurban roads, using V2V and V2P communications. Bike rider presence warning system using V2V and V2P communications. Motorcycle warning system for road with poor visibility, including blid spot warning, using V2V communications The cooperative system based on WSAN and three cooperative systems based DSRC presented in this thesis have been tested in controlled conditions and real traffic situations. The systems have obtained optimal results.",project-academic
,1996-06-01,a,,신경회로망 기반 스테레오 비젼을 이용한 실시간 거리 계측," A real time depth measurement scheme with a neural network-based stereo vision is proposed. The depth information is very useful for autonomous vehicle or intelligent robot tasks. Image matching and distance interpolation are necessary for the stereo vision based depth computation. Computation load is a problem for real time applications. The proposed Lateral Information Propagation Neural Networks (LIPN) is for the real time stereo vision. Hardware systems for dynamic programming and interpolation can be implemented with the LIPN for image matching and for depth information of whole image, respectively. The networks are composed of two layers: input and output layers. Each output unit has connections from outputs of its neighbor units as well as that of its input unit. The output value of each unit is updated toward the weighted sum of inputs and outputs of some neighbor units at each time step. The information of each unit propagates to its neighbor units with such neurocomputing mechanism. The proposed idea is proven through some simulation for the stereo images.",project-academic
,2006-01-01,a,,aplicacion de metodos de inteligencia artificial para la toma de decisiones en simulacion de moviles," Este proyecto, realizado en la Universidad Complutense de Madrid para la asignatura de Sistemas Informaticos a peticion de la empresa Eads-Casa,
consiste en la simulacion mediante tecnicas de inteligencia artificial del
comportamiento de un UAV (Vehiculo Aereo no Tripulado), capaz de tomar
decisiones sobre su trayectoria y encontrar un camino optimo entre dos puntos
frente a un conjunto de obstaculos y teniendo en cuenta diversos factores
limitantes. El algoritmo principal esta implementado en java con una interfaz
grafica en 3-D en Matlab.
[ABSTRACT]
This project, carried out in the “Universidad Complutense de Madrid” for
the subject of Computers Systems at request of the EADS-CASA company,
consists in the simulation by means of techniques of artificial intelligence of the
behaviour of an UAV (Unmanned Air Vehicle), capable of taking decisions
about his path and find an optimum way between two points facing a group of
obstacles and taking into account different restricted factors. The principal
algorithm is implemented in java, with a graphical interface in 3-D in Matlab.",project-academic
10.1109/TIV.2016.2551553,2016-04-15,a,IEEE,the role of machine vision for intelligent vehicles," Humans assimilate information from the traffic environment mainly through visual perception. Obviously, the dominant information required to conduct a vehicle can be acquired with visual sensors. However, in contrast to most other sensor principles, video signals contain relevant information in a highly indirect manner and hence visual sensing requires sophisticated machine vision and image understanding techniques. This paper provides an overview on the state of research in the field of machine vision for intelligent vehicles. The functional spectrum addressed covers the range from advanced driver assistance systems to autonomous driving. The organization of the article adopts the typical order in image processing pipelines that successively condense the rich information and vast amount of data in video sequences. Data-intensive low-level “early vision” techniques first extract features that are later grouped and further processed to obtain information of direct relevance for vehicle guidance. Recognition and classification schemes allow to identify specific objects in a traffic scene. Recently, semantic labeling techniques using convolutional neural networks have achieved impressive results in this field. High-level decisions of intelligent vehicles are often influenced by map data. The emerging role of machine vision in the mapping and localization process is illustrated at the example of autonomous driving. Scene representation methods are discussed that organize the information from all sensors and data sources and thus build the interface between perception and planning. Recently, vision benchmarks have been tailored to various tasks in traffic scene perception that provide a metric for the rich diversity of machine vision methods. Finally, the paper addresses computing architectures suited to real-time implementation. Throughout the paper, numerous specific examples and real world experiments with prototype vehicles are presented.",project-academic
10.1109/ITSC.2019.8917403,2019-10-01,p,IEEE,efficient autonomy validation in simulation with adaptive stress testing," During the development of autonomous systems such as driverless cars, it is important to characterize the scenarios that are most likely to result in failure. Adaptive Stress Testing (AST) provides a way to search for the most-likely failure scenario as a Markov decision process (MDP). Our previous work used a deep reinforcement learning (DRL) solver to identify likely failure scenarios. However, the solver’s use of a feed-forward neural network with a discretized space of possible initial conditions poses two major problems. First, the system is not treated as a black box, in that it requires analyzing the internal state of the system, which leads to considerable implementation complexities. Second, in order to simulate realistic settings, a new instance of the solver needs to be run for each initial condition. Running a new solver for each initial condition not only significantly increases the computational complexity, but also disregards the underlying relationship between similar initial conditions. We provide a solution to both problems by employing a recurrent neural network that takes a set of initial conditions from a continuous space as input. This approach enables robust and efficient detection of failures because the solution generalizes across the entire space of initial conditions. By simulating an instance where an autonomous car drives while a pedestrian is crossing a road, we demonstrate the solver is now capable of finding solutions for problems that would have previously been intractable.",project-academic
,2019-07-16,a,,efficient autonomy validation in simulation with adaptive stress testing," During the development of autonomous systems such as driverless cars, it is important to characterize the scenarios that are most likely to result in failure. Adaptive Stress Testing (AST) provides a way to search for the most-likely failure scenario as a Markov decision process (MDP). Our previous work used a deep reinforcement learning (DRL) solver to identify likely failure scenarios. However, the solver's use of a feed-forward neural network with a discretized space of possible initial conditions poses two major problems. First, the system is not treated as a black box, in that it requires analyzing the internal state of the system, which leads to considerable implementation complexities. Second, in order to simulate realistic settings, a new instance of the solver needs to be run for each initial condition. Running a new solver for each initial condition not only significantly increases the computational complexity, but also disregards the underlying relationship between similar initial conditions. We provide a solution to both problems by employing a recurrent neural network that takes a set of initial conditions from a continuous space as input. This approach enables robust and efficient detection of failures because the solution generalizes across the entire space of initial conditions. By simulating an instance where an autonomous car drives while a pedestrian is crossing a road, we demonstrate the solver is now capable of finding solutions for problems that would have previously been intractable.",project-academic
10.1016/J.ENGAPPAI.2016.08.019,2017-06-01,a,Pergamon,gpu based parallel optimization of immune convolutional neural network and embedded system," Up to now, the image recognition system has been utilized more and more widely in the security monitoring, the industrial intelligent monitoring, the unmanned vehicle, and even the space exploration. In designing the image recognition system, the traditional convolutional neural network has some defects such as long training time, easy over-fitting and high misclassification rate. In order to overcome these defects, we firstly used the immune mechanism to improve the convolutional neural network and put forward a novel immune convolutional neural network algorithm, after we analyzed the network structure and parameters of the convolutional neural network. Our algorithm not only integrated the location data of the network nodes and the adjustable parameters, but also dynamically adjusted the smoothing factor of the basis function. In addition, we utilized the NVIDIA GPU (Graphics Processing Unit) to accelerate the new immune convolutional neural network (ICNN) in parallel computing and built a real-time embedded image recognition system for this ICNN. The immune convolutional neural network algorithm was improved with CUDA programming and was tested with the sample data in the GPU-based environment. The GPU-based implementation of the novel immune convolutional neural network algorithm was made with the cuDNN, which was designed by NVIDIA for GPU-based accelerating of DNNs in machine learning. Experimental results show that our new immune convolutional neural network has higher recognition rate, more stable performance and faster computing speed than the traditional convolutional neural network.",project-academic
10.1109/AERO.2019.8742084,2019-03-02,p,IEEE,estimating wheel slip of a planetary exploration rover via unsupervised machine learning," Planetary exploration rovers often encounter imperfect traction and wheel slip, which negatively impacts navigation and in the worst case can result in permanent immobilization. Recent studies have applied machine learning to estimate rover wheel slip, which this paper extends via the implementation of three unsupervised learning algorithms: self-organizing maps, k-means clustering, and autoencoding. Unsupervised learning is preferred since labelled training data may be risky or time-consuming to obtain on site; each algorithm classifies the rover's current slip state into one of several discrete categories. Proprioceptive sensors are used to avoid added complexity and prevent a reliance on visual odometry. The algorithms are validated using sensor data from a planetary rover driving on a sandy incline, and performance is evaluated for different velocities, sensor inputs, slip classes, algorithm parameters, and data filters. Self-organizing maps (SOM) demonstrate the best slip classification accuracy, achieving 97% immobilization detection in the ideal two-class case. At rover-like speeds of 0.10 m/s, 88% accuracy is demonstrated for three classes. For ten slip classes, 71% accuracy is obtainable. Compared to SOM, k-means loses 5-30% accuracy and autoencoders lose 2-10% accuracy. SOM is most computationally intensive while k-means is least. An analysis of significant parameters for algorithm tuning displays accuracy benefits of up to 25 %, and mis-classifications can be further reduced by modifying class boundaries. The algorithms are generic and can be trained for different terrain, environment or vehicle parameters, and although some labelled data is needed to directly associate unsupervised clusters with slip classes, it is significantly less than what a fully-supervised algorithm requires. Unsupervised learning is thus considered promising for robust real-time rover slip estimation.",project-academic
,2016-11-09,,,intelligent cargo delivering and collecting device of unmanned aerial vehicle and implementation method," The invention provides an intelligent cargo delivering and collecting device of an unmanned aerial vehicle and an implementation method, which sufficiently utilize the modern network and the artificial intelligence technology. The intelligent cargo delivering and collecting device comprises a delivering aerial vehicle, a dropping cargo delivering and collecting intelligent device assembly and an intelligent cargo delivering and collecting implementation method; the delivering aerial vehicle is suspended in the mid air to intelligently carry out cargo packet delivering or collecting operation and repeated landing and taking-off working manners of the unmanned aerial vehicle are changed; the device is more convenient, more efficient and safer and realizes intelligent direct delivery; the investment of manpower and material resources of secondary handover, transportation and home delivery of cargo packets can also be greatly and effectively reduced, so that the cost is saved and resources are saved. Especially, aiming at current situations of social development and modern living manners, the delivering aerial vehicle is suspended in the air and the cargo packets can be rapidly and directly transferred and can be easily, conveniently, directly and intelligently collected and delivered; the intelligent cargo delivering and collecting device can give better services to old people, dwelling people and people working and living in high-rise buildings, and can also be adaptive to outdoor consumption requirements of people at anytime and anywhere and meet the fashion psychology of pursuing high-tech content and following time trend of young people.",project-academic
,2017-01-04,,,unmanned aerial vehicle transport airborne robot cargo express delivery device and implementation method," The invention discloses an unmanned aerial vehicle transport airborne robot cargo express delivery device and an implementation method. By making full use of modern network, artificial intelligence and modern aerial vehicle technology, a cargo express delivery system network operation platform receives network transaction orders of customers, cargoes and parcels, particularly fast food delivery, can be fast delivered to homes and handed over to the customers within the shortest time, the problem of 'last one-meter distance' of logistic express delivery is really solved, elder populations, residence populations, high-rise building office and living populations can be more effectively served by aerial vehicle transport, airborne delivery, robot operation, fast direct arrival, easiness, convenience and artificial intelligent delivery modes and programs, whenever and wherever possible consumption demands of people in outdoor places and even in the driving process can be met, and the fashion psychology of young people pursuing high-technology content and following trend is met.",project-academic
10.23919/EETA.2018.8493233,2018-07-09,p,IEEE,exploiting posit arithmetic for deep neural networks in autonomous driving applications," This paper discusses the introduction of an integrated Posit Processing Unit (PPU) as an alternative to Floating-point Processing Unit (FPU) for Deep Neural Networks (DNNs) in automotive applications. Autonomous Driving tasks are increasingly depending on DNNs. For example, the detection of obstacles by means of object classification needs to be performed in real-time without involving remote computing. To speed up the inference phase of DNNs the CPUs on-board the vehicle should be equipped with co-processors, such as GPUs, which embed specific optimization for DNN tasks. In this work, we review an alternative arithmetic that could be used within the co-processor. We argue that a new representation for floating point numbers called Posit is particularly advantageous, allowing for a better trade-off between computation accuracy and implementation complexity. We conclude that implementing a PPU within the co-processor is a promising way to speed up the DNN inference phase.",project-academic
10.1109/ACC.2016.7525529,2016-07-06,p,IEEE,a supervised adaptive learning based fuzzy controller for a non linear vehicle system using neural network identification," In this paper, a Supervised Adaptive Learning-based Fuzzy Controller (ALFC) with Neural Network Identification and Convex Parameterization is designed to identify and control the unmanned vehicle in an autonomous parking system. The objective is to achieve robust learning and control while maintaining a low implementation cost. The proposed algorithm design incorporates the following learning and control theorems - non-linear system identification using neural network, fuzzy logic, supervised adaptive learning as well as multiple model based convex parameterization. To demonstrate the algorithm in a more straight forward manner, we are using a real nonlinear unmanned autonomous driving system as an example to apply the algorithm and showing the superior performance of controller. In the autonomous driving system, the proposed method can be used for both estimating and further controlling a desired vehicle speed and steering wheel turning. With a supervised adaptive learning-based method, robustness can be also assured under various operating environments regardless of unpredictable disturbances. The convex parameterization further improves the speed of convergence of the adaptive learning process for the Fuzzy controller by using the multiple models concept. Last but not least, comparative experiments have also demonstrated that systems equipped with the new algorithm are able to achieve faster and smoother convergence.",project-academic
10.1109/IV48863.2021.9575135,2021-07-11,p,IEEE,end to end intersection handling using multi agent deep reinforcement learning," Navigating through intersections is one of the main challenging tasks for an autonomous vehicle. However, for the majority of intersections regulated by traffic lights, the problem could be solved by a simple rule-based method in which the autonomous vehicle behavior is closely related to the traffic light states. In this work, we focus on the implementation of a system able to navigate through intersections where only traffic signs are provided. We propose a multi-agent system using a continuous, model-free Deep Reinforcement Learning algorithm used to train a neural network for predicting both the acceleration and the steering angle at each time step. We demonstrate that agents learn both the basic rules needed to handle intersections by understanding the priorities of other learners inside the environment, and to drive safely along their paths. Moreover, a comparison between our system and a rule-based method proves that our model achieves better results especially with dense traffic conditions. Finally, we test our system on real world scenarios using real recorded traffic data, proving that our module is able to generalize both to unseen environments and to different traffic conditions.",project-academic
,2021-04-28,a,,end to end intersection handling using multi agent deep reinforcement learning," Navigating through intersections is one of the main challenging tasks for an autonomous vehicle. However, for the majority of intersections regulated by traffic lights, the problem could be solved by a simple rule-based method in which the autonomous vehicle behavior is closely related to the traffic light states. In this work, we focus on the implementation of a system able to navigate through intersections where only traffic signs are provided. We propose a multi-agent system using a continuous, model-free Deep Reinforcement Learning algorithm used to train a neural network for predicting both the acceleration and the steering angle at each time step. We demonstrate that agents learn both the basic rules needed to handle intersections by understanding the priorities of other learners inside the environment, and to drive safely along their paths. Moreover, a comparison between our system and a rule-based method proves that our model achieves better results especially with dense traffic conditions. Finally, we test our system on real world scenarios using real recorded traffic data, proving that our module is able to generalize both to unseen environments and to different traffic conditions.",project-academic
,2019-04-19,a,,deep learning based automatic video annotation tool for self driving car," In a self-driving car, objection detection, object classification, lane detection and object tracking are considered to be the crucial modules. In recent times, using the real time video one wants to narrate the scene captured by the camera fitted in our vehicle. To effectively implement this task, deep learning techniques and automatic video annotation tools are widely used. In the present paper, we compare the various techniques that are available for each module and choose the best algorithm among them by using appropriate metrics. For object detection, YOLO and Retinanet-50 are considered and the best one is chosen based on mean Average Precision (mAP). For object classification, we consider VGG-19 and Resnet-50 and select the best algorithm based on low error rate and good accuracy. For lane detection, Udacity's 'Finding Lane Line' and deep learning based LaneNet algorithms are compared and the best one that can accurately identify the given lane is chosen for implementation. As far as object tracking is concerned, we compare Udacity's 'Object Detection and Tracking' algorithm and deep learning based Deep Sort algorithm. Based on the accuracy of tracking the same object in many frames and predicting the movement of objects, the best algorithm is chosen. Our automatic video annotation tool is found to be 83% accurate when compared with a human annotator. We considered a video with 530 frames each of resolution 1035 x 1800 pixels. At an average each frame had about 15 objects. Our annotation tool consumed 43 minutes in a CPU based system and 2.58 minutes in a mid-level GPU based system to process all four modules. But the same video took nearly 3060 minutes for one human annotator to narrate the scene in the given video. Thus we claim that our proposed automatic video annotation tool is reasonably fast (about 1200 times in a GPU system) and accurate.",project-academic
10.3901/CJME.2012.01.098,2012-01-20,a,Chinese Mechanical Engineering Society,online learning control for hybrid electric vehicle," Improvements in hybrid electric vehicle (HEV) fuel economy and emissions heavily depend on an efficient energy management strategy (EMS). However, the uncertainty of future driving conditions generally cannot be easily tackled in EMS design. Most existing EMSs act upon fixed parameters and cannot adapt to varying driving conditions. Therefore, they usually fail to fully explore the potential of these advanced vehicles. In this paper, a novel EMS design procedure based on neural dynamic programming (NDP) is proposed. The NDP is a generic online learning algorithm, which combines stochastic dynamic programming (SDP) and the temporal difference (TD) method. Instead of computing the utility function and optimal control actions through Bellman equations, the NDP algorithm uses two neural networks to approximate them. The weights of these neural networks are updated online by the TD method. It avoids the high computational cost that SDP suffers from and is suitable for real-time implementation. The main advantages of NDP EMS is that it does not rely on prior information related to future driving conditions, and can self-tune with a wide variance in operating conditions. The NDP EMS has been applied to “Qianghua-I”, a prototype of a parallel HEV, using a revolving drum test bench for verification. Experiment results illustrate the potential of the proposed EMS in terms of fuel economy and in keeping state of charge (SOC) deviations at a low level. The proposed research ensures the optimality of NDP EMS, as well as real-time applicability.",project-academic
10.1109/ACCESS.2018.2808538,2018-03-26,a,Institute of Electrical and Electronics Engineers (IEEE),overcoming the loss of performance in unmanned ground vehicles due to the terrain variability," Performance in autonomous driven vehicles is susceptible of degradation when traversing different terrains, thus needing motion controllers to be tuned for different terrain profiles. Such tuning stage is a time consuming process for the programmer or operator, and it is often based on intuition or heuristic approaches, and once tuned, the performance of the vehicle varies according to the terrain nature. In this context, we provide a visual based approach to identify terrain variability and its transitions, while observing and learning the performance of the vehicle using machine learning techniques. Based on the identified terrain and the knowledge regarding the performance of the vehicle, our system self-tunes the motion controller, in real time, to enhance its performance. In particular, the trajectory tracking errors are reduced, the control input effort is decreased, and the effects of the wheel-terrain interaction are mitigated preserving the system robustness. The tests were carried out by simulation and experimentation using a robotized commercial platform. Finally, implementation details and results are included in this paper, showing an enhancement in the motion performance up to 92.4% when the highest accuracy of the terrain classifier was 84.3%.",project-academic
,2017-09-25,a,Daffodil International University,reconfigurable processor for deep learning in autonomous vehicles," The rapid growth of civilian vehicles has stimulated the development of advanced driver assistance systems (ADASs) to be equipped in-car. Real-time autonomous vision (RTAV) is an essential part of the overall system, and the emergence of deep learning methods has greatly improved the system quality, which also requires the processor to offer a computing speed of tera operations per second (TOPS) and a power consumption of no more than 30 W with programmability. This article gives an overview of the trends of RTAV algorithms and different hardware solutions, and proposes a development route for the reconfigurable RTAV accelerator. We propose our field programmable gate array (FPGA) based system Aristotle, together with an all-stack software-hardware co design workflow including compression, compilation, and customized hardware architecture. Evaluation shows that our FPGA system can realize real-time processing on modern RTAV algorithms with a higher efficiency than peer CPU and GPU platforms. Our outlook based on the ASIC-based system design and the ongoing implementation of next generation memory would target a 100 TOPS performance with around 20 W power.",project-academic
10.1109/TVT.2021.3084829,2021-07-08,a,Institute of Electrical and Electronics Engineers (IEEE),guest editorialintroduction to the special section on vehicular networks in the era of 6g end edge cloud orchestrated intelligence," The articles in this special section focus on vehicular networks in the era of 6G mobile communication. With the growth of the vehicle population, vehicular networks play a key role in building safe, efficient, and intelligent transport systems and has been attracting a lot of attention from both academic and industrial communities around the world. The rise of autonomous driving technology and the prosperity of mobile applications, e.g., real-time video analytic, image-aided navigation, natural language processing, and etc, have brought tremendous pressure on current vehicular networks, e.g., high bandwidth, ultra-low latency, high reliability, high security, powerful computation capability, and massive connections. It is necessary to continue to develop vehicular networks by combining the latest research intends in other fields to meet quickly rising communication and computation demands. The upcoming 6G technology, which provides Holographic and Artificial Intelligence (AI) enabled communications, together with the increasing implementation of artificial intelligence in mobile devices, will lead to a new research trend to end-edge-cloud orchestrated computing with intelligence. It means that, not only the intelligent communication protocols, but also the intelligent computing resource management and machine learning algorithms among the mobile vehicles, the edge and the cloud, should be redesigned to support the development of vehicular networks.",project-academic
10.1007/978-3-319-75928-9_57,2018-03-15,a,"Springer, Cham",an edge computer based driver monitoring system for assisting safety driving," Driver Monitoring System (DMS) is a promising IoT application in Intelligent Transport Systems (ITS) research field. DMS assists car drivers by monitoring their driving activities, sensing incidents to cause possible dangers, and alerting the drivers to prevent accidents. We aim to realize a new DMS that is inexpensive and highly effective. This paper proposes a method for detecting any incidents based on machine learning. The proposed method firstly configures a detector by training in-car environment data and driver’s vital signs gathered from multiple sensors. Then, the detector is embedded in a self-contained edge computer for monitoring a driver in a car. The device is always connected to the information communication network by radio waves. Those data obtained by monitoring are stored in the cloud server. The server learns and analyzes the stored data using processing such as machine learning. As a result, we acquire knowledge leading to safe driving. The edge computer uses these knowledge to process the sensor data in real time, observe the driver, sense the danger, and call attention. These mechanisms prevent occurrence of troubles such as traffic accidents. The paper describes the proposed system overview, implementation method, and initial evaluations.",project-academic
10.1109/SYSOSE.2017.7994953,2017-06-18,p,IEEE,autonomous decision making for a driver less car," Autonomous driving has been a hot topic with companies like Google, Uber, and Tesla because of the complexity of the problem, seemingly endless applications, and capital gain. The technology's brain child is DARPA's autonomous urban challenge from over a decade ago. Few companies have had some success in applying algorithms to commercial cars. These algorithms range from classical control approaches to Deep Learning. In this paper, we will use Deep Learning techniques and the Tensor flow framework with the goal of navigating a driverless car through an urban environment. The novelty in this system is the use of Deep Learning vs. traditional methods of real-time autonomous operation as well as the application of the Tensorflow framework itself. This paper provides an implementation of AlexNet's Deep Learning model for identifying driving indicators, how to implement them in a real system, and any unforeseen drawbacks to these techniques and how these are minimized and overcome.",project-academic
10.1109/TSMC.2018.2850367,2020-11-01,a,Institute of Electrical and Electronics Engineers (IEEE),compensating delays and noises in motion control of autonomous electric vehicles by using deep learning and unscented kalman predictor," Accurate knowledge of the vehicle states is the foundation of vehicle motion control. However, in real implementations, sensory signals are always corrupted by delays and noises. Network induced time-varying delays and measurement noises can be a hazard in the active safety of over-actuated electric vehicles (EVs). In this paper, a brain-inspired proprioceptive system based on state-of-the-art deep learning and data fusion technique is proposed to solve this problem in autonomous four-wheel actuated EVs. A deep recurrent neural network (RNN) is trained by the noisy and delayed measurement signals to make accurate predictions of the vehicle motion states. Then unscented Kalman predictor, which is the adaption of unscented Kalman filter in time-varying-delay situations, combines the predictions of the RNN and corrupted sensory signals to provide better perceptions of the locomotion. Simulations with a high-fidelity, CarSim, full-vehicle model are carried out to show the effectiveness of our RNN framework and the entire proprioceptive system.",project-academic
10.1109/EEEIC/ICPSEUROPE49358.2020.9160705,2020-06-09,p,IEEE,asdvc a self driving vehicle controller using unsupervised machine learning," ASDVC is a self-driving vehicle controller that uses unsupervised machine learning methods, namely clustering based k-means, hierarchical, Gaussian Matrix Model and self-organizing mapping to optimize the path the vehicle follows from the source to destination. The real-time optimal selection of the unsupervised machine learning based motion control algorithm could provide fast response times of under one microsecond during the lateral, longitudinal and angular motion control of the autonomous vehicle. However, it is shown that a simple selection of one of the machine learning methods may not guarantee the optimality of the results. The successful implementation of ASDVC controller in self-driving vehicles could have a significant contribution towards making mobility more reliable and sustainable for the future vehicular transportation systems.",project-academic
10.3390/ELECTRONICS9050832,2020-05-18,a,Multidisciplinary Digital Publishing Institute,novel cnn based ap2d net accelerator an area and power efficient solution for real time applications on mobile fpga," Standard convolutional neural networks (CNNs) have large amounts of data redundancy, and the same accuracy can be obtained even in lower bit weights instead of floating-point representation. Most CNNs have to be developed and executed on high-end GPU-based workstations, for which it is hard to transplant the existing implementations onto portable edge FPGAs because of the limitation of on-chip block memory storage size and battery capacity. In this paper, we present adaptive pointwise convolution and 2D convolution joint network (AP2D-Net), an ultra-low power and relatively high throughput system combined with dynamic precision weights and activation. Our system has high performance, and we make a trade-off between accuracy and power efficiency by adopting unmanned aerial vehicle (UAV) object detection scenarios. We evaluate our system on the Zynq UltraScale+ MPSoC Ultra96 mobile FPGA platform. The target board can get the real-time speed of 30 fps under 5.6 W, and the FPGA on-chip power is only 0.6 W. The power efficiency of our system is 2.8× better than the best system design on a Jetson TX2 GPU and 1.9× better than the design on a PYNQ-Z1 SoC FPGA.",project-academic
10.1109/SIEDS49339.2020.9106581,2020-04-24,p,IEEE,explorer51 indoor mapping discovery and navigation for an autonomous mobile robot," The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint.To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",project-academic
10.1109/IECON.2018.8591129,2018-10-01,p,IEEE,development of an autonomous unmanned surface vehicle with object detection using deep learning," A large number of research has been accomplished in the field of the Unmanned Surface Vehicle (USV) in recent years. As deep learning has the potential to raise the technology to the next level by teaching the algorithm to learn by itself, we aim at developing an autonomous USV which has the capabilities to acquire various types of data and information in offshore areas, process them, and then execute missions based on the situation with the aid of the deep convolutional neural network. This paper describes the implementation of such USV system outfitted with sensors for localization with autonomous navigation technologies and algorithms being adopted for the potential real-life applications such as identifying approaching vehicles to alert the ground station or exploring the surrounding environment of assigned locations. In this manuscript, Global Positioning System (GPS) and compass are equipped to provide the geolocation and the heading for autonomous navigation. Experimental results are provided to validate the proposed implementation. In the end, a summary of current progress is presented as well as the proposed future works.",project-academic
10.1016/J.ISATRA.2020.02.012,2020-06-01,a,Elsevier,adaptive tracking control of an unmanned aerial system based on a dynamic neural fuzzy disturbance estimator," Abstract None None The main goal of this study is developing an adaptive controller which can solve the trajectory tracking for a class of quadcopter unmanned aerial system (UAS), namely a quadrotor. The control design introduces a new paradigm for adaptive controllers based on the implementation of a set of differential neural networks (DNNs) in the consequence section of a Takagi–Sugeno (T–S) fuzzy inference system. This dynamic fuzzy inference structure was used to approximate the UAS description. The particular form of interaction between neural networks and fuzzy inference systems proposed in the present work received the name of dynamic neural fuzzy system (DNFS). An adaptive controller based on this DNFS form was the main solution attained in this study. This DNFS controller was focused on the estimation and compensation of the uncertain section of the Quadrotor dynamics and then, forced the UAS to perform a hover flight while the tracking of desired angular positions succeeded, which results in tracking a desired trajectory in the X-Y plane. The control design methodology supported on the Lyapunov stability theory guaranteed ultimate boundedness of the estimation and tracking errors simultaneously. Several experimental tests in an outdoor environment by using a real Quadrotor platform was performed by using an RTK-GPS (Real Time Kinematic) system to determine the position of the vehicle in the X-Y plane. The experimental results confirmed the superior performance of the proposed algorithm based on the combination of DNNs and T–S techniques with respect to classical robust controllers.",project-academic
10.1109/41.704895,1998-08-01,a,IEEE,modeling of ultrasonic range sensors for localization of autonomous mobile robots," This paper presents a probabilistic model of ultrasonic range sensors using backpropagation neural networks trained on experimental data. The sensor model provides the probability of detecting mapped obstacles in the environment, given their position and orientation relative to the transducer. The detection probability can be used to compute the location of an autonomous vehicle from those obstacles that are more likely to be detected. The neural network model is more accurate than other existing approaches, since it captures the typical multilobal detection pattern of ultrasonic transducers. Since the network size is kept small, implementation of the model on a mobile robot can be efficient for real-time navigation. An example that demonstrates how the credence could be incorporated into the extended Kalman filter (EKF) and the numerical values of the final neural network weights are provided in the appendices.",project-academic
10.1109/FPT.2018.00091,2018-12-01,p,Institute of Electrical and Electronics Engineers Inc.,fpga design for autonomous vehicle driving using binarized neural networks," We propose an autonomous vehicle controlled by FPGAs. In our design, considering embedded systems, we apply the binarized neural networks (BNNs) which can realize a satis-fying result in high speed and accuracy to recognize pedestrians and some obstacles on a given road. To detect the traffic light, a passive camera-based pipeline is applied. Furthermore, the implementation of road lane detection is based on color selection algorithm, Canny Edge Detection, and Hough Transformation. The proposed design is realized by two Xilinx boards: PYNQ-Z1 and Zynq-Xc7Z010. These two FPGA boards cooperate with each other through a shared network cable. In the proposed design, the resource used by Zynq-Xc7Z010 can be greatly reduced and the inference time on the FPGA has been thousands times faster than the software implementation.",project-academic
,2020-05-22,a,,towards automated safety coverage and testing for autonomous vehicles with reinforcement learning," The kind of closed-loop verification likely to be required for autonomous vehicle (AV) safety testing is beyond the reach of traditional test methodologies and discrete verification. Validation puts the autonomous vehicle system to the test in scenarios or situations that the system would likely encounter in everyday driving after its release. These scenarios can either be controlled directly in a physical (closed-course proving ground) or virtual (simulation of predefined scenarios) environment, or they can arise spontaneously during operation in the real world (open-road testing or simulation of randomly generated scenarios). 
In AV testing, simulation serves primarily two purposes: to assist the development of a robust autonomous vehicle and to test and validate the AV before release. A challenge arises from the sheer number of scenario variations that can be constructed from each of the above sources due to the high number of variables involved (most of which are continuous). Even with continuous variables discretized, the possible number of combinations becomes practically infeasible to test. To overcome this challenge we propose using reinforcement learning (RL) to generate failure examples and unexpected traffic situations for the AV software implementation. Although reinforcement learning algorithms have achieved notable results in games and some robotic manipulations, this technique has not been widely scaled up to the more challenging real world applications like autonomous driving.",project-academic
10.1109/ICTAI.2019.00220,2019-11-01,p,IEEE Computer Society,learning to drive via apprenticeship learning and deep reinforcement learning," With the implementation of reinforcement learning (RL) algorithms, current state-of-art autonomous vehicle technology have the potential to get closer to full automation. However, most of the applications have been limited to game domains or discrete action space which are far from the real world driving. Moreover, it is very tough to tune the parameters of reward mechanism since the driving styles vary a lot among the different users. For instance, an aggressive driver may prefer driving with high acceleration whereas some conservative drivers prefer a safer driving style. Therefore, we propose an apprenticeship learning in combination with deep reinforcement learning approach that allows the agent to learn the driving and stopping behaviors with continuous actions. We use gradient inverse reinforcement learning (GIRL) algorithm to recover the unknown reward function and employ REINFORCE as well as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal policy. The performance of our method is evaluated in simulation-based scenario and the results demonstrate that the agent performs human like driving and even better in some aspects after training.",project-academic
,2020-01-12,a,,learning to drive via apprenticeship learning and deep reinforcement learning," With the implementation of reinforcement learning (RL) algorithms, current state-of-art autonomous vehicle technology have the potential to get closer to full automation. However, most of the applications have been limited to game domains or discrete action space which are far from the real world driving. Moreover, it is very tough to tune the parameters of reward mechanism since the driving styles vary a lot among the different users. For instance, an aggressive driver may prefer driving with high acceleration whereas some conservative drivers prefer a safer driving style. Therefore, we propose an apprenticeship learning in combination with deep reinforcement learning approach that allows the agent to learn the driving and stopping behaviors with continuous actions. We use gradient inverse reinforcement learning (GIRL) algorithm to recover the unknown reward function and employ REINFORCE as well as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal policy. The performance of our method is evaluated in simulation-based scenario and the results demonstrate that the agent performs human like driving and even better in some aspects after training.",project-academic
10.20944/PREPRINTS202101.0412.V1,2021-01-21,a,Preprints,raspberry pi for kill mosquitoes by laser," More than 700 thousand human deaths from mosquito bites are observed annually in the world. It is more than 2 times the number of annual murders in the world. In this regard, the invention of new more effective methods of protection against mosquitoes is necessary. In this article for the first time, comprehensive studies of mosquito neutralization using machine vision and a 1 W power laser are considered. Developed laser installation with Raspberry Pi that changing the direction of the laser with a galvanometer. We developed a program for mosquito tracking in real. The possibility of using deep neural networks, Haar cascades, machine learning for mosquito recognition was considered. We considered in detail the classification problems of mosquitoes in images. A recommendation is given for the implementation of this device based on a microcontroller for subsequent use as part of an unmanned aerial vehicle. Any harmful insects in the fields can be used as objects for control.",project-academic
10.2139/SSRN.3772579,2021-01-25,a,,raspberry pi for kill mosquitoes by laser," More than 700 thousand human deaths from mosquito bites are observed annually in the world. It is more than 2 times the number of annual murders in the world. In this regard, the invention of new more effective methods of protection against mosquitoes is necessary. In this article for the first time, comprehensive studies of mosquito neutralization using machine vision and a 1 W power laser are considered. Developed laser installation with Raspberry Pi that changing the direction of the laser with a galvanometer. We developed a program for mosquito tracking in real. The possibility of using deep neural networks, Haar cascades, machine learning for mosquito recognition was considered. We considered in detail the classification problems of mosquitoes in images. A recommendation is given for the implementation of this device based on a microcontroller for subsequent use as part of an unmanned aerial vehicle. Any harmful insects in the fields can be used as objects for control.",project-academic
10.1016/S0921-8890(98)00005-0,1998-10-31,a,North-Holland,a robust landmark based system for vehicle location using low bandwidth vision," This paper presents novel computer algorithms, a system architecture, and the prototype implementation of a vision-based automatic vehicle location system. The objective of the vehicle location system is to keep track of the vehicle location for a human driver, and perhaps to provide the driver with real-time audio directions to his destination. The techniques developed here are equally applicable to autonomous robot navigation. The prototype system uses odometer readings and a skeleton map to perform dead reckoning, and uses low-bandwidth visual information and neural networks to recognize places for correcting cumulative dead reckoning errors. The visual information is also used to detect turns, for dead reckoning at intersections. The system is self-contained in the sense that it requires no infrastructure outside the vehicle, such as external beacons installed on roadways or satellites used by Global Positioning Systems (GPS). The system maintains a large number of location hypotheses and searches for a large number of landmarks stored in a database in real time. Hence the system is robustly able to recover the vehicle location after being lost for various reasons. The system has been tested, with success, in both day and night time, in all four seasons, and on roads in New York City, a regional highway, and on suburban streets.",project-academic
10.1109/TVT.2021.3121985,2021-10-21,a,IEEE,driving tasks transfer using deep reinforcement learning for decision making of autonomous vehicles in unsignalized intersection," Knowledge transfer is a promising concept to achieve real-time decision-making for autonomous vehicles. This paper constructs a transfer deep reinforcement learning (RL) framework to transform the driving tasks in the intersection environments. The driving missions at the unsignalized intersection are cast into a left turn, right turn, and running straight for automated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive through the intersection situation efficiently and safely. This objective promotes the studied vehicle to increase its speed and avoid crashing other vehicles. The decision-making policy learned from one driving task is transferred and evaluated in another driving mission. Simulation results reveal that the decision-making strategies related to similar tasks are transferable. It indicates that the presented control framework could reduce time consumption and realize online implementation.",project-academic
10.1109/ITSC.2019.8917249,2019-10-01,p,IEEE,trade off analysis using synthetic training data for neural networks in the automotive development process," Applications in the field of Deep Learning are constantly increasing the need for extensive, annotated data sets. Simulation software offers the possibility to create data sets of almost any size and thus the potential to cover this need. In the context of autonomous driving the test effort in the development processes increases to an extent that the use of virtual driving environments comes into focus. Deep Learning offers the opportunity to learn advanced driving strategies, starting from image recognition up to trajectory implementation.In this paper different driving simulation environments are used as data sources for the training of a neural network and examined for applicability on the basis of the working example of vehicle detection in image data.The visualizations include CarMaker, Carla and Grand Theft Auto V with different procedures for exporting ground truth information. For object detection, a pre-trained Convolutional Neural Network (CNN) is used and the effects on the detector quality of the data source and data size are investigated.An important part of the task of generating suitable data is the annotation process. The quality of the generated data is a decisive factor in achieving high performance training results. The test executions show that virtual data sources in training achieve lower detection rates in contrast to real data, but are more cost-effective in the overall context by scales.",project-academic
10.1109/I2CACIS.2017.8239054,2017-10-01,p,IEEE,detection of markers using deep learning for docking of autonomous underwater vehicle," Autonomous Underwater Vehicle (AUV) has limited energy capacity due to it being an embedded system. To overcome this limitation, the AUV can home into a docking station to recharge its battery. Several research has been conducted on the docking of AUV using vision. In some literatures, docking would fail if the target placed at the docking station is missing or disoriented from the camera view. This study proposes a deep learning system to detect the target markers to solve the disoriented view issues. The proposed system comprises of two phases which are training and testing. In training phase, there are region proposal, labeling data, developing convolutional neural network architecture, and network training. In testing phase, the trained network will be fed by various input data so as to measure the performance of the network. Result in this study shows that the system is able to locate and classify the target markers even though the view of the object of interest is disoriented. Future work may include the implementation of the developed system on real docking operation.",project-academic
10.1109/EICONRUS.2019.8657013,2019-01-01,p,IEEE,model of motion control system of driverless car," At the present stage, the development of driverless car are engaged in all the leading automotive manufacturers. The main priorities for developers were the tasks of security, transport communication and the organization of the regulation of traffic flows. Their solution is possible with the help of an effective motion control system. Information processing is realized with the help of artificial intelligence, organs of ""senses"" and executive mechanisms. For the implementation of this task, an important step is the compilation of a mathematical model.",project-academic
,2011-01-01,c,"CRC Press, Taylor & Francis Group",learning of a bayesian autonomous driver mixture of behaviors bad mob model," The Human or Cognitive Centered Design (HCD) of intelligent transport systems requires computational Models of Human Behavior and Cognition (MHBC). They are developed and used as driver models in traffic scenario simulations and risk- based design. The conventional approach is first to develop handcrafted control-theoretic or artificial intelligence based prototypes and then to evaluate ex post their learnability, usability, and human likeness. We propose a machine-learning alternative: The Bayesian estimation of MHBCs from behavior traces. The learnt Bayesian Autonomous Driver (BAD) models are empirical valid by construction. An ex post evaluation of BAD models is not necessary. BAD models can be built so that they decompose or compose skills into or from basic skills: BAD Mixture-of-Behaviors (BAD MoB) models. We present an efficient implementation which is able to control a simulated vehicle in real-time. It is able to generate complex behaviors of several layers of expertise by mixing and sequencing simpler behavior models.",project-academic
10.1007/978-3-319-99620-2_16,2018-07-04,a,"Springer, Cham",identification and recognition of vehicle environment using artificial neural networks," Object detection using deep learning over the years became one of the most popular methods for implementation in autonomous systems. Autonomous vehicle requires very reliable and accurate identification and recognition of surrounding objects in real traffic environments to achieve decent detection results. In this paper, special type of Artificial Neural Network (ANN) named Convolutional Neural Network (CNN) was used for identification and recognition of surrounding objects in real traffic. The new model based on CNN was trained and developed to be able to identify and recognize 4 different classes of objects: cars, traffic lights, persons and bicycles. The developed model has shown 94.6% accuracy of object identification and recognizing on the test set.",project-academic
10.12783/SHM2017/14232,2017-09-28,a,"DEStech Publications, Inc.",level of detail assessment of structural surface damage using spatially sequential stereo images and deep learning methods," In this paper, we report an innovative framework for automating structural surface damage assessment in engineering practice. Assessment of structural surface damage has been heavily relied on human-based inspection, which incurs significant cost to stakeholders of civil structures and infrastructure and often severe risk to the inspectors. Recognizing the promise of aerial robotics that can access dangerous locations and envisaging a future of structural inspection that ought to be fully autonomous, we have developed a framework, termed level-of-detail assessment of structural surface damage, that is geared towards real-time implementation for use in practice. The level-of-detail assessment is enabled by a remote sensing approach based on a small Unmanned Aerial Vehicle (UAV or drone) platform with an integrated payload of a low-cost stereo camera and a compact embedded computer. To achieve real-time detection, we propose the use of the faster region-based Convolution Neural Network (faster RCNN) as an artificial intelligence (AI) utility at different imaging depths. The stereo-camera based geometric reconstruction provides the basis of achieving level-of-detail quantitative damage assessment. In this paper, we further propose a novel data preparation method to accommodate the RCNN training. In the end, we will showcase some of these results based on our current implementation and experimental evaluation.",project-academic
10.1109/ICSTCC50638.2020.9259777,2020-10-08,p,IEEE,integrated fault detection and diagnosis of an unmanned aerial vehicle using time difference of arrival," An integrated approach to the fault detection and diagnosis (FDD) of an unmanned aerial vehicle is presented. A novel approach using the Time Difference Of Arrival (TDOA) principle has been developed to detect, isolate and identify an incipient fault condition in the rotor dynamics. The requirements of a reconfigurable controller (RC) has been taken into account through the real-time implementation of a continuous forward algorithm (CFA) with a golden section search (GSS) combined with a meta-heuristic global optimization technique. The training and testing data for Radial Basis Function Neural Networks (RBF-NN) learning and prediction were supplied in discrete-time and its integration capacity validated through a Hardware-in-the-loop simulation (HILS) using a Teensy 3.6 microcontroller. The Pseudo real-time desktop simulation showed that the FDD algorithm was able to detect and isolate an incipient rotor fault and supply the RC a post-fault model and associated fault uncertainties. This method showed robustness towards prediction errors (bias and variance) and can be used in an integrated fault-tolerant control framework.",project-academic
10.1371/JOURNAL.PONE.0252754,2021-06-10,a,Public Library of Science (PLoS),optimizing hyperparameters of deep reinforcement learning for autonomous driving based on whale optimization algorithm," Deep Reinforcement Learning (DRL) enables agents to make decisions based on a well-designed reward function that suites a particular environment without any prior knowledge related to a given environment. The adaptation of hyperparameters has a great impact on the overall learning process and the learning processing times. Hyperparameters should be accurately estimated while training DRL algorithms, which is one of the key challenges that we attempt to address. This paper employs a swarm-based optimization algorithm, namely the Whale Optimization Algorithm (WOA), for optimizing the hyperparameters of the Deep Deterministic Policy Gradient (DDPG) algorithm to achieve the optimum control strategy in an autonomous driving control problem. DDPG is capable of handling complex environments, which contain continuous spaces for actions. To evaluate the proposed algorithm, the Open Racing Car Simulator (TORCS), a realistic autonomous driving simulation environment, was chosen to its ease of design and implementation. Using TORCS, the DDPG agent with optimized hyperparameters was compared with a DDPG agent with reference hyperparameters. The experimental results showed that the DDPG's hyperparameters optimization leads to maximizing the total rewards, along with testing episodes and maintaining a stable driving policy.",project-academic
,2021-02-05,a,,fusion of neural networks for lidar based evidential road mapping," LIDAR sensors are usually used to provide autonomous vehicles with 3D representations of their environment. In ideal conditions, geometrical models could detect the road in LIDAR scans, at the cost of a manual tuning of numerical constraints, and a lack of flexibility. We instead propose an evidential pipeline, to accumulate road detection results obtained from neural networks. First, we introduce RoadSeg, a new convolutional architecture that is optimized for road detection in LIDAR scans. RoadSeg is used to classify individual LIDAR points as either belonging to the road, or not. Yet, such point-level classification results need to be converted into a dense representation, that can be used by an autonomous vehicle. We thus secondly present an evidential road mapping algorithm, that fuses consecutive road detection results. We benefitted from a reinterpretation of logistic classifiers, which can be seen as generating a collection of simple evidential mass functions. An evidential grid map that depicts the road can then be obtained, by projecting the classification results from RoadSeg into grid cells, and by handling moving objects via conflict analysis. The system was trained and evaluated on real-life data. A python implementation maintains a 10 Hz framerate. Since road labels were needed for training, a soft labelling procedure, relying lane-level HD maps, was used to generate coarse training and validation sets. An additional test set was manually labelled for evaluation purposes. So as to reach satisfactory results, the system fuses road detection results obtained from three variants of RoadSeg, processing different LIDAR features.",project-academic
10.1002/ROB.22009,2021-01-14,a,"John Wiley & Sons, Ltd",fusion of neural networks for lidar based evidential road mapping," LIDAR sensors are usually used to provide autonomous vehicles with 3D representations of their environment. In ideal conditions, geometrical models could detect the road in LIDAR scans, at the cost of a manual tuning of numerical constraints, and a lack of flexibility. We instead propose an evidential pipeline, to accumulate road detection results obtained from neural networks. First, we introduce RoadSeg, a new convolutional architecture that is optimized for road detection in LIDAR scans. RoadSeg is used to classify individual LIDAR points as either belonging to the road, or not. Yet, such point-level classification results need to be converted into a dense representation, that can be used by an autonomous vehicle. We thus secondly present an evidential road mapping algorithm, that fuses consecutive road detection results. We benefitted from a reinterpretation of logistic classifiers, which can be seen as generating a collection of simple evidential mass functions. An evidential grid map that depicts the road can then be obtained, by projecting the classification results from RoadSeg into grid cells, and by handling moving objects via conflict analysis. The system was trained and evaluated on real-life data. A python implementation maintains a 10 Hz framerate. Since road labels were needed for training, a soft labelling procedure, relying lane-level HD maps, was used to generate coarse training and validation sets. An additional test set was manually labelled for evaluation purposes. So as to reach satisfactory results, the system fuses road detection results obtained from three variants of RoadSeg, processing different LIDAR features.",project-academic
10.1007/S00521-019-04386-4,2019-12-01,a,Springer London,a versatile hardware software platform for personalized driver assistance based on online sequential extreme learning machines," In the present scenario of technological breakthroughs in the automotive industry, machine learning is greatly contributing to the development of safer and more comfortable vehicles. In particular, personalization of the driving experience using machine learning is an innovative trend that comprises the development of both customized driver assistance systems and in-cabin comfort features. In this work, a versatile hardware/software platform for personalized driver assistance, using online sequential extreme learning machines (OS-ELM), is presented. The system, based on a programmable system-on-chip (SoC), is able to recognize the driver and personalize the behavior of the car. The platform provides high speed, small size, efficient power consumption, and true capability for real-time adaptation (i.e., on-chip self-learning). In addition, due to the plasticity and scalability of the OS-ELM algorithm and the programmable nature of the SoC, this solution is flexible enough to cope with the incremental changes that the new generation of vehicles are demanding. The implementation details of a system, suitable for current levels of driving automation, are provided.",project-academic
,2002-01-01,a,,an agent based traffic simulation framework to model intelligent virtual driver behaviour," This paper presents an agent-based traffic simulation framework that supports intelligent virtual driver behaviour. The framework exploits concepts used in Artificial Life (ALife), Artificial Intelligence (AI) and Agent technology to model the inherent unpredictability and autonomous behaviour of drivers within traffic simulation models. Each driver agent in our system contains knowledge and a decision-making mechanism, both of which are based on heuristics. This approach replaces some of the prescriptive nature of driving simulation models by allowing behaviours to emerge as a result of individual driver agent interactions. The framework also contributes to accident analysis by improving current limitations in which accident investigation methods concentrate on the events themselves, rather than pre- crash influences. Within this context, the framework provides an opportunity to increase the understanding of accident causation factors, to examine alternative traffic scenarios (what if analyses) and methodology to obtain quantitative estimates of accident risk. Current implementation results show that driver agents within the integrated simulation are able to perceive other drivers' speeds and distances, avoid collisions, perform realistic vehicle following, and demonstrate emergent traffic flow. A major application area for this framework includes the evaluation of vehicle, highway and road user factors that precede a collision, or near misses.",project-academic
10.1007/S12008-019-00619-X,2019-12-01,a,Springer Paris,hardware in the loop framework proposal for a semi autonomous car architecture in a closed route environment," The development of intelligent vehicles has been increasing at great speed in recent years, which has allowed to improve their capabilities in autonomous driving systems. Many of these features are related to advanced driving assistance systems and autonomous driving systems. This capability improvement, has been achieved because of recent developments of automation oriented software and hardware. Such improvements, allowed the vehicle to achieve a more precise perception of it’s working environment. For this improvement it is important the integration and simulation of the systems in different configurations, such as hardware-in-the-loop, software-in-the-loop and model-in-the-loop. In this paper, we present a framework proposal that allows the design and testing of computer vision and control systems for the partial automation of a vehicle, with the use of hardware and software systems in the loop. This proposal is focused on the rapid experimental development of these systems for the implementation by autonomous vehicle designers and engineers. Our proposal allows faster data capture, either in a real or simulated environment, to improve and optimize data training with machine learning algorithms; this proposal integrates several open source systems and hardware with the necessary capacity for real-time implementation.",project-academic
10.1007/S10846-020-01274-1,2021-01-01,a,Springer Science and Business Media LLC,a dynamically feasible fast replanning strategy with deep reinforcement learning," In this work, we aim to develop a fast trajectory replanning methodology enabling highly agile aerial vehicles to navigate in cluttered environments. By focusing on reducing complexity and accelerating the replanning problem under strict dynamical constraints, we employ the b-spline theory with local support property for defining the high dimensional agile flight trajectories. We utilize the differential flatness model of an aerial vehicle, allowing us to directly map the desired output trajectory into input states to track a high dimensional trajectory. Dynamically feasible replanning problem is addressed through regenerating the local b-splines with control point reallocation. As the geometric form of the trajectory based on the location of the control points and the knot intervals, the control point reallocation for fast replanning with dynamical constraints is turned into a constrained optimization problem and solved through deep reinforcement learning. The proposed methodology enables generating dynamically feasible local trajectory segments, which are continuous to the existing, hence provides fast local replanning for collision avoidance. The DRL agent is trained with different environmental complexities, and through the batch simulations, it is shown that the proposed methodology allows to solve fast trajectory replanning problem under given or hard dynamical constraints and provide real-time applicability for such collision avoidance applications in agile unmanned aerial vehicles. Hardware implementation tests of the algorithm with the agile trajectory tracker to a small UAV can bee seen in the following video link: None None None None None None None None None None None None None None None None https://youtu.be/8IiLQFQ3V0E
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None .",project-academic
10.1007/S12205-021-1796-9,2021-07-02,a,Korean Society of Civil Engineers,model for the identification and classification of partially damaged and vandalized traffic signs," The development of Convolutional Neural Networks (CNN) has expanded with the accelerated progress of IT, as well as with the needs of the autonomous vehicle (AV) implementation. The specifics and requirements of AV towards the infrastructure primarily relate to the condition and quality of traffic signs. For the independent participation of these vehicles in traffic, an impeccable traffic sign condition is required, which is often not the case in practice. Damaged, faded, obscured, or vandalized traffic signs can usually be seen in the road network, which can impede the movement of AV in traffic. In the existing literature, little or very little attention is focused on the problem of identifying and classifying damaged and especially vandalized traffic signs. In this paper, the mentioned problem is addressed, and the CNN model is proposed. This model has been tested on a specially designed novel and challenging database containing 6,000 real-time images of traffic signs in the road network of the Republic of Serbia. This model is invariant to different lighting and weather (nighttime and fog) conditions. In this case study, the model reached an overall accuracy of 99.17%, whereby all vandalized and damaged traffic signs are accurately identified and classified.",project-academic
10.1109/HPEC43674.2020.9286246,2020-09-22,p,IEEE,target classification in synthetic aperture radar and optical imagery using loihi neuromorphic hardware," Intel's novel Loihi processing chip has been used to explore new information exploitation techniques. Specifically, we analyzed two types of data (optical and radar). These data modalities and associated machine learning algorithms were used to showcase the ability of the system to address real world problems, such as object detection and classification. Intel's fully digital Loihi design is inspired by biological processes and brain functions. Neuromorphic architectures, such as Loihi, promise to improve computational efficiency for various machine learning tasks with a realizable path toward implementation into many systems, e.g., airborne computing for intelligence, surveillance and reconnaissance systems, and/or future autonomous vehicles and household appliances. With the current software development kit, it is possible to train an artificial neural network model in a common deep learning framework such as Keras and quantize the model weights for a simplistic, direct translation onto the Loihi hardware. The radar imagery analyzed included a seven-vehicle class target set, which was processed at a rate of 9.5 images per second and with an overall accuracy of 90.1%. The optical data included a binary (two classes), and another nine-class data set. The binary classifier processed the optical data at a rate of 12.8 images per second with 94.0% accuracy. The nine classes optical data was processed at a rate 12.9 images per second and 79.7% accuracy. Lastly, the system used ~6 Watts of total power with ~0.6 Watts being utilized by the neuromorphic cores. The inferencing energy used to classify each image varied between 14.9 and 63.2 millijoules/image.",project-academic
10.1109/ISORC.2018.00025,2018-05-29,p,IEEE,representative safety assessment of autonomous vehicle for public transportation," The implementations and testing in real conditions of Autonomous Vehicles (AV) for private usage show important advances. However, a lack still exists in addressing the particularities of AVs for Public Transportation. Such particularities range from limited safety mechanisms aboard, risky situations associated to particular users and complex self-driving situations up to the limited passengers-vehicle interactions possible. Since, to our knowledge, no comprehensive safety assessment actually exists and the current automotive related standards do not address identified aspects, in this paper, we propose to conduct a minimal but representative safety assessment based upon a local but real autonomous vehicle implementation. To conduct our study, the Hazard Analysis and Risks Assessment introduced in the ISO 26262 standard is taken as a basis. Initial outcomes suggest that critical autonomy aspects, like machine learning of complex operational situations, the metrics for quantitative assessment of autonomy, and potential conflicts between autonomy principles and external safety fences can have critical safety impacts and demand further discussions.",project-academic
10.5194/ISPRS-ARCHIVES-XLIV-2-W1-2021-15-2021,2021-04-15,a,Copernicus GmbH,real time deep neural networks for multiple object tracking and segmentation on monocular video," Abstract. The paper is devoted to the task of multiple objects tracking and segmentation on monocular video, which was obtained by the camera of unmanned ground vehicle. The authors investigate various architectures of deep neural networks for this task solution. Special attention is paid to deep models providing inference in real time. The authors proposed an approach based on combining the modern SOLOv2 instance segmentation model, a neural network model for embedding generation for each found object, and a modified Hungarian tracking algorithm. The Hungarian algorithm was modified taking into account the geometric constraints on the positions of the found objects on the sequence of images. The investigated solution is a development and improvement of the state-of-the-art PointTrack method. The effectiveness of the proposed approach is demonstrated quantitatively and qualitatively on the popular KITTI MOTS dataset collected using the cameras of a driverless car. The software implementation of the approach was carried out. The acceleration of the procedure for the formation of a two-dimensional point cloud in the found image segment was done using the NVidia CUDA technology. At the same time, the proposed instance segmentation module provides a mean processing time of one image of 68 ms, the embedding and tracking module of 24 ms using the NVidia Tesla V100 GPU. This indicates that the proposed solution is promising for on-board computer vision systems for both unmanned vehicles and various robotic platforms.",project-academic
10.3390/MATH8081208,2020-07-22,a,Multidisciplinary Digital Publishing Institute,risc conversions for lns arithmetic in embedded systems," The paper presents an original methodology for the implementation of the Logarithmic Number System (LNS) arithmetic, which uses Reduced Instruction Set Computing (RISC). The core of the proposed method is a newly developed algorithm for conversion between LNS and the floating point (FLP) representations named “looping in sectors”, which brings about reduced memory consumption without a loss of accuracy. The resulting effective RISC conversions use only elementary computer operations without the need to employ multiplication, division, or other functions. Verification of the new concept and related developed algorithms for conversion between the LNS and the FLP representations was realized on Field Programmable Gate Arrays (FPGA), and the conversion accuracy was evaluated via simulation. Using the proposed method, a maximum relative conversion error of less than ±0.001% was achieved with a 22-ns delay and a total of 50 slices of FPGA consumed including memory cells. Promising applications of the proposed method are in embedded systems that are expanding into increasingly demanding applications, such as camera systems, lidars and 2D/3D image processing, neural networks, car control units, autonomous control systems that require more computing power, etc. In embedded systems for real-time control, the developed conversion algorithm can appear in two forms: as RISC conversions or as a simple RISC-based logarithmic addition.",project-academic
10.1109/ICAIIC.2019.8669047,2019-02-01,p,IEEE,a complete multi cpu fpga based design and prototyping methodology for autonomous vehicles multiple object detection and recognition case study," Embedded smart systems are Hardware/Software (HW/SW) architectures integrated in new autonomous vehicles in order to increase their smartness. A key example of such applications are camera-based automatic parking systems. In this paper we introduce a fast prototyping perspective within a complete design methodology for these embedded smart systems. One of our main objective being to reduce development and prototyping time, compared to usual simulation approaches. Based on our previous work [1], a supervised machine learning approach, we propose a HW/SW algorithm implementation for objects detection and recognition around autonomous vehicles. We validate our real-time approach via a quick prototype on the top of a Multi-CPU/FPGA platform (ZYNQ). The main contribution of this current work is the definition of a complete design methodology for smart embedded vehicle applications which defines four main parts: specification & native software, hardware acceleration, machine learning software, and the real embedded system prototype. Toward a full automation of our methodology, several steps are already automated and presented in this work. Our hardware acceleration of point cloud-based data processing tasks is 300 times faster than a pure software implementation.",project-academic
10.1109/ICICCS51141.2021.9432374,2021-05-06,p,IEEE,vehicle detection through instance segmentation using mask r cnn for intelligent vehicle system," The recent advancement in artificial intelligence approach or deep learning techniques explored the ways to facilitate automation in various sectors. The application of deep learning with computer vision field has resulted in realization of intelligent systems. Vehicle detection plays a key role in Intelligent Vehicle System and Intelligent Transport System as it assists critical components of these systems like road scene classification, detecting obstacle vehicles to find an unhindered pathway, and even preventing accidents. This paper presents an implementation of Mask R-CNN state-of-the-art method using transfer learning technique for vehicle detection via instance wise segmentation which produces bounding box and object mask simultaneously. As the autonomous systems demands precise and flawless identification of the vehicles thus segmentation based approach is adopted. The model performs satisfactorily for occluded and small sized objects as well. This study is accomplished using an online GPU and cloud services provided by Google Colab by using Tensorflow and Keras framework. A mAP of 90.27% and mAR of 92.38% is achieved by using a combination of benchmark datasets.",project-academic
10.1109/ICSMC.2009.5346250,2009-10-11,p,IEEE,implementation of fuzzy q learning based on modular fuzzy model and parallel structured learning," In order to realize intelligent agent such as autonomous mobile robots, Reinforcement Learning is one of the necessary techniques in control system. Fuzzy Q-learning is one of the promising approaches for implementation of reinforcement learning function owing to its high ability of model representation. However, in applying fuzzy Q-learning to actual application, the number of iterations for learning also becomes huge as well as almost all Q-learning application. Furthermore convergence performance is often deteriorated owing to its complicated model structure. In this study, implementation method of fuzzy Q-learning is discussed in order to improve the learning performance of fuzzy Q-learning. The modular fuzzy model construction method based on fuzzy Q-learning is proposed in this paper. Multi-grain configuration of modular fuzzy model is compared with parallel structured learning scheme. Through numerical experiments of mountain car task and Acrobot task, I found that the proposed construction of modular fuzzy model improved the performance of fuzzy Q-learning.",project-academic
10.3390/RS13091723,2021-04-29,a,Multidisciplinary Digital Publishing Institute,detection of european aspen populus tremula l based on an unmanned aerial vehicle approach in boreal forests," European aspen (Populus tremula L.) is a keystone species for biodiversity of boreal forests. Large-diameter aspens maintain the diversity of hundreds of species, many of which are threatened in Fennoscandia. Due to a low economic value and relatively sparse and scattered occurrence of aspen in boreal forests, there is a lack of information of the spatial and temporal distribution of aspen, which hampers efficient planning and implementation of sustainable forest management practices and conservation efforts. Our objective was to assess identification of European aspen at the individual tree level in a southern boreal forest using high-resolution photogrammetric point cloud (PPC) and multispectral (MSP) orthomosaics acquired with an unmanned aerial vehicle (UAV). The structure-from-motion approach was applied to generate RGB imagery-based PPC to be used for individual tree-crown delineation. Multispectral data were collected using two UAV cameras: Parrot Sequoia and MicaSense RedEdge-M. Tree-crown outlines were obtained from watershed segmentation of PPC data and intersected with multispectral mosaics to extract and calculate spectral metrics for individual trees. We assessed the role of spectral data features extracted from PPC and multispectral mosaics and a combination of it, using a machine learning classifier—Support Vector Machine (SVM) to perform two different classifications: discrimination of aspen from the other species combined into one class and classification of all four species (aspen, birch, pine, spruce) simultaneously. In the first scenario, the highest classification accuracy of 84% (F1-score) for aspen and overall accuracy of 90.1% was achieved using only RGB features from PPC, whereas in the second scenario, the highest classification accuracy of 86 % (F1-score) for aspen and overall accuracy of 83.3% was achieved using the combination of RGB and MSP features. The proposed method provides a new possibility for the rapid assessment of aspen occurrence to enable more efficient forest management as well as contribute to biodiversity monitoring and conservation efforts in boreal forests.",project-academic
10.1109/ICCE.2018.8326285,2018-01-01,p,IEEE,deep learning in low power stereo vision accelerator for automotive," Various forms of Convolutional Neural Network (CNN) architectures are used as Deep Learning (DL) tools for learning the similarity measure on video patches in order to run the stereo matching algorithm — the most computationally intensive stage of the pipeline for the stereo vision function used in designing an autonomous car. We propose a hybrid system implementation of the algorithm for real-time, low-power and high-temperature environment. The accelerator part of our system is a programmable many-core system with a Map-Reduce Architecture. The paper describes and evaluates the proposed accelerator for different versions of the stereo matching algorithm.",project-academic
,2020-01-21,,,uuv real time collision avoidance planning method based on deep double q network reinforcement learning," The invention belongs to the technical field of UUV control, and specifically relates to a UUV real-time collision avoidance planning method based on deep double-Q network reinforcement learning. Theinvention provides an autonomous collision avoidance planning method suitable for the working environment and the perception characteristics of a UUV (unmanned Underwater vehicle). A strategy of the UUV is continuously improved by performing continuous trial and error interaction between the UUV and the environment and generating a reward or punishment signal by using successful or failed experience, so that the UUV has the self-learning capability. Through the method disclosed by the invention, a network system has self-learning capability in the local collision avoidance planning of the complex environment to realize an end-to-end model, and the deep learning and the reinforcement learning are combined to be applied to the solution of the collision avoidance planning problem by directlylearning a mapping relation of a state and the action from an original data set. By using the deep reinforcement learning, the condition that the strategy cannot be executed due to complex path can beavoided, the development period of the project is shortened in the actual application, the implementation is more concise, efficient, and high in robustness.",project-academic
,2020-09-07,a,,driving tasks transfer in deep reinforcement learning for decision making of autonomous vehicles," Knowledge transfer is a promising concept to achieve real-time decision-making for autonomous vehicles. This paper constructs a transfer deep reinforcement learning framework to transform the driving tasks in inter-section environments. The driving missions at the un-signalized intersection are cast into a left turn, right turn, and running straight for automated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive through the intersection situation efficiently and safely. This objective promotes the studied vehicle to increase its speed and avoid crashing other vehicles. The decision-making pol-icy learned from one driving task is transferred and evaluated in another driving mission. Simulation results reveal that the decision-making strategies related to similar tasks are transferable. It indicates that the presented control framework could reduce the time consumption and realize online implementation.",project-academic
10.1109/CONIELECOMP.2016.7438571,2016-03-24,p,IEEE,support and monitoring trajectory paths for vehicles using mobile devices," Currently artificial intelligence combined with computer vision has helped in performing daily activities, the current tendency of semi-autonomous vehicles assisted by artificial intelligence and computer vision has created a new field of image processing research. The image processing to support autonomous route tracking systems they have been tested in controlled media. In this investigation we perform the implementation of a system of guide and trajectory tracking in real scenarios (not controlled media) as road and city streets. Propose a new method for detecting lines as the Hough transform, in a simple and efficient for the detection of lane on a mobile manner. With the above determined whether or not the vehicle conserves his lane by opening angles of triangles detected with the mobile camera, to support and assist the driver. The methodology is tested to determine its performance qualitatively and quantitatively.",project-academic
10.1109/ASYU48272.2019.8946332,2019-10-01,p,IEEE,autonomous car racing in simulation environment using deep reinforcement learning," Self-Driving Cars are, currently a hot topic throughout the globe thanks to the advancements in Deep Learning techniques on computer vision problems. Since driving simulations are fairly important before real life autonomous implementations, there are multiple driving-racing simulations for testing purposes. The Open Racing Car Simulation (TORCS) is a highly portable open source car racing -self-driving- simulation. While it can be used as a game in which human players compete with scripted agents, TORCS provides observation and action API to develop an artificial intelligence agent. This study explores near-optimal Deep Reinforcement Learning agents for TORCS environment using Soft Actor-Critic and Rainbow DQN algorithms, exploration and generalization techniques.",project-academic
10.1109/ICSESS49938.2020.9237730,2020-10-16,p,IEEE,mixed pruning method for vehicle detection," Object detection is a popular direction in computer vision and digital image processing, and has important implementation significance in many fields. In unmanned driving, it is also an indispensable component, and vehicle detection as its important branch has also received much attention. With the continuous development of deep learning in recent years, convolutional neural networks have been widely used for object detection. Compared with traditional detection methods, it has better generalization ability and recognition accuracy. However, most current deep learning-based object detection methods rely on the graphics processor (GPU) to ensure the real-time detection. This is difficult for an unmanned system with limited memory and computing power resources to support its operation. In order to solve the problem of excessive resource consumption of these hardware platforms, we propose a vehicle detection algorithm based on a hybrid pruning model, which ensures that the accuracy of the model is within a controllable range while reducing the number of model parameters as much as possible. The model increases the sparsity of the network by using the L1 norm regularization method, and cyclically prunes the model through channel pruning and layer pruning. The experimental results show that the compressed network model is reduced by 83% compared to the original model, and the corresponding speed is reduced to half of the original.",project-academic
10.1109/EIT51626.2021.9491894,2021-05-14,p,IEEE,teaching vehicles to steer themselves with deep learning, Traditional approaches for steering a vehicle using machine vision require large amounts of robust hand-crafted software which is both time consuming and expensive. The presented method uses a deep neural network to teach cars to steer themselves without any additional software. We created a labeled dataset for the ACTor (Autonomous Campus TranspORt) electric vehicle by pairing real world images taken during a drive with the associated steering wheel angle. We trained a model end to end using modern deep learning techniques including convolutional neural networks and transfer learning to automatically detect relevant features in the input and provide a predicted output. This means that no traditional hand engineered algorithm features were required for this implementation. We currently use an pretrained inception network on the ImageNet dataset to leverage the high level features learned from ImageNet to the steering problem through transfer learning. We removed the top portion of the network and replaced it with a linear regression node to provide the output. The model is trained end to end using backpropagation. The trained model is integrated with vehicle software on ROS (Robot Operating System) to read image data and provide a corresponding steering angle in real time. The current model achieves 15.2 degree error on average. As development continues the model may replace the current lane centering software and will be used for IGVC Self-Drive competition and campus transportation.,project-academic
,2020-10-30,,,fixed wing unmanned aerial vehicle cluster control collision avoidance method and device based on deep reinforcement learning," The invention discloses a fixed-wing unmanned aerial vehicle cluster control collision avoidance method and device based on deep reinforcement learning. The method comprises the steps of S1, establishing an unmanned aerial vehicle kinematic model and D3QN, updating network parameters by using historical interaction data in the interaction process of each wing plane and the environment; training toform a D3QN model, constructing a joint state between the wing planes and a lead plane according to the environment state in the interaction process, performing situation assessment construction to obtain a local map, and inputting the local map into the D3QN model to obtain control instruction output of each wing plane; S2, obtaining state information in real time by each wing plane to form a joint state between the current wing plane and the lead plane, carrying out situation assessment in real time to construct a local map, and inputting the joint state constructed in real time and the local map into the D3QN network model to obtain a control instruction of each wing plane. The method has the advantages that the implementation method is simple, the expandability is good, cluster control over the fixed-wing unmanned aerial vehicles can be achieved, and meanwhile, collision is avoided.",project-academic
10.1111/0885-9507.00109,1998-09-01,a,Blackwell Publishers Inc,collision avoidance using a cerebellar model arithmetic computer neural network," Avoiding collisions with obstacles in a clustered environment is a difficult task for autonomous vehicles. Deterministic algorithms cannot address all scenarios encountered and may fail to perform in dynamically changing environments. Neural networks, owing to their ability to map complex relationships between multiple input-output patterns, can learn the task of maneuvering around and in-between obstacles to reach a goal state. The Cerebellar Model Arithmetic Computer (CMAC) neural network in particular is based on a model of human sensory motor responses and can efficiently model responsive control actions. A CMAC neural network controller was developed and examined, in simulation, for its suitability to capture a driver's function of steering and braking. The performance of the controller was tested in a simulation of a moving platform (vehicle) encountering obstacles of various shapes, whereas the CMAC was trained only with limited shapes and scenarios. Preliminary simulation results have shown the CMAC's ability to successfully generalize its learned patterns to avoid obstacles after only a few training sessions. The CMAC output is generated in a computationally efficient manner with physically and economically realizable memory sizes. Therefore, real-time hardware implementation of the controller is feasible. This research demonstrates that the method has the ability to accommodate more complex scenarios.",project-academic
,2016-06-02,p,,deep reinforcement learning for computer games," !!Motivation
Designing an artificial agent that can autonomously perform actions and learn with minimal amount of supervision is one of the biggest challenges in the field of artificial intelligence. One of the approaches to this challenge is reinforcement learning (RL), which is a subfield of machine learning concerned with the question of how should a system (an agent) select actions in some environment so as to maximize the cumulative value known as reward. An agent has to infer the optimal action from a reward that is determined by the environment and from observations of the state of the environment. Although there are many algorithms for learning optimal action selection function or policy, only the recent advancements in the field of deep learning made it possible to learn policies from the high-dimensional representations of complex environments. Our primary focus is on the Deep Q Learning algorithm [1], which uses deep neural networks to learn optimal policies based on the high-dimensional representation of the environment [1]. So far, Deep Q Learning was used for learning policies in various domains such as arcade games, robotic control tasks or board games. We think that deep reinforcement learning algorithms like Deep Q Learning could be used as a basis of a controller in more complex tasks, for example in autonomous car control.

!!Method
There are three main goals that we want to achieve in this work. First, we None examine the theoretical basis of RL algorithms including the biological significance of this concept. Secondly, we examine discrete and continuous versions of the Deep Q Learning algorithm. We also consider potential extensions of the Deep Q Learning algorithm based on the current development in the field of deep learning. More specifically, we None consider the possibility of endowing Deep Q Learning agent with the core cognitive competences or “ingredients” of the human intelligence that are necessary for artificial agents in order to act as competent agents in an environment. Among these competences is developmental start-up software, learning by rapid building of the models of environment and fast thinking [2]. Thirdly, we attempt to replicate and improve upon some of the results from [1] in the realm of arcade computer games. For this purpose, we use our own Python based implementation of Deep Q Learning algorithm. 

!!Acknowledgements
I would like to thank my supervisor prof. Ing. Igor Farkas, Dr. for his support and advice. 

!!References
[1] V. Mnih, K. Kavukcuoglu, D. None Silver, et al.,""Human-level control through deep reinforcement learning"", Nature, vol. 518, no. 7540, 2015, pp. 529-533.
[2] B. None Lake, T. None Ullman, J. None Tenenbaum and S. None Gershman, ""Building Machines That Learn and Think Like People"", Arxiv.org, 2016. [Online]. Available: https://arxiv.org/abs/1604.00289.",project-academic
10.1109/ICCC51557.2021.9454613,2021-05-31,p,IEEE,deep learning based automated vehicle steering," Autonomous Vehicle applications are full of open challenges. Despite the advanced technologies, the lack of robust systems still exists due to the high complexity of the surrounded environments. The automated steering is one of the most complex autonomous driving system’s application. Model predictive control is the most common control strategy used to implement the automated steering tasks due to its ability to solve an online quadratic optimization problem in the real-time, in addition to its efficiency in handling the constraints of the system’s environments. MPC controller is used to drive the vehicle autonomously along the centerline of the road based on two main factors, the lateral deviation and relative yaw angle. Deep learning technology has been widely used in recent years because of the promising performance achieved in different applications and tasks. In this context, we suggested that the implementation of the Deep Neural Network (DNN) will provide a great improvement and it can be more computationally efficient than solving an online quadratic problem (QP), that will naturally lead to reduce the time, the complexity, and the computational loads of implementations. The main aims of this paper are to design a deep learning-based approach for automated vehicle steering based on the behaviour of the traditional MPC controller. In addition, to study the efficiency of the full replacement of the MPC controller by the suggested DNN model. The study is based on performing a comparison between the implementations of both controllers (MPC and DNN model) in terms of the performance and the execution time. The performance indicator is the ability of the controller to drive the decision variables (lateral deviation and yaw angle) to be close to zero in order to drive the vehicle autonomously along the desired path.",project-academic
,2021-05-20,a,,raspberrypi for mosquito neutralization by power laser," In this article for the first time, comprehensive studies of mosquito neutralization using machine vision and a 1 W power laser are considered. Developed laser installation with Raspberry Pi that changing the direction of the laser with a galvanometer. We developed a program for mosquito tracking in real. The possibility of using deep neural networks, Haar cascades, machine learning for mosquito recognition was considered. We considered in detail the classification problems of mosquitoes in images. A recommendation is given for the implementation of this device based on a microcontroller for subsequent use as part of an unmanned aerial vehicle. Any harmful insects in the fields can be used as objects for control.",project-academic
,2008-01-01,p,,towards a generic infrastructure to adjust the autonomy of soar agents," Developing and testing intelligent agents is a complex task that is both time-consuming and costly. This creates the potential that problems in the agent’s behavior will be realized only after the agent has been put to use. In this paper we explore two implementations of a generic agent selfassessment framework applied to the Soar agent architecture. Our system extends previous work and can be used to achieve adjustable levels of agent autonomy or runtime verification with only minor modifications to existing Soar agents. We present results indicating the computational overhead of both approaches compared against an agent that exhibits identical behavior without the help of the self-assessment framework. Agents whose behavior has not been completely validated run the risk of performing their tasks incorrectly. Such situations may occur if an agent encounters situations it was not designed to deal with or if its knowledge for how to deal with a particular situation is incorrect. In the former case, the agent is operating outside of its intended (specified) scope; in the later case, the agent’s implementation is inconsistent with its specification and thus incorrect. Regardless, the impact of unintended behavior may be relatively minor, or, in mission critical situations such as when controlling an unmanned aerial vehicle, the consequences may have a far reaching impact. Prior work on adjustable autonomy (e.g., [Bradshaw & et. al.2005, Reed2005, Sellner et al.2006]) has explored a variety of approaches that allow a human supervisor, or an agent itself to deal with exceptional situations that may arise due to incomplete or incorrect knowledge. In this paper, we briefly describe a generic infrastructure of adjustable autonomy that can be used in conjunction with Soar agents and compare the performance of two implementations of this infrastructure. Our generic framework (see Figure 1) works in conjunction with the Soar [Laird, Newell, & Rosenbloom1987] agent archicture. After a Soar agent identifies possible operators (goals or actions) to pursue next, the framework intercepts decision making to compare the actions and goals to an external policy. The result of the comparsion may deny, require or allow operators the agent has proposed. If all proposed operators have been denied, the framework provides Copyright c © 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Agent’s Internal Reasoning",project-academic
10.3390/APP11188425,2021-09-10,a,Multidisciplinary Digital Publishing Institute,an initial machine learning based victim s scream detection analysis for burning sites," Fire incidents are responsible for severe damage and thousands of deaths every year all over the world. Extreme temperatures, low visibility, toxic gases, and unknown locations of victims create difficulties and delays in rescue operations, escalating the risk of injury or death. It is time-critical to detect the victims trapped inside the burning sites for facilitating the rescue operations. This research work presents an audio-based automated system for victim detection in fire emergencies, investigating two machine learning (ML) methods: support vector machines (SVM) and long short-term memory (LSTM). The performance of these two ML techniques has been evaluated based on a variety of performance metrics. Our analyses show that both ML methods provide superior scream detection performance, with SVM slightly overperforming LSTM. Because of its lower complexity, SVM is a better candidate for real-time implementation in our autonomous embedded system vehicle (AESV).",project-academic
10.1088/1748-3190/AC290C,2021-09-22,a,IOP Publishing,lidar driven spiking neural network for collision avoidance in autonomous driving," Facilitated by advances in real-time sensing, low and high-level control, and machine learning, autonomous vehicles draw ever-increasing attention from many branches of knowledge. Neuromorphic (brain-inspired) implementation of robotic control has been shown to outperform conventional control paradigms in terms of energy efficiency, robustness to perturbations, and adaptation to varying conditions. Here we propose LiDAR-driven neuromorphic control of both vehicle's speed and steering. We evaluated and compared neuromorphic PID control and online learning for speed control, finally suggesting proportional learning as a preferred control scheme. We employed biologically plausible basal-ganglia and thalamus neural models for steering and collision-avoidance, finally extending them to support a null controller, significantly increasing performance.",project-academic
10.13052/JMM1550-4646.1811,2021-08-31,a,Rinton Press Inc.,service orchestration for object detection on edge and cloud in dependable industrial vehicles," Industrial applications, including autonomous systems and vehicles, rely on processing data on multiple physical devices. The composition of functionality across heterogeneous computing infrastructure is challenging, and will likely get even more challenging in the future as software in vehicles is updated to introduce new features and ensure the safety. New soft real-time use cases emerge and in such cases the model of offloading processing from a limited or malfunctioning device is a viable solution. This study examines orchestration of services across edge and cloud for an industrial vehicle application use case involving image based object detection using machine learning (ML) based models. First, service orchestration requirements are defined taking into account the dependable nature of industrial vehicle applications. Second, an implementation based on Arrowhead framework is presented and evaluated. The open Arrowhead framework offers means for dynamic service discovery, authorization and late binding of computational units. The feasibility of object detection as a service and the suitability of Arrowhead framework to support such orchestrations across edge and cloud is assessed.",project-academic
,2021-07-01,a,JETIR(www.jetir.org),development of self driving vehicle," Self-Driving cars are at the forefront of the automotive industry. Autonomous driving is the future. We are basing our vehicle on basic necessities such as identifying and classifying traffic signals, obstacles on the road. Lane switching and maneuvering is also one of the objectives to be accomplished. Artificial Intelligence, Deep Learning, machine Learning are the cornerstones of our development process. The implementation of this idea into the real world would result in a vast number of advantages. Prevention of accidents, safer transport and a huge revolution in transportation.",project-academic
,2021-03-12,,,rgb d indoor unmanned aerial vehicle positioning implementation method based on unsupervised deep learning," The invention discloses an RGBD indoor unmanned aerial vehicle positioning implementation method based on unsupervised deep learning. The method comprises the following steps: 1) acquiring an RGBD data set; 2) establishing a CNN network, and extracting features of the RGB image and the depth image through a double-flow structure based on RGB-D flow and depth flow; 3) constructing an RNN network, taking the features output by the CNN as the input of the RNN, replacing the standard RNN structure with the assistance of LSTM, and outputting the pose of the camera based on the features of the image; and 4) designing a 2D + 3D loss function for RCNN network training. The method is beneficial to an unsupervised network, does not need a large number of workers to mark the data set, and takes the depth image as the input of the neural network, thereby greatly improving the precision and robustness of a visual odometer system, and improving the positioning speed and precision of an indoor unmanned plane. Compared with a traditional indoor unmanned aerial vehicle visual odometer positioning system, the indoor unmanned aerial vehicle visual odometer positioning system is based on a deep learning framework, hardware resources can be fully utilized, and therefore the real-time performance of the indoor unmanned aerial vehicle positioning system is improved.",project-academic
10.1109/GIIS50753.2020.9248490,2020-10-28,p,IEEE,platooning of autonomous vehicles with artificial intelligence v2i communications and navigation algorithm," A solution to provide greater road safety consists in making vehicles move much closer to each other, i.e. using platoons, and to avoid the constant stop-and-go in urban traffic. This paper discusses the implementation of platooning in Autonomous vehicles (AVs) and the different difficulties associated with it. It also proposes a physical platform able to perform a form of platooning using Artificial Intelligence (AI) to create platoons with miniature cars. The platform called Autonomous Learning Intelligent Vehicles Engineering-ALIVE is the association of multiple physical cars coupled with an infrastructure, which handles the data of every single car and makes decisions based on the augmented environmental perception. This augmented perception can be created thanks to the received data. Our platform is low-cost, energy efficient and easy to use for other researchers to test their platooning ideas or algorithms. Finally, we tested the platooning AVs under real conditions. Preliminary results demonstrate the effectiveness of ALIVE to create platoons between multiple cars, allowing a car to reach any destination without making any other decision than creating or entering a platoon with another car going to the same destination.",project-academic
,2020-10-30,,,q learning based deep neural network adaptive back off strategy implementation method and system," The invention provides a Q learning-based deep neural network adaptive back-off strategy implementation method and system. The method comprises the steps of: 1, carrying out initialization on networknodes and a network topological structure in an unmanned plane network, determining a cluster head node of a tree network, carrying out initialization on back-off strategy parameters, and broadcastingthe initialized back-off strategy parameters to whole-network nodes; 2, enabling the whole-network nodes to update a local back-off strategy according to the initialized back-off strategy parameters;3, enabling the cluster head node to perform statistics according to the received update information to obtain a network fairness index and form a vector, and store the vector in an experience pool;4, enabling the cluster head node to extract the vector from the experience pool, and input the vector into a deep neural network to perform training to obtain a real Q value, and compare the real Q value with a predicted Q value; and step 5, returning to the step 2 to continue to execute the method, and outputting a back-off strategy under the condition that a learning strategy tends to stably meet a preset condition. According to the method and system of the invention, the communication performance of unmanned aerial vehicle nodes in a dynamic change network scene is improved.",project-academic
,2020-01-01,a,,a real time traffic sign recognition system for autonomous vehicle using yolo nurul paudziah aida mohd paudzi," In recent years, research towards Autonomous Vehicle (AV) has grown up tremendously. The introduction of Advanced Driving Assistance System (ADAS) in AV has led researchers to explore on the key functionalities that an AV should have, proposes to create a convenience and safe environment where there is no input acquire from a human throughout the journey. The key functionalities are including traffic sign recognition, parking space detection, pedestrian crash avoidance and blind spot detection. As the rises of road accident due to drivers’ carelessness and the distracted drivers that has been neglected the traffic signs on the road, this project aims to develop a traffic sign recognition system that can recognize in real-time for integrated on autonomous vehicles and to test the accuracy of the system. The image processing technique has been chosen to be applied on developing this system where the project is the implementation of the deep learning technology using You Only Look Once (YOLO) algorithm to train the model for detection. Five types of warning sign including crossroad, crossroad right, crossroad left, school children crossing and hump from Malaysian Traffic Sign is used. System testing was also conducted to study the accuracy of the detection and recognition towards traffic signs on the road. Test results reached real-time object detection with 96% accuracy on both traffic sign detection and recognition. The finding from this study is believed to be helpful as it may contribute to the automotive industry. In future, this system can be improved by integrating with the navigation system such as Global Positioning System (GPS) to make the system more functional and achieve more advance monitoring.",project-academic
,2020-01-01,a,Innovare Academics Sciences,development of intelligent self balancing e bike usingmachine learning," The self-driving autonomous cars is becoming an increasingly popular concept all around the world but
the area of self-driving two wheelers is still under developed. For developing countries like India, two wheelers are
affordable than cars for most of the population. The project aims at developing intelligent self-balancing bike using
artificial intelligence because the major problem in developing an autonomous bike is in the area of balancing. Even
though there are many working mechanisms available for self-balancing of bike, the implementation of AI will be an
edge over others from the point of computational power requirement and the programming complexity incurred.
 A prototype of the bike was developed with reaction wheel mechanism for self-balancing. The mechanism was fully
controlled by AI by preventing the need of explicit programming for balancing which was the earlier technique used in
self-balancing bike. Reinforcement learning, a type of machine learning technique is adopted for this purpose. The policy
gradient algorithm was used to make the bike learn by itself for balancing. Even though the AI algorithm worked well in
the virtual environment (balancing a cart-pole) it fails in the real environment. (i.e. it fails to balance the bike). It is
because of the noisy data from the sensor, which gives inaccurate information about the orientation of the bike. The noise
in the data is due to the vibration of the body when the reaction wheel rotates. This could be solved if the AI is fed with
accurate information about the orientation of the vehicle.",project-academic
10.1109/WORLDS4.2019.8904014,2019-07-30,p,IEEE,autonomous drone for defence machinery maintenance and surveillance," This proposed research work focuses on the implementation of an autonomous unmanned aerial vehicle (UAV) which is controlled using a pix hawk flight controller. The Quad Copter is capable of navigating autonomously without any real-time input from the user and also programmed to follow a specified path autonomously. The algorithm enables a control technique by which quad copter is empowered to fly autonomously, trajectory tracking, graceful motion and accurate altitude hold performance. Surveillance and Machinery maintenance application are the primary applications designed for the Defense purposes in the Line Of Control and War-zones. This work is aimed to design a quad copter that will follow a command to fly through specified way points. The deep learning algorithm detects human motions and from data acquired camera and ultrasonic sensors to the cloud. On deviations from the standard protocol which is detected using a Sjcam 5000x elite Camera. Also, here a backup auxiliary mini drone is programmed to eject along with the data stored on the primary drone's memory on an unforeseen calamity or an attack that would damage the primary drone's ability to fly.",project-academic
,2011-01-01,a,,a novel nero fuzzy controller as underwater discoverer," In this paper, a novel Nero-Fuzzy controller based autonomous underwater controller for UN_UND_VHs (unmanned underwater vehicles) is described. The research describes a Nerofuzzy controller as basic tasks to be accomplished of handling of motion coordination between the vehicle and the discoverer to successfully execute the manipulation task. A numerical case study is developed to demonstrate effectiveness of the proposed technique. The result of chip design is a chip in an area less than 0.56mm^2. The speed is 3420MFILIPS. Fuzzy controllers use fuzzy logic that is a nonlinear mapping of the nonlinear systems. Nonlinear systems lack a simple mathematical model and therefore are very complex to implement with classical systems. Fuzzy systems use language terms (words) instead of mathematic variables and rule-based inferences (Word Computing) instead of mathematical model. Using fuzzy logic for the implementation of the controllers used for nonlinear systems with high nonlinearity provides low cost, simple design and the possibility to design without knowing the exact mathematical model of process. Nowadays, general tendency for implementing the controllers of nonlinear systems is toward using fuzzy logic. The design and simulation of a fuzzy logic controller using MOS circuits is considered in this project. The state of the art of underwater manipulation is based on remotely operated vehicles carrying a tale-operated discoverer. One or more human operators are in charge of remotely controlling the vehicle actuators and the discoverer by, e.g., a master–slave technique. It is evident that trained and skilled operators are necessary to accomplish such operations and that the achievable performance is quite limited. Moreover, the operators are often required to be physically near to the vehicle-discoverer system, e.g., in a submarine, which raises the risks and costs involved with the mission to be executed. To partly solve the above problems, the ROV can be replaced by an autonomous underwater vehicle (ROV); in this case, however, while the operator can be in a surface vessel and control the sole discoverer, new problem s arise due to the time delays introduced by the vessel–discoverer communication system. To overcome the above limitations, recent research efforts are gold at developing completely autonomous underwater vehicle–discoverer systems. In this framework, one of the basic tasks to be accomplished is handling of motion coordination of the bodies constituting the UVMS to successfully execute the manipulation. The ocean has not been fully explored because of the hazardous underwater environment. The recent advancement in various areas such as batteries, materials, wireless communications and computers makes autonomous Information Sciences [1, 2, and 3] underwater vehicles (ROVs) attractive to various underwater applications. However, ROVs are highly nonlinear, coupled, and time varying and their hydrodynamic parameters are often poorly known [4]. Unlike other terrestrial systems, it is impossible to manually tune control parameters of ROVs, especially in deep water. Therefore, ROVs would require an intelligent control system that would self-tune the controller when the performance degrades during the operation, due to changes in the system and environment. Various advanced ROV control systems have been proposed in the literature, such as sliding control [5, 6], nonlinear control [7], adaptive control [8, 9], neural network [10,11], and fuzzy control [12,13]. Nonlinear control schemes often require an accurate system model. However, it is not easy to derive an accurate model of the ROV system due to parameter uncertainties in hydrodynamics. Conventional fuzzy control schemes require an expert knowledge or many cycles of trial-and-error to achieve the desired performance. In neural network control, training time is unpredictable and neural networks may not be suitable for real-time control [14]. Wang et al. [15] proposed Nero-fuzzy controller, called self–adaptive Nero-fuzzy inference system (SANFIS), for ROVs. The SANFIS controller can make fuzzy rules automatically with selflearning parameters. However, it requires learn the relationship between input and output using off-line learning schemes with input–output data generated by another control system.",project-academic
,2019-10-25,a,,automatic recognition and classification of passengers emotions in autonomous driving vehicles," Automatic Recognition And Classification Of Passengers' Emotions In Autonomous Driving Vehicles None None None Introduction None Development of autonomous driving vehicles is a challenging activity, with technological, ethical, and social implications. People use cars for over a hundred years, and during all this time period the vehicles have been operated by human drivers. Due to this habit, it is simpler for people to trust another person with respect to a computer to drive their vehicles. So, it is important to consider their social implications in order to avoid making the expected safety improvement useless due to a lack of trust of people on those vehicles. These regards ethic issues, social trust on autonomous driving capabilities, and novel commercialization model for car manufacturer. So, new methods for helping the social acceptance and trustiness on these new technologies are needed. None None None Thesis purpose None Our idea to solve this problem, that is the main purpose of this thesis, is to perform autonomous vehicles passengers’ emotions detection and use this data to adapt the autonomous cars driving style. Regarding the driving style adaptation, we’ll make some clarifications about what is the main objective that we want to achieve: None - if the people on the car are scared or sad, the car adopts a caring driving style, that slows the speed and takes the curve more accurately (lowering the lateral accelerations); None - if the people on the car are neutral, the car adopts a normal driving style; None - if the people on the car are happy or over enjoyed, the car adopts a sportive driving style (steeper acceleration/braking ramps and curve trajectory with higher lateral accelerations). None In this way, we hope to improve people’s confidence towards self-driving cars. None None None Facial Expression Database Classifier None As first step, we focused on the dataset preparation activities. To improve the effectiveness of this phase, we chose to develop a novel software that we called Facial Expression Database Classifier (FEDC); FEDC is a program able to automatically classify images of some of the most used databases, depicting posed human faces: None - Extended Cohn-Kanade Database (CK+); None - FACES Database; None - Facial Expression Recognition 2013 Database; None - Japanese Female Facial Expression Database (JAFFE); None - Multimedia Understanding Group Database (MUG); None - Radboud Faces Database (RaFD); None - Static Facial Expression in the Wild 2.0 Database (SFEW 2.0). None None None Neural Network None After realizing the first version of FEDC, we started to work on the possible improvements for this program and we also started to work on the implementation of a neural network. After a period of research of the state of the art regarding neural networks capable of doing emotion detection, we decided to implement the neural network proposed in the “Physiological Inspired Deep Neural Networks for Emotion Recognition” paper , obtaining almost the same results as the authors. None None None Road Tests None The last part of our work was to make some road test, in order to test the neural network performance. So, we developed Emotion Detector, a program that can take picture from the camera of a laptop and predict the emotions of a person. Using this tool, we took some pictures on realistic condition, obtaining very good results. None None None Conclusion None After the test, and in summary, we think that the result we obtained are really promising: this approach could really facilitate the diffusion of the autonomous driving cars.",project-academic
,2019-07-18,a,,sistem klasifikasi sampah berbasis convolutional neural network," Unmanned Surface Vehicle (USV) becomes a new solution in overcoming waste pollution in rivers. Use of USV replaces the garbage management system that is still done manually. Therefore the USV should be able to work as a garbage collector tool in the water by autonomous. To be able to detect the presence of garbage in the river, USV needs a garbage classification system capable of distinguishing garbage with plants. Many classification systems object to difficulty in identifying two objects that have a form that has been deformed and has the same color so that the approach is done using Deep Learning 
The implementation of this study used a Convutional Neural Network-based Garbage classification system (CNN). CNN-based Deep Learning is able to identify multiple objects at the same time in realtime and few of research availabe is CNN-based garbage classification systems specifically for river garbage. This research makes and tests CNN-based garbage classification system in identifying garbage in realtime in rivers. The type of CNN used in this study is You Only Look Once (YOLO). After its application, YOLO is able to classify garbage (Milo box) and water hyacinth plants with a percentage success of 65%.
	
Keywords: USV, CNN, Waste Classification System, YOLO.",project-academic
,2012-01-01,a,,online learning control for hybrid electric vehicle," Improvements in hybrid electric vehicle (HEV) fuel economy and emissions heavily depend on an efficient energy management strategy (EMS).However,the uncertainty of future driving conditions generally cannot be easily tackled in EMS design.Most existing EMSs act upon fixed parameters and cannot adapt to varying driving conditions.Therefore,they usually fail to fully explore the potential of these advanced vehicles.In this paper,a novel EMS design procedure based on neural dynamic programming (NDP) is proposed.The NDP is a generic online learning algorithm,which combines stochastic dynamic programming (SDP) and the temporal difference (TD) method.Instead of computing the utility function and optimal control actions through Bellman equations,the NDP algorithm uses two neural networks to approximate them.The weights of these neural networks are updated online by the TD method.It avoids the high computational cost that SDP suffers from and is suitable for real-time implementation.The main advantages of NDP EMS is that it does not rely on prior information related to future driving conditions,and can self-tune with a wide variance in operating conditions.The NDP EMS has been applied to 'Qianghua-I',a prototype of a parallel HEV,using a revolving drum test bench for verification.Experiment results illustrate the potential of the proposed EMS in terms of fuel economy and in keeping state of charge (SOC) deviations at a low level.The proposed research ensures the optimality of NDP EMS,as well as real-time applicability.",project-academic
,2018-09-21,a,,machine learning and big data processing in a human vehicle interaction system," Machine Learning and Big Data processing are the key points in the development of an Advanced Driving Assistance System (ADAS) and in general of an Autonomous or Semi-Autonomous vehicle. With the rising of the Internet Of Things (IoT) every object in a road environment will be connected and will interact with all the other components in the scenario. In this scenario, intelligent vehicles will be the linking point for human beings with the general system. Taking all these data coming from the environment, the vehicle will acquire knowledge by means of Machine Learning techniques, in order to improve safety, that is the final goal of the ADAS. In this project all these considerations were taken into account: the creation of a Big Data simulated environment, the processing of these data by means of the Ontologies creation and finally the application of 2 ML techniques thought for obstacle identification, classification and avoidance. This thesis shows all the results achieved, highlighting the previous system problems with the corresponding solutions. As a research thesis, the contribution is related to the ADAS and ML anatomy comparison and analysis, Ontology creation for different scenarios and ML application for the obstacle context. This thesis was a contribution to the artificial intelligence sub-system of a complete ADAS. Final goal of the project is the real implementation of the complete Autonomous Driving system, where the AI sub-system will play a key-role together with a communication intra-vehicle one and a general networking based sub-system.",project-academic
10.12783/SHM2017/13852,2017-09-28,a,"DEStech Publications, Inc.",development of a remote acquisition and transmission system of strain measurements in an unmanned aerial vehicle for damage detection," Reliability is a key requirement in the aerospace industry. Therefore, structural health monitoring (SHM) applications using strain-field estimation and pattern recognition techniques are in development as an alternative to improve reliability and reduce maintenance costs, promising to ease damage detection on aerospace structures. However, some challenges need to be resolved before real implementation of these techniques. One of these challenges is to uncouple operational conditions changes in strain field from those related directly to damage. In this paper, the development of a strain measurement remote acquisition and transmission system on an unmanned aerial vehicle (UAV) using Fiber Grating Sensors (FBGs) is presented. Before flight testing, ground tests are carried out to emulate the dynamic loads that will be presented during flight. The strain data acquired are processed using unsupervised learning algorithms based on Self-Organizing Maps (SOM) and DS2L-SOM (density-based techniques) in order to classify different operational conditions. The results showed the capability of the system for classifying different load conditions for a UAV’s main beam.",project-academic
,1996-01-01,b,Springer-Verlag,experimental robotics iv the 4th international symposium stanford california june 30 july 2 1995," Collective and cooperative group behaviours: Biologically inspired experiments in robotics.- Distributed robotic manipulation: Experiments in minimalism.- A general framework for multi-robot cooperation and its implementation on a set of three hilare robots.- Cooperative autonomous low-cost robots for exploring unknown environments.- An object-oriented framework for event-driven dextrous manipulation.- Toward obstacle avoidance in intermittent dynamical environments.- Integrating grasp planning and visual servoing for automatic grasping.- contact and grasp robustness measures: Analysis and experiments.- Performance limits and stiffness control of multifingered hands.- Real-time vision plus remote-brained design opens a new world for experimental robotics.- Experimental validation of an active visual control scheme based on a reduced set of image parameters.- Task oriented model-driven visually servoed agents.- Experiments in hand-eye coordination using active vision.- Visual positioning and docking of non-holonomic vehicles.- An intelligent observer.- The development of a robotic endoscope.- The extender technology: An example of human-machine interaction via the transfer of power and information signals.- Coordinated and force-feedback control of hydraulic excavators.- Experiments with a real-time structure-from-motion system.- Robotic perception of material: Experiments with shape-invariant acoustic measures of material type.- Multi-level 3D-tracking of objects integrating velocity estimation based on optical flow and kalman-filtering.- Experimental approach on artificial active antenna.- Low cost sensor based obstacle detection and description.- Parameter sensitivity analysis for design and control of tendon transmissions.- Stiffness isn't everything.- In pursuit of dynamic range: Using parallel coupled actuators to overcome hardware limitations.- Total least squares in robot calibration.- Symbolic modelling and experimental determination of physical parameters for complex elastic manipulators.- Learning compliant motions by task-demonstration in virtual environments.- Motion control for a hitting task: A learning approach to inverse mapping.- Experimental verification of progressive learning control for high-speed direct-drive robots with structure flexibility and non-collocated sensors.- Accurate positioning of devices with nonlinear friction using fuzzy logic pulse controller.- Platooning for small public urban vehicles.- Robust vehicle navigation.- Dynamic analysis of off-road vehicles.- An autonomous guided vehicle for cargo handling applications.- Robots that take advice.- Towards principled experimental study of autonomous mobile robots.- Mission programming: Application to underwater robots.- Specification, formal verification and implementation of tasks and missions for an autonomous vehicle.- Experimental study on modeling and control of flexible manipulators using virtual joint model.- Experimental research on impact dynamics of spaceborne manipulator systems.- An operational space formulation for a free-flying, multi-arm space robot.- Experimental research of a nonholonomic manipulator.- Mobile manipulation of a fragile object.- Empirical verification of fine-motion planning theories.- Estimating throughput for a flexible part feeder.- Interest of the dual hybrid control scheme for teleoperation with time delays for proceeding of ISER'95.- Robot force control experiments with an actively damped compliant end effector.- Improved force control for conventional arms using wrist-based torque feedback.- Indoor navigation of an inverse pendulum type autonomous mobile robot with adaptive stabilization control system.- Motion and perception strategies for outdoor mobile robot navigation in unknown environments.- Programming symmetric platonic beast robots.- An experimental study on motion control of a biped locomotion machine using reaction wheels.- Real-time programming of mobile robot actions using advanced control techniques.",project-academic
,2008-01-01,a,,color and texture features for landmarks recognition on uav navigation," Image processing in real-time is a fundamental issue in many applications in computer vision such as remote sensing, tracking and autonomous navigation. Nowadays many unmanned aerial vehicles (UAVs) depend on Global Positioning System (GPS) and inertial systems for navigation and are controlled by a ground control station. Vision systems could improve the autonomous capacity of navigation of such vehicles. The goal of this paper is to present empirical experiments of landmark recognition using color and texture features. Once the landmarks are recognized in a class of geo-referenced images they can be used to estimate the UAV position and help the autonomous navigation. Experiments are presented here using one set of aerial geo-referenced images (train set) and another set of aerial images (test set) of the same region, collected in different time, which are not geo-referenced. Two implementations of supervised learning algorithms, namely, Neural Networks and Adaptive Boosting were used to classify the instances. Besides the accuracy, training time and testing time other three metrics, recall, precision and ROC curve, were used to evaluate the landmark recognition experiments. Even using images from complex environments with different angles, illuminations and scales, the obtained recognition rate of up to 99% indicates the adequacy of using color and texture features for landmark recognition in autonomous aerial vehicle navigation.",project-academic
,2017-01-01,a,Chalmers University of Technology,hybrid map for autonomous commercial vehicles global localization using topological mapping and machine learning," We propose and investigated a novel method for global navigation and localization of an autonomous
commercial vehicle within a conned area using a hybrid map. The hybrid map is based on a topology using
nodes and edges where signicant places are adapted as nodes. The hybrid map is able to store dierent type
of machine learning algorithms and its 
exible design allows the topology to be easily extended. The hybrid
map operates using a node detector algorithm complimented with a node classication algorithm for increased
robustness. The machine learning algorithms uses two dimensional lidar data as inputs exclusively. When it
comes to the detection of nodes, performance evaluation showed that the Adam method are superior to the
common gradient descent method when training feed forward neural networks in the considered scenario. In
order to classify the nodes, one class support vector machines are preferred.
The performance of the hybrid map system was further on evaluated by implementing it on a Raspberry Pi
3 to prove its simplicity.
In conclusion, our results suggest that the system has potential for implementation in a real vehicle. However,
it needs further verication and improvements to ensure a robust system and for it to be useful as a real
application.",project-academic
10.6092/UNINA/FEDOA/10369,2015-03-31,a,,innovative virtual air data sensors algorithms and flight test results," This thesis deals with the design, prototype implementation and the assessment of virtual sensors for an Air Data System (ADS). The needs for the development of a virtual Air Data Sensors resides on two relevant aspects in aviation transport development: a) the opportunity to improve the safety of manned aviation, by implementing an affordable solution for ADS redundancy; b) the possibility to improve the reliability of unmanned air vehicles (UAVs), which can support their integration in non-segregated airspace.
Virtual sensors are normally considered as a relevant component of Fault Detection and Isolation approaches to the Fault Tolerant Control Theory, briefly introduced in the thesis.
Virtual sensors for both the Angle-of-Attack and the Indicated Air Speed have been developed and completely assessed in CIRA Laboratory test bed for Real-Time Simulation with Hardware and Pilot-in-the-Loop.
In some cases, the assessment has also been achieved in flight test, on the FLARE vehicle which CIRA operates specifically for the execution of flight test of prototype technologies.
The thesis first analyses and describe the basic methodologies for the virtual sensors design, identifying those better suitable for application to air data measures. In particular, both the model-based technique and the implementation of ADS Virtual Sensors through Artificial Neural Networks are described. Special attention is given to the data selection techniques aimed at network training and assessment, focusing the machine learning approach to this aspects.
The study case applied to the TECNAM P92 VLA vehicle is described in detail, posing attention to the description of both the laboratory set-up realization and to the specific upgrades which have been required to the TECNAM P92 vehicle for the in-flight tests of the developed virtual sensors.
The assessment of both the model-based Virtual Sensors and the ANN Virtual Sensors is finally documented.",project-academic
,2014-01-01,a,Politecnico di Torino,a real time absolute position estimation architecture for autonomous aerial robots using artificial neural networks," The civil applications of Unmanned Aerial Vehicle (UAV) technology are constantly on a rise and the safety rules for the operation of UAVs in populated areas are being drafted. The UAV technology is an active area of academic research due to the challenges related to aerodynamics, tight power and payload budgets, multi-sensor information fusion, reactive real-time path planning, perception and communication bandwidth requirements. Autonomous navigation is a complex problem due to the challenges of algorithmic complexity and their real-time implementation. The challenges like long-term GPS errors/outage/jamming and exponential error growth in inertial sensors increase the complexity of autonomous navigation to an extent that high level of redundancy is mandatory in the design of navigation systems. Typical UAV systems use multi-sensor (GPS + INS +Vision) data fusion coupled with responsive sensors, innovative navigation algorithms, computationally capable onboard computers and reactive electromechanical systems to accomplish the navigational needs of safe operations in urban environments. Machine learning is a very promising technology and has broad applicability in the many real-life problems: ranging from hand-held & wearable computers to intelligent cars and homes. It can be efficiently used in autonomous navigation of UAVs. This work presents a novel absolute position estimation solution that leverages Radial Basis Function (RBF) classifier for robust aerial image registration. The proposed solution covers the entire spectrum of the problem involving algorithm design, hardware architecture and real-time hardware implementation. The system relies on single passive imaging source for acquisition of aerial images. The sensed image is geometrically transformed to bring it in a common view point as the reference satellite image. The orthorectified aerial image is then learned by the RBF network and full search is performed in the Region of Interest (ROI) of the reference satellite image. The real-time implementation of computationally intensive algorithm is accomplished by designing a customized wide data path in Field Programmable Gate Array (FPGA). The proposed architecture offers a reliable drift-free position estimation solution by conglomerating information from the inertial sensors and geo-registration of the aerial images over a geodetically aligned satellite reference image. We compare the robustness of our proposed matching algorithm with the standard normalized area correlation techniques and present limitations and False Acceptance Rates (FAR) of the two algorithms. This analysis has been performed on a set of real aerial and satellite imagery, acquired under different lightening and weather conditions. This is then followed by a discussion on real-time FPGA based architecture and power analysis. We conclude by presenting future directions of the work. Keywords: Inertial Measurement Units, Vision based Navigation, Real-time implementation, FPGA, Neural Network",project-academic
,2019-09-10,,,method for detecting farmland plastic film residues by near earth aerial photography of unmanned aerial vehicle," The invention relates to a method for detecting farmland plastic film residue by near-earth aerial photography of an unmanned aerial vehicle, which adopts a near-earth aerial photography system of theunmanned aerial vehicle and is realized by the following steps of: 1, calculating required spatial resolution; setting the flight height through the focal length and the resolution of the camera; 2,planning an aerial photography route; starting the unmanned aerial vehicle to complete a flight task according to the planned route, and collecting farmland videos through an aerial camera in the flight process; 3, splitting the video stream into single pictures; splicing a plurality of images to obtain a panorama of the cultivated land; 4, surveying the mulching film pollution degree of part of cultivated land soil on site manually in advance, collecting an image of the area as a training sample, and constructing a mulching film pollution degree prediction model based on deep learning; 5, inputting the to-be-tested sample into the deep learning model to obtain a cultivated land pollution degree. The farmland yield prediction method is a set of systematic, complete and rapid farmland yieldprediction method, has obvious advantages in prediction speed compared with a traditional method, is more accurate in prediction, is low in implementation cost, is safe and efficient, and is rapid and flexible.",project-academic
,2019-07-01,a,E.T.S.I de Sistemas Informáticos (UPM),clasificacion supervisada de imagenes mediante redes neuronales convolutivas," Tradicionalmente, la identificacion de las plantas ha sido realizada por personas especializadas llamadas taxonomos. Sin embargo, las nuevas tecnologias permiten la automatizacion de esta tarea, teniendo como fin simplificar y agilizar su realizacion. Persiguiendo este objetivo, se desarrollo una clasificacion automatica de plantas, de tal manera que con tan solo pasar la imagen de una hoja al sistema, este es capaz de identificar a que tipo de planta pertenece. El desarrollo de una aplicacion asi es deseable en muchisimas situaciones. Por ejemplo, el uso de un vehiculo aereo no tripulado capaz de identificar sobre que tipo de plantas esta sobrevolando. Otro ejemplo seria utilizarlo como base para el desarrollo de nuevas aplicaciones, como el uso de este sistema en dispositivos moviles. Este trabajo describe como se ha llevado a cabo la clasificacion supervisada de distintos tipos de hojas mediante la ayuda de Redes Neuronales Convolutivas. Incluyendo, el proceso detallado de la creacion de dichas redes. Ademas, se analizaron los modelos obtenidos y se intento seleccionar el mejor como solucion del problema en cuestion. A lo largo del proyecto se busco tomar medidas para mejorar los modelos y se llevaron a cabo estas medidas con el fin de verificar su utilidad a la hora de mejorar los resultados. Nombrar tambien que, este proyecto, se considera como un primer acercamiento hacia una mayor investigacion en el campo de las redes de neuronas y la clasificacion automatica de objetos. Es por esto que mediante su desarrollo se pretende aprender a usar herramientas, librerias y entornos que se utilizan en proyectos reales y que tienen un gran potencial en este campo. None Abstract: Traditionally, plant identification has been done by specialized people called taxonomists. However, new technologies allow the automation of this task, with the aim of simplifying and speeding up its implementation. Pursuing this objective, an automatic classification of plants was developed, in such a way that with only passing the image of a leaf to the system, it is able to identify to which type of plant it belongs. The development of such an application is desirable in many situations. For example, the use of an unmanned aerial vehicle capable of identifying over what type of plants it is flying over. Another example would be to use it as a basis for the development of new applications, such as the use of this system in mobile devices. This work describes how the supervised classification of different types of leaves has been carried out with the help of Convolutive Neural Networks. Including, the detailed process of the creation of these networks. In addition, the models obtained were analyzed and an attempt was made to select the best as the solution to the problem in question. Throughout the project, measures were sought to improve the models and these measures were carried out in order to verify their usefulness in improving the results. Also it is important to say that, this project is considered as a first approach to further research in the field of Neural Networks and automatic classiffication of objects. This is why I tried to learn how to use tools, libraries and environments that are used in real projects and that have great potential in this field.",project-academic
,2006-01-01,a,,neuralnetworks implementation ofthevisual information processing foranintelligent aerial vehicle," Thispaperdescribes anewwayofthevisual This paper introduces anewconcept ofvision system information processing forsmallintelligent aerial based ontheneural networks andtheapplication of vehicles usingneuralnetworks, and itsVLSI spike-based neural hardware implementation bythenew implementation. Thevision using neural networks isfor bio-inspired conductance withtheadvantages ofup-to-date thenavigation toavoidobstacles, basedonthe64x64 VLSItechnology. image. Theareainthefront offlying ismappedto sixteen sectors, andanappropriate pathisselected by II.NEURAL NETWORKS FOR THE VISUAL thetrained neural networks. Themultilayered network INFORAMTAIONBASEDFLYING withtwohidden layers isemployed, andtheempirical rules areaddedtothetraining process. Pre-processing Thevisual information processing forthenavigation is ofsectored imagedataisprovedtoimprovethe widelyinvestigated in many area,especially for cognition performance remarkably, by itslocaliseduninhabited aerial vehicle orflying robots. Oneofissues is attention. Thesize ofneural networks isminimised for toavoidobstacles, whicharelikely a problem for asingle VLSIdevice implementation, lessthan4,000 autonomous flying incomplex environments. Thevision synaptic connections. based ontheinformation ofcolour contrast wasinspired by Theproposed vision system demonstrates thedesired thebiological vision system, andhasbeenapplied tothe behaviour withrealenvironmental scenes after the flying control. Theflying robot withneuromorphic eyes, training by thesimulated data.The feasibility of mimicking theinsect eye,demonstrated thefeasibility of neuromorphic VLSIimplementation isdemonstratedflowsensing toavoid obstacles andfollow terrains. Forthe bytheneural networkwithreduced synaptic weight navigation intheconfined 3-dimensional space, thevision accuracy, whichrepresents themeasured accuracy of based onsuchprinciple wasapplied tocontrol theflying biologically plausible conductance basedCMOS neural blimp. Theobstacles orflying environments like ground or networkVLSI.The proposedneuralnetworks wallneeds tobepredefined colour contrast, suchasblack implementation demonstrates thefeasibility ofan andwhite strips. (1)(2)Suchcolour contrast information is intelligent vision systemofsmalluninhabited aerial considered helpful forahumaninthree-dimensional",project-academic
,2018-11-09,,,systems and methods for safe and reliable autonomous vehicles," Autonomous driving is one of the world's most challenging computational problems. Very large amounts of data from cameras, RADARs, LIDARs, and HD-Maps must be processed to generate commands to control the car safely and comfortably in real-time. This challenging task requires a dedicated supercomputer that is energy-efficient and low-power, complex high-performance software, and breakthroughs in deep learning Al algorithms. To meet this task, the present technology provides advanced systems and methods that facilitate autonomous driving functionality, including a platform for autonomous driving Levels 3, 4, and/or 5. In preferred embodiments, the technology provides an end-to-end platform with a flexible architecture, including an architecture for autonomous vehicles that leverages computer vision and known ADAS techniques, providing diversity and redundancy, and meeting functional safety standards. The technology provides for a faster, more reliable, safer, energy-efficient and space- efficient System-on-a-Chip, which may be integrated into a flexible, expandable platform that enables a wide-range of autonomous vehicles, including cars, taxis, trucks, and buses, as well as watercraft and aircraft.",project-academic
10.1016/J.TRPRO.2016.05.236,2016-01-01,a,Elsevier,traffic models for self driving connected cars," Self-driving and connected vehicles, communicating with one another (V2V technology) and with the road infrastructure (V2I technology), are a subject of extensive research nowadays and are expected to revolutionize the automotive industry in the near future. The major goal of the authors' work is to design a microscopic traffic simulation model for such vehicles, including a robust protocol for exchanging information. The question arises as to whether such communication system may efficiently improve travel quality while reducing the risk of collisions. For the purpose of their research the authors created and developed a simulation software. Their tool visualizes traffic flow for custom but simplified road maps. The transport infrastructure includes multiple junctions, optionally equipped with traffic lights, and roads with varying number of travel lanes. Each vehicle is assigned a fixed route leading to a randomly chosen destination point. Any decisions made by autonomous cars (regarding acceleration or turning maneuvers) are preceded by communication stages (retrieving necessary data, negotiations). In the paper we present fundamental concepts, assumptions and design of our model and simulation software, the authors also discuss potential issues relevant to their approach. As for the future work, the authors plan to implement their model in a large-scale agent-based traffic simulation software, Traffic Simulation Framework, so that further examination will be carried out for realistic road networks taken from the OpenStreetMap project. The authors also plan to apply machine learning techniques, so that self-driving vehicles, as well as traffic light controllers, will be able to learn how to develop the best strategy and by this way improve traffic safety and efficiency in atypical cases.",project-academic
10.1023/A:1008822205706,1998-05-01,a,Kluwer Academic Publishers,rough terrain autonomous mobility part 2 an active vision predictive control approach," Off-road autonomous navigation is one of the most difficult automation challenges from the point of view of constraints on mobility, speed of motion, lack of environmental structure, density of hazards, and typical lack of prior information. This paper describes an autonomous navigation software system for outdoor vehicles which includes perception, mapping, obstacle detection and avoidance, and goal seeking. It has been used on several vehicle testbeds including autonomous HMMWV‘s and planetary rover prototypes. To date, it has achieved speeds of 15 km/hr and excursions of 15 km.

We introduce algorithms for optimal processing and computational stabilization of range imagery for terrain mapping purposes. We formulate the problem of trajectory generation as one of predictive control searching trajectories expressed in command space. We also formulate the problem of goal arbitration in local autonomous mobility as an optimal control problem. We emphasize the modeling of vehicles in state space form. The resulting high fidelity models stabilize coordinated control of a high speed vehicle for both obstacle avoidance and goal seeking purposes. An intermediate predictive control layer is introduced between the typical high-level strategic or artificial intelligence layer and the typical low-level servo control layer. This layer incorporates some deliberation, and some environmental mapping as do deliberative AI planners, yet it also emphasizes the real-time aspects of the problem as do minimalist reactive architectures.",project-academic
10.1109/TIV.2018.2886678,2019-03-13,a,IEEE,test your self driving algorithm an overview of publicly available driving datasets and virtual testing environments," Many companies aim for delivering systems for autonomous driving reaching out for SAE Level 5. As these systems run much more complex software than typical premium cars of today, a thorough testing strategy is needed. Early prototyping of such systems can be supported using recorded data from on-board and surrounding sensors as long as open-loop testing is applicable; later, though, closed-loop testing is necessary—either by testing on the real vehicle or by using a virtual testing environment. This paper is a substantial extension of our work presented at the 2017 IEEE International Conference on Intelligent Transportation Systems (ITSC) that was surveying the area of publicly available driving datasets. Our previous results are extended by additional datasets and complemented with a summary of publicly available virtual testing environments to support closed-loop testing. As such, a steadily growing number of 37 datasets for open-loop testing and 22 virtual testing environments for closed-loop testing have been surveyed in detailed. Thus, conducting research toward autonomous driving is significantly supported from complementary community efforts: A growing number of publicly accessible datasets allow for experiments with perception approaches or training and testing machine-learning-based algorithms, while virtual testing environments enable end-to-end simulations.",project-academic
10.1155/2018/8489326,2018-06-13,a,Hindawi,air to air path loss prediction based on machine learning methods in urban environments," Recently, unmanned aerial vehicle (UAV) plays an important role in many applications because of its high flexibility and low cost. To realize reliable UAV communications, a fundamental work is to investigate the propagation characteristics of the channels. In this paper, we propose path loss models for the UAV air-to-air (AA) scenario based on machine learning. A ray-tracing software is employed to generate samples for multiple routes in a typical urban environment, and different altitudes of Tx and Rx UAVs are taken into consideration. Two machine-learning algorithms, Random Forest and KNN, are exploited to build prediction models on the basis of the training data. The prediction performance of trained models is assessed on the test set according to the metrics including the mean absolute error (MAE) and root mean square error (RMSE). Meanwhile, two empirical models are presented for comparison. It is shown that the machine-learning-based models are able to provide high prediction accuracy and acceptable computational efficiency in the AA scenario. Moreover, Random Forest outperforms other models and has the smallest prediction errors. Further investigation is made to evaluate the impacts of five different parameters on the path loss. It is demonstrated that the path visibility is crucial for the path loss.",project-academic
,2020-04-03,a,,tensorfi a flexible fault injection framework for tensorflow applications," As machine learning (ML) has seen increasing adoption in safety-critical domains (e.g., autonomous vehicles), the reliability of ML systems has also grown in importance. While prior studies have proposed techniques to enable efficient error-resilience techniques (e.g., selective instruction duplication), a fundamental requirement for realizing these techniques is a detailed understanding of the application's resilience. 
In this work, we present TensorFI, a high-level fault injection (FI) framework for TensorFlow-based applications. TensorFI is able to inject both hardware and software faults in general TensorFlow programs. TensorFI is a configurable FI tool that is flexible, easy to use, and portable. It can be integrated into existing TensorFlow programs to assess their resilience for different fault types (e.g., faults in particular operators). We use TensorFI to evaluate the resilience of 12 ML programs, including DNNs used in the autonomous vehicle domain. Our tool is publicly available at this https URL.",project-academic
10.1109/ISSRE5003.2020.00047,2020-10-01,p,IEEE,tensorfi a flexible fault injection framework for tensorflow applications," As machine learning (ML) has seen increasing adoption in safety-critical domains (e.g., autonomous vehicles), the reliability of ML systems has also grown in importance. While prior studies have proposed techniques to enable efficient error-resilience (e.g., selective instruction duplication), a fundamental requirement for realizing these techniques is a detailed understanding of the application’s resilience. In this work, we present TensorFI, a high-level fault injection (FI) framework for TensorFlow-based applications. TensorFI is able to inject both hardware and software faults in general TensorFlow programs. TensorFI is a configurable FI tool that is flexible, easy to use, and portable. It can be integrated into existing TensorFlow programs to assess their resilience for different fault types (e.g., faults in particular operators). We use TensorFI to evaluate the resilience of 12 ML programs, including DNNs used in the autonomous vehicle domain. The results give us insights into why some of the models are more resilient. We also present two case studies to demonstrate the usefulness of the tool. TensorFI is publicly available at https://github.com/DependableSystemsLab/TensorFI.",project-academic
10.3390/ELECTRONICS8090943,2019-08-27,a,Multidisciplinary Digital Publishing Institute,toward a comfortable driving experience for a self driving shuttle bus," The convergence of mechanical, electrical, and advanced ICT technologies, driven by artificial intelligence and 5G vehicle-to-everything (5G-V2X) connectivity, will help to develop high-performance autonomous driving vehicles and services that are usable and convenient for self-driving passengers. Despite widespread research on self-driving, user acceptance remains an essential part of successful market penetration; this forms the motivation behind studies on human factors associated with autonomous shuttle services. We address this by providing a comfortable driving experience while not compromising safety. We focus on the accelerations and jerks of vehicles to reduce the risk of motion sickness and to improve the driving experience for passengers. Furthermore, this study proposes a time-optimal velocity planning method for guaranteeing comfort criteria when an explicit reference path is given. The overall controller and planning method were verified using real-time, software-in-the-loop (SIL) environments for a real-time vehicle dynamics simulation; the performance was then compared with a typical planning approach. The proposed optimized planning shows a relatively better performance and enables a comfortable passenger experience in a self-driving shuttle bus according to the recommended criteria.",project-academic
10.2139/SSRN.2927459,2017-03-01,a,,self driving contracts," Ex post gap filling is a central function of contract law. This is about to change. Predictive capabilities created by big data and artificial intelligence increasingly allow parties to draft contracts that fill their own gaps and interpret their own standards without adjudication. With these self-driving contracts, parties can agree to broad objectives and let automated analytics fill in the specifics based on real-time contingencies. Just as a self-driving car fills in the driving details to get its passenger to a designated end point, the self-driving contract fills in the contract details to achieve the parties’ designated outcome. 
This development suggests a new focus for the doctrine and theories of contract law. Our primary goal in this Article is to introduce and develop that new focus. For example, self-driving contracts are both complete and incomplete. They are complete in that they specify actions for every contingency. This reduces the likelihood of breach and renegotiation. It also means that notions of efficient breach and ex post hold-up will be of reduced importance in contract law. At the same time, self-driving contracts are also incomplete in ways that render current notions of definiteness and mutual assent irrelevant or at best misleading. 
Perhaps most importantly, with contracts being interpreted by their own internal software, contract law will have to focus on where that software comes from and how it operates. Markets will arise for third-party vendors who either certify or provide independent contract programming. In some cases, these will be new markets; in others, they will evolve from existing markets such as the market for contract arbitrators. Law will play a role in supporting and overseeing these markets. We explore that role, and how it will differ in markets for contracts between sophisticated parties and in markets for consumer contracts.",project-academic
,2017-09-22,a,University of Iowa,self driving contracts," Ex post gap filling is a central function of contract law. This is about to change. Predictive capabilities created by big data and artificial intelligence increasingly allow parties to draft contracts that fill their own gaps and interpret their own standards without adjudication. With these self-driving contracts, parties can agree to broad objectives and let automated analytics fill in the specifics based on real-time contingencies. Just as a self-driving car fills in the driving details to get its passenger to a designated end point, the self-driving contract fills in the contract details to achieve the parties’ designated outcome. 
This development suggests a new focus for the doctrine and theories of contract law. Our primary goal in this Article is to introduce and develop that new focus. For example, self-driving contracts are both complete and incomplete. They are complete in that they specify actions for every contingency. This reduces the likelihood of breach and renegotiation. It also means that notions of efficient breach and ex post hold-up will be of reduced importance in contract law. At the same time, self-driving contracts are also incomplete in ways that render current notions of definiteness and mutual assent irrelevant or at best misleading. 
Perhaps most importantly, with contracts being interpreted by their own internal software, contract law will have to focus on where that software comes from and how it operates. Markets will arise for third-party vendors who either certify or provide independent contract programming. In some cases, these will be new markets; in others, they will evolve from existing markets such as the market for contract arbitrators. Law will play a role in supporting and overseeing these markets. We explore that role, and how it will differ in markets for contracts between sophisticated parties and in markets for consumer contracts.",project-academic
,2018-10-17,p,"Institute of Control, Robotics and Systems (ICROS)",development of simulator for autonomous underwater vehicles utilizing underwater acoustic and optical sensing emulators," This paper addresses an autonomous underwater vehicle (AUV) simulator with underwater image sonar and optical vision emulation. Recently, various underwater missions have been automated through the great improvement in underwater image sonar and optical vision technology along with utilization of artificial intelligence. Development of the simulator that emulates underwater image sonar and optical vision can support intelligent underwater missions by visualizing and simulating virtual scenarios and reproducing real missions. In order to benefit from existing software, the presented simulator is based on ROS (Robot Operating System) environment integrated with our image sonar and optical vision emulators. When an underwater virtual scenario of terrain, target objects, and AUVs with sensors is plotted using standard 3-D modeling programs, the simulator configures the scenario and displays sonar and optical images. The ultrasound and light Beams are modeled as a set of rays each, and the image sonar and optical vision are modeled as objects detecting collisions between the rays and target objects at certain positions and orientations. The sonar images generated by the simulator are compared with real images to confirm the validity of the models.",project-academic
10.1007/978-3-319-99996-8_8,2018-09-16,p,"Springer, Cham",cnn based traffic sign recognition for mini autonomous vehicles," Advanced driving assistance systems (ADAS) could perform basic object detection and classification to alert drivers for road conditions, vehicle speed regulation, and etc. With the advances in the new hardware and software platforms, deep learning has been used in ADAS technologies. Traffic signs are an important part of road infrastructure. So, it is very important task to detect and classify traffic signs for autonomous vehicles. In this paper, we firstly create a traffic sign dataset from ZED stereo camera mounted on the top of Racecar mini autonomous vehicle and we use Tiny-YOLO real-time object detection and classification system to detect and classify traffic signs. Then, we test the model on our dataset in terms of accuracy, loss, precision and intersection over union performance metrics.",project-academic
10.1109/ICCAS.2008.4694666,2008-12-02,p,IEEE,enhancing situational awareness by means of hybrid adaptive neural control of vertical flight in unmanned helicopter," This paper focuses on a critical component of the situational awareness, the neural control of autonomous vertical flight for an unmanned aerial vehicle. Autonomous vertical flight is a challenging but important task for tactical unmanned aerial vehicles to achieve high level of autonomy under adverse conditions. The fundamental requirement for vertical flight is the knowledge of the height above the ground, and a properly designed controller to govern the process. With the situational awareness strategy, we proposed a two stage flight control procedure using two adaptive neural networks to address the dynamics variation and performance requirement difference in initial and final stages of flight trajectory for a nontrivial small-scale helicopter model comprising five states, two inputs and two outputs. This control strategy for chosen helicopter model has been verified by simulation of descending and landing manoeuvres using software package Simulink and demonstrated good performance for fast situational awareness in real-time search-and-rescue operations.",project-academic
10.1145/3394885.3431620,2021-01-18,p,ACM,efficient computing platform design for autonomous driving systems," Autonomous driving is becoming a hot topic in both academic and industrial communities. Traditional algorithms can hardly achieve the complex tasks and meet the high safety criteria. Recent research on deep learning shows significant performance improvement over traditional algorithms and is believed to be a strong candidate in autonomous driving system. Despite the attractive performance, deep learning does not solve the problem totally. The application scenario requires that an autonomous driving system must work in real-time to keep safety. But the high computation complexity of neural network model, together with complicated pre-process and post-process, brings great challenges. System designers need to do dedicated optimizations to make a practical computing platform for autonomous driving. In this paper, we introduce our work on efficient computing platform design for autonomous driving systems. In the software level, we introduce neural network compression and hardware-aware architecture search to reduce the workload. In the hardware level, we propose customized hardware accelerators for pre- and post-process of deep learning algorithms. Finally, we introduce the hardware platform design, NOVA-30, and our on-vehicle evaluation project.",project-academic
,2014-12-01,a,University of Derby,a novel approach to the control of quad rotor helicopters using fuzzy neural networks," Quad-rotor helicopters are agile aircraft which are lifted and propelled by four rotors. Unlike traditional helicopters, they do not require a tail-rotor to control yaw, but can use four smaller fixed-pitch rotors. However, without an intelligent control system it is very difficult for a human to successfully fly and manoeuvre such a vehicle. Thus, most of recent research has focused on small unmanned aerial vehicles, such that advanced embedded control systems could be developed to control these aircrafts. Vehicles of this nature are very useful when it comes to situations that require unmanned operations, for instance performing tasks in dangerous and/or inaccessible environments that could put human lives at risk. This research demonstrates a consistent way of developing a robust adaptive controller for quad-rotor helicopters, using fuzzy-neural networks; creating an intelligent system that is able to monitor and control the non-linear multi-variable flying states of the quad-rotor, enabling it to adapt to the changing environmental situations and learn from past missions. Firstly, an analytical dynamic model of the quad-rotor helicopter was developed and simulated using Matlab/Simulink software, where the behaviour of the quad-rotor helicopter was assessed due to voltage excitation. Secondly, a 3-D model with the same parameter values as that of the analytical dynamic model was developed using Solidworks software. Computational Fluid Dynamics (CFD) was then used to simulate and analyse the effects of the external disturbance on the control and performance of the quad-rotor helicopter. Verification and validation of the two models were carried out by comparing the simulation results with real flight experiment results. The need for more reliable and accurate simulation data led to the development of a neural network error compensation system, which was embedded in the simulation system to correct the minor discrepancies found between the simulation and experiment results. Data obtained from the simulations were then used to train a fuzzy-neural system, made up of a hierarchy of controllers to control the attitude and position of the quad-rotor helicopter. The success of the project was measured against the quad-rotor’s ability to adapt to wind speeds of different magnitudes and directions by re-arranging the speeds of the rotors to compensate for any disturbance. From the simulation results, the fuzzy-neural controller is sufficient to achieve attitude and position control of the quad-rotor helicopter in different weather conditions, paving way for future real time applications.",project-academic
,2017-10-19,,,autonomous set of devices and method for detecting and identifying plant species in an agricultural crop for the selective application of agrochemicals," The invention relates to an autonomous set of devices for detecting and identifying wild and cultivated plant species on a farm, using software which, by obtaining a video in real time, can detect, isolate and identify different wild and cultivated plant species by using convolutional neural networks able to distinguish distinctive aspects of the morphology, taxonomy and philotaxy of the plants. By previously training the convolutional neural networks on the characteristics that distinguish one species from another, the system allows the particular identification of each species. By means of a system of video cameras mounted along a transport vehicle, and with the data being obtained in real time, the computer system can determine the agrochemical to be applied according to the plant identified and electronically or mechanically actuate the opening of the valve of a spray nozzle. In this way, the plant receives the exact dose and the specific agrochemical according to the necessary treatment.",project-academic
,2017-05-08,,,vehicle based independent range system vbirs," A Vehicle Based Independent Range System (VBIRS) ( 10 ) comprised of individual stacked chambered modules that function as a single integrated system that provides a self-contained space based range capability, and is comprised of a power module ( 12 ), an artificial intelligence/autonomous engagement/flight termination system module ( 20 ), a satellite data modem module system ( 30 ) and a navigation, communications and control module system ( 40 ), all of which interface with a VBIRS test and checkout system ( 52 ) and a weather data system ( 116 ). The artificial intelligence/autonomous engagement/flight termination system module ( 20 ) is comprised of an inherent artificial intelligence capability that envelopes and interchanges data with an autonomous engagement controller ( 22 ) that contains all missile/rocket autonomous cooperative engagement, destruct decision software and range safety algorithm parameters required for optimum mission planning. VBIRS employed aboard an aircraft or between any combination of launching systems allows that aircraft to launch a missile/rocket from any location on earth, whether the missile/rocket is singularly launched by itself or as a larger group of missiles/rockets launched in a salvo arrangement, while providing collaborative real-time targeting to occur directly between missiles/rockets in conjunction with other missile/rocket launch platforms or stand-alone mission control centers.",project-academic
,2017-11-01,a,"University of Texas, Austin, School of Law Publications, Inc.",the foreseeability of human artificial intelligence interactions," Consider the following hypotheticals:(1) A hospital uses artificial intelligence software to analyze a patient's medical history and make a determination as to whether he or she needs surgery. One day, the artificial intelligence software incorrectly diagnoses a patient and recommends an unnecessary surgery. In preparation for the surgery, an anesthesiologist applies an incorrect dosage of the surgical anesthetic and kills the patient.(2) An investment firm uses artificial intelligence software to identify promising stocks for investment. Without any further research, an investment banker negligently recommends stocks off of the software's prepared list. Those stocks go bust, costing their new owners thousands of dollars.(3) A vehicle with autonomous-driving software is cruising down a two-lane road. The lane to its right is filled with cars driving in the same direction. A human driver is in oncoming traffic and recognizes the autonomous car as being from a notable autonomous car brand. The human driver decides it would be fun to ""play chicken"" with the car to see how it will react. The human driver proceeds to swerve into the autonomous vehicle's lane and the autonomous vehicle, thinking it best to avoid a head-on collision and not realizing the human driver won't hit it, swerves into the right lane, triggering a collision with an innocent third-party car.(4) A delivery drone, piloted with autonomous-piloting software, is en route to deliver a package. On its way, it passes the home of a paranoid man who is very concerned with his privacy. He proceeds to take a baseball, and with an impressive throw, knocks the drone out of the sky. The drone crashes down and hits a child playing in a nearby park.(5) A company selling artificial intelligence software sells its product to a racist. The racist proceeds to install the software onto a robot butler, and the robot butler proceeds to learn and develop under the teachings of its owner. One day, a black UPS driver delivers a package to the front door. The now-racist robot answers the door and upon seeing the black UPS driver, thinks, ""The only reason a black person would be on my front porch would be if he were here to burgle my owner."" The robot proceeds to attack the UPS driver under the mistaken assumption that he is a burglar.In each of the above hypotheticals, the use of artificial intelligence led to the injury of an innocent person. When faced with an injury caused by another, each of these persons may seek a remedy through the tort system. The tort system is designed to provide monetary damages for injured parties when they are harmed by the negligent conduct of another.1 In this way, the tort system assures that the costs of negligent conduct lie with those responsible for causing the injury.2 Each injured party in the hypotheticals above can sue the negligent actor who caused the harm-but who (or what) exactly caused the injured party's harm? In the above hypotheticals, there are human actors who cause the injured party's harm through obviously negligent conduct or even intentional conduct. These human actors present themselves as obvious targets, but what about the developers of the artificial intelligence software? When the injured parties sue in court, they are likely to sue whomever has the deepest pockets.3 This should strike fear into the hearts of many artificial intelligence companies, because in these tort suits, they are likely to be the parties in the best financial position to pay out damages.If artificial intelligence companies are sued for the negligent development of their software, courts will be faced with a difficult question of foreseeability. When proving a case of negligence, plaintiffs are required to show the harm that occurred was a foreseeable consequence of the defendant's negligent conduct.4 This is also called satisfying the proximate cause requirement of a negligence case.5 In each hypothetical, was the interaction between the artificial intelligence software and human actor foreseeable? …",project-academic
10.1109/MWC.2019.1800505,2019-08-22,a,Institute of Electrical and Electronics Engineers (IEEE),detecting malware on x86 based iot devices in autonomous driving," X86-based software runs on some mainstream autonomous driving systems to perform intelligent operations and help to significantly improve driving safety. However, vulnerabilities of software in autonomous driving can lead to vehicle components and systems being attacked, which ultimately affects the work of the autonomous vehicle. Although many scholars have detected malware on X86-based Internet of Things (IoT) devices through static or dynamic analysis, these methods cannot be directly ported to X86-based IoT devices in autonomous driving because of hardware and software capabilities and real-time requirements. In this work, we propose the detection of malware on X86-based IoT devices in an autonomous driving approach combining fusion features from static analysis and machine learning to solve problems of resource overhead for dynamic analysis and low accuracy of the static analysis. First, a feature extraction model based on the level of operation code is designed. Then fusion features at three different levels are extracted through unpacking programs. Finally, a detection model based on Extreme Gradient Boosting (XGBoost) is used to discover malware on X86-based IoT devices in autonomous driving. On this basis, a malware detection approach based on fusion features is demonstrated. After that, we compare our approach with other identification approaches on a dataset consisting of 4169 samples, which includes 2379 malware and 1790 benign programs. Experimental results show that fusion features can significantly increase the recognition rate. Moreover, XGBoost has a higher recognition accuracy than other mainstream classification algorithms.",project-academic
10.1109/FMEC49853.2020.9144828,2020-04-20,p,IEEE,keynote speech 3 big data computing and machine learning for intelligent transportation and connected vehicles," We are developing machine learning algorithms and software to fuse real-time feeds from video cameras and traffic sensor data to generate real-time detection, classification, and space-time trajectories of individual vehicles and pedestrians. This information is then transmitted to a cloud-based system and then synthesized to create a real-time city-wide traffic palette. I will discuss our research on: Smart intersections: Space-time trajectories are used to understand and improve the safety and efficiency of the intersection. Using conflict points of the vehicle-pedestrian trajectories, we identify potential collisions, or “near-misses,” and how they are related to the state of the signal cycle (transition from green to yellow, from yellow to red, etc.) and the presence of other vehicles and pedestrians. • Smart system: We are developing efficient signal re-timing for different corridors by time of day and day of the week to reflect the changes in network demand. We are also developing machine learning techniques for real-time detection of incidents and accidents on arterial networks. • Smart interactions with connected and autonomous vehicles: We have developed signalized intersection control strategies and sensor fusion algorithms for jointly optimizing vehicle trajectories and signal control for a mixture of autonomous vehicles and traditional vehicles at every intersection",project-academic
10.1155/2020/3035741,2020-01-17,a,Hindawi,malware detection in self driving vehicles using machine learning algorithms," The recent trend for vehicles to be connected to unspecified devices, vehicles, and infrastructure increases the potential for external threats to vehicle cybersecurity. Thus, intrusion detection is a key network security function in vehicles with open connectivity, such as self-driving and connected cars. Specifically, when a vehicle is connected to an external device through a smartphone inside the vehicle or when a vehicle communicates with external infrastructure, security technology is required to protect the software network inside the vehicle. Existing technology with this function includes vehicle gateways and intrusion detection systems. However, it is difficult to block malicious code based on application behaviors. In this study, we propose a machine learning-based data analysis method to accurately detect abnormal behaviors due to malware in large-scale network traffic in real time. First, we define a detection architecture, which is required by the intrusion detection module to detect and block malware attempting to affect the vehicle via a smartphone. Then, we propose an efficient algorithm for detecting malicious behaviors in a network environment and conduct experiments to verify algorithm accuracy and cost through comparisons with other algorithms.",project-academic
10.2514/6.2020-4164,2020-11-16,p,American Institute of Aeronautics and Astronautics,artificial intelligence powering human exploration of the moon and mars," Artificial Intelligence (AI) is a growing field of computa- tional science techniques designed to mimic functions per- formed by people. Advancements in autonomy will depend on a portfolio of AI technologies. Automated planning and scheduling is a venerable field of study in AI, and is needed for a variety of mission planning functions. Plan execution technology is less well studied, but important for auton- omy and robotics. Specialized forms of automated reason- ing and machine learning are key technologies to enable fault management. Over the past decade, the NASA Au- tonomous Systems and Operations (ASO) project has devel- oped and demonstrated numerous autonomy enabling tech- nologies employing AI techniques. Our work has employed AI in three distinct ways to enable autonomous mission op- erations capabilities. Crew Autonomy gives astronauts tools to assist in the performance of each of these mission oper-ations functions. Vehicle System Management uses AI tech- niques to turn the astronaut's spacecraft into a robot, allow- ing it to operate when astronauts are not present, or to reduce astronaut workload. AI technology also enables Autonomous Robots as crew assistants or proxies when the crew are not present. When these capabilities are used to enable astro- nauts to operate autonomously, they must be integrated with user interfaces, introducing numerous human factors con- siderations; when these capabilities are used to enable vehi- cle system management, they must be integrated with flight software, and run on embedded processors under the control of real-time operating systems.We first describe human spaceflight mission operations capabilities. The remainder of the paper will describe the ASO project, and the development and demonstration per- formed by ASO since 2011. We will describe the AI tech- niques behind each of these demonstrations, which include a variety of symbolic automated reasoning and machine learn- ing based approaches. Finally, we conclude with an assess- ment of future development needs for AI to enable NASA's future Exploration missions.",project-academic
,2019-11-07,p,,artificial intelligence powering human exploration of the moon and mars," Artificial Intelligence (AI) is a growing field of computa- tional science techniques designed to mimic functions per- formed by people. Advancements in autonomy will depend on a portfolio of AI technologies. Automated planning and scheduling is a venerable field of study in AI, and is needed for a variety of mission planning functions. Plan execution technology is less well studied, but important for auton- omy and robotics. Specialized forms of automated reason- ing and machine learning are key technologies to enable fault management. Over the past decade, the NASA Au- tonomous Systems and Operations (ASO) project has devel- oped and demonstrated numerous autonomy enabling tech- nologies employing AI techniques. Our work has employed AI in three distinct ways to enable autonomous mission op- erations capabilities. Crew Autonomy gives astronauts tools to assist in the performance of each of these mission oper-ations functions. Vehicle System Management uses AI tech- niques to turn the astronaut's spacecraft into a robot, allow- ing it to operate when astronauts are not present, or to reduce astronaut workload. AI technology also enables Autonomous Robots as crew assistants or proxies when the crew are not present. When these capabilities are used to enable astro- nauts to operate autonomously, they must be integrated with user interfaces, introducing numerous human factors con- siderations; when these capabilities are used to enable vehi- cle system management, they must be integrated with flight software, and run on embedded processors under the control of real-time operating systems.We first describe human spaceflight mission operations capabilities. The remainder of the paper will describe the ASO project, and the development and demonstration per- formed by ASO since 2011. We will describe the AI tech- niques behind each of these demonstrations, which include a variety of symbolic automated reasoning and machine learn- ing based approaches. Finally, we conclude with an assess- ment of future development needs for AI to enable NASA's future Exploration missions.",project-academic
,2004-01-01,a,,a distributed architecture for intelligent unmanned aerial vehicle experimentation," The emerging area of intelligent unmanned aerial vehicle (UAV) research has shown rapid development in recent years and offers a great number of research challenges for artificial intelligence. In this article, a prototype distributed architecture for intelligent unmanned aerial vehicle experimentation is presented which supports the development of intelligent capabilities and their integration in a robust, scalable, plug-and-play hardware/software architecture. The architecture itself uses real-time CORBA to support its infrastructure and it is based on a reactive concentric software control philosophy. A number of capabilities of the architecture are presented including a multi-mode flight control system for a Yamaha RMAX VTOL platform, an on-board path planning service and a dynamically reconfigurable image processing system. A research prototype system has been built, is operational and is being used in actual missions. In the article, we emphasize the characteristics of the architecture which support the integration of numerous AI technologies.",project-academic
10.1016/J.MEASUREMENT.2021.109541,2021-08-01,a,Elsevier,data driven vehicle modeling of longitudinal dynamics based on a multibody model and deep neural networks," Abstract None None The vehicle dynamics simulation and preview control require a dedicated vehicle model, such as multibody dynamics model. However, the multibody model has higher computational complexity which affects the response time of the vehicle controller. This issue can be alleviated by using a data-driven vehicle dynamics model due to its effective generalization and computational speed. In this work, we propose a data-driven modeling approach based on deep neural networks (DNNs) for computing and predicting the vehicle characteristics. The high-fidelity simulations of a validated vehicle multibody model are performed for data acquisition. This data is then used for training and testing the proposed model. The DNN inputs comprise the initial speed of the vehicle and the torque applied on front wheels to imitate vehicle acceleration and deceleration. The DNN outputs comprise the driving distance and the longitudinal velocity of the vehicle. The dynamics characteristics resulting from both the data-driven model and the multibody model are investigated and compared. Furthermore, the accuracy of the data-driven model is analyzed in terms of various error functions. The data-driven model is verified by using the results obtained from a commercial software package. The simulation results show that the data-driven vehicle model predicts the accurate velocity and driving distance in real-time. The data-driven model can be used for real-time simulation and preview control in autonomous vehicles.",project-academic
10.1145/3449356,2021-07-18,a,"ACMPUB27New York, NY, USA",transfer reinforcement learning for autonomous driving from w ise m ove to w ise s im," Reinforcement learning (RL) is an attractive way to implement high-level decision-making policies for autonomous driving, but learning directly from a real vehicle or a high-fidelity simulator is variously infeasible. We therefore consider the problem of transfer reinforcement learning and study how a policy learned in a simple environment using WiseMove can be transferred to our high-fidelity simulator, WiseMove. WiseMove is a framework to study safety and other aspects of RL for autonomous driving. WiseMove accurately reproduces the dynamics and software stack of our real vehicle. None We find that the accurately modelled perception errors in WiseMove contribute the most to the transfer problem. These errors, when even naively modelled in WiseMove, provide an RL policy that performs better in WiseMove than a hand-crafted rule-based policy. Applying domain randomization to the environment in WiseMove yields an even better policy. The final RL policy reduces the failures due to perception errors from 10% to 2.75%. We also observe that the RL policy has significantly less reliance on velocity compared to the rule-based policy, having learned that its measurement is unreliable.",project-academic
10.3390/RS12183035,2020-09-02,a,Multidisciplinary Digital Publishing Institute (MDPI),detection of a moving uav based on deep learning based distance estimation," Distance information of an obstacle is important for obstacle avoidance in many applications, and could be used to determine the potential risk of object collision. In this study, the detection of a moving fixed-wing unmanned aerial vehicle (UAV) with deep learning-based distance estimation to conduct a feasibility study of sense and avoid (SAA) and mid-air collision avoidance of UAVs is proposed by using a monocular camera to detect and track an incoming UAV. A quadrotor is regarded as an owned UAV, and it is able to estimate the distance of an incoming fixed-wing intruder. The adopted object detection method is based on the you only look once (YOLO) object detector. Deep neural network (DNN) and convolutional neural network (CNN) methods are applied to exam their performance in the distance estimation of moving objects. The feature extraction of fixed-wing UAVs is based on the VGG-16 model, and then its result is applied to the distance network to estimate the object distance. The proposed model is trained by using synthetic images from animation software and validated by using both synthetic and real flight videos. The results show that the proposed active vision-based scheme is able to detect and track a moving UAV with high detection accuracy and low distance errors.",project-academic
10.1109/NILES50944.2020.9257941,2020-10-24,p,IEEE,real time collision warning system based on computer vision using mono camera," This paper aims to help self-driving cars and autonomous vehicles systems to merge with the road environment safely and ensure the reliability of these systems in real life. Crash avoidance is a complex system that depends on many parameters. The forward-collision warning system is simplified into four main objectives: detecting cars, depth estimation, assigning cars into lanes (lane assign) and tracking technique. The presented work targets the software approach by using YOLO (You Only Look Once), which is a deep learning object detector network to detect cars with an accuracy of up to 93%. Therefore, apply a depth estimation algorithm that uses the output boundary box’s dimensions (width and height) from YOLO. These dimensions used to estimate the distance with an accuracy of 80.4%. In addition, a real-time computer vision algorithm is applied to assign cars into lanes. However, a tracking proposed algorithm is applied to evaluate the speed limit to keep the vehicle safe. Finally, the real-time system achieved for all algorithms with streaming speed 23 FPS (frame per second).",project-academic
10.1016/J.SSCI.2017.10.020,2018-03-01,a,Elsevier,safety engineering of computational cognitive architectures within safety critical systems," Abstract None None This paper presents the integration of a cognitive architecture with an intelligent decision support model (IDSM) that is embedded into an autonomous non-deterministic safety critical system. The IDSM will integrate multi-criteria decision making via intelligent technologies like expert systems, fuzzy logic, machine learning and genetic algorithms. None Cognitive technology is currently simulated in safety–critical systems to highlight variables of interest, interface with intelligent technologies, and provide an environment that improves a system’s cognitive performance. In this study, the IDSM is being applied to an actual safety–critical system, an unmanned surface vehicle (USV) with embedded artificial intelligence (AI) software. The USV’s safety performance is being researched in a simulated and a real world nautical based environment. The objective is to build a dynamically changing model to evaluate a cognitive architecture’s ability to ensure safe performance of an intelligent safety–critical system. The IDSM does this by finding a set of key safety performance parameters that can be critiqued via safety measurements, mechanisms and methodologies. The uniqueness of this research will be on bounding the decision making associated with the cognitive architecture’s key safety parameters (KSP). None Other real-time applications that could benefit from advancing the safety of cognitive technologies are unmanned platforms, transportation technologies, and service robotics. The results will provide cognitive science researchers a reference for safety engineering artificially intelligent safety–critical systems.",project-academic
10.15496/PUBLIKATION-28045,2018-06-26,p,IEEE,rendering physically correct raindrops on windshields for robustness verification of camera based object recognition," Recent developments in the field of autonomous cars indicate the appearance of those vehicles on the streets of every city in the near future. This urban driving requires zero error tolerance. In order to guarantee safety requirements self-driving cars and the used software have to pass exhaustive tests under as many different conditions as possible. The more versatile the considered influences and the more thorough the tests made under those influences, the safer the car will drive under real conditions. Unfortunately, it is very time and resource intensive to record the same test set of images over and over again, every time producing, or hoping for, specific conditions; especially when using real test vehicles. This is where environment simulation comes into play. This research investigates the simulation of environmental influences which may affect the sensors used in autonomous vehicles, in particular how raindrops resting on a windshield affect cameras as they may occlude large parts of the field of view. We propose a novel method to render these raindrops using Continuous Nearest Neighbor search leveraging the benefits of R-trees. The 3D scene in front of the camera, which is generated from stereo images, reflects physically correct in these drops. This leads to near photo-realistic simulated results. The derived images may be used to extend the training data sets used for machine learning without being forced to capture new real pictures.",project-academic
,2009-01-01,p,Elsevier,extending the evolutionary robotics approach to flying machines an application to mav teams," The work presented in this article focuses on the use of embodied neural networks - developed through Evolutionary Robotics and Multi-Agent Systems methodologies - as autonomous distributed controllers for Micro-unmanned Aerial Vehicle (MAV) teams. The main aim of the research is to extend the range of domains that could be successfully tackled by the Evolutionary Robotics approach. The flying robots realm is an area that has not been yet thoroughly investigated by this discipline. This is due to the lack of an affordable and reliable robotic platform to use for carrying out experiments, and to the difficulty and the high computational load involved in experiments based upon a realistic software simulator for aircraft. We believe that the most recent improvements to the state of the art now permit the investigation of this domain. For demonstrating this point, two different evolutionary computer simulation models are presented in this article. The first model, which uses a simplified 2D test environment, has resulted in controllers evolved with the following capabilities: (1) navigation through unknown environments, (2) obstacle-avoidance, (3) tracking of a movable target, and (4) execution of cooperative and coordinated behaviors based on implicit communication strategies. In order to improve the robustness of these results and their potential use in real MAV teams, a more sophisticated 3D model is presented herein. The results obtained so far using the two models demonstrate the feasibility of the chosen approach for further research on the design of autonomous controllers for MAVs.",project-academic
10.3390/S20133679,2020-06-30,a,MDPI AG,simultaneous estimation of vehicle roll and sideslip angles through a deep learning approach," Presently, autonomous vehicles are on the rise and are expected to be on the roads in the coming years. In this sense, it becomes necessary to have adequate knowledge about its states to design controllers capable of providing adequate performance in all driving scenarios. Sideslip and roll angles are critical parameters in vehicular lateral stability. The later has a high impact on vehicles with an elevated center of gravity, such as trucks, buses, and industrial vehicles, among others, as they are prone to rollover. Due to the high cost of the current sensors used to measure these angles directly, much of the research is focused on estimating them. One of the drawbacks is that vehicles are strong non-linear systems that require specific methods able to tackle this feature. The evolution in Artificial Intelligence models, such as the complex Artificial Neural Network architectures that compose the Deep Learning paradigm, has shown to provide excellent performance for complex and non-linear control problems. In this paper, the authors propose an inexpensive but powerful model based on Deep Learning to estimate the roll and sideslip angles simultaneously in mass production vehicles. The model uses input signals which can be obtained directly from onboard vehicle sensors such as the longitudinal and lateral accelerations, steering angle and roll and yaw rates. The model was trained using hundreds of thousands of data provided by Trucksim® and validated using data captured from real driving maneuvers using a calibrated ground truth device such as VBOX3i dual-antenna GPS from Racelogic®. The use of both Trucksim® software and the VBOX measuring equipment is recognized and widely used in the automotive sector, providing robust data for the research shown in this article.",project-academic
,2011-06-10,a,IEEE,alturi a thin middleware for simulated robot vision applications," Fast software performance is often the focus when developing real-time vision-based control applications for robot simulators. In this paper we have developed a thin, high performance middleware for USARSim and other simulators designed for real-time vision-based control applications. It includes a fast image server providing images in OpenCV, Matlab or web formats and a simple command/sensor processor. The interface has been tested in USARSim with an Unmanned Aerial Vehicle using two control applications; landing using a reinforcement learning algorithm and altitude control using elementary motion detection. The middleware has been found to be fast enough to control the flying robot as well as very easy to set up and use.",project-academic
10.1109/IJCNN.2017.7966404,2017-05-01,p,IEEE,following the leader using a tracking system based on pre trained deep neural networks," In this work, we present a software architecture to solve, at some level, the follow the leader problem. This problem consists of an autonomous vehicle trying to track and follow a leader vehicle. To track the leader position in consecutive camera images, we employed the Generic Object Tracking Using Regression Networks (GOTURN). GOTURN is a pre-trained Deep Neural Network capable of tracking generic objects, without application-specific training or fine-tuning. The proposed software architecture was evaluated using a real autonomous vehicle, in four stretches of a University ring road. In all experiments, the autonomous vehicle was able to follow the leader's path with maximum root mean square error of 0.28m.",project-academic
,1993-03-01,a,"Monterey, California. Naval Postgraduate School",the rational behavior model a multi paradigm tri level software architecture for the control of autonomous vehicles," Abstract : There is currently a very strong interest among researchers in the fields of artificial intelligence and robotics in finding more effective means of linking high level symbolic computations relating to mission planning and control for autonomous vehicles to low level vehicle control software. The diversity exhibited by the many processes involved in such control has resulted in a number of proposals for a general software architecture intended to provide an efficient yet flexible framework for the organization and interaction of relevant software components. The Rational Behavior Model (RBM) has been developed with these requirements in mind and consists of three levels, called the Strategic, the Tactical, and the Execution levels, respectively. Each level reflects computations supporting the solution to the global control problem based on different abstraction mechanisms. The unique contribution of the RBM architecture is the idea of specifying different programming paradigms to realize each software level. Specifically, RBM uses rule-based programming for the Strategic level, thereby permitting field reconfiguration of missions by a mission specialist without reprogramming at lower levels. The Tactical level realizes vehicle behaviors as the methods of software objects programmed in an object-based language such as Ada. These behaviors are initiated by rule satisfaction at the Strategic level, thereby rationalizing their interaction. The Execution level is programmed in any imperative language capable of supporting efficient execution of real-time control of the underlying vehicle hardware.",project-academic
,2020-03-10,,,unmanned aerial vehicle visual angle vehicle identification tracking method based on reinforcement learning," The invention discloses an unmanned aerial vehicle visual angle vehicle identification tracking method based on reinforcement learning. Based on unmanned aerial vehicle visual angle scene understanding, monitoring and tracking, efficient and self-adaptive panoramic video management is established, and through a transfer learning target tracking method of reinforcement learning, the unmanned aerialvehicle can perform self-adaptive fast moving vehicle tracking under the non-supervision condition. The cross-view and cross-azimuth space-ground cooperative tracking system is realized through ground camera data, cooperative processing and re-identification information and algorithms, so that traffic analysis does not pay attention to repeated video annotation work any more, the labor force of manual monitoring is liberated, and automatic analysis and monitoring application can be quickly, efficiently and accurately carried out according to an initialization target vehicle provided by software in advance.",project-academic
10.1109/ROBOT.1986.1087518,1986-04-01,p,IEEE,architecture and early experience with planning for the alv," This paper describes the software architecture and the initial algorithms that have proved to be effective for a real time robot planning system. The architecture is designed to incorporate planning technology from research on artificial intelligence while at the same time supporting the high performance decision making needed to control a fast-moving autonomous vehicle. The symbolic representation of the vehicle's plan is a key element in this architecture. Our initial algorithms use an especially efficient version of dynamic programming to find the best routes. The route is then translated into a symbolic plan. Replanning happens at several levels with the cost of replanning proportionate to the scope of the changes. This software is currently running in an environment which simulates the vehicle and perception systems, but it will be transferred to the DARPA Autonomous Land Vehicle built by Martin Marietta Denver Aerospace [Lowrie 86].",project-academic
10.1109/UVS.2019.8658283,2019-02-01,p,IEEE,automatic fault detection of power lines using unmanned aerial vehicle uav," Safety and automation are the two major challenges in the application of Unmanned Aerial Vehicle (UAV), commonly known as drone, to the power lines inspection and fault detection. While current state-of-the-art UAVs are equipped with collision avoidance features, there is less attention to the automatic and real-time fault detection of power lines using UAVs. This paper presents the architecture of three drone-oriented concept designs for automatic and real-time fault detection of power lines using UAVs. The proposed systems could be potential candidates for replacing traditional inspection methods of power lines, which are risky and costly. By incorporating a robust neural network, i.e., Artificial Intelligence (AI), and using appropriate and efficient sensors, the systems can automatically detect various faults and defects on power lines with high precision. We propose three concept design options comprised of different hardware/software components and their feasibility factors. For instance, FLIR Duo Pro R as a thermal sensor and Zenmuse XT for thermal vision have been proposed to be used in the concept designs. For data communication, the proposed designs use cloud-based virtual private network (VPN) for a secure connection between remote control (RC) of the UAV and the server. Based on the advantages and disadvantages of the three proposed design options, the most efficient design is also discussed. This design proposes a system with lightweight sensors, which could increase the flight time of the UAV. Further, the AI interface is coded on to the RC, making it economical, without any database for big data storage. The back-end of the neural network is stored in a cloud server. With the help of GSM antenna, the AI can run on the tablet if there is an available cellular network.",project-academic
10.1109/ICUAS48674.2020.9213884,2020-09-01,p,Institute of Electrical and Electronics Engineers Inc.,image based sense and avoid of small scale uav using deep learning approach," Distance detection of target object is an important information for obstacle avoidance in many fields, such as autonomous car. When the distance of the obstacle is calculated, one can determine the potential risk of collision. In this paper, a monocular camera was utilized to get the distance from an incoming unmanned aerial vehicle (UAV) using deep learning approach. The distance detection of an UAV using You Only Look Once (YOLO) object detector was proposed in this study. The region which contain the detected UAV was processed into 100 by 100 pixel and was input into the proposed model to estimate the distance of the target object. For the proposed model, a Convolutional Neural Network (CNN) was adopted to solve the regression problem. First, the feature extraction based on VGG network was performed, and then its results was applied to the distance network to estimate distance. Finally, Kalman filter was used to improve the object tracking when YOLO detector is not able to detect UAV and to smooth the estimated distance. The proposed model was trained only by using synthetic images from animation software and was validated by using both synthetic and real flight videos.",project-academic
10.1109/UIC-ATC.2017.8397582,2017-08-01,p,IEEE,autonomous uav forced graffiti detection and removal system based on machine learning," This paper proposes a smart graffiti clean-up system based on an autonomous Unmanned Aerial Vehicle (UAV) platform. This smart clean system is based on edge detection and machine learning algorithms to realize the detection and tracking of graffiti image in real time. In Graffiti detection, we aim to build a model to detect graffiti on walls which can help navigate the UAV to the correct coordinate and estimate the area of the graffiti. The data set which contain graffiti images are trained using machine learning techniques which will be used for the detections of the graffiti patterns. This will automate the process of detecting the location of the graffiti based on the edge detection technique and the model will be able to estimate the area of the graffiti. To achieve obstacle detection, and collision, a smart navigation approach is also proposed with the help of LiDAR and external camera. The overall graffiti cleanup system contains hardware and software that allow the user to use spray enamel with the reach and scale of an autonomous UAV.",project-academic
,2020-03-07,a,,a machine learning environment for evaluating autonomous driving software," Autonomous vehicles need safe development and testing environments. Many traffic scenarios are such that they cannot be tested in the real world. We see hybrid photorealistic simulation as a viable tool for developing AI (artificial intelligence) software for autonomous driving. We present a machine learning environment for detecting autonomous vehicle corner case behavior. Our environment is based on connecting the CARLA simulation software to TensorFlow machine learning framework and custom AI client software. The AI client software receives data from a simulated world via virtual sensors and transforms the data into information using machine learning models. The AI clients control vehicles in the simulated world. Our environment monitors the state assumed by the vehicle AIs to the ground truth state derived from the simulation model. Our system can search for corner cases where the vehicle AI is unable to correctly understand the situation. In our paper, we present the overall hybrid simulator architecture and compare different configurations. We present performance measurements from real setups, and outline the main parameters affecting the hybrid simulator performance.",project-academic
10.2139/SSRN.3492778,2019-11-01,a,,building vehicle autonomy sensors semiconductors software and u s competitiveness," This paper describes the current state of driving automation, the components that go into autonomous vehicles, and U.S. firm participation in the sector. There are three main components that enable autonomous driving: sensors, semiconductors, and software. Sensors, including cameras, Light Detection and Ranging (LiDAR), and radar are used together to help vehicles see road conditions at various distances, and in different weather and lighting conditions. Semiconductors facilitate the processing of data gathered by sensors in order to make real time driving decisions. Machine learning and mapping software provide the tools to improve the operation and decision making of vehicles. U.S. firms, including vehicle manufacturers, parts suppliers, and tech companies are competing across all of the components of driving automation. As a new area of competition, there are opportunities for startups and for firms to move into new areas (e.g., vehicle manufacturers developing chips, and technology companies supplying automotive parts).",project-academic
10.1109/IPCCC50635.2020.9391526,2020-11-06,p,IEEE,software define radio in realizing the intruding uas group behavior prediction," With the advancement of unmanned aerial vehicle (UAV) technology, UAV swarm has been showing its great security threats towards the ground facility. With current technologies, it is still challenging in unknown UAV swarm tracking and neutralization. In this paper, we propose an analytical method in predicting drone flying behavior based on the machine learning algorithm, which could be integrated into swarm behavior prediction. Radiofrequency (RF) signals emitted from the UAV are captured by software-defined radio (SDR) to form the time series data. By using conventional short-time Fourier transform (STFT), a time-frequency spectrum revealing the RF data energy distribution is obtained for analyzing the signal variance pattern formed by the two different types of UAV flying trajectory. The transformed time-frequency domain matrix would be applied in multiple machine learning classifier for telling the difference of different flying trajectory. The results present the applicability of using machine learning in predicting the flying features and modes of intruding UAV swarm. It shows the potential application of this method in realizing effective UAV swarm negation.",project-academic
10.1016/J.DCAN.2021.09.006,2021-09-17,a,Elsevier BV,huge deeppose detecting gps spoofing attack via deep recurrent neural network," Abstract None None The Global Positioning System (GPS) has become a foundation for most location-based services and navigation systems, such as autonomous vehicles, drones, ships, and wearable devices. However, it is a challenge to verify if the reported geographic locations are valid due to various GPS spoofing tools. The existence of pervasive tools, such as Fake GPS, Lockito, and software-defined radio, makes it feasible for ordinary users to hijack and report fake GPS coordinates, to cheat the monitoring server without being detected. Furthermore, it is also a challenge to get accurate sensor readings on mobile devices because of the high noise level introduced by commercial motion sensors. To this end, we propose DeepPOSE, a deep learning model, to address the noise introduced in sensor readings and detect GPS spoofing attacks on mobile platforms. Our design uses a convolutional and recurrent neural network to reduce the noise, to recover a vehicle’s real-time trajectory from multiple sensor inputs. We further propose a novel scheme to map the constructed trajectory from sensor readings onto the Google map, to smartly eliminate the accumulation of errors on the trajectory estimation. The reconstructed trajectory from sensors is then used to detect the GPS spoofing attack. Compared with the existing method, the proposed approach demonstrates a significantly higher degree of accuracy for detecting GPS spoofing attacks.",project-academic
10.1016/J.NEUNET.2009.06.032,2009-07-01,a,Neural Netw,2009 special issue extending the evolutionary robotics approach to flying machines an application to mav teams," The work presented in this article focuses on the use of embodied neural networks-developed through Evolutionary Robotics and Multi-Agent Systems methodologies-as autonomous distributed controllers for Micro-unmanned Aerial Vehicle (MAV) teams. The main aim of the research is to extend the range of domains that could be successfully tackled by the Evolutionary Robotics approach. The flying robots realm is an area that has not been yet thoroughly investigated by this discipline. This is due to the lack of an affordable and reliable robotic platform to use for carrying out experiments, and to the difficulty and the high computational load involved in experiments based upon a realistic software simulator for aircraft. We believe that the most recent improvements to the state of the art now permit the investigation of this domain. For demonstrating this point, two different evolutionary computer simulation models are presented in this article. The first model, which uses a simplified 2D test environment, has resulted in controllers evolved with the following capabilities: (1) navigation through unknown environments, (2) obstacle-avoidance, (3) tracking of a movable target, and (4) execution of cooperative and coordinated behaviors based on implicit communication strategies. In order to improve the robustness of these results and their potential use in real MAV teams, a more sophisticated 3D model is presented herein. The results obtained so far using the two models demonstrate the feasibility of the chosen approach for further research on the design of autonomous controllers for MAVs.",project-academic
10.2174/1874155X01307010040,2013-10-18,a,Bentham Science Publishers Ltd.,an auv for ocean exploring and its motion control system architecture," With the development of exploring and utilizing ocean source, Autonomous Underwater Vehicle (AUV) which could finish autonomous mission process is paid more and more attention. As an artificial intelligence system, AUV has high independence, reliability and adaptability to ocean environment. An efficient architecture of AUV plays an important role in achieving those properties. A newly developed AUV, ""ZT-AUV"", which is used for ocean exploring, is introduced. And its motion control system architecture is described. The architecture is divided into four parts including blackboard system, elementary behavior agent group, reflection behavior agent group and execution agent. The blackboard system is not only information processing and management center, but also agents' behavior control center. As the executable unit of motion controller, elementary behavior agent group makes AUV achieve three kinds of motion including surge, yaw and heave by certain control algorithm. Reflection behavior agent group is the unit by which the behavior of AUV can be achieved in another way, and it works when the system has fault. Execution agent finally drives the actuators of the system. The structures of the four parts mentioned above are discussed respectively. Both the hardware and software are described. Finally, simulation experiments and real experiments are conducted to test the whole system, and the results prove that the system architecture is reliable, flexible and extensible.",project-academic
,2011-03-25,a,,fuzzy logic approach in real time uav control," The current article presents a fuzzy logic approach for creating an artificial intelligent and autonomous pilot for unmanned aerial vehicle. The article presents a new way of identifying the position of the UAV relative to a destination point, based on two angles: deflection angle and relative angle. The major advantage of the presented method (over other artificial intelligent methods like genetic programming or neural networks) is the way of taking decisions in real-time, without the need of presenting any domain specific data to the system before running the simulation. In this article, a professional flight simulator - Microsoft Flight Simulator X (FSX) - is used and its software development kit (SDK), and therefore, all computations are specific to this flight simulator. The aircraft that is used is a real UAV - General Atomics RQ/MQ-1 Predator - an FSX add-on.",project-academic
,2017-12-12,a,,simulated autonomous driving on realistic road networks using deep reinforcement learning," Using Deep Reinforcement Learning (DRL) can be a promising approach to handle various tasks in the field of (simulated) autonomous driving. However, recent publications mainly consider learning in unusual driving environments. This paper presents Driving School for Autonomous Agents (DSA^2), a software for validating DRL algorithms in more usual driving environments based on artificial and realistic road networks. We also present the results of applying DSA^2 for handling the task of driving on a straight road while regulating the velocity of one vehicle according to different speed limits.",project-academic
10.1007/978-981-15-8462-6_24,2020-10-16,a,"Springer, Singapore",research on autonomous driving perception test based on adversarial examples," Recently some accidents brought the safety of autonomous vehicles to the public’s attention. Autonomous vehicles are not only hardware products, but also a system of multi-sensor perception modules and Deep Neural Networks (DNNs) software. There are many methods to test traditional software. However, finding a good enough software testing method for vehicles on-board DNNs models is still an open problem. In this paper, we provide a testing method based on boundary value testing. For DNNs, many studies have shown that adversarial examples can disable DNNs, and they are often closed to the decision boundary. Therefore, adversarial examples can be used as test cases. To accomplish this task, we use two novel algorithms to design boundary value test cases: a white-box method based on gradient information and a black-box method using Deep Reinforcement Learning. Further, we propose a whole testing procedure, including a computer simulation test, sensor unit test and real vehicle test. The experimental results show that it is feasible to use adversarial examples for testing and our method could increase efficiency. Our work may have inspirations for automobile manufacturers and researchers.",project-academic
,2018-02-16,,,super large scale anti jamming customized high speed traffic system and operation method of the same," The invention relates to a super-large scale anti-jamming customized high speed traffic system and an operation method of the same. The super-large scale anti-jamming customized high speed traffic system is an air intelligent traffic control system which is formed by totally-stereo elevated tracks, unmanned electric intelligent vehicles, an elevated station, a track transfer apparatus, an intelligent scheduling system and the like, wherein a passenger calls an intelligent vehicle nearby the elevated station, and determines to get on at the entrance; and the system automatically calculates theoptimal operation path and performs real-time acquisition on the mass operation data of intelligent vehicles, analyzes and processing the feedback operation data through the big data technology and the artificial intelligence algorithm to form a customized terminal-to-terminal traffic system, and adjusts operation of vehicles according to the intelligent scheduling algorithm. Therefore, the super-large scale anti-jamming customized high speed traffic system can realize the anti-jamming capability under super-large scale operation to smooth and optimize the traffic of the overall traffic system, and can realize a novel traffic system that traffic is defined by software through a control platform. The super-large scale anti-jamming customized high speed traffic system defines traffic throughsoftware, and all the vehicles are totally scheduled through the intelligent scheduling system, so that the super-large scale anti-jamming customized high speed traffic system is efficient in operation and can avoid jam.",project-academic
,2017-01-01,a,University of Glasgow,machine learning techniques to estimate the dynamics of a slung load multirotor uav system," This thesis addresses the question of designing robust and flexible controllers to enable autonomous operation of a multirotor UAV with an attached slung load for general cargo transport. This is achieved by following an experimental approach; real flight data from a slung load multirotor coupled system is used as experience, allowing for a computer software to estimate the pose of the slung in order to propose a swing-free controller that will dampen the oscillations of the slung load when the multirotor is following a desired flight trajectory. The thesis presents the reader with a methodology describing the development path from vehicle design and modelling over slung load state estimators to controller synthesis.

Attaching a load via a cable to the underside of the aircraft alters the mass distribution of the combined ""airborne entity"" in a highly dynamic fashion. The load will be subject to inertial, gravitational and unsteady aerodynamic forces which are transmitted to the aircraft via the cable, providing another source of external force to the multirotor platform and thus altering the flight dynamic response characteristics of the vehicle. Similarly the load relies on the forces transmitted by the multirotor to alter its state, which is much more difficult to control. The principle research hypothesis of this thesis is that the dynamics of the coupled system can be identified by applying Machine Learning techniques.

One of the major contributions of this thesis is the estimator that uses real flight data to train an unstructured black-box algorithm that can output the position vector of the load using the vehicle pose and pilot pseudo-controls as input. Experimental results show very accurate position estimation of the load using the machine learning estimator when comparing it with a motion tracking system (~2% offset). Another contribution lies in the avionics solution created for data collection, algorithm execution and control of multirotor UAVs, experimental results show successful autonomous flight with a range of algorithms and applications. Finally, to enable flight capabilities of a multirotor with slung load, a control system is developed that dampens the oscillations of the load; the controller uses a feedback approach to simultaneously prevent exciting swing and to actively dampen swing in the slung load. The methods and algorithms developed in this thesis are validated by flight testing.",project-academic
,2019-07-17,a,,end to end sensor modeling for lidar point cloud," Advanced sensors are a key to enable self-driving cars technology. Laser scanner sensors (LiDAR, Light Detection And Ranging) became a fundamental choice due to its long-range and robustness to low light driving conditions. The problem of designing a control software for self-driving cars is a complex task to explicitly formulate in rule-based systems, thus recent approaches rely on machine learning that can learn those rules from data. The major problem with such approaches is that the amount of training data required for generalizing a machine learning model is big, and on the other hand LiDAR data annotation is very costly compared to other car sensors. An accurate LiDAR sensor model can cope with such problem. Moreover, its value goes beyond this because existing LiDAR development, validation, and evaluation platforms and processes are very costly, and virtual testing and development environments are still immature in terms of physical properties representation. In this work we propose a novel Deep Learning-based LiDAR sensor model. This method models the sensor echos, using a Deep Neural Network to model echo pulse widths learned from real data using Polar Grid Maps (PGM). We benchmark our model performance against comprehensive real sensor data and very promising results are achieved that sets a baseline for future works.",project-academic
10.1109/ITSC.2019.8917398,2019-10-01,p,IEEE,end to end sensor modeling for lidar point cloud," Advanced sensors are a key to enable self-driving cars technology. Laser scanner sensors (LiDAR, Light Detection And Ranging) became a fundamental choice due to its long-range and robustness to low light driving conditions. The problem of designing a control software for self-driving cars is a complex task to explicitly formulate in rule-based systems, thus recent approaches rely on machine learning that can learn those rules from data. The major problem with such approaches is that the amount of training data required for generalizing a machine learning model is big, and on the other hand LiDAR data annotation is very costly compared to other car sensors. An accurate LiDAR sensor model can cope with such problem. Moreover, its value goes beyond this because existing LiDAR development, validation, and evaluation platforms and processes are very costly, and virtual testing and development environments are still immature in terms of physical properties representation.In this work we propose a novel Deep Learning-based LiDAR sensor model. This method models the sensor echos, using a Deep Neural Network to model echo pulse widths learned from real data using Polar Grid Maps (PGM). We benchmark our model performance against comprehensive real sensor data and very promising results are achieved that sets a baseline for future works.",project-academic
10.1109/ICE2T.2017.8215979,2017-09-01,p,IEEE,application framework for forest surveillance and data acquisition using unmanned aerial vehicle system," An application framework is proposed in this paper that considers low cost surveillance mechanism and data acquisition in the forest. An application is developed as proof of concept with detailed design that can take advantage of unmanned urban vehicle to be directly configured and controlled in real-time. The advantages are numerous; it can be used for many purposes. For example, it can be used for observing critical and important area for intruder activities or to know the current state of any object of interest. We considered using machine learning and image processing and can be used for species of trees in the forest by color and size detection. A separate service running on separate remote server will be responsible for this. We have proposed a application framework particularly to be cheap and targeted to be easy to handle by non-technical persons and that it does not require large software system knowledge like Pix4D or DroneDeploy. This system will be useful for operations and research specially the forestry and palm oil plantation surveillance, and sustainable timber industry that specially needs carefully collected imageries and data from objects. Collection of raw data from sensor networks is also proposed in the system architecture.",project-academic
10.18799/24131830/2019/11/2346,2019-11-15,a,Государственное образовательное учреждение высшего профессионального образования «Томский политехнический университет»,интеллектуальная система компьютерного зрения беспилотных летательных аппаратов для мониторинга технологических объектов предприятий нефтегазовой отрасли," The relevance of the research is caused by the necessity to develop modern computer vision systems for monitoring hazardous technological objects of oil and gas industry. The main aim of the research is to develop the intelligent computer vision system for unmanned aerial vehicles, which allows monitoring dangerous technological objects and analyzing the monitoring data in real-time on the board of the unmanned aerial vehicle. Objects: the concept of construction of intelligent computer vision system; new architectures of convolutional neural networks hardware-based using field programmable gate array; the method of unification of computing blocks and ways of parallel calculation in hardware-based convolutional neural networks; algorithms of error-correction encoding and decoding data for exchanging message between ground and airborne components of the intelligent computer vision system.  Methods: methods of detection and classification objects in images using convolutional neural networks; convolutional neural network deep learning methods; methods of designing software and hardware systems. Results. We have been analyzed the current state of research in the field of monitoring hazardous technological objects of the oil and gas industry and developed the concept of construction of intelligent computer vision system for unmanned aerial vehicles for monitoring dangerous objects. The idea of analyzing the images, obtained at monitoring of technological objects and surrounding areas, directly onboard of the unmanned aerial vehicle in real time was the base in this concept. Moreover, it is shown that the use of hardware-based convolutional neural networks for providing such analysis in real time is required. The authors developed the convolutional neural networks architectures for computer vision system from promising subclasses LeNet5 and YOLO and proposed the algorithms of error-correction data encoding/decoding for messages exchanging between these components, considering the specifics of ground and airborne components. The authors developed the original method of organizing calculation in hardware-based convolutional neural networks using field programmable gate array, which differs from the known ones by using the unified computing blocks and new ways of parallel calculation in layers in these convolutional neural networks. They proposed the architecture of computing device of the unmanned aerial vehicle which includes the blocks of the hardware-based convolutional neural networks and the data encoder/decoder. This device is based on the Altera Cyclone V SX system-on-a-chip. The paper demonstrates the first results of studying the device efficiency. The authors developed the software for the ground component of the computer vision system.",project-academic
10.1109/ITSC45102.2020.9294684,2020-09-20,p,IEEE,creating value from in vehicle data detecting road surfaces and road hazards," An important component for the realization of the automated driving task is a holistic environment model. Connected and Autonomous Vehicles (CAVs) must be capable of detecting other vehicles, road markings, dangerous obstacles and upcoming road conditions. Apart from the comfort dependency on the road condition, friction values are calculated on the basis of road properties, which in turn are relevant for e.g. breaking and safety distances of CAVs. Due to the substitution of the human control task by the machine, this information must in future be detected by the vehicle itself. Based on the existing Vehicle Level Sensors (VLSs) and Acceleration Sensors (ASs) data, which are standard components in modern vehicles, a machine-learning approach of determining road surface materials and road hazards is presented. Our software solution of determining different road surface materials as asphalt, concrete, cobblestone or gravel with a total accuracy of 92.36% is presented. Furthermore, the results of the road hazards detection as potholes and speed bumps with a total accuracy of 92.39% is stated. Additionally to the edge calculations in the vehicle, our idea resolves in connected vehicles being capable of classifying road conditions enabling them to provide road analyses to a cloud platform. The goal is to establish a holistic cloud solution for road conditions to enable CAVs for the consumption of road condition data of upcoming road segments and empower them to adjust to those.",project-academic
10.1109/ICTC.2017.8190968,2017-10-01,p,IEEE,unmanned aerial vehicle surveillance system uavss for forest surveillance and data acquisition," An application framework is proposed in this paper that considers low cost surveillance mechanism and data acquisition in the forest. An application is developed as proof of concept with detailed design that can take advantage of unmanned urban vehicle to be directly configured and controlled in real-time. The advantages are numerous; it can be used for many purposes. For example, it can be used for observing critical and important area for intruder activities or to know the current state of any object of interest. We considered using machine learning and image processing and can be used for species of trees in the forest by color and size detection. A separate service running on separate remote server will be responsible for this. We have proposed a application framework particularly to be cheap and easy to handle by non-technical persons and that it does not require large software system knowledge like Pix4D or DroneDeploy. This system will be useful for operations and research specially the forestry and palm oil plantation surveillance, and sustainable timber industry that specially needs carefully collected imageries and data from objects. Collection of raw data from sensor networks is also proposed in the system architecture.",project-academic
10.1109/AERO47225.2020.9172376,2020-03-01,p,IEEE,using fault detection identification software with local awareness sensors to improve satellite resiliency," With 20,000 trackable orbital objects and hundreds of thousands of orbital debris too small to be cataloged, satellites today operate in an increasingly congested environment as more and more launches are performed. It is also common for a satellite to not be in 24/7 contact with the ground, this break in the communication network implying that when there is an anomalous event, there is often a longer downtime than desired. Coupling a probabilistic Artificial Intelligence (AI) system with local awareness sensors running onboard the vehicle, will enable the satellite to execute maneuvers to reduce the chances of an on-orbit collision and have higher resilience to the effects and dangers of space. To reduce the chances of the satellite being struck by debris the autonomous system could use local cameras to plan and execute maneuvers around reducing the chance of an on-orbit collision. By monitoring the local structural state health of the satellite using sensors, the satellite could be alerted when it has been struck by debris and which area of the satellite has been effected. The information from the monitoring local structure state health system can be used by an onboard autonomous system to not only update the operator but also plan around the damaged area if possible, so the overall mission can still be accomplished. At the Space Vehicle Directorate in the Air Force Research Laboratory (AFRL), software has been built to investigate aspects of this concept. This software has been designed to be modular with each executable performing a specific function. Each executable falls into one of three different categories: processing sensor data, analysis of the processed data, and decision making using the analyzed information (data fusion). Probabilistic model are used to infer and recommend a proper course of action. The initial capabilities of this concept have been tested with a hardware-in-the-loop (HIL) testbed. This testbed allows us to work with realistic attitude information, simulated high-fidelity orbital dynamics, and hardware emulating on-board local awareness sensors local awareness sensor hardware. Future work will focus on taking a version of this software and implement it on repeated 12-27U CubeSat missions, expanding our software and hardware library and improving the resiliency of the satellite.",project-academic
10.2139/SSRN.2293051,2013-05-23,a,,what will the law do about autonomous vehicles," Autonomous vehicles are just beginning to emerge on roads and highways all over the world. The autonomous vehicle prototypes available now provide some clues to understanding how law will apply to this developing technology. There appear to be several types of autonomous vehicles. Most of the experimental autonomous vehicles tend to be either self-contained or interconnected or some combination of these two types. Another category of autonomous vehicles, a self-willed autonomous vehicle, appears only in fiction - often fantasy or horror stories about vehicles run amok or falling in love with humans. More benign self-willed vehicles include Herbie the Love Bug and Chitty Chitty Bang Bang. Until the singularity, when machines are smarter than humans are, self-willed autonomous vehicles are likely to exist in our imaginations, rather than on the roads.It is not clear what the market for autonomous vehicles will be. Driving enthusiasts will probably avoid them. However, differently abled persons, such as persons with disabilities, as well as children and the elderly are likely to find autonomous vehicles especially attractive.Autonomous vehicles may possibly appeal to commuters, who find long daily commutes over boring roads tedious. However, whether ordinary consumers will be inclined to purchase autonomous vehicles remains a matter of speculation.In very general terms, autonomous vehicles are self-driving cars operated by artificial intelligence using automated controls and, usually, GPS. Internal vehicle sensors constantly monitor the car’s mechanical operation - such as its speed, steering, braking, and the like. The differences between the self-contained and interconnected autonomous vehicles lie in the ways in which the two types assess the dynamic driving environment on the roads where they travel.Self-contained autonomous vehicles gather and keep all information within the vehicle. They collect data from outward facing sensors (cameras, lidar, radar, etc.) to visualize and predict the changing roadway situation around the moving car. Most of the self-contained autonomous vehicle prototypes require that roadways on which these vehicles travel be mapped in advance by a human driver.On the other hand, the interconnected type of autonomous vehicle relies on real-time communications from other vehicles or the roadside to provide data about what is happening in the roadway environment in which it operates. Interconnected autonomous vehicles do not require pre-mapped routes, but rather rely on data about the driving environment that is communicated into the vehicle from outside sources.These technical differences result in a number of interesting legal questions that may have different answers depending on the type of autonomous vehicle. How should legal rules determine civil and criminal legal liability, for example, when an autonomous vehicle breaks a traffic rule or damages another’s vehicle or is involved in vehicular manslaughter? Products liability could be placed on the manufacturer or seller of the vehicle, on the hardware provider, or on the maker of the software used by the vehicle’s artificial intelligence. Privacy rights, insurance law, and regulatory jurisdiction have yet to be determined. As autonomous vehicles’ new, innovative transportation technology develops, the law also will need to innovate.",project-academic
10.1109/DASC50938.2020.9256611,2020-10-11,p,IEEE,natural language processing for autonomous identification of impactful changes to specification documents," Functional specification documents describe system requirements and component functionality. In avionics this would include Interface Control Documents (ICD) or Interface Design Descriptions (IDD). New and modified requirements drive changes to specifications, resulting in updates to the interface designs. When interface designs are updated, engineers and software developers are required to manually compare the previous and new versions of the documentation to determine the changes. This is a tedious and error-prone process. Natural Language Processing (NLP) can be leveraged to automatically determine and report the changes between two versions of a hardware or software interface specification. To this end, our work demonstrates a novel use of NLP, a branch of artificial intelligence aiding computers in understanding human (natural) languages, to autonomously identify and classify changes in a specification document. Using the identified specification changes, the corresponding source code was tagged with required changes (updates, additions, and deletions), with the goal of automatically modifying the source code based on changes made to the specification. Two versions of an existing specification within the ground vehicle community written in Markdown were parsed into abstract syntax trees (AST) before being saved into OrientDB graph databases, herein described as the specification databases. The source code to be updated was the Extensible Markup Language (XML) schema documents for a ground vehicle data network specification. The source code, too, was parsed into an OrientDB graph database, herein described as the code database. For each node in the specification databases, a direct comparison of text was performed, and a variety of NLP techniques were applied primarily using spaCy, a Python library with previously trained models and word vectors. The parent relationships of the most similar nodes were verified, and a numerical threshold was used to determine the state of the “change” and subsequent update, addition, or deletion to the code database. We provide an example use case for the application of NLP against different versions of specifications using a software architecture paradigm where the code is closely modelled with the corresponding documentation. Pre-written code templates are used for reoccurring patterns in the documentation. While it does require initial development of the templates and the structure of the code, we believe this approach to updating a carefully crafted code base based on NLP-identified specification updates will have more achievable results in the realm of autonomous code generation than other approaches to code generation. Our approach carries potential of supplying a more intelligent and automated solution to generate sophisticated and accurate specification documentation for the fast-paced avionics industry while ensuring relevant protocols and changes in individual component requirements from varying suppliers are met.",project-academic
10.1109/CTS.2008.4543953,2008-05-19,p,IEEE,intelligent decision support to assist real time collaboration," Under conditions associated with real-time decisions, humans may experience stressors such as information overload, time pressure, emotional intensity, and uncertainty. These pressures increase with distributed teams that must collaborate to make decisions in rapidly changing environments over networks due to factors such as delays or misunderstandings in communication. Intelligent decision support systems attempt to mitigate these issues by integrating capabilities from the human user and artificial intelligence. One of the most promising technologies for real applications is intelligent agents. Agents are generally described as software programs that are autonomous, adaptive, proactive, reactive, communicative, cooperative, mobile, goal- driven and persistent in performing their tasks. Using these characteristics, agents and multi-agent teams can be integrated into decision support systems to perform tasks such as monitoring, alerting, learning, and even making decisions. This talk looks at intelligent decision support for real-time collaboration. We present an application to an autonomous robotic vehicle in which decision making is shared by the human/machine team.",project-academic
10.1109/ICCAE.2010.5451523,2010-04-19,p,IEEE,autonomous agent oriented traffic control system," Emerging trends in software development has been changed due to the huge amount of data, growth of internet, mobile, dynamic and smart applications. Most of such applications consist of small, intelligent, flexible and distributed components known as agents. Number of agent methodologies has been presented but few of these are evaluated and verified. Due to the invention of agent technology, the way to analyze, design and build the systems has been changed. Agents take input from the multiple sources and have real time response. Vehicle traffic management especially in large cities is rapidly becoming one of the major challenges due to heavy growth in population and vehicles. Our research proposed a solution for traffic control and management system using intelligent/ autonomous agents technology. These agents have the ability to observe, act and learn from their experience. Our system uses the knowledge of flow of previous signal to predict the incoming flow for the next signal. The proposed architecture involves the video analysis and exploration using some machine learning techniques to estimate and guess the flow of traffic.",project-academic
10.1007/978-1-4614-9120-0_4,2014-01-01,a,"Springer, New York, NY",unmanned ground vehicle otonobil design perception and decision algorithms," Unmanned ground vehicles (UGV) have been the subject of research in recent years due to their future prospective of solving the traffic congestion and improving the safety on roads while having a more energy-efficient profile. In this chapter, the first UGV of Turkey, Otonobil, will be introduced detailing especially on its hardware and software design architecture, the perception capabilities and decision algorithms used in obstacle avoidance, and autonomous goal-oriented docking. UGV Otonobil features a novel heuristic algorithm to avoid dynamic obstacles, and the vehicle is an open test-rig for studying several intelligent-vehicle technologies such as steer-by-wire, intelligent traction control, and further artificial intelligence algorithms for acting in real-traffic conditions.",project-academic
,2021-04-01,a,JETIR(www.jetir.org),application of generative design approach for optimization and additive manufacturing of uav s frame structure," Additive manufacturing (AM) has the potential to change the way products are made, packaged, and marketed to consumers. Because of its ability to create complex geometries with customizable material properties, this technology has gotten a lot of attention from both academia and industry. AM has aided the development of the maker movement by democratizing design and manufacturing. In recent years, generative methods have risen in popularity across a wide range of technical fields. Using artificial intelligence software, they can elaborate and recommend a series of realistic solutions for a design problem to a human user. This paper describes the overall design of a UAV (Unmanned Air Vehicle) frame, followed by an analysis of the frame using the FUSION 360 programme. Choosing the right material and structure to meet the system's rigidity and strength requirements.",project-academic
,2021-06-23,a,,objects detection for self driving cars using yolo algorithm," In the world of trending tech and autonomous uprising capacity of machines, the benchmarks set by both of the advancements mentioned above resulted in bleeding-edge technology, namely Self-Driving Cars or Autonomous Vehicles (AV's). An autonomous vehicle is one that navigates between destinations without the assistance of a human operator, using data from sensors, cameras, radar, and artificial intelligence (AI). Self-driving cars' functionality lies in how the developers use vast amounts of data from machine learning and neural networks. They create and store a map of their surroundings based on various sensors placed on different vehicle parts. The sensors used are Radar, Lidar (light detection and ranging), ultrasonic sensors. After processing all of this sensory data, sophisticated software creates a route and sends instructions to the car's actuators, which control acceleration, braking, and steering.
 The main difficulty in AVs comes through the detection of objects which were surrounded by the vehicle.As a result, many algorithms were developed, like HOG (Histograms of Oriented Gradients, 2005), R-CNN (Region Convolutional Neural Network), and YOLO (YOU ONLY LOOK ONCE). Out of them, YOLO is a transparent convolutional neural network for detecting the object in real-time. This method has several advantages compared to the algorithms mentioned above because it looks at the image entirely by predicting the bounding boxes to see the kind of object. As of now, there are four versions of YOLO developed from YOLO v1 to YOLO v4. YOLO is fast and accurate, and thus it outperforms the other algorithms and is so used widely across many aspects like self-driving cars.
How to cite this article:Kumar NL, Maram B. Objects Detection for Self Driving Cars using YOLO Algorithm. J Adv Res Auto Tech Transp Sys 2021; 5(1): 17-23.",project-academic
10.1109/ICCMC51019.2021.9418403,2021-04-08,p,IEEE,ai based autonomous driving assistance system," The immense growth and research in modern technology have led to convenience and comfort becoming mankind’s demand and first priority in any technology presented to them. With this, automation has become the need of the hour. The use of automation in cars is one such area that is getting more and more importance and recognition around the world. Driving demands total attention from the driver in activities such as lane-keeping and lane changing, slowing down at turns, keeping a watch on traffic lights and traffic signs, and handling the car in traffic. The smallest lapse in concentration can also prove to be very dangerous. Self-driving cars aim at making use of the latest technologies in Artificial Intelligence to automate as many features as possible and leave as little as possible for the driver to do. The main motive of the research work will be to develop a model of the software part needed for the efficient working of a driver assistance system on cars on real-time data and simulate it.",project-academic
,2021-02-26,,,intelligent patrol system of unmanned aerial vehicle based on parking apron cluster," The invention discloses an intelligent patrol system of an unmanned aerial vehicle based on a parking apron cluster and the system is characterized in that a ground station control system remotely controls an unmanned aerial vehicle, achieves autonomous flight of the unmanned aerial vehicle, and avoids limitation of a manual remote controller operation mode; the unmanned aerial vehicle flies according to the planned task path, performs image recognition through a built-in artificial intelligence module in the task execution process, and uploads abnormal data to the cloud platform for abnormalconditions; after the task is completed, accurate return shutdown and charging are carried out through two mutual correction modes of image recognition and positioning of a UWB base station positioning module of the parking apron and an artificial intelligence module of the unmanned aerial vehicle; the image recognition system recognizes a target picture and a video; the parking apron is matched with the unmanned aerial vehicle to ensure accurate landing and charging of the unmanned aerial vehicle; the cloud platform provides interface service and is used for data exchange and data managementbetween software and hardware. The invention is wide in patrol range, low in construction cost, high in safety, good in real-time performance and high in precision, and is not influenced by cloud layer conditions.",project-academic
10.1145/3292500.3340409,2019-07-25,p,ACM,building a better self driving car hardware software and knowledge," Lyft's mission is to improve people's lives with the world's best transportation. Self driving vehicles have the potential to deliver unprecedented improvements to safety and quality, at a price and convenience that challenges traditional models of vehicle ownership. A combination of hardware, software, and knowledge technologies are needed to build self-driving cars. In this talk, I'll present the core problems in self-driving and how recent advances in computer vision, robotics, and machine learning are powering this revolution. The car is carefully designed with a variety of sensors that complement each other to address a wide variety of driving scenarios. Sensor fusion bring all of these signals together into an interpretable AI engine comprising of perception, prediction, planning, and controls. For example, deep learning models and large scale machine learning have closed the gap between human and machine perception. In contrast, predicting the behavior of other humans and effectively planning and negotiating maneuvers continue to be hard problems. Combining AI technologies with deep knowledge about the real world is key to addressing these.",project-academic
,2020-12-18,a,,a complete end to end simulation flow for autonomous driving frameworks," The research on automotive industry in the last year focused on three main aspects: electric engine, advanced infotainment and autonomous driving. None Nowadays autonomous driving represents one of the hottest topics in the automotive field, since technology advancement in these last years, especially with the new discovery on Artificial Intelligence, allowed to lay the foundations for the development of fully autonomous vehicles and revolutionize the concept of autonomous mobility. None Since building a real vehicle equipped with the needed sensors is very expensive, it is critical to test every component, both hardware and software, considering all the possible scenarios where the vehicle may operate. It is clear how Software and Hardware in the Loop play a key role for the development, allowing a preliminary validation of the vehicle before road testing. However, this approach, to be reliable, requires a virtual environment that mimics the conditions of the real world. The goal of this thesis is to create an automated system for the generation of three-dimensional maps starting from simple 2D maps. The building of a structured simulation ready map, a detailed map containing information of the environment, starting from OpenStreetMap data is the key for reduce costs and time for fast prototyping of this new generation of algorithms. The map generation is accomplished by using Carla simulator, an Unreal Engine-based simulator. After this, the map is converted into a specific format suitable for an eventual field test by using a bridge between Carla and the ROS-based platform Autoware. The last part is dedicated to the evaluation of the achieved result considering possible limitations and improvements.",project-academic
,2019-07-01,a,,towards debugging and testing deep learning systems," Au cours des dernieres annees, l’apprentissage profond, en anglais Deep Learning (DL) a fait d’enormes progres, en atteignant et depassant meme parfois le niveau de performance des humains pour differentes tâches, telles que la classification des images et la reconnaissance vocale. Grâce a ces progres, nous constatons une large adoption du DL dans des applications critiques, telles que la conduite autonome de vehicules, la prevention et la detection du
crime, et le traitement medical. Cependant, malgre leurs progres spectaculaires, les systemes de DL, tout comme les logiciels traditionnels, presentent souvent des comportements errones en raison de l’existence de defauts caches ou d’inefficacites. Ces comportements errones
peuvent etre a l’origine d’accidents catastrophiques. Ainsi, l’assurance de la qualite des logiciels (SQA), y compris la fiabilite et la robustesse, pour les systemes de DL devient une preoccupation majeure. Les tests traditionnels pour les modeles de DL consistent a mesurer leurs performances sur des donnees collectees manuellement ; ils dependent donc fortement de la qualite des donnees de test qui, souvent, n’incluent pas de donnees d’entree rares, comme en
temoignent les recents accidents de voitures avec conduite autonome (exemple Tesla/Uber). Les techniques de test avancees sont tres demandees pour ameliorer la fiabilite des systemes de DL. Neanmoins, les tests des systemes de DL posent des defis importants, en raison de leur nature non-deterministe puisqu’ils suivent un paradigme axe sur les donnees (la tâche cible est apprise statistiquement) et leur manque d’oracle puisqu’ils sont concus principalement
pour fournir la reponse. Recemment, les chercheurs en genie logiciel ont commence a adapter des concepts du domaine du test logiciel tels que la couverture des cas de tests et
les pseudo-oracles, pour resoudre ces difficultes. Malgre les resultats prometteurs obtenus de cette renovation des methodes existantes de test logiciel, le domaine du test des systemes de DL est encore immature et les methodes proposees a ce jour ne sont pas tres efficaces. Dans ce memoire, nous examinons les solutions existantes proposees pour tester les systemes de DL et proposons quelques nouvelles techniques. Nous realisons cet objectif en suivant une approche systematique qui consiste a : (1) etudier les problemes et les defis lies aux tests des logiciels de DL; (2) souligner les forces et les faiblesses des techniques de test logiciel adaptees aux systemes de DL; (3) proposer de nouvelles solutions de test pour combler certaines lacunes identifiees dans la litterature, et potentiellement aider a ameliorer l’assurance qualite des systemes de DL.----------ABSTRACT: Over the past few years, Deep Learning (DL) has made tremendous progress, achieving or surpassing human-level performance for different tasks such as image classification and speech recognition. Thanks to these advances, we are witnessing a wide adoption of DL in safetycritical applications such as autonomous driving cars, crime prevention and detection, and medical treatment. However, despite their spectacular progress, DL systems, just like traditional software systems, often exhibit erroneous corner-cases behaviors due to the existence of
latent defects or inefficiencies, and which can lead to catastrophic accidents. Thus, software quality assurance (SQA), including reliability and robustness, for DL systems becomes a big concern. Traditional testing for DL models consists of measuring their performance on manually collected data ; so it heavily depends on the quality of the test data that often fails to include rare inputs, as evidenced by recent autonomous-driving car accidents (e.g., Tesla/Uber). Advanced testing techniques are in high demand to improve the trustworthiness of DL systems. Nevertheless, DL testing poses significant challenges stemming from the non-deterministic nature of DL systems (since they follow a data-driven paradigm ; the target task is learned
statistically) and their lack of oracle (since they are designed principally to provide the answer). Recently, software researchers have started adapting concepts from the software testing domain such as test coverage and pseudo-oracles to tackle these difficulties. Despite some
promising results obtained from adapting existing software testing methods, current software testing techniques for DL systems are still quite immature. In this thesis, we examine existing testing techniques for DL systems and propose some new techniques. We achieve this by following a systematic approach consisting of : (1) investigating DL software issues and testing challenges ; (2) outlining the strengths and weaknesses of the software-based testing techniques adapted for DL systems ; and (3) proposing novel testing solutions to fill some of the identified literature gaps, and potentially help improving the SQA of DL systems.",project-academic
,2019-07-17,a,Universidad de Sevilla,architecture for planning and execution of missions with fleets of unmanned vehicles," espanolEsta tesis presenta contribuciones en el campo de la planificacion automatica y la programacion de tareas, la rama de la inteligencia artificial que se ocupa de la realizacion de estrategias o secuencias de acciones tipicamente para su ejecucion por parte de vehiculos no tripulados, robots autonomos y/o agentes inteligentes. Cuando se intenta alcanzar un objetivo determinado, la cooperacion puede ser un aspecto clave. La complejidad de algunas tareas requiere la cooperacion entre varios agentes. Mas aun, incluso si una tarea es lo suficientemente simple para ser llevada a cabo por un unico agente, puede usarse la cooperacion para reducir el coste total de la misma. Para realizar tareas complejas que requieren interaccion fisica con el mundo real, los vehiculos no tripulados pueden ser usados como agentes. En los ultimos anos se han creado y utilizado una gran diversidad de plataformas no tripuladas, principalmente vehiculos que pueden ser dirigidos sin un humano a bordo, tanto en misiones civiles como militares. En esta tesis se aborda la aplicacion de planificacion simbolica de redes jerarquicas de tareas (HTN planning, por sus siglas en ingles) en la resolucion de problemas de enrutamiento de vehiculos (VRP, por sus siglas en ingles) [18], en dominios que implican multiples vehiculos no tripulados de capacidades heterogeneas que deben cooperar para alcanzar una serie de objetivos especificos. La planificacion con redes jerarquicas de tareas describe dominios utilizando una descripcion que descompone conjuntos de tareas en subconjuntos mas pequenos de subtareas gradualmente, hasta obtener tareas del mas bajo nivel que no pueden ser descompuestas y se consideran directamente ejecutables. Esta jerarquia es similar al modo en que los humanos razonan sobre los problemas, descomponiendolos en subproblemas segun el contexto, y por lo tanto suelen ser faciles de comprender y disenar. Los problemas de enrutamiento de vehiculos son una generalizacion del problema del viajante (TSP, por sus siglas en ingles). La resolucion del problema del viajante consiste en encontrar la ruta mas corta posible que permite visitar una lista de ciudades, partiendo y acabando en la misma ciudad. Su generalizacion, el problema de enrutamiento de vehiculos, consiste en encontrar el conjunto de rutas de longitud minima que permite cubrir todas las ciudades con un determinado numero de vehiculos. Ambos problemas cuentan con una fuerte componente combinatoria para su resolucion, especialmente en el caso del VRP, por lo que su presencia en dominios que van a ser tratados con un planificador HTN clasico supone un gran reto. Para la aplicacion de un planificador HTN en la resolucion de problemas de enrutamiento de vehiculos desarrollamos dos metodos. En el primero de ellos presentamos un sistema de optimizacion de soluciones basado en puntuaciones, que nos permite una nueva forma de conexion entre un software especializado en la resolucion del VRP con el planificador HTN. Llamamos a este modo de conexion el metodo desacoplado, puesto que resolvemos la componente combinatoria del problema de enrutamiento de vehiculos mediante un solucionador especifico que se comunica con el planificador HTN y le suministra la informacion necesaria para continuar con la descomposicion de tareas. El segundo metodo consiste en mejorar el planificador HTN utilizado para que sea capaz de resolver el problema de enrutamiento de vehiculos de la mejor forma posible sin tener que depender de modulos de software externos. Llamamos a este modo el metodo acoplado. Con este motivo hemos desarrollado un nuevo planificador HTN que utiliza un algoritmo de busqueda distinto del que se utiliza normalmente en planificadores de este tipo. Esta tesis presenta nuevas contribuciones en el campo de la planificacion con redes jerarquicas de tareas para la resolucion de problemas de enrutamiento de vehiculos. Se aplica una nueva forma de conexion entre dos planificadores independientes basada en un sistema de calculo de puntuaciones que les permite colaborar en la optimizacion de soluciones, y se presenta un nuevo planificador HTN con un algoritmo de busqueda distinto al comunmente utilizado. Se muestra la aplicacion de estos dos metodos en misiones civiles dentro del entorno de los Proyectos ARCAS y AEROARMS financiados por la Comision Europea y se presentan extensos resultados de simulacion para comprobar la validez de los dos metodos propuestos. EnglishThis thesis presents contributions in the field of automated planning and scheduling, the branch of artificial intelligence that concerns the realization of strategies or action sequences typically for execution by unmanned vehicles, autonomous robots and/or intelligent agents. When trying to achieve certain goal, cooperation may be a key aspect. The complexity of some tasks requires the cooperation among several agents. Moreover, even if the task is simple enough to be carried out by a single agent, cooperation can be used to decrease the overall cost of the operation. To perform complex tasks that require physical interaction with the real world, unmanned vehicles can be used as agents. In the last years a great variety of unmanned platforms, mainly vehicles that can be driven without a human on board, have been developed and used both in civil and military missions. This thesis deals with the application of Hierarchical Task Network (HTN) planning in the resolution of vehicle routing problems (VRP) [18] in domains involving multiple heterogeneous unmanned vehicles that must cooperate to achieve specific goals. HTN planning describes problem domains using a description that decomposes set of tasks into subsets of smaller tasks and so on, obtaining low-level tasks that cannot be further decomposed and are supposed to be executable. The hierarchy resembles the way the humans reason about problems by decomposing them into sub-problems depending on the context and therefore tend to be easy to understand and design. Vehicle routing problems are a generalization of the travelling salesman problem (TSP). The TSP consists on finding the shortest path that connects all the cities from a list, starting and ending on the same city. The VRP consists on finding the set of minimal routes that cover all cities by using a specific number of vehicles. Both problems have a combinatorial nature, specially the VRP, that makes it very difficult to use a HTN planner in domains where these problems are present. Two approaches to use a HTN planner in domains involving the VRP have been tested. The first approach consists on a score-based optimization system that allows us to apply a new way of connecting a software specialized in the resolution of the VRP with the HTN planner. We call this the decoupled approach, as we tackle the combinatorial nature of the VRP by using a specialized solver that communicates with the HTN planner and provides all the required information to do the task decomposition. The second approach consists on improving and enhancing the HTN planner to be capable of solving the VRP without needing the use of an external software. We call this the coupled approach. For this reason, a new HTN planner that uses a different search algorithm from these commonly used in that type of planners has been developed and is presented in this work. This thesis presents new contributions in the field of hierarchical task network planning for the resolution of vehicle routing problem domains. A new way of connecting two independent planning systems based on a score calculation system that lets them cooperate in the optimization of the solutions is applied, and a new HTN planner that uses a different search algorithm from that usually used in other HTN planners is presented. These two methods are applied in civil missions in the framework of the ARCAS and AEROARMS Projects funded by the European Commission. Extensive simulation results are presented to test the validity of the two approaches.",project-academic
,2018-11-09,,,systems and methods for safe and reliable self driving vehicles," Autonomous driving is one of the most difficult computational problems in the world. Very large amounts of data from cameras, radar, lidar, and HD maps must be processed to generate commands to control a car safely and comfortably in real time. This difficult task requires breakthroughs in dedicated supercomputers, which are energy-efficient, low-power composite high-performance software, and deep learning AI algorithms. To address this task, the technology provides advanced systems and methods that facilitate autonomous driving functions, including platforms for autonomous driving levels 3, 4, and / or 5. In a preferred embodiment, the technology provides a flexible architecture that provides diversity and redundancy, including architecture for self-driving vehicles that leverage computer vision and known ADAS techniques, and meets functional safety standards. Providing an end-to-end platform. The technology is faster, more reliable and more reliable and can be incorporated into flexible and expandable platforms that enable a wide range of self-driving vehicles, including cars, taxis, trucks and buses, as well as ships and aircraft. It provides a safe, energy efficient and space efficient system-on-chip.",project-academic
,2016-11-23,,,unmanned aerial vehicle bionic intelligent obstacle avoiding method based on light streams," The invention discloses an unmanned aerial vehicle bionic intelligent obstacle-avoiding method based on light streams and belongs to the field of artificial intelligence and computer vision. Obstacle-avoiding flight of an unmanned aerial vehicle is realized through combination of software and hardware. The method comprises the specific steps that an image sequence is captured through a monocular camera carried on the unmanned aerial vehicle, an LK (Lucas Kanade) method is used for calculating a light stream field according to a front frame image and a rear frame image, and noise light streams are filtered; each image is divided into an edge, a left middle part and a right middle part, and whether large obstacles exist on the left side and the right side or not is judged based on an SVM classifier; the sum of TTC in all columns is calculated, free sections and obstacle sections are calibrated and interpolated, and a maximum free communicating section is obtained; a translation amount and a rotation amount are obtained in combination with a left and right light stream balancing strategy, and therefore the unmanned aerial vehicle is controlled to fly avoiding obstacles. By means of the method, real-time obstacle-avoiding flight of the unmanned aerial vehicle in an unknown disordered environment can be realized.",project-academic
10.2514/6.IAC-03-U.2.A.04,2003-09-29,p,American Institute of Aeronautics and Astronautics,growing dependability using a multi agent approach to fault tolerance," The use of Artificial Intelligence (AI) in creating autonomous, fault tolerant systems is becoming increasingly important for complex space software. Recent applications of a single intelligent agent in deep space probe management have highlighted the potential of AI in space applications. Whilst highly suited to small spacecraft, this type of approach can represent a single point of failure and is less than ideal for highly complex systems with distributed centres of computing and without the potential for standby operating states. We present an argument in favour of software built from multiple agents as a useful representation of a complex, fallible system. We propose a novel approach to the development of highly dependable space systems software using multiple agents to react cooperatively and autonomously to fault conditions. To further explain our approach, we discuss the system in the context of the Skylon spaceplane, an autonomous SSTO launch vehicle, highlighting the need for fault tolerance and dependability within hard real-time constraints. Finally, we discuss the challenges in applying multiagent systems more widely in the software of complex space systems.",project-academic
,2020-10-12,a,,deep learning basato su immagini da drone per la super risoluzione di scene multispettrali acquisite da satellite deep learning based on uav data for super resolution of multispectral satellites scenes," La tecnologia legata all’utilizzo dei droni ha subito nell’ultimo decennio un forte sviluppo migliorando la stabilita del mezzo, alleggerendo la struttura, perfezionando precisione e accuratezza dell’acquisizione e ottimizzando i software per l’elaborazione dei dati. None Questa tecnologia trova applicazione in svariati ambiti tra cui quello del monitoraggio ambientale, permettendo di congiungere l’acquisizione di dati su una area vasta con una risoluzione elevata e con informazioni multispettrali. Tuttavia, e necessario effettuare un’analisi dei costi in funzione della scala di applicazione e delle specifiche condizioni dello studio di interesse per valutare quando il rilevamento con UAV (Unmanned Aerial Vehicle) risulti piu conveniente rispetto all’utilizzo di altre strumentazioni di Remote Sensing come le acquisizioni satellitari. None In questo contesto si inserisce l’utilizzo del machine learning, e in particolare della Super-Risoluzione, che puo trovare un’interessante applicazione nei casi in cui non prevalga, in termini di convenienza, una specifica tipologia di acquisizione da remoto. None None L’obiettivo di questo lavoro e lo studio dell’applicabilita della rete neurale VDSR (Very Deep Super Resolution) nel contesto del telerilevamento, utilizzando le immagini da drone come dati di base per allenare la rete e le immagini satellitari come immagini di input su cui migliorare la risoluzione. La valutazione del risultato si concentra su applicazioni di monitoraggio ambientale, in particolare sulla possibilita di identificare porzioni di territori agricoli con diversa attivita vegetativa sulla base di indici multispettrali, dunque in riferimento al comportamento spettrale. Per effettuare queste analisi i dati utilizzati contengono infatti informazioni nel campo delle lunghezze d’onda del visibile e dell’infrarosso vicino. None Nel primo capitolo si presentano le diverse tecnologie di Remote Sensing, ciascuna con i relativi vantaggi e svantaggi. Successivamente si esaminano nel dettaglio alcune camere multispettrali e iperspettrali utilizzabili per le acquisizioni con drone e si relazionano con il payload della missione satellitare selezionata come piu adatta per questo studio, la missione Copernicus Sentinel-2. Dopo questa prima parte sulle generalita delle due tecnologie utilizzate, si definisce l’algoritmo utilizzato per l’elaborazione dei dati, ossia la rete neurale convoluzionale VDSR. Si giunge dunque al centro dell’analisi, in cui si determinano i dati da utilizzare, i processamenti da effettuare per renderli idonei all’utilizzo, si definiscono le scelte per effettuare i test e gli strumenti con cui analizzare i risultati e valutarne l’accuratezza. Nel capitolo successivo sono riportati i risultati ottenuti. I test sono organizzati in due fasi: nella prima fase si eseguono le analisi su immagini RGB a colori reali al fine di consolidare il metodo; nella seconda fase si introducono le immagini multispettrali da cui sviluppare le specifiche analisi. Nella parte finale si commentano i risultati ottenuti, traendo le conclusioni relative all’utilizzo della rete VDSR per l’applicazione di monitoraggio ambientale studiata. Infine, nel capitolo degli allegati, si riportano le schede tecniche dei sensori, il codice per definire e utilizzare l’algoritmo della rete VDSR e gli elaborati grafici dei risultati ottenuti.",project-academic
10.1117/12.2540782,2019-12-18,p,International Society for Optics and Photonics,hardware and software complex for monitoring oil pollution of sea aquatories," A program for recognizing oil spill on the sea surface, based on an artificial intelligence element, was developed and tested on the example of real oil pollution in Peter the Great Bay for use on an unmanned aerial vehicle. The feature of the spectra of broadband radiation ascending from the sea surface is analyzed. It is concluded that the method of recording the spectra of the ascending radiation can be used to detect heavy oil fractions on the sea surface. A software algorithm for the formation of datasets of spectra of induced fluorescence of sea water containing various dissolved grades of petroleum products has been developed and tested. A machine learning procedure has been carried out to create a program element for classifying the type of oil hydrocarbons dissolved in seawater.",project-academic
,1988-06-01,a,"Monterey, California. Naval Postgraduate School",a prototype simulation system for combat vehicle coordination and motion visualization," Abstract : This thesis develops a prototype rule based command and control system for units of autonomous tactical vehicles. By applying artificial intelligence techniques, tactical coordination of multiple autonomous land vehicles is also accomplished. This study identifies the requirements for such a system and provides a prototype system with a sophisticated computer graphics simulator as a testing facility for future follow on research. This study was a joint research project. Andrew H. Nelson was responsible for the rule system modeling on the LISP machines and Corinne McConkle was responsible for the real time graphics motion visualization on the IRIS workstation. The networking software was developed jointly. Keywords: Autonomous vehicle; Artificial intelligence; Computer simulations; Rule based systems; Robotics; Ground vehicles; Autonomous navigation.",project-academic
10.1145/2377576.2377598,2010-09-28,p,ACM,measurement of autonomous operation," While robotic systems and the field of Artificial Intelligence (AI) have been funded through the Department Of Defense (DoD) and Industry for decades, it was not until recent years that the combination of these two technologies has made truly significant advances in the area of Autonomous Operation (AO) systems. Through the efforts of the Defense Advanced Research Project Agency (DARPA) challenges in 2004--2007 timeframe, the academic and industrial communities came together to overcome some significant hurdles for the development of AO ground vehicles in both the rural and desert environments (DARPA Grand Challenge 2004--2005) and the urban environment (DARPA Urban Challenge 2007). Although no AO vehicle succeeded in the 2004 event, the following year four systems completed the 132 mile course within the 10 hour time limit. The winner of the 2005 event (The Stanley from Stanford University) designed an autonomous (learning system) vehicle that fused five Lidars, Radar, and an Electro Optic sensor in addition to the waypoint GPS (provided by DARPA) and an internal Inertial Measurement Unit (IMU) system to produce the situational awareness required to meet the challenge. The team took approximately one year ""training"" the perception and planning sections of the software to compensate for various types of terrain and maneuvering. It was through extensive planning, meticulous design, and thorough testing that the final goal was achieved and it will take a much greater level of effort for DoD to realize a similar capability in the air environment.In the Air domain, DoD will not have the luxury of releasing autonomous vehicles (without significant constraints) within an operationally relevant environment (like the National Air Space (NAS)) until a very high level of confidence is achieved in their ability to perform the mission while providing a level of safety commensurate with manned operation. For DoD to succeed, it is imperative that we provide the Unmanned Air System (UAS) development community the tools required to assess all of the engineering components necessary for transition of AO vehicles into the NAS and operational environments. These tools should include a model of the required environments (emulated with access to standardized hardware/software in the loop), standard set of operational test procedures (with desired metrics), and a framework through which individual components can be assessed. It is ironic that the success of AO unmanned systems will require a structured collaborative learning process within the human domain for our goals to be realized.",project-academic
,2020-05-12,,,coal seam roof and floor path virtual planning method for fully mechanized mining equipment space time kinematics," The invention discloses a coal seam roof and floor path virtual planning method for fully mechanized mining equipment space-time kinematics. The method comprises the following steps of establishing aninherent coal seam roof and floor through Unity3d software; realizing real contact between fully mechanized mining equipment and the coal seam roof and floor by using a physical engine, and constructing a space-time kinematics relationship between the fully mechanized mining equipment and the coal seam roof and floor; dynamically generating a single-cycle coal seam roof and floor by using a meshcomponent, and cooperatively propelling a scraper conveyor and a hydraulic bracket along with the guidance of a coal mining machine; predicting the track of the coal seam roof and floor by using MATLAB and a machine learning algorithm, detecting the contour of the lower-cycle coal seam roof and floor by using detection equipment carried by an unmanned aerial vehicle, and continuously processing discrete points; and fusing the data detected by the unmanned aerial vehicle and the predicted data to obtain a lower-cycle coal seam roof and floor virtual planning path. Through the method, the blindness of track prediction of the coal seam roof and floor can be avoided, and prediction of the lower-cycle coal seam roof and floor and planning of a working path are realized.",project-academic
,2009-11-13,p,IEEE,depth control of an autonomous underwater vehicle in situational awareness a mission," This paper focuses on a critical component of the situational awareness (SA), the neural control of depth flight of an autonomous underwater vehicle (AUV). Constant depth flight is a challenging but important task for AUVs to achieve high level of autonomy under adverse conditions. The fundamental requirement for constant depth flight is the knowledge of the depth, and a properly designed controller to govern the process. With the SA strategy, we proposed a two stage depth control procedure using two adaptive neural networks to address the dynamics variation and performance requirement difference in various stages of AUV's trajectory for a nontrivial mid-small size AUV “r2D4” model. Two adaptive neural network controllers are designed for fast and stable diving maneuvers of this AUV model. This hybrid control strategy for chosen AUV model has been verified by simulation of diving maneuvers using software package Simulink and demonstrated good performance for fast SA in real-time search-and-rescue operations.",project-academic
,2007-01-01,a,Engineers Australia,truly autonomous uavs and teaming," There is broad consensus that future of air warfare will see the proliferation of uninhabited systems. Uninhabited Aerial Vehicle (UAV) technologies have been with us for some time now, but most are controlled via human operators located in ground stations, relying on human command and control to complete their missions. In recent years intelligent agent research and development aimed at replacing the pilot located with the ground station in UAV missions has provided examples of approaches worthy of exploration. The next challenge for UAV pilot-agents is: How do we team agents to complete a complex multi-platform mission autonomously? Improvements in Artificial Intelligence (AI) technologies offer the potential of realising this dream. None None The use of AI agents to represent battle field entities inside large simulations has been a significant focus of DSTO's Air Operations Division (AOD) research activities. However, moving from pilot-agent operation in a simulated environment to operation in the real world is qualitatively different. Teaming up a group of autonomous AI agent controlled UAVs is an even greater challenge. In order to truly reduce the human requirement within the mission control loop, a large degree of autonomous cooperative behaviour between platforms is required. The advantages of removing humans from the control loop include the ability to run longer missions with faster decision making processes and a smaller UAV support crew - advantages that can be achieved only with the use of agents that can communicate effectively with humans and each other and act in teams. None None AOD, Air Vehicle Division (AVD) and Weapons System Division (WSD) have combined to develop a basic concept demonstrator based on a small fixed-wing UAV platform. Recent field trials have exhibited teamed autonomous behaviour of multiple UAVs in a simple joint surveillance mission. This paper focuses on the software systems, the underlying research programme, the lessons learnt during the development and the field trials.",project-academic
,2013-12-20,a,E.T.S.I. Industriales (UPM),arquitectura de control para la conduccion autonoma de vehiculos en entornos urbanos y autovias," Hoy en dia, el desarrollo tecnologico en el campo de los sistemas inteligentes de transporte (ITS por sus siglas en ingles) ha permitido dotar a los vehiculos con diversos sistemas de ayuda a la conduccion (ADAS, del ingles advanced driver assistance system), mejorando la experiencia y seguridad de los pasajeros, en especial del conductor. La mayor parte de estos sistemas estan pensados para advertir al conductor sobre ciertas situaciones de riesgo, como la salida involuntaria del carril o la proximidad de obstaculos en el camino. No obstante, tambien podemos encontrar sistemas que van un paso mas alla y son capaces de cooperar con el conductor en el control del vehiculo o incluso relegarlos de algunas tareas tediosas. Es en este ultimo grupo donde se encuentran los sistemas de control electronico de estabilidad (ESP - Electronic Stability Program), el antibloqueo de frenos (ABS - Anti-lock Braking System), el control de crucero (CC - Cruise Control) y los mas recientes sistemas de aparcamiento asistido. Continuando con esta linea de desarrollo, el paso siguiente consiste en la supresion del conductor humano, desarrollando sistemas que sean capaces de conducir un vehiculo de forma autonoma y con un rendimiento superior al del conductor. En este trabajo se presenta, en primer lugar, una arquitectura de control para la automatizacion de vehiculos. Esta se compone de distintos componentes de hardware y software, agrupados de acuerdo a su funcion principal. El diseno de la arquitectura parte del trabajo previo desarrollado por el Programa AUTOPIA, aunque introduce notables aportaciones en cuanto a la eficiencia, robustez y escalabilidad del sistema. Ahondando un poco mas en detalle, debemos resaltar el desarrollo de un algoritmo de localizacion basado en enjambres de particulas. Este esta planteado como un metodo de filtrado y fusion de la informacion obtenida a partir de los distintos sensores embarcados en el vehiculo, entre los que encontramos un receptor GPS (Global Positioning System), unidades de medicion inercial (IMU – Inertial Measurement Unit) e informacion tomada directamente de los sensores embarcados por el fabricante, como la velocidad de las ruedas y posicion del volante. Gracias a este metodo se ha conseguido resolver el problema de la localizacion, indispensable para el desarrollo de sistemas de conduccion autonoma. Continuando con el trabajo de investigacion, se ha estudiado la viabilidad de la aplicacion de tecnicas de aprendizaje y adaptacion al diseno de controladores para el vehiculo. Como punto de partida se emplea el metodo de Q-learning para la generacion de un controlador borroso lateral sin ningun tipo de conocimiento previo. Posteriormente se presenta un metodo de ajuste on-line para la adaptacion del control longitudinal ante perturbaciones impredecibles del entorno, como lo son los cambios en la inclinacion del camino, friccion de las ruedas o peso de los ocupantes. Para finalizar, se presentan los resultados obtenidos durante un experimento de conduccion autonoma en carreteras reales, el cual se llevo a cabo en el mes de Junio de 2012 desde la poblacion de San Lorenzo de El Escorial hasta las instalaciones del Centro de Automatica y Robotica (CAR) en Arganda del Rey. El principal objetivo tras esta demostracion fue validar el funcionamiento, robustez y capacidad de la arquitectura propuesta para afrontar el problema de la conduccion autonoma, bajo condiciones mucho mas reales a las que se pueden alcanzar en las instalaciones de prueba. ABSTRACT Nowadays, the technological advances in the Intelligent Transportation Systems (ITS) field have led the development of several driving assistance systems (ADAS). These solutions are designed to improve the experience and security of all the passengers, especially the driver. For most of these systems, the main goal is to warn drivers about unexpected circumstances leading to risk situations such as involuntary lane departure or proximity to other vehicles. However, other ADAS go a step further, being able to cooperate with the driver in the control of the vehicle, or even overriding it on some tasks. Examples of this kind of systems are the anti-lock braking system (ABS), cruise control (CC) and the recently commercialised assisted parking systems. Within this research line, the next step is the development of systems able to replace the human drivers, improving the control and therefore, the safety and reliability of the vehicles. First of all, this dissertation presents a control architecture design for autonomous driving. It is made up of several hardware and software components, grouped according to their main function. The design of this architecture is based on the previous works carried out by the AUTOPIA Program, although notable improvements have been made regarding the efficiency, robustness and scalability of the system. It is also remarkable the work made on the development of a location algorithm for vehicles. The proposal is based on the emulation of the behaviour of biological swarms and its performance is similar to the well-known particle filters. The developed method combines information obtained from different sensors, including GPS, inertial measurement unit (IMU), and data from the original vehicle’s sensors on-board. Through this filtering algorithm the localization problem is properly managed, which is critical for the development of autonomous driving systems. The work deals also with the fuzzy control tuning system, a very time consuming task when done manually. An analysis of learning and adaptation techniques for the development of different controllers has been made. First, the Q-learning –a reinforcement learning method– has been applied to the generation of a lateral fuzzy controller from scratch. Subsequently, the development of an adaptation method for longitudinal control is presented. With this proposal, a final cruise control controller is able to deal with unpredictable environment disturbances, such as road slope, wheel’s friction or even occupants’ weight. As a testbed for the system, an autonomous driving experiment on real roads is presented. This experiment was carried out on June 2012, driving from San Lorenzo de El Escorial up to the Center for Automation and Robotics (CAR) facilities in Arganda del Rey. The main goal of the demonstration was validating the performance, robustness and viability of the proposed architecture to deal with the problem of autonomous driving under more demanding conditions than those achieved on closed test tracks.",project-academic
,1991-09-01,a,,ai for rpvs sensor driven airborne replanner sdar for a robotic aircraft sensor platform rasp," Abstract : This report describes the Robotic Aircraft Sensor Platform (RASP) simulation developed at the Naval Air Development Center in Warminster, PA. It is extracted from the final report of a three year research effort into the architectures needed to develop real time Artificial Intelligence (AI) techniques for autonomous aircraft. A hardware and associated software architecture has been developed to use on-board sensor information for high level AI decision making. The decisions then direct the flight path of the aircraft and camera gimbal through complex environments. This project has produced a system architecture that breaks the bottleneck of flyable real-time AI control systems. The work has transitioned into three new efforts; a flight test effort for the Unmanned Air Vehicle Joint Program Office, an investigation into use of SDAR for novel systems of sensors and platforms such as the Tactical Imaging System, and a study of applying this technology to manned platforms to assist human operators.",project-academic
10.1109/ISAECT50560.2020.9523700,2020-11-25,p,IEEE,edge cloud architectures using uavs dedicated to industrial iot monitoring and control applications," The deployment of new technologies to ease the control and management of a massive data volume and its uncertainty is a very significant challenge in the industry. Under the name ""Smart Factory"", the Industrial Internet of Things (IoT) aims to send data from systems that monitor and control the physical world to data processing systems for which cloud computing has proven to be an important tool to meet processing needs. unmanned aerial vehicles (UAVs) are now being introduced as part of IIoT and can perform important tasks. UAVs are now considered one of the best remote sensing techniques for collecting data over large areas. In the field of fog and edge computing, the IoT gateway connects various objects and sensors to the Internet. It function as a common interface for different networks and support different communication protocols. Edge intelligence is expected to replace Deep Learning (DL) computing in the cloud, providing a variety of distributed, low-latency and reliable intelligent services. In this paper, An unmanned aerial vehicle is automatically integrated into an industrial control system through an IoT gateway platform. Rather than sending photos from the UAV to the cloud for processing, an AI cloud trained model is deployed in the IoT gateway and used to process the taken photos. This model is designed to overcome the latency channels of the cloud computing architecture. The results show that the monitoring and tracking process using advanced computing in the IoT gateway is significantly faster than in the cloud.",project-academic
10.1109/AICAS51828.2021.9458488,2021-06-06,p,IEEE,evaluation of machine learning based detection against side channel attacks on autonomous vehicle," Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world has introduced new security risks. Recent studies have shown that using Cache-based Side-Channel Attacks (SCAs) could infer sensitive users’ information (e.g., which route the user is taking) highlighting significant vulnerability posed to today’s computer systems. As a result, it is crucial to propose effective detection mechanisms against emerging microarchitectural SCAs on autonomous driving systems. In response, we first identify the threat model and victim applications of autonomous driving systems in this work. Next, we explore the suitability of various machine learning-based classifiers trained by information collected from built-in hardware performance counter registers available in modern autonomous vehicle systems. To this end, various supervised machine learning models are implemented for cache-based SCAs detection and precisely compared and characterized in terms of detection accuracy, robustness, and latency of the detection. Our experiments conducted on an Intel Xeon, which Waymo autonomous driving vendor uses, demonstrate that J48 achieves 99.5% accuracy with the highest efficiency compared with other investigated models.",project-academic
,2017-10-01,p,,work in progress testing autonomous cyber physical systems using fuzzing features from convolutional neural networks, Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional filters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA’s end-to-end self-driving deep neural net running on the Udacity open-source simulator.,project-academic
10.1145/3125503.3125568,2017-10-15,p,ACM,testing autonomous cyber physical systems using fuzzing features from convolutional neural networks work in progress, Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyber-physical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional filters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator.,project-academic
10.25394/PGS.15057192.V1,2021-07-26,a,Purdue University Graduate School,voice command recognition with deep neural network on edge devices," Interconnected devices are becoming attractive solutions to integrate physical parameters and making them more accessible for further analysis. Edge devices, located at the end of the physical world, measure and transfer data to the remote server using either wired or wireless communication. The exploding number of sensors, being used in the Internet of Things (IoT), medical fields, or industry, are demanding huge bandwidth and computational capabilities in the cloud, to be processed by Artificial Neural Networks (ANNs) – especially, processing audio, video and images from hundreds of edge devices. None Additionally, continuous transmission of information to the remote server not only hampers privacy but also increases latency and takes more power. Deep Neural Network (DNN) is proving to be very effective for cognitive tasks, such as speech recognition, object detection, etc., and attracting researchers to apply it in edge devices. Microcontrollers and single-board computers are the most commonly used types of edge devices. These have gone through significant advancements over the years and capable of performing more sophisticated computations, making it a reasonable choice to implement DNN. In this thesis, a DNN model is trained and implemented for Keyword Spotting (KWS) on two types of edge devices: a bare-metal embedded device (microcontroller) and a robot car. The unnecessary components and noise of audio samples are removed, and speech features are extracted using Mel-Frequency Cepstral Co-efficient (MFCC). In the bare-metal microcontroller platform, these features are efficiently extracted using Digital Signal Processing (DSP) library, which makes the calculation much faster. None A Depth wise Separable Convolutional Neural Network (DSCNN) based model is proposed and trained with an accuracy of about 91% with only 721 thousand trainable parameters. After implementing the DNN on the microcontroller, the converted model takes only 11.52 Kbyte (2.16%) RAM and 169.63 Kbyte (8.48%) Flash of the test device. It needs to perform 287,673 Multiply-and-Accumulate (MACC) operations and takes about 7ms to execute the model. This trained model is also implemented on the robot car, Jetbot, and designed a voice-controlled robotic vehicle. This robot accepts few selected voice commands-such as “go”, “stop”, etc. and executes accordingly with reasonable accuracy. The Jetbot takes about 15ms to execute the KWS. Thus, this study demonstrates the implementation of Neural Network based KWS on two different types of edge devices: a bare-metal embedded device without any Operating System (OS) and a robot car running on embedded Linux OS. It also shows the feasibility of bare-metal offline KWS implementation for autonomous systems, particularly autonomous vehicles.",project-academic
